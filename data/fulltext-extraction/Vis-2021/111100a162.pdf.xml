<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MultiVision: Designing Analytical Dashboards with Deep Learning Based Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Aoyu</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Yun</forename><surname>Wang</surname></persName>
							<email>wangyun@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Mengyu</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Xinyi</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Haidong</forename><surname>Zhang</surname></persName>
							<email>haidong.zhang@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="first">Huamin</forename><surname>Qu</surname></persName>
							<email>huamin@cse.ust</email>
						</author>
						<author>
							<persName><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
							<email>dongmeiz@microsoft.com</email>
						</author>
						<author>
							<persName><forename type="middle">Y</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">are from Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Microsoft Research Area</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MultiVision: Designing Analytical Dashboards with Deep Learning Based Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6969FE7ABB9081457D206FD0BC213FEE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T13:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visualization Recommendation</term>
					<term>Deep Learning</term>
					<term>Multiple-View</term>
					<term>Dashboard</term>
					<term>Mixed-Initiative</term>
					<term>Visualization Provenance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. The interface: A When uploading a tabular dataset, the Table Field shows data columns with the corresponding data type; B Clicking the Multiple-View Recommender will generate a dashboard containing a user-specified number of charts. The recommendation is conditioned on, if any, user-locked charts; C Users could specify the chart type, encoding channels, and data transformation in the Chart Editor; D Chart Ideas recommends charts based on the current dashboard; E The Dashboard View displays the charts in an interactive grid layout; and F Users could restore the history, change the theme, and save logs in Control Panel.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>dataset in a tabular format, followed by selecting the data of interests and creating corresponding charts (e.g., Excel <ref type="bibr" target="#b9">[10]</ref> and Tableau <ref type="bibr" target="#b55">[56]</ref>). However, users usually need to engage in a tedious and time-consuming process to explore different data selections through trial and error. Besides, it requires experience and expertise to create visualizations that effectively facilitate data analysis <ref type="bibr" target="#b37">[38]</ref>. This process is further complicated by the demands for creating multiple-view visualizations that enable simultaneous exploration of the same data from different perspectives <ref type="bibr" target="#b42">[43]</ref>. Due to those challenges, there have been huge research efforts in developing visualization recommendation systems that assist laypeople in conducting visual data exploration.</p><p>Most existing recommendation systems build upon visualization design knowledge gained from empirical experiments. For instance, APT <ref type="bibr" target="#b30">[31]</ref>, Show Me <ref type="bibr" target="#b31">[32]</ref>, and Voyager <ref type="bibr" target="#b61">[62]</ref> recommend visual encodings according to their effectiveness rankings based on perceptual principles. Recent systems extend those approaches with data recommendation support, i.e., to select data columns to be visualized.</p><p>Those systems (e.g., Voder <ref type="bibr" target="#b52">[53]</ref>, DataShot <ref type="bibr" target="#b58">[59]</ref>, Calliope <ref type="bibr" target="#b50">[51]</ref>) associate charts with insights, thereby proposing hand-crafted metrics to rank and recommend insights. However, hand-crafted metrics face limitations such as sub-optimal performances and high requirements for domain expertise <ref type="bibr" target="#b64">[65]</ref>.</p><p>In response, recent research starts to propose machine learning (ML) methods that learn to recommend visualizations from large-scale corpora. Existing approaches such as Draco <ref type="bibr" target="#b34">[35]</ref>, Data2Vis <ref type="bibr" target="#b8">[9]</ref>, and VizML <ref type="bibr" target="#b16">[17]</ref> mainly focus on recommending visual encodings of a single chart. Although proven useful, they do not support data recommendation. This limitation results in a quasi-automated process that users need to manually select data columns prior to automated recommendation. However, manual selection is time-consuming and challenging due to two reasons: First, not every data column counts. The number of possible charts grows exponentially as the cardinality of data columns increases. Therefore, it is necessary to select data columns that are more "worthy of" visual analysis. Second, one chart does not fit all. It is crucial to design dashboards containing multiple charts that satisfy different criteria such as diversity and consistency <ref type="bibr" target="#b38">[39]</ref>. Some combinations of charts might not be interesting or meaningful <ref type="bibr" target="#b60">[61]</ref>.</p><p>To address the above challenges, we aim to propose deep-learningbased approaches for recommending an analytical dashboard. Dashboards are typically a multiple-view visualization (MV), and we interchangeably use those two terms throughout this paper. We focus on the selection of MVs, i.e., to select important and meaningful data columns. Different from existing ML-based recommenders that generate charts in an end-to-end manner and hardly enable user control, we take a mixed-initiative perspective that integrates automated recommendation into an interactive system for authoring dashboards and exploring a dataset. In doing so, we hope to leverage the combined power of human agency and machine automation to solve the challenging task of constructing effective dashboards.</p><p>We present MultiVision, a mixed-initiative system for designing multiple-view visualizations for analyzing tabular datasets. MultiVision features deep-learning models for assessing the qualities of charts, whereby recommending best-scored charts. Specifically, we develop two deep-learning models for assessing a single chart and assessing multiple charts, respectively. The first model builds on a large corpus consisting of more than 200k Excel data tables and charts <ref type="bibr" target="#b70">[71]</ref>. Due to the lack of large-scale datasets of MVs, we design the second model for learning from provenance data, i.e., authoring logs in MultiVision. More importantly, we design and implement an interactive system for users to interact with automated recommendations (Fig. <ref type="figure">1</ref>). Once users edit charts in the MV, the system automatically makes recommendations based on the current MV to facilitate data exploration. While the deeplearning models focus on recommending data column selections, the system interface allows users to adjust the presentation of MVs (i.e., visual encodings and layouts) and interact with the MV (e.g., crosschart filtering and highlighting).</p><p>To evaluate MultiVision, we conduct an experiment to compare our model with baseline approaches in existing ML-based visualization recommenders. We further conduct a user study with 12 participants to demonstrate the usefulness of our system, whereby discussing implications for future research regarding the challenging and important problem of recommending and authoring dashboards. Our codes are open-sourced 1 . In conclusion, the contributions of this work include:</p><p>• A deep-learning-based approach for recommending multiple-view visualizations • A mixed-initiative system that integrates automated recommendation into interactive authoring of multiple-view visualizations and data exploration • An experiment and a user study that demonstrates the effectiveness of our deep learning models and system, respectively</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>This work is related to visualization recommendation, dashboards, visualization authoring tools, as well as mixed-initiative systems.</p><p>1 https://github.com/Franches/MultiVision</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visualization Recommendation</head><p>Decades of research have proposed many visualization recommendation systems that are thoroughly discussed in recent surveys <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b72">73]</ref>.</p><p>There are growing research interests in leveraging machine learning (ML) for visualization recommendation <ref type="bibr" target="#b56">[57]</ref>. ML-based methods learn visualization design knowledge from large-scale corpora, surpassing traditional rule-based approaches and even laypersons in some cases <ref type="bibr" target="#b16">[17]</ref>.</p><p>For instance, Data2Vis <ref type="bibr" target="#b8">[9]</ref> and VizML <ref type="bibr" target="#b16">[17]</ref> formulate a prediction problem, i.e., to predict the visual encodings given data columns to be visualized. These prediction-based methods output a single chart, which can be insufficient in unveiling different perspectives of data.</p><p>In contrast, other approaches learn to assess the "goodness" of visualizations, whereby recommending top-k assessed charts. DeepEye <ref type="bibr" target="#b28">[29]</ref> trains a binary classifier to determine whether a chart is good or bad and subsequently ranks charts by pair-wise comparisons. Instead of rankings, other methods output scores that better reflect the absolute qualities of charts. Draco <ref type="bibr" target="#b34">[35]</ref> uses RankSVM to learn the weighted hand-crafted constraints to obtain an overall score of visualization specifications. LQ2 <ref type="bibr" target="#b65">[66]</ref> proposes a Siamese neural network to predict chart layout qualities from crowdsourcing comparison data. Those approaches recommend visual encodings, where the output has fixed cardinality. We address a different problem, i.e., to recommend data column selections and chart combinations, which has varying cardinality, e.g., charts might encode a varying number of data columns. Our method builds upon similar Siamese network structure, but extends it with recurrent neural networks and new chart embedding modules to overcame the above challenges, outperforming the naive Siamese structure in our experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Dashboards and Multiple-View Visualizations</head><p>A multiple-view visualization (MV) composes multiple visualizations into a single cohesive representation that facilitates analyzing different perspectives of data <ref type="bibr" target="#b41">[42]</ref>. One common genre of MVs is dashboards, which is a common technique for visual analytics <ref type="bibr" target="#b45">[46]</ref>. Despite their prevalence, there exist few guidelines on designing effective MVs or dashboards. Baldonado et al. <ref type="bibr" target="#b41">[42]</ref> drew upon workshop discussions to present eight guidelines for using multiple views in information visualizations. Qu et al. <ref type="bibr" target="#b38">[39]</ref> emphasized the consistency constraints among multiple charts. Besides, several work studies how to extend MV to multiple devices <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b44">45]</ref> or large displays <ref type="bibr" target="#b23">[24]</ref>. However, those studies investigate design guidelines as qualitative reflections from empirical experiments rather than quantitative metrics. It remains unclear how to quantitatively encode those guidelines to promote automated design.</p><p>In response, recent research starts to quantify the MV and dashboard designs from a data-driven perspective. Al-maneea and Roberts <ref type="bibr" target="#b0">[1]</ref> quantified the layout designs as seen from visualization publications. Chen et al. <ref type="bibr" target="#b5">[6]</ref> investigated the composition and configuration patterns of MV, whereby developing a recommendation system for suggesting an exemplar design from visualization publications. LADV <ref type="bibr" target="#b29">[30]</ref> generates dashboard visualizations by recognizing chart types from an input image or sketch. While helpful, those approaches mainly focus on the presentation of views such as layout design or colour palette. Different from them, we study selection of views, that is, how to select multiple charts from many candidates given a data table in order to facilitate data analysis. Inspired by Draco <ref type="bibr" target="#b34">[35]</ref>, we seek to propose quantitative metrics to encode MV design guidelines and learn to weight different metrics to recommend top-k MV designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visualization Authoring Tools</head><p>Researchers have investigated ways of making it easy to design and create data visualizations. Numerous efforts support visualization design in the form of interactive authoring systems. For example, early research such as SageBrush <ref type="bibr" target="#b43">[44]</ref> let users create visualizations by choosing chart types through drag-and-drop operations. Recently, more advanced tools such as Lyra <ref type="bibr" target="#b46">[47]</ref>, iVisDesigner <ref type="bibr" target="#b39">[40]</ref>, DDG <ref type="bibr" target="#b19">[20]</ref>, InfoNice <ref type="bibr" target="#b59">[60]</ref>, Data Illustrator <ref type="bibr" target="#b27">[28]</ref>, Charticulator <ref type="bibr" target="#b40">[41]</ref> provide users with power of more customized visualization design of encodings and styles.</p><p>However, those tools mainly focus on encodings and designs of a single visualization. Tulip <ref type="bibr" target="#b1">[2]</ref> and Cytoscape <ref type="bibr" target="#b10">[11]</ref> support authoring Fig. <ref type="figure">2</ref>. MultiVision is a mixed-initiative system that generates a multiple-view visualization given a data table. The automation consists of deep learning models that learn to assess the quality of a single chart and multiple charts from a chart corpus and provenance data. The assessment models, combined with user-input constraints, make recommendations of MVs, which are then rendered in the interface. The agency can interact with the recommended results in the interface, and the editing logs, in turn, are fed into the deep learning models in an offline manner.</p><p>MVs for graph data, which are incapable of tabular datasets. Commercial tools like Tableau and Microsoft Power BI have enabled users to encode data with different visual forms, which are further arranged together into MVs such as dashboards. Similarly, we enable users to create MVs for visual analytics with the additional power of ML-based recommendations.</p><p>In the field of data storytelling, researchers have investigated approaches of composing multiple visualizations in a logical form. For example, Hullman et al. <ref type="bibr" target="#b17">[18]</ref> and Kim et al. <ref type="bibr" target="#b20">[21]</ref> have proposed algorithms to generate a sequence of visualizations to support storytelling and sequencing. DataShot <ref type="bibr" target="#b58">[59]</ref> and Calliope <ref type="bibr" target="#b50">[51]</ref> organize visualizations into topics based on data insights. Different from them, we aim to assist users in designing MVs for data analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Mixed-Initiative System for Visualizations</head><p>Mixed-initiative systems allow the human agency to collaborate with computer automation <ref type="bibr" target="#b15">[16]</ref>. In the field of data visualization, many systems have been proposed to facilitate the design and use of visualizations. For example, VizAssist <ref type="bibr" target="#b3">[4]</ref> guides users to find a relevant visualization through an interactive genetic algorithm that adapts to user needs. Bylinskii et al. <ref type="bibr" target="#b4">[5]</ref> proposed a method for predicting and showing the visual importance of visualizations during interactive authoring. Other applications include managing ambiguity in natural language <ref type="bibr" target="#b12">[13]</ref> or extracting data from chart images <ref type="bibr" target="#b18">[19]</ref>.</p><p>MultiVision differs from the above systems in two aspects. Firstly, human input or intervention is made compulsory in those systems. In contrast, MultiVision provides more significant value-added automation where human input is not mandatory. Instead, users can optionally request recommendations based on their current MV to obtain customized results. More importantly, we propose two recommendation strategies, including the passive recommendation that is triggered upon request and the active recommendation that automatically updates with user changes. We draw on the participants' feedback in the user study to discuss our lessons learnt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW</head><p>MultiVision aims to assist in designing multiple-view visualizations (MV) for analyzing a dataset in tabular formats. Since the design space of MVs is vast, we consider the following constraints to make our research focused. The design space of MV spans three dimensions: selection, presentation, and interaction among views <ref type="bibr" target="#b60">[61]</ref>. We primarily focus on the selection of views, i.e., to select data columns for creating a chart, and to select multiple charts for creating a cohesive whole. That said, other design factors such as layouts, colours, and interactivity are beyond our scope of automated recommendation. Another simplifying assumption is that we support five primary chart types, including scatterplots, bar, line, pie, and area charts, which are found most commonly used online <ref type="bibr" target="#b2">[3]</ref>. For visual encodings, we only recommend visualization-level design choices (i.e., chart types), leaving encodinglevel design choice (e.g., color scales) to future work. Besides, we set Fig. <ref type="figure">3</ref>. We abstract the recommendation problem into machine learning tasks: A We model the relationships among data columns, charts, and multiple-view visualizations using a three-layered heterogeneous graph; B For each node, the goal is to convert node features into a quality score; C Thus, the problem is abstracted into two sequence-to-one regression tasks at the chart-and MV-level, respectively.</p><p>the maximal number of encoded data columns per chart to be four, as we find that 93.5% charts in our training dataset encode no more than 4 data columns. We make this decision to balance the trade-offs between resource usage and efficiency, as the number of chart candidates grows exponentially with the cardinality of data columns.</p><p>It should be noted that we interchangeably use some terms in pair throughout the paper, including views and charts, as well as MVs and multiple-charts. In the remaining text of this section, we discuss the design considerations of MultiVision and the overview of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Design Considerations</head><p>The design of MultiVision is guided by the following considerations:</p><p>C1: Reducing the overheads of data selection. Given a data table, data workers often need to select a few data columns for creating meaningful charts through trial and error. This repetitive, tedious task should be delegated and automated.</p><p>C2: Automating the selection for multiple charts. The system should select multiple charts from the candidate pool of exponentially growing size and further combine selected charts into a cohesive, meaningful multiple-view presentation.</p><p>C3: Recommending charts conditioned on optional manual selections. Machine learning models are imperfect and could generate sub-optimal recommendations. Besides, data workers often leverage their domain knowledge to specify partial selections regarding data columns or charts <ref type="bibr" target="#b62">[63]</ref>. Thus, the system should blend human-input selections to provide conditional recommendations.</p><p>C4: Leveraging the provenance data about authoring logs. The lack of MV corpora hinders the deployment of ML approaches <ref type="bibr" target="#b56">[57]</ref>. We propose to leverage provenance as training datasets which receive growing research attentions through "learning from users" <ref type="bibr" target="#b66">[67]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Method and Problem Abstraction</head><p>Fig. <ref type="figure">2</ref> provides an overview of our system pipeline that consists of the automation, agency, and mixed-initiative module. Given an input data table, the automation module leverages deep learning models to predict an assessment score for all possible charts (i.e., combinations of data columns) and MVs (i.e., combinations of charts) (C1, C2). Subsequently, the scores are forwarded to recommend MVs through optimization, i.e., to generate an MV that maximizes the scores predicted by deep-learning models. Critically, the optimizer takes optional user specification as constraints to generate conditional recommendation (C3). As users edit the recommended results, their authoring logs are fed into the deep learning model in an offline manner (C4).</p><p>Our method highlights a perspective that treats the visualization construction process as a multi-layered heterogeneous graph. As shown in Fig. <ref type="figure">3</ref>, the graph consists of three layers where the nodes at each layer represent data columns, charts, and MVs, respectively. Each link represents a "composing" relationship, e.g., several data columns compose a chart, and several charts compose an MV. In this way, the node features are forwarded along the links to accomplish the machine learning task, i.e., to predict the assessment score. For instance, the chart feature is fused with the features with corresponding columns to predict the chart score. Since the "composing" relationships can be expressed as a sequence (e.g., an MV is a sequence of charts), the score prediction problem is abstracted into a sequence-to-one regression task, which is widely studied in deep learning research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DEEP LEARNING MODEL</head><p>Our deep learning model aims to predict an assessment score for charts and multiple-view visualizations (MVs). As discussed in Sect. 3.2, we abstract this assessment problem into two sequence-to-one regression tasks at the chart-and MV-level, respectively. This task abstraction allows us to design a shared architecture for both the chart assessment model and the MV assessment model. In this section, we first discuss the shared model architecture, followed by descriptions of dedicated designs for single-chart assessment and multiple-chart assessment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Architecture</head><p>We propose to solve the assessment problem through a learning-to-rank approach <ref type="bibr" target="#b26">[27]</ref>, which aims to compute the overall rankings according to many partial orders. Inspired by LQ2 <ref type="bibr" target="#b65">[66]</ref>, we use a Siamese neural network structure <ref type="bibr" target="#b21">[22]</ref> which consists of two identical scoring networks (Fig. <ref type="figure" target="#fig_0">4 A</ref> ). Two scoring networks share the same weight and work in parallel to calculate comparable results. Given an input ranked pair, denoted as I + , I − , where I + is ranked higher than I − , the scoring network, denoted f , is a function that converts an input to a score, denoted S = f (I). Thus, the training goal becomes:</p><formula xml:id="formula_0">f (I + ) &gt; f (I − ), ∀ I + , I − (1)</formula><p>Fig. <ref type="figure">5</ref>. The training input contains chart pairs or MV pairs, which can be collected flexibly from A visualization corpus and B provenance data about authoring logs. The positive is considered better than the negative so that the model should learn to predict a higher assessment score for the positive than the negative.</p><p>To that end, we use the margin ranking loss, which imposes penalty to mistakes that assign a higher score to a lower ranked input:</p><formula xml:id="formula_1">L(S + , S − ) = max(0, m + S + − S − ),<label>(2)</label></formula><p>where m is a hyper-parameter for margins.</p><p>A key benefit of the above learning-to-rank problem formulation is the flexible and compatible mechanism for constructing and collecting training datasets, that is, ranked pairs. As shown in Fig. <ref type="figure">5</ref>, the ranked pairs can be collected from both visualization corpus and provenance data. For visualization corpus (Fig. <ref type="figure">5</ref> A ), we consider the groundtruth charts to be better, i.e., higher ranked, than all the remaining possible combinations of data columns. For provenance data (Fig. <ref type="figure">5</ref> B ), we select the final output as the positive one, while the intermediate historical versions are marked negative. We ignore the partial rankings among intermediate versions, since the process of editing charts might be back-and-forth. For example, it is possible that users find the edited version to get worse.</p><p>Despite the flexibility and compatibility, we acknowledge the downsides of this learning-to-rank problem formulation, i.e., the scalability. Specifically, we obtain pairs through bipartite matching between the positive and the negative. However, the number of possible charts and MVs grows exponentially with the cardinally of data columns and charts, respectively, which theoretically results in an exponential time complexity. Although we find the training time to be acceptable in our experiments, future research should propose more efficient algorithms for selecting "important" pairs instead of enumeration to cope with the data explosion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Single-Chart Assessment</head><p>We abstract the single-chart assessment into a sequence-to-one regression task, which is widely studied in deep learning research for different types of sequences. However, this task in the context of visualizations poses distinct challenges from common sequences. Common sequences such as natural language sentences and event sequences have a fixed vocabulary set, i.e., words and event types, respectively. Correspondingly, there exist many off-the-shelf methods for converting a vocabulary to a multiple-dimensional vector (e.g., word embeddings), which are often essential for deep learning models <ref type="bibr" target="#b32">[33]</ref>.</p><p>In contrast, most data columns in a data table tend to be distinct from each other and columns in different data tables. In other words, there does not exist a vocabulary set of data columns. To solve this problem, we adopt the strategy proposed by Zhou et al. <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b71">72]</ref> to derive the data column embeddings through feature engineering. Their column embedding mechanism consists of three types of information, including the semantic text embeddings from column header text, data statistics such as mean values, and data types. As shown in Fig. <ref type="figure" target="#fig_0">4</ref> B , the embeddings are fed into a bidirectional Long Short-Term Memory (LSTM) layer to learn the sequence features, which are subsequently forwarded into linear layers to predict an assessment score regarding data column selections (denoted S(d) for a subset of data columns d).We implement an add-on feature for recommending visual encodings, which is a basic component for practical visualization recommendation systems. Specially, we add another layer to predict the visual encoding (i.e., five chart types including scatterplots, bar, line, pie, and area charts), which is the likelihood (or posterior probability) of the data column selection belonging to chart type v, denoted P(v). Therefore, the overall assessment score for both the data column selection and visual encodings is calculated by:</p><formula xml:id="formula_2">S(d, v) = S(d) × P(v)<label>(3)</label></formula><p>While we only consider the visualization-level encodings (i.e., chart type) in this work, other visual encodings can be added in a similar manner, i.e., to add a layer for predicting the visual encodings and compute the likelihood. The key challenge here is that the detailed visual encodings vary among different chart types, which requires simplifying abstraction (e.g., VizML <ref type="bibr" target="#b16">[17]</ref>) or comprehensive nested decision-treelike models. Besides, it might need encoding visualization design rules to yield satisfactory performances (e.g., Draco <ref type="bibr" target="#b34">[35]</ref>).</p><p>There exists an alternative to our approach in Equation 3. To be specific, we can train a model that directly learns S(d, v). This can be achieved by adding the visual encodings to the training input, i.e., the embeddings. However, a major downside is, again, the scalability, as this alternative requires enumerating all possible combinations between data column selections and encodings. This enumeration adds more degrees, depending on the cardinality of visual encodings, to the exponential complexity that "explode" the training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multiple-Chart Assessment</head><p>The multi-chart assessment model is similar to the single-chart assessment model, since it shares a similar challenge that almost every chart is distinct. However, unlike charts, there does not exist mechanism for computationally describing a multiple-view visualization (MV) in terms of data column selections and chart types. Therefore, we propose a novel method for modelling an MV as a sequence of chart embeddings. The chart embeddings enable learning a shared MV representation, i.e., the MVs created for one particular dataset can be used as training data to recommend MVs for another dataset.</p><p>Our chart embedding mechanism involves two types of information. First, we use the scores predicted by the single-chart assessment model, since our single-chart scoring network achieves satisfactory performances on assessment and encoding prediction. Second, we propose to leverage design guidelines of MVs to improve the recommendation results, inspired by Draco <ref type="bibr" target="#b34">[35]</ref>. As shown in Fig. <ref type="figure">6</ref>, we propose several novel functions to computationally encode the guidelines for the selection of multiple views in information visualization proposed by Baldonado et al. <ref type="bibr" target="#b60">[61]</ref>. However, the guidelines do not provide thresholds (e.g., the maximal number of views) so that we Fig. <ref type="figure">6</ref>. We encode the guidelines for the of multiple-views in information visualization Baldonado et al. <ref type="bibr" target="#b60">[61]</ref> to B computational metrics, which are fed into the deep learning models.</p><p>cannot encode those guidelines to constraints in the same way with Draco. Instead, we describe those guidelines as statistical features and fed it into deep learning models in an attempt to learn the "best" values of those guidelines (Fig. <ref type="figure" target="#fig_0">4 C</ref> ).</p><p>It should be noted that Baldonado et al. <ref type="bibr" target="#b60">[61]</ref> proposed another four guidelines for the presentation and interaction of MVs such as consistency and space optimization, which are beyond the scope of this work and warrant future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">INTERFACE</head><p>MultiVision features an interactive interface that integrates the deeplearning-based recommendation into data exploration. Fig. <ref type="figure">1</ref> shows the interface, which is vertically divided into three panes. The leftmost pane offers system-wise services including A uploading and viewing datasets, B making MV recommendation, and F other system functions such as changing themes. The middle pane provides chart-wise functionalities including C editing charts and D browsing chart recommendation. Finally, users can explore and interact with the charts in the right-most pane ( E ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Multiple-View Recommender</head><p>Multiple-View Recommender directly generates an MV based on user specifications. To be specific, it allows users to specify the number of charts in an MV and optionally locked charts. Locked charts are taken into consideration during recommendation. There is no limitation to the number of locked charts. Fig. <ref type="figure" target="#fig_1">7</ref> A illustrates an example where MultiVision recommends a MV composed of five charts based on one user-locked chart.</p><p>We abstract the recommendation into a constrained optimization problem, i.e., to find a combination of charts that maximize the scores predicted by the multiple-chart assessment model (Sect. 4.3). However, this is a challenging problem due to the huge, exponentially growing space of chart combinations. For the sake of running time and user experience, we implement a naive greedy algorithm that takes locked charts as the initial selection and incrementally picks one chart that leads to the highest score. In this way, MultiVision can make a recommendation responsively within few seconds, which, however, might not always yield the optimal solution. Future work should study and propose advanced algorithms to further improve the performance, e.g., possibility-based approximation algorithms <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Chart Ideas</head><p>Chart Ideas offers an alternative method for users to interact with automatic recommendations. As shown in Fig. <ref type="figure">1 D</ref> , it provides chart recommendations based on the current MV. Specifically, it lists and ranks charts from top to bottom in the order of the assessment score, i.e., the score of the MV after adding the chart to the current MV. This process shares the same computation procedure with Multiple-View Recommender since it can be seen as one step in the greedy algorithm. User could click a chart to add it to Dashboard View (Fig. <ref type="figure" target="#fig_1">7 B</ref> ). To facilitate browsing and selecting charts of interest, users could select data columns in the "Must Includes" drop-down list to view charts containing selected columns. Dashboard View by default considers charts encoding the same data columns to be the same, irrespective of the chart type. Users could un-check the "drop alternative chart-types" to view all alternative chart types.</p><p>Different from Multiple-View Recommender which is passive and triggered upon request, Chart Ideas makes active recommendation, i.e., it is automatically updated upon user changes to the current MV, including adding, editing, and removing charts. We design those two recommendation strategies in an attempt to probe into the open challenge in designing mixed-initiative user interfaces, i.e., "to what degree will such systems promote behavior characterized by user control vs. more passive acceptance of algorithmic recommendations?" <ref type="bibr" target="#b14">[15]</ref>. We reflect on our findings about the active and passive recommendation in Sect. 7.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Chart Editor</head><p>Chart Editor allows users to edit chart specifications, including visual encodings, chart types, and data transformation. We implemented Chart Editor since users might need to make adjustments to recommended results or create charts that satisfy personal needs. We borrowed the editor design in Voyager <ref type="bibr" target="#b61">[62]</ref> which has proven to be easy use. To be specific, Chart Editor supports editing chart specifications in the Vega-Lite grammar <ref type="bibr" target="#b47">[48]</ref>. For example, Fig. <ref type="figure">1</ref> C illustrates the visual specification of the top-right chart in Fig. <ref type="figure">1 E</ref> , which is highlighted with the same background color. MultiVision currently supports five chart types including area, bar, line, pie charts and scatterplots that are found most commonly used online <ref type="bibr" target="#b2">[3]</ref>.</p><p>Since the deep learning model only recommends chart types, we decided the visual encodings according to the heuristics in Voyager <ref type="bibr" target="#b62">[63]</ref>, e.g., nominal data types are firstly assigned to the x/y channel. Chart Editor provides six encoding channels, including x, y, column, row, size, and color. We acknowledge that those heuristics might return suboptimal visual encodings. Future work could implement advanced visual encoding recommender such as Draco <ref type="bibr" target="#b34">[35]</ref> and InfoColorizer <ref type="bibr" target="#b68">[69]</ref> to improve the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Presentation and Interaction</head><p>Although MultiVision primarily focuses on the selection of MVs, we provided basic support for interaction and presentation of MVs. As shown in Fig. <ref type="figure" target="#fig_1">7</ref> C , users could perform cross-chart filtering between multiple charts through mouse clicking or brushing. Besides, users could move and resize a chart in a responsive grid layout (Fig. <ref type="figure" target="#fig_1">7 D</ref> ).</p><p>Finally, users could change the theme, restore historical versions, and save logs in Control Panel (Fig. <ref type="figure">1 F</ref> ). The logs contain the uploaded data table, the computed features of the data table, event logs for the functionality above, as well as the rendered charts of all historical versions. It is up to users to decide whether the logs will be stored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>To evaluate MultiVision, we conduct an experiment to evaluate the model performance from the perspective of techniques, as well as a user study to understand MultiVision from a system perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Model Experiment</head><p>We evaluate the algorithm performance of our deep learning model as introduced in Sect. 4. We report the dataset, baselines, implementation details, results and discussions in the following text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Dataset</head><p>We collect and construct two datasets for single-chart and multiplecharts assessment, respectively. For single-chart assessment, we adopt the Excel corpus in Table2Charts <ref type="bibr" target="#b71">[72]</ref> which consists of 271,250 charts from 167,329 data tables. After filtering out data tables consisting of more than ten columns (14.2%) and charts encoding over four columns (6.5%), we obtain 3,920,941 pairs following the procedure described in Fig. <ref type="figure">5</ref> A . Since the number of possible chart pair is huge, we only keep pairs where two charts encoding the same number of data columns. Each chart in a pair is described as a sequence of data columns with feature vectors sized 4 × 96, where 4 is the maximal sequence length and 96 is the feature size per column.</p><p>However, the aforementioned Excel dataset is not suited to multiplechart assessment, since most Excel sheet consists of a single chart (75.6%). Thus, we decide to use the user logs of editing MVs as the training dataset, as illustrated in Fig. <ref type="figure">5</ref> B . Here we report the performance over the provenance data that we obtained from the user study (Sect. 6.2), which consists of 692 pairs from 11 participants 2 . Each chart is described as a feature vector sized 9 × 1, and the maximal sequence length of an MV is 12 in our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Comparison with Baseline Model Structures</head><p>Since existing machine-learning-based visualization recommenders do not focus on generating multiple charts, we do not identify a fair baseline recommender for comparing the recommendation performances. Instead, we compare our model structure in Fig. <ref type="figure" target="#fig_0">4</ref> against two machine learning model structures used in previous visualization recommenders:</p><p>• NN (Neural Network) is the best-performed method in VizML <ref type="bibr" target="#b16">[17]</ref> and LQ2 <ref type="bibr" target="#b65">[66]</ref>, which consists of several fullyconnected layers and ReLU activation layers. • RankSVM (Ranking Support Vector Machine) <ref type="bibr" target="#b24">[25]</ref> is adopted in DeepEye <ref type="bibr" target="#b28">[29]</ref> and Draco <ref type="bibr" target="#b34">[35]</ref>. Given a ranked pair (v 1 , v 2 ) with feature vectors x 1 , x 2 , it predicts the order by sign f (</p><formula xml:id="formula_3">x 1 − x 2 ),</formula><p>where sign is a sign function and f is the training target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Implementation and Model Detail</head><p>We implement our deep-learning models using PyTorch <ref type="bibr" target="#b36">[37]</ref>. We manually tune the hyper-parameters of our and baseline NN models by diagnosing the training curves, i.e., until both the validation and training scores converge to a desired level with small gaps in between them. We find that the margin hyper-parameter in the loss function (Equation <ref type="formula" target="#formula_1">2</ref>) plays a dominant role in the performance, while other parameters such as dropout rates and learning rates have a smaller effect on the model behaviour.</p><p>We run the experiment on a Linux server with a Tesla P100 GPU. The number of epochs is set to 10. We split the dataset with an 80/20 training-testing ratio and run Monte-Carlo cross validation <ref type="bibr" target="#b67">[68]</ref> 10 times.  <ref type="table" target="#tab_0">1</ref> presents the performance of our models and baselines. Our model outperforms baseline approaches in both single-chart and multiple-chart assessment tasks. We note that multiple-chart assessment performs poorer than single-chart assessment, suggesting that our feature engineering methods for describing an MV might be insufficient and unrepresentative. Therefore, future research should propose efficient methods for modelling and describing MVs.</p><p>The results in Table <ref type="table" target="#tab_0">1</ref> should be interpreted carefully since it represents the ranking accuracy on the pairs. In other words, it does not directly reflect the quality of recommended results. To better understand the performance of recommendation, we run an additional experiment to evaluate the top-k recall on single-chart assessment, i.e., the proportion of ground-truth charts found in the top-k recommendations. As shown in Fig. <ref type="figure" target="#fig_2">8</ref>, our model on average reaches 47.2%, 68.1%, 76.2%, and 87.0% at k = 1, 3, 5, 10, respectively. That said, 87% of the ground-truths can be found within the top-10 recommended results. The standard deviation is small, i.e., &lt; 0.01, suggesting the model stability. It should be noted that we do not run this additional experiment on multiple-chart assessment at the current state, since the data size is small (N = 11) and thus insufficient in proving statistically meaningful results. Moving forward, we are excited to involve more participants, collect large-scale MV datasets, and further investigate the performance.</p><p>Critically, our model achieves satisfying performance at the cost of algorithm complexity and training time. Our method for collecting training data (Fig. <ref type="figure">5</ref>) can be considered a "brute-force" strategy that enumerates possible pairs between good and bad selections. This brute-force manner is expensive, e.g., we convert 271k charts into 3,920k pairs. Subsequently, this growth imposes additional costs on the computational resources for deep learning. Thus, continued research on problem formulation and model architecture will be beneficial to the resource-performance tradeoff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">User Study</head><p>We conducted a formal user study to evaluate MultiVision from a system perspective. Our overall goal is to investigate: (1) whether MultiVision helps data workers create multiple-view visualizations and conduct data analysis; and (2) whether the deep-learning-based recommendation assists and engages users in exploring tabular datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Study Design</head><p>Based on the above goals, we conducted a usability test to understand how users interacted with MultiVision and gather their feedback.  Participants. We recruited 12 participants including five females. We asked participants to specify their experience in charting software (e.g., Excel, Tableau) and programming tools (e.g., Matplotlib, Vega) on a five-point Likert scale, where 1-point denotes "never heard of it" and 5-point means "very familiar". Their responses suggested varying degrees of experience in data visualizations, i.e., charting software (μ = 3.75, σ = 0.75) and programming tools (μ = 2.92, σ = 1.51). Two participants (E1,2) were experts in data analysis and visualization from a global high tech company. Remaining participants (P1-10) were undergraduate or postgraduate students with different majors including computer science, mathematics, and finance.</p><p>Datasets and Settings. We prepared five datasets from Vega-lite dataset 3 , including cars, gapminder, penguins, countries, and Seattleweather. Those datasets consisted of 6-9 data columns, which had a suitable level of complexity and exploration efforts for running user studies. To train the initial multiple-chart assessment model and enable recommenders, we conducted a pilot study to collect a small dataset of editing logs. We only used the cars dataset in the pilot study to qualitatively investigate how well the trained models generalize to other new datasets.</p><p>Procedure. A study session lasted between 50-60 minutes. We first asked participants to read and sign the consent form, especially that "I understand that my editing logs and comments will be collected". Participants were then given a tutorial about MultiVision and allowed to try out and get familar with the system (∼15 minutes). Next, we instructed participants to "select a dataset that you have not heard of and conduct data analysis" (∼20 minutes). For the sake of accountability, we asked participants to report findings during exploration and "finally create an MV to communicate important findings". The study ended with an exit questionnaire on the subjective ratings of MultiVision functions and a short interview.</p><p>Interview Questions. We asked participants' opinions on the pros and cons of each functionality in MultiVision and the overall system. Then we asked them to compare MultiVision with their previous experience in analyzing tabular datasets, and if any, in multiple-view visualizations or dashboards. To elicit fair comments, questions were one-off to avoid being double-barreled, and we avoided potentially leading questions such as "how about MultiVision in terms of conveniency" <ref type="bibr" target="#b25">[26]</ref>. As such, we collected explicit immediate reactions from participants. Although this setting might have hindered us from assembling in-depth thoughts through detailed inquiries, our expectation was that immediate responses reflected the foremost thoughts about MultiVision. The interview session ended with questions regarding the performance of automated recommendation and the user experience about the mixed-initiative system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Participant Feedback</head><p>Overall, MultiVision received an enthusiastic reaction from the participants. As shown in Fig. <ref type="figure" target="#fig_3">9</ref>, participants, in general, deemed the functionality of MultiVision and the overall system to be useful. In the following text, we summarized participants' feedback on the advantages of MultiVision. MultiVision is useful, convenient, and easy to learn. From a tool perspective, MultiVision scored a high usefulness rating among participants (μ = 4.58, σ = 0.51). When asked to compare MultiVision with their previous experience with charting software or libraries for analyzing tabular datasets, eleven participants explicitly commented on the convenience of MultiVision, i.e., it required few efforts to browse, select, create, and edit multiple charts. Four participants (P5,6,9,10) emphasized that MultiVision has a short learning curve, e.g., "it is a plain and simple tool for the masses".</p><p>MultiVision facilitates exploratory data analysis. Participants expressed that the recommendation provides helpful starting points (P5,8,10) or inspiration when they get stuck (P9). E2 positioned the prototype to exploratory data analytical scenarios when users had little understanding and no clear analytic tasks about the dataset. Nine of twelve participants made their first attempt at creating multiple-view visualizations (MVs), all appreciating that MVs helped them explore datasets from different perspectives effectively. P4 who had previously created dashboards for the purposes of monitoring commented that "it takes some yet small costs to learn (the use of MVs in MultiVision). Everything is intuitive".</p><p>MultiVision weighs automation and human intervention. Participants exhibit generally satisfactory yet diverse feelings on the "overall performance of machine learning models" during interviews. Their responses from "roughly 40% of results need manual adjustments" (P10) to "I tried to create charts myself but found the recommended results to be better than my decisions" (P3). This was further evidenced by the large negative correlation (ρ = −0.42) between the usefulness ratings of Multiple-View Recommender (automation) and Chart Editor (human intervention), i.e., the more participants consider automation to be useful, the less they appreciate manual efforts. During interviews, all participants appreciated the "semi-automated" or "human-computer collaborative" paradigm of MultiVision, i.e., users could modify the automatically recommended charts which are dynamically updated in line with their current selections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Log Analysis</head><p>We investigated the user behaviour about the usage of charts and each functionality, which is described in Sect. 5.4. As shown in Fig. <ref type="figure" target="#fig_4">10</ref>, participants on average created 25.8 charts which indicated a high user engagement. The number of charts in an MV during exploration averaged 5.1, showing that overmuch charts were not desirable.</p><p>We observed differences among the usage count of each functionality. Participants had engaged more in Cross-Chart Interactions and Chart Editor, showing that participants had actively interacted with automated support and engaged in their own creative practice. Those high usage counts also conformed to the high usefulness ratings of those two functionalities. From the aspect of recommendation, Chart Ideas was much more frequently used than Multiple-View Recommender, which was in contrast to the usefulness ratings. During interviews, participants explained that they used Multiple-View Recommender at the beginning and found it helpful to offer initial ideas. Afterwards, they preferred to use Chart Ideas to create and explore charts incrementally. However, Chart Ideas suffered few minor design flaws such as lacking previews that lowered their rankings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">IMPLICATION AND LESSONS LEARNED</head><p>In this section, we reflect on the lessons learned for designing more effective MVs, balancing agency and automation, and creating visualization authoring tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Designing More Efficient MVs</head><p>All participants, including those who were new to MVs, considered MVs to be useful and intuitive for data analysis. Despite enthusiastic feedback, we identify several future directions to further improve the usefulness and user experience (UX) of MVs.</p><p>Integrating methodology of visual analytics. E2 drew on the high autonomy and freedom in MultiVision, saying that our design was proper in terms of user experience but might lack guidance for laypersons. This comment was exemplified by P7, a beginner to MVs who commented "I had no idea how to analyze data with MVs at the beginning". Different from P7, some other MV beginners explained their methodology, e.g., "I want to see the distributions of each variable first and then explore the correlations" (P1), to which we refer as breadth-first exploration. In contrast, other participants (P2,8,9) adopt depth-first exploration, e.g., "I focus on (a variable) and examine how it influences others". Those comments underscore the importance of methodology for efficient data analysis with MVs. Therefore, future research should better understand the analytical pipelines of MVs and integrate them into automated creation of MVs to provide guided exploration, e.g., "overview-first, detailed on demaind".</p><p>Enhancing the interactions among views. Participants thought highly of the usefulness of Cross-Chart Interactions (μ = 4.33, σ = 0.78), commenting that interactions helped reveal new insights (P6,8), scope to data of interest (P7), and reduce clutter (P3,10). A major UX issue arises that "it is unclear which charts are connected" (P1). P1 suggested to put linked charts nearby, and P2 recommended explicit representations of inter-chart relationships such as an addition figure showing the relationships. Besides, P11 noted that "clicking and brushing is insufficient". Those comments call for continued research on the presentation and interaction of MVs.</p><p>Modeling the analytical progress of MVs. MultiVision implements a linear model for tracking and restoring authoring history, which is common in UX design such as text editors. However, we find that this linear model is insufficient in visualization authoring. Specifically, participants often experienced iterative and back-and-forth exploration processes, i.e., to reach back previous charts and explore alternative chart combinations. Future research might represent analytical progress using non-linear, tree-like models that better reflect the iterative changes of MVs. Besides, they expressed demands for more detailed history tracking due to the huge pool of charts, e.g., "there are many charts. I want the system to tell which charts I have checked" (P6) and "I need to know columns that I have not examined" (P8).</p><p>Recommending theme-based and explainable MVs. Although all participants agreed that MVs promoted data analysis, some participants pointed that a single MV might be insufficient. For instance, P8 wished to create multiple MVs, each focusing on several data columns. Similarly, E2 commented that a dashboard typically consists of 4-6 views to avoid being overwhelming and embody a core theme. Besides, participants felt that it was not always easy to understand the recommended MV (P1,2,6) and a "readme" might help (P4). Therefore, an interesting question is how to summarize an MV into a theme, which in turn could inform research in recommending more explainable theme-based MVs. Besides, it is helpful to conduct user studies with laypersons (e.g., <ref type="bibr" target="#b51">[52]</ref>) to investigate the understandability of MVs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Balancing Agency and Automation</head><p>E2 describes MultiVision as a "conversation" between users and machines -both could update the current MV according to the feedback from another. In this subsection, we reflect on the participants' feedback about their "conversations" with automation.</p><p>Automation might be disrupting. MultiVision offers two methods for recommending MVs, including Multiple-View Recommender that generates multiple charts at once and Chart Ideas that recommends a single chart dynamically upon each manual change to the MV. Chart Ideas received a lower rating of usefulness (μ = 3.83, σ = 0.94) than the former (μ = 4.33, σ = 0.89). Although participants generally agreed that it was helpful to make recommendation bases on the current MV, concerns arose that each update required rethinking the newly recommended charts and thus sometimes became disturbing (P5,7,8 and E1,2). Besides, the rethink was cognitively costly as Chart Ideas listed charts as text descriptions which were less intuitive than chart images. Future research should investigate how to alleviate this problem to leverage the combined power of agent and automation.</p><p>Personalization is in-demand. Participants were inconsistent in conducting data analysis with MultiVision, e.g., breath-first and depthfirst exploration. As such, they exhibited conflicting feelings over the recommended results, including "lacking diversity" (P6,11) and "diverging from my current selection" (P8). Similar opinions include that "it did not learn that I dislike pie charts although I had removed pie charts for many times" (P3). Those problems require further research on recommendation systems that counter-balance the short-time user satisfaction and long-term model converge <ref type="bibr" target="#b49">[50]</ref>. One promising solution might be personalized recommendations that allow users to specify their intent on different criteria (e.g., Calliope <ref type="bibr" target="#b50">[51]</ref>). Besides, future recommendation system should propose collaborative filtering approaches <ref type="bibr" target="#b54">[55]</ref> by grouping similar peer users and generating recommendations using the neighbourhood.</p><p>Leveraging user data warrants deeper studies. We proposed to recommend MVs by learning from user provenance data. Despite being useful and generalizable, such systems suffered from the "cold-start" problem that the recommended results were far from being perfect due to limited training datasets at the beginning. Thus, a clear next step is to collect more provenance data on new datasets to improve the performance and better evaluate the system. Another interesting problem is to explore strategies such as few-shot learning to cope with the "cold-start" problem. When asked for opinions for gathering user data, all participants exhibited open-minded attitudes if "I am informed". However, concerns regarding the data quality arose among participants, such as "I am not confident that my data is of high-quality and helpful" (P5) and "many of my operations were meaningless" (P9). E2 similarly expressed this point, saying "charts are similar to paintings. It is easy to differentiate 'rubbish' but much harder to compare 'masterpieces'. How to ensure the quality of collected logs?". Therefore, it warrants more studies to understand how to leverage user data effectively (e.g., data wrangling and cleaning).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Creating More Useful Charting Tools</head><p>From a charting tool perspective, MultiVision receives enthusiastic comments on its convenience, usefulness, and short learning curves. Still, participants required more functionality for further improvements.</p><p>Data Transformation. Nine participants expressed the needs for applying data transformation to the raw data table. MultiVision supported limited operations of data transformation (e.g., bin) that were insufficient. A promising research question would be to predict the data transformation given a data table. Besides, E1 suggested leveraging natural language interface for specifying data transformation, which was easy-to-use for novice users and could be integrated into MultiVision.</p><p>Expressiveness. In general, participants felt that the chart types supported in MultiVision were sufficient in basic data analysis and rated highly of the Chart Editor (μ = 4.66, σ = 0.65). This feedback conformed to our findings in the training dataset that those basic types were dominant. However, two participants demanded additional chart types such as box-plots (P2,11). In addition, participants presented various requirements for editing access to scales (P4,10) and text (E2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>We present MultiVision, a mixed-initiative system that leverages deeplearning-based recommendation for creating and authoring dashboards to analyze a data table. We believe that this is an important and challenging problem and there are several open directions for future work.</p><p>Investigating visualization-tailed machine learning. From a broader sense, it remains an open challenge to propose proper machine learning model and feature representation techniques for visualization research <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b69">70]</ref>. Future research should investigate and propose advanced deep learning models, e.g., generative models <ref type="bibr" target="#b57">[58]</ref>. Besides, we see that Graph Neural Network (GNN) <ref type="bibr" target="#b48">[49]</ref> is promising, which has recently demonstrated success across various application domains. For instance, Graphiti <ref type="bibr" target="#b53">[54]</ref> models tabular datasets as a homogeneous graph where a node represents a column and a link indicate the linking conditions. As shown in Fig. <ref type="figure">3</ref>, we could extend this model to a heterogeneous graph where data columns, charts, and MVs are nodes and an edge represents a composing relationship (e.g., several columns compose a chart). In this way, the recommendation problem could be abstracted into edge regression or edge cutting tasks that might be solved by GNNs. However, the graph model of MVs suffer an "openvocabulary" problem, i.e., each node, including columns, charts, and MVs, is distinct. This differs from the application of GNN in other domains where there exists a fixed, closed vocabulary of nodes (e.g., scholars in citation network). Future research should be aware of the particularity of visualization research and study visualization-tailored solutions.</p><p>Continuing research on multiple-view visualizations. Despite the wide usage of multiple-view visualizations, research efforts on MVs remain relatively limited. From a theoretical perspective, there exist limited understandings about the guidelines and the design space of MVs <ref type="bibr" target="#b5">[6]</ref>. Thus, it is vital to continue research on the empirical studies of MVs to understand the user engagement, the strategies for data analytics, design considerations and "best practices" of MVs. From a practical perspective, there are limited grammars or language that allow describing MVs in a shared representation. Shared representations are critical since they can be authored and edited by both human and machines, which in turn contribute to or learn from solutions to design better visualizations <ref type="bibr" target="#b14">[15]</ref>. Recent research (e.g., <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b63">64]</ref>) has suggested that declarative grammars (i.e., parameters) are effective and compact representations for data visualizations that benefit the use of machine learning, while visualization images are expensive and inefficient representations <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b64">65]</ref>. That said, continued research on declarative grammars for the presentation and interactions of MVs is essential.</p><p>Benchmarking recommendation and systems. In both model experiment and user study, we do not directly compare MultiVision with a baseline approach. This is because we do not identify a fair baseline for both the deep learning model and the system. Specifically, existing visualization recommenders do not focus on generating an MV. Sequential single-chart recommenders do not consider the relationships among charts (e.g., DeepEye <ref type="bibr" target="#b28">[29]</ref>) or target at a logically coherent data story for storytelling purposes (e.g., Calliope <ref type="bibr" target="#b50">[51]</ref>) instead of a cohesive, linked MV for analyzing different perspective of data. Thus, our experiments compare our deep-learning model with the machine learning methods in existing recommenders on our dataset. In the future, we plan to compare models using other datasets (e.g., DeepEye <ref type="bibr" target="#b28">[29]</ref>) to better evaluate our approach. Similarly, we do not find a fair baseline system that supports both editing multiple-view visualizations and providing recommendations. We hope that our initial results will inspire and provide benchmarks for future work.</p><p>Understanding users in mixed-initiative visualization systems. MultiVision only takes one of the initial steps in integrating deep learning models into visualization authoring systems. We draw on participants' feedback to discuss the effects of different recommendation strategies. We found that active recommendation might be disrupting while passive recommendation are much less likely to be used. That said, it remains challenging to propose approximate interaction designs that prompt efficient usage and understandings of automation while reducing disruptions to users. Another exciting idea is to characterize user behaviour <ref type="bibr" target="#b7">[8]</ref> and make recommendations through collaborative filtering approaches <ref type="bibr" target="#b35">[36]</ref>. Finally, it is important to consider visualization tools as a social system where users could share and communicate their visualizations with each other. Recent research in mining user behaviour in visualization systems <ref type="bibr" target="#b33">[34]</ref> seems a promising direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. We propose a shared model architecture for both single-chart assessment and multiple-charts assessment: A We adopt a Siamese neural network structure which consists of two identical scoring networks working in tandem to compute comparable output; B The single-chart scoring network builds upon LSTM recurrent networks with data column embeddings mechanism, which includes semantic embeddings, data statistics, types, and other cost functions; and C The multiple-charts scoring network shares a similar architecture, and additionally leverages the output of single-chart scoring models and MV design guidelines to compute chart embeddings.</figDesc><graphic coords="4,128.03,49.13,430.34,118.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Major user interactions in MultiVision: A Users request a MV recommendation conditioned on the current selections of charts; B A chart can also be added from the Chart Ideas; C Users can click or brush to perform cross-chart interactions; and D A chart can be moved, resized, and deleted in a responsive grid layout.</figDesc><graphic coords="6,88.43,152.09,102.69,68.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. The top-k recall curve of our model averaged after Monte-Carlo Cross-Validation. Recall at k is the proportion of ground-truths found in the top-k recommendations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. Usefulness ratings for 4 features and the overall system on a 5-point likert scale (N = 12). The rightmost column indicates the average and standard deviations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Analysis of user behaviour in the user study: A The chart usage; and B The usage count of each functionality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Model performance in terms of the ranking accuracy on pairs (%) through Monte-Carlo Cross-Validation averaged for 10 runs with an 80-20 training-testing split ratio.</figDesc><table><row><cell></cell><cell>Ours</cell><cell>NN</cell><cell>RankSVM</cell></row><row><cell>Single Chart</cell><cell cols="2">97.86 96.59</cell><cell>93.42</cell></row><row><cell cols="3">Multiple Charts 94.05 88.99</cell><cell>84.78</cell></row><row><cell cols="2">6.1.4 Result and Discussion</cell><cell></cell></row><row><cell>Table</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">One participant decided not to share the logs with us.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/vega/vega-datasets</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors wish to thank anonymous reviewers for their suggestions. This research was supported in part by a grant from MSRA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards quantifying multiple view layouts in visualisation as seen from research publications</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Visualization Conference (VIS)</title>
				<meeting>of the IEEE Visualization Conference (VIS)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="121" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tulip-a huge graph visualization framework</title>
		<author>
			<persName><forename type="first">D</forename><surname>Auber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing Software</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="105" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beagle: Automated extraction and interpretation of visualizations from the web</title>
		<author>
			<persName><forename type="first">L</forename><surname>Battle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Miranda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mukusheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stonebraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI)</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Vizassist: an interactive user assistant for visual data mining. The Visual Computer</title>
		<author>
			<persName><forename type="first">F</forename><surname>Bouali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Guettala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Venturini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1447" to="1463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning visual importance for graphic designs and data visualizations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>O'donovan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alsheikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual ACM symposium on User Interface Software and Technology (UIST)</title>
				<meeting>the Annual ACM symposium on User Interface Software and Technology (UIST)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="57" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Composition and configuration patterns in multiple-view visualizations</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Al-Maneea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards automated infographic design: Deep learning-based auto-extraction of extensible timeline</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="917" to="926" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Lassonet: Deep lasso-selection of 3d point clouds</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="195" to="204" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Data2vis: Automatic generation of data visualizations using sequence-to-sequence recurrent neural networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dibia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">¸</forename><surname>Demiralp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="33" to="46" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">create-a-chart-in-excel-formac-9407d77e-9695-488a-8e0a-7cb3fd507862</title>
		<author>
			<persName><forename type="first">M</forename><surname>Excel</surname></persName>
		</author>
		<ptr target="https://support.microsoft.com/en-us/office/" />
		<imprint>
			<date type="published" when="2021-02">Feb 2021</date>
		</imprint>
	</monogr>
	<note>Create a chart in excel for mac</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">js: a graph theory library for visualisation and analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Sumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName><surname>Cytoscape</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="309" to="311" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visualization assessment: A machine learning approach</title>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Visualization Conference (VIS)</title>
				<meeting>of the IEEE Visualization Conference (VIS)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="126" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Datatone: Managing ambiguity in natural language interfaces for data visualization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Annual ACM Symposium on User Interface Software &amp; Technology (UIST)</title>
				<meeting>of the Annual ACM Symposium on User Interface Software &amp; Technology (UIST)</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Evaluating &apos;graphical perception&apos;with cnns</title>
		<author>
			<persName><forename type="first">D</forename><surname>Haehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tompkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="641" to="650" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Agency plus automation: Designing artificial intelligence into interactive systems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the National Academy of Sciences</title>
				<meeting>of the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="1844" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Principles of mixed-initiative user interfaces</title>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI)</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Vizml: A machine learning approach to visualization recommendation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kraska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hidalgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI)</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A deeper understanding of sequence in narrative visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2406" to="2415" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Chartsense: Interactive data extraction from chart images</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI)</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="6706" to="6717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data-driven guides: Supporting expressive design for information graphics</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schweickart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="491" to="500" />
			<date type="published" when="2017-01">Jan 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Graphscape: A model for automated reasoning about visualization similarity and sequencing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI)</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2628" to="2638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
				<meeting><address><addrLine>Lille</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Vistiles: Coordinating and combining co-located mobile devices for visual data exploration</title>
		<author>
			<persName><forename type="first">R</forename><surname>Langner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Horak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="626" to="636" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multiple coordinated views at large displays for multiple users: Empirical findings on user behavior, movements, and distances</title>
		<author>
			<persName><forename type="first">R</forename><surname>Langner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Kister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dachselt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="608" to="618" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Large-scale linear ranksvm</title>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="781" to="817" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A classification of biased questions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Litwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="186" />
			<date type="published" when="1956">1956</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning to rank for information retrieval</title>
		<author>
			<persName><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer Science &amp; Business Media</publisher>
			<pubPlace>Berlin, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Data illustrator: Augmenting vector design tools with lazy data binding for expressive visualization authoring</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Delorey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grigg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI), CHI &apos;18</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI), CHI &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="1" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deepeye: Towards automatic data visualization</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Data Engineering (ICDE)</title>
				<meeting>of the International Conference on Data Engineering (ICDE)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="101" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ladv: Deep learning assisted authoring of dashboard visualizations from images and sketches</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automating the design of graphical presentations of relational information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="141" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Show me: Automatic presentation for visual analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Competing models: Inferring exploration patterns and information relevance via bayesian model selection</title>
		<author>
			<persName><forename type="first">S</forename><surname>Monadjemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ottley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Formalizing visualization design knowledge as constraints: Actionable and extensible models in draco</title>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="438" to="448" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Vizcommender: Computing text-based similarity in visualization repositories for content-based recommendations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Oppermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.01703</idno>
		<title level="m">An imperative style, high-performance deep learning library</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Making data visualization more efficient and effective: a survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="93" to="117" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Keeping multiple views consistent: Constraints, validations, and exceptions in visualization authoring</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="468" to="477" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ivisdesigner: Expressive interactive design of information visualizations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Höllerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2092" to="2101" />
			<date type="published" when="2014-12">Dec 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Charticulator: Interactive construction of bespoke chart layouts</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="789" to="799" />
			<date type="published" when="2019-01">Jan 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">On encouraging multiple views for visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Information Visualization (IV)</title>
				<meeting>of the IEEE Conference on Information Visualization (IV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="8" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">State of the art: Coordinated &amp; multiple views in exploratory visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Coordinated and Multiple Views in Exploratory Visualization (CMV)</title>
				<meeting>of the International Conference on Coordinated and Multiple Views in Exploratory Visualization (CMV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="61" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Interactive graphic design using automatic presentation knowledge</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kolojejchick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mattis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI)</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="112" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Designing multiple coordinated visualizations for tablets</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="261" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">What do we talk about when we talk about dashboards?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="682" to="692" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Lyra: An interactive visualization design environment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="351" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Vega-lite: A grammar of interactive graphics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="341" to="350" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Short-term satisfaction and long-term coverage: Understanding how users tolerate algorithmic exploration</title>
		<author>
			<persName><forename type="first">T</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM International Conference on Web Search and Data Mining (WSDM)</title>
				<meeting>of the ACM International Conference on Web Search and Data Mining (WSDM)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="513" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Calliope: Automatic visual data story generation from a spreadsheet</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">What makes a datagif understandable?</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1492" to="1502" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Augmenting visualizations with interactive data facts to facilitate interpretation and communication</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="672" to="681" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Graphiti: Interactive specification of attribute-based edges for network modeling and visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Basole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="226" to="235" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A survey of collaborative filtering techniques</title>
		<author>
			<persName><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title/>
		<ptr target="https://help.tableau.com/current/pro/desktop/en-us/gettingstarted_overview.htm" />
	</analytic>
	<monogr>
		<title level="j">Tableau. Get started</title>
		<imprint>
			<date type="published" when="2020-04">Apr 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Applying machine learning advances to data visualization: A survey on ml4vis</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00467</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deepdrawing: A deep learning approach to graph drawing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="676" to="686" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Datashot: Automatic generation of fact sheets from tabular data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="895" to="905" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Infonice: Easy creation of information graphics</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno>335:1-335:12</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI), CHI &apos;18</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI), CHI &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Guidelines for using multiple views in information visualization</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Q</forename><surname>Wang Baldonado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Woodruff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuchinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Working Conference on Advanced Visual Interfaces (AVI)</title>
				<meeting>of the Working Conference on Advanced Visual Interfaces (AVI)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Voyager: Exploratory analysis via faceted browsing of visualization recommendations</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="649" to="658" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Voyager 2: Augmenting visual analysis with partial view specifications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ouk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM Conference on Human Factors in Computing Systems (CHI)</title>
				<meeting>of the ACM Conference on Human Factors in Computing Systems (CHI)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2648" to="2659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Mobilevisfixer: Tailoring web visualizations for mobile phones leveraging an explainable reinforcement learning framework</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Ai4vis: Survey on artificial intelligence approaches for data visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Learning to automate chart layout configurations using crowdsourced paired comparison</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.03680</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Survey on the analysis of user interactions and visualization provenance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ottley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Walchshofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wenskovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Monte carlo cross validation. Chemometrics and Intelligent Laboratory Systems</title>
		<author>
			<persName><forename type="first">Q.-S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-Z</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Infocolorizer: Interactive recommendation of color palettes for infographics</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">L.-P</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00741</idno>
		<title level="m">Deep colormap extraction from visualizations</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Table2charts: Recommending charts by learning shared representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD &apos;21)</title>
				<imprint>
			<date type="published" when="2021-08">August 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Table2analysis: Modeling and recommendation of common analysis patterns for multi-dimensional data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the AAAI Conference on Artificial Intelligence</title>
				<meeting>of the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="320" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A survey on automatic infographics and visualization recommendations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="24" to="40" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
