<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data-Aware Predictive Scheduling for Distributed-Memory Ray Tracing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hyungman</forename><surname>Park</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Donald</forename><surname>Fussell</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Navr</surname></persName>
						</author>
						<title level="a" type="main">Data-Aware Predictive Scheduling for Distributed-Memory Ray Tracing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8DDCA4E6B63F1AEB134F70C4FBFDE5E7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T14:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Ray tracing, distributed data visualization</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1: We have path traced the distributed partitions of the Lambda2 dataset [15, 18] of simulated vortices using the Frontera supercomputer at the Texas Advanced Computing Center. With our predictive scheduling method, we are able to achieve a throughput of 7-33 MRays/s while sending rays across 4-128 distributed compute nodes. Lambda2 contains an aggregate of 2.3 billion unique triangles in 1024 domains extracted from a 77.3GB HDF5 file.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>With petascale supercomputing, large-scale scientific simulations can produce up to terascale data in minutes to hours <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30]</ref>. Large data generated by a simulation is typically a group of domains, each responsible for a spatial partition of the total volume. This is relevant particularly for distributed-memory settings because most computational simulations decompose a volume into subregions and assign them to processes to exploit data parallelism. As the subsets of a simulation data are generated, the simulation either writes them to permanent storage for post hoc visualization <ref type="bibr" target="#b5">[6]</ref> or sends them to active visualization processes for in situ visualization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b30">31]</ref>, which may or may not be co-located with simulation processes. Regardless of the visualization method employed, simulations are continuously adopting ray tracing as a vehicle for visualization <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b29">30]</ref> since modern ray tracers can generate high-fidelity images at high throughput rates <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33]</ref>. One of the challenges for tracing rays through partitioned data is that visibility queries for each ray evolve from a single task in the whole scene space into many discrete tasks in individual subspaces, incurring large overhead due to deferred task finalizations. Moreover, assigning domains to distinct remote processes exacerbates the problem even further, making the system less work efficient, thus demanding an effective scheduling method to orchestrate tasks of local and remote processes.</p><p>Generally, the tasks of tracing and forwarding rays are processed in front-to-back order based on the spatial ordering of domains affected by groups of rays <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28]</ref>. The ordering requirement, however, may become a limiting factor for performance especially as more tasks tend to finalize in the back of the order. We can address this problem by allowing the system to speculatively process the tasks and defer the resolution of unordered tracing outcomes until all redundant tasks speculatively issued are processed <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24]</ref>. Nevertheless, a secondary effect is that in case the majority of tasks tends to finalize early in the order, the excessive amount of work may negate the effect of improved parallelism enabled by speculation. Based on this reasoning, we argue that the premise of each method may be suited to restricted settings at best, and thus neither of these methods may act as a panacea for all rendering scenarios.</p><p>Inspired by this insight, we develop a scheduling method that demonstrates good performance consistently over a wide range of rendering scenarios. To achieve this nontrivial goal, we unify the two existing methods into a single method such that it dynamically adjusts to the characteristics of underlying data by means of prediction models. Furthermore, we introduce a generalized parallel scheduling framework that is flexible enough to accommodate existing scheduling methods as well as our unified, prediction-based method. In essence, the framework encapsulates groups of rays with a speculation context into runnable tasks and assigns each of the tasks to the work queue of an available processor for parallel processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND 2.1 Ray Tracing Distributed Data</head><p>Distributed-memory ray tracing can be a combination of sort-first, sortmiddle, and sort-last. If a dataset fits into the size of a process, it is common to use the sort-first approach. Primary rays are initially assigned to individual processes, which in turn trace them to completion using the dataset replicated in each process. Most interactive ray tracers to date <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b32">33]</ref> are based on this rendering classification.</p><p>This sort-first distributed-memory rendering approach essentially means concurrently running multiple Whitted-style recursive ray tracers on different processes and combining the pixel values generated by each process into the frame buffer of a display process. Therefore, only job assignments and pixel values are communicated between processes, but rays and scene data remain in each local process.</p><p>As for rendering distributed data spanning multiple processes, the sort-last approach is typically used. Every process participates in evaluating all pixels based on the partial data it owns, and the images from all processes are lastly composited into a single image based on the depth information. When it comes to ray tracing, this approach in modern ray tracers <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref> provides users with interactivity; however, global secondary effects cannot be computed since each process views only its local data and can only generate localized effects such as ambient occlusion with a bounded ray length.</p><p>To achieve full-fledged global illumination on distributed data, data must be brought into where rays are, or rays must be sent to where data are. In the former case, geometry caching <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26]</ref> is effective in reducing data transfer between processes. In addition, out-of-core rendering methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26]</ref>, which page in required data from storage, are another way of effectively amortizing the cost over multiple tasks. However, both approaches become intractable with limited I/O bandwidth as the amount of data tends to easily reach terascale levels in petascale computing and beyond. Therefore, our work adopts the latter approach where rays are periodically sorted and redistributed among processes based on the domain each ray belongs to. Many methods following this sort-middle approach have shown promising results in prior work <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref> and commonly utilize ray reordering <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ray Scheduling</head><p>Ray tracing distributed data can be perceived as a problem of two-level visibility queries. Given a ray, the domains of a scene are queried to find the first domain closest to the ray origin, and then the data within that domain is further queried to process the ray inside. Thus, the domains overlapping the ray have to be marched through and searched until secondary rays are spawned or the ray is retired as a pixel.</p><p>A preferred way of achieving efficiency in multi-level visibility queries is to process rays in groups. This is typically done by sorting the order of the domains that a ray enters and queuing the ray into the first domain prior to collectively processing the ray group in each domain. This deferred approach allows the system to exploit parallelism within and across the sorted ray groups and to further amortize various data Fig. <ref type="figure">2</ref>: An abstract view of the ray tracing pipeline for distributed data rendering. The pipeline places the incoming rays to the queues of spatial domains, assigns each queue to the process owning the data, and performs visibility queries and shading on assigned rays to update the frame buffer, which is composited with others to form an image.</p><p>management costs over many rays. For this reason, such queuing ray tracers have shown superb performance and scalability in distributed address space settings <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref> as well as in single address space settings <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>As illustrated in Fig. <ref type="figure">2</ref>, there are mainly three functional stages involved in processing the unsorted incoming rays before the image compositing stage: ray placement, ray assignment, and ray processing. The first two stages in particular, often collectively referred to as ray scheduling, are of our primary interest because they act as an overhead to actual work in the last ray processing stage, but simultaneously, they are responsible for assigning work to processes, directly impacting workload balance. The performance impact of image compositing is negligible with regard to achieving global illumination on distributed data, thus it is beyond the scope of our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEMS AND GOALS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ray Placement Policies</head><p>Placing a ray into domains can be non-speculative or speculative. The non-speculative placement policy is what most queuing ray tracers commonly adopt in single address space <ref type="bibr" target="#b25">[26]</ref> and distributed address space <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28]</ref>. In this policy, a ray is placed into the next closest domain that it enters. As scheduling progresses, the affected domains for each ray are examined one after another from the closest to the farthest until each ray finally terminates. The tracing results in all domains being undisputed, the scheduler can immediately issue the next actions to follow: migrating each of the rays into the next domain, spawning new rays, or updating pixel values. We refer to the ray scheduled in this way as a shallow ray.</p><p>The speculative placement policy has also been studied in single address space <ref type="bibr" target="#b4">[5]</ref> and distributed address space <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24]</ref>. This policy permits placement of rays into all affected domains, relaxing the constraint that domains are examined one at a time and thus boosting levels of concurrency with simultaneous tracing. This approach not only makes ray placement speculative but also makes tracing carried out in all domains inherently speculative. The tracing results being inconclusive, the scheduler needs an extra step to resolve the unordered tracing outcomes prior to initiating the aforementioned next actions. We refer to the ray scheduled in this way as a deep ray.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Awareness</head><p>Relying on shallow or deep rays alone is not amenable to variations in system input. Regardless of the ray type, the distance to ray termination can extensively vary depending on scene characteristics and system configurations. For instance, in geometry rendering of matte surfaces, the overall density of geometries determines ray termination; rays in dense regions tend to terminate earlier than those in sparse regions. In volume rendering of scalar fields, however, alpha compositing determines ray termination; rays in opaque regions tend to terminate earlier than those in transparent regions. For this reason, input characteristics play a crucial role in altering the dynamics of spatial and temporal ray distribution, impacting system workloads considerably. Consequently, scheduling with deep rays may outperform scheduling with shallow rays, and vice versa, depending on the characteristics of the data. Therefore, we dynamically adjust the scheduling depth of each ray to achieve a highly adaptive, data-aware system that consistently demonstrates good performance over a wide range of input variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Concurrency</head><p>All distributed-memory ray tracers to date, whether they rely on shallow scheduling <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b27">28]</ref> or deep scheduling <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24]</ref>, improve performance by exploiting levels of parallelism within and across processes. One breed of the deep scheduling system <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24]</ref> processes work in a way similar to the bulk synchronous parallel model where work is divided into phases and in each phase all processes independently run tasks assigned to them until reaching the next synchronization point. Similarly, another breed of the shallow or deep scheduling system adopts a hybrid programming model of message passing combined with multithreading <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b15">16]</ref> or SIMT <ref type="bibr" target="#b27">[28]</ref> but decomposes work into much finer granularities for asynchronous processing. In light of our comparative studies between these approaches, we find that regardless of the scheduling depth, shallow or deep, the latter approach is much appreciated when it comes to performance. For the adaptive system we desire to build, the challenge is to devise a scheduling framework that can seamlessly manage all the complexities involved in coordination of the fine-grained tasks of speculation while meeting all the constraints and goals discussed in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Performance</head><p>Distributed-memory ray tracers are designed with different performance goals in mind. In one approach, interactive performance is emphasized over global illumination, exhibiting local lighting effects only. To render global effects, interactive distributed-memory ray tracers <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b32">33]</ref> require replications of entire subsets of data in all visualization processes, making it impractical to visualize the data larger than a single-process memory. Another approach <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b23">24]</ref> emphasizes more on global illumination by creating an image database offline, providing a limited interactivity when the user explores the database with an imagebased analysis tool such as Cinema <ref type="bibr" target="#b2">[3]</ref>. One of our ambitious goals is to fulfill both of these perspectives by building a high-throughput ray scheduling system, enabling interactive and offline rendering of distributed data with the rays sent across processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Versatility</head><p>For scientific visualization, it is often required to render various data types such as volumes, geometries, or a mixture of the two. However, the scope of prior work is restricted to one type of rendering or scheduling only. For systems supporting deep scheduling, some are tailored to render geometry data <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b27">28]</ref> whereas some are tailored to render volume data <ref type="bibr" target="#b8">[9]</ref>. Although Galaxy <ref type="bibr" target="#b1">[2]</ref> can render both volumes and geometries, it can perform shallow scheduling only. OSPRay <ref type="bibr" target="#b32">[33]</ref> supports a variety of data types, including adaptive mesh refinement data, but for distributed data, it can only support local effects of illumination because it does not send rays across processes. That said, our next goal is to make the scheduling framework general enough to support a broad range of rendering capabilities on both distributed and non-distributed data while achieving global illumination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PREDICTIVE SCHEDULING</head><p>Scheduling a ray in a partitioned scene can be perceived as determining the order in which different regions of space, or domains, are traversed for one or more rays. The traversal for a ray continues until it finds a termination point along the ray, which in turn triggers the following actions depending on the rendering method used. In volume rendering, as ray marching reaches a point of high opacity, the corresponding pixel is updated with the color value accumulated along the ray. In geometry rendering, as a ray intersects a point on a surface, secondary rays are newly spawned and traced within the domain. Each of the newly spawned rays is then conditionally scheduled if it travels beyond the boundaries of the region without being terminated.</p><p>The existing scheduling methods adopt one of the two fixed ordering policies: the non-speculative front-to-back traversal for shallow scheduling <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b27">28]</ref> and the fully speculative unordered traversal for deep scheduling <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b23">24]</ref>. In shallow scheduling, a ray is moved from one domain to another until a condition for ray termination is met. Between the moves, the ray is queued along with other rays sharing the same destination domain, and the ray group in the queue is forwarded to the process owning the data, which then performs ray-data queries and queues both the non-terminated rays and the newly generated rays for the next round of scheduling. As long as many rays are available, this approach provides the system with levels of parallelism across ray groups as well as across the rays within a ray group. However, as more rays tend to terminate early, the amount of active rays is drastically reduced, limiting the level of available parallelism over time.</p><p>Providing the system with a sufficient amount of independent work can address the problem of reduced parallelism. The deep scheduling method implements this principle by unconditionally inserting a ray into all affected domains, processing the redundantly placed rays in parallel, and finally resolving the outcomes from different domains before scheduling the newly created rays. This approach greatly improves parallelism with increased processor utilization. However, it requires additional synchronizations to resolve speculations, and an exceedingly large amount of speculative work may incur high communication overhead. Moreover, if rays tend to terminate early because of certain scene characteristics, the vast majority of rays processed in farther domains may turn unnecessary after all.</p><p>In this section, we evolve these two extremes of the scheduling method to a unified, generic method that has much relaxed scheduling constraints. While elaborating on this new approach, we use the example scene drawn in Fig. <ref type="figure">3</ref> containing a triangle in the third domain that basically symbolizes the termination point of a ray.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Adjusting Speculation Levels</head><p>Given a list of domains affected by a ray, there are fundamentally two questions that need to be answered in each scheduling step where the ray is assigned to different domains: In what order should we process the domains? And given the order, what domains should we assign the ray to? The shallow scheduling method uses the front-to-back ordering policy and assigns the ray to the next closest domain. The deep scheduling method does not constrain the spatial order but rather assigns the ray to all affected domains. Therefore, depending on the scheduling method used, the ray is assigned to one or all of the domains affected.</p><p>Our method, however, relaxes the spatial ordering constraint by using what we call in-order or out-of-order speculation. For in-order speculation, a ray is assigned to one or more domains in front-to-back order. For out-of-order speculation, a ray is assigned to one or more domains using a different ordering constraint other than the front-toback order used in the shallow scheduling method. In-order speculation is useful when the front-to-back order is warranted, which is especially true for radiance rays but is equally relevant to shadow rays as well. On the other hand, out-of-order speculation can alternatively be used only for shadow rays because the main role of shadow rays is to query the scene for occlusion from light sources, i.e., to find any hit along a ray, not the first hit point. Fig. <ref type="figure">3c</ref> and Fig. <ref type="figure">3e</ref> illustrate both of these scheduling approaches.</p><p>In addition, our method further relaxes the constraint on the number of domains that a ray is assigned to. Our approach first sorts the domains by some order constrained by the in-order or out-of-order speculation policy and chooses the first d domains for ray assignments. We define d as a scheduling depth or speculation level. Ideally, d has to be chosen such that redundant ray-data queries and additional rounds of scheduling are minimized. For example, as shown in Fig. <ref type="figure">3d</ref>, if the traversal in the first round of scheduling fails to finalize, another round of scheduling is necessary to perform additional ray-data queries in untraversed domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Predictive Queuing System</head><p>With the controllability incorporated, the question now becomes what criteria and strategies we should use for sorting the domains and choosing the scheduling depth d. Our short answer to this question is the prediction-based, adaptive queuing system shown in Fig. <ref type="figure">4</ref>. The basic idea is to predict the domain in which a ray is mostly likely to terminate  based on the statistics of probability or depth values measured over frames. Given a ray, the queuing system sorts the affected domains according to a predefined sorting criterion and evaluates the value d as a function of the measured statistics. The system then places the ray into the first d domains in the sorted list, and once each domain is populated with the ray, it distributes copies of the ray across processes and aggregates the resulting statistics for the next round of scheduling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Depth-Based Prediction</head><p>One straightforward way of predicting a scheduling depth is to directly use past scheduling depth values. In this case, the predicted depth can simply be expressed as d = d µ where d µ is the mean of the measured depth values averaged over the previous frames. One caveat is that when shadow rays are scheduled with out-of-order speculation, this depth-based approach may become invalid because the sorted order of the domains may be inconsistent between the measured and the predicted. Sorting the domains in front-to-back order is required for the depth-based prediction so that the assumption of the prediction holds true.</p><p>In addition, it is worth noting that the method makes use of binning to localize predictions to coherent groups of rays with similar directional or geometric properties. For primary rays, image tiles are subdivided into bins of smaller subspaces, and a bin ID is assigned to each ray based on the subspace that each ray belongs to. For secondary rays, each domain is associated with bins of the outgoing ray direction (±x, ±y, and ±z), forming a total of 8n virtual subspaces for n domains. In this case, a bin ID is assigned based on the domain that each ray originates from and one of the eight subspaces that each ray belongs to, which is evaluated based on the signs of vector components of ray direction.</p><p>Listing 1 is the pseudocode for the depth-based prediction method. The algorithm first populates a list of domains affected by a ray and sorts the list by distance to arrange the domains in front-to-back order. With a bin ID assigned, the algorithm simply evaluates d as the mean of the previous depth values in the corresponding virtual subspace indexed by the bin ID. With the estimated value of d in place, the algorithm speculatively places the ray into the first d domains of the sorted list, finalizing the ray placement. Notice that for correctness, d must be properly clamped to the valid range prior to the ray placement. Also notice that at the end of each ray placement, the scheduling depth is cached to avoid placing the ray, in the next round of scheduling, into the domains already traversed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Probability-Based Prediction</head><p>In addition to the depth-based prediction method, we introduce another prediction model that makes predictions by evaluating the probability of ray termination in each domain. Unlike the depth model, this method does not require binning. However, it maintains counter values for hits and misses in each domain (i.e., terminating and nonterminating). Whenever ray marching or ray-data queries are performed in each domain, the number of terminations are tallied into the counter values.</p><p>With all the statistics aggregated over frames, the main goal of this method becomes choosing the scheduling depth d such that the overall probability of ray termination is maximized. To explain the approach at a high level, the probability of ray termination is first estimated on a list of sorted domains, then scanning over the sorted list, the scheduler continuously inserts the ray into the domain as long as the aggregate probability evaluated so far does not exceed the target probability defined by the user.</p><p>In probability-based prediction, the scheduling system employs slightly different prediction models for different types of rays. For radiance rays, we use an additive prediction model expressed as p hit, j = ∑ j i=0 (1 − p hit,i−1 ) × h i , where p hit, j is the estimated probability of a ray having a termination point between domains 0 and j, and h i is the measured probability of a ray having a termination point in domain i. p hit, j is initially set to p hit,−1 = 0. For shadow rays, we use a multiplicative prediction model expressed as p miss, j = ∏ j i=0 p miss,i−1 × m i , where p miss, j is the estimated probability of a ray not having a termination point between domains 0 and j, and m i is the measured probability of a ray not having a termination point in domain i. p miss, j is initially set to p miss,−1 = 1. We can then compute the probability of having any termination point between domains 0 and j by using the expression p anyhit, j = 1 − p miss, j . The algorithms in Listing 2 and Listing 3 each implement one of these prediction models for radiance and shadow rays, respectively.</p><p>One advantage of using this approach is that the same statistics can be applicable to both types of rays. Another advantage is that the counter values are easy to maintain because of the lack of binning. On the other hand, when evaluating the scheduling depth d, it involves more computations than the depth model in which a single lookup of the average depth value is sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Aggregating Statistics</head><p>To collect the statistics discussed so far, we subdivide each frame into subframes and aggregate the statistics over multiple subframes or frames depending on the statistic used. The idea of employing subframes naturally fits into the framework of progressive rendering, which is a widely used technique to achieve interactive rendering in many applications.</p><p>For the depth values acquired from 2D binning, assuming the camera position changes every frame, the statistics are aggregated over multiple subframes within a frame but need to be refreshed at the beginning of every frame. In contrast, because the depth values or hit/miss counters acquired from 3D space are more dependent on the geometric properties of the rays, the statistics can be aggregated over different frames as well as over different subframes. However, it is worth noting that accumulating values over many frames can cause overflows in numbers, thus our implementation computes running averages of statistics instead of allowing continued aggregations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">A SCHEDULING FRAMEWORK</head><p>With the prediction models established, we need a generic scheduling framework that can efficiently implement this high-level idea on modern supercomputers. The main goal is to provide a high-throughput ray processing capability for rendering large-scale distributed data. We achieve this goal by viewing the whole system as a giant tree of speculative or non-speculative ray groups. With this perspective, we compartmentalize the tree of rays into many fine-grained subtrees and turn the nodes of each subtree into runnable concurrent tasks having different levels of dependency within and across subtrees. We then map and run these tasks on a system that employs a hybrid programming model of inter-process messaging and multi-threading. In order to build a system bearing such design philosophy, there are many design choices we have to make along the way, which eventually leads to many challenging questions that we have to answer in order to achieve the performance goal: How do we compose such subtrees? How do we manage and resolve the dependencies within and across subtrees? What needs to be processed within a subtree? How do we translate Fig. <ref type="figure">5</ref>: A hash table-based distributed consensus protocol for nonblocking work management.</p><p>subtrees into tasks of computation and communication? How do we make the framework versatile such that various rendering algorithms and the prediction models are seamlessly incorporated? In this section, we strive to answer all these questions as we build such a sophisticated system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Task-based Execution and Work Management</head><p>The notion of encapsulating rays into a tree of speculation nodes makes the implementation highly amenable to parallel computing because of a high degree of inherent concurrency that exists within and across subtrees. In order to efficiently process the whole evolving tree, we make use of a task-based parallel computing framework similar to the one used in Galaxy <ref type="bibr" target="#b1">[2]</ref>. We innovate beyond Galaxy-like task scheduling by the use of a tree-based abstraction to organize the speculation levels, described in Sect. 5.2. Essentially, the framework is a hybrid programming model of inter-process messaging and multi-threading which incorporates a number of different types of threads in each process. Specifically, each process maintains a round-robin task scheduler acting as a receiver thread and as it receives a task from a local or remote process, it assigns the task to one of the worker threads capable of executing different types of speculation nodes in the tree that are defined as runnable tasks. In addition, if a new task is to be sent to another process, it is first pushed to a message queue, and a dedicated sender thread eventually sends it to the destination process. Using this framework, all processes continue to run until they finish processing all the nodes in the tree that no longer grows in size. Especially when all tasks are highly distributed and are created asynchronously, devising an efficient consensus system is challenging. To address this challenge, we have developed a hash table-based distributed consensus protocol, which allows non-blocking notifications of work progression.</p><p>Fig. <ref type="figure">5</ref> shows a high-level view of our work management system. Each process maintains a dedicated thread for work management, allocating a list of hash tables for bookkeeping. To minimize conflicts in the hash table, we use a separate hash table for each image tile, which can be owned by any process in the system. Thus, the ownership of a tile determines the ownership of the corresponding hash table as well as all the subtrees derived from it. After creating and scheduling child subtrees, the node being processed notifies the tile owner process of its work status with the ID of the parent subtrees, the number of completed tasks, the ID of the child subtrees, and the number of newly scheduled child tasks. Upon receiving the notification, the owner process updates the hash table entries of task counters indexed by the IDs of the parent and child subtrees. Once all hash tables of tiles of each process become empty, each process notifies the root process, and if all hash tables across processes turn out to be empty, the root process notifies all processes to finalize the current render frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Speculation Nodes</head><p>We employ a tree-based abstraction to organize the speculation levels. First, we define primitives to compose the tree. A speculation node is an abstraction that encapsulates a group of rays, which can be speculative or non-speculative. The encapsulation simplifies the complex management of many different types of rays.</p><p>Speculation nodes are broadly classified into sender nodes and receiver nodes. As the names imply, the sender and receiver nodes are responsible for sending and receiving messages from one process to another. The sender node, acting as the parent of a subtree, encompasses a group of non-speculative rays as the input. It places the input rays into domains and sends each of the ray groups in different domains to the process owning the data. A receiver node, acting as a child of a subtree, encompasses a group of rays received from the parent sender node. Depending on the ray placement policy used in the sender node, the ray groups created in the sender node and the input rays of the receiver node can be speculative or non-speculative. But the input rays of the sender node are always non-speculative.</p><p>If the rays are speculative, a receiver node is tightly coupled to the parent sender node for the duration of its lifetime. In this case, the receiver node performs ray-data queries on the input rays and sends the results back to their parent node. Unless all the rays are terminated, the receiver node is still alive and waits for the next message to arrive from the parent node. If the rays are non-speculative, the receiver node is not bound to its parent and is free to play its role without blocking on the parent node. That is, it recursively traces all the rays within the domain that it is assigned to and subsequently initiates new subtrees by creating new sender nodes encapsulating the rays that migrate into other domains.</p><p>The sender nodes that perform shallow scheduling on the input rays terminate their lifetime immediately upon sending groups of rays to the owner processes of the receiver nodes. In contrast, the sender nodes that result in speculative ray groups block on the results coming from the receiver nodes. Once a sender node receives a message from one of the receiver nodes, it updates the results into what we call a visibility buffer. Then, as the sender node updates the buffer for the last child (receiver node), it resolves speculations for all child nodes and individually sends the resolved ray indices to all child nodes that are still alive. Simultaneously, since the visibility buffer is correct at this point after the resolution, the sender node retires the contributions of all the input rays as pixel values. It is worth noting that serialization only occurs while updating the visibility buffer, and the remaining parts of the whole process are highly parallel.</p><p>Finally, upon receiving the ray indices, each of the receiver nodes recursively traces the resolved rays to completion until the maximum ray depth within the domain is reached or until the rays traverse out of the domain bounds. The rays that must be moved to other domains are again encapsulated into sender nodes, and the whole process repeats as described. Therefore, sender nodes are created whenever a new non-speculative ray group is available as the input. The non-speculative ray group can be either the primary rays generated from an image tile or the secondary rays spawned by a receiver node. Fig. <ref type="figure" target="#fig_2">6</ref> clarifies some of these roles by illustrating the progression of the trees that are either speculative or non-speculative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">The Subtree Structure</head><p>As already discussed, each subtree comprises a sender node and one or more receiver nodes. Because radiance and shadow rays each serve different purposes, we define two separate subtree types: a radiance subtree and a shadow subtree. Grouping the same type of rays together allows the execution of ray-data queries to follow similar control paths,</p><formula xml:id="formula_0">{o i } ⠒ Visibility buffer: {t i,surface ,rgb𝛼 i,domain } {r i } {i} S T S O ⠒ S T S O ⠒ R T Radiance Subtree Shadow Subtree R T R T Visibility buffer: {o i,surface } {t i ,rgb𝛼 i } S O S T ⠒ {r i } R O R O</formula><p>Fig. <ref type="figure">7</ref>: A generalized form of N-nary subtrees created for radiance and shadow rays. With proper coordination between subtree nodes, we can enable asynchronous ray speculation on volume and geometry data.</p><p>mitigating the complexity of managing different ray types. As shown in Fig. <ref type="figure">7</ref>, the radiance subtree contains a radiance sender node S T and one or more radiance receiver nodes R T . Likewise, the shadow subtree contains a shadow sender node S O and one or more shadow receiver nodes R O .</p><p>At the end of the lifetime of a radiance subtree, each of the radiance receiver nodes R T creates up to two sender nodes including a radiance sender node S T and a shadow sender node S O , initiating two child subtrees. Notice that a child subtree is constructed only if there exist rays crossing the domain boundaries; otherwise, no child subtrees are created for the current subtree. Unlike radiance subtrees, shadow subtrees do not result in a child subtree because shadow rays do not spawn secondary rays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Messaging within a Subtree</head><p>We can view the sender and receiver nodes of a subtree as state memories and the edges connecting the nodes as channels for messaging. Therefore, implementing a variety of rendering algorithms with different types of data in place implies defining different memory entities in each node and defining messages communicated within each N-nary subtree. We additionally need to define a sequence of algorithmic steps driven by each message in order to orchestrate all the state changes within each node.</p><p>For geometry rendering, each radiance sender node S T maintains the depth information {t i } in the visibility buffer, and each shadow sender node S O maintains the occlusion information {o i } in the visibility buffer. On the other hand, for volume rendering, each radiance sender node maintains the color values {rgbα i,domain } obtained from different receiver nodes R T in the visibility buffer. Since volume rendering only involves integrating color values by means of ray marching, shadow subtrees are unnecessary.</p><p>For geometry rendering, the state values stored on the sender side are updated through messaging between senders and receivers. The update operations are carried out by taking the minimum of t values and the logical OR of occlusion flags. Once all values are updated and merged, the sender node in the radiance subtree individually sends the resolved ray indices {i} to the receiver nodes, which is unnecessary for shadow rays because they do not create secondary rays.</p><p>For volume rendering, however, the sender node instead blends the partial color composites with proper depth ordering. Basically, we implement the same sorting approach suggested by Binyahib et al. <ref type="bibr" target="#b8">[9]</ref>. As each receiver node R T receives a group of rays, it performs ray marching within the assigned domain and returns partially composited color values to the sender node S T , which in turn composites the partial values into a single, final color for each ray.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Compacting Communication Data</head><p>Although the abstraction of organizing ray groups in a tree of nodes greatly overlaps computation and communication by exploiting parallelism within and across subtrees, we can further reduce the communication cost by reducing the amount of communication between the nodes. One optimization we apply to our system is to avoid sending raw t values after processing each radiance receiver node R T . We instead send only 1-bit hit/miss information for each radiance ray, reducing the payload size by 32 or 64 times depending on the floating-point  precision used for t values. This is possible under the assumption that the domains are organized as a regular grid without overlaps between the domains, which is typically the case for most scientific data. If a receiver node's flag indicates a hit for a ray, the sender node retrieves the ray and updates the visibility buffer with its scheduling depth and domain ID. Upon merging all of the depth values, the sender node resolves the visibility by searching for the speculative ray having the same domain ID as the one in the buffer. For shadow rays, we achieve data reduction by maintaining 1-bit occlusion flags in the visibility buffer; each latest buffer entry indicates the occlusion status. For volume rendering, we can pack each RGBA color value into a smaller size, but we have not implemented it in our system because of potential precision issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Handling Special Cases</head><p>When predictive scheduling is performed, inaccurate predictions lead to insufficient visibility information, delaying the finalization of ray processing. When mispredictions occur, instead of immediately launching another subtree for the error rays, we create an error node and defer processing it until the next subframe in the context of progressive rendering. Our error handling approach shown in Fig. <ref type="figure" target="#fig_3">8</ref> not only addresses the issue of incurring additional delays in handling errors but also reduces the amount of work near the end of a subframe. The basic insight is to hide the misprediction penalty by handing over error nodes to the next subframe such that they can be processed along with other nodes initiated in the next subframe, improving overall throughput with abundant work available.</p><p>When one or more rays exclusively overlap only one domain, all the ray processing results in the domain are non-speculative and complete, obviating the need for additional error handling steps. This basically implies falling back to shallow scheduling where all the nodes are loosely coupled without requiring any coordination between them. As shown in Fig. <ref type="figure" target="#fig_2">6</ref>, once a sender node creates and schedules receiver nodes, the receiver nodes are able to independently trace all the rays within the domain on their own. However, such instances may still initiate another round of speculative scheduling, making our system capable of switching between shallow, deep, and predictive scheduling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>In this section, we evaluate the effectiveness of our asynchronous scheduling framework and compare the performance of predictive and non-predictive scheduling methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Setup</head><p>We use both synthetic and real datasets throughout our evaluation process. For synthetic datasets, we procedurally generate the regular grid volumes shown in Fig. <ref type="figure">9</ref> using the Perlin noise function <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25]</ref>. To evaluate the performance of predictive scheduling on scenes with a wide range of characteristics, we vary opacity levels by altering Fig. <ref type="figure">9</ref>: Synthetic Noise datasets. Surfaces with isosurface values of 0.1, 0.4, 0.7, and 1.0 (or sparsity levels of 0, 1, 2 and 3) from left to right (top row). Regular volumes with transparency levels of 0, 1, 2, and 3 from left to right (bottom row). See Table <ref type="table">1</ref> for configurations. (d) Exajet <ref type="bibr" target="#b19">[20]</ref>: an unstructured volume of 656M hexahedral cells (7 3 domains). color maps for volume rendering and vary density levels by altering isosurface values for surface rendering. For real datasets, we use the benchmark datasets shown in Fig. <ref type="figure" target="#fig_6">10</ref>. For each dataset, we uniformly assign domains to processes in z-curve order so that spatially adjacent domains are mapped to the same process in case the domain count exceeds the process count.</p><p>For all experiments, we use the Frontera supercomputer <ref type="bibr" target="#b28">[29]</ref> at the Texas Advanced Computing Center and launch a single process on each compute node, comprising dual sockets of 2.7GHz 28-core Intel Xeon Platinum 8280 Cascade Lake processors and 192GB DDR4 memory. All compute nodes on Frontera are interconnected via the Mellanox 100Gb/s InfiniBand system. We compile our hybrid MPI and multithreaded C++ code with the Intel compiler 19.1.1 and the Intel IMPI library 19.0.9. We do not explicitly vectorize the code besides activating the compiler's default optimization features. On the rendering side, we use the Intel Embree ray tracing library 3.12.1 for visibility queries and the Intel OpenVKL volume kernel library 0.11.0 for volume sampling.</p><p>We evaluate our approach on both surface and volume data. For surface rendering, we use implicit isosurfacing on volume data, and we  use ambient occlusion and path tracing on geometry data. For shading and materials, we include a diffuse hemisphere light source in each scene and use the pure diffuse material for all surfaces. For volume rendering, we perform ray marching on volume data to integrate the scalar values sampled along each ray. For implicit isosurfacing, we allow one ray bounce and generate one shadow ray for each hit point. For ambient occlusion, we allow one ray bounce and generate eight ambient occlusion rays for each hit point. For path tracing, we allow four ray bounces and generate one radiance ray and one shadow ray for each hit point. For each test case, we generate a total of 2500 subframe images at a resolution of 1024 2 pixels in the context of progressive rendering; we integrate 50 samples per pixel over 50 subframes to form a fully integrated frame and capture the performance distributions of 50 different viewpoints orbiting around each dataset.</p><p>For all performance measurements, we use throughput as a performance metric. We specifically define throughput as the number of newly generated non-speculative rays processed per unit time, measured in MRays/s. We do not count duplicate ray copies or pointers traversing different domains in the scene but rather count them only once as they are created in a certain domain or at the camera position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>Table <ref type="table" target="#tab_4">2</ref> shows the effectiveness of our asynchronous scheduling approach compared to the synchronous scheduling approach <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24]</ref>. All throughput measurements are as a result of performing shallow and deep scheduling on a set of weak scaling benchmarks of the Noise dataset using implicit isosurfacing. It is clearly seen that our asynchronous scheduling framework dominates in performance by orders of magnitude for a range of node counts and isosurface values.  When it comes to surface rendering, our general expectation on performance behavior is that for dense geometry data, predictive scheduling should perform as good as shallow scheduling, and for sparse geometry data, predictive scheduling should perform as good as deep scheduling. This is because rays typically terminate early within dense geometry (i.e., there are more opportunities for an intersection), whereas rays typically terminate late within sparse geometry. A similar duality applies for volume rendering. For highly opaque volume data, predictive scheduling should match the performance of shallow scheduling, and for highly transparent volume data, predictive scheduling should match the performance of deep scheduling. Again, similar to the case of geometry rendering, this is because rays typically terminate early in scenes with high opacity whereas rays typically terminate late in scenes with low opacity (i.e., high transparency).</p><p>We consistently observe such performance behavior in Fig. <ref type="figure" target="#fig_7">11</ref> for both methods of depth-based and probability-based predictive scheduling. For volume rendering, however, although predictive scheduling shows good performance on 64 nodes, the performance does not scale well on 128 nodes particularly for highly opaque volumes (not included in Fig. <ref type="figure" target="#fig_7">11</ref>) because the large amount of communication required to composite partial color values limits the overall performance. Nevertheless, we find that depending on the viewpoints, predictive scheduling can also be effective even for opaque volumes rendered on 128 nodes. Fig. <ref type="figure" target="#fig_7">11</ref> shows that particularly for path tracing with many incoherent secondary rays, depth-based scheduling outperforms probability-based scheduling because the measurement of depth-based scheduling is more fine-grained by design, which groups the statistics of depth values into eight different directions using 3D binning. However, such disparities in performance can be overcome by scheduling shadow rays out of order using the probability-based scheduling method. Table <ref type="table" target="#tab_5">3</ref> shows that except for implicit isosurfacing performed on 16 nodes, out-of-order scheduling achieves up to 4.5× higher throughput when rendering the Noise dataset with implicit isosurfacing and path tracing. Because shadow rays, unlike radiance rays, do not require the order of domain traversal to be front to back, and because shadow rays can terminate upon any hit, shadow rays can traverse only a portion of what is required by radiance rays, thus reducing the amount of computation and communication, improving performance greatly.</p><p>Predictive scheduling attempts to find the right amount of speculation when it comes to placing a ray into domains. The right amount implies the actual distance to ray termination as a result of resolving the visibility of a ray after performing visibility queries on all of its speculative rays placed in different domains. To demonstrate the correctness of our prediction models, we measure the amount of redundancy incurred by different scheduling methods in terms of the total scheduling depth of all rays. With the depth values, we calculate the percentage of overhead defined as the ratio of a redundant scheduling depth and a required scheduling depth. For the domain traversal of a radiance  ray, the required depth can be one or more of the affected domains, for the domain traversal of a shadow ray, the required depth can be one or all of the affected domains since a single hit is sufficient to determine the occlusion of a shadow ray. Fig. <ref type="figure" target="#fig_4">12</ref> shows the overhead measured separately for radiance and shadow rays. As can be seen, both methods of depth-based and probability-based predictive scheduling effectively limit overhead to shallow or even sub-shallow levels, drastically reducing the overhead incurred by deep scheduling.</p><p>Although users do not have control over the depth-based prediction model, the model automatically adjusts speculation levels between a shallow scheduling depth and a deep scheduling depth based on the statistics measured from previous rays in flight. In addition to the self-control capability, the probability-based prediction model provides users with a control knob for adjusting speculation levels. Fig. <ref type="figure" target="#fig_4">13</ref> shows such controllability for various rendering algorithms. Fig. <ref type="figure" target="#fig_10">14</ref> shows the performance comparison of different scheduling methods used to render the benchmark datasets. For volume rendering of the RM dataset <ref type="bibr" target="#b10">[11]</ref>, predictive scheduling achieves up to 1.7× speedup compared to shallow scheduling and up to 1.8× speedup compared to deep scheduling. Both deep and predictive scheduling methods begin to outperform shallow scheduling as the node count increases. For implicit isosurfacing of the RM dataset, predictive scheduling achieves up to 2× speedup compared to shallow scheduling and up to 2.3× speedup compared to deep scheduling. Unlike the case of volume rendering, both shallow and deep scheduling methods perform similarly, but predictive scheduling consistently outperforms non-predictive scheduling for all node counts.</p><p>As for rendering geometry data with path tracing, predictive scheduling outperforms shallow and deep scheduling. For the DNS dataset <ref type="bibr" target="#b17">[18]</ref>, predictive scheduling achieves up to 3× speedup compared to shallow scheduling and up to 6.8× speedup compared to deep scheduling. For the Lambda2 dataset <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18]</ref>, predictive scheduling achieves up to 2.3× speedup compared to shallow scheduling and up to 7.8× speedup compared to deep scheduling. For the DNS and Lambda2 datasets, shallow scheduling outperforms deep scheduling overall.</p><p>For implicit isosurfacing of the Exajet dataset <ref type="bibr" target="#b19">[20]</ref>, predictive scheduling achieves up to 2.4× speedup compared to shallow scheduling and up to 2.5× speedup compared to deep scheduling. Both shallow and deep scheduling methods achieve similar throughput. As indicated by the error bars, the throughput variations for predictive scheduling are relatively high compared to other datasets due to irregular distributions of unstructured hexahedral cells captured from different viewpoints.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 :Fig. 4 :</head><label>34</label><figDesc>Fig.3: Our predictive scheduling framework generalizes existing ray scheduling methods to a unified method that adapts to the characteristics of underlying data by adjusting the scheduling depth of each ray. Although a single ray is used in this example, rays are scheduled in groups, not individually.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>SCHEDULE-BY-PROBABILITY-RADIANCE(ray) D[0..n-1] = DOMAIN-TESTS-SORT-BY-DISTANCE(ray) d = n, p_hit = 0.0 for i = ray.next to n-1 Q[D[i].ID].push(ray) p_hit += (1.0 -p_hit) * D[i].p_hit if p_hit &gt; THRESHOLD d = i + 1 break ray.next = d Listing 2: A probability-based queuing method for radiance rays. SCHEDULE-BY-PROBABILITY-SHADOW(ray) D[0..n-1] = DOMAIN-TESTS-SORT-BY-DISTANCE-OR-PROBABILITY(ray) d = n, p_miss = 1.0 for i = ray.next to n-1 Q[D[i].ID].push(ray) p_miss = p_miss * (1.0 -D[i].p_hit) p_anyhit = 1.0 -p_miss if p_anyhit &gt; THRESHOLD d = i + 1 break ray.next = d Listing 3: A probability-based queuing method for shadow rays.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Progression of speculation nodes as part of non-speculative subtrees (top) and speculative subtrees (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Deferred error handling for predictive scheduling. Error tasks are queued within the current subframe and are carried over to the next subframe in the context of progressive rendering.</figDesc><graphic coords="7,326.64,49.50,230.35,108.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Table 1 :</head><label>1</label><figDesc>Configurations of the Noise dataset used for performance analysis. Isosurface values shown in parentheses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(a) RM [11]: a 2048 × 2048 × 1920 regular volume (8 3 domains). (b) DNS [18]: 621M triangles (16 × 4 × 16 domains). (c) Lambda2 [15, 18]: 2.3B triangles (16 × 4 × 16 domains).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 10 :</head><label>10</label><figDesc>Fig. 10: Benchmark datasets used for performance comparison.</figDesc><graphic coords="7,330.26,405.96,225.32,87.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 :</head><label>11</label><figDesc>Fig. 11: Adaptive performance behavior of predictive scheduling methwith variations of volume transparency and surface density of the Noise dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11</head><label>11</label><figDesc>Fig.11compares the performance of depth-based and probabilitybased predictive scheduling to shallow and deep scheduling. In this performance comparison, we evaluate the impact of variations in surface density and volume transparency on the performance of different scheduling methods when rendering the Noise dataset with various rendering algorithms, including volume rendering, implicit isosurfacing, ambient occlusion, and path tracing.When it comes to surface rendering, our general expectation on performance behavior is that for dense geometry data, predictive scheduling should perform as good as shallow scheduling, and for sparse geometry data, predictive scheduling should perform as good as deep scheduling. This is because rays typically terminate early within dense geometry (i.e., there are more opportunities for an intersection), whereas rays typically terminate late within sparse geometry. A similar duality applies for volume rendering. For highly opaque volume data, predictive scheduling should match the performance of shallow scheduling, and for highly transparent volume data, predictive scheduling should match the performance of deep scheduling. Again, similar to the case of geometry rendering, this is because rays typically terminate early in scenes with high opacity whereas rays typically terminate late in scenes with low opacity (i.e., high transparency).We consistently observe such performance behavior in Fig.11for both methods of depth-based and probability-based predictive scheduling. For volume rendering, however, although predictive scheduling shows good performance on 64 nodes, the performance does not scale well on 128 nodes particularly for highly opaque volumes (not included in Fig.11) because the large amount of communication required to composite partial color values limits the overall performance. Nevertheless, we find that depending on the viewpoints, predictive scheduling can also be effective even for opaque volumes rendered on 128 nodes. Fig.11shows that particularly for path tracing with many incoherent secondary rays, depth-based scheduling outperforms probability-based scheduling because the measurement of depth-based scheduling is more fine-grained by design, which groups the statistics of depth values into eight different directions using 3D binning. However, such disparities in performance can be overcome by scheduling shadow rays out of order using the probability-based scheduling method. Table3shows that except for implicit isosurfacing performed on 16 nodes, out-of-order scheduling achieves up to 4.5× higher throughput when rendering the Noise dataset with implicit isosurfacing and path tracing. Because shadow rays, unlike radiance rays, do not require the order of domain traversal to be front to back, and because shadow rays can terminate upon any hit, shadow rays can traverse only a portion of what is required by radiance rays, thus reducing the amount of computation and communication, improving performance greatly.Predictive scheduling attempts to find the right amount of speculation when it comes to placing a ray into domains. The right amount implies the actual distance to ray termination as a result of resolving the visibility of a ray after performing visibility queries on all of its speculative rays placed in different domains. To demonstrate the correctness of our prediction models, we measure the amount of redundancy incurred by different scheduling methods in terms of the total scheduling depth of all rays. With the depth values, we calculate the percentage of overhead defined as the ratio of a redundant scheduling depth and a required scheduling depth. For the domain traversal of a radiance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 :Fig. 13 :</head><label>1213</label><figDesc>Fig.12: Percentages of scheduling overhead for rendering the Noise dataset with ambient occlusion on 128 nodes. Predictive scheduling effectively limits overhead to shallow or sub-shallow levels, reducing the significant amount of redundancy incurred by deep scheduling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 14 :</head><label>14</label><figDesc>Fig. 14: Throughput results for the benchmark datasets. The error bars show standard deviation due to 50 different camera positions orbiting around each dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="1,105.69,131.55,409.67,226.18" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Throughput comparison of synchronous and asynchronous scheduling methods. Implicit isosurfacing was used to render a set of weak scaling benchmarks of the Noise dataset. Throughput measured in MRays/s. Speedup shown in parentheses.</figDesc><table><row><cell>Iso.</cell><cell>Scheduling</cell><cell>Method</cell><cell></cell><cell cols="4">Number of Nodes Volume Grid Size</cell><cell></cell></row><row><cell>Value</cell><cell>Depth</cell><cell></cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>128</cell></row><row><cell></cell><cell></cell><cell></cell><cell>512×</cell><cell>512×</cell><cell>512 3</cell><cell>1024×</cell><cell>1024×</cell><cell>1024 3</cell></row><row><cell></cell><cell></cell><cell></cell><cell>256 × 256</cell><cell>512 × 256</cell><cell></cell><cell>512 × 512</cell><cell>1024 × 512</cell><cell></cell></row><row><cell>0.1</cell><cell>Shallow</cell><cell>Sync</cell><cell>1.4</cell><cell>1.7</cell><cell>2.1</cell><cell>3.4</cell><cell>4.5</cell><cell>5.3</cell></row><row><cell></cell><cell></cell><cell>Async</cell><cell>22.9 (16×)</cell><cell>28.9 (17×)</cell><cell>34.3 (16×)</cell><cell>56.2 (16×)</cell><cell>67.4 (14×)</cell><cell>71.2 (13×)</cell></row><row><cell>0.1</cell><cell>Deep</cell><cell>Sync</cell><cell>1.1</cell><cell>1.4</cell><cell>1.7</cell><cell>2.8</cell><cell>3.6</cell><cell>4.2</cell></row><row><cell></cell><cell></cell><cell>Async</cell><cell>17.5 (15×)</cell><cell>20.5 (14×)</cell><cell>27.4 (16×)</cell><cell>50.7 (18×)</cell><cell>61.2 (17×)</cell><cell>71.6 (17×)</cell></row><row><cell>1.0</cell><cell>Shallow</cell><cell>Sync</cell><cell>0.3</cell><cell>0.3</cell><cell>0.3</cell><cell>0.7</cell><cell>0.9</cell><cell>1.0</cell></row><row><cell></cell><cell></cell><cell>Async</cell><cell>9.0 (30×)</cell><cell>9.5 (31×)</cell><cell>10.5 (35×)</cell><cell>25.1 (35×)</cell><cell>25.8 (28×)</cell><cell>25.6 (25×)</cell></row><row><cell>1.0</cell><cell>Deep</cell><cell>Sync</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>1.7</cell><cell>2.2</cell><cell>2.4</cell></row><row><cell></cell><cell></cell><cell>Async</cell><cell>8.8 (22×)</cell><cell>9.7 (19×)</cell><cell>12.2 (20×)</cell><cell>37.9 (22×)</cell><cell>43.5 (19×)</cell><cell>47.6 (19×)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Effects of out-of-order scheduling of shadow rays when the probability-based scheduling method is used to render the Noise dataset. Throughput measured in MRays/s. Speedup shown in parentheses.</figDesc><table><row><cell>Rendering</cell><cell cols="2">Nodes Method</cell><cell></cell><cell></cell><cell>Sparsity Level</cell><cell></cell></row><row><cell>Algorithm</cell><cell></cell><cell></cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>Implicit</cell><cell>16</cell><cell>In-order</cell><cell>26.1</cell><cell>20.2</cell><cell>16.5</cell><cell>13.2</cell></row><row><cell>isosurfacing</cell><cell></cell><cell cols="5">Out-of-order 24.1 (0.9×) 19.5 (0.9×) 15.9 (0.9×) 12.9 (0.9×)</cell></row><row><cell></cell><cell>128</cell><cell>In-order</cell><cell>26.7</cell><cell>20.4</cell><cell>14.5</cell><cell>14.2</cell></row><row><cell></cell><cell></cell><cell cols="5">Out-of-order 57.3 (2.1×) 41.1 (2.0×) 31.3 (2.1×) 34.5 (2.4×)</cell></row><row><cell cols="2">Path tracing 16</cell><cell>In-order</cell><cell>17.4</cell><cell>5.5</cell><cell>3.0</cell><cell>4.4</cell></row><row><cell></cell><cell></cell><cell cols="4">Out-of-order 20.8 (1.1×) 11.6 (2.1×) 7.6 (2.5×)</cell><cell>11.9 (2.7×)</cell></row><row><cell></cell><cell>128</cell><cell>In-order</cell><cell>11.9</cell><cell>6.6</cell><cell>4.1</cell><cell>8.0</cell></row><row><cell></cell><cell></cell><cell cols="5">Out-of-order 30.1 (2.5×) 22.4 (3.3×) 18.8 (4.5×) 21.5 (2.6×)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">CONCLUSIONScientific simulations are increasingly producing larger datasets reaching up to terascale levels and continuously demand high-fidelity images with realistic shading and illumination models. With such trends, highperformance rendering for in situ visualization on distributed data plays an important role. In this paper, we have developed a data-aware predictive scheduling method and its system for distributed-memory ray tracing. Specifically, we have established a communication abstraction to form a scheduling framework for asynchronous speculation. In addition, we have incorporated simple heuristic prediction models, making the framework highly adaptable to a spectrum of scene characteristics. The framework is flexible enough to support a wide range of rendering techniques, including many variants of volume rendering and geometry rendering. By exploiting concurrency and parallelism, our scheduling method achieves many-times higher throughput on a multi-node, distributed system compared to prior methods, which makes our method fit for both interactive and offline applications. For future work, it would be interesting to consider a machine learning-based prediction model incorporated into distributed-memory ray tracers. Looking forward, we believe that our studies on predictive scheduling have established some groundwork for such a research avenue ahead.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers for their thoughtful comments and suggestions during the review cycle. We also thank a number of people and organizations for providing us with the datasets and tools: the Noise volume generator provided by Greg Abram at the Texas Advanced Computing Center at the University of Texas at Austin; the RM dataset provided by the Lawrence Livermore National Laboratory; the DNS and Lambda2 datasets provided by Myoungkyu Lee at the Sandia National Laboratories; and the Exajet dataset provided by Dassault Systèmes and the NASA Open Data Portal. This work was funded in part by US NSF award ACI-1339863; and an Intel Graphics and Visualization Institute of eXcellence award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Abram</surname></persName>
		</author>
		<ptr target="https://github.com/gregabram/noise" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Galaxy: Asynchronous ray tracing for large high-fidelity visualization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Abram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Navrátil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grossett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ahrens</surname></persName>
		</author>
		<idno type="DOI">10.1109/LDAV.2018.8739241</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 IEEE 8th Symposium on Large Data Analysis and Visualization (LDAV)</title>
				<meeting>the 2018 IEEE 8th Symposium on Large Data Analysis and Visualization (LDAV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018-10">Oct. 2018</date>
			<biblScope unit="page" from="72" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An image-based approach to extreme scale in situ visualization and analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ahrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jourdain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Patchett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petersen</surname></persName>
		</author>
		<idno type="DOI">10.1109/SC.2014.40</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;14</title>
				<meeting>the International Conference for High Performance Computing, Networking, Storage and Analysis, SC &apos;14</meeting>
		<imprint>
			<publisher>ACM/IEEE</publisher>
			<date type="published" when="2014-11">Nov. 2014</date>
			<biblScope unit="page" from="424" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Architecture considerations for tracing incoherent rays</title>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<idno>doi: 10. 2312/EGGH/HPG10/113-122</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on High Performance Graphics, HPG &apos;10</title>
				<meeting>the Conference on High Performance Graphics, HPG &apos;10</meeting>
		<imprint>
			<date type="published" when="2010-06">June 2010</date>
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding the efficiency of ray traversal on GPUs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<idno type="DOI">10.1145/1572769.1572792</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on High Performance Graphics 2009, HPG &apos;09</title>
				<meeting>the Conference on High Performance Graphics 2009, HPG &apos;09</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009-08">Aug. 2009</date>
			<biblScope unit="page" from="145" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The ParaView Guide: A Parallel Visualization Application</title>
		<author>
			<persName><forename type="first">U</forename><surname>Ayachit</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Kitware Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ParaView Catalyst: Enabling in situ data analysis and visualization</title>
		<author>
			<persName><forename type="first">U</forename><surname>Ayachit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Geveci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>O'leary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Moreland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mauldin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2828612.2828624</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, ISAV &apos;15</title>
				<meeting>the 1st Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, ISAV &apos;15</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-11">Nov. 2015</date>
			<biblScope unit="page" from="25" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The SENSEI generic in situ interface</title>
		<author>
			<persName><forename type="first">U</forename><surname>Ayachit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Whitlock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Loring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Geveci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lonie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Bethel</surname></persName>
		</author>
		<idno type="DOI">10.1109/ISAV.2016.013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, ISAV &apos;16</title>
				<meeting>the 2nd Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, ISAV &apos;16</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016-11">Nov. 2016</date>
			<biblScope unit="page" from="40" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A scalable hybrid scheme for ray-casting of unstructured volume data</title>
		<author>
			<persName><forename type="first">R</forename><surname>Binyahib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Peterka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2833113</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2349" to="2361" />
			<date type="published" when="2019-07">July 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image-parallel ray tracing using OpenGL interception</title>
		<author>
			<persName><forename type="first">C</forename><surname>Brownlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ize</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="DOI">10.2312/EGPGV/EGPGV13/065-072</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Eurographics Symposium on Parallel Graphics and Visualization, EGPGV &apos;13</title>
				<meeting>the 13th Eurographics Symposium on Parallel Graphics and Visualization, EGPGV &apos;13</meeting>
		<imprint>
			<date type="published" when="2013-05">May 2013</date>
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Three-dimensional simulation of a Richtmyer-Meshkov instability with a two-scale initial perturbation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">P</forename><surname>Dannevik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dimits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Eliason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Mirin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Woodward</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.1504452</idno>
	</analytic>
	<monogr>
		<title level="j">Physics of Fluids</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3692" to="3709" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributed interactive ray tracing for large volume visualization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Demarle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gribble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="DOI">10.1109/PVGS.2003.1249046</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Parallel and Large-Data Visualization and Graphics</title>
				<meeting>the IEEE Symposium on Parallel and Large-Data Visualization and Graphics</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003-10">2003. 2003. Oct. 2003</date>
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sorted deferred shading for production path tracing</title>
		<author>
			<persName><forename type="first">C</forename><surname>Eisenacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Burley</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.12158</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics Symposium on Rendering, EGSR &apos;13</title>
				<meeting>the Eurographics Symposium on Rendering, EGSR &apos;13</meeting>
		<imprint>
			<date type="published" when="2013-06">June 2013</date>
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dynamically scheduled regionbased image compositing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V P</forename><surname>Grosset</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Knoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<idno type="DOI">10.2312/pgv.20161184</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Eurographics Symposium on Parallel Graphics and EGPGV &apos;16</title>
				<meeting>the 16th Eurographics Symposium on Parallel Graphics and EGPGV &apos;16</meeting>
		<imprint>
			<date type="published" when="2016-06">June 2016</date>
			<biblScope unit="page" from="79" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the identification of a vortex</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hussain</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0022112095000462</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="page" from="69" to="94" />
			<date type="published" when="1995-02">Feb. 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Kilauea&quot;: Parallel global illumination renderer</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Saito</surname></persName>
		</author>
		<idno type="DOI">10.2312/EGPGV/EGPGV02/007-016</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Eurographics Workshop on Parallel Graphics and Visualization, EGPGV &apos;02</title>
				<meeting>the 4th Eurographics Workshop on Parallel Graphics and Visualization, EGPGV &apos;02</meeting>
		<imprint>
			<date type="published" when="2002-09">Sept. 2002</date>
			<biblScope unit="page" from="7" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Petascale direct numerical simulation of turbulent channel flow on up to 786k cores</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Malaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Moser</surname></persName>
		</author>
		<idno>doi: 10.1145/ 2503210.2503298</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis, SC &apos;13</title>
				<meeting>the International Conference on High Performance Computing, Networking, Storage and Analysis, SC &apos;13</meeting>
		<imprint>
			<publisher>ACM/IEEE</publisher>
			<date type="published" when="2013-11">Nov. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Direct numerical simulation of turbulent channel flow up to Re τ ≈ 5200</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Moser</surname></persName>
		</author>
		<idno type="DOI">10.1017/jfm.2015.268</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">774</biblScope>
			<biblScope unit="page" from="395" to="415" />
			<date type="published" when="2015-07">July 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">In situ visualization at extreme scale: Challenges and opportunities</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2009.120</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="14" to="19" />
			<date type="published" when="2009-11">Nov. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The Exajet Data Portal</title>
		<ptr target="https://data.nas.nasa.gov/exajet/" />
		<imprint/>
		<respStmt>
			<orgName>NASA</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Memory-Efficient, Scalable Ray Tracing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Navrátil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-08">Aug. 2010</date>
		</imprint>
		<respStmt>
			<orgName>The University of Texas at Austin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD dissertation</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploring the spectrum of dynamic scheduling algorithms for scalable distributed-memory ray tracing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Navrátil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Fussell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.261</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="893" to="906" />
			<date type="published" when="2014-06">June 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dynamic ray scheduling to improve ray coherence and bandwidth utilization</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Navrátil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Fussell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Mark</surname></persName>
		</author>
		<idno type="DOI">10.1109/RT.2007.4342596</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 IEEE Symposium on Interactive Ray Tracing</title>
				<meeting>the 2007 IEEE Symposium on Interactive Ray Tracing</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007-09">Sept. 2007</date>
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SpRay: Speculative ray scheduling for large data visualization</title>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fussell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Navrátil</surname></persName>
		</author>
		<idno type="DOI">10.1109/LDAV.2018.8739224</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 IEEE 8th Symposium on Large Data Analysis and Visualization (LDAV)</title>
				<meeting>the 2018 IEEE 8th Symposium on Large Data Analysis and Visualization (LDAV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018-10">Oct. 2018</date>
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving noise</title>
		<author>
			<persName><forename type="first">K</forename><surname>Perlin</surname></persName>
		</author>
		<idno type="DOI">10.1145/566654.566636</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="681" to="682" />
			<date type="published" when="2002-07">July 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rendering complex scenes with memory-coherent ray tracing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pharr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kolb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gershbein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<idno>doi: 10 .1145/258734.258791</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;97</title>
				<meeting>the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;97</meeting>
		<imprint>
			<publisher>ACM/Addison-Wesley</publisher>
			<date type="published" when="1997-08">Aug. 1997</date>
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lorensen</surname></persName>
		</author>
		<title level="m">The Visualization Toolkit</title>
				<imprint>
			<publisher>Kitware Inc</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Timeline scheduling for out-of-core ray batching</title>
		<author>
			<persName><forename type="first">M</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<idno type="DOI">10.1145/3105762.3105784</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of High Performance Graphics, HPG &apos;17</title>
				<meeting>High Performance Graphics, HPG &apos;17</meeting>
		<imprint>
			<date type="published" when="2017-07">July 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Frontera: The evolution of leadership computing at the National Science Foundation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stanzione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minyard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Ghattas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Panda</surname></persName>
		</author>
		<idno type="DOI">10.1145/3311790.3396656</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Practice and Experience in Advanced Research Computing, PEARC &apos;20</title>
				<meeting>the ACM Conference on Practice and Experience in Advanced Research Computing, PEARC &apos;20</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="106" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">yt: A multi-code analysis toolkit for astrophysical simulation data</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Oishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Skory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Skillman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Norman</surname></persName>
		</author>
		<idno type="DOI">10.1088/0067-0049/192/1/9</idno>
	</analytic>
	<monogr>
		<title level="j">The Astrophysical Journal Supplement Series</title>
		<imprint>
			<biblScope unit="volume">192</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2011-01">Jan. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">libIS: A lightweight library for flexible in transit visualization</title>
		<author>
			<persName><forename type="first">W</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rizzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Amstutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Insley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ferrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Papka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<idno type="DOI">10.1145/3281464.3281466</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, ISAV &apos;18</title>
				<meeting>the Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, ISAV &apos;18</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018-11">Nov. 2018</date>
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scalable ray tracing using the Distributed FrameBuffer</title>
		<author>
			<persName><forename type="first">W</forename><surname>Usher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Amstutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brownlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.13702</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="466" />
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">OSPRay -a CPU ray tracing framework for scientific visualization</title>
		<author>
			<persName><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Amstutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brownlee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Knoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jeffers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Navrátil</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2599041</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="931" to="940" />
			<date type="published" when="2017-01">Jan 2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
