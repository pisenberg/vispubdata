<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Visual Pattern Search on Graph Data via Graph Representation Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Huan</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Robert Bosch Research and Technology Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zeng</forename><surname>Dai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Robert Bosch Research and Technology Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Panpan</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Robert Bosch Research and Technology Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Liu</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Robert Bosch Research and Technology Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Interactive Visual Pattern Search on Graph Data via Graph Representation Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9326CC00D0BB22EC34388947B32C3ED3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T13:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph</term>
					<term>Graph Neural Network</term>
					<term>Representation Learning</term>
					<term>Visual Query Interface</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. The visualization interface of GraphQ contains: (1) A query editing panel to specify the subgraph patterns and initiate the search.</p><p>(2.1) (2.2) Query result panels to display the retrieved results. The graph thumbnails can be displayed in overview and detail modes.</p><p>(3) A statistics and filtering panel that helps users select a graph to construct example-based query, and visualizes the distribution of the query results in the database. (4) A query option control panel to specify whether fuzzy-pattern search is enabled and whether the node-match should be highlighted. (5) A popup window for pairwise comparison between the query pattern and the returned result.</p><p>The figure shows a case study on program workflow graph pattern search and the details are described in Section 5.1.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Huan Song and Liu Ren are with Robert Bosch Research and Technology</head><p>Center, USA. E-mail: huan.song, liu.ren@us.bosch.com. • Zeng Dai is with ByteDance Inc. E-mail: zeng.dai@bytedance.com * . • Panpan Xu is with Amazon AWS AI. E-mail: xupanpan@amazon.com * .</p><p>The graph data structure models a wide range of processes and relations in real-world applications. Examples include business processes <ref type="bibr" target="#b62">[64]</ref>, control flow graphs in programs <ref type="bibr" target="#b3">[5]</ref>, social connections <ref type="bibr" target="#b51">[53,</ref><ref type="bibr" target="#b76">78]</ref>, knowledge graphs <ref type="bibr" target="#b33">[35]</ref> and semantic scene graphs in image analysis <ref type="bibr" target="#b46">[48]</ref>. Visually identifying and searching for persistent subgraph patterns is a common and important task in graph analysis. For example, searching for graph motifs such as cliques or stars in a social network reveals the community structures or influencers <ref type="bibr" target="#b15">[17]</ref>; searching for similar workflow templates helps streamline or simplify business processes; searching for images with similar scene graphs helps systematic retrieval of training/testing cases to develop models for computer vision tasks.</p><p>In this work, our goal is to support human-in-the-loop, examplebased graph pattern search in a graph database, which could contain hundreds to thousands of individual graphs. Supporting interactive, example-based visual graph pattern query is challenging. Previous graph motif/pattern finding algorithms, e.g. <ref type="bibr" target="#b52">[54,</ref><ref type="bibr" target="#b53">55,</ref><ref type="bibr" target="#b73">75]</ref> often impose a strict limit on the size of query pattern and do not scale well as the size of the query pattern and the number or the size of the query targets increases. In fact, subgraph matching is a well-known NP-complete problem <ref type="bibr" target="#b68">[70]</ref> and there is no known efficient solution so far. Furthermore, the complexity of the subgraph matching problem also makes it difficult to obtain accurate one-to-one node correspondence in the matching results. The node correspondences are crucial to enable visualization-based interpretation and verification of the model's finding. Besides that, it is quite often that domain knowledge is needed to further refine and adjust the results, which cannot be easily supported in algorithms with heavy computational costs.</p><p>To address those challenges, we propose a novel framework for interactive visual graph pattern search via graph representation learning. Our approach leverages graph neural networks (GNNs) to encode topological as well as node attribute information in a graph as fixed-length vectors. The GNNs are applied to both the query graph and the query targets to obtain their respective vector representations. The graph matching problem is therefore transformed into a high-dimensional vector comparison problem, which greatly reduces the computational complexity. In particular, we leverage two separate GNNs to address 1) the decision problem to determine whether a query pattern exists in a graph and 2) the node-alignment problem to find the one-to-one node correspondence between the query pattern and the query targets. We leverage NeuroMatch <ref type="bibr" target="#b42">[44]</ref> for the decision problem. For the node-alignment problem, we propose a novel approach called NeuroAlign that can directly generate cross-graph node-to-node attention scores indicating the node correspondences. In most application scenarios we can precompute and store the vector representations of the query targets for efficient retrieval of the graph matching results. The visualization interface enables easy search and specification of the graph query patterns. Since the query engine could return a large number of matched graphs, we present the results with different levels-of-details that show the matched graphs in space-efficient, thumbnail style representations. They can also be sorted via a variety of criteria. Users can also interactively specify additional constraints to further filter the returned results based on their domain knowledge.</p><p>We develop the visual analytics system GraphQ based on the proposed framework. GraphQ goes beyond looking for a predefined set of graph motifs and the users can interactively specify and search for meaningful graph patterns in the respective application domain. The query pattern can include both topological structures and domain-specific node attributes to be matched in the query results. The specified query can be partially matched to enable fuzzy-pattern search.</p><p>We demonstrate GraphQ's usefulness with two example usage scenarios in different application domains. In the first usage scenario, we apply the system to analyze a large collection of engineering workflow graphs describing the diagnostics programs in automotive repair shops. The goal is to understand whether there are repetitive patterns in the workflow graphs which eventually serves two purposes -curate the workflows to reduce repetitive operations and reuse the patterns as templates for future workflow creation. In the second usage scenario, we apply GraphQ to analyze the semantic scene graphs generated from images, where the nodes are image regions (super-pixels) with semantic labels such as buildings and road, and the links describe the adjacency relations between regions. Searching for subgraph patterns in such semantic scene graphs can help retrieve similar test cases for model diagnostics in computer vision tasks. The example usage scenarios demonstrate that the framework is generalizable and can be applied to graphs of different nature.</p><p>Furthermore, we conduct quantitative experiments to evaluate the accuracy and the speed of both NeuroMatch and NeuroAlign. We show that for the node alignment problem, NeuroAlign can produce 19%-29% more accurate results compared to the baseline technique described in NeuroMatch <ref type="bibr" target="#b42">[44]</ref>. The improvement greatly helps in validating and interpreting the query results in the visualization. We also compared the speed of the algorithm with a baseline combinatorial approach, the result shows that our algorithm gains up to 100× speed improvement. The speed improvement is the key that enables a human-in-loop, visual analytics pipeline.</p><p>To summarize, our contributions include:</p><p>• A visual analytics framework for human-in-the-loop, examplebased graph pattern search via graph representation learning. To the best of our knowledge, this is the first deep learning-based approach for interactive graph pattern query. • A novel approach (NeuroAlign) for pairwise node-alignment based on graph representation learning which provides 10×-100× speedup compared to baseline combinatorial algorithm <ref type="bibr" target="#b45">[47]</ref> and 19%-29% more accurate results than existing deep learning based approach. • A prototype implementation of the framework, GraphQ, with interactive query specification, query result display with multiple levels-of-detail, and user feedback mechanisms for query refinement. Two example usage scenarios illustrating the general applicability and effectiveness of the proposed system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we focus on the most relevant research to our work in the areas of graph visualization, visual graph query, and graph representation learning for subgraph pattern matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Visualization</head><p>Graph visualization is an extensively studied topic <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b49">51]</ref> for its application in a wide range of domains. Open source or commercial software for graph visualization (e.g. Gelphi <ref type="bibr" target="#b6">[8]</ref> and Neo4j Bloom <ref type="bibr" target="#b1">[3]</ref>) are also available for off-the-shelf use. Researchers in graph visualization typically focus on one or more of the following aspects: develop layout algorithms to efficiently compute readable and aesthetic visualizations (e.g. <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b31">33,</ref><ref type="bibr" target="#b32">34,</ref><ref type="bibr" target="#b36">38]</ref>), design new visual encoding to display nodes and edges (e.g. <ref type="bibr" target="#b27">[29,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b69">71]</ref>), develop graph simplification or sampling technique to avoid over-plotting and visual clutter (e.g. <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b70">72]</ref>), and design novel user interaction scheme for exploratory analysis (e.g. <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b54">56,</ref><ref type="bibr" target="#b61">63,</ref><ref type="bibr" target="#b65">67]</ref>). Depending on the nature of the graph data, they have developed a variety of systems and algorithms for directed/undirected graphs, multivariate graphs (with node/edge attributes) and dynamic network visualization to support a wide range of graph analytic tasks <ref type="bibr" target="#b38">[40,</ref><ref type="bibr" target="#b55">57]</ref>.</p><p>In this work, we focus on supporting interactive, example-based visual query of graph patterns in a database and visualizing the results. This is a generic framework that can be applied to both directed or undirected graph and graphs with node/edge attributes, as demonstrated in the example usage scenarios. We utilize existing graph layout techniques for a detailed view of directed graphs <ref type="bibr" target="#b20">[22]</ref> and design a compact visualization for summarizing graph structure to provide an overview of the query results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Graph Query</head><p>Graph patterns/motifs are frequently used to simplify the display of graphs and reduce visual clutter. Motif Simplification <ref type="bibr" target="#b15">[17]</ref> was developed to identify graph motifs including clique, fan, and d-connectors based on topological information and visualized them as glyphs in the node-link display for more efficient usage of the screen space. More generally, cluster patterns, esp. "near-clique" structures are the most studied and visualized in the literature and various methods have been developed to compute and visualize them <ref type="bibr" target="#b73">[75]</ref>. However, most of the patterns/ motifs here are predefined and can not be easily modified by users.</p><p>Graphite <ref type="bibr" target="#b11">[13]</ref>, Vogue <ref type="bibr" target="#b8">[10]</ref>, and Visage <ref type="bibr" target="#b53">[55]</ref> support interactive, user-specified queries on graph data and Vigor <ref type="bibr" target="#b52">[54]</ref> focuses on visualization of the querying results. In these systems, users can interactively specify node attributes as well as topological constraints in the form of a query graph and the system searches for matching subgraphs. However, the complexity of the query is usually limited, which reduces the expressive power of the specified patterns.</p><p>Our approach is also inspired by a number of existing visual query system on time series data, where the user can interactively specify the patterns they are searching for, by either drawing the pattern directly on a canvas or selecting the pattern from a data sample <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b77">79]</ref>. Supporting user-specified patterns gives the user great flexibility and power to perform exploratory analysis in various application domains. However, querying arbitrary patterns on a graph structure brings unique challenges in terms of the computation speed needed to support an interactive user experience, which we address with a graph representation learning-based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph Representation Learning for Subgraph Pattern Matching</head><p>Graph neural networks (GNNs) have emerged as a generic approach for graph representation learning, which can support a variety of graph analytics tasks including link prediction, node classification, and community structure identification <ref type="bibr" target="#b25">[27,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b58">60,</ref><ref type="bibr" target="#b74">76,</ref><ref type="bibr" target="#b78">80]</ref>. The recent development on GNN library further increases the popularity among researchers <ref type="bibr" target="#b17">[19]</ref>. The success of GNN on diverse graph tasks also motivated researchers to address the comparison problem between different graphs, such as graph matching <ref type="bibr" target="#b40">[42]</ref> and graph similarity learning <ref type="bibr" target="#b2">[4]</ref>.</p><p>A comprehensive survey on this topic is provided in <ref type="bibr" target="#b43">[45]</ref>. Recently, GNNs have been shown to improve the performance on the challenging subgraph-isomorphism problems, including subgraph matching <ref type="bibr" target="#b42">[44]</ref>, subgraph isomorphism counting <ref type="bibr" target="#b41">[43]</ref>, maximum common subgraph detection <ref type="bibr" target="#b5">[7]</ref>, and graph alignment <ref type="bibr" target="#b18">[20]</ref>. Powered by flexible representation learning, these approaches addressed issues of heuristic-based solutions <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b63">65]</ref> in terms of accuracy and query scalability. Our objective is to utilize GNNs to facilitate fast user-interaction with graph queries, where the embeddings of the existing graphs can be precomputed and stored to enable efficient retrieval during the inference stage. Compared to <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b18">20]</ref>, our approach resolves subgraph isomorphism from the learned embedding space alone, without expensive iterative search <ref type="bibr" target="#b5">[7]</ref> or embedding refinement aided by the additional network <ref type="bibr" target="#b18">[20]</ref>. Our proposed framework utilizes NeuroMatch <ref type="bibr" target="#b42">[44]</ref> as a core component to efficiently query matching graphs but involves a novel component NeuroAlign to resolve the issue of NeuroMatch on obtaining accurate node alignment. The capability to identify matching nodes is critical for intuitive user interaction with complex topologies. There are relatively fewer works in the visual analytics domain utilizing graph representation learning. In <ref type="bibr" target="#b19">[21]</ref>, a contrastive learning approach is developed to visualize graph uniqueness and explain learned features. Graph representation learning-based algorithms have also been developed for graph layout/drawing <ref type="bibr" target="#b37">[39,</ref><ref type="bibr" target="#b75">77]</ref>, evaluating graph visualization aesthetics <ref type="bibr" target="#b24">[26]</ref>, and sample large graphs for visualization <ref type="bibr" target="#b81">[83]</ref>. Our framework addresses the important problem of subgraph matching and facilitates intuitive interaction. To the best of our knowledge, this is the first approach based on representation learning for interactive visual graph queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM</head><p>In this section, we first define the subgraph matching problem and describe our overall framework to resolve it. We then describe NeuroMatch and NeuroAlign, the two GNNs as the core components of the framework. Finally, we introduce an improved inference method and a simple extension to support approximate query matching. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Definition</head><p>We first formally define the subgraph matching problems. We denote G = (V, E) as an undirected, connected graph with vertex set V and edge set E, X as the features associated with V (e.g. categorical attributes). Given a query graph G Q and a target graph G T , we consider the decision problem which determines whether there exists a subgraph H T ⊆ G T , such that G Q is isomorphic to H T . When H T exists, i.e. G Q is subgraph-isomorphic to G T , we further consider the node alignment problem which looks for an injective mapping function f :</p><formula xml:id="formula_0">V Q → V T , such that { f (v), f (u)} ∈ E T if {v, u} ∈ E Q .</formula><p>When the node features X exist, the matching requires equivalence of the feature too. Note that this defines edge-induced subgraph isomorphism, which is our focus in the paper. However, the system is general to apply on node-induced subgraph isomorphism <ref type="bibr" target="#b4">[6]</ref> too.</p><p>An illustrative example is shown in Fig. <ref type="figure" target="#fig_0">2</ref>, where the colors encode node categorical feature and letters are the node names. The example query graph</p><formula xml:id="formula_1">G Q is a subgraph of G T with the correct node alignment of f (a) = A, f (b) = B, f (c) = C, f (d) = D.</formula><p>In this paper, we consider the practical case of a large database of target graphs, where the task is to solve the above decision problem and node-alignment problem for each of the target graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overall Framework</head><p>Our proposed framework consists of two core components: Neu-roMatch (Fig. <ref type="figure" target="#fig_1">3</ref>) and NeuroAlign (Fig. <ref type="figure" target="#fig_2">4</ref>), which focus on solving the subgraph decision and node alignment problems respectively. Given a graph database and user-created query graph, we utilize the state-of-the-art NeuroMatch method <ref type="bibr" target="#b42">[44]</ref> to efficiently retrieve matching target graphs which contain the query graph. NeuroMatch decomposes the graphs into small neighborhoods to make fast decision locally and then aggregates the results. After a matching target graph is found, the node alignment between the two graphs can still be ambiguous and misleading based on what we observe in the experimental results. This is due to the fact that the learning process of NeuroMatch relies entirely on small neighborhoods within the graphs. As a result, each query node could end up matched to multiple target nodes where many of them are actually false positives. To tackle these issues, we propose a novel model NeuroAlign, which directly predicts node alignment from query and target graphs, without segmenting them into small neighborhoods. It computes node-to-node attention based on graph node embeddings to obtain the alignment results. Finally, the matching target graphs and corresponding matching nodes are returned to the user for exploration and analysis.</p><p>NeuroMatch and NeuroAlign both employ GraphSAGE <ref type="bibr" target="#b25">[27]</ref> as the backbone GNN for representation learning. For simplicity, we consider GraphSAGE as a general function that performs representation learning, where the input is a given graph and the output is a set of embeddings for every node in the graph. Optionally, a pooling layer can be added on top of the node embeddings to obtain a single embedding of the input graph. A more detailed description can be found in the appendix. We use h v to denote the learned representation of node v at the final output layer, which will be used by NeuroMatch and NeuroAlign as described in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Subgraph Decision via NeuroMatch</head><p>Conducting subgraph matching in the embedding space can facilitate efficient retrieval. However, considering the scale of the database and the large size of certain graphs, it is challenging to build the predictive model to encode the subgraph relationships. NeuroMatch resolves this issue by decomposing the given query and target graphs into many small regions and learns the subgraph relationship in these small regions first. In particular, for each node q in the query graph, it extracts a small khop neighborhood graph g q . For each node t in the target graph, it also extracts their k-hop neighborhood g t . Then the problem of determining whether G Q ⊆ G T transforms into many local subgraph matching decisions about whether g q ⊆ g t . To find potential local matches, Neuro-Match compares all pairs of nodes between the query and target graphs. Finally, the ensemble decision can be made by checking whether every query neighborhood can find a matching target neighborhood. Figure <ref type="figure" target="#fig_1">3</ref> shows a simple example to illustrate the main idea of NeuroMatch. In order to determine the local subgraph relationship, i.e. whether the k-hop neighborhood graph g q is a subgraph of g t , the algorithm feeds g q and g t into GNN with the pooling layer to extract the respective anchor node embedding at q and t. A comparator function then takes each pair of these embeddings and predicts the subgraph relationship, as shown in Fig. <ref type="figure" target="#fig_1">3</ref>. We describe the method in the appendix and refer readers to the NeuroMatch paper for more detail <ref type="bibr" target="#b42">[44]</ref>.</p><p>When the model is trained, we pre-compute and store embeddings of all graphs in the database. The inference process simply iterates through all pairs of query and target nodes, and utilizes the (trained) comparator to make local subgraph decisions. The aggregated decision is then made by checking whether each query neighborhood finds a match. This process has linear complexity in terms of both query and target number of nodes, thus facilitates efficient retrieval at the front-end interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Node Alignment via NeuroAlign</head><p>NeuroMatch determines whether the query is a subgraph of the target graph. When a matching target graph is retrieved and visualized, it is still difficult for the user to extract insights when the target graph is large and the topology is complex. In this case, showing the corresponding nodes can provide intuitive and explainable visual cues. We propose NeuroAlign, to obtain improved node alignment performance. We formulate the prediction problem as a classification task, where query nodes are examples and the target nodes correspond to labels. This architectural change is crucial to enable more accurate alignment by accounting for much larger areas on both graphs. However, for different target graphs, the number of classes (i.e. target nodes) varies. This creates a challenge for predictive models. We resolve it by employing a flexible, cross-graph attention mechanism.</p><p>As shown in Fig. <ref type="figure" target="#fig_2">4</ref>, NeuroAlign directly takes the node embeddings obtained from GNN on the entire graphs G Q and G T . These embeddings are denoted as {h q , ∀q ∈ G Q } and {h t , ∀t ∈ G T }. We then compute the similarity between each query embedding and every target embeddings through an attention network. This process can be considered as creating an attention matrix A ∈ R V Q × V T , where the element A q,t contains the attention from node q to t. We then directly transform the similarity matrix to a probability matrix P ∈ R V Q × V T using row-wise softmax and use them in the cross-entropy loss. Formally,</p><formula xml:id="formula_2">A q,t = ψ(h q h t ) p q = softmax(a q ) L(G Q , G T ) = − ∑ q∈G Q y q log(p q ) (1)</formula><p>where ψ denotes the attention network, a q is the q-th row of A, and y q is the one-hot ground-truth label for node q, indicating which node in G T is the corresponding node of q. The prediction p q contains the probabilities of matching query node q to every target node. We implement the attention network as a multi-layer perceptron, which takes a pair of embeddings produced by the GNN, concatenate them and return a similarity score between a node q in the query graph and a node t in the target graph. In case G T is too large, the computation of A q,t could consume too much memory, and needs to be constrained to a subgraph at t. In practice, we specify a maximum size that covers most target graphs in the database.</p><p>Similar to NeuroMatch, when the model is trained, we can pre-compute all graph embeddings generated by NeuroAlign to make the retrieval process efficient. In addition, NeuroAlign works subsequently to NeuroMatch and only activates when a subgraph relationship is predicted, thus creating minimal computational overhead for visualization and interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Algorithm Training</head><p>The training of NeuroMatch and NeuroAlign are conducted separately. Training NeuroMatch (and its backbone GraphSAGE GNN) involves sampling large amounts of mini-batches containing both positive and negative pairs. A positive pair consists of two neighborhood graphs g q and g t that satisfy the subgraph relationship, while a negative pair consists of neighborhood graphs where the relationship is violated. To sample a positive pair, we first randomly sample a k−hop neighborhood as g t , and then sample a subgraph within g t as the query neighborhood g q . To sample negative pairs, we start with the obtained target neighborhood g t above, and sample a smaller neighborhood from a different graph as g q (query neighborhood). Note that g q needs to be verified with exact matching protocol <ref type="bibr" target="#b12">[14]</ref> to ensure g q g t . In practice, we find that hard negatives are necessary to achieve high precision, which are obtained by perturbing the above positive pair (g q ⊆ g t ) such that the subgraph relationship no longer exists. We perturb the positive pair by randomly adding edges to g q and verify the success with exact matching <ref type="bibr" target="#b12">[14]</ref>. As can be seen, negative sampling extensively invokes exact matching algorithm, which is slow to compute. To keep the training tractable, we set small neighborhood hop k = 3 and also limit the number of nodes to sample from the neighborhood to 30.</p><p>Training NeuroAlign (and its backbone GraphSAGE GNN) is much simpler. It involves sampling only positive pairs, since its objective is to improve node alignment when the subgraph decision has already been made that G Q ⊆ G T . Therefore, the sampling involves extracting random queries from the graphs in the database. For each target graph G T in the database, we randomly sample a subgraph within it as G Q . The ground-truth injection mapping is acquired directly in the sampling process, and it is converted to y q to indicate which node in G T is the corresponding node of q. NeuroAlign can be trained efficiently through this simple sampling process and without invoking the expensive exact matching algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Greedy Assignment for Inference</head><p>During inference of node alignment, different nodes in the query graph could be mapped to the same node on the target graph. This is likely to occur among nodes with highly similar topological and attribute features. The prediction conflict can be resolved with a task assignment algorithm. Instead of resorting to the combinatorial Hungarian algorithm <ref type="bibr" target="#b45">[47]</ref>, we further develop a simple greedy assignment approach. Specifically, given the predicted probability matrix P, we iterate the probabilities in descending order and record the corresponding matching pair only when both the query and target nodes have not been assigned. The iteration stops when all query nodes have been assigned. This simple process resolves conflicting assignment to the same target node and improves the overall node alignment performance (experimental results in Section 5.3.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Approximate Query Matching</head><p>In addition to the retrieval results obtained from the query graph, we provide the option to perform approximate query matching. This method perturbs the query graph slightly, in order to obtain similar, but different matching graphs. Specifically, denote the set of obtained matches from the original query graph G Q as R. We remove one node from G Q and its associated edges to obtain the perturbed query G Q . Then we conduct the search with NeuroMatch on G Q and add the novel matches R. We continue the iteration by removing a node from the perturbed query, until either a prespecified maximum number of steps is reached or G Q becomes disconnected. To lower the chance of getting a disconnected graph, each time we remove the node with the lowest degree in G Q .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VISUALIZATION AND INTERACTION</head><p>In this section, we first evaluate the design goals of GraphQ (Section 4.1). We then describe the GraphQ system with details on its visualization and interaction components (Section 4.2.1), and technical implementation (Section 4.2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Design Goals</head><p>GraphQ's principle design goal is to provide a generic solution for interactive graph pattern search on a graph database based on user-specified examples. The basic requirement is that the user needs to be able to interactively select and refine graph patterns and analyze the retrieved results. In the meanwhile, the system should display the matching instances as well as explaining the results by highlighting the node correspondences.</p><p>We further enrich and refine the design goals by collecting requirements for domain-specific usage scenarios. We analyzed two example usage scenarios including workflow graph pattern analysis and semantic scene graph analysis in image understanding. For the first usage scenario (details in Section 5.1) we worked closely with the domain experts who provided the workflow graph data and who are also the end-user of the system. In the second usage scenario, we reference the relevant literature in computer vision on semantic scene graphs. Semantic scene graph is a commonly used graph structure that describes not only the objects in an image but also their relations <ref type="bibr" target="#b34">[36]</ref>. They are frequently used to retrieve images with the same semantics. By analyzing the commonalities of the two usage scenarios we identified the following user analysis tasks to support in GraphQ: T1 Browse/search the graph database. To start the query process, the user needs to be able to select from hundreds to thousands of graphs. Therefore, the system should provide graph search and filtering functionalities based on the category, the name, or graph statistics such as the number of nodes/links. Besides that, a visualization showing an overview of all graphs in the database will be useful to help locate interesting graphs or clusters. T2 Interactively construct the query pattern by selecting on a graph visualization. To minimize user effort, the system should support both bulk selection mechanisms such as brushing the graph regions as well as query refinement methods to add/delete individual nodes/edges from the pattern. T3 Interpret and validate the matched graphs via highlighted similarities and differences. To help users interpret the matching results, the node correspondences, as well as differences in the query results, should be highlighted. Furthermore, since the subgraph matching and node correspondence calculation algorithms are not 100% accurate, the results need to be presented in a meaningful way for easy verification. T4 Explore the distribution of the matching instances. After the matched graphs are returned, the system should indicate how frequently the query pattern occurs in the entire database, and provide the distribution of the pattern among different categories of graphs in the database. T5 Refine query results. A flexible query system should further support query refinement mechanism where the users can apply their domain knowledge to filter the results with additional constraints, such as matching additional node attributes or limiting the results to a certain category of graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">GraphQ System</head><p>We design GraphQ to support the user analysis tasks (T1-5) described in Section 4.1 with the architecture and user workflow featured in Fig. <ref type="figure" target="#fig_3">5</ref>.</p><p>The user can start with an overview of the graph database (T1), brush, and select a graph to create example-based query patterns (T2). The query pattern (along with optionally perturbed query pattern for approximate query matching) will be sent to the back-end, its node representations will be computed and compared with the precomputed node embeddings to obtain a set of matching graphs containing the query pattern.</p><p>The matching results along with the query pattern will go through Neu-roAlign to compute one-to-one node correspondence. The query results will be displayed in the front-end with multiple levels-of-detail (T3) and can be refined further by adding node-attribute constraints interactively in the query panel (T5). The distribution of the matching graphs will be highlighted interactively in the database overview panel (T4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Components</head><p>The user interface of GraphQ is composed of four main components: Overview and filters. In the overview panel (Fig. <ref type="figure">1</ref>(3)) the system displays the distribution of key graph statistics such as the number of the nodes/edges as well as domain-specific attributes such as the category of the graph. Both univariate distributions and bivariate distributions can be displayed as histograms or scatterplots. Users can brush the charts and select a subset of graphs to create example-based query patterns. To provide an overview of the graph structural information and help users navigate and select a graph to start the query (T1), we further precompute the graph editing distance <ref type="bibr" target="#b21">[23]</ref> which roughly captures the structural similarities between all pairs of graphs. A 2-D projection coordinates of the graph can then be precomputed using t-SNE <ref type="bibr" target="#b71">[73]</ref> based on the distance matrix and stored as additional graph attributes (Fig. <ref type="figure">1(a)</ref>).</p><p>After the query result is obtained, the charts will be updated to provide a contextual view of how the subgraph pattern occurs in the database. For example, the user can observe whether the pattern occurrence concentrate on a small subset of graph categories or it is a generic pattern that appears in many different categories (T4) (Fig. <ref type="figure">1(d)</ref>). Furthermore, the overview panel is a customizable module that can be configured through a json file specifying the attributes to be displayed and the chart to display it. Users can also interactively fold each chart and hide it in the display, such that space can be used for keeping important attribute information on the screen. The system also displays a popup window to show detailed information for selected charts.</p><p>Graph query panel. In the graph query panel ( Fig. <ref type="figure">1</ref>(1)), the user can interactively select from a graph instance to construct the query pattern. The color of the nodes encodes the key node attribute to be matched in the subgraph pattern query. The system currently supports categorical node attributes. This can be extended to numerical attributes by quantizing the values. Additional node attributes are displayed in attachment to the nodes or in tooltips. As discussed in Sect. 4.1, we need to support fast, interactive query construction (T2). In this panel, the user can quickly select a group of nodes and the subgraph they induce by brushing a rectangular area on the visualization. They can also construct the pattern in a more precise manner by clicking the + andbutton on the top right corner of each node. A minimap on the bottom right of the panel allows the user to easily navigate and explore graphs of larger size. The layout of the graph is computed with existing layout algorithms, such as the algorithm described in <ref type="bibr" target="#b20">[22]</ref> for directed graphs. When the nodes have inherent spatial locations, they are used directly for display.</p><p>Query results. After the sub-graph pattern matching results are returned, the query results panel will be updated to display all the matching graphs as a small multiples display (Fig. <ref type="figure">1</ref>(2.1) and (2.2)). Since the number of returned results could be large, the system supports sorting the returned graphs with graph attribute values such as the number of nodes (Fig. <ref type="figure">1(f)</ref>). To support T3, the matching nodes are highlighted based on the results returned by the node alignment module. The graphs can be displayed either in a node-link diagram with the same layout as the graph in the query panel (Fig. <ref type="figure">1</ref>(2.2)) or in a thumbnail visualization designed to display the graph in a more compact manner (Fig. <ref type="figure">1</ref>(2.1)). In particular, we use topological sorting of the nodes for directed acyclic graphs to order the nodes, layout them vertically, and route the links on the right to obtain a compact view (Fig. <ref type="figure" target="#fig_0">1(2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.1)).</head><p>Comparison view. To support T3 and T5, we further visualize the query and selected matching graphs side-by-side in a popup window. The user can click on the zoom-in button on each small multiple to bring out the comparison view (Fig. <ref type="figure">1</ref>(5)) and review each matching graph in detail. The matched nodes are highlighted for verification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Implementation</head><p>GraphQ's implementation uses a typical client-server architecture. The frontend UI framework is implemented in Javascript with React <ref type="bibr" target="#b16">[18]</ref> and AntD UI <ref type="bibr" target="#b13">[15]</ref> libraries. The visualizations are drawn using D3.js <ref type="bibr" target="#b9">[11]</ref> on svg within the React framework. We use dagre [1] to compute directed graph layout in the front-end. The backend server is implemented in Python with Flask <ref type="bibr" target="#b22">[24]</ref>. The graph data are stored as json documents in the file system and modeled with NetworkX <ref type="bibr" target="#b23">[25]</ref>. We use Py-Torch <ref type="bibr" target="#b50">[52]</ref> for graph representation learning for both subgraph matching and node correspondence learning. More specifically, we use PyTorch Geometric <ref type="bibr" target="#b17">[19]</ref> and DeepSNAP <ref type="bibr" target="#b0">[2]</ref> to batch graph data (including their topological structures and node features) for training and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>Our evaluation of the proposed system consists of two example usage scenarios (Section 5.1 and 5.2), quantitative experiments on various datasets (Section 5.3), and interview with domain experts on both usage scenarios (Section 5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Example Usage Scenario: Program Workflow Analysis</head><p>In the first usage scenario, we apply GraphQ to analyze a collection of graphs describing the workflows in a vehicle diagnostics software program. The software program uses prescripted workflow graphs to check the functionalities of the system and locate the problem in the vehicles. The workflows are modeled as directed graphs where each node represents an individual procedure in the workflow and the link represents their sequential orders. We convert the graphs to undirected graphs as input for the query algorithms. In total, there are ∼20 different types of procedures in the workflow, and we use node colors in the system to distinguish them (Fig. <ref type="figure">1</ref>) (all the names of the nodes are anonymized). In both NeuroMatch and NeuroAlign, the type of the procedures is considered as a node attribute.</p><p>The workflows are manually created and it is a time-consuming process. The goal of analyzing workflow graphs is to identify subroutines in the workflow that are reused frequently and therefore can be used as templates, or submodules in the future to facilitate the workflow editing process or to simplify the workflow descriptions. However, identifying such frequent subroutines cannot be easily automated -substantial domain knowledge in automotive hardware and software system is needed to curate meaningful patterns, therefore a human-in-the-loop approach is well-suited.</p><p>Through an initial data exploration together with the domain experts, we found that pairwise comparison of workflows using graph editing distance <ref type="bibr" target="#b21">[23]</ref> can provide an overview of the graph similarities in the dataset. This overview can help the user to select interesting workflows as the starting point for exploration. Our system integrates a t-SNE projection <ref type="bibr" target="#b71">[73]</ref> of all the graphs based on the graph editing distance matrix which reveals several clusters (Fig. <ref type="figure">1(a)</ref>). The user can use the brushing function to select one cluster and the selected graphs will be updated in the table (Fig. <ref type="figure">1(b)</ref>). The user could then select any graph from the table to be displayed in the query editor (Fig. <ref type="figure">1</ref>(1)) to create example-based queries. In Fig. <ref type="figure">1(c</ref>), a subroutine with a branching structure is selected by brushing on the visualization. The user can invoke the context menu and search for the query pattern in the graph database. With approximate matching disabled (Fig. <ref type="figure" target="#fig_2">1(4</ref>)), the system returns 45 matched graphs in the database. In the graph types histogram, we can see that most of the matched graphs belong to two types (Fig. <ref type="figure">1(d)</ref>). For an overview of the matching results (Fig. <ref type="figure">1</ref>(2.1)), the user could toggle minimize in the query results display (Fig. <ref type="figure">1(f)</ref>) and highlight the node matches returned by NeuroAlign (Fig. <ref type="figure">1(e)</ref>). The result shows that indeed most of the graphs returned contain the nodes in the query pattern, indicating that the algorithm is returning reliable results. To further view the details, the user turns off the minimize toggle, and the graphs are displayed in a similar layout as in the query panel and the user can review more details about each graph including the graph name, number of nodes, and links, etc (Fig. <ref type="figure">1</ref>(2.2)). To facilitate the inspection of more detail about the returned matches and aligned nodes, we design the side-by-side display of the query graph and returned matching graph (Fig. <ref type="figure">1</ref>(5)). The display is activated as a popup window when the user clicks on the zoom button (Fig. <ref type="figure">1(g)</ref>). Users can also add additional node attribute constraints by clicking on the corresponding node attribute (Fig. <ref type="figure">1(h)</ref>) to be matched in the query results. In this example there is no workflow satisfying the specified attribute constraint. After verifying the results the user can save the query pattern in a json file to be reused when manually creating workflows in the future. Fig. <ref type="figure">6</ref> shows the query results for a fan-like structure selected from a graph (Fig. <ref type="figure">6</ref>(a)). The system returns 21 matched results with approximate search disabled. Indeed most of the returned graphs contain the fan-like structure (Fig. <ref type="figure">6(b</ref>)), indicating another reusable submodule in the workflow creation process. In the t-SNE plot, the graphs with matching fan-like patterns are highlighted in orange, showing the graphs are scattered in different clusters according to graph editing distance (Fig. <ref type="figure">6(c)</ref>). This finding indicates our method can uncover meaningful patterns in the sub-regions of the graphs that are missed by graph-level similarities. To further extend the search to graphs that may contain similar, but not exact the same patterns, the user toggles the button to enable approximate search (Fig. <ref type="figure" target="#fig_2">1(4</ref>)), the returned result contains much more graphs (172 graphs) than in exact matching (Fig. <ref type="figure">6(d)</ref>).</p><p>The user sorts the results based on the number of nodes and found that the graphs with approximate matches contain a simpler fan-like structure with fewer nodes. Based on the analysis the user concludes that the fan-like pattern can be used as a template in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Example Usage Scenario: Scene Graph Search</head><p>In the second usage scenario, we apply GraphQ to semantic scene graph search in computer vision applications to find images with similar objects and relationships that resemble our query subgraph structure. It can be useful for many computer vision tasks such as image retrieval <ref type="bibr" target="#b57">[59,</ref><ref type="bibr" target="#b80">82]</ref>, visual question answering, relationship modeling, and image generation. We follow the procedures described in <ref type="bibr" target="#b47">[49]</ref> to extract a semantic scene graph from each image. Each node in the graph represents a super-pixel extracted from the image using a segmentation algorithm and the links between nodes encode the adjacency information between those super-pixels. Each node is annotated with a semantic label, as one of its attributes and the whole extracted graph from an image is an undirected, planar graph <ref type="bibr" target="#b67">[69]</ref>. In this study, we use a public image segmentation dataset (MSRC-21 <ref type="bibr" target="#b60">[62]</ref>) to illustrate this approach. Each image contains ground-truth labels such as tree, grass, wall and unlabeled void, etc. We illustrate the process to extract the scene graph from each image in Fig. <ref type="figure">7</ref>.</p><p>To perform scene graph search, the user starts with the overview of all graphs in the database. The user picks a graph to work on and brushes a subgraph, for example, three connected nodes (Fig. <ref type="figure" target="#fig_5">8(a)</ref>) including sky, building and road. This subgraph structure could indicate a typical city environment (with buildings and road). The backend, with approximate search disabled, returns matched result of 25 graphs and most of them contain the same subgraph: street view: interconnected super-pixels of sky, building and road as shown in (Fig. <ref type="figure" target="#fig_5">8(b)</ref>). Note in histogram overview (Fig. <ref type="figure" target="#fig_5">8(c</ref>)), all of these resulted images come from the same row (17th) in MSRC-21 dataset that belongs to the category "road/building". The user can also sort by different metrics and filter by different node information such as area range, or even super-pixel location, etc. Through these interactions, the user eventually finds interesting images tailored to needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Quantitative Evaluation</head><p>We evaluate the performance of the proposed system on 4 graph datasets in various domains: program workflow dataset (vehicle   <ref type="bibr" target="#b44">[46,</ref><ref type="bibr" target="#b56">58]</ref> contains 600 graphs of protein tertiary structure with 3 to 96 nodes. The last 3 datasets are public.</p><p>We utilize an 8-layer GraphSAGE in training and the hidden dimension for node embeddings is 64. For NeuroAlign, the attention network has two hidden layers of dimensions 256 and 64. We use ReLU activation. The learning rate is fixed at 0.0001 without weight decay and Adam optimizer is utilized.</p><p>The training data is generated on the fly by randomly sampling the positive and negative pairs, as described in Sect. 3.5. Note that the ground-truth label for a positive pair is obtained automatically during sampling, and for a negative pair is calculated by exact matching algorithm <ref type="bibr" target="#b12">[14]</ref>. The batch size is fixed to 128. For validation data, we sample the dataset following the same process, prior to training. For testing data, we sample based on the evaluation tasks as described in the following sections.</p><p>All experiments are conducted on a single GeForce GTX 1080 Ti GPU. We measure the performance of the system in terms of prediction correctness and runtime efficiency. For all evaluations, the approximate query matching is turned off. The detailed description of the evaluation setup and experimental results are presented below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Prediction Accuracy</head><p>To construct the testing dataset for evaluation of the prediction accuracy, we randomly extract 5 queries from each graph, and obtain their groundtruth subgraph-isomorphism labels. The evaluation is conducted on the problem of subgraph decision and node alignment separately. For subgraph decision, we measure the precision and recall, commonly used in the information retrieval domain, to measure how well NeuroMatch retrieves the ground-truth matching target graphs from the graph database.</p><p>For node alignment, the objective is to measure how well the algorithm predicts the correct matching nodes on the retrieved target graphs. Since the wrong retrieval does not have ground-truth node alignment, we conduct the evaluation on the set of correctly retrieved target graphs. For this task, we compare our proposed NeuroAlign with NeuroMatch, which provides node correspondence through the matched anchor nodes. Greedy assignment (Section 3.6) is applied on both NeuroMatch and NeuroAlign to improve the inference. The details on utilizing the greedy assignment on NeuroMatch can be found in the appendix. To measure the performance, we calculate the top-k (k ∈ {1, 2, 3}) accuracy along with the accuracy after the greedy assignment on each query, and report the average among all queries. In case multiple matches exist in the ground truth, we only consider the one closest to algorithm prediction to measure the accuracy. The identification of multiple subgraph isomorphisms <ref type="bibr" target="#b41">[43]</ref> is a more challenging research topic and we provide a discussion in Section 6.</p><p>The performance of subgraph decision is shown in Table <ref type="table" target="#tab_0">1</ref>. The results show that the system is able to retrieve around 90% matching target graphs for both datasets while maintaining high precision. Note that achieving high precision is much more challenging than high recall since a matching target graph is rare as compared to non-matching graphs. The excellent precision and F1 score of the system demonstrate the model's capability to learn embeddings that correctly reflect the subgraph relationship.</p><p>The comparison between NeuroMatch and our proposed algorithm NeuroAlign on the node alignment task is shown in Table <ref type="table">2</ref>. Neuro-Match performed poorly on this task due to multiple predicted matches for many query nodes. We achieve significant improvement over Neuro-Match (e.g. 27.3% improvement on top-1 acc. and 22.2% improvement after assignment for Workflow, 18.7% improvement on top-1 acc. and 28.7% improvement after assignment for MSRC-21). We also observe that MSRC-21 is much more challenging than Workflow dataset due to the dense connectivity and a large number of similar adjacency nodes. Interestingly, although NeuroAlign makes many wrong decisions from the top-1 predictions, its top-3 predictions contain most labels. As a result, the simple assignment approach successfully resolves many predicted conflicts and significantly improves the accuracy. Contrarily the assignment does not make much improvement for NeuroMatch predictions. In addition, we experimented with the optimal Hungarian assignment algorithm and observe that, as compared to our greedy approach, the improvement is negligible for NeuroAlign, but higher for NeuroMatch (e.g. achieves 73.1% acc. on Workflow and 55.4% acc. on MSRC-21) due to more conflicting predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Runtime Efficiency</head><p>Next, we measure the runtime efficiency in comparison with the VF2 baseline <ref type="bibr" target="#b12">[14]</ref> to evaluate the speed gain. VF2 is the state-of-the-art exact matching algorithm based on backtracking procedure. Although it calculates true subgraph-isomorphism results, the computation is ex- Fig. <ref type="figure">9</ref>. Runtime comparison with VF2 <ref type="bibr" target="#b12">[14]</ref> and NeuroMatch <ref type="bibr" target="#b42">[44]</ref> on the Workflow dataset. Runtime in seconds is shown on the y-axis as logarithm scale and the exact number is above the bar. Compared to VF2, our system provides 10×-100× speedup starting from 10 query nodes and therefore enables interactive query. Our proposed NeuroAlign component adds little to none computational overhead as compared to NeuroMatch, while providing much more accurate node-alignment results.</p><p>pensive, especially for larger graphs. In addition, we also compare with a similar system where NeuroAlign component is removed to evaluate the added computational overhead of NeuroAlign. For this evaluation, we consider the number of query nodes ranging from 5 to 30 with an increment of 5 on the Workflow dataset, and randomly extract 2000 corresponding queries for each number. We measure the averaged runtime in seconds for the matching with the entire database. The results are visualized in Fig. <ref type="figure">9</ref>. We observe that the runtime of VF2 increases exponentially with the increase in query nodes and reaches close to 6 minutes with just 25 query nodes. With further increased query nodes they become larger than many target graphs and cannot be matched, thus creating a runtime drop at node size 30. In contrast, our runtime increases linearly with query node size. Compared to NeuroMatch, the added Neu-roAlign component induces little to none computational overhead. Surprisingly it is slightly faster than NeuroMatch in some cases. We conjecture this is due to the easier assignment task generated by NeuroAlign (i.e. fewer conflicts), such that the greedy algorithm can terminate early.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Expert Interview</head><p>To evaluate the usability of the system, we conducted a semi-structured interview involving three industrial experts working on program workflow construction and review for the first usage scenario, as well as three researchers working in the computer vision domain for the second usage scenario. We introduced the system with a walk-through of the interactive features and visual encodings and then explored the system together through a remote call. We report a brief summary of the findings here as an initial validation of the usability and utility of the system. For the first usage scenario, the domain experts considered the visual analytic system easy to understand and fits their current usage scenario very well: identifying reusable workflow modules to simplify future workflow creation. They can easily create new patterns and search for matching graphs in the database and validate the results in the visualization interface. They even proposed new usages such as using the visualization to review newly created workflows. One of them commented, "The abstraction and searching of custom queries open up a lot of opportunities". In addition, they requested that the returned workflows to be grouped by additional node features for fine-grained analysis. We are currently working with the experts to deploy the system for larger-scale use, and are expecting more feedback after long-term usage.</p><p>For the second usage scenario, the domain experts appreciated the usefulness of the system by commenting, "It's great to perform query so fast and see results interactively. It's certainly very powerful for many computer vision problems". They showed great interest in applying the system for diagnosing computer vision models to answer questions such as: does an object detection model performs worse when the object is placed on the road instead of in a room? One of them is interested in retrieving images containing similar semantic structure as some failure cases of the model to perform further analysis and model refinement. Another expert is interested in utilizing the tool for computer vision problems with a heavy focus on object relationships, such as image captioning and visual question answering. For improvement, they mentioned that the graph edge could encode additional information such as the relative positions (up, down, left, right) of the superpixels to retrieve similar images. In addition, a ranking of the matched images could be provided based on the closeness of visual appearance to the query image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION, LIMITATIONS AND FUTURE WORK</head><p>We introduced a novel system GraphQ to perform interactive visual pattern queries on graph databases based on user-created query patterns. To facilitate interactive query, we utilize graph representation learning to resolve the problem of subgraph decision and node alignment. The intuitive and explainable visual cues provided by NeuroAlign are paired with novel visual and interaction designs to help users navigate the retrieval results and extract insights. Due to the complexity of the subgraph matching problem, there are still many open questions we have not addressed yet:</p><p>Node alignment for multiple subgraph isomorphism. Currently, the training and inference of NeuroAlign focus on a single instance of subgraph isomorphism. However, in practice, the query nodes could be mapped to multiple sets of nodes in the same matching target graph.</p><p>Counting and enumerating all these instances is a very challenging problem and requires future research. Besides that, multiple pattern matches in a large graph bring additional challenges for interaction and scalable visual representations.</p><p>Scalability to very large query graphs. During training of Neuro-Match, we observe that hard negative samples are crucial to achieving high precision rate. However, sampled or perturbed queries need to be verified with exact matching algorithms to ensure the subgraph relationship does not exist. These algorithms are slow to compute especially when the query and target neighborhood graphs become larger and the connectivity becomes denser. A potential approach to alleviate the issue is to assign large weights to these hard negatives and reduce the overall need to invoke these algorithms during training.</p><p>Handling directed or disconnected query patterns. Currently, our algorithm works with using undirected, connected graphs as the query pattern. For directed graphs, we converted them into undirected graphs as input for NeuroMatch and NeuroAlign. To account for the direction of connectivity, the backbone GNN model needs to be modified. For example, GraphSAGE can be modified by distinguishing the in-node and out-node neighborhoods during the aggregate-update process and other GNNs specifically designed for directed graphs such as <ref type="bibr" target="#b59">[61,</ref><ref type="bibr" target="#b66">68]</ref> can be considered. On the other hand, for disconnected query patterns, a potential workaround is to consider each connected component separately and make an ensemble of the individual predictions. However, the performance still needs to be investigated.</p><p>In the future, besides addressing the aforementioned limitations, we plan to investigate database index applied on the embeddings of the large graph database to allow even more efficient retrieval at sub-linear time. Furthermore, considering the wide variety of graph-structured data, we plan to extend the current work to more usage scenarios including social network analysis <ref type="bibr" target="#b79">[81]</ref> and 3-D point clouds <ref type="bibr" target="#b48">[50]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Visual illustration of the subgraph matching problem. We color-encode the node categorical features of both graphs. The example query graph is subgraph-isomorphic to the target graph with the correct node alignment indicated by dashed lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. NeuroMatch determines whether G Q is a subgraph of G T by looking for local matches first and then aggregate the results. In this figure, we highlight the 1-hop local neighborhoods at anchor nodes b, c in the query graph as an example (in green and orange outlines). The NeuroMatch algorithm compares these 1-hop neighborhoods with those in the target graph. It finds that the 1-hop neighborhood graph of b is a subgraph of the 1-hop neighborhood of B (highlighted in green) and the neighborhood of c is a subgraph of the neighborhood of C (highlighted in orange). Since for each query node (a, b, c, d), we can find a matching 1-hop neighborhood graph in the target graph (A, B, C, D), the algorithm concludes that indeed G Q is a subgraph of G T .</figDesc><graphic coords="4,68.75,107.93,100.58,69.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. NeuroAlign algorithm obtains accurate node-to-node correspondence. It extracts the embeddings of each node in the query graph and the target graph by directly feeding them through GNN. It then uses an attention network to compare every pair of node embeddings between the query and target graphs. For the convenience of computation, these pair-wise comparison results are formed as a matrix. The rows correspond to query nodes and columns correspond to target nodes. The matrix is then transformed into a probability matrix through softmax on each row. A greedy assignment algorithm resolves potential conflicts (black outlined block) during inference (Section 3.6).</figDesc><graphic coords="4,310.07,104.21,104.60,66.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig.5. System architecture of GraphQ. The back-end precomputes and stores the graph representations to support efficient matching graph retrieval through the NeuroMatch algorithm. After the matching graphs are obtained, we use NeuroAlign to obtain accurate node-to-node correspondence to be displayed in the visualization for the user to verify the results. Users can start from an overview of all the graphs in the database and select one to construct example-based query pattern. The query pattern can be slightly perturbed to retrieve approximate matching results from the database. After the results are returned, the user can use a variety of views to explore the returned results.</figDesc><graphic coords="6,474.23,127.49,70.07,59.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Fig.6. The user selects a fan-like pattern (a). Exact subgraph matching returns 21 results (b). After enabling approximate search (Fig.1(4)), the back-end returns 172 graphs (d) containing fan-like patterns, although some of them are simpler than the query. The query results indicate that such structure can be reused as a template to reduce the manual effort for future workflow creation.</figDesc><graphic coords="7,258.23,192.29,103.92,102.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Case study 2, searching by brushing a subregion (a chain of sky, building, and road nodes) on the (MSRC-21) scene graph and find the matching results (b), most of which contain the same chain of such three nodes as in (a). The three nodes' relationship resembles a typical street view image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Subgraph decision performance using NeuroMatch.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Precision Recall</cell><cell>F1</cell></row><row><cell>Workflow</cell><cell>87.0</cell><cell>89.9</cell><cell>88.4</cell></row><row><cell>MSRC-21</cell><cell>83.6</cell><cell>91.6</cell><cell>87.4</cell></row><row><cell>COX2</cell><cell>87.4</cell><cell>90.9</cell><cell>89.1</cell></row><row><cell>Enzymes</cell><cell>81.8</cell><cell>73.0</cell><cell>77.1</cell></row><row><cell cols="4">diagnostic), MSRC-21 (image processing), COX2 (chemistry) and</cell></row><row><cell cols="4">Enzymes (biology). The workflow dataset contains ∼500 individual</cell></row><row><cell cols="4">workflow graphs with the number of nodes ranging from 5 to 150.</cell></row><row><cell cols="4">∼20 different types of nodes correspond to different diagnostic</cell></row><row><cell cols="4">procedures. MSRC-21 [62] contains natural scene images with 21</cell></row><row><cell cols="4">object semantic labels. After the super-pixel extraction and processing</cell></row><row><cell cols="4">steps as described in Section 5.2 and Fig. 7, the resulting graph dataset</cell></row><row><cell cols="4">includes 544 graphs with 11 to 31 nodes. COX2 [46, 66] consists of</cell></row><row><cell cols="4">467 chemical molecule graphs with the number of nodes ranging from</cell></row><row><cell cols="2">32 to 56. Enzymes dataset</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>Deepsnap</surname></persName>
		</author>
		<ptr target="https://github.com/snap-stanford/deepsnap" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neo4j bloom: Friendly graph visualization, exploration and collaboration tool</title>
		<ptr target="https://neo4j.com/product/bloom/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ddgk: Learning graph representations for deep divergence graph kernels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
				<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Control flow analysis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Allen</surname></persName>
		</author>
		<idno type="DOI">10.1145/800028.808479</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of a Symposium on Compiler Optimization</title>
				<meeting>a Symposium on Compiler Optimization<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="1970">1970</date>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Isomorphic subgraphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bachl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Graph Drawing</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="286" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Neural maximum common subgraph detection with guided subgraph extraction</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marinovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Gephi: an open source software for exploring and manipulating networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bastian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Heymann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jacomy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International AAAI Conference on Web and Social Media</title>
				<meeting>the International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The aesthetics of graph visualization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ryall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Spalteholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gooch</surname></persName>
		</author>
		<editor>CAe</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vogue: Towards a visual interaction-aware graph query processing framework</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Bhowmick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cidr. Citeseer</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">D3 data-driven documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2011.185</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011-12">Dec. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Interactive pattern search in time series</title>
		<author>
			<persName><forename type="first">P</forename><surname>Buono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Society for Optics and Photonics</title>
				<imprint>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">5669</biblScope>
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
	<note>Visualization and Data Analysis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Graphite: A visual query system for large graphs</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE International Conference on Data Mining Workshops</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="963" to="966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A (sub) graph isomorphism algorithm for matching large graphs</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Cordella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Foggia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sansone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1367" to="1372" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Ant design -an enterprise-class ui design language and react ui library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Design</surname></persName>
		</author>
		<ptr target="https://github.com/ant-design/ant-design" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A survey of graph layout problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Petit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Serna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="356" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Motif simplification: improving network visualization readability with fan, connector, and clique glyphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Dunne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3247" to="3256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">React -a javascript library for building user interfaces</title>
		<author>
			<persName><surname>Facebook</surname></persName>
		</author>
		<ptr target="https://github.com/facebook/react" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09621</idno>
		<title level="m">Deep graph matching consensus</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A visual analytics framework for contrastive network analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A technique for drawing directed graphs</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Gansner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Koutsofios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-P</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="214" to="230" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey of graph edit distance</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Analysis and applications</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="113" to="129" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Flask web development: developing web applications with python</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grinberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Exploring network structure, dynamics, and function using networkx</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hagberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Swart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chult</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Los Alamos, NM (United States</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Los Alamos National Lab.(LANL)</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluating the readability of force directed graph layouts: A deep learning approach</title>
		<author>
			<persName><forename type="first">H</forename><surname>Haleem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wadhwa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="40" to="53" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02216</idno>
		<title level="m">Inductive representation learning on large graphs</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Regal: Representation learning-based graph alignment</title>
		<author>
			<persName><forename type="first">M</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Safavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM international conference on information and knowledge management</title>
				<meeting>the 27th ACM international conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Nodetrix: a hybrid visualization of social networks</title>
		<author>
			<persName><forename type="first">N</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1302" to="1309" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Graph visualization and navigation in information visualization: A survey</title>
		<author>
			<persName><forename type="first">I</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Melanc ¸on</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="43" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interactive exploration of time series data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hochheiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Craft of Information Visualization</title>
				<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="313" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dynamic query tools for time series data sets: timebox widgets for interactive exploration</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hochheiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Efficient, high-quality force-directed graph drawing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematica journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="71" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Forceatlas2, a continuous graph layout algorithm for handy network visualization designed for the gephi software</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jacomy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Venturini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Heymann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bastian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">e98679</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A survey on knowledge graphs: Representation, acquisition and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marttinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.00388</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Image retrieval using scene graphs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3668" to="3678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">What would a graph look like in this layout? a machine learning approach to large graph visualization</title>
		<author>
			<persName><forename type="first">O.-H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Crnovrsanin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="478" to="488" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A deep generative model for graph layout</title>
		<author>
			<persName><forename type="first">O.-H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="665" to="675" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Task taxonomy for graph visualization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Parr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 AVI workshop on BEyond time and errors: novel evaluation methods for information visualization</title>
				<meeting>the 2006 AVI workshop on BEyond time and errors: novel evaluation methods for information visualization</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Peax: Interactive visual pattern search in sequential data using unsupervised deep representation learning</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lekschas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Haehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gehlenborg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.13971</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="167" to="179" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Graph matching networks for learning the similarity of graph structured objects</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dullien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="3835" to="3845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural subgraph isomorphism counting</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1959" to="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Canedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.03092</idno>
		<title level="m">Neural subgraph matching</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Deep graph similarity learning: A survey</title>
		<author>
			<persName><forename type="first">G</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Willke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11615</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Tudataset: A collection of benchmark datasets for learning with graphs</title>
		<author>
			<persName><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Bause</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mutzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2020 Workshop on Graph Representation Learning and Beyond</title>
				<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Algorithms for the assignment and transportation problems</title>
		<author>
			<persName><forename type="first">J</forename><surname>Munkres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the society for industrial and applied mathematics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="38" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Propagation kernels: efficient graph kernels from propagated information</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bauckhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
				<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="209" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Propagation kernels: efficient graph kernels from propagated information</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bauckhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="245" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Graph kernels for object category prediction in task-dependent robot grasping</title>
		<author>
			<persName><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Antanas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Online Proceedings of the Eleventh Workshop on Mining and Learning with Graphs</title>
				<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="0" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The state of the art in visualizing multivariate networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nobre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="807" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Balancing systematic and flexible exploration of social networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="693" to="700" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Vigor: interactive visual exploration of graph query results</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pienta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamersoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roundy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Navathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="215" to="225" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Visage: Interactive visual graph querying</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pienta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tamersoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Navathe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Working Conference on Advanced Visual Interfaces</title>
				<meeting>the International Working Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="272" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Integrating prior knowledge in mixed-initiative social network clustering</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Buono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Valdivia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Tasks for multivariate network analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pretorius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Purchase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multivariate Network Visualization</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="77" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Brenda, the enzyme database: updates and major new developments</title>
		<author>
			<persName><forename type="first">I</forename><surname>Schomburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ebeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gremse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Heldt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Huhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schomburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="D431" to="D433" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>suppl 1</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Structured query-based image retrieval using scene graphs</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tripathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="178" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Gramme: Semisupervised learning using multilayered graph attention models</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">S</forename><surname>Shanthamallu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Thiagarajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Spanias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3977" to="3988" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Skeleton-based action recognition with directed graph neural networks</title>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="7912" to="7921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Graphiti: Interactive specification of attribute-based edges for network modeling and visualization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Basole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="226" to="235" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Visualization support for managing large business process specifications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Business Process Management</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="205" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1205.6691</idno>
		<title level="m">Efficient subgraph matching on billion node graphs</title>
				<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Spline-fitting with a genetic algorithm: A method for developing classification structureactivity relationships</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Weaver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical information and computer sciences</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1906" to="1915" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Fisheye tree views and lenses for graph visualization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Tominski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Abello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Van</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth International Conference on Information Visualisation (IV&apos;06)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Rosenblum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13970</idno>
		<title level="m">Directed graph convolutional network</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Introduction to Graph Theory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Trudeau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Dover Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">An algorithm for subgraph isomorphism</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Ullmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="42" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Reducing snapshots to points: A visual analytics approach to dynamic network exploration</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Den Elzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Holten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blaas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Multivariate network exploration and presentation: From detail to overview via selections and aggregations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Van Den Elzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2310" to="2319" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Quick shift and kernel methods for mode seeking</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="705" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Visualizing group structures in graphs: A survey</title>
		<author>
			<persName><forename type="first">C</forename><surname>Vehlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="201" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Deepdrawing: A deep learning approach to graph drawing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="676" to="686" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Social network analysis: Methods and applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wasserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Faust</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Sketching a graph to query a time-series database</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<idno type="DOI">10.1145/634067.634292</idno>
	</analytic>
	<monogr>
		<title level="m">CHI &apos;01 Extended Abstracts on Human Factors in Computing Systems, CHI EA &apos;01</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="381" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00826</idno>
		<title level="m">How powerful are graph neural networks? arXiv preprint</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName><forename type="first">P</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
				<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Image-to-image retrieval by learning similarity between scene graphs</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E.-S</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.14700</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Context-aware sampling of large networks via graph representation learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
