<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GenNI: Human-AI Collaboration for Data-Backed Text Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hendrik</forename><surname>Strobelt</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jambay</forename><surname>Kinley</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Krueger</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Johanna</forename><surname>Beyer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
						</author>
						<title level="a" type="main">GenNI: Human-AI Collaboration for Data-Backed Text Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EF0544D16098D3532E36F702CB567F64</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T14:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tabular Data</term>
					<term>Text/Document Data</term>
					<term>Machine Learning, Statistics, Modelling, and Simulation Applications</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Fig. 1. GenNI's forecast-refine loop applied to an example of a table2text model for generating restaurant descriptions of different forms. The right side shows the Generation Forecast Component with examples of unconstrained generation. The left side shows the Constraint Refinement Component with the construction of a potential new constraint graph.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Artificial intelligence methods for text generation are becoming increasingly advanced, with systems demonstrating convincing output in many surprising domains such as news and story generation. Machine learning based systems can learn how to generate text from seeing a massive amount of examples of human writing and interaction in the wild <ref type="bibr" target="#b44">[45]</ref>. Underlying the systems are large models that process textual input and learn how to mimic the word-use, syntax, and high-level knowledge for generic generation. These tools can also be adapted to environments where they are tasked with generating specific conditioned textual outputs. For instance, in this work, we consider the problem of generated textual description of structured data, i.e., the Table2Text setting.</p><p>However, the ability to generate fluent output is often not sufficient for real-use cases. Many settings that use textual generation, such as user assistants (e.g., tools like Alexa) or automated response and search, require systems that can generate specific responses in a highprecision manner. Generic free generation systems cannot directly be deployed in these scenarios since they often "go off-script" and generate information that is not supported by their conditioning <ref type="bibr" target="#b59">[60]</ref>. It is a non-trivial challenge to ensure that these systems stick to a specific type of conditioned generation, even when a user clearly knows the goals and targets of the system. Given this issue, many approaches use human-crafted rule-based systems as opposed to machine learning.</p><p>GenNI is a prototype and a framework that facilitates Human-AI collaboration for the challenging domain of data-backed text generation with machine learning systems. The goal is to achieve the benefits of ML based generation, while ensuring the precision of human crafted control by using visual means. GenNI supports three targeted aspects of the collaboration process:</p><p>• Refinement of Model Constraints GenNI allows users to impose model constraints that ensure specific high-level properties hold during generation.</p><p>• Forecasting of Model Outputs GenNI makes it easy to see how these constraints affect real generation examples across a representative range of inputs.</p><p>• Deployable Model Corrections The GenNI prototype utilizes a rigorous constraint-graph method that makes it easy to view the model update and utilize it in production use cases.</p><p>The system design is based on the collaborative framework of Gehrmann et al. <ref type="bibr" target="#b15">[16]</ref>, who argue that it is critical to design ML systems that take the end-user user control scenario into account during the model design process. GenNI incorporates a controlled text generation model trained to interact with human users through explicit control states. The tool facilitates an interactive and visual negotiation where a human user refines the set of possible generations through a constraint graph and then explores the system's actual outputs through a global forecasting procedure. The tool allows the user to cycle through concrete examples to build up the constraint graph as they go.</p><p>In Sect. 2 we introduce controllable text generation formally, describing the model and modes of user interaction. We then provide in Sect. 3 a guiding example for how a user might use the interactive tool for table2text description. Sect. 4 introduces the goals and tasks required for building the prototype called GenNI for data-backed generation through Human-AI collaboration. Sect. 5 presents the design decisions made to follow these guidelines and Sect. 7 describes the implementation details of the tool. Further use cases for GenNI are given in Sect. 6. Sect. 8 reviews the related work in this research domain to provide some context for our work. We conclude the paper in Sect. 9 by outlining ideas for future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MODEL: TABLE2TEXT WITH CONTROLS</head><p>Underlying GenNI is a model designed for controllable text generation to enable visual interaction. The model extends standard ML models for text generation with explicit control states (i.e., discrete latent variables) that allow an end-user to alter the model's output through constraints. Additionally, given an input and output, the model provides a method for inferring the control states. These control states are the main interface used by GenNI.</p><p>Table2Text generation aims to produce a textual description consisting of word tokens y 1:T from an input of data x represented as a table. While one could generate this description directly from the data, we distinguish controllable systems as ones that provide intermediate control states for directing the structure of the description. We use one control state for each word, z 1:T , that are generic discrete values from a small label set, for example, represented as letters A to Z. Each control state corresponds to a high-level cluster of the corresponding word's semantics learned by the model for the problem. An underlying assumption of this work is that an end-user can craft higher-level constraints with these states than by acting directly on words.</p><p>Formally, the model outputs control states and one word at a time. Starting from data x, the model generates the description y autoregressively (left-to-right) by first generating a state z and then the corresponding word.</p><formula xml:id="formula_0">z 1 ∼ p(z 1 | x) y 1 ∼ p(z 1 | x, z 1 ) z 2 ∼ p(z 2 | x, z 1 , y 1 ) y 2 ∼ p(y 2 | x, z 1 , y 1 , z 2 )</formula><p>. . . This process produces the probability of the description and states given the data p(y, z|x). Each part is implemented using a deep learning model. We utilize a recurrent neural network to predict both the z and y outputs and an attention based encoder to condition on the input x. Specifically the probabilities are given as:</p><formula xml:id="formula_1">p(z t |z &lt;t , y &lt;t ) = softmax(W 0 h(x, y &lt;t , z &lt;t )) (1) p(y t |z ≤t , y &lt;t ) = softmax(W 1 [h(x, y &lt;t , z &lt;t ) + g(z t )])<label>(2)</label></formula><p>where h is the output of a recurrent neural network over the input, previous words, and control states, W are parameters, and g is a function of the current control state.</p><p>A key aspect of the system will be the reverse process, i.e. inferring control states z from examples tables and sentences x, y . Unfortunately, the posterior distribution p(z|x, y) is intractable to compute exactly. We therefore employ variational inference to approximate this distribution using a parameterized inference network q(z|x, y). We train this approximation jointly with the forward model in the standard variational autoencoder framework <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b49">50]</ref>.</p><p>For the inference network, we use a linear-chain conditional random field (CRF) with a neural parameterization. This family of distributions is particularly suited for labeling segments of the text with control states, and has been used effectively in similar tasks <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b32">33]</ref>. To train this part of the system, we use the Gumbel-CRF method proposed by Fu et al. <ref type="bibr" target="#b13">[14]</ref> which allows us both to learn the variational approximation and also train the rest of the model with concrete control states.</p><p>Finally, during training we enforce a soft correspondence between control states and table properties. These constraints enforce weak supervision in the form of a heuristic alignment between data and text, i.e. whether some part of the sentence is describing a table field using identical text as in the table. Following Li et al. <ref type="bibr" target="#b32">[33]</ref>, we use a technique known as posterior regularization which allows the model to follow or ignore these alignments. We find this can produce more human-legible control states for some of our tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model Interaction</head><p>Directly visualizing deep learning models is challenging <ref type="bibr" target="#b19">[20]</ref>. Instead of visualizing the internals of the model, we interact with it through its outputs and control states through three distinct modes shown in Fig. <ref type="figure">2:</ref> (M1) free generation where the model searches for the most likely textual output given the input data; (M2) controlled generation where the model searches for an output that obeys a constraint graph; (M3) inferred control a reversed version of generation, where the user provides a goal text, and the control states are inferred. These three modes will act as the building blocks for the interactive system. Free Generation (M1): The most basic operation is to allow the AI model to generate freely. This mode produces the highest-scoring output from the model, formally arg max y,z p(y, z|x). Note, though, that high scores from the model often do not correspond to generated text that a human user would have wanted.</p><p>Practically, computing this argmax is a search problem over a very large search space. It is common to utilize an algorithm known as beam search as an approximation. Beam search works by exploring the search tree using a fixed number of hypotheses per time step, i.e., considering five different hypothesis sentences of t words long before moving on to five different hypothesis sentences of t + 1 words. We can extend the beam search for controlled generation to alternate between exploring the best succeeding control state and the best next word. This search is shown in Fig. <ref type="figure">2 (top)</ref>. Controlled Generation (M2): An alternative to free generation of the output text is to control the generation to fit specific cases of an enduser application. For this mode, the user provides an explicit constraint graph to the model. These constraints are applied to the control states z, which act to restrict the word outputs y. For controlled generation, we solve arg max y,z∈Z p(y, z|x) where Z is the constrained set of possible outputs.</p><p>Formally, the constraint graph is equivalent to a regular expression on control states restricting the set Z. Regular expressions allow a user to encode complex sets for shaping the space of possible outputs. To leverage this control, we use a constrained beam search algorithm where the constraint graph ensures that z is correct for the model output (Fig. <ref type="figure">2</ref> (middle)). For instance, given the constraint A.B*, during generation, we ensure that the control state of the first word is A, the second is unconstrained ., and the remaining words must have control state B.</p><p>It is important to note that these constraints do not directly constrain the words generated y. Each control state can generate many possible words. This can be seen in Fig. <ref type="figure" target="#fig_4">6</ref> (g) where, given a control state, the model has options over the word to generate. Inferred Control (M3): As described above, the system is trained to also allow for reverse computation of control states, using an inference network. This mode allows for the inferred control where the user can write an expected output sentence, and the model will produce plausible control states arg max z p(z | x, y). While generation allows us to infer output given an input, this term allows us to find the control states for a human written input and output (Fig. <ref type="figure">2</ref> (bottom)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATING CASE STUDY: COLLABORATIVE GENERATION</head><p>We now consider a motivating case study of human-AI collaboration for text generation in GenNI. Alice is a user building an ML-based chatbot system. She is designing a module that generates a restaurant description from a table <ref type="bibr" target="#b42">[43]</ref> such as the following: name eat type food area near the phoenix pub french city center cafe sicilia Alice first tried developing a system using free generation (M1) but found that the generated text is highly variable and does not suit her specific use case, which requires high precision constraints. In particular, Alice wants the system to focus exclusively on the cuisine (food) and the type of establishment (eat type). However, she found that, under free generation, the model would use all of the fields, e.g., generating: the phoenix is a french pub near cafe sicilia in the city centre . To benefit from our controllable system, Alice needs to provide specific constraints on the control states to produce high-precision outputs that fulfill her specified goals. Concretely, she will want to develop a constraint graph that ensures that her system outputs are correct. We describe her use of GenNI to achieve this goal.</p><p>Step 1: Observing Control States on an Example To begin to gain intuition into model prediction and the control states, Alice starts with a specific example input x, e.g., the table row shown above. GenNI produces text in free model generation (M1) while also showing the control states for each word token -Fig. <ref type="figure" target="#fig_0">3a</ref>.</p><p>This step grounds the collaboration process in a specific starting point. This visual representation maps concrete textual outputs to the underlying control states. For this example, Alice infers that the model has allocated the blue state for the restaurant name, red for food type, and cyan for location.</p><p>Step 2: Inferring Control States for Manual Output Next, Alice can actively posit a counterfactual: "What would the control states have been for a user-generated target output?" To do this, Alice can provide her own textual description ("the phoenix is a french pub .") to the system in the form of the sequence y 1:T . Utilizing the model's inference mode (M3), the model will infer the control states that would have most likely lead to that output -Fig. <ref type="figure" target="#fig_0">3b</ref>.</p><p>This step is the start of the refinement procedure that allows Alice to build up a constraint graph on the model itself. Specifically, if she is happy with the control states that the model assigned, she can add this sequence of control states to the constraint graph. This refinement tells GenNI that this sequence of control states is appropriate for the AI model to generate.</p><p>Step 3: Forecasting AI Generations Under Constraints The constraint graph allows Alice to ensure that the model generates outputs from a set of acceptable control state sequences. However, it can be difficult to tell how constraints will generalize across examples. GenNI allows users to do this through forecasting, applying controlled generation (M2) across a set of different diverse inputs. In this case, GenNI allows Alice to randomly sample different inputs with different properties to observe generations from the system or, alternatively, probe a range of targeted inputs -Fig. <ref type="figure" target="#fig_0">3c</ref>.</p><p>Alice can then view all these outputs simultaneously to observe patterns and relationships. She confirms her hypothesis about the control states for the restaurant name (blue) and food type (red). The forecasting feature of GenNI makes it easy for her to see specific regions where the AI failed to generate the correct output.</p><p>Step 4: Precision Refinement of Constraints: The set of control states obtained in Step 2 can be applied as a constraint for other inputs (see Step 3). However, this constraint is specific to the input used to obtain it and may not generalize well. Alice can use a regular expression editor to refine the constraint so that it may generalize better.</p><p>When browsing through the forecast results, Alice spots a particular problem. The model copies the establishment name "strada" twice from the input and also fantasizes a food type -Fig. <ref type="figure" target="#fig_3">4a</ref>.</p><p>Alice knows from her exploration that the blue control state instructs the model to copy the establishment name. However, her current constraint is too rigid, since some restaurants like "strada" are only a single word (vs. "the phoenix"). Similarly, some tables do not reveal the food type. By switching to this example and correcting (using step 2) for the repetition, Alice can include the corrected sequence of control states into the constraint graph to allow for both outputs -Fig. <ref type="figure" target="#fig_3">4b</ref>.</p><p>Alternatively, using the constraint editor, Alice can manually replace the sequence of two blue boxes to a variable length repeat of blue boxes and make the red box optional -Fig. <ref type="figure" target="#fig_3">4c</ref>.</p><p>After applying the newly created constraint, she can forecast again and confirm that the issue has been fixed -Fig. <ref type="figure" target="#fig_3">4d</ref>.</p><p>Step 5: Building Constraints into a Model: Alice can repeat this process of forecasting and refinement to obtain a constraint that generalizes well. She repeats Steps 1-4, each time alternating between observing generation, inferring control states for custom outputs, transferring across input types, and merging constraints. In each iteration, the constraint graph grows with the addition of more rules. Finally, Alice can save the constraints to use the constrained model on a more extensive test set and in production.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GOALS, TASKS AND USER GROUPS</head><p>GenNI aims to support the collaborative development of data-backed generation systems. AI tools for generation can efficiently produce textual outputs on a variety of inputs; however, without close inspection of these free generations, it is difficult for a human user to find issues or correct errors. Alternatively, human users can produce careful example outputs, but each is slowly crafted and hard to generalize.</p><p>At each alternating round of GenNI's use, either the user can formulate explicit constraints on the AI system, or the AI system can generate a set of outputs based on its current state. In this manner, the user can quickly observe that the system is over-constrained or under-constrained while at the same time having assistance from the AI system to help produce generalizable constraints. When the collaboration is over and both sides reach an equilibrium, the full set of constraints produced in the process can be incorporated into the AI system.</p><p>To act as a tool for reaching this human-AI equilibrium for constraints, GenNI was designed with three high-level user goals in mind (Fig. <ref type="figure">5</ref>): G1: Ensure controlled generation AI systems with free generation can produce unexpected outputs which do not follow the guidelines that the user prefers. The goal is to provide feedback controls in the form of constraints. The language of control states may be difficult for a user to apply directly, so the tool must convey how these work and make it easy for the user to link these to specific examples. Once constraints are created, a user needs to be able to manipulate the constraints in an intuitive and precise manner. G2: Demonstrate model constraint generalization Upon specifying constraints, the user needs to understand how the AI will apply and interpret them in a global manner. While the user may have an intuitive sense of the constraints, they will not know whether they will act consistently and naturally across any input the AI receives. As such, a tool needs to provide guidance about general outputs such that a user can build intuition and trust the system. G3: Deploy as a controlled Human-AI system Many approaches for debugging neural models find issues but do not provide a path for remediation. The final goal of GenNI is to produce a constraint set that can be packaged and deployed as part of a production model. The constructed constraint graph contains all of the final information about the appropriate controlled use of the system, and controlled generation can be efficiently run on real systems. After deployment, if an issue comes up in production use, new constraints can be refined into the model.</p><p>The case study in Sect. 3 takes advantage of these goals. The user is interested in the targeted use of the generation system in Step 1.</p><p>Step 2 is a step towards defining constraints based on the user goals (G1). These constraints need to be explored on a larger set of examples (G2) in Step 3. However, upon observation, further refinement is needed in step 4 (return to G1). Finally, the negotiation leads to a model in Step 5 that can be deployed in a production system (G3).</p><p>These three domain goals motivate the main interaction and tasks of the system: Task 1: Browse and Modify AI Generations by observing the textual output y and control states z for possible inputs x. The user should be able to modify outputs manually or by using alternative model Export controlled model (T5) Fig. <ref type="figure">5</ref>. Overview of GenNI domain goals, interaction tasks, and addressed user groups. GenNI aims at supporting goals for working with control state models: (G1) ensuring controlled generation, (G2) evaluating these constraints on subsets of relevant data and demonstrate model constraint generalization, and (G3) deploying the outcome as a controlled Human-AI system. From these high-level goals, a series of interaction tasks (middle part) is inferred. These tasks are the building blocks for the main interaction loop of forecasting constraint effects and refining constraints as a result. GenNI targets end-users and model architects alike for most tasks (right). (see Sect. GenNI targets two user groups (see <ref type="bibr" target="#b54">[55]</ref>). One group is a technically versed end-user that does not need to know about the underlying model, just about the task at hand. We call this group technical editors. The other group is model architects that want to evaluate their model under real human constraints. See Fig. <ref type="figure">5</ref> for reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DESIGN</head><p>GenNI is an interactive prototype for facilitating collaborative interaction for controlled generation. The visual layout and the interactions are the results of an iterative design process between visualization experts, NLP researchers developing controllable models, and users aiming to deploy these models in practice.</p><p>The GenNI interface is constructed out of two meta components that immediately reflect the domain goals G1 and G2. These components are juxtaposed to facilitate the continuous iteration between forecasting constraints on global examples and refining the constraint as a result of observing global effects. Accordingly, the left half collects Refine Constraint views. (Sect. 5.1) The right half provides Generation Forecast views. (Sect. 5.2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Constraint Refinement Component</head><p>The Constraint Refinement component (Fig. <ref type="figure" target="#fig_4">6a</ref>) facilitates the construction and exploration of constraints by the user (G1). It allows direct editing of constraints and constructing constraints from wellcrafted examples. This component has three supporting views: 1) a Constraint Editor (6c) which allows direct textual and visual modification of constraints, 2) a Refine-by-Example (6d) view to collect and utilize examples for constraint refinement, 3a) an Example Creation view (6e) to construct output examples by manual edits (6f), and 3b) to generate examples utilizing alternative model decisions (6g).</p><p>The Constraint Editor (Fig. <ref type="figure" target="#fig_4">6c</ref>) encodes the entire collaborative state of the system, i.e., all information collected to constrain the generation procedure. A user can add multiple different valid control state sequences, and they will be merged into this graph [T2]. The constraint graph is represented in two ways. First, it is encoded as an editable node-link diagram. The user can modify and update the constraint by visually adding, deleting, and modifying nodes and metanodes (like OR) [T3]. Secondly, the constraint graph is represented by a simple language borrowing the syntax from regular expressions. At the top of the Constraint Editor, this textual representation can be modified directly [T3]. For keeping track of provenance, a history field collects previous iterations of constraint formulations in textual form. On click, they are available for re-editing.</p><p>To develop new constraints from user preferred examples, the user needs a place to collect examples and merge them into complex constraints. The Refine-by-Examples view (Fig. <ref type="figure" target="#fig_4">6d</ref>) provides these functions. Each example represents y as text and z as a color. Their origin (i.e., human-generated or model alternative) is encoded as a postfix symbol (Fig. <ref type="figure" target="#fig_4">6d1</ref>) followed by buttons to trigger propagation to the Constraint Editor [T2] or forecasting in the Global Forecast view [T4] (see Fig. <ref type="figure" target="#fig_4">6h</ref>). If multiple examples are selected, the Merge Constraints button attempts to merge all of them into one combined constraint graph for the Constraint Editor [T2].</p><p>Examples are created by using the Example Creation view [T1] (Fig. <ref type="figure" target="#fig_4">6e</ref>). The user starts by first setting a reference input x. This input can be acquired by selecting an input ID to point to one item in the Examples can be created (e) by inferring control states from a user output (f) or from the model's beam tree (g). The effect of specific constraints can be forecast on random samples (h) or tested on data ranges (i). The controlled model code can be exported for deployment or further testing (j). Model architects can investigate the control state alignments for each control state (k). Details are given in Sect. 5.</p><p>model's test set directly or randomly. Alternatively, examples can be selected from the Global Forecast view.</p><p>To produce a matching output, the user can write a custom freehand text y (Manual Output, Fig. <ref type="figure" target="#fig_4">6f</ref>) and derive the matching control states z from the inference network (M3) of the model.</p><p>A second way to produce outputs is by meaningfully interacting with the model internals to modify its predictions (6g). The user can create these alternative model outputs by constraining the beam tree (lower part) from the visual tree representation or by selecting alternative tokens by clicking on a token. The beam tree tool allows the user to see the paths taken by the model during beam search, probe its decisions at specific locations and even alter its decisions (when choosing the control state) to see in real-time the effect of changes to the constraint graph. While this view might be complex for the end-user group, it provides a way to generate outputs that the model can reproduce.</p><p>In both cases, the control states sequence of the produced outputs defines a simple constraint and can be tested by forecasting it, or it can be added to the Refine-by-Example collection to create a new constraint graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Generation Forecast Component</head><p>The right-hand component of the GenNI ( Fig. <ref type="figure" target="#fig_4">6b</ref>) visualizes the model's response to the constraints. It presents a global insight into the AI system by providing either free or controlled generation on a more extensive set of examples [T4].</p><p>The Global Forecast view ( Fig. <ref type="figure" target="#fig_4">6h</ref>) conveys a global perspective on The Range Forecast view ( Fig. <ref type="figure" target="#fig_4">6i</ref>) provides the same features like the Global Forecast view, but the x values are selected from value ranges or lists of values. This allows more systematic testing in a local neighborhood of examples. E.g., for the use case of producing date strings (see Sect. 6), a user could test which influence the day value has by producing x and generations for all days of a specific month.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Encodings</head><p>The concept of a control state is central to the functioning of the collaboration and provides a shared space between the human user and the underlying AI system. All constraints are developed on these states, and they are the single unit of transfer between the two views (see Fig. <ref type="figure" target="#fig_4">6</ref>). As such, GenNI uses a visual encoding of control states as colors in all locations, both in the constraint formulation and the evaluation side. Unlike words, which are very fine-grained, control states allow for a high-level color encoding. This visual encoding makes it easier for a user to see differences and anomalies in sequences quickly.</p><p>The use of color as a central encoding poses some design challenges. Legibility is drastically decreased if the contrast between background and text color is low. That restricts the use of colors to either very dark or very light palettes. To be less restricted in color choices, we changed our encoding for the combination of y and z from full background coloring to only color underlines. Only in the very space-limited beam tree view, we use color bleeding.</p><p>Since color encoding is a core part of our prototype, we also thought about methods to support two scenarios where the color encoding might not be sufficient: 1) when modifying the constraint graph by textual input, the user has to refer to the colors in a meaningful way; 2) our color choices are not colorblind-safe. To address these issues, we added an optional representation of control states as letters. On click, the user can reveal the letters for single generation tuples. See Fig. <ref type="figure" target="#fig_5">7</ref>.</p><p>The selection and arrangement of all functional parts of the GenNI interface underwent many iterations. E.g., during the experimentation phase, all views were organized as rows to a single vertical list. The idea of juxtaposing Constraint Definition and Generation Forecast and arranging the subviews to support this bifold character results from understanding the interplay between forecast and refinement as a forthand-back loop and not as a strict sequential order first-a-then-b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">USE CASES</head><p>We apply the GenNI prototype to build controllable generation systems for two different domains. In both cases, a model architect utilized the system and explored the insights it gives for the problem and the underlying model. First, we build a model for a date conversion problem, where the model is simple enough such that all constraints can be explored. Next, we apply it to a real-world system using the E2E restaurant recommendation dataset <ref type="bibr" target="#b42">[43]</ref>. Date Generation The first model is a synthetic date generation dataset where the input x is a table representing a date consisting of (day, month, year). The corresponding output text is a sentence y describing the date. Eight different formats of representing the same date data were created using nominal or ordinal days, changing the order of day and month, and deciding to use commas or not before the year. For example, consider the input:</p><formula xml:id="formula_2">day month year 14 9 2015</formula><p>This date can be generated as "today is the fourteenth of september, 2015 ." o r " today is september the fourteenth in the year 2015 ." as well as six other formats. Model control is used to select the preferred output form, e.g., the ordering of the days and months, use of commas, and ordinal vs. numerical ways of writing the day.</p><p>Under this well-specified task, the goal is to test if GenNI allows for reasonable clusters of words for the control states. We also want to see if we can construct constraint graphs for formats that generalize as expected. In particular, the text format allows for variable day lengths, so the constraint graph must allow for this output. GenNI provides tools for performing these tests through interactions with the AI system.</p><p>Using the Forecast Generation component for free generation [T1], we can confirm from Fig. <ref type="figure" target="#fig_6">8a</ref> that the model has learned reasonable clusters for the control states. We can see that the model uses red for year, purple for month, yellow for ordinal day, light blue for nominal day, and so on. This view confirms the model structure is correct and that the system will alternate between different styles of generation.</p><p>Furthermore, the Example Creation view in Fig. <ref type="figure" target="#fig_6">8b</ref> shows us that the control states inferred by the model [T2] also agree with the clustering a b a s s s Fig. <ref type="figure">9</ref>. Final constraint graph produced in the Restaurant use case. Section (a) ensures generation of a location either in the order (area, near) or (near, area). Section (b) forces the use of family-friendly allowing an optional state for not. Section (s) is the seed that allows for additional descriptive information. Fig. <ref type="figure">10</ref>. Alignment between control states, table field and text. Cyan is the control state for area. Orange for the near. observed. (Anecdotally, in early testing, the model architect was able to find an error in the model implementation based on the interaction mode through this process.)</p><p>Finally, the Constraint Graph view can be used to enforce that output text obeys a specified format. We consider the constraining to the format "the date is september the fourteenth, 2015 .". Note, that the yellow state has been edited to add a repeat loop allowing for variable length (in practice, one or two) day output text. See Fig. <ref type="figure" target="#fig_6">8c</ref>. Restaurant Recommendation For more complex use-cases, we turn to the problem of refining text for an assistive agent or bot. The E2E dataset <ref type="bibr" target="#b42">[43]</ref> is a standard data set designed for benchmarking Table2Text generation systems to simulate conversational responses in a constrained environment. Here the input x is a table containing information about a restaurant (subset of eight different possible fields). The corresponding sentence y is a description of the data table x.</p><p>For this use case, we assume the challenge is to constrain the output to highlight the location of the restaurant and whether it is familyfriendly. There are several challenges that make this difficult. In the beginning, we do not know the right alignments between the control states and the relevant table fields. We also need to allow for different possible orderings of these fields. Additionally, we do not know how fields like family-friendly with yes,no values that cannot be copied directly are described.</p><p>Let us start with the location of the restaurant. There are two table fields area and near related to location and we would like to include both of them. Using the Control States (see Fig. <ref type="figure">10</ref>) section of the Generation Forecast view we can determine how these fields are used. This section shows overall alignment between control states, table fields (inputs) and text (output). We can see that the model uses cyan (A) control states for area, outputting words such as city and riverside from this state, and orange (G) control states for near. We can now ensure that these fields are both used. We observe that location fields can appear in either order -(area, near) or (near, area). We encode this in a constraint graph shown in Fig. <ref type="figure">9a</ref>. The (a) section of this graph ensures that some descriptive text comes first (seed s), and then the model can fork to generate the location in either order. Upon constructing this section of the graph, we can check that this constrained generation is looking correct. The generation results in Fig. <ref type="figure" target="#fig_7">11</ref> show that the generation with constraints works as expected, producing initial text followed by full location descriptions such as near raja indian cuisine in the city centre.</p><p>However, this constraint graph does not yet ensure that the text mentions whether the restaurant is family-friendly. To first determine how the system might encode this property, we use the Manual Output tool in the Refine Constraints section. Ignoring the rest of the text, we manually type out the phrases it is family friendly . and it is not family friendly .. The system then finds the best control states for each of the input tokens. In this case, the system produces the same control states for family friendly but differs in the not state. We can then combine these two control paths using the Refine by Examples tool. This effectively creates an optional not state in the graph, allowing both possibilities.</p><p>Finally, we combine this section (b) into the full constraint graph in Fig. <ref type="figure">9</ref>. Together this ensures we have both the location and the description of family friendliness. We can ensure this works using the Range Forecast tool. This tool allows us to generate a range of possible input tables to test the output text. The outputs in Fig. <ref type="figure" target="#fig_8">12</ref> for yes and no values for the family friendly table field shows that our constraint works well in both cases and even generates text in a different manner (kid friendly) than our manual input.</p><p>GenNI requires interaction with a live model designed to facilitate interactive visualization and refinement. To support this, it uses tight integration of a model with the visual client. We based the interface between both parts on a REST API, and we used a custom generation system for the underlying model framework using Torch-Struct <ref type="bibr" target="#b50">[51]</ref>. We designed an API to allow easy access of free generations, controlled generation, inferred control, and interaction with the model's beam tree. Both the backend and frontend communicate constraints only through the z control states that form the central white-box component of the model.</p><p>The model framework works within a FastAPI server to deliver content via a REST interface to the client. The client is written in Typescript. Most visualization components are using the d3js library. Source code, a demo instance, and a descriptive webpage are available at https://genni.vizhub.ai.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Table2Text Generation Models</head><p>Methods for table2text generation are commonly divided into rulebased approaches, statistical methods, and neural models. Rule-based approaches merge domain knowledge into the text generation systems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b48">49]</ref>. The domain knowledge can be encoded using hand crafted templates that map the data directly to language <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b56">57]</ref> or through rule-based transformations of semantic representations to produce the output text <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref>. Some systems combine templatebased methods with standard rule-based approaches <ref type="bibr" target="#b2">[3]</ref>. Our system does not use manual rule-based approaches; however, the learned control states are reminiscent of templates since the codes learn to align with specific characteristics of the text output. In this way, our approach has some similarities to statistical approaches that learn rules from training data <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b30">31]</ref>. Dou et al. <ref type="bibr" target="#b10">[11]</ref> built a model called Data2Text Studio for automated text generation from structured data by extracting templates. Like our system, it provides the user tools to edit templates for models and APIs to generate text. However, our system uses a neural model and also constructs constraint graphs rather than hard-coded templates.</p><p>As with most tasks involving language modeling, neural network models have become popular in conditional text generation. These models have provided significant improvements in performance as compared to rule-based and statistical models. The most popular models are seq2seq models that use recurrent neural networks, especially LSTMs, <ref type="bibr" target="#b55">[56]</ref> and transformer-based models that replace recurrence with multi-headed attention in a feed-forward set-up <ref type="bibr" target="#b57">[58]</ref>. These seq2seq models have been used for conditional text generation by encoding the data as a source sequence and employing standard transduction methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38]</ref>. Transformer-based models that have been trained on huge corpus of data <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b44">45]</ref> such as GPT2 and BERT are commonly used to warm-start such models <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b61">62]</ref>. Recently, transformer-based models similar to BERT <ref type="bibr" target="#b9">[10]</ref> have been pre-trained on table dataset <ref type="bibr" target="#b18">[19]</ref>. Our system uses recurrent network models for its different components. However, since the working of our system depends on the probabilistic generative model (similar to a statistical modeling approach) and not the underlying implementation, it should be able to leverage larger transformer-based models, pre-trained or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Controllable Text Generation</head><p>Standard neural network models trained end-to-end are black-box text generators, and it is difficult to control the generated text. To this extent, recently developed methods allow injecting control into these models. The controllable attributes can vary from topic, sentiment, politeness, tense, ordering of information, content, etc. These models learn control codes <ref type="bibr" target="#b28">[29]</ref> that only moderate high-level attributes such as sentiment <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b34">35]</ref> and style <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b51">52]</ref>, and thus can still generate text that differ at the word and phrase levels. Other models manipulate the syntactic structure of generated text <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>For more fine-level properties, some models learn templates <ref type="bibr" target="#b60">[61]</ref>, alignment between data and text <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b52">53]</ref>. Our system, which is built upon the model proposed by Li et al. <ref type="bibr" target="#b32">[33]</ref> with a linear chain conditional random field in the inference network and trained using Gumbel approximation following Fu et al. <ref type="bibr" target="#b13">[14]</ref> is most similar to these approaches. The control states learned to control some high-level semantics of the words generated and can be used to extract templates (in the form of constraint graphs). The semi-supervised training done for posterior regularization performs soft alignment between the text and the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Interactive Interfaces for Text Generation</head><p>Interactive interfaces for free text generation are increasingly popular. "Write with transformer" <ref type="bibr" target="#b24">[25]</ref> completes paragraphs that have been started by user input using transformer models like GPT-2. Some commercial applications like GMail use language models to improve their sentence completion. The Google Translate UI uses text generation for translation. TabNine <ref type="bibr" target="#b33">[34]</ref> offers language generation for programming languages integrated into multiple IDEs. MixingBoard <ref type="bibr" target="#b14">[15]</ref> demonstrates interfaces for knowledge grounded stylized text generation. Text generation models can also be used to detect if the models have created an input text themselves <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b62">63]</ref>. Note, though, that these differ from systems that focus on conditional generation. CSI:Summary <ref type="bibr" target="#b15">[16]</ref> describes a system for text summarization that uses a controlled generation model. Outputs can be constrained as a response to user interactions. Data2Text Studio <ref type="bibr" target="#b10">[11]</ref> allows formulation of constraints as set of Boolean rules. GenNI builds on the work of CSI:Summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Explainable AI for Sequence Models</head><p>Visualization for explainable AI is a very active research topic resulting in high-frequent publications. Hohman et al. <ref type="bibr" target="#b19">[20]</ref> provide a comprehensive start into this topic. Here, we exclusively focus on approaches for sequence models.</p><p>As the fundamental and earliest building block, RNNs have been the subject of study. The "unreasonable" effectiveness of RNNs for encoding sequential information <ref type="bibr" target="#b27">[28]</ref> can be interactively explored by approaches like LSTMVis <ref type="bibr" target="#b54">[55]</ref>, RNNVis <ref type="bibr" target="#b38">[39]</ref> or ProtoSteer <ref type="bibr" target="#b39">[40]</ref>. Several methods utilize the model's gradient and map them to model input for analysis <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>Current state-of-the-art deep learning NLP methods, like seq2seq models or transformers, are more complex and require interactive methods to investigate this complexity. Seq2SeqVis <ref type="bibr" target="#b53">[54]</ref> enables interactive what-if analysis of the five parts of a seq2seq model. BertViz <ref type="bibr" target="#b58">[59]</ref> and exBert <ref type="bibr" target="#b20">[21]</ref> allow a deep look into the attention mechanisms of transformer models. These tools provide interactivity to analyze single examples. GenNI extends from this idea and aims to generalize from concrete examples to a set of applicable rules for the whole dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION</head><p>We present GenNI, a system for collaborative development of databacked text generation systems. Unlike many systems developed for understanding deep learning models for NLP, GenNI is designed to help users produce actionable constraints that can be used with systems designed for user control. The system facilitates a collaborative interaction with users refining explicit constraints on the model and the AI system forecasting generations on new data.</p><p>This style of controllable model can be designed for many different tasks in NLP and related domains. Building models with user understandable controls opens up the ability for explicitly collaborative systems as opposed to the trade-off of rule-based systems and full AI-driven outputs. Visual interaction plays a key role for making it possible for a user to intuit, develop, and apply these constraints in a test environment as well as deploy them in real systems. In GenNI, the encodings and structure used were targeted specifically to a class of controllable generation models, but the approach of a single control state shared in a refine/forecast setting can be applied much more broadly. Future work will look to develop shared encodings that can be applied to a wide class of controllable NLP models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Motivating use case, steps 1-3. (a) Model output during free generation (M1). The control states are indicated by color below the produced output tokens. (b) Alice provides the custom output "the phoenix is a french pub ." The matching control states are inferred and mapped to colors (M3). (c) The constraint "FFJKECT" is applied to other random inputs (M2).</figDesc><graphic coords="3,318.35,148.97,211.70,159.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig. 4. Motivating use case, step 4. (a) Alice observes that "strada" is copied twice and no information about cuisine is available. (b) The selected example sequences of control states are merged into a combined constraint graph shown in the Constraint Editor view. (c) The constraint graph can be edited in the Constraint Editor by either using the text editor or the visual editing tool. (d) After applying the refined constraint, Alice observes the correct output: "strada" is copied once and no food type is mentioned.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>4 )</head><label>4</label><figDesc>Fig.5. Overview of GenNI domain goals, interaction tasks, and addressed user groups. GenNI aims at supporting goals for working with control state models: (G1) ensuring controlled generation, (G2) evaluating these constraints on subsets of relevant data and demonstrate model constraint generalization, and (G3) deploying the outcome as a controlled Human-AI system. From these high-level goals, a series of interaction tasks (middle part) is inferred. These tasks are the building blocks for the main interaction loop of forecasting constraint effects and refining constraints as a result. GenNI targets end-users and model architects alike for most tasks (right). (seeSect. 4)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. The GenNI user interface is split into a Constraint Refinement component (a) and a Generation Forecast component (b). A user can edit constraints directly in the Constraint editor (c) or derive them from a set of examples (d).Examples can be created (e) by inferring control states from a user output (f) or from the model's beam tree (g). The effect of specific constraints can be forecast on random samples (h) or tested on data ranges (i). The controlled model code can be exported for deployment or further testing (j). Model architects can investigate the control state alignments for each control state (k). Details are given in Sect. 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. On click, the control states are represented by letters to support formulation of constraint graphs and to support color-blind users.</figDesc><graphic coords="7,78.71,49.13,201.02,62.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Date Generation use case. (a) Model outputs during free generation [T1]. (b) Inferred control states for provided text output [T2]. (c) Constraint graph inferred and edited for this output format [T3].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Fig.11. Generation output for constraint graph section (a) in Fig.9. Note that the first output does not utilize the family-friendly field. This will be corrected in section (b) of the graph.</figDesc><graphic coords="8,44.75,293.21,250.94,69.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 12 .</head><label>12</label><figDesc>Fig. 12. Outputs of Range Forecast for the constraint graph. By providing the range no,yes for family-friendly, the system generates multiple tables with different values and uses these to produce text under the constraint graph. The output shows reasonable results for both values.</figDesc><graphic coords="8,307.31,212.09,215.18,144.50" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Probabilistic Generation of Weather Forecast Texts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Belz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
				<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Content selection from an ontology-based knowledge base for the generation of football summaries</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bouayad-Agha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Casamayor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ENLG</title>
				<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A Flexible Shallow Approach To Text Generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Busemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Horacek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>INLG</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mellish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Paiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scott</surname></persName>
		</author>
		<title level="m">Search of a Reference Architecture for NLG Systems</title>
				<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">RNNbow: Visualizing Learning via Backpropagation Gradients in Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cashman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mosca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2018.2878902</idno>
		<idno type="arXiv">arXiv:1907.12545</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="39" to="50" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">CoCon: A Self-Supervised Approach for Controlled Text Generation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Pung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>ArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Controllable Paraphrase Generation with a Syntactic Exemplar</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1599</idno>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generating Syntactic Paraphrases</title>
		<author>
			<persName><forename type="first">E</forename><surname>Colin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gardent</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1113</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Syntactic Manipulation for Generating more Diverse and Interesting Texts</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deriu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cieliebak</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-6503</idno>
	</analytic>
	<monogr>
		<title level="m">INLG</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Data2Text Studio: Automated Text Generation from Structured Data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-Y.</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-2003</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistical Acquisition of Content Selection Rules for Natural Language Generation</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Duboué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mckeown</surname></persName>
		</author>
		<idno>doi: 10. 3115/1119355.1119371</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings</title>
		<author>
			<persName><forename type="first">O</forename><surname>Dusek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Jurcícek</surname></persName>
		</author>
		<idno>doi: 10.18653/ v1/P16-2008</idno>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.14244</idno>
		<title level="m">Latent Template Induction with Gumbel-CRFs. 34th Conference on Neural Information Processing Systems</title>
				<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MixingBoard: a Knowledgeable Stylized Integrated Text Generation Platform</title>
		<author>
			<persName><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.26</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="224" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visual Interaction with Deep Learning Models through Collaborative Semantic Inference</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934595</idno>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2020-01">Jan. 2020</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="884" to="894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04043</idno>
		<idno>arXiv: 1906.04043</idno>
		<title level="m">GLTR: Statistical Detection and Visualization of Generated Text</title>
				<imprint>
			<date type="published" when="2019-06">June 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An architecture for template based (hyper)text generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geldof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Velde</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">TAPAS: Weakly Supervised Table Parsing via Pre-training</title>
		<author>
			<persName><forename type="first">J</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Piccinno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Eisenschlos</surname></persName>
		</author>
		<idno>doi: 10. 18653/v1/2020.acl-main.398</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pienta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2843369</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2674" to="2693" />
			<date type="published" when="2019-08">Aug. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Hoover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos.22</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automated Discourse Generation Using Discourse Structure Relations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.1016/0004-3702(93)90021-3</idno>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Domain Adaptable Semantic Clustering in Statistical NLG</title>
		<author>
			<persName><forename type="first">B</forename><surname>Howald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kondadadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schilder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IWCS</title>
				<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Toward Controlled Generation of Text</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Write With Transformer</title>
		<author>
			<persName><surname>Huggingface</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021-03">Mar. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adversarial Example Generation with Syntactically Controlled Paraphrase Networks. NAACL-HLT</title>
		<author>
			<persName><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1170</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Text-to-Text Pre-Training for Data-to-Text Tasks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<publisher>INLG</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02078</idno>
		<idno>arXiv: 1506.02078</idno>
		<title level="m">Visualizing and Understanding Recurrent Networks</title>
				<imprint>
			<date type="published" when="2015-11">Nov. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">N</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<title level="m">CTRL: A Conditional Transformer Language Model for Controllable Generation. ArXiv</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generation that Exploits Corpus-Based Statistical Knowledge</title>
		<author>
			<persName><forename type="first">I</forename><surname>Langkilde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
		<idno type="DOI">10.3115/980451.980963</idno>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Neural Text Generation from Structured Data with Application to the Biography Domain</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lebret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1128</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Posterior Control of Blackbox Generation</title>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.243</idno>
	</analytic>
	<monogr>
		<title level="j">ACL</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">TabNine -Code Faster with AI Code Completions</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D C</forename><surname>Ltd</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to Control the Fine-grained Sentiment for Story Ending Generation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1603</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visualizing memorization in RNNs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Madsen</surname></persName>
		</author>
		<idno type="DOI">10.23915/distill.00016</idno>
	</analytic>
	<monogr>
		<title level="j">Distill</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">e16</biblScope>
			<date type="published" when="2019-03">Mar. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An augmented template-based approach to text realization</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Mcroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Channarukul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Ali</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1351324903003188</idno>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="420" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">What to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1086</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>HLT-NAACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Understanding Hidden Memories of Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2017.8585721</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
				<imprint>
			<date type="published" when="2017-10">Oct. 2017</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ProtoSteer: Steering Deep Sequence Model with Prototypes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ren</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934267</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="238" to="248" />
			<date type="published" when="2020-01">Jan. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Neural Variational Inference and Learning in Belief Networks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.0030</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Planning Text for Advisory Dialogues: Capturing Intentional and Rhetorical Information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Paris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguistics</title>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The E2E Dataset: New Challenges For End-to-End Generation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Dušek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
		<idno>doi: 10. 18653/v1/W17-5525</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</title>
				<meeting>the 18th Annual SIGdial Meeting on Discourse and Dialogue<address><addrLine>Saarbrücken, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Controlling Personality-Based Stylistic Variation with Neural Natural Language Generators</title>
		<author>
			<persName><forename type="first">S</forename><surname>Oraby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharatht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Lukin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5019</idno>
	</analytic>
	<monogr>
		<title level="m">SIGDIAL Conference</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Language Models are Unsupervised Multitask Learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Reiter</surname></persName>
		</author>
		<title level="m">NLG vs. Templates. ArXiv</title>
				<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Building applied natural language generation systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<idno>doi: 10.1017/ S1351324997001502</idno>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Building natural language generation systems</title>
		<author>
			<persName><forename type="first">E</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Stochastic Backpropagation and Approximate Inference in Deep Generative Models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.4082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
				<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Torch-Struct: Deep Structured Prediction Library</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-demos</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07">July 2020</date>
			<biblScope unit="page" from="335" to="342" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Style Transfer from Non-Parallel Text by Cross-Alignment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klakow</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.641</idno>
		<title level="m">Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence. ACL</title>
				<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Seq2seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models</title>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2865044</idno>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2019-01">Jan. 2019</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="353" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2744158</idno>
	</analytic>
	<monogr>
		<title level="m">Conference Name: IEEE Transactions on Visualization and Computer Graphics</title>
				<imprint>
			<date type="published" when="2018-01">Jan. 2018</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="667" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">From data to speech: a general approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Theune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Klabbers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Pijper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Krahmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Odijk</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1351324901002625</idno>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Attention is All you Need</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A Multiscale Visualization of Attention in the Transformer Model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-3007</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">July 2019</date>
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Challenges in Data-to-Document Generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1239</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning Neural Templates for Text Generation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1356</idno>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents</title>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Roesner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.12616</idno>
		<idno>arXiv: 1905.12616</idno>
		<title level="m">Defending Against Neural Fake News</title>
				<imprint>
			<date type="published" when="2020-12">Dec. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
