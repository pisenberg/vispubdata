<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Weighted Average Illusion: Biases in Perceived Mean Position in Scatterplots</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Matt-Heun</forename><surname>Hong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jessica</forename><forename type="middle">K</forename><surname>Witt</surname></persName>
							<email>jessica.witt@coloradostate.edu</email>
						</author>
						<author>
							<persName><forename type="first">Danielle</forename><surname>Albers</surname></persName>
							<email>danielle.szafir@colorado.edu</email>
						</author>
						<author>
							<persName><roleName>IEEE</roleName><forename type="first">Szafir</forename><surname>Member</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">• Matt-Heun Hong and Danielle Albers Szafir are with the ATLAS Institute</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Colorado Boulder</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Colorado State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Weighted Average Illusion: Biases in Perceived Mean Position in Scatterplots</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8AA76E5F2E7EB060C9581A8FA92D3716</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T13:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Human-Subjects Quantitative Studies, Perception &amp; Cognition</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The mean provides a reference for judging data points as above or below average.</p><p>If points vary in lightness or size, the perceived mean position will be biased... ...leading some data points to be misjudged as being above average. Fig. <ref type="figure">1</ref>. We measured how integrating size or lightness into scatterplots can systematically bias the perceived mean of those points. We model how individual marks contribute to this bias, allowing us to predict differences in the actual mean (blue) and where people see the mean (orange). This misinterpretation can inhibit sensemaking and decision making. For instance, points in the grey boxes above will be incorrectly perceived as having higher-than average y-values. Under this illusion, graph readers' mean estimates can be increasingly biased as a function of size or lightness ranges mapped onto the data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Effective visualizations like scatterplots communicate data by leveraging fast and accurate visual processes. Scatterplots map two data dimensions to position <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b75">77]</ref>, a precise channel for comparing values <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b49">51]</ref>. They also leverage our ability to summarize sets of point marks through ensemble processing mechanisms <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b85">87,</ref><ref type="bibr" target="#b91">93]</ref>. Ensemble processing helps readers easily intuit how data points are distributed, allowing judgments about summary statistics such as correlations <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b70">72]</ref>, position means <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b90">92]</ref>, and clusters <ref type="bibr" target="#b0">[1]</ref>.</p><p>While ensemble perception is fundamental to visual data comprehension, it has limitations that can also interfere with effective communication. Recent work in vision science suggests that visual channels corresponding to common design elements, like size or color, may systematically bias our abilities to estimate the mean position of a small collection of point marks <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b72">74,</ref><ref type="bibr" target="#b81">83]</ref>. These limitations could manifest in common visualization techniques like line charts-which lead to underestimation of means <ref type="bibr" target="#b94">[96]</ref> and overestimation of trends <ref type="bibr" target="#b88">[90]</ref>)-and scatterplots.</p><p>Our work focuses on a systematic bias in estimating the mean position of data points in a scatterplot. This task is commonly used to assess differences across groups of data points <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b75">77]</ref>. For example, Rosling used multiclass scatterplots for Gapminder <ref type="bibr" target="#b73">[75]</ref> to compare mean GDP per capita and mean mortality rates between geographic regions. Using small multiples scatterplots like Parlapiano <ref type="bibr" target="#b63">[65]</ref>, people can assess trends in per capita income and life expectancy by comparing means and variances across time <ref type="bibr" target="#b51">[53]</ref>. Mean position can also provide a reference point: a survey <ref type="bibr" target="#b42">[43]</ref> published by The New York Times used a scatterplot to ask readers which venues should reopen first during the COVID-19 pandemic. Readers' decision criteria <ref type="bibr" target="#b79">[81]</ref> are likely to be determined based on the perceived x-and y-means, as illustrated in Hessney et al. <ref type="bibr" target="#b43">[44]</ref> and in Figure <ref type="figure">1</ref>.</p><p>We conducted a crowdsourced study with 130 participants ( §4.1) to measure biases in mean position estimates in scatterplots where point marks varied in size or lightness. Our study illustrates graph readers' enduring tendency to weigh large or dark marks more toward the mean. However, this is a misinterpretation of scatterplots, where weighted position means will shift with the range of size or lightness mapped onto the data (see Figures <ref type="figure" target="#fig_0">1 and 2</ref>). Our demonstration of this weighted average illusion and the ensuing bias adds to the growing literature on visualization biases <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b88">90,</ref><ref type="bibr" target="#b94">96]</ref>. To guide our discussion of causal factors in §7.2, we incorporate a statistical model of feature-based attention (FBA) <ref type="bibr" target="#b11">[12]</ref> known as the centroid method <ref type="bibr" target="#b81">[83]</ref> which quantifies attention given to individual data marks ( §6.2). In addition, our models lead to hypotheses about other strategies people might utilize, such as selective attention <ref type="bibr" target="#b61">[63]</ref> ( §7.2.2) and spatial segmentation <ref type="bibr" target="#b30">[31]</ref>, that may help practitioners understand how similar biases may arise in other designs ( §7.2.3). Contributions: Our primary contribution is quantifying the bias that may arise under the weighted average illusion in trivariate scatterplots, as a function of design choices and data patterns (Figure <ref type="figure">6</ref>), even after training. We also demonstrate how modeling techniques in visual cognition like the centroid method can enable causal interpretations of visualization studies. These models allow practitioners to predict when biases may arise and avoid potential misjudgments. Our findings create opportunities at the intersection of visualization and vision science by hypothesizing possible mental shortcuts used in visualization interpretation and decision making.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>Honest communication in visualization means avoiding deceptions and biased interpretations of data. Understanding bias has a long tradition in visualization research <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b57">59,</ref><ref type="bibr" target="#b62">64,</ref><ref type="bibr" target="#b84">86,</ref><ref type="bibr" target="#b92">94]</ref>, and one recent study demonstrates possible priming effects on position means <ref type="bibr" target="#b94">[96]</ref>. We suspect that position mean biases could also be caused by limits on our visual system. We build on knowledge and techniques from vision science to model bias as a function of visual elements in scatterplots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visualization Biases</head><p>Visualizations provide a powerful yet imperfect means for communicating data. Subtle design choices may bias conclusions drawn from data <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b57">59]</ref>. For example, encoding data using a bubble's area rather than its diameter can inflate perceived data differences <ref type="bibr" target="#b62">[64]</ref>. Other biases may emerge from choices made in the data processing pipeline. For example, changing the rendering order of scatterplot points can distort our perception of distributions <ref type="bibr" target="#b57">[59]</ref>. And cognitive biases often do not stem from the visualizations themselves, but from imperfections in an analyst's sensemaking process (see Dimara et al. <ref type="bibr" target="#b23">[24]</ref> for a survey).</p><p>Design guidelines can provide proactive strategies for avoiding common biases <ref type="bibr" target="#b84">[86]</ref>. For example, designers are encouraged to avoid rainbow colormaps, partly because they can cause "banding" biases that lead people to group marks that share similar hues <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b68">70]</ref>. Intelligent design systems, such as visualization linters <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b56">58]</ref>, can leverage these guidelines to identify potentially misleading practices.</p><p>However, we lack formal models of biases that can help us reason about potential design trade-offs. While controlled experiments <ref type="bibr" target="#b62">[64]</ref> substantiate the harmfulness of distorting aspect ratios and truncating y-axes, this latter (much maligned) practice can be helpful for interpretation depending on the data patterns and communication goals <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b92">94]</ref>. If magnitudes of bias could be modeled as a function of visual elements, designers can make better judgments about these trade-offs to enhance the overall effectiveness of a visualization while limiting bias <ref type="bibr" target="#b71">[73]</ref>.</p><p>While bias can emerge as an artifact of explicit design choices, other biases may be more subtle. Xiong et al. <ref type="bibr" target="#b94">[96]</ref> showed that position means can be biased in conventional plots: people systematically overestimated the mean using bar charts, and underestimated it using line charts. Statistical patterns in scatterplots can be distorted by geometric scaling <ref type="bibr" target="#b90">[92]</ref>. Visualizations optimized for one task may fail for many others <ref type="bibr" target="#b65">[67]</ref>, and such failures may lead to bias: even the most honest charts might mislead the reader.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Scatterplot Perception</head><p>Scatterplots are amongst the most commonly used <ref type="bibr" target="#b74">[76]</ref> and scrutinized <ref type="bibr" target="#b75">[77]</ref> visualization techniques. They primarily map data to both x-and y-positions, yet encompass a diverse range of design variations <ref type="bibr" target="#b75">[77]</ref> and are applicable to a broad array of tasks, from comparing individual values <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16]</ref> to summary statistical tasks such as clustering <ref type="bibr" target="#b76">[78]</ref>, averaging <ref type="bibr" target="#b33">[34]</ref>, and correlation <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b70">72]</ref>.</p><p>Their variations <ref type="bibr" target="#b75">[77]</ref> frequently communicate more than two data dimensions. The ways these additional dimensions are depicted can impact the scatterplot's usability, making it easier or harder to estimate trends <ref type="bibr" target="#b18">[19]</ref> or compute differences across groups of data points <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b33">34]</ref>. Computational models of these trade-offs exist for optimizing scatterplot designs for different tasks <ref type="bibr" target="#b58">[60]</ref>.</p><p>Such trade-offs in scatterplot designs become more complex as a function of visual channels used to encode data. The term separability refers to the ease with which our visual system can process one visual channel without interference from another <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b60">62,</ref><ref type="bibr" target="#b89">91]</ref>. For example, color and position channels are separable, since our perception of position is robust to changes in color, and vice versa. But when visualizing data using red hue values for one measure and blue hue values for another, people will struggle to process each measure independently <ref type="bibr" target="#b89">[91]</ref>.</p><p>While position is generally considered separable from all other channels, evidence suggests that position may be integral with some channels for more complex visualization tasks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b49">51]</ref>. For example, position is integral with motion in outlier detection in multivariate scatterplots <ref type="bibr" target="#b87">[89]</ref>. Recent studies provide formal models of separability across color, shape, and size for comparing data values <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b78">80,</ref><ref type="bibr" target="#b83">85]</ref>, but we lack formal models for the separability of position with other channels in perceiving means and distributions.</p><p>A scatterplot's ability to support averaging and other ensemble tasks may also be affected by the underlying data distributions <ref type="bibr" target="#b49">[51,</ref><ref type="bibr" target="#b88">90]</ref>. While one study showed that averaging in scatterplots is generally robust to the size of data and a variety of tertiary encodings <ref type="bibr" target="#b33">[34]</ref>, positional outliers may bias trend perceptions <ref type="bibr" target="#b18">[19]</ref>, and performance on position summary tasks can vary across geometric scales <ref type="bibr" target="#b90">[92]</ref>. In this study, we model the separability of position and two common visual channels-size and lightness-for the position mean task across varying data distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Ensemble Perception</head><p>Visualization tasks often involve extracting statistical summaries from data, such as mean position and size of data points; detecting color, size, or position outliers; spatial or feature-based segmentation; and judging correlation <ref type="bibr" target="#b85">[87]</ref>. These tasks rely on our ability to rapidly summarize sets of visual elements through ensemble processing <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b85">87,</ref><ref type="bibr" target="#b91">93]</ref> at a glance, even without focused attention to locations of individual objects <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b70">72,</ref><ref type="bibr" target="#b93">95]</ref>. While ensemble perception is mostly beneficial for data comprehension, it may be susceptible to bias. Although mark color should be separable from position, Sun et al. <ref type="bibr" target="#b82">[84]</ref> suggests color lightness will systematically bias position averaging. These biases can lead to illusory misjudgments when viewing dot plots.</p><p>Previous work <ref type="bibr" target="#b94">[96]</ref> studied the impact of higher-level cognitive influences on position mean biases. Our work draws on vision science techniques to model bias in terms of visual elements using the regression models of the centroid method <ref type="bibr" target="#b81">[83]</ref>. These models have been used to explain systematically biased mean estimates as a function of object lightness <ref type="bibr" target="#b81">[83,</ref><ref type="bibr" target="#b82">84]</ref>, hue <ref type="bibr" target="#b80">[82]</ref>, size <ref type="bibr" target="#b72">[74]</ref>, orientation <ref type="bibr" target="#b47">[48]</ref>, and texture <ref type="bibr" target="#b81">[83]</ref> in small sets of objects. However, these studies aim to isolate specific mechanisms, so stimuli are presented in subsecond durations. Only twelve or fewer targets are displayed, and no additional context such as labels or axes could divert attention. We extend their methods to realistic visualization scenarios to understand how biased data interpretations may arise as a function of design choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">HYPOTHESES</head><p>Graph readers can use scatterplot means to characterize a range of values, compare classes in multiclass scatterplots <ref type="bibr" target="#b33">[34]</ref>, compare distributions over time or other facets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b51">53]</ref>, or create decision thresholds <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b79">81]</ref>. Studies in vision science showed that common visual variables like lightness or size can interfere with people's abilities to estimate mean properties for a small collection of objects <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b72">74,</ref><ref type="bibr" target="#b81">83]</ref>. However, these studies sought to measure perceptual mechanisms using flash tasks (i.e., stimuli were displayed for 500ms) and asking people to average fewer than 16 randomly distributed objects. These interference effects may not hold in visualization contexts, where people see a large number of marks, including the axes and ticks, for longer periods of time. To measure potential systematic bias in scatterplot averaging, we asked participants to indicate the average position of all marks in scatterplots where a third data dimension was mapped to either lightness or size. Based on prior studies, we hypothesize: H1: Scatterplot means will always be pulled towards locations of dark or larger points. Vision science studies demonstrate that locations of more salient (larger or darker) marks pull the perceived mean among small sets of objects. We expected these results to extend when reading trivariate scatterplots over the course of several seconds. H2: Increasing correlations between the irrelevant channel and position will increase bias. Increased correlation between position and either size or lightness will cause dark or large data points to group together. If locations of dark or large data points pull mean position, we will see significantly biased mean responses directed towards regions where these points are located. <ref type="bibr">Kim &amp; Heer [51]</ref> demonstrated increased error rates with scatterplots with size variance, suggesting that size may have a stronger biasing effect than lightness. H3: Widening the encoding range of the irrelevant channel will amplify bias. Increasing the visual difference among data points increases the differences in contrast across a scatterplot (e.g., the large marks would become larger, and the small marks smaller). If variations in contrast already shift the perceived position mean, increasing this difference would increase the ensuing bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODS</head><p>We investigated the effects of size and color on mean position estimation for trivariate scatterplots in two separate experiments: one investigating size and the other lightness. Each experiment was a 3 (encoding ranges) To ensure comprehension, we stepped participants through the target task, steadily building in more information. The tutorial images above were presented serially with the following instructions: 1. Scatterplots reduce information about two measures into a single data point. 2. On this scatterplot, 30 countries are presented in terms of their life expectancies and income levels. 3. Therefore, the pink dot alone represents both the average life expectancy and the average income of the 30 countries shown. 4. Each point on a scatterplot can also depict a third variable, such as unemployment rate. After viewing the tutorial, participants were instructed that: "In the following study, you are asked to estimate and click on the average position of all points (i.e., average life expectancy and average income of all countries) on each scatterplot."</p><p>× 3 (correlations) within-subjects design. We measured performance using the vector between the reported means and the true means. We provide anonymized data and our study infrastructure at https://osf. io/h8ft3/?view_only=9564278544b4411c82610c73daed8c00.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Stimuli Generation</head><p>Our stimuli consisted of 500 × 500 pixel scatterplots generated using D3 (Figure <ref type="figure">3</ref>). Each scatterplot was rendered on two orthogonal black axes with unlabeled tick marks every 50 pixels.</p><p>To generate the x-and y-data, we used Poisson disk sampling [50] to produce 30 uniquely distributed point grids, with minimum distance between the boundaries of any two points set at 8 pixels. This methodology is similar to Gleicher et al. <ref type="bibr" target="#b33">[34]</ref>. Each dataset always contained 30 marks, with the number of points selected in piloting.</p><p>For each of the above datasets, we generated additional data for size and lightness to satisfy each of three spatial correlation levels: no correlation, low correlation, and high correlation. In the no correlation condition, the position of points had no correlation with the size or lightness data, providing a random distribution of the distractor encodings. In the low correlation condition, both the x-and y-positions of points were correlated with size or lightness by ρ = 0.4 ± 0.05; in the high correlation condition, position was correlated with size or lightness by ρ = 0.8 ± 0.05. We generated four datasets for each direction of correlation-either increasing or decreasing, along either the positive or negative diagonal-for each of the 30 point grids. These correlations between the third measure and the two position measures created a  <ref type="formula">3</ref>) and report the perceived mean position by clicking on the corresponding location in the scatterplot, with the cross moving with the cursor. We would visually indicate the reported value (4) and then ask participants to click on a link at the center of the screen (5) to recenter their mouse before the next trial.</p><p>visual gradient (from light-to-dark, or small-to-large) along one of these four diagonals (Figure <ref type="figure">1</ref>, right). This process led to 12 variations for each of the 30 scatterplot stimuli.</p><p>The encoding range for each distractor variable (size or lightness) corresponded to one of three levels: 45L * to 75L * , 37.5L * to 82.5L * , and 30L * to 90L * for lightness and 17.5px to 32.5px, 13.75px to 36.25px, and 10px to 40px for size, specified in terms of mark diameter (Figure <ref type="figure" target="#fig_0">2</ref>). The linear ranges were sampled at seven evenly spaced values and shared the same middle value (i.e., the same size or lightness) to focus on the effect of range width rather than its midpoint. We chose the lightness ranges based on conventional L * distributions in ColorBrewer <ref type="bibr" target="#b39">[40]</ref>, where the darkest colors are typically near 30L*, and the brightest colors are typically near 90L*. The ranges of size were restricted to those that would prevent occlusion given the 8 pixel limit on distance between points and align with default ranges found in commercial systems. In both size and lightness experiments, the narrowest range spanned half the width of the largest range.</p><p>Each participant saw 60 trials: 54 test trials varying in size or lightness and 6 control trials with no size or lightness variation to provide a baseline error rate. The test trials consisted of six trials for each combination of correlation (none, low, high) and encoding range (narrow, medium, wide). Data for each trial was randomly sampled from the set of pre-generated datasets with the correct corresponding correlation level. We presented the 60 trials in a random serial order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Procedure</head><p>We conducted a Mechanical Turk experiment consisting of four phases: 1. informed consent, 2. instructions and tutorial, 3. formal trials, and 4. demographics. Participants were first provided with a consent form containing basic information about the data to be collected in the study. After providing consent, each participant passed an online Ishihara plate test to screen for color vision deficiencies <ref type="bibr" target="#b12">[13]</ref>.</p><p>After completing the screening, participants moved to a tutorial to ensure proper task understanding. The tutorial walked participants through the design of a trivariate scatterplot, first describing mark position, then demonstrating mean mark position, and finally introducing an additional channel using unemployment rate as an example measure. The tutorial, their accompanying figures, and text annotations were iterated through extensive piloting. During in-person piloting, we debriefed participants on our research goals, and confirmed that no participant interpreted the additional third measure as a factor that should affect the mean value of scatterplots. Figure <ref type="figure">3</ref> summarizes this aspect of the experiment.</p><p>After the tutorial, participants were instructed to "Click on the average position of all points" on each scatterplot, and this instruction persisted throughout both training and test trials. Training consisted of 18 trials where participants received immediate feedback by being presented the true mean position (Figure <ref type="figure" target="#fig_2">4</ref>) after their click response. Prior work <ref type="bibr" target="#b81">[83]</ref> utilized such feedback to collect more consistent estimates of mean position. During these practice trials, cursor movements were animated by moving reference lines along the x-and y-axis, reinforcing the idea that the participant was to average the x-and y-positions of the data points.</p><p>During the test trials, the interactive cursor guides and feedback were removed. Participants saw each of their 60 scatterplots in a random serial order. Each trial began with a 500ms gray mask followed by a fixation cross symbol to cue the participant that the trial was about to begin. After another 500ms, the scatterplot was rendered and participants had five seconds to click on the mean position of points in the scatterplot, with the time limit determined in piloting. A pink dot appeared briefly at the clicked location, signaling the trial's end. Participants could complete the task after the scatterplot was hidden, but delayed responses prompted an alert to encourage the participant to respond within the allotted time. Before beginning the next trial, participants had to move the cursor back to the center of the stimulus by clicking a link in the middle of the scatterplot to reset their cursor position, minimizing potential motor bias.</p><p>We interspersed four engagement checks in the formal study to assess honest participation. On average, 7.5 trials passed before the first engagement check, and then 15 trials passed before each successive check. During these engagement checks, a single data point was shown in one of the four quadrants, and participants were removed from the analysis if they failed two or more checks. After completing all trials, participants completed a demographic survey and were compensated for their participation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lightness ranges</head><p>Size ranges Fig. <ref type="figure">5</ref>. Mean error magnitude across encoding type, encoding range, and correlations. Note the y-axis represents pixel values, and our stimuli size was 500px by 500px. Using lightness (green lines) did not significantly increase error over the baseline. In the size experiment (blue lines), errors were significantly higher than the baseline condition for all ranges. Error bars represent 95% confidence intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Measures &amp; Analysis</head><p>Error was measured as the magnitude of the error vector between the true mean and the reported mean. We additionally computed the directional bias in responses by projecting the error vectors to the direction of the correlation gradient. We analyzed these measures using a two-factor (encoding range, and correlation level) ANCOVA with trial order, direction of the correlation gradient, the specific datasets, and interparticipant variation as random covariates. We examined both primary effects and first-order interaction effects and used Tukey's Honest Significant Difference (HSD) test (α = .05) with Bonferroni correction for post-hoc comparisons. These analyses excluded the control scatterplots (those with no lightness or size differences) as those trials reflect no measurable correlations or encoding ranges. However, we used Dunnett's Method to identify where error or bias significantly differed from baseline performance measured in these trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Participants</head><p>We recruited 174 subjects with US IP addresses from Amazon's Mechanical Turk. We excluded 22 participants with limited or no cursor movements, flagged by back-to-back clicks on the same pixel position, and another 22 participants who failed the engagement trials, leaving us with a final sample size of 130. These participants were between 20 and 71 years of age (μ = 37.3, σ = 10.5). 108 (83.1%) participants used mouse clicks and 21 (16.1%) participants used a trackpad. One participant used a touchscreen. Participants were compensated $1.75 for their time. On average, the experiment took 7.8 minutes.</p><p>Crowdsourcing platforms exchange some control for ecological validity: sizes and colors may be affected by the display and environment used by each participant. However, this variety reflects visualization viewing in practice and has been shown to produce reliable models in past visualization research <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b49">51,</ref><ref type="bibr" target="#b50">52,</ref><ref type="bibr" target="#b78">80,</ref><ref type="bibr" target="#b83">85]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>We report inferential statistics, means, and 95% bootstrapped confidence intervals (means ± 95% confidence intervals) for relevant effects in accordance with guidelines for transparent statistical communication <ref type="bibr" target="#b24">[25]</ref>. Means and confidence intervals are reported in pixel values: our stimuli size was 500px by 500px.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Error</head><p>Figure <ref type="figure">5</ref> summarizes error rates across the experimental conditions. We did not find any significant differences of error in the lightness experiment. In the size experiment, there was a significant interaction effect of correlations and size range on error rates (F(4, 63) = 3.02, p &lt; .02). Tukey's HSD reveals that error rates rose dramatically in the highcorrelations, high-size range condition (μ = 70.2px ± 5.0).</p><p>We used Dunnett's Method to compare errors in the control condition and the three experimental conditions for both experiments. We found no significant differences between the control condition and the three lightness conditions. However, each size condition introduced significantly greater error rates than the control condition (narrow size ranges: p &lt; .05; middle size ranges: p &lt; .005; large size ranges p &lt; .0001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Bias</head><p>While the previous section showed rates of precision that were comparable across conditions, bias in participants' responses may still increase, making error rates a less reliable measure in evaluating position mean perception.</p><p>To illustrate, assume that participant responses in the control condition were normally and randomly distributed around the true mean, and that size or lightness pulled these responses northeast. In this case, some responses (i.e., those already northeast of the true mean) are pulled further away from the true mean, potentially increasing the error rates. However, some responses (i.e., those southwest of the true mean) are simultaneously pulled closer to the true mean; these displacements can effectively balance out the above shifts in error rates.</p><p>Correlations between the distractor encoding and position created a visual gradient (from light-to-dark, or small-to-large) along one of the four diagonals. We measured bias as a function of the amount of signed error displaced along each scatterplot's direction of gradient. Overall, position means were biased toward the direction of increasing size or darkness, with the magnitude of the bias increasing with correlation between the distractor encoding and position. Figure <ref type="figure">6</ref> summarizes the results.</p><p>Lightness: While we did not find a significant effect of increasing lightness range alone (F(2, 67) = 0.77, p &lt; .5), bias in the perceived mean increased as the correlation between position and lightness increased (F(2, 67) = 4.51, p &lt; .02). Highly correlated scatterplots with a wide lightness range (μ = 22.2px ± 5.4) were significantly more biased than all other conditions except the other highly correlated scatterplots (narrow range: μ = 17.1px ± 5.4; middle range: μ = 15.8px ± 5.4). The highly correlated conditions with narrow and middle ranges displayed significantly higher bias than uncorrelated data with moderate (μ = 7.3px ± 5.4) and wide (μ = 17.1px ± 5.5) lightness ranges.</p><p>Size: While we did not find a significant effect of increasing size range alone (F(2, 63) = 0.47, p &lt; .7), there was a significant interaction effect between increasing correlations and increasing size levels (F(4, 63) = 2.44, p &lt; .05). Increasing correlation between size and position led to significant increases in bias (F(2, 63) = 15.22, p &lt; .0001). Specifically, in the high correlations conditions, middle (μ = 32.91px ± 9.6) and wide size ranges (μ = 36.0px ± 9.7) were significantly more biased than the narrow size range (μ = 20.5px ±9.7). Within each size range condition, if correlations were greater, bias was greater. The exception to this pattern was the narrow size range, where increasing correlations from low (μ = 15.2px ± 9.7) to high (μ = 20.5px ± 9.7) did not significantly affect bias. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Narrow</head><p>Medium Wide H M H M Fig. <ref type="figure">6</ref>. Mean bias across encoding type, encoding range, and correlations. Note the y-axis represents pixel values, and our stimuli size was 500px by 500px. Errors in both lightness (green) and size (blue) exhibited systematic biases towards locations of larger or darker points. These effects were amplified by increased correlations. Error bars represent 95% CIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">MODELING FEATURE-BASED ATTENTION</head><p>Mean position estimates were biased toward locations of larger and (to a lesser extent) darker points, creating a weighted average illusion giving more weight to areas with larger or darker marks. However, the above results do not give an account of why the bias emerges. What elements of a scatterplot's design might be biasing position mean perception?</p><p>Here, we seek to build a more predictive model of this bias as a function of visual elements and data distributions. With such a model, practitioners can better reason about design trade-offs by predicting magnitudes of bias across designs and distributions. This motivates our models of observed bias using the centroid method <ref type="bibr" target="#b81">[83]</ref>. This technique uses linear regression to measure how much of the observed errors in participants' position mean responses is attributable to varying attention given to mark features, such as its specific size or lightness.</p><p>Our primary goal with this analysis was to model bias in the nocorrelation conditions, where size and lightness were randomly distributed. In such cases, we could not measure bias as signed errors along directions of the correlation gradient as there was no correlation gradient to project against. Models of this condition can provide a baseline rate of bias for any given trivariate scatterplot. Since it is less likely that random scatterplots contain global features like a texture density gradient, which is a potentially confounding factor <ref type="bibr" target="#b36">[37]</ref>, this model will help us answer whether people attend to data points with certain features differently toward the mean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Feature-Based Attention</head><p>Feature-based attention is an attention mechanism that operates in a parallel, distributed manner across space <ref type="bibr" target="#b3">[4]</ref>. It does so by modulating the gain of regions in the visual cortex selective for a feature (e.g., a given color or shape) <ref type="bibr" target="#b77">[79]</ref>. When performing a visual summary task, such as comparing average values in multiclass scatterplots <ref type="bibr" target="#b33">[34]</ref>, feature-based attention helps viewers attend to each set of point marks separately before comparing their average values.</p><p>Feature-based attention is usually considered a selective attention mechanism in visualization <ref type="bibr" target="#b85">[87]</ref>. However, the distribution of attention given to objects that vary across a continuous channel, such as size or lightness, need not be selective. Attention can be automatically attuned to one type of objects relatively more than others (e.g., large marks over small marks), while still being distributed across all objects to execute a summary task like position averaging <ref type="bibr" target="#b81">[83]</ref>. In other words, feature-based attention may automatically "weigh" certain kinds of marks relatively more than others when summarizing data.</p><p>The centroid method is a linear regression model of feature-based attention that models such weights distributed across a set of point marks. Much like eye tracking, the centroid computation provides a behavioral marker that acts as a proxy for studying attention. However, unlike eye-tracking, the centroid method allows us to model attention being distributed across multiple locations in parallel by estimating the weight given to certain kinds of marks based on their visual features (e.g., size or lightness levels).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">The Centroid Method</head><p>The centroid method <ref type="bibr" target="#b81">[83]</ref> defines a weight function w(τ), where ∑ τ w(τ) = 1, as the weight given to each item of type τ. This weight function w is called the attention filter, a model of feature-based attention <ref type="bibr" target="#b11">[12]</ref>-our ability to attend to items with specific visual features more, or less, than other items-which may cause the bias towards larger and darker points. This attention filter corresponds to the visual 'weight' of individual marks. We discuss the role of feature-based attention in interpreting our results in §7.2.1.</p><p>We model a participant's mean estimate (R t,x , R t,y ) on scatterplot trial t as</p><formula xml:id="formula_0">R t,x = V μ t,x + (1 −V )x de f ault + Q t,x R t,y = V μ t,y + (1 −V )y de f ault + Q t,y</formula><p>where μ t,x and μ t,x are coordinates of the true mean position of the points; V , where 0 ≤ V ≤ 1, is the Data-Drivenness parameter-a measure of how much participants depended on a default location (x de f ault , y de f ault ) (e.g., the center of the graph) rather than true point positions to compute mean position-and Q t,x and Q t,y are independent and normally distributed random response errors.</p><p>We can define μ t,x and μ t,x as the weighted sums of mark coordinates divided by the sum of all weights:</p><formula xml:id="formula_1">μ t,x = N stims ∑ i=1 w(τ t,i )x t,i N stims ∑ i=1 w(τ t,i ) , μ t,y = N stims ∑ i=1 w(τ t,i )y t,i N stims ∑ i=1 w(τ t,i )</formula><p>where τ t,i is the item type of mark i in trial t, w is the attention filter (the visual 'weight' of each mark), and x t,i and y t,i are coordinates of mark i in trial t.</p><p>The process for generating point and interval estimates for w is outlined in Appendix 1 and 2 of Sun et al. <ref type="bibr" target="#b81">[83]</ref>. The point estimation finds the maximum likelihood estimate of w via linear regression. The interval estimation uses Fieller's theorem <ref type="bibr" target="#b29">[30]</ref> for calculating a 95% confidence interval for the ratio of two means. The interval estimates give the expected variance of visual weights given to each mark across the population. No significant differences Significantly different from other marks Fig. <ref type="figure">7</ref>. Weights describing the contribution of classes of marks to the observed bias derived using the centroid method (means and 95% confidence intervals). White marks indicate points that have significantly different weights and highlighted marks indicate where weights differed significantly from equal weighting. An upward slope indicates that people give greater weight to larger or darker marks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head><p>Our stimuli contained marks of seven different sizes or lightnesses, which we used to represent our mark categories τ. If participants weighed all marks equally regardless of size or lightness, the weight for any mark would be 1/7 (14.29%). This threshold provides a baseline for determining whether participants weighed certain marks more heavily than others. Figure <ref type="figure">7</ref> summarizes the weight distributions across conditions. The leftmost values within each plot correspond to the smallest or brightest marks in each scatterplot, and the rightmost values correspond to the largest or darkest marks in each scatterplot.</p><p>We found that even when size had no correlation with position (Figure <ref type="figure">7</ref>, top row, blue), people weighed the smallest marks significantly less than and the largest marks significantly more for moderate and wide size ranges. When data was uncorrelated and the encoding ranges were narrow (top row, 1st and 4th columns), participants weighed marks roughly equally.</p><p>We found that these weights varied significantly along with variations in range widths and correlations. In general, people weighed marks more heavily as they became darker or larger, correlated with the corresponding increase in bias toward locations of those marks from §5.2. We also found evidence that these weights, rather than a default response like clicking in the center of the graph, explain the errors we found in our data. The Data-Drivenness (V ) of click responses were 81.09% for lightness, and 69.46% for size, comparable to those found by Sun et. al. <ref type="bibr" target="#b81">[83]</ref> in in-person laboratory studies.</p><p>We can use these weights to predict where people are likely to see the mean on a scatterplot (Fig. <ref type="figure">1</ref>). While we focused on lightness and size, this weighting approach has been used with other visual features like orientation <ref type="bibr" target="#b47">[48]</ref> and hue <ref type="bibr" target="#b80">[82]</ref>. Future work could similarly extend the approach to other kinds of visualizations, such as bar charts or line charts, where position is redundantly coded using height or orientation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>We explored the relationship between size, lightness, and positional means in trivariate scatterplots. Our results show that the perceived mean of a scatterplot is biased towards larger or darker points (H1). We have labeled this bias the weighted average illusion because the bias can be explained by asymmetries in weights we assign to marks based on irrelevant properties like size and color. We found that these effects were robust to training and increased as the structure in the data and range of size or lightness increased ( §5). Bias always increased as correlations between position and the third data dimension increased. This bias was directed toward areas of larger or darker points and, in the strongest conditions, caused people to misread the average by 35 pixels, supporting H2. Widening size ranges also affected bias as correlations increased, partially supporting H3. While these effects were stronger for size than lightness, they demonstrate the predictability of this bias as a function of data patterns and design choices (Figure <ref type="figure">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Design Implications</head><p>Our results indicate that, despite classical guidelines that position is robust to other encodings <ref type="bibr" target="#b89">[91]</ref>, adding additional data to scatterplots can interfere with and even bias people's abilities to reason over position. These biases likely extend to other visualizations using both size and position to communicate data, such as Augmented Stripplots <ref type="bibr" target="#b69">[71]</ref>. While we explore this phenomena in the context of mean judgments, bias may occur in other summary tasks that rely on similar visual processes, like variance estimation and correlation. Designers can use the observed bias and weights to predict when this bias might occur and use alternative design strategies, like providing reference lines or explicit summary values, to support critical summary tasks.</p><p>Size is a more precise channel for communicating data than lightness <ref type="bibr" target="#b13">[14]</ref>, but our study indicates that size interferes with position summaries more significantly. Error rates in the lightness experiment were often comparable to those in the control condition. Further, bias in bubble charts may be much greater in practice than demonstrated in our results where our tested ranges were limited to prevent occlusion. Designers should consider these trade-offs given their target audience, datasets, and the visualization tasks at hand: if assessing global properties, such as means or variances, are more important than comparing values, lightness may provide a more robust channel. If interpreting individual values is more critical, size may be preferable.</p><p>Using the centroid paradigm, designers can run exploratory selfstudies to quantify the degree to which readers can summarize relevant data when distracting categorical (e.g., hue palettes <ref type="bibr" target="#b60">[62,</ref><ref type="bibr" target="#b80">82]</ref>) or continuous channels (e.g., size or lightness) are present. When the relevant and distractor channels may not seem separable, weights modeled using the centroid method can be used to estimate a baseline rate of bias. For example, by simply computing the average of mark locations weighed according to our attention filters presented in Figure <ref type="figure">7</ref>, designers can predict which data points will be seen as being above or below average. This is how the predicted perceived means in Figure <ref type="figure">1</ref> (open circles) were computed. Developing a more extensive set of models covering a larger range of designs could provide significant predictive power for predicting bias in information design.</p><p>Both current and prior work suggest that readers can be trained to mitigate this bias in small collections of objects. While our results exhibited a consistent bias, there can be significant individual differences in how much weight people give to each mark during averaging that can be reduced with sufficient training <ref type="bibr" target="#b25">[26]</ref>. In pilot studies, we found that without training, people exhibited a wider range of bias magnitudes but these biases converged over time. We account for this in our study with our training phase, where participants receive feedback for 18 trials before entering the formal study. However, these findings suggest the possibility that certain kinds of biases can be mitigated by training. Participants could have segmented highly correlated scatterplots into sets of smaller points and sets of larger points, then computing the midpoint of those segments weighted by estimates of density in each segment. This strategy amounts to asking the question "How many points are here, as opposed to there?" instead of directly computing the mean position. Although the segment with larger marks might seem to contain more data, both segments contain 15 marks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Potential Basis for the Weighted Average Illusion</head><p>By modeling how different elements of a design may bias mean estimates, we can generate new hypotheses for visualization psychology that allow us to anticipate why this bias might arise and when it may impact other visualization types or tasks. Many ensemble coding strategies, proxies, and heuristics can support or combine to help people compute visual summary statistics. We expand on what the centroid method results ( §6.2) tell designers about attention in trivariate scatterplots and propose two possible mental shortcuts that people could be using to compute mean positions: 1. sampling only a subset of marks that could be held in working memory (Figure <ref type="figure">8</ref>-1), and 2. comparing texture densities between spatial segments of the data (Figure <ref type="figure">8</ref>-2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Local Basis: Feature-Based Attention</head><p>The position mean is a reliable behavioral marker for studying featurebased attention in vision science <ref type="bibr" target="#b81">[83]</ref> and information visualization <ref type="bibr" target="#b33">[34]</ref>. Feature-based attention implies that attention is unevenly distributed across space, skewing towards marks with certain visual features <ref type="bibr" target="#b11">[12]</ref>.</p><p>The attention filters modeled with the centroid method quantify this skew <ref type="bibr" target="#b81">[83]</ref>. When reading visualizations, we rely on feature-based attention to, for example, make judgments about different data categories <ref type="bibr" target="#b33">[34]</ref> or search for relevant data <ref type="bibr" target="#b37">[38]</ref>.</p><p>Although we did not use eye tracking in our study (as discussed in §7.3), prior work already confirmed that dark and large marks are more salient than light and small marks <ref type="bibr" target="#b40">[41]</ref>. This implies that participants' eye movements may have reflexively saccaded to the locations of dark or large objects as soon as each scatterplot was presented. Such behavior might have a priming effect on computing the mean position of scatterplot marks, causing feature-based attention to be distributed more towards larger or darker marks and potentially leading to the skewed attention filters modeled in Figure <ref type="figure">7</ref>.</p><p>However, if feature-based attention was the only factor at play, we would see the same attention filters in each correlation condition, varying only as a function of increasing size or lightness ranges. Instead, we found that the attention filters varied with increasing correlations in the data as well, indicating there is more to the observed bias than simple pop-out effects. People may alternatively be using subsampling or density-driven strategies (Figure <ref type="figure">8</ref>). We discuss these strategies below as both potential explanations for the observed bias as well as opportunities to inform future designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Hyperlocal Basis: The Subsampling Strategy</head><p>Myczek and Simons <ref type="bibr" target="#b61">[63]</ref> demonstrated that subsampling four objects from a larger collection can account for performance on size averaging. However, other studies show that people may need significantly more information to make sense of eight or more objects <ref type="bibr" target="#b4">[5]</ref>, far fewer than the number of marks in a typical visualization, with later work estimating that the number of samples must be closer to the square root of the number of marks <ref type="bibr" target="#b91">[93]</ref>. Using the centroid method, we can compute the minimum portion of marks, called the Efficiency, or Eff, required to converge onto our models in §6.2 (w, V , x de f ault and y de f ault ). In other words, this measure of efficiency quantifies the minimum number of objects that would have to be used in computing position mean to achieve the same level of performance achieved by the participants.</p><p>Given the residual sum of squares SS Residual derived using the centroid method, the standard error σ provides an unbiased estimate of the standard deviations of the random response errors Q t,x and Q t,x :</p><formula xml:id="formula_2">σ = SS Residual d f</formula><p>We assume as in prior work <ref type="bibr" target="#b4">[5]</ref> that all error in σ was due to the number of items unattended to by participants. To compute Eff, we use the technique from Sun et al. <ref type="bibr" target="#b81">[83]</ref> to calculate the variance of the difference between participants' responses and the predicted responses using w, V , x de f ault , and y de f ault after removing N marks. Starting by deleting only N = 1 mark from each stimulus scatterplot, this variance is iteratively computed for each possible number of marks that can be deleted until a single mark is remaining (0 &lt; N &lt; 30), terminating once the variance is greater than σ .</p><p>Averaging over the experimental conditions, our models in Figure <ref type="figure">7</ref> could have been achieved by attending to as little as 22.48% of marks (around 7 marks) in the lightness experiment, and 15.18% of marks (around 5 marks) in the size experiment, aligning with the square root of the number of marks predicted in Whitney &amp; Leib <ref type="bibr" target="#b91">[93]</ref>. These results may imply that people attend to a small number of marks when summarizing trivariate scatterplots. Our measured bias could arise if dark or large marks capture more attention and are disproportionately represented in participants' subsamples. If people are subsampling marks, then we anticipate that this bias may arise in other visualizations that use discrete marks, such as bar charts. This bias may be reduced by using continuous representations like kernel-density estimation <ref type="bibr" target="#b27">[28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.3">Global Basis: The Density Strategy</head><p>Attention filters in §6.2 varied as a function of both encoding ranges and correlations, suggesting that clustering darker and larger marks together may introduce other factors that increase the observed bias. One factor may be that the density across different spatial segments also pulls the perceived mean.</p><p>We use the term density to refer to any of three mechanisms possibly involved numerosity estimation in a group of marks: subitization (when discriminating 10 or fewer data points), estimation (for more than 10 data points), and low spatial frequency features such as texture density or contrast energy <ref type="bibr" target="#b66">[68]</ref> (for review, see Picon et al. <ref type="bibr" target="#b64">[66]</ref>). People can estimate the densities of overlapping dot textures of different colors in parallel <ref type="bibr" target="#b35">[36]</ref> and visualization techniques leverage density to deal with challenges like overdraw <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b54">56]</ref>.</p><p>When a scatterplot depicts a third data dimension and this dimension is correlated with position, the resulting clusters will share the same visual features. For example, a bubblechart will have clusters of mostly large and mostly small dots. When clusters emerge, the visual system may immediately segment the scene and then estimate the density of the resulting segments <ref type="bibr" target="#b30">[31]</ref>.</p><p>Some participants might have computed the midpoint of those centroid estimates, weighted by estimates of density in each segment. Prior work confirmed that large or dark points clustering together within an area creates illusions of higher point density <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b52">54,</ref><ref type="bibr" target="#b59">61,</ref><ref type="bibr" target="#b64">66,</ref><ref type="bibr" target="#b86">88]</ref>. If people use the positions and densities of spatial segments to estimate the overall mean, these illusions will bias the mean towards clusters that contain large or dark marks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Limitations &amp; Future Work</head><p>We investigated two common visual channels-size and color-that are frequently used to encode additional information in scatterplots. However, the simplicity of scatterplots affords a large space of potential designs that may offer different perceptual trade-offs <ref type="bibr" target="#b75">[77]</ref>. Future work might consider these alternatives to understand the robustness of mean position perception across scatterplot designs and how this bias may influence a broader range of ensemble tasks like correlation and variance estimation. For example, the centroid method employed here could be used to understand biases introduced by a range of visual variables for both categorical and numeric data. Further, we measured weights along a small set of size and lightness ranges. While these weights allow us to reasonably estimate the probable location of a perceived mean over these ranges, we do not have sufficient data for a fully predictive model. Modeling weights across a wider range of factors may enable robust bias predictions across a range of encoding lengths and designs.</p><p>Our experimental stimuli were generated according to Poisson disk sampling, creating random dot textures. While these textures contain a range of clusters and structures, real datasets often have additional global features that can cause data points to more strongly cluster. These factors could introduce additional biases in realistic scatterplots and may limit the generalizability of the computed weights. Additionally, our data generation approach led to scatterplots where the direction of correlation was slightly displaced from the true diagonal. Although these displacements are small and randomly distributed, since we define bias as the magnitude of the error vectors projected onto the diagonals, the bias illustrated in Figure <ref type="figure">6</ref> may underestimate the true bias.</p><p>While our crowdsourcing study led to consistent results, the attention filters derived in §5.2 may vary across individuals. For example, certain people can discount the contribution of peripheral objects toward the mean <ref type="bibr" target="#b25">[26]</ref>. These individual differences may shift the ways people reason about means, especially for visualizations targeting data within specific areas of expertise <ref type="bibr" target="#b48">[49]</ref>. Disciplines may exaggerate bias by introducing semantic factors such as context or risk that add mental "weight" to critical data. Future work might leverage the centroid method to model these individual differences under varying data contexts to the influence of disciplinary knowledge and other factors on bias.</p><p>Lastly, we identified two potential strategies that might explain the observed bias. Given that feature-based attention operates prior to voluntary eye movements <ref type="bibr" target="#b55">[57]</ref> and constraints of the COVID-19 pandemic, we did not incorporate eye tracking in our study. However, eye-tracking may provide further insight into these strategies. Future work should combine the centroid computation and eye tracking, both state-of-the-art behavioral markers for studying visuospatial attention, to investigate the subsampling and density hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>Our abilities to estimate summary statistics from scatterplots may be sensitive to attributes of the scatterplot design and underlying data <ref type="bibr" target="#b49">[51]</ref>. We conducted a crowdsourced experiment investigating how irrelevant channels, the ranges of those channels, and their relationhips with the position channel may shift the position mean. We found that the perceived mean position in a scatterplot is biased in the direction of larger, and to a lesser extent, darker marks. We model the contribution of different elements of a visualization design towards this bias using the centroid method, a statistical technique from vision science, offering designers a way to predict weights people give to a given mark.</p><p>Our results raise new opportunities at the intersection of visualization and vision science: we elucidate a systematic bias that gives insight into feature-based attention in visualization as well as a variety of ensemble strategies that can be employed in visualization interpretation and decision making. For designers, modeling bias as a function of design choices and data patterns allows designers to avoid misleading practices and experienced graph readers to notice and correct for potential bias.</p><p>Research in visualization biases tend to develop in parallel with research in visualization literacy, since biases often arise when readers are not familiar with a visualization <ref type="bibr" target="#b53">[55]</ref>. The weighted average illusion adds to the growing literature of biases <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b67">69,</ref><ref type="bibr" target="#b88">90,</ref><ref type="bibr" target="#b94">96]</ref> that may affect interpretations of even the most familiar visualizations.</p><p>In our pilot studies, even visualization experts had a hard time avoiding this bias, likely naming justifications for weighing point marks differently, such as: "What if the size channel represented population size?" We emphasize that this illusion is a misjudgment regardless of what lightness or size represents, since weighted scatterplot means change with the ranges of visual channels a designer chose to map the data onto. By elucidating these biases, we can both promote honest communication in visualization practice, and guide the development of data literacy for everyone.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. We mapped the third dimension in trivariate scatterplots to one of three size or lightness ranges (shown here to scale). Steps in pixel diameter and L* values are evenly spaced, with the midpoints of all ranges being identical. Every scatterplot stimulus contained seven different mark sizes or lightness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Fig.3. To ensure comprehension, we stepped participants through the target task, steadily building in more information. The tutorial images above were presented serially with the following instructions: 1. Scatterplots reduce information about two measures into a single data point. 2. On this scatterplot, 30 countries are presented in terms of their life expectancies and income levels. 3. Therefore, the pink dot alone represents both the average life expectancy and the average income of the 30 countries shown. 4. Each point on a scatterplot can also depict a third variable, such as unemployment rate. After viewing the tutorial, participants were instructed that: "In the following study, you are asked to estimate and click on the average position of all points (i.e., average life expectancy and average income of all countries) on each scatterplot."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig.4. The formal study consisted of five steps. A grey mask (1) would be replaced by a fixation cross (2) to guide participant attention. Participants would then see a scatterplot (3) and report the perceived mean position by clicking on the corresponding location in the scatterplot, with the cross moving with the cursor. We would visually indicate the reported value (4) and then ask participants to click on a link at the center of the screen (5) to recenter their mouse before the next trial.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 Fig. 8 .</head><label>88</label><figDesc>Figure 8-1. Subsampling Figure 8-2. Density strategy</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported in part by NSF awards BCS-1632222, SES-2030059, IIS-2046725, IIS-1764092, and IIS-1764089.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Clustme: A visual quality measure for ranking monochrome scatterplots based on cluster patterns</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aupetit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bensmail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="225" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Task-driven evaluation of aggregation in time series visualization</title>
		<author>
			<persName><forename type="first">D</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="551" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Perceptual Biases in Font Size as a Data Encoding</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shimabukuro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2723397</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2397" to="2410" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Representing multiple objects as an ensemble enhances visual cognition</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2011.01.003</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The representation of simple ensemble visual features outside the focus of attention: Research article</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2008.02098.x</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="392" to="398" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Seeing sets: Representation by statistical properties</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ariely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="162" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Semiology of Graphics: Diagrams, Networks, Maps (Translated by William J. Berg)</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bertin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>University of Wisconsin Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Why Shouldn&apos;t All Charts Be Scatter Plots? Beyond Precision-Driven Visualizations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<idno type="DOI">10.1109/vis47514.2020.00048</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="206" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rainbow color map (still) considered harmful</title>
		<author>
			<persName><forename type="first">D</forename><surname>Borland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M T</forename><surname>Ii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer graphics and applications</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="14" to="17" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Open vs. closed shapes: New perceptual categories?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Burlinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Goolkasian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="574" to="583" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Studying Biases in Visualization Research: Framework and Methods. Cognitive Biases in Visualizations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Valdez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ziefle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-95831-62</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="13" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual attention: The past 25 years</title>
		<author>
			<persName><forename type="first">M</forename><surname>Carrasco</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2011.04.012</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1484" to="1525" />
			<date type="published" when="2011-07">July 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The ishihara test for color blindness</title>
		<author>
			<persName><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Physiological Optics</title>
		<imprint>
			<date type="published" when="1924">1924</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Graphical perception: Theory, experimentation, and application to the development of graphical methods</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1984.10478080</idno>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Ensemble Perception, Summary Statistics, and Perceptual Awareness: A Response</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Dennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2016.06.007</idno>
		<imprint>
			<date type="published" when="2016-09">sep 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Comparing averages in time series data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1095" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Truncating the y-axis: Threat or menace?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Black hat visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Dealing with Cognitive Biases in Visualisations (DECISIVe), IEEE VIS</title>
				<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Regression by eye: Estimating trends in bivariate visualizations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2017 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1387" to="1396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A common visual metric for approximate number and density</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Dakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Tibber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Greenwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Kingdom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Morgan</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1113195108</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">49</biblScope>
			<biblScope unit="page" from="19552" to="19557" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The computation of orientation statistics from visual texture</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Dakin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Watt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="3181" to="3192" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning perceptual kernels for visualization design</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">¸</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1933" to="1942" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mitigating the Attraction Effect with Visualizations</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dimara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bailly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2865233</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="850" to="860" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A task-based taxonomy of cognitive biases for information visualization</title>
		<author>
			<persName><forename type="first">E</forename><surname>Dimara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bezerianos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fair statistical communication in hci</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modern statistical methods for HCI</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="291" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Precise attention filters for Weber contrast derived from centroid estimations</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Chubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sperling</surname></persName>
		</author>
		<idno type="DOI">10.1167/10.10.20</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">2010</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Texture Density Adaptation and the Perceived Numerosity and Distribution of Texture</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H</forename><surname>Durgin</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.21.1.149</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="149" to="169" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Enhancing scatterplots with smoothed densities</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Eilers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Goeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="623" to="628" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Objects, Sets, and Ensembles. Space, Time and Number in the Brain</title>
		<author>
			<persName><forename type="first">L</forename><surname>Feigenson</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-0-12-385948-8.00002-5</idno>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="13" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Some problems in interval estimation</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Fieller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Number estimation relies on a set of segmented objects</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Bemis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2009.07.002</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2009-10">oct 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Interaction of stimulus dimensions in concept and choice processes</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Garner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="123" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The interplay between nonsymbolic number and its continuous visual properties</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gebuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Reynvoet</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0026218</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="642" to="648" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Perception of average value in multiclass scatterplots</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nothelfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.183</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2316" to="2325" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Ensemble perception: Summarizing the scene and broadening the limits of visual processing. From perception to consciousness: Searching with Anne Treisman</title>
		<author>
			<persName><forename type="first">J</forename><surname>Haberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="339" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multiple spatially overlapping sets can be enumerated in parallel</title>
		<author>
			<persName><forename type="first">J</forename><surname>Halberda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Sires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Feigenson</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2006.01746.x</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="572" to="576" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">How Capacity Limits of Attention Influence Information Visualization Effectiveness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">How capacity limits of attention influence information visualization effectiveness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Haroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Ranking visualizations of correlation using weber&apos;s law</title>
		<author>
			<persName><forename type="first">L</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1943" to="1952" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ColorBrewer.org: An Online Tool for Selecting Colour Schemes for Maps</title>
		<author>
			<persName><forename type="first">M</forename><surname>Harrower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Brewer</surname></persName>
		</author>
		<idno type="DOI">10.1179/000870403235002042</idno>
	</analytic>
	<monogr>
		<title level="j">The Cartographic Journal</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="37" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attention and Visual Memory in Visualization and Computer Graphics</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2011.127</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1170" to="1188" />
			<date type="published" when="2012-07">jul 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Crowdsourcing graphical perception: using mechanical turk to assess visualization design</title>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on human factors in computing systems</title>
				<meeting>the SIGCHI conference on human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">What&apos;s going on in this graph? -easing lockdowns. The New York Times</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hessney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dickensheets</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-12">Dec 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">What&apos;s going on in this graph?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hessney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The New York Times</title>
				<imprint>
			<date type="published" when="2019-04-17">april 17, 2019. Apr 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Comparing set summary statistics and outlier pop out in vision</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hochstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pavlovskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Bonneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Soroker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="12" to="12" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Visualint: Sketchy in situ annotations of chart construction errors</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="219" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Sometimes area counts more than number</title>
		<author>
			<persName><forename type="first">F</forename><surname>Hurewitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schnitzer</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0609485103</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">51</biblScope>
			<biblScope unit="page" from="19599" to="19604" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Evidence against global attention filters selective for absolute bar-orientation in human vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Inverso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sperling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="293" to="308" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">What geoscience experts and novices look at, and what they see, when viewing data visualizations</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Kastens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Shipley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Boone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Straccia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Astronomy &amp; Earth Sciences Education</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="58" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Assessing Effects of Task and Data Distribution on the Effectiveness of Visual Encodings</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno>doi: 10. 1111/cgf.13409</idno>
	</analytic>
	<monogr>
		<title level="j">Technical Report</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Do mechanical turks dream of square pie charts?</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ziemkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd BELIV&apos;10 Workshop: Beyond time and errors: Novel evaluation methods for information visualization</title>
				<meeting>the 3rd BELIV&apos;10 Workshop: Beyond time and errors: Novel evaluation methods for information visualization</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Visual comparison of two data sets: Do people use the means and the variability?</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Telfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Towler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">When the weaker conquer: A contrast-dependent illusion of visual numerosity</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Reeves</surname></persName>
		</author>
		<idno type="DOI">10.1167/18.7.8</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2018-07">jul 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Data Visualization Literacy and Visualization Biases: Cases for Merging Parallel Threads. Cognitive Biases in Visualizations</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mansoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Harrison</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-95831-67</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="87" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Splatterplots: Overcoming overdraw in scatter plots</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mayorga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1526" to="1538" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Spatial Attention, Feature-Based Attention, and Saccades: Three Sides of One Coin?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Mazer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biopsych.2011.03.014</idno>
	</analytic>
	<monogr>
		<title level="j">Biological Psychiatry</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1147" to="1152" />
			<date type="published" when="2011-06">jun 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Linting for visualization: Towards a practical automated visualization guidance system</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcnutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VisGuides: 2nd Workshop on the Creation, Curation, Critique and Conditioning of Principles and Guidelines in Visualization</title>
				<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Surfacing visualization mirages</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mcnutt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Towards perceptual optimization of the visual design of scatterplots</title>
		<author>
			<persName><forename type="first">L</forename><surname>Micallef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Palmas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oulasvirta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Weinkauf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1588" to="1599" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A textureprocessing model of the &apos;visual sense of number</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Raphael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Tibber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Dakin</surname></persName>
		</author>
		<idno>doi: 10.1098/ rspb.2014.1137</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">281</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="1790">1790. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Marks and Channels</title>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<idno type="DOI">10.1201/b17511-5</idno>
	</analytic>
	<monogr>
		<title level="m">Visualization Analysis and Design</title>
				<imprint>
			<publisher>A K Peters/CRC Press</publisher>
			<date type="published" when="2018-07">jul 2018</date>
			<biblScope unit="page" from="95" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Better than average: Alternatives to statistical summary representations for rapid judgments of average size</title>
		<author>
			<persName><forename type="first">K</forename><surname>Myczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Simons</surname></persName>
		</author>
		<idno type="DOI">10.3758/PP.70.5.772</idno>
	</analytic>
	<monogr>
		<title level="j">Perception and Psychophysics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="772" to="788" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">How deceptive are deceptive visualizations? an empirical analysis of common distortion techniques</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Rall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Satterthwaite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Nov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</title>
				<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1469" to="1478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Where income is higher, life spans are longer. The New York Times</title>
		<author>
			<persName><forename type="first">A</forename><surname>Parlapiano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-03">Mar 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Visual illusions help reveal the primitives of number perception</title>
		<author>
			<persName><forename type="first">E</forename><surname>Picon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dramkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Odic</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000553</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1675" to="1687" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Chapter 4: A Theory of Graph Comprehension</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pinker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and the future of testing</title>
				<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Different reactiontimes for subitizing, estimation, and texture</title>
		<author>
			<persName><forename type="first">A</forename><surname>Pomè</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Anobile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Cicchini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Burr</surname></persName>
		</author>
		<idno type="DOI">10.1167/19.6.14</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019-06">jun 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Impact of Cognitive Biases on Progressive Visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Procopio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mosca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<idno>doi: 10. 1109/TVCG.2021.3051013</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">2626</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Examining implicit discretization in spectral schemes</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Quinan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Padilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Creem-Regehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.13695</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="363" to="374" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">On the prospects for a science of visualization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of human centric visualization</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="147" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The perception of correlation in scatterplots</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Baldridge</surname></persName>
		</author>
		<idno>doi: 10.1111/j. 1467-8659.2009.01694.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1203" to="1210" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A lie reveals the truth: Quasimodes for task-aligned data presentation</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wigdor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">How can observers use perceived size? Centroid versus meansize judgments</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Rodriguez-Cintron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sperling</surname></persName>
		</author>
		<idno type="DOI">10.1167/19.3.3</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019-03">mar 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Health advocacy with gapminder animated statistics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Rosling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of epidemiology and global health</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="14" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Simple is good: Observations of visualization use amongst the big data digerati</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Working Conference on Advanced Visual Interfaces</title>
				<meeting>the International Working Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Scatterplots: Tasks, Data, and Designs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2744184</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="402" to="412" />
			<date type="published" when="2018-01">jan 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A Taxonomy of Visual Cluster Separation Factors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2012.03125.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3pt4</biblScope>
			<biblScope unit="page" from="1335" to="1344" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Estimating the influence of attention on population codes in human visual cortex using voxel-based tuning functions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Serences</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saproo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scolari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Muftuler</surname></persName>
		</author>
		<idno>doi: 10. 1016/j.neuroimage.2008.07.043</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="223" to="231" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Measuring the separability of shape, size, and color in scatterplots</title>
		<author>
			<persName><forename type="first">S</forename><surname>Smart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300899</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Human Factors in Computing Systems -Proceedings</title>
				<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019-05">may 2019</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Uncertainty, Judgment, and Error in Prediction</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Stewart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Human attention filters for single colors</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sperling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">43</biblScope>
			<biblScope unit="page" from="E6712" to="E6720" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">The centroid paradigm: Quantifying feature-based attention in terms of attention filters. Attention, Perception, and Psychophysics</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sperling</surname></persName>
		</author>
		<idno>doi: 10.3758/ s13414-015-0978-2</idno>
		<imprint>
			<date type="published" when="2016-02">feb 2016</date>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="474" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">High-capacity preconscious processing in concurrent groupings of colored dots</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chubb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sperling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">52</biblScope>
			<biblScope unit="page" from="E12153" to="E12162" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Modeling color difference for visualization design</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="392" to="401" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">The good, the bad, and the biased: five ways visualizations can mislead (and how to fix them). interactions</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Four types of ensemble coding in data visualizations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haroz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<idno type="DOI">10.1167/16.5.11</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">2016</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Number and density discrimination rely on a common metric: Similar psychophysical effects of size, contrast, and divided attention</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Tibber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Greenwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Dakin</surname></persName>
		</author>
		<idno type="DOI">10.1167/12.6.8</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="8" to="8" />
			<date type="published" when="2012-06">jun 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Saliency deficit and motion outlier detection in animated scatterplots</title>
		<author>
			<persName><forename type="first">R</forename><surname>Veras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2019 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Overestimation of Variability in Ensembles of Line Orientation, Size, and Hue</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Witt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dodd</surname></persName>
		</author>
		<idno type="DOI">10.1167/jov.20.11.1240</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1240</biblScope>
			<date type="published" when="2020-10">oct 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Information visualization: perception for design</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Evaluating Perceptual Bias During Geometric Scaling of Scatterplots</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934208</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Ensemble perception. Annual review of psychology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Yamanashi</forename><surname>Leib</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="105" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Graph construction: Setting the range of the y-axis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Witt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Meta-Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">The perceptual experience of variability in line orientation is greatly exaggerated</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Witt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1083</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Biased Average Position Estimates in Line and Bar Graphs: Underestimation, Overestimation, and Perceptual Pull</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Ceja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934400</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="301" to="310" />
			<date type="published" when="2020-07">jul 2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
