<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">COVID-view: Diagnosis of COVID-19 using Chest CT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Shreeraj</forename><surname>Jadhav</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gaofeng</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marlene</forename><surname>Zawin</surname></persName>
						</author>
						<author>
							<persName><roleName>Fellow, IEEE •</roleName><forename type="first">Arie</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science at</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Radiology at Stony</orgName>
								<orgName type="institution">Brook University Hospital</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">COVID-view: Diagnosis of COVID-19 using Chest CT</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0CE40328FE6FA8E03FE54845359AF9E6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T13:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>(sdjadhav</term>
					<term>dgaofeng</term>
					<term>ari)@cs.stonybrook.edu *Equal contribution</term>
				</keywords>
			</textClass>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-Significant work has been done towards deep learning (DL) models for automatic lung and lesion segmentation and classification of COVID-19 on chest CT data. However, comprehensive visualization systems focused on supporting the dual visual+DL diagnosis of COVID-19 are non-existent. We present COVID-view, a visualization application specially tailored for radiologists to diagnose COVID-19 from chest CT data. The system incorporates a complete pipeline of automatic lungs segmentation, localization/isolation of lung abnormalities, followed by visualization, visual and DL analysis, and measurement/quantification tools. Our system combines the traditional 2D workflow of radiologists with newer 2D and 3D visualization techniques with DL support for a more comprehensive diagnosis. COVID-view incorporates a novel DL model for classifying the patients into positive/negative COVID-19 cases, which acts as a reading aid for the radiologist using COVID-view and provides the attention heatmap as an explainable DL for the model output. We designed and evaluated COVID-view through suggestions, close feedback and conducting case studies of real-world patient data by expert radiologists who have substantial experience diagnosing chest CT scans for COVID-19, pulmonary embolism, and other forms of lung infections. We present requirements and task analysis for the diagnosis of COVID-19 that motivate our design choices and results in a practical system which is capable of handling real-world patient cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index Terms-Visual+deep learning diagnosis, COVID-19, chest CT, volume rendering, MIP, classification model, explainable DL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The Coronavirus disease 2019 (COVID- <ref type="bibr" target="#b18">19)</ref> is caused by the SARS-CoV-2 virus and may lead to severe respiratory symptoms (e.g., shortness of breath, chest pain), hospitalization, ventilator support, and even death. The real-time reverse transcriptase polymerase chain reaction (RT-PCR) lab test is commonly used for screening patients and is considered the reference standard for diagnosis. However, none of the lab tests, including RT-PCR, are 100% accurate. For example, sensitivity of RT-PCR depends on the timing of specimen collection <ref type="bibr" target="#b42">[43]</ref>. Chest CT was found to have significant sensitivity for diagnosing COVID-19 <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b32">33]</ref>. While the role of chest CT in diagnosis continues to evolve, there is no universal consensus on its usage and recommendation. Med-ical practitioners often recommend a chest CT scan as a complement diagnostic test to RT-PCR, or as clinical triage if the patient have severe symptoms that require immediate attention. For example, chest CT can help in ruling out pulmonary embolism (PE) <ref type="bibr" target="#b20">[21]</ref> which has overlapping symptoms with COVID-19. Consequently, chest CT remains an important modality for diagnosis, as well as management and prognosis of suspected COVID-19 cases that lead to hospitalization, intensive care unit (ICU) admission, and ventilation.</p><p>Significant amount of research on automatic detection, segmentation, and classification of various diseases (e.g., cancer) in medical imaging have been driven by advances in deep learning (DL) and artificial intelligence (AI). Similar approaches were also developed recently for detection <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b71">72]</ref> and segmentation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref> of COVID-19 lesions on chest X-ray and CT images. However, these automatic methods remain secondary to the expertise of an experienced radiologist performing manual visual diagnosis on medical images. Very few applications are currently available that are particularly tailored to support visual diagnosis of COVID-19 that keeps the radiologists in the loop and enhances their workflow. We have developed COVID-view, an elaborate application for visual diagnosis of COVID-19 from chest CT data that integrates DL-based automatic analysis with interactive visualization. We incorporate a complete application pipeline from automatic segmentation of lungs, localization of lung abnormalities, traditional 2D views, a suite of contemporary 3D and 2D visualizations suitable for COVID-19 diagnosis, quantification tools that can help in measuring the volume and extent of the lung abnormalities, and a novel automatic classification model along with visualized activation heatmap that act as a second reader of the CT scan.</p><p>Our contributions are as follows:</p><p>• A novel, automatic and effective DL classification model for classifying patients into COVID positive or negative types with good interpretability. • A novel dual visualization-DL application, COVID-view, for the diagnosis of COVID-19 using chest CT, above and beyond current workflow of radiologists. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>A comprehensive visual diagnostic pipeline includes indispensable components such as the segmentation of relevant anatomy, detection and segmentation of abnormalities, automatic characterization and analysis of the abnormalities, and interactive visualization tools for qualitative and quantitative analysis. Each components may use automatic or semi-automatic methods based on desired accuracy, user control, and availability of training data. Examples of applications include virtual colonoscopy <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b69">70]</ref>, virtual bronchoscopy <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b38">39]</ref>, and virtual pancreatography <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b33">34]</ref>. Here, we restrict our discussion to work related to lungs segmentation, visualization and COVID-19 diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lungs Segmentation</head><p>Segmentation is a critical backend operation for visualization and diagnostic applications. Typically, transfer functions are effective only locally and do not overcome global occlusion and clutter. Segmentation of lungs <ref type="bibr" target="#b4">[5]</ref> and its internal anatomical structures, such as the bronchial tree <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b64">65]</ref> and blood vessels <ref type="bibr" target="#b73">[74]</ref>, can provide greater control over the 3D rendering and visual inspection tools. Techniques for vessel segmentation in chest CT range from local geometry-based methods such as vesselness filters <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b34">35]</ref> that utilize a locally-computed Hessian matrix to determine the probability of vascular geometry, to more sophisticated methods utilizing supervised DL. Some methods also attempt a hybrid approach to combine vesselness filters and machine learning <ref type="bibr" target="#b40">[41]</ref>. Lo et al. <ref type="bibr" target="#b47">[48]</ref> have conducted a comparative study of methods for bronchial tree segmentation. Other methods focus on segmenting the entire lungs and identifying the interior lobes <ref type="bibr" target="#b65">[66]</ref>. Segmenting healthy lungs can be easier than diseased lungs since the geometry of the lungs and its internal features can change drastically with a disease. Segmentation in chest CT plays an essential role in lesion quantification, diagnosis and severity assessment of COVID-19 by delineating regions of interest (ROIs) (e.g., lung, lobes, infected areas). Segmentation related to COVID-19 from chest CT could be categorized into two groups: lung segmentation and lesion segmentation. The popular classic segmentation models including U-Net <ref type="bibr" target="#b55">[56]</ref> and Deeplabv3 <ref type="bibr" target="#b7">[8]</ref> and their variants are widely used for COVID-19. Wang et al. <ref type="bibr" target="#b66">[67]</ref> have trained a U-Net using lung masks generated by an unsupervised learning method and then used the pre-trained U-Net to segment lung regions. Zhang et al. <ref type="bibr" target="#b72">[73]</ref> have constructed a lung-lesion segmentation framework with five classic segmentation models as the backbone to segment background, lung fields, and five lesions. Fan et al. <ref type="bibr" target="#b16">[17]</ref> have developed a lung infection segmentation deep network (Inf-Net) for COVID-19 and proposed a semi-supervised learning framework to alleviate the shortage of labeled data. Hofmanninger et al. <ref type="bibr" target="#b27">[28]</ref> have compared four generic deep learning models (U-Net, ResU-Net, DRN, Deeplab v3+) for lung segmentation using various datasets, and have further trained a model for diseased lungs. We found this model to be fairly robust for COVID-19 cases, and therefore, we have adapted this model for our COVID-view application pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">COVID-19 Classification</head><p>Computer-aided diagnosis (CAD) of COVID-19 can assist the radiologists, as it is not only instantaneous but also can reduce errors caused by radiologists' visual fatigue and lack of training. The rapid increase in the number of suspected or known COVID-19 patients has posed tremendous challenge to radiologists regarding the increasing amount of work. CAD of COVID-19 can act as a second reader and thus help the radiologists. A common problem for developing a CAD system is weakly annotated data in CT images, where usually only patient-level diagnosis label is available. Some studies developed their diagnosis systems using the result of lesion segmentation <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b72">73]</ref>. They firstly trained a lesion segmentation model and then input the segmented lesion to the classification model. However, manual annotation of lesion masks for training the segmentation model is very expensive. Another type of method is slice-based <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b49">50]</ref>. The slice-wise decisions obtained by a 2D classification model are fused to get the final classification result for the CT volume. Similarly, the manual selection of the infected slices among all the CT slices is of high cost. Some other diagnosis techniques were developed with 3D convolutional neural networks (CNNs) <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b66">67]</ref>. While 3D CNN can capture the spatial features, the complexity of the 3D convolution makes it harder to interpret. Besides, 3D CNN usually requires more GPU memory, which makes it difficult to be trained on machines with limited GPU memory size.</p><p>Here, we build a COVID-19 classification model based on deep multiple instance learning (MIL) to address the problem of weakly annotated data in chest CT. Our COVID-view integrates this effective and efficient model as a second reader to assist the radiologist. Furthermore, it provides the class activation heatmap generated by Grad-CAM <ref type="bibr" target="#b61">[62]</ref> to visualize important regions used for the classification model decisions, making it more transparent and explainable to the radiologists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visualization and Diagnostic Systems</head><p>Many visual diagnostic systems for lungs focus on the paradigm of virtual endoscopy <ref type="bibr" target="#b22">[23]</ref> and path planning and navigation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b63">64]</ref>. Region-growing <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref> has been proposed for isolating and visualizing the lungs and their internal features. Lan et al. <ref type="bibr" target="#b44">[45]</ref> have used the selection of voxels over intensity-gradient histograms and spatial connectivity for visualizing lungs and their structures. Automatic semantic labeling of bronchial tree <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b64">65]</ref> can support further analysis and visualization. Volume deformation <ref type="bibr" target="#b57">[58]</ref> and context preserving planar reformations <ref type="bibr" target="#b48">[49]</ref> are deployed for managing occlusions, partial abstraction or visual simplification. Wang et al. <ref type="bibr" target="#b68">[69]</ref> have proposed DL model for reconstruction of lungs 3D/4D geometry from 2D images (e.g., X-Ray). Hemminger et al. <ref type="bibr" target="#b26">[27]</ref> have developed a 3D lungs visualization application for cardiothoracic surgical planning (e.g., for lung transplant and tumor resection). To the best of our knowledge, there are no COVID-19 oriented 3D visualization systems that focus on supporting radiologists' visual diagnosis workflow, such as COVID-view. Some of the DL-based classification models only incorporate restricted 2D visualizations on CT or X-ray images, in the form of Grad-CAM activation or localization heatmaps <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b71">72]</ref>. The Coronavirus-3D visualization system <ref type="bibr" target="#b60">[61]</ref> presents only a dashboard for tracking SARS-Cov-2 virus mutations and 3D structure analysis of related proteins.</p><p>Many general-purpose open source software (e.g., 3D Slicer <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b54">55]</ref>, ParaView <ref type="bibr" target="#b1">[2]</ref>, MeVisLab <ref type="bibr" target="#b25">[26]</ref>) support image analysis and volume visualization tasks. These in turn extend their abilities by building upon or integrating open source libraries (e.g., VTK <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b59">60]</ref>, ITK <ref type="bibr" target="#b30">[31]</ref>) that provide an extensive breadth of image and geometry processing, and rendering techniques. Our COVID-view is specifically designed with chest CT inspection in mind. We implement COVID-view ground-up using VTK and Qt with a simplified and essential interface. It could have also been implemented using other open source frameworks (e.g., ParaView, 3D Slicer, or MeVisLab). However, beyond implementing a specialized application, our contributions in COVID-view are the selection and curation of essential tools and interface for chest CT inspection through collaboration with expert radiologists who are experienced in inspecting chest CT for COVID-19. Our pipeline also seamlessly integrates lungs and lesions automatic segmentation, novel COVID-19 classification, and incorporates appropriate results from these models (classification probabilities, activation maps, automatic measurements) that do not come out-of-the-box in general software frameworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">COVID-19 BACKGROUND AND TASK ANALYSIS</head><p>While there is no universal consensus on the usage of chest CT for COVID-19 diagnosis, some practitioners request chest CT for patient management, both confirmed and unconfirmed cases, to complement lab tests (RT-PCR) which suffer from inaccuracies. To improve the accuracy of CT, various approaches have been reported. For instance, Fan et al. <ref type="bibr" target="#b51">[52]</ref> divided the course of COVID into four temporal stages to account for differing CT findings. A recent report <ref type="bibr" target="#b56">[57]</ref> shows that lung involvement (lesion volume percentage with respect to the lungs) is a good predictor of patient outcome in terms of ICU admission and death. In this section, we discuss the manifestation and appearance of COVID-19 lung abnormalities in chest CT as relevant to visual diagnosis. However, these imaging features are not unique to COVID-19 (not pathognomonic) and can be caused by other infections. Particularly, our system design choices focus on four prominent lung lesions: ground glass opacities (GGOs), consolidations, interlobular septal thickening (IST), and vascular pathology (i.e., dilation of blood and air vessels). There are numerous other reported abnormalities/lesions <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b43">44]</ref>, but they occur less frequently in COVID-19. Apart from the lesion type, its locations, distribution, and left-right lung symmetry are also critical in assessing the patients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">COVID-19 Chest-CT Imaging Features</head><p>Ground Glass Opacity (GGO): GGO is the most common chest CT feature of COVID-19. It appears as low intensity regions (as compared to lung vessels) around the lung vessels usually in the periphery of the lungs. Fig. <ref type="figure" target="#fig_1">2a</ref> shows an example axial image with GGO. Early stage GGO is often unilateral (i.e., in one lung), whereas intermediate and late stage GGOs often have peripheral and bilateral distribution.</p><p>Consolidations: Consolidations are formed when GGOs translate into denser regions over time. They appear as solid mass on the CT images (see Fig. <ref type="figure" target="#fig_1">2b</ref>). Similar to GGOs, they have peripheral distribution, unilateral in early stage and bilateral in intermediate and late stage.</p><p>Interlobular Septal Thickening (IST): The septal walls between lobes can thicken due to COVID-19. They are difficult to locate, as they are very similar to blood vessels in the planar views (see Fig. <ref type="figure" target="#fig_1">2c</ref>).</p><p>Vascular Pathology: Blood vessels within the lungs can show abnormalities such as enlargement or dilation (see Fig. <ref type="figure" target="#fig_1">2d</ref>), particularly within the neighborhood of other abnormalities (e.g., GGO). Similarly, the bronchial tree vessels (air-ways) show abnormally thicker walls. These imaging features are very subtle and not always discernible.</p><p>Additional imaging features related to COVID-19 include intralobular septal thickening which often appears as crazy paving pattern on the planar images, and mixing of GGO and consolidation morphology resulting in halo and reverse-halo signs. A comprehensive list of features and their frequency of occurrences in COVID positive patients is discussed by Homsi et al. <ref type="bibr" target="#b14">[15]</ref> and by Kwee et al. <ref type="bibr" target="#b43">[44]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Requirements and Task Analysis</head><p>We discuss here the conventional workflow of radiologists while diagnosing COVID-19 on chest CT scans, and determine high-level tasks that are commonly performed. The analysis of 2D chest CT images follows a largely conventional workflow, though the tasks performed and their order may vary between practicing radiologists. A chest CT scan is ordered not only for the singular task of diagnosing COVID-19 and its severity, but also due to other possible conditions that may require urgent attention, such as pulmonary embolism (PE). Thus, apart from examining the lungs, the radiologist often performs a holistic analysis of other regions, such as the heart and vascular structures in the lungs proximity, swelling of axillary lymph nodes, as well as searching for the presence of other lesions and abnormalities throughout the CT scan.</p><p>In the conventional 2D workflow, the radiologist may begin with identifying the range of slices (and extents within the slices) within which the lungs are contained, by observing the extremities and lungs boundary (Task T1). This task also includes inspection of the lung boundaries for abnormal/stiffness of shape. The radiologist will also adjust the gray scale map to improve contrast between the lungs background and the vascular structures such as the bronchial tree (Task T2), the arteries, and the veins inside the lungs.</p><p>The radiologist then scans through the identified range of 2D axial planes for lung abnormalities listed in Sec. 3.1, the most common of which are GGOs and consolidations (Task T3). In addition, the radiologist will determine the location and distribution of these abnormalities (Task T4). Peripheral and bilateral distributions are characteristic of COVID-19 diagnosis. The radiologist will also look for more subtle abnormalities, such as interlobular and intralobular septal thickening and vascular enlargements (Task T5). Early stage abnormalities can be subtle and hard to detect, which requires careful and comprehensive inspection of the lungs. Furthermore, the radiologist may measure the lesions (e.g., GGO) to determine the growth or severity of the disease (Task T6), helping in patient management and prognosis. A radiologist experienced in COVID-19 diagnosis confirmed these high-level tasks, and that currently they do not use any 3D visualization tools.</p><p>While these tasks are identified in the conventional 2D workflow, our design choices and visualization tools translate these tasks to include them in the combined 3D/2D workflow. 3D visualization of the segmented lungs can provide a holistic view of lungs and lesions to identify the distribution of affected areas. While a similar assessment can also be made using 2D slice views, our 3D visualizations provide an alternate viewpoint that can further inform the radiologist beyond their usual workflow. As shown in our case studies (Case 3), 3D can also make IST identification easier than in 2D views. Additionally, it has been generally accepted that 3D visualizations can be better in inspecting vascular structures such as bronchial trees and blood vessels in the lungs and elsewhere. While GGO and consolidations are macrolevel structures easily seen in 2D slices, inspection of more subtle abnormalities such as smaller opacity regions, vascular enlargements, and septal thickening can benefit from 3D visualizations.</p><p>In addition to supporting these identified tasks, we design our system to fully support their conventional 2D workflow. This also helps in rare events when the system fails to compute the necessary information such as the segmentation masks. In such cases, the radiologist can still continue to analyze the case using their conventional 2D workflow. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE COVID-view APPLICATION</head><p>We have designed the COVID-view application based on the requirements of the COVID-19 chest CT diagnosis and task analysis performed in Sec. <ref type="bibr" target="#b2">3</ref>. The high-level pipeline of COVID-view is shown in Fig. <ref type="figure" target="#fig_2">3</ref>, and incorporates all the important components for such a visual diagnostic system, including automatic lung segmentation, automatic lesions and abnormalities segmentation, and novel ML model for classification of cases into COVID-19 negative/positive. All the modules are integrated into a single application and presented through a well-designed user interface. Since the modules use fully-automatic methods, the user does not have to interact with any of the pre-processing steps before the dataset and the processed information is loaded into the visualization interface. The lungs segmentation mask, lesion segmentation, and classification results are computed only once when a new dataset is loaded into the system. These results are then cached into the hard drive so that future loading and analysis of the CT scans happens faster, as re-computing these for every execution is time-consuming and unnecessary. We discuss each of the COVID-view modules and its user-interface and visualization tools in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lungs Segmentation</head><p>Use of a segmentation mask in a 3D rendering pipeline can provide significant control over the visualization process through deployment of local transfer functions and multi-label rendering. Global transfer functions have limited ability to control rendering occlusions and clutter in complex datasets (e.g., chest and abdominal CT scans). Existing visual diagnostic systems, such as virtual colonoscopy <ref type="bibr" target="#b28">[29]</ref> and virtual pancreatography <ref type="bibr" target="#b33">[34]</ref> also incorporate organ segmentation methods.</p><p>In COVID-view, we incorporate Hofmanninger et al. <ref type="bibr" target="#b27">[28]</ref> lungs segmentation model that was trained on a large variety of diseased lungs, encompassing different lesions and abnormalities with air pockets, tumors, and effusions, and includes COVID-19 data. In our tests, we found this model to be fairly robust on COVID-19 datasets. Particularly, we did not find any cases where the segmentation outline deviated significantly from the true boundary of the lungs. Any rare and minor deviations did not degrade the utility of our analysis pipeline. This incorporated automatic segmentation allows us to provide segmentation outlines in 2D views, compute the lungs clipping box, and 3D render the lungs anatomy in isolation, which supports Task T1 (see Sec. 3.2). Hofmanninger et al. also provide a model for lungs lobe segmentation, which is desirable for our system as it can support identification of anatomical locations for the COVID-19 lesions. However, the model was not found to be very robust on lungs with large COVID-19 lesions. In case of significant GGO and consolidation, the model failed to provide satisfactory segmentation of the lobes. Inaccurate segmentation in a diagnostic application can lead to degraded 3D visualizations and incorrect diagnosis. Thus, we prefer models that work more reliably even though they may not provide further subdivision of structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Lesion Localization and Detection</head><p>Our system provides segmentation outlines in 2D views for identifying and examining regions of abnormalities, drawing the radiologist's attention to regions that should be examined more closely. Localization or segmentation of COVID-19 lesions allows us to provide these outlines in 2D views. The segmentation mask is also used to render the lesions in 3D view and to highlight them along with the lungs surrounding structures. We have adapted and integrated into our pipeline, a COVID-19 lesion segmentation model by Fan et al. <ref type="bibr" target="#b16">[17]</ref>. They provide a binary segmentation model that segments overall lesions and abnormalities of the lungs as well as a multi-class model that is trained to segment both GGO and consolidation regions. We found that on our datasets, this model worked more accurately to highlight the regions of abnormality, which is consistent with the dice overlap numbers (0.739 and 0.458 for binary and multi-class models, respectively) reported by Fan et al. The binary detection model that we utilize (Semi-Inf-Net) is trained to identify lung abnormalities using COVID-19 chest CT images that predominantly contain GGOs and consolidations, and is thus suitable for our needs. After localization, the characterization of the lesions into further sub-types is handled by the radiologist through examination using the visualization tools provided in the user interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classification</head><p>Multiple instance learning (MIL) is a kind of weakly supervised learning <ref type="bibr" target="#b75">[76]</ref>. It was first formulated by Dietterich et al. <ref type="bibr" target="#b11">[12]</ref> for drag activity prediction and then widely applied to various tasks. In MIL, the training set consists of bags, where each bag is composed of a set of instances. The goal is to train a model to predict the labels of unseen bags. In MIL, only the bag-level label is given, and the instance-level label is unknown. This setting is particularly suitable for medical imaging, where typically only image-level or patient-level label is given. According to Amores' taxonomy <ref type="bibr" target="#b2">[3]</ref>, MIL algorithms can be categorized into three groups: Instance-Space (IS) paradigm, Bag-Space (BS) paradigm, and Embedded-Space (ES) paradigms. The IS paradigm learns an instancelevel classifier and the bag-level classifier is obtained by aggregating the instance-level response. The BS and the ES paradigms treat each bag as a whole entity and learn a bag-level classifier by exploiting global, bag-level information. The difference between both paradigms is how the bag-level information is extracted. The BS paradigm implicitly calculates the bag-to-bag similarity by defining a distance or kernel function, while the ES paradigm explicitly embeds the bag into a compact feature vector by defining a mapping function.</p><p>MIL pooling methods are used to represent the bag with the corresponding instances. Popular methods include max, mean, and log-sumexp poolings <ref type="bibr" target="#b67">[68]</ref>. However, they are non-trainable which may limit their applicability. To address this, some methods such as noisy-and pooling <ref type="bibr" target="#b41">[42]</ref> and adaptive pooling <ref type="bibr" target="#b74">[75]</ref> have been developed, but their flexibility is restricted. Ilse et al. <ref type="bibr" target="#b31">[32]</ref> have proposed an attention-based pooling that is fully trainable and can weigh each instance for the final bag prediction. Han et al. <ref type="bibr" target="#b21">[22]</ref> applied this pooling <ref type="bibr" target="#b31">[32]</ref> for bag representation, and a 3D CNNs was designed by Wang et al. <ref type="bibr" target="#b66">[67]</ref> as deep feature generator in their COVID-19 CAD system. Here, we also build our COVID-19 classification model based on this pooling method <ref type="bibr" target="#b31">[32]</ref> for its flexibility and interpretability. In addition, we propose a regularization term composed of differences between learned weights of adjacent slices to further smooth the attention weights and enhance the connection between adjacent slices. Also, we use ResNet18 <ref type="bibr" target="#b24">[25]</ref> to transform each slice into feature vector for its strong feature extraction ability, and thus each slice contains more information for diagnosis.</p><p>Our slice-based deep MIL method can thus generate the class activation map with Grad-CAM <ref type="bibr" target="#b61">[62]</ref> for each slice to increase our model interpretability and decision support. Our classification model performance is also superior due to the fact that each slice contains more information. See Sec. 5.1 for quantitative results of our classification model.</p><p>In our COVID-19 DL classification, we denote each CT scan as a bag-label pair {X,Y }, where X = {x 1 ,..., x K } denotes the CT volume containing K instances, instance x k denotes the slice, and Y ∈ {0, 1} denotes whether the patient is COVID-19 positive. K can vary for different bags. We use a feature extractor parameterized by the CNNs f ψ (•) with parameters ψ to transform the instance x k into a low dimensional feature vector h k = f ψ (x k ) where h k ∈ R D . Here, we use the ResNet18 as f ψ (•) and D = 512. For the bag presentation, we use the following attention-based pooling method <ref type="bibr" target="#b31">[32]</ref> as the mapping function in the Embedded-Space paradigm:</p><formula xml:id="formula_0">z = K ∑ k=1 a k h k ,<label>(1)</label></formula><p>where:</p><formula xml:id="formula_1">a k = exp w tanh Vh k ∑ K j=1 exp w tanh Vh j (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>where w ∈ R L×1 and V ∈ R L×D are parameters of a two-layered neural network. Here we set the dimension (L) in V as 128. Let L CE denote the binary cross entropy loss as follows:</p><formula xml:id="formula_3">L CE = − 1 N N ∑ i=1 1 ∑ c=0 p (Y i = c) log (q (Y i = c)) , (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>where N is the batch size, p (Y i = c) ∈ {0, 1} is the true class probability of X i belonging to the class c and q (Y i = c) is the estimated class probability of X i belonging to the class c . The loss function is:</p><formula xml:id="formula_5">L Total = L CE + λ L AW ,<label>(4)</label></formula><p>where:</p><formula xml:id="formula_6">L AW = K ∑ i=2 (a i − a i−1 ) 2 (5)</formula><p>and λ is a non-negative constant to balance L CE and L AW . Eqs. 4 and 5 are inspired by the similarity between adjacent slices. As two adjacent CT slices are similar, their learned instance weights should also be similar. Thus, the difference between two adjacent slices weights should be very small. The proposed regularization term L AW facilitates the attention-based pooling module assigns the weights to each instance better, and thus can further improve the model performance on bag prediction. As shown in Fig. <ref type="figure" target="#fig_3">4</ref>, the classification model takes the preprocessed CT volume as input (details later), and the feature extractor transforms each slice into a low dimensional feature vector. All the feature vectors are mapped into a semantic embedding representing the CT information using the attention-based pooling method mentioned above. Then, the embedding is further processed by a fully connected (FC) layer and softmax function to output the probability of different classes (COVID-19, non-COVID-19) for the CT volume. Eqs. 4 is used to calculate the total loss L Total and the model is trained end-to-end by backpropagation.</p><p>Data prepossessing starts with the CT images extracted from the DICOM files, and the CT volume is resampled to the same spacing of 1mm in the z-direction. We used the lung segmentation mask generated by a pre-trained U-Net <ref type="bibr" target="#b27">[28]</ref> to extract the lungs and remove the background. Then, a bounding box is calculated using the lung mask to crop the lung region. The bounding box is padded to keep the width and height of all CT images the same. The original CT intensity values are clipped into [−1250, 250] range and then normalized into [0, 1]. Next, the CT images are resized to T × 224 × 224, where T is the number of slices. To reduce overfitting, online data augmentation strategies, including random rotation (−10 to 10 degrees) and horizontal/vertical flipping with 50% probabilities are applied. For each training example, the augmentation is the same for every slice in the volume.</p><p>We qualitatively compare our classification model with other existing COVID-19 detection algorithms. Unlike <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b72">73]</ref> requiring lesion segmentation or manual selection of infected slices, our method only requires patient level weak label, which is much easier to obtain. Li et al. <ref type="bibr" target="#b45">[46]</ref> have proposed 2D CNNs to extract features of each slice, then the slice-wise features were fused into CT volumelevel feature via a max-pooling layer. However, since max pooling is non-trainable, its applicability is limited. Ilse et al. <ref type="bibr" target="#b31">[32]</ref> have shown that attention-based pooling outperforms max pooling in image classification experiments. Besides, the attention weights for each slice makes the model more interpretable. Thus, attention-based pooling used in our model is more effective and interpretable than max pooling. Furthermore, our proposed regularization term helps the attention-based MIL pooling module to assign the weights to each instance better by considering the similarity between adjacent slices, thereby can further improve the model classification performance. There are also 3D CNNs methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b66">67]</ref>, but, 3D CNNs usually require larger GPU memory. Also, our framework can be used with widely available 2D CNNs pretrianed on ImageNet <ref type="bibr" target="#b10">[11]</ref>, which makes the convergence of model training faster and better. Furthermore, the quantitative weights learned for each instance and Grad-CAM make our model more interpretable, which is helpful for diagnosing and improving the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Visualization Tools and User Interface</head><p>The visualization interface of COVID-view integrates all the components of our pipeline (Fig. <ref type="figure" target="#fig_2">3</ref>) for the radiologist to access in different modes. The interface allows the radiologist to visualize the chest CT in different 2D and 3D views that support conventional 2D radiologists' workflow and contemporary 3D visualization methods for better discernment of lesions and their morphology for improved diagnosis.</p><p>2D Views: A snapshot of the user interface of COVID-view is shown in Fig. <ref type="figure" target="#fig_4">5a</ref>. The right-hand side displays the conventional 2D views of axial, coronal, and sagittal planes. A range-slider immediately below the 3D View is used for adjusting the gray-scale colormap in all the 2D views. Similar action can also be performed using mouse left-click and drag operation on the 2D views. This supports Task T2. These views are indispensable as radiologists are trained to use them to examine scans. We incorporate additional cues in the 2D views to highlight the segmented lungs outline (in green) and COVID-19 lesions (in red), which support Tasks T1 and T3, respectively. Thus, we support the radiologists in their conventional workflow (Tasks T1 and T2) and augment additional information to draw attention to abnormal regions of the lungs that require special attention and characterization.</p><p>3D View: In Fig. <ref type="figure" target="#fig_4">5a</ref>, the main canvas shows the 3D rendering of the chest CT, utilizing multi-label volume rendering and applies local transfer function to each segmentation label. The composite segmentation mask used by the 3D rendering contains the segmented lesions, segmented lungs, and the context volume outer region. Each of the three regions use three separate transfer functions. Additionally, the user can choose to hide/show each of these regions in the 3D view, thereby allowing to create different visualization combinations for better understanding of the lungs and surrounding regions (Task T3). For example, the user may choose to hide the context volume and only render the lungs and internal lesions to get an occlusion-free view of the lungs interior (Fig. <ref type="figure" target="#fig_5">6a</ref>). As seen in the figure, we also allow the user to render the lungs outline geometry as a translucent surface mesh. This provides important context when rendering partial or restricted volumes in the 3D view and also supports Task T1 for inspection of lung geometry for stiffness or restrictions. As another example, the user may choose to render all three regions and use one or more clipping planes to control occlusion and get a look into the lungs/chest (Fig. <ref type="figure" target="#fig_5">6b</ref>). The 2D views and the 3D view are linked to each other for easier navigation, correlating features, and simultaneous lesion inspection across views. Clicking on any one of the planes will steer the other two planes to the clicked voxel, and a 3D cursor crosshair (3 black orthogonal intersecting lines) will update its position in the 3D view to the selected voxel position. Similarly, the user can directly select a point in the 3D view by clicking twice from different viewpoints while pressing the control key. This will update the 3D cursor, and the 2D view points will automatically steer to the corresponding axial, coronal, and sagittal planes that intersect with the selected voxel. Clipping Tool: As shown in Fig. <ref type="figure" target="#fig_5">6b</ref>, we include a volume clipping tool that works in tandem with the multi-label volume renderer, which can render three different regions (context, lungs, lesions) with localized transfer functions. The clipping tool uses three range sliders, one for each axis, to control the six clipping planes (also covering Task T1). The user can choose to move any single clipping plane at any given time (e.g., Fig. <ref type="figure" target="#fig_5">6b</ref> uses single coronal clipping plane), or both planes of an axis by dragging the middle of the range sliders. This function of dragging both minimum and maximum clipping plane of an axis allows a visualization mode where a thick slab of the volume is rendered and the slab can be moved along the axis for 3D inspection of the lung slabs. This can be considered as the 3D extensions of the axial, sagittal and coronal 2D views. The thick slab mode allows better discernment of the local 3D structures and lesion morphology without significant surrounding occlusion (Fig. <ref type="figure" target="#fig_6">7</ref>). This can support task T5 for closer inspection of lesion morphology and understanding subtle geometries. Transfer Function Design and Presets: COVID-view provides two different ways to manipulate optical properties of 3D rendering: basic mode, and advanced mode. In the basic mode, the user manipulates two sliders: opacity and offset. The opacity slider modifies the global opacity of a label (lungs, lesions, or context volume). Similarly, the offset slider applies an offset to the local transfer function of the chosen label. Specifically, the mapping between the transfer function and the scalar range over which it is applied can be manipulated using this slider. It offsets the transfer function mapping to lower or higher values of intensity. This allows for easy manipulation and adjustment of the preset transfer functions without the need to directly manipulate the piece-wise linear color and opacity maps. In the advanced mode, the user can choose the Transfer Function Tab in the Vis Tools (Fig. <ref type="figure" target="#fig_4">5a</ref>) to directly edit the transfer functions as a polyline on a 2D graph of Intensity vs Opacity (Fig. <ref type="figure" target="#fig_4">5b</ref>). We provide some well-designed preset transfer functions that the user can directly choose for visualizing the context volume, lungs, and the lesion volume. The user can also create their own transfer functions and save them for future use. All saved presets are automatically loaded into the COVID-view system during future runs. Task T2 of manipulating the colormap in the conventional workflow can be translated to the 3D view as manipulation and management of optical properties or transfer functions. Therefore, this feature of our user interface design accommodates abstract Task T2.</p><p>MIP Mode: Maximum intensity projection (MIP) mode creates 2D projection of volumes by projecting the highest intensity voxels to the foreground. This rendering is particularly useful for visualizing vascular structures, and consequently are suitable for lungs visualization. The MIP mode can be activated in all three 2D views, and is applied within the segmented lungs volume. This helps in overcoming any occlusion caused by the context volume, and the radiologist can focus only on the features internal to the lungs. Fig. <ref type="figure" target="#fig_6">7c-d</ref> shows a comparison of MIP mode with conventional 2D views for the visualization of COVID-19 chest CT lesions. The MIP mode also essentially supports Tasks T3 and T5 of observing both vascular and GGO/consolidation abnormalities.</p><p>Explainable DL: As automatic classification and assessment models are developed and incorporated into medical diagnosis workflow, it has become important to provide reliable and explainable results to the users. We described our novel binary classification model for COVID-19 in Sec. 4.3. The model executes automatically when a chest CT is loaded into the COVID-view Ṫhe results are presented in the form of two percentage probabilities for the COVID negative and positive classes, within a separate Classification tab of the Vis Tools. We also provide the user with a checkbox to overlay the activation heatmap of our classification model using an adaptation of the Gradient-weighted Class Activation Mapping (Grad-CAM) <ref type="bibr" target="#b61">[62]</ref> on the 2D axial, coronal, and sagittal views. We incorporated this activation heatmap as a visual overlay in our user-interface to improve the radiologists' trust in the output of our classification model. The activation heatmap is extracted from our classification model without any external supervision and allows the radiologist to evaluate what regions of the CT images triggered the classifier results. This provides an explanation and insight into our model results . Fig. <ref type="figure" target="#fig_7">8</ref> shows several examples of the activation heatmap in our application for CT images of COVID-19 patients. Measurements: COVID-view provides quantification tools for measuring lesions and tracking their growth. Linear measurements are supported in all the 2D views. The user can select the Measurements and Camera tab in the Vis Tools to show, hide, clear, or start linear measurements. In addition, since we have a lesion segmentation model integrated into COVID-view we also provide automatic volume measurement of the lungs and lesions. Three values are presented: lungs volume, lesions volume, and lesions percentage. Such volume measurements can help the radiologist to assess the lesion severity and distribution. As described earlier in Sec. 3, a recent study <ref type="bibr" target="#b56">[57]</ref> has shown that disease severity based on approximate lesion volume percentage is a promising predictor for patient management and prognosis. Together, the linear and volume measurements support Task T6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>In this section, we present a quantitative evaluation of our novel COVID-19 classification model, and a qualitative evaluation of our visualization system and user interface through expert feedback and case studies performed using our system by collaborating radiologists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Classification</head><p>Our classification model was developed, trained and evaluated on a total of 580 CT volumes including 343 COVID-19 positive volumes and 237 COVID-19 negative volumes. The dataset size of our study is similar to other studies <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b66">67]</ref>. Since public datasets typically have some limitations, such as only positive cases are available or the labels are not RT-PCR-based <ref type="bibr" target="#b50">[51]</ref>, all our CT scans were collected in our own hospital, as other studies did (e.g., <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b66">67]</ref>). Our 343 COVID-positive volumes were from patients with RT-PCR positive confirmation for the presence of SARS-CoV-2, and 202 COVID-negative volumes were collected from trauma patients undergone CT exams before the outbreak of COVID-19, and 35 COVID-negative volumes were collected in 2020 from patients without pneumonia. The model was implemented with the PyTorch <ref type="bibr" target="#b53">[54]</ref> framework. It was trained using Adam <ref type="bibr" target="#b37">[38]</ref> optimizer with the initial learning rate of 1e − 5 for 100 epochs. We evaluated the performance of the model using 5-fold cross-validation. For the detection of COVID-19, the accuracy and area under the receiver operating characteristic (ROC) curve (AUC) are 0.952( 95% confidence interval (CI): 0.938, 0.966) and 0.985 (95% CI: 0.981, 0.989), respectively. The sensitivity and specificity are 0.953 (95% CI: 0.932, 0.974) and 0.949 (95% CI: 0.928, 0.97), respectively. The ROC curve of the COVID-19 binary classification results was shown in Fig. <ref type="figure" target="#fig_8">9</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Expert Feedback and Case Studies</head><p>We developed COVID-view through close collaboration between computer scientists and a co-author expert radiologist (MZ). MZ provided feedback on our design choices during multiple discussion sessions through different development stages. We gathered a final round of feedback on the design and utility of different tools of our completed system from MZ, another radiologist Dr. Almas Abbasi (AA), and a medical trainee Joshua Zhu (JZ). Both MZ and AA used COVID-view on real-world patient cases over remote meetings before providing qualitative feedback. MZ also performed case studies on multiple real-world cases using the completed COVID-view. Following is a description of the case studies and their diagnostic findings.</p><p>Case 1: The first case analyzed by the radiologist MZ is a 79 year old female who had a chest CT scan with intravenous (IV) contrast (see Fig. <ref type="figure" target="#fig_9">10 Case 1</ref>). MZ inspected the case in both 2D views (particularly using axial slices) and 3D visualization of the lungs. After glancing at the 3D view of the lungs volume, MZ was quickly able to comment on the distribution of the COVID-19 lesions. MZ pointed out that most lesions proportion were posterior rather than anterior, and were in the lungs dependent region. This may also happen due to the patient's supine pose as the lungs may collapse (sub-segmental atelectasis) due to gravity, showing higher opacity in the lungs dependent region regardless of whether the lungs are diseased. Another case for cause of higher opacities in the lungs posterior region is pulmonary edema, that is, accumulation of fluid in the lungs webbing. MZ observed an asymmetry in the lesion mass between left and right lungs, which favors an infectious process in the right lower lobe, but was hesitant to strongly classify it as COVID-19 related lesions due to the aforementioned possibility of atelectasis or pulmonary edema. MZ looked at the classification results which confirmed this case as COVID-19 positive with 99% certainty. MZ also looked at the activation heatmap which pointed to the same region in the patient's lower right lung which MZ also had identified as possible infectious region. Indeed, the ground truth label also confirmed that the patient was COVID-19 positive.</p><p>Case 2: The second case is a 77 year old female who had a chest CT without IV contrast (see Fig. <ref type="figure" target="#fig_9">10</ref> Case 2). MZ identified a pulmonary nodule on the scan. The chest scan did not have any other visible abnormalities. The classification module reported this case as COVID-19 negative, and the lesion localization model also did not identify any abnormalities on the chest volume. MZ was glad to see that the nodule, which is not COVID-19 related, was not misidentified as a COVID-19 related lesion and the classification model was also able to correctly report the case as a negative with 97.8% certainty.</p><p>Case 3: The third case is a 72 year old male who had a chest CT with IV contrast (see Fig. <ref type="figure" target="#fig_9">10</ref> Case 3). MZ studied the patient through the 2D views and the 3D lungs rendered in isolation with vessels and lesions. They were able to identify IST in the right lung through the 3D visualizations. MZ noticed that the lesion localization model showed outlines on the 2D views for subtle abnormal regions that they would not have noticed. The outlines in the 2D views were able to draw the radiologist's attention to subtle areas of GGOs, which they would have otherwise missed. MZ explained that early stage COVID-19 lung opacities can be more subtle as they have not fully developed. The outlines in such cases can help in drawing attention to the lesions extent and distribution and support a more thorough examination of the chest CT. A radiology report will often describe the distribution and extent of GGO in terms of how many are covered.</p><p>Case 4: The fourth case is a 77 year old female who had a chest CT without IV contrast (see Fig. <ref type="figure" target="#fig_9">10 Case 4</ref>). MZ looked at the automatic classification results and checked the correlation between the identified lesions and the classification model activation heatmap. MZ found a decent correlation between the two, but had questions regarding why the lesion localization outlines didn't accurately correspond with the classifier activation heatmap. We explained that the lesion localization model <ref type="bibr" target="#b16">[17]</ref> was trained on manually segmented lesions and is specifically trained for segmentation tasks, whereas the activation heatmap is part of model results explanation rather than an accurate segmentation. MZ also expressed the desire to have some control over the heatmap parameters such as the scaling and thresholding parameters of the colormap, which could be used to identify multiple peak points of the heatmap. MZ identified a lesion (GGO) in the right lung that was not particularly highlighted by the heatmap but was identified by the lesion segmentation model (red outlines in 2D views). The radiologist then looked at the isolated lesion in 3D view along with the lungs surface. MZ appreciated the 3D view as it was able to provide additional information about the lesion shape and its location, for example, that the lesion is peripheral and provides a general qualitative sense of the lesion size with respect to surrounding features, such as vessels. MZ mentioned that if a radiologist was in doubt about the lesion in 2D views, the 3D views can provide additional qualitative information that may be able to clear up the doubt. The radiologist also viewed the case with context and lungs rendered in 3D with a coronal clipping plane, as in Fig. <ref type="figure" target="#fig_5">6b</ref>. MZ explored the visualization with provided transfer function presets. They noticed the heart and the subcutaneous fat region due to the color mapping. They opined that since COVID-19 diagnosis and the causes of severity of illness are still being investigated and are an active medical research, there is also some interest in correlating body fat with the disease. Visualizing the fat region and perhaps even quantifying it might be a useful for diagnosis and even for research. Similarly, the rendering of the context volume and use of clipping tool can help visualize the cardiac region. The cardiac region can be of interest for investigating pulmonary embolism, and change in contour of particularly the right heart chamber due to back pressure from the lungs. This case demonstrates non-dependent areas of opacity (lesions).</p><p>Beyond the case studies, we had further discussions with both radiologists (MZ and AA). They commented on each of the COVIDview user interface and visualization component, and their qualitative feedback is summarized below.</p><p>3D Visualizations: Overall, both radiologists were pleased with the 3D visualization capabilities. MZ mentioned that the vessels in the lungs were clearly visible in 3D. AA was also able to quickly identify a nodule and interlobular septal wall thickening in the scan using the 3D views as compared to the 2D views. Both radiologists found that the 3D view of the isolated lungs volume is helpful to quickly identify lesion locations and characterize the distributions (e.g., bilateral/unilateral and location in dependent or non-dependent regions) which is important to identify infectious processes in the lungs. MZ mentioned that 3D visualization of blood vessels could also be helpful since non-aerated areas of the lungs get shunted out and blood tends to flow in regions that are more oxygenated. The lungs outline rendered as translucent surface provided critical context for understanding lesion distribution, and may also help in visualizing stiffness in the lungs. Stiffness can cause lungs to under-inflate and reduce oxygenation. Identifying these regions can help the physicians for better patient's management in terms of hospitalization, ICU and appropriate ventilation.</p><p>Clipping Tool: 3D view of the context volume with clipping planes is robust and provides additional look at the cardiac region and body fat through suitable transfer function presets. The clipping tool was very useful in localizing 3D ROIs. Both radiologists mentioned that they are familiar with the bounding box based clipping. Such 3D visualizations and interaction tools are not common in their workflow. They are more common to specialized applications such as virtual colonoscopy and virtual bronchoscopy. MZ also mentioned that for COVID-19 diagnosis, virtual endoscopy style navigation would not be useful, and it was better to have an outside rendering of the lungs, such as in COVID-view.</p><p>Transfer Function Design and Presets: MZ stated that they prefer different color combinations than the color-maps we had used in the provided presets. Therefore, they appreciated the facility to allow them to create their own presets and personalize the TFs for different tasks. AA liked the application of color presets in the 3D clipped (front plane) view, which provided the view point for inspecting the heart region and lungs blood vessels. AA stated that such renderings can be helpful in assessing other conditions, such as pulmonary embolism.</p><p>MIP views: It is a well-known tool to radiologists and many find it very helpful. Particularly, subtle GGOs and nodules are easily visible in MIP views. AA suggested adding colors, such as application of transfer functions for the MIP views, to further improve its utility.</p><p>COVID-19 Classifier: Both radiologists appreciated that we had incorporated the novel automatic binary classifier into the system, and that the pre-processing pipeline of the application was entirely automatic. This greatly helps in the utility of the system in the field, since a radiologist is unlikely to spend time interacting with semi-automatic segmentation or classification. MZ noted that it is useful to have a second reader and the activation heatmap provides explanation for the classifier results and has the potential to improve COVID-19 detection. They pointed out that the heatmap was generally activated heavily by a singular region rather than being activated by every COVID related lesion. We explained that the activation heatmap may rely heavily on the most prominent lesion and may not get triggered by every lesion.</p><p>Measurement Tools: MZ explained that the 2D measurement tools and automatic lungs and lesions volume measurements are indispensable for assessing the size and growth of lung opacities, and the quantitative assessment of lesion volumes can help in patient management and prognosis. Furthermore, both AA and MZ mentioned other scenarios where COVID-view and its visualization capabilities can be useful, for example, to inspect cases of pulmonary embolism and rib fractures in trauma patients as those could be difficult to analyze in 2D axial views. In addition, we demonstrated COVID-view to medical trainee JZ to understand the perspective of medical students currently undergoing training for reading CT images. Based on the automatic classification capability, JZ stated that the COVID-view could be used as a second reader to the radiologist that can provide additional data points for diagnosis. JZ also stated that in their personal experience COVID-view user interface and visualizations appear better than other software applications they have encountered in the hospital during their training, and that they are interested in using the tool and learning more about its capabilities. They also suggested that help documentation in the form of tool-tips and question mark buttons should be embedded into the system for easier adoption by new users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>We have developed a novel 3D visual diagnosis application, COVIDview, for radiological examination of chest CT for suspected COVID-19 patients. It aims at supporting disease diagnosis and patient management and prognosis decision making. While lab tests (RT-PCR) are available for screening patients for COVID-19, our COVID-view vi-sual+DL system provides a more comprehensive analytical tool for assessing severity and urgency in case of hospitalized patients. It further supports other analysis tasks (e.g., pulmonary embolism diagnosis) by augmenting the conventional 2D workflow with 3D visualization of not just the lungs but also the context volume of the lungs and heart. We developed a novel DL classification model for classifying patients as COVID-19 positive/negative, which has high accuracy and reliability. It is integrated into our user interface as a second reader along with the visualization system for visual+DL diagnosis. In addition, an activation heatmap generated by our classification model can be overlaid on the 2D views as explainable DL and as visual+DL decision support.</p><p>Diagnosis and treatment of COVID-19 is an active on-going research. We believe that a visual+DL system, such as COVID-view can play a critical role in not only diagnosing and managing patients but also supporting researchers in further understanding the disease through 3D lung exploration and visualization, 3D lesion morphology, lungs exterior geometry, cardiac region, and full-body scans. It has been suggested by our expert radiologists to expand our detection to other forms of abnormalities and diseases, such as cancer lesions, nodules, pulmonary embolism, and other forms of lung fibrosis due to various pneumonia. This would expand our application to a more general chest CT analysis utility, which we plan to pursue in the future.</p><p>We further plan to improve our application prototype by adding an heart segmentation model to support additional analysis of the cardiac region and the heart right chambers, and visualization and quantification of body fat as additional measure. We will also apply other explainable DL methods, such as network dissection methods <ref type="bibr" target="#b5">[6]</ref>, and compare their performance to improve the classification model interpretability. We will also explore the possibility of developing automatic viewpoints for structures that are better viewed from specific orientations (e.g., IST). The data for our study was collected from a single hospital, as is common in initial studies, especially in COVID-19 (e.g., <ref type="bibr" target="#b66">[67]</ref>). We will collaborate with other institutions and collect additional data from different populations to perform cross-institution and cross-population validation. While the incorporated lesion segmentation model by Fan et al. <ref type="bibr" target="#b16">[17]</ref> is useful in our current prototype, we plan to develop a more accurate segmentation and lesion type classification models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An overview of the user interface and visualizations in our COVID-view system. (a) Snapshot of the user interface containing 2D and 3D views. (b) Results from our deep learning binary classifier showing COVID positive diagnosis. (c) Axial view with lesion segmentation outlines (red) and Grad-CAM activation heatmap overlay for explainable classification results. Both heatmap and lesion localization outlines point towards the interlobular septal thickening. (d) Clipped 3D view with lungs and vicinity context volume rendered together showing the 3D rendering of the thick interlobular septation (pink surface-like structure in the right lung).</figDesc><graphic coords="1,321.35,192.17,140.66,57.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Prominent chest CT features for COVID-19: (a) GGO. (b) Consolidations. (c) Interlobular septal thickening. (d) Vessel enlargement.</figDesc><graphic coords="3,66.23,132.53,111.38,80.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. The COVID-view application pipeline. The segmented lungs and lesion localization from the CT scan are processed by our COVID-19 classifier, which calculates the probability of COVID-19 positive/negative for the case, and generates an attention heatmap, as part of the explainable DL, that is displayed along with other exploratory 3D/2D visualizations in the user interface.</figDesc><graphic coords="4,450.95,85.01,81.62,54.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FeatureFig. 4 .</head><label>4</label><figDesc>Fig. 4. Architecture of our COVID-19 classification model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Snapshot of COVID-view user interface. (a) The top panel of the user interface contains the central 3D view, visualization tools, and the conventional 2D axial, sagittal and coronal views. Vertical panel on the left shows DICOM patient information. (b) The bottom panel of the user interface provides widgets for controlling the 2D/3D visualizations, clipping, measurements, and access to classification model results and heatmap.</figDesc><graphic coords="6,44.75,49.49,255.62,145.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Lungs multi-label 3D visualization. (a) Rendering lungs and lesions as volume and lungs outline as surface. (b) Rendering lungs with outer context volume and coronal clipping plane for managing occlusion. The heart chambers and subcutaneous fat can be seen with the clipping.</figDesc><graphic coords="6,176.75,476.21,89.42,105.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Thick slab mode can provide 3D extensions of the conventional 2D planar views. (a) Coronal view of slice 232. (b) Thick slab mode in coronal view. 3D cursor cross-hair points to a GGO whose morphology is clearly visible in 3D rendering along with neighboring vessels that connect with it. (c) MIP view in coronal plane using 10 adjacent slices around slice number 232. GGO lesions have a much larger footprint in MIP view and hence are easier to spot. The single slice views (a) only show fragments of the lesion and is difficult to judge the shape and morphology of the lesion in conventional 2D views. (a, c) Comparison of MIP mode with conventional 2D views for lesion visualization.</figDesc><graphic coords="6,472.43,336.41,73.10,108.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Representative examples of the class activation heatmap for the CT images of COVID-19 patients.</figDesc><graphic coords="7,64.19,410.09,77.00,57.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Fig. 9. ROC curve of our COVID-19 classification results.</figDesc><graphic coords="7,214.67,410.09,77.00,57.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Case studies performed by our collaborating radiologist (MZ). Case 1: (a1) 3D view with lungs and context volume clipped by top and front planes shows affected lower-posterior lungs regions. (a2) Lower posterior lung regions rendered in isolation. (a3) Axial view. (a4) Coronal view showing opacities in the lungs dependent regions. Case 2: (b1) Axial view showing very little abnormality detected by lesion segmentation model. (b2) Axial view showing nodule (red arrow) identified by radiologist. (b3) 3D view of isolated lungs volume. (b4) 3D clipped view of lungs and vicinity context volume showing a nodule (red arrow). Case 3: (c1) 3D view of isolated lungs showing 3D structure of interlobular wall thickening. (c2) Axial view with red arrows showing segmented lesions outlines. The radiologist noticed that these opacities were very subtle and they would have missed them without the outlines drawing attention to them. (c3) Axial view with red arrow pointing to the septal thickening shown in 3D view. Case 4: (d1) 3D view with lungs outline rendered as translucent surface. The outline provides a good context to understand lesion locations and overall lungs geometry (specially if diseased). Zoomed inset shows a closer look at GGO in right lung. (d2) Axial view with an overlay of the classification model activation heatmap. The model detected COVID-19 on the scan with 99% certainty. (d3) Axial MIP view showing segmented lesion outlines in red.</figDesc><graphic coords="9,441.95,270.29,108.98,72.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• Our COVID-view incorporates a comprehensive pipeline that includes automatic lung segmentation, lesion localization, novel automatic classification, and a user interface for 2D and 3D visualization tools for the analysis and characterization of lung lesions.• COVID-view incorporates explainable DL and decision support by overlaying the activation heatmap of our classification model with the 2D views in the user-interface. It also includes quantitative tools for volume and extent measurements of the lesions.</figDesc><table /><note>• COVID-view was designed through close collaboration between computer scientists and an expert radiologist who has experience in diagnosing COVID-19 in chest CTs. Important feedback, case-studies, evaluations and discussions with the experienced radiologist regarding our design choices substantially influenced the COVID-view development and implementation.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The chest CT datasets are courtesy of Stony Brook University Hospital. We thank Luke Cesario and Michael Yao for coding help and to Dr. Almas Abbasi and Joshua Zhu for application evaluation and qualitative feedback. This work was funded in part by NSF grants CNS1650499, OAC1919752, ICER1940302, and IIS2107224, and OVPR-IEDM COVID-19 grant.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Abad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Aguilar-Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RRTbased path planning for virtual bronchoscopy simulator. International Conference on Augmented Reality</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="155" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Paraview: An end-user tool for large data visualization. The Visualization Handbook</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ahrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Geveci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Law</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">717</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple instance classification: Review, taxonomy and comparative study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Amores</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">201</biblScope>
			<biblScope unit="page" from="81" to="105" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Artificial intelligence augmentation of radiologist performance in distinguishing COVID-19 from pneumonia of other origin at chest CT</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Halsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M L</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-B</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="E156" to="E165" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Hybrid segmentation and exploration of the human lungs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Río</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Thust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Heussel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-U</forename><surname>Kauczor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Straßer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>IEEE Visualization</publisher>
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Network dissection: Quantifying interpretability of deep visual representations. Computer Vision and Pattern Recognition</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An effective deep neural network for lung lesions segmentation from COVID-19 CT images</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">3d segmentation and visualization of lung and its structures using ct images of the thorax</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Cortez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H C</forename><surname>De Albuquerque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1099</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rebouc ¸as Filho. Segmentation and visualization of the lungs in three dimensions using 3d region growing and visualization toolkit in ct examinations of the chest</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V M</forename><surname>Da Nóbrega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 30th International Symposium on Computer-Based Medical Systems (CBMS)</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="397" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
				<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Solving the multiple instance problem with axis-parallel rectangles</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Lathrop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lozano-Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="31" to="71" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Classification of pancreatic cysts in computed tomography images using a random forest and convolutional neural network ensemble</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dmitriev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Hruban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">K</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Lennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Saltz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Computing and Computer Assisted Intervention</title>
		<imprint>
			<biblScope unit="page" from="150" to="158" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visual analytics of a computer-aided diagnosis system for pancreatic lesions</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dmitriev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2174" to="2185" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Review of chest CT manifestations of COVID-19 infection</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">El</forename><surname>Homsi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bernheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jacobi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Taouli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Radiology Open</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">100239</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">An encoder-decoderbased method for COVID-19 lung infection segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Elharrouss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Al-Maadeed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00861</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Inf-net: Automatic COVID-19 lung infection segmentation from CT images</title>
		<author>
			<persName><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2626" to="2637" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sensitivity of chest CT for COVID-19: Comparison to RT-PCR</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="E115" to="E117" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hybrid segmentation of colon filled with air and opacified fluid for CT colonography</title>
		<author>
			<persName><forename type="first">M</forename><surname>Franaszek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Pickhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="358" to="368" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Frangi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Niessen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Vincken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<title level="m">Multiscale vessel enhancement filtering. International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
				<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Acute pulmonary embolism associated with COVID-19 pneumonia detected with pulmonary CT angiography</title>
		<author>
			<persName><forename type="first">F</forename><surname>Grillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Behr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Calame</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aubry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Delabrousse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="E186" to="E188" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Accurate screening of COVID-19 using attention-based deep 3D multiple instance learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2584" to="2594" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Virtual bronchoscopy</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Haponik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Aquino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Vining</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinics in Chest Medicine</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="201" to="217" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Artificial intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Harmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Sanford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Turkbey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Myronenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Amalou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
				<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Object-oriented application development with mevislab and python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Heckel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schwier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-O</forename><surname>Peitgen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Informatik 2009-Im Focus das Leben</title>
				<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Assessment of real-time 3D visualization for cardiothoracic diagnostic evaluation and surgery planning</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Hemminger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Egan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">C</forename><surname>Detterbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Coffey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Imaging</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="153" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatic lung segmentation in routine imaging is primarily a data diversity problem, not a methodology problem</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hofmanninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Prayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Röhrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Prosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Radiology Experimental</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">3D virtual colonoscopy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Viswambharan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Biomedical Visualization</title>
				<meeting>IEEE Biomedical Visualization</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="26" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Virtual voyage: Interactive navigation in the human colon</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Muraki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH</title>
				<meeting>the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The ITK software guide</title>
		<author>
			<persName><forename type="first">L</forename><surname>Ibanez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cates</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention-based deep multiple instance learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2127" to="2136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Thoracic imaging tests for the diagnosis of COVID-19</title>
		<author>
			<persName><forename type="first">N</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Salameh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Leeflang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Hooft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Mcgrath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Pol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Hare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cochrane Database of Systematic Reviews</title>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">3D virtual pancreatography</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jadhav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dmitriev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Barish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2020.3020958</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Beyond frangi: an improved multiscale vesselness filter</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pernuš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Likar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ž</forename><surname>Špiclin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging: Image Processing</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">9413</biblScope>
			<biblScope unit="page">94132A</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Development and evaluation of an artificial intelligence system for COVID-19 diagnosis</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">3D Slicer: a platform for subject-specific image analysis, visualization, and clinical support. Intraoperative Imaging and Image-guided Therapy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Pieper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Vosburgh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="277" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Three-dimensional path planning for virtual bronchoscopy</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Kiraly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Helferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mclennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1365" to="1379" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Automated nomenclature labeling of the bronchial tree in 3D-CT lung images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kitaoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tschirren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sonka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mclennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Vessel tree segmentation in presence of interstitial lung disease in MDCT</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Korfiatis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kalogeropoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Karahaliou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Kazantzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Costaridou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Technology in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="214" to="220" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Classifying and segmenting microscopy images with deep multiple instance learning</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">Z</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Variation in false-negative rate of reverse transcriptase polymerase chain reaction-based SARS-CoV-2 tests by time since exposure</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Kucirka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Laeyendecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Boon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Internal Medicine</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="262" to="267" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Chest CT in COVID-19: what the radiologist needs to know</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Kwee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kwee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RadioGraphics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1848" to="1865" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A visually guided framework for lung segmentation and visualization in chest CT images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Imaging and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="485" to="493" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Artificial intelligence distinguishes COVID-19 from community acquired pneumonia on chest CT</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Using artificial intelligence to detect COVID-19 and community-acquired pneumonia based on pulmonary CT: evaluation of the diagnostic accuracy</title>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="E65" to="E71" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Extraction of airways from CT (EXACT&apos;09)</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yavarna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fetita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ortner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pinho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sijbers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2093" to="2107" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Planar visualization of treelike structures</title>
		<author>
			<persName><forename type="first">J</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="906" to="915" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Artificial intelligence-enabled rapid diagnosis of patients with COVID-19</title>
		<author>
			<persName><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Robson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1224" to="1228" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Morozov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Andreychenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vladzymyrskyy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ledikhova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gombolevskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">A</forename><surname>Blokhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gelezhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gonchar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">Y</forename><surname>Chernina</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.06465</idno>
		<title level="m">Mosmeddata: Chest CT scans with COVID-19 related findings dataset</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Time course of lung changes at chest CT during recovery from coronavirus disease 2019 (COVID-19)</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Hesketh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">295</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="715" to="721" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A deep learning and Grad-CAM based color visualization approach for fast detection of COVID-19 cases using chest X-ray and CT-Scan images</title>
		<author>
			<persName><forename type="first">H</forename><surname>Panwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Morales-Menendez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chaos, Solitons &amp; Fractals</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page">110190</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.01703</idno>
		<title level="m">An imperative style, high-performance deep learning library</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Pieper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Halle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
		<author>
			<persName><surname>Slicer</surname></persName>
		</author>
		<title level="m">2nd IEEE International Symposium on Biomedical Imaging: Nano to Macro</title>
				<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="632" to="635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">U-net: convolutional networks for biomedical image segmentation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">CT lung lesions as predictors of early death or ICU admission in COVID-19 patients</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kaeuffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ohana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Labani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fabacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bilbault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kepka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Solis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Greigert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lefebvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Microbiology and Infection</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1417" to="e1422" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Modeling real-time 3-D lung deformations for medical visualization</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Imielinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kupelian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Rolland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Technology in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="270" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lorensen</surname></persName>
		</author>
		<title level="m">The Visualization Toolkit</title>
				<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>4th edn. Kitware</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Visualizing with VTK: a tutorial</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="20" to="27" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Coronavirus3D: 3D structural visualization of COVID-19 genomic divergence</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sedova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jaroszewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Alisoltani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Godzik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="4360" to="4362" />
		</imprint>
	</monogr>
	<note type="report_type">Bioinformatics</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Grad-CAM: Visual explanations from deep networks via gradientbased localization</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
				<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Large-scale screening to distinguish between COVID-19 and community-acquired pneumonia using infection size-aware classification</title>
		<author>
			<persName><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics in Medicine &amp; Biology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">65031</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Navigational aids for real-time virtual bronchoscopy</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJR. American journal of roentgenology</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1165" to="1170" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Robust segmentation and anatomical labeling of the airway tree from thoracic CT scans</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Baggerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Van Rikxoort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
				<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Automatic segmentation of pulmonary lobes robust against incomplete fissures</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Van Rikxoort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Prokop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>De Hoop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1286" to="1296" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A weakly-supervised framework for COVID-19 classification and lesion localization from chest ct</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2615" to="2625" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Revisiting multiple instance neural networks</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="15" to="24" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">DeepOrganNet: on-the-fly reconstruction and visualization of 3D/4D lung models from single-view projections by deep deformation network</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="960" to="970" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">An improved electronic colon cleansing method for detection of colonic polyps by virtual colonoscopy</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eremina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1635" to="1646" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A deep learning system to screen novel coronavirus disease</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">pneumonia. Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1122" to="1129" />
			<date type="published" when="2019">2019. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">COVID-19 detection and disease progression visualization: Deep learning on chest X-rays for classification and coarse localization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zebin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rezvy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Intelligence</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1010" to="1021" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Clinically applicable AI system for accurate diagnosis, quantitative measurements, and prognosis of COVID-19 pneumonia using computed tomography</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1423" to="1433" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Automatic segmentation and recognition of anatomical lung structures from high-resolution chest CT images</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yokoyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kiryu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="299" to="313" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Adaptive pooling in multiinstance learning for web video annotation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
				<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="318" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A brief introduction to weakly supervised learning</title>
		<author>
			<persName><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National Science Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="53" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
