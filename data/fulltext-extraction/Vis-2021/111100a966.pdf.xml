<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Arrangements of Bar Charts Influence Comparisons in Viewer Takeaways</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Cindy</forename><surname>Xiong</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vidya</forename><surname>Setlur</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Benjamin</forename><surname>Bach</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kylie</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Eunyee</forename><surname>Koh</surname></persName>
						</author>
						<author>
							<persName><roleName>Member, IEEE</roleName><forename type="first">Steven</forename><surname>Franconeri</surname></persName>
						</author>
						<title level="a" type="main">Visual Arrangements of Bar Charts Influence Comparisons in Viewer Takeaways</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D5896F8514F46FE7E602CE3FD8A761BD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-06-13T13:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Comparison</term>
					<term>perception</term>
					<term>visual grouping</term>
					<term>bar charts</term>
					<term>recommendation systems</term>
					<term>natural language interaction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Well-designed data visualizations can lead to more powerful and intuitive processing by a viewer. To help a viewer intuitively compare values to quickly generate key takeaways, visualization designers can manipulate how data values are arranged in a chart to afford particular comparisons. Using simple bar charts as a case study, we empirically tested the comparison affordances of four common arrangements: vertically juxtaposed, horizontally juxtaposed, overlaid, and stacked. We asked participants to type out what patterns they perceived in a chart and we coded their takeaways into types of comparisons. In a second study, we asked data visualization design experts to predict which arrangement they would use to afford each type of comparison and found both alignments and mismatches with our findings. These results provide concrete guidelines for how both human designers and automatic chart recommendation systems can make visualizations that help viewers extract the "right" takeaway.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Well-chosen data visualizations can lead to powerful and intuitive processing by a viewer, both for visual analytics and data storytelling. When poorly chosen, that visualization leaves important patterns opaque, misunderstood, or misrepresented. Designing a good visualization requires multiple forms of expertise, weeks of training, and years of practice. Even after this, designers still require ideation and several critique cycles before creating an effective visualization. Current visualization recommendation systems formalize existing design knowledge into rules that can be processed by a multiple constraint satisfaction algorithm. Tableau and similar products use such rules to decide whether data plotted over time should be shown as lines or over discrete bins as bars. These systems are useful but rely on simple rules that fail to generalize when additional constraints are added, like the intent of the viewer, their graphical literacy level, the patterns being sought, and the relevant patterns in the underlying data.</p><p>One fundamental problem with existing recommenders is that, while they can correctly specify a visualization type, they offer little or no suggestion for how to arrange the data within the visualization. For example, the same data values can be grouped differently by spatial proximity, as shown in Figure <ref type="figure" target="#fig_0">1</ref>. These different visual arrangements can lead to different viewer percepts for the same dataset. For example, the vertical or overlaid configuration might emphasize the strong difference for the two bars in the middle, while the stacked bar configuration might emphasize that group 2 has the highest sum.</p><p>Through two studies, we generate a new set of design guidelines for visual arrangements of bar chart values, as a starting point for visualization interfaces intended to help viewers see the 'right' story in a dataset -one that aligns with a designer's goal. We showed people visualizations, asked them to record their takeaways, and categorized them, generating a mapping between different arrangements of values within a visualization and the types of comparisons that viewers are more likely to make.</p><p>Contributions: We contribute an empirical study, studying the ef- fect of visual arrangements on visual comparison, establishing a preliminary taxonomy that can be used to categorize the comparisons that people make within visualizations. We compare the results of our study with expert intuitions, generating design implications that could support natural language (NL) interfaces and visualization recommendation tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Design choices, like picking a chart type or deciding whether to highlight a given pattern, can strongly influence how people perceive, interpret, and understand data. <ref type="bibr" target="#b66">[67]</ref>. Showing the same data as a bar graph can make viewers more likely to elicit discrete comparisons (e.g., A is larger than B), while a line graph is more likely to elicit detection of trends or changes over time (e.g., X fluctuates up and down as time passes) <ref type="bibr" target="#b73">[74]</ref>. Histograms are effective for finding extremes; scatterplots are helpful for analyzing clusters; choropleth maps are effective for making comparisons of approximate values, and treemaps encourage identification of hierarchical structures <ref type="bibr" target="#b41">[42]</ref>. Chart types that aggregate data points, such as bar charts, can lead viewers to more likely infer causality from data compared to charts that do not, such as scatterplots <ref type="bibr" target="#b69">[70]</ref>. Charts that show probabilistic outcomes as discrete objects, such as a beeswarm chart, can promote better understanding of uncertainties <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b64">65]</ref>. Showing difference benchmarks on bar charts can not only facilitate a wider range of comparison tasks <ref type="bibr" target="#b63">[64]</ref>, but also increase the speed and accuracy of the comparison <ref type="bibr" target="#b48">[49]</ref>.</p><p>Visualizations are often presented in multiples so that analysts can explore different combinations and compare patterns of interest <ref type="bibr" target="#b52">[53]</ref>. For example, in interactive visualization dashboards, the spatial arrangement of a visualization can impact decision making, even when the same raw values are displayed <ref type="bibr" target="#b10">[11]</ref>. Ondov et al. <ref type="bibr" target="#b49">[50]</ref> identified four spatial arrangements used to represent multiple views in static visualizations: vertically stacked, adjacent, mirror-symmetric, and overlaid (also referred to as superposed). We investigate the effect of four similar spatial arrangements, except that we replaced the mirrorsymmetric arrangement, which less commonly used and often for the specific condition of comparing two similar data series <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b49">50]</ref>, with a more commonly used spatial arrangement: stacked bars, as shown in Figure <ref type="figure" target="#fig_0">1</ref>. The adjacent and overlaid arrangements both align bars horizontally, but the adjacent arrangement separates them into multiple x-axes with one group of bars on each. The overlaid arrangement uses a single axis with individual bars of a group next to the corresponding bars from the other group. These four spatial arrangements might encourage different comparisons because they put different values closer to each other. They also differently align values at the same horizontal or vertical positions, which can help viewers compare aligned objects more quickly <ref type="bibr" target="#b45">[46]</ref>.</p><p>We hypothesize that participants will more readily compare bars that are visually aligned, and less so the bars that are not. For example, participants might more often compare bar i to bar x, rather than bar i to y, when they view the vertical configuration in Figure <ref type="figure" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Comparisons in Visualization</head><p>Visual comparison has been widely studied, across scenes <ref type="bibr" target="#b54">[55]</ref>, scalar fields <ref type="bibr" target="#b42">[43]</ref>, and brain connectivity graphs <ref type="bibr" target="#b5">[6]</ref>. It can be a difficult and powerfully capacity-limited cognitive operation. Franconeri <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> discussed multiple cognitive limitations on comparison that should have direct impact on the design displays that facilitate comparisons. For example, objects are easier to compare across translations, relative to transformations of scale or rotation tasks <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b72">73]</ref>.</p><p>Representing comparisons in data visualizations is an important aspect of supporting the user in their analytical workflows. Small multiples make it easier to view objects side-by-side <ref type="bibr" target="#b3">[4]</ref> or examine juxtaposed views through multi-view coordination <ref type="bibr" target="#b55">[56]</ref>. Tufte discussed small multiples as an effective way to use the same graphic to display different slices of a data set for comparison <ref type="bibr" target="#b65">[66]</ref>. Prior work surveyed a variety of visualization solutions to support comparisons. Graham and Kennedy <ref type="bibr" target="#b24">[25]</ref> surveyed a range of visual mechanisms to compare trees, while other surveys consider methods for comparing flow fields <ref type="bibr" target="#b50">[51]</ref>. Gleicher et al. <ref type="bibr" target="#b22">[23]</ref> presented a general taxonomy of visual designs for comparison based on a broad survey of over 100 different comparative information visualization tools. Designs were grouped into three categories: juxtaposition, superposition, and explicit encodings.</p><p>Comprehension of visual comparisons is an important aspect of determining their efficacy. Shah and Freedman <ref type="bibr" target="#b62">[63]</ref> investigated the effect of format (line vs. bar) on the comprehension of multivariate (three variable) data and found that line and bar chart features have a substantial influence on viewers' interpretations of data. The differences between people's perceptions of bar and line graphs can be explained by differences in the visual chunks formed by the graphs based on Gestalt principles of proximity, similarity, and good continuity. Jardine et al. <ref type="bibr" target="#b28">[29]</ref> conducted an empirical evaluation on two comparison tasks -identify the "biggest mean" and "biggest range" between two sets of values -and showed that visual comparisons of largest mean and range are most supported by vertically stacked chart arrangements. More recently, Xiong et al. <ref type="bibr" target="#b70">[71]</ref> found that in 2x2 bar charts, people are more likely to group spatially proximate bars together and compare them as a unit, rather than grouping spatially distance bars or comparing bars individually without grouping them.</p><p>Based on these, we hypothesize that participants will form visual groups based on spatial proximity (e.g., seeing bar i, j, k in Figure <ref type="figure" target="#fig_0">1</ref> as a group, and bar x, y, z, as another group), and make comparisons between bars within a group more often than across different groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Comparisons in Computational Linguistics</head><p>The ability to establish orderings among objects and make comparisons between them according to the amount or degree to which they possess some property is a basic component of human cognition <ref type="bibr" target="#b32">[33]</ref>. Natural languages reflect this fact: all languages have syntactic categories (i.e., words in a language which share a common set of characteristics) that express gradable concepts, i.e., expressing explicit orderings between two objects with respect to the degree or amount to which they possess some property (e.g., "the temperatures in Death Valley are higher than in Bangalore in the summer") <ref type="bibr" target="#b58">[59]</ref>. Research in computational linguistics has explored the semantics of comparison based on gradable concepts <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b59">60]</ref>. Bakhshandeh and Allen presented a semantic framework that describes measurement in comparative morphemes such as 'more', 'less', '-er' <ref type="bibr" target="#b6">[7]</ref>.</p><p>The semantics of comparatives can be vague as their interpretation depends on the context and the boundaries that make up the definition of the comparative. For the example, "coffee and doughnuts in the Bay Area are more expensive than in Texas," is the statement about whether those items are more expensive on average, or whether both items are individually more expensive? While linguistic vagueness has been explored for comparative expressions along with their semantic variability, little work has been done in determining how best to visually represent comparatives based on these variations, especially in the context of visual analysis. Our work explores the types of comparisons readers make and their inherent ambiguities when comparing bar charts in different configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Visualization Recommendation Tools</head><p>Visual analysis tools, such as visualization recommendation (VizRec) systems, can help people gain insights quickly by providing reasonable visualizations. While a detailed review of visualization recommendation (VizRec) systems and techniques is beyond the scope of this paper, it can be found in survey manuscripts such as <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b74">75]</ref>. Broadly speaking, VizRec systems can be classified based on whether they suggest visual encodings (i.e., encoding recommenders) <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref> or aspects of the data to visualize (i.e., data-based recommenders) <ref type="bibr" target="#b67">[68]</ref>.</p><p>VisRec systems can provide a specific recommendation <ref type="bibr">[13-15, 39, 40]</ref>, but none of these systems focus on how to best provide recommendations specifically for facilitating visual comparison, and offer little or no suggestions for how to arrange the data within the visualization. In this paper, we address this gap in VisRec systems by better understanding how visual arrangements affect the viewers' takeaways during their analysis and the types of comparisons that are made based on these visual arrangements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Natural Language Interfaces for Visual Analysis</head><p>NL interfaces for visualization systems <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref> attempt to infer a user's analytical intent and provide a reasonable visualization response. These systems often support a common set of analytical expressions such as grouping of attributes, aggregations, filters, and sorts <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62]</ref>. Current NL interfaces however, do not deeply explore how utterances about comparisons ought to be interpreted even though such forms of intent are prevalent <ref type="bibr" target="#b61">[62]</ref>. In this paper, we explore different ways users express takeaways that compare bars in variants of visual arrangements. The implications of our work also help inform NL interfaces with guidelines towards reasonable visualization responses based on the types of comparisons users specify in their utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">STUDY MOTIVATION AND OVERVIEW</head><p>We investigate comparison affordances of four spatial arrangements of bar charts by showing crowdsourced participants bar charts and asking them to write sentences describing their most salient takeaways. We analyzed these written takeaways to create a mapping between the visualization arrangements and the takeaways, along with comparisons they tend to elicit. In experiment 2, we compare our data-driven mappings with expert intuitions and generate design guidelines for visualization recommendation systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ELICITING VIEWER TAKEAWAYS IN NATURAL LANGUAGE</head><p>One critical challenge in investigating viewer affordances is how to elicit viewer percepts when they interact with visualizations. A dataset can contain many patterns to perceive <ref type="bibr" target="#b71">[72]</ref>. For example, looking at the top panel in Figure <ref type="figure" target="#fig_1">2</ref>, one could notice that both reviewers gave higher scores to A and lower scores to B. Alternatively, one could notice that the differences in scores given to A and B is smaller for Reviewer 2 and bigger for Reviewer 1. To communicate what patterns one extracted from these visualizations, the viewer has to generate sentence descriptions of the pattern or relation, such as "A is greater than B," or "the difference between X and Y is similar to the difference between P and Q." In order to examine affordances of different visualization spatial arrangements and to create a mapping between viewer takeaways and the arrangements, we need to interpret and categorize the types of patterns and relations viewers take away from the visualizations. However, we end up facing similar challenges to that of the natural language and linguistics communities <ref type="bibr" target="#b21">[22]</ref>. Specifically, the sentences the viewers generate to describe their percepts/takeaways in visualization can be ambiguous. There are three types of ambiguity in natural language: lexical, syntactic, and semantic <ref type="bibr" target="#b21">[22]</ref>. Figure <ref type="figure" target="#fig_1">2</ref> provides an example of each type of ambiguity and how they map to different visual comparisons in the same visualization.</p><p>Lexical ambiguity represents instances when the same word is used to represent different meanings <ref type="bibr" target="#b29">[30]</ref>. In our study, we encountered situations where the participants used words such as "spread," which can be interpreted differently depending on their intent. As shown in Figure <ref type="figure" target="#fig_1">2</ref>, "spread" can be interpreted as either the amount of variability in data, or the range of the data as shown in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>Syntactic ambiguity occurs when there exists multiple ways to parse a sentence. For example, the takeaway "East makes more revenue from Company A and B" could be parsed as "East makes more revenue from (Company A and B)," or "East makes more revenue from Company A and (B)." As shown in Figure <ref type="figure" target="#fig_1">2</ref>, the viewer could have looked Company A and B holistically and notice that the average or combined values of the East branches is higher than that of the West branches. Alternatively, the viewer could have individually compared pairs of bars, noticing that in Company A, the East branch has a higher revenue than the West and that in Company B, the East branch has a higher revenue than the West.</p><p>Semantic ambiguity occurs when multiple meanings can still be assigned to the sentence despite being neither lexically nor syntactically ambiguous. For example, as shown in the bottom panel of Figure <ref type="figure" target="#fig_1">2</ref>, "Bacteria 1 and Bacteria 2 are the opposite of each other" can be mapped to two comparisons. The first could be a comparison between A and B in Bacteria 1 and a comparison between A and B in Bacteria 2, where the former has a smaller than relationship, and the latter has a larger than relationship. The second could be a comparison between Bacteria 1 and 2 in A and another between Bacteria 1 and 2 in B.</p><p>Since there does not exist natural language processing tools nor existing visual comparison taxonomies to aid our interpretation of chart takeaways, we could not automate the process. We had to manually read every sentence, infer the intent of the participant, and then connect the sentence to a visual pattern in the visualization. The ambiguity in these sentence descriptions can still be vague to even a human interpreter, so we also asked participants to annotate for us which chart component they compared to the best of their abilities. The human interpreter (or researcher, in our case) of these sentences could refer to these drawings and annotations to resolve ambiguities in the sentences. We decided to implement this method after a series of pilot experiments where we failed to comprehensively and accurately capture participant percepts when they viewed visualizations. We describe these failures with the hope that they can inspire future researchers to better capture viewer percepts or takeaways in visualizations. Attempt 1: We initially thought that human interpreters of viewergenerated sentences would have little problem resolving the ambiguities in language; unlike machines, we are capable of inferring intention, understanding implicit comparisons, and correcting obvious errors in text. We realized quickly that this was not the case and when a researcher read sentence descriptions as listed in Figure <ref type="figure" target="#fig_1">2</ref>, they could not reverse engineer the visual patterns the participants extracted. Attempt 2: We realized that we needed to ask our participants for more context than just sentence descriptions. If we knew which data values in a visualization they looked at or which pairs of data values they compared, the majority of the ambiguous cases could be resolved. After our participants generated sentence descriptions of the patterns they extracted from a visualization, we asked them to also indicate the data values they compared via a multiple choice task. Consider the chart in the bottom panel of Figure <ref type="figure" target="#fig_1">2</ref> as an example, the participant would be able to select a subset from the list 'Bacteria 1 A', 'Bacteria 1 B', 'Bacteria 2 A', and 'Bacteria 2 B' to indicate the ones they looked at and compared. However, most comparisons ended up containing the entire set (e.g., a comparison of A1 to B1, and then A2 to B2). In these scenarios, the multiple choice task ends up being uninformative as the participant would select all options in the entire list, because they compared every data value.</p><p>Attempt 3: A sentence typically unfolds as a comparison of two groups in which one group is the 'referent' and the other the 'target' <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b56">57]</ref>. The target and the referent are connected by a relation. In the sentence "East makes more revenue than West in Company A," the revenue of East A is the target and the revenue of West A is the referent. The relation is 'greater than.' This process applies to both natural language and to visual comparisons across data values in a visualization <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b62">63]</ref>. To improve upon Attempt 2, we separated the question where participants indicate which data values they compared into three questions so that they could indicate which values were the target, which were the referent, and the relation between them.</p><p>We piloted with 20 participants, including both crowdsourced workers from Prolific.com <ref type="bibr" target="#b51">[52]</ref> and undergraduate students enrolled in a research university and learned that while most people are able to generate sentences describing their percepts, they could not map their comparisons to target, referent, and relations. They especially struggled with implicit comparisons, such as "there is a decreasing trend from left to right" and "West A has the second highest revenue." Both cases could be translated into target, referent, and relation in multiple ways. For example, assuming that the participant noticed that the bars became smaller from left to right, the decreasing trend could involve a comparison of the left-most bar to the second left-most bar with the former bigger than the latter. In this case, the target is the left-most bar, the referent is the second left-most bar, and the relation is 'bigger than.' Alternatively, the participant could have compared the decreasing trend (the target) to an imagined horizontal line that is not decreasing (the referent). The training process quickly became more complex and its duration became less proportional to its effectiveness. We additionally collected data on participants' confidence as they translated their sentences and observed consistent low confidence in their own translations. Attempt 4: Inspired by the relation component in the Failure 3, we recognized that mathematical expressions such as 'A &gt; B' contain all three elements of target, referent, and relation. Mathematical expressions tend to be far less ambiguous compared to the English language, and writing these simple expressions seems more intuitive than segmenting a sentence into an unfamiliar units. In this attempt, we asked people to write pseudo mathematical expressions to reflect the data values they compared or the pattern they noticed. We provided examples such as 'A != C' (A is not equal to C), 'A &gt; B &gt; C' (decreasing from A to B to C), and 'max = A' (A is the biggest bar) to get people started. After piloting 10 university student participants, we realized that this likely would not scale efficiently to crowd-sourced participants. Participants' expressions varied depending on the type of programming languages they were familiar with. There was little semantic consistencies in how participants used conjunction words like 'and', 'or', and 'but.' For example, some participants used 'but' to connect two comparison statements (e.g., A is better than B, but C is worse than D) whereas others used it to represent contrast (e.g., A is better than B, but A is worse than C) or provide context to their comparisons (e.g., they are all the same but A is slightly more). Some sentences were just difficult to be intuitively represented as a mathematical expression, such as "the population is the same for both rivers, but for different bacteria types." Attempt 5: This method was a success, but a temporary solution nonetheless. This is the version where we asked participants to write a sentence description and attach a digital drawing annotating the specific patterns they noticed or data values they have compared, as that shown in Figure <ref type="figure" target="#fig_3">4</ref>, to clarify the sentence descriptions. What we ended up with was over a thousand sentences and drawings that our laterreported findings are based on. However, this is more of an imperfect, intermediate solution than it is a success -the method required dozens of hours of manual interpretation from multiple people to ensure that viewer intent is captured accurately and consistently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lessons Learned</head><p>We share some takeaways from our attempts with future researchers below. First, because there are many patterns to potentially see within our visualization, mapping verbal chart takeaways to visual features is challenging because natural language can be ambiguous. Investigators should try to not rely on sentence descriptions alone to make sense of user intent in the research process. Second, because we do not have tools to automatically interpret viewer takeaways, the research process can become labor intensive, as researchers had to manually decode viewer intents. It will be worthwhile to develop tools that can automate the interpretation of viewer takeaways in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT 1 CROWDSOURCING TAKEAWAYS</head><p>In Experiment 1, we investigated the comparison affordances of four common arrangements in bar charts: vertically juxtaposed, adjacent, overlaid, and stacked. We asked participants to type out what patterns they perceived and qualitatively coded their takeaways into types of comparisons. We then created a mapping between the visual arrangements and the comparisons they tend to afford.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Participants</head><p>We recruited 76 participants via Prolific.com <ref type="bibr" target="#b51">[52]</ref>. They were compensated at nine USD per hour. In order to participate in our study, the workers had to be based in the United States and be fluent in English. After excluding participants who had failed attention checks (e.g., failing to select a specific answer in a multiple choice question to pass the check) or entered illegible/nonsensical response, we ended up with 74 participants (M age = 25.22, SD age = 7.23, 32 women).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Methods and Procedure</head><p>We generated two datasets for the four spatial arrangements, creating eight total visualizations. Figure <ref type="figure" target="#fig_2">3</ref> shows the two datasets in the overlaid configuration. Each visualization depicts two groups of three data points. For example, the chart could be showing the sales of two ice cream flavors (flavor A and flavor B) in three different markets (market 1, market 2, and market 3). In our analysis, we will refer to the two groups as 'groups' and each of the three data points within each group as 'elements.'</p><p>We created a within-subject experiment where each participant viewed all eight of the visualizations and wrote their two main takeaways for each visualization. They were also asked to annotate their takeaways on the bar visualization by drawing circles around the bars they mentioned or using mathematical operators (e.g., &gt;, &lt;, =) to represent the patterns they saw, as shown in Figure <ref type="figure" target="#fig_3">4</ref>. We examined the sentence takeaways to identify the comparisons participants made upon seeing the visualizations. The takeaways and corresponding drawings can be found in the supplementary materials. To distract the participants from noticing similarities in patterns between the charts, we added distractor tasks (e.g., demographic and visual literacy questions) between each visualization and provided each of the eight charts presented with a different context, as shown in Figure <ref type="figure" target="#fig_2">3</ref>. We randomized the order of the charts such that the charts alternated between the two datasets and participants never saw the same spatial arrangements in back-to-back trials. Additionally, we asked at the end of the survey if the participants noticed anything unusual or have any comments regarding the visualizations shown in the survey; six out of the 74 participants mentioned that they noticed similar patterns across the visualizations seen. They mentioned that "many of the charts were the same, that's why I gave the same answer" and "some charts were recycled as the study advanced." We decided to keep these participants' data since only a few noticed similarities between our stimuli, and we anticipate them to make our results more conservative (as their answers might differ less among the arrangements).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparison Classification and Coding Approach</head><p>We took a top-down approach and identified 12 possible comparisons to generate takeaways from bar charts, as shown in Figure <ref type="figure" target="#fig_4">5</ref>, which we will refer to as C1 through C12. Previously, we mentioned that the charts we have shown participants all depict two groups (A, B) with three elements (1, 2, 3) in each group. A comparison could be made across group, meaning the viewer compared something in group A to something in group B, or it could be made within group, meaning the viewer compared something in group A to something else in group A, or compared something in group B to something else in group B. The comparison could also be classified as within element or across element. A within element comparison compares the same elements between two groups, such as comparing element 1 in group A to element 1 in group B. An across element comparison compares different elements, such as comparing element 1 to element 2. This could be within the same group, meaning element 1 in group A is compared to element 2 in group A, or across different groups, meaning element 1 in group A is compared to element 2 in group B.</p><p>A viewer could mix-and-match their comparison operations for groups and elements in four ways: across group -within element, across group -across element, within group -across element, and within group-within element. For an across group -within element comparison, the same element is identified in each group and compared to one another. An across group -across element comparison means the viewer identifies one element from one group and compares it to another element in a different group. For within group -across element comparisons, the viewer zooms in on one group, and compares different elements within that same group. However, within groupwithin element, does not apply in most scenarios since it requires a viewer to compare the same element in the same group, such as comparing element 1 in group A to element 1 in group A. This is just a comparison of a data point to itself, therefore not of interest, and we omit it from our classification system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">One-to-One Comparisons (1:1)</head><p>Viewers can compare two individual bars in their takeaways. We refer to them as "one-to-one" comparisons, as shown in the leftmost column in Figure <ref type="figure" target="#fig_4">5</ref>, comparison types C1, C5, and C9. For across group -within element operations, one-to-one comparison means that the viewer compares one element in one group to the same element in another group, such as comparing element 1 in group A (which we will refer to as A1) to element 1 in group B (which we will refer to as B1)</p><p>. For across group -across element operations, the viewer compares one element in one group to another element in a different group, such as comparing A1 to B2</p><p>. For within group -across element operations, one-to-one comparison means that the viewer compares one element in one group to another element in the same group, such as comparing A1 to A3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Two-to-Two Comparisons (2:2)</head><p>Viewers can alternatively visually group together two bars and compare them as a set to another set of visually grouped two bars, which we refer to as "two-to-two" comparisons, as shown in the second column in Figure <ref type="figure" target="#fig_4">5</ref>, comparison types C2, C6, and C10. These differ from one-to-one comparisons as the viewer is no longer comparing individual values, but rather comparing the sum/difference of two elements to the sum/difference of two other elements. For example, for an across group -within element two-to-two comparison, the viewer would compare element 1 to element 3 overall . Using the two ice cream flavor sales across three markets example from before, a comparison of this type will say "the overall sales in market 1 considering both flavors is lower than the overall sales in market 3." For an across group -across element two-to-two comparison, the viewer will compare a set of two different elements (one from each group) to another set of two different elements (one from each group)</p><p>. For a within group -across element two-to-two comparison, the viewer will com-pare a set of two different elements from the same group to another set of the same two elements from the other group .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">All Elements (All)</head><p>The previously mentioned two categories involve the viewer comparing a subset of the data in the chart. The viewer can also visually group together a set of bars and compare that set to the remaining data points, which we refer to as "all element" comparisons (third column in Figure <ref type="figure" target="#fig_4">5</ref>), comparison types C3, C7, and C11. For this category, an across group -within element comparison would involve the viewer visually grouping the element 1s together and comparing them to the element 2s and 3s . Examples of this type of comparison might include the viewer identifying that the set containing element 1s is overall the smallest compared to element 2s and element 3s (e.g., considering both ice cream flavors, market 1 has the lowest amount of sales compared to market 2 and 3). An across group -across element comparison happens when the viewer groups together two different elements, one from each group (e.g., A1 and B2) and compares them to the other pairs of elements . Since this category requires the elements to not be matching between the two groups, it can seem arbitrary. Our data supports this point as this type of comparison is extremely rare among viewers. Finally, a within group -across element comparison involves the viewer visually grouping together all elements in A and comparing their sum/differences to the sum/differences of all the elements in B as a whole .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">One-to-Multiple (1:M)</head><p>The last category is "one-to-multiple" comparisons, as shown in the fourth column in Figure <ref type="figure" target="#fig_4">5</ref> -types C4, C8, and C12, where participants identify one data point and simultaneously compare it to multiple other bars. People typically do this type of operation when they rank the bars by value (e.g., B3 is the second highest), or when they identify extrema such as maximums or minimums. We refer to the scenario where the viewer picks out one bar and compares it to the rest of the bars as an across group -within/across element comparison because the comparison happened both within the same element (e.g., comparing A2 to B2) and across different elements (e.g., comparing A2 to A1, to A3, etc.</p><p>) . An across group -across element comparison type requires the viewer to identify one element from one group, and comparing it to multiple elements in the other group . Lastly, a viewer can identify one element within one group and compare it to all of the other elements in the same group, which we refer to as a within group -across element comparison .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5">Hypotheses in Context</head><p>Following the hypotheses we proposed in Sections 2, we anticipate participants to do more across group -within element comparisons, because they require the viewer to compare the spatially aligned bars, and more within group -across element comparisons, because they require the viewer to group bars together and compare the bars within the same group. Additionally, they might do more 1:1 comparisons than everything else, as 1:1 comparisons have the most straightforward alignment. However, if participants are actually more likely to group spatially proximate bars to compare them, we should see an interaction between comparison type and chart arrangement. For bar charts in the vertical and stacked arrangements, we should see more C1, C2, and C3 because they are vertically aligned and spatially proximate, which makes them intuitive to compare, or C9 and C12 because they involve comparing bars within a spatially proximate group. Following a similar logic, C9 and C12 might also be often compared in the adjacent arrangement. For the overlaid arrangement, because the bars are grouped together by element pairs (1, 2, 3), we expect to see fewer of C9 and C12, and more of C2 and C3, as viewers will likely group the element pairs together to compare one pair with another pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Making Sense of Participant Takeaways</head><p>To make sense of participant takeaways, we analyzed their written description in conjunction with their drawings, as shown in Figure <ref type="figure" target="#fig_3">4</ref>.</p><p>These drawings are especially helpful when we were not sure what elements the participants compared exactly based solely on their written descriptions. Most takeaways involved a comparison between two chart elements, so we identified what they compared in each takeaway and what relationship described that comparison, mapping that comparison to one of our twelve categories. For example, for the takeaway "it looks like flavor B sold more than flavor A in market 2", the two chart elements compared would be B2 (flavor B in market 2) and A2 (flavor A in market 2), and the relation is 'greater than.' Since this is a comparison of one individual bar to another individual bar, this would be a one-to-one comparison. Additionally, since the element is fixed (market 2 for both) and the group is changing, this would be an across group -within element comparison (type C1). Two authors participated in this qualitative coding process and double coded all responses. They agreed 89.5% of the time in their ratings, with a high inter-rater reliability Kappa value of 0.867 (z = 72.3, p &lt; 0.001). Disagreements were resolved through discussion. Some participants would make multiple accounts of the same type of comparison upon seeing one chart, such as making two instances of across group -within element one-to-one comparisons (see 1 in Figure <ref type="figure" target="#fig_4">5</ref> ). For example, one participant wrote "I noticed that in market 1, flavor B sold more than flavor A, and in market 2, flavor A sold more than flavor B." This participant compared B1 to A1, as well as compared B2 to A2. In situations like this, we removed the duplicate and counted this participant as having done a one-to-one across group -within element comparison.</p><p>We also noticed that some participants mentioned conjunction comparisons in their takeaways, touching on two comparison categories, such as saying "flavor B sold more than flavor A in market 1, but flavor A in market 1 sold more than flavor A in market 3." In this example, the first part of this comparison is a one-to-one across group -within element comparison (C1</p><p>), and the second part of this comparison is a one-to-one within group -across element comparison (C9</p><p>). We recognize that conjunctions could also be used to join two takeaways as a higher order comparison (e.g., a comparison of the result of two previous comparisons). However, related work has shown that these cases are relatively rare as higher order comparisons are complex and people seldom make them <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b70">71]</ref>. Thus for the present experiment, we break up conjunctions, which cover different types of comparisons, and treat them as separate takeaways from the same participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Comparison Overview</head><p>We collected a total of 584 chart takeaways with 53.09% of them being conjunction comparisons, with a total of 1100 comparisons collected from participants. Figure <ref type="figure" target="#fig_5">6</ref> and Table <ref type="table" target="#tab_1">1</ref> summarize the number of comparisons participants made for each category and shows the frequencies of the 12 types of comparisons across the four visualization arrangements. Participants most frequently made the one-to-one across group -within element comparisons (C1 in Figure <ref type="figure" target="#fig_4">5</ref>). Using the ice cream flavor sales across three markets example, where the two groups are flavors A and B and the three elements are markets 1, 2, and 3, participants most often wrote takeaways saying "I noticed that in market 1, ice cream flavor A sold less than flavor B."</p><p>The second most frequently made comparison was all elements across group -within element (C3). For example, "the total sales in market 1 is smaller than the total sales in market 2, and it's also smaller than the total sales in market 3."</p><p>The third and fourth (tie) most frequently made comparisons were all elements within group -across element (C11), such as saying "overall, flavor A sold more than flavor B," and one-to-multiple within group -across element (C12), such as saying "for flavor A, market 2 sold more ice cream than market 1 and market 3."</p><p>The fifth most frequently made comparison was one-to-multiple across group -within/across element (C4). This type of comparison mostly involved identification of the maximum or the minimum points, or a ranking of data values. For example, "flavor B in market 2 is the least sold flavor, considering all the flavors and all the markets."</p><p>The sixth most frequently made comparison was one-to-one within group -across element (C9). For example, one participant said "For flavor A, market 1 sold more than market 3 did."</p><p>The seventh most frequently made comparison was the two-to-two across group -within element comparison (C2). This is similar to the all element across group -within element comparison (C3), except that the participant only compared one element to one other element. For example, "market 1 has better business than market 3."</p><p>Participants very rarely did a comparison of the remaining five categories (C5, C6, C7, C8, C10), making up less than 5% of all comparisons each. No participants made all elements across group -across element comparisons (C7), which means no one visually grouped nonmatching elements from the two groups and compared them. Only one participant made a one-to-multiple across group -across element comparison (C8), where they compared the biggest bar in group A to all of the bars in group B. The one-to-one across group -across element comparisons (C5) that participants made may seem arbitrary, but they were always comparing two bars of similar sizes together. This finding supports our hypothesis from Section 2, suggesting that most comparisons centered around spatially aligned elements in bar charts.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Visual Arrangements and Number of Bars Compared</head><p>We analyzed whether different visual arrangements impacted whether a viewer would do one-to-one (1:1), two-to-two (2:2), all elements (All), or one-to-multiple (1:M) comparisons (the four columns in Figure <ref type="figure" target="#fig_4">5</ref>). As shown in Figure <ref type="figure" target="#fig_6">7</ref>, as we expected, most participants made 1:1 comparisons (40.0%), followed by All comparisons (30.1%) and 1:M comparisons (21.4%), and the least 2:2 comparisons (8.5%).</p><p>Considering the specific visual arrangements, another Chi-Square analysis found that the only significant relationship is that the adjacent arrangement affords more one-to-multiple (1:M) comparisons, while the stacked arrangement affords fewer such comparisons (χ 2 = 38.405, p &lt; 0.001). This means visual arrangement in general does not affect how many bars people compare in a chart.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Across/Within Group and Element Comparisons</head><p>We conducted a Chi-Square analysis and, as shown in Figure <ref type="figure" target="#fig_6">7</ref>, found that participants were significantly more likely to make across group -within element, and within group -across element comparisons (χ 2 = 65.39, p &lt; 0.001). Very few people made across group -across element comparisons. This agrees with our hypothesis that viewers are more likely to compare spatially aligned bars.</p><p>Overlaid arrangements were most likely to trigger an across group -within element comparison (first row, p &lt; 0.001), but are least likely to trigger a within group -across element comparison (third row, p &lt; 0.001). Adjacent arrangements were most likely to trigger a within-group -across element comparison (third row, p &lt; 0.001), and were least likely to trigger an across group -within element comparison (first row, p &lt; 0.001). This means that people were more likely to identify the same element and compare their values across two different groups when they view bar charts in the overlaid arrangements, and are more likely to focus on one group and compare elements within that group when they view adjacent charts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Visual Arrangements and Comparison Categories</head><p>We examined how visual arrangements impacted the likelihood of participants making each of the twelve types of comparisons via a Chi-square analysis and found a significant effect (χ 2 = 132.25, p &lt; 0.001). We visualize the number of comparisons participants made in each of the 12 comparisons in Figure <ref type="figure" target="#fig_5">6</ref>. Post-hoc analysis with Bonferroni's correction revealed that some visual arrangements particularly elicit certain comparison types. As summarized in Table <ref type="table">2</ref>, overlaid arrangements especially afford C3 (all element, across group -within element, p = 0.001) and C4 comparisons (one-to-multiple, across group -within element, p = 0.037). Vertical arrangements afford type 9 comparisons (one-to-one, within group -across element, p = 0.017). Adjacent arrangements afford C12 comparisons (one-tomultiple, across group -within element, p = 0.013). Some arrangements are also particularly bad at eliciting certain comparison types. Participants were the least likely to make C3 comparisons with adjacent arrangements (p = 0.002). Vertical arrangements were the least We share some participant drawings in Figure <ref type="figure" target="#fig_3">4</ref>. You can see that the amount of effort the participant put into visually representing their comparisons differed between comparison type and arrangements, which also reflects the differing comparison affordances of the visual arrangements. For overlaid arrangements, visually annotating comparison type C3 was simple, whereas visually annotating the same comparison in an adjacent arrangement was much more complex. This corroborates with our finding that participants were more likely to make C3 comparisons when viewing overlaid arrangements, and less likely to do so when viewing adjacent arrangements. Surprisingly, although type C1 and C11 comparisons were among the most frequently made comparisons, we did not find any difference in the likelihoods of participants making them between the four visual arrangements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Discussion</head><p>Overall, as we hypothesized, viewers were more likely to compare bars that are visually aligned and spatially proximate. Vertical and adjacent arrangements best afford comparisons that involve comparing one element in one group to another element in the same group (C9: and C12:</p><p>). Overlaid arrangements best afford comparisons that involve comparing one bar to all other bars in the chart (which are most often superlative comparisons, C4:</p><p>), and comparisons that involve comparing one element to other elements, considering both groups (C3:</p><p>). Although comparisons that involve comparing one group to another holistically (C11:</p><p>) and comparisons that involve comparing the same element across two different groups (C1: ) are popular comparisons, no particular visual arrangements especially afford these comparisons.</p><p>Considering that the above six comparison types (C1, C3, C4, C9, C11, C12) were commonly observed and especially afforded by the four arrangements we tested, we present them as comparison intents to visualization experts in Experiment 2 and ask them to select an arrangement that would best afford these comparison intents. There is a subtle difference between C4 and C12, as C4 is about a global extrema (viewer needs to consider all bars), while C12 is a local extrema (viewer needs to select one group and identify an extrema in it). Be-cause both are about identifying extrema, in respect to the experts' time and to avoid a combinatorial explosion of experimental conditions, we condensed the experiment to only include C4, as finding global extremum tends to be the more common task used in other visualization evaluations (e.g., <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b57">[58]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENT 2 EXPERT INTUITIONS</head><p>In Study 2, we showed data visualization experts bar charts in the four different visual arrangements and asked them which one they would choose to facilitate a specific type of comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Participant and Procedure</head><p>We recruited 45 visualization expert volunteers from Adobe and Tableau (M age = 37.88, SD age = 13.14, 16 women) to complete an online survey through Qualtrics <ref type="bibr" target="#b53">[54]</ref>. They reported their experience with visualizations in multiple-choice, multiple-answer questions. Among our participants, for those that chose to complete the demographic questionnaire at the end of the survey, 22 people stated that they were data analysts who used visualizations frequently or were visualization researchers, 7 people said to have taken at least one visualization design course, and 3 people indicated to be engaged with data visualization design and development (e.g., engineering, graphic design, product manager). 31% of our participants mentioned that they enjoyed learning about visualizations through popular media and infographics. The participants also completed a subjective graph literacy report <ref type="bibr" target="#b19">[20]</ref> and reported an average value of 4.75 out 6 (SD = 0.75, 1 = not good at all, 6 = extremely good), suggesting that most participants were comfortable interpreting visualizations.</p><p>Experts were given a comparison goal and asked to select the visualization they thought best makes that comparison from four arrangements via a multiple-choice task, as shown in Figure <ref type="figure" target="#fig_8">8</ref>. Everyone viewed five sets of data presented with five different scenarios (e.g., Figure <ref type="figure" target="#fig_2">3</ref>), and each scenario came with one of the five listed comparison goals from Table <ref type="table">2</ref>. The order in which the five scenarios were presented and the mapping between datasets and scenarios follow a 5 x 5 Graeco Latin Square design, such that the order in which the scenarios were presented, as well as how the datasets mapped onto the scenarios, were counterbalanced. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>We conducted a Chi-Square analysis to investigate whether experts associate certain comparison types with certain visual arrangements. We found a significant relationship between experts' preferred visual arrangement for each comparison goal (χ 2 = 163.67, p &lt; 0.001). We summarize the visual arrangements the experts identified to facilitate each comparison type in Table <ref type="table">2</ref> and compared their intuitions to our empirical results from Experiment 1. The rightmost column shows the distribution of the experts response. From left to right, the bars represents the number of experts that selected adjacent, overlaid, stacked, and vertical arrangement as the most effective design for the given comparison goal. We see that for C4 and C9, most experts agree that overlaid is the best arrangement, but for the other three, even the experts do not agree on which arrangement might be the most effective.</p><p>Post-hoc comparisons with Bonferroni's correction suggest that experts preferred the stacked arrangement (p &lt; 0.001) to make comparison C1, in contrast to crowdworkers, who collectively suggested that all four arrangements were equally likely to elicit this comparison type. For comparison C3, experts preferred the stacked arrangement (p &lt; 0.001), while overlaid arrangement worked the most effectively with crowdworkers. For comparison C4, experts chose the overlaid arrangement as the most effective one (p = 0.022), which is consistent with crowdsourced results from Experiment 1. For comparison C9, experts preferred the overlaid arrangement (p &lt; 0.001), but crowdsourced results suggest that the vertical arrangement most affords this comparison type. For comparison C11, crowdsourced data from Experiment 1 suggests that the four arrangements were equally likely to elicit this comparison and experts agreed (p &gt; 0.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DESIGN GUIDELINES</head><p>We found that visual arrangements can afford different visual comparisons in bar charts, and viewers most readily compare bars that are visually aligned and spatially proximate. We recommend that visualization designers consider how the data can be best spatially arranged to facilitate key comparisons among data values. We identify comparison affordances of the visual arrangements in Table <ref type="table" target="#tab_2">3</ref>. These findings provide guidelines for a variety of visual analysis tools and applications. Additionally, while experts generally showed good intuitions about visualization design, there are several instances where their choices did not align with our results. This suggests that visualization researchers should continue to empirically explore the design affordances rather than solely relying on expert intuitions. Handling comparison intent in VisRec systems and NL interfaces: Insights from the study can be incorporated as rules for providing targeted visualization responses based on the type of comparison that the user may find useful or helps answer their question. For example, an NL utterance, "Are paper products doing better in the West region or East region?" is a common type of analytical inquiry. Showing a vertical arrangement of bar charts for instance, could help facilitate an effective takeaway that satisfies the user's intent. Smarter defaults in authoring tools: To improve the efficacy of chart-caption pairs for visual comparisons, authors could (1) design the chart with a visual arrangement that supports the comparison goal and (2) provide a caption that emphasizes the type of comparison that the arrangement affords, beyond the current practice of just describing the variables depicted in the chart. Visual analysis tools can suggest reasonable defaults and design choices to guide the author in creating such effective chart-caption comparison pairs to doubly emphasize the comparative features in the takeaways <ref type="bibr" target="#b33">[34]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">LIMITATION AND FUTURE DIRECTIONS</head><p>We identify several limitations in our study that provide promising future research directions. First, our investigation was limited to bar charts that show groups of discrete variables. Although we experimented with different datasets and scenarios, the underlying data is relatively simple. Future research can experiment with more complex bar charts, additional datasets, and other visualization chart types. This can also lead to investigations of generalizability between visual arrangements and comparison affordances across different charts, data values, and data complexity.</p><p>Second, to address the ambiguous nature of human language, we solicited accompanying drawings that provide more detail to the sentence takeaways. As a result, we could not automate the data analysis process, and the authors had to manually read, segment, and categorize each sentence takeaway. We analyzed conjunction sentences by breaking them into separate comparisons. But people could make more complex comparisons involving conjunctions, usually in the form of a comparison from the results of an existing comparison. Future research could explore the visual affordances for conjunction comparisons in bar charts, and investigate ways to more effectively collect viewer takeaways via improved natural language interfaces that can automatically map verbal chart takeaways to visual comparisons and allow for a wider range of user input queries.</p><p>Third, although we found that certain visualization arrangements better afford certain visual comparisons, it is unclear whether these arrangements would also increase the accuracy of value comparisons. There might be a mismatch between what people intuitively compare in an arrangement and how accurately they can make that comparison. Future research could investigate the effectiveness of different visual arrangements from a perception angle using psychophysical methods.</p><p>Finally, we only looked at how visual arrangements could affect how people compare elements and groups. There may be other factors that could strengthen a chart's comparison affordances. For example, highlighting aspects of a visualization has been shown to help elicit takeaways <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28]</ref>. Future work could further explore techniques to help designers choose the best arrangement that ensures that a viewer sees the 'right' story in a dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Four spatial arrangements examined in the study.</figDesc><graphic coords="2,44.99,83.81,250.46,91.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Three linguistic ambiguities for various visual comparisons. Bar charts displayed in the overlaid arrangement.</figDesc><graphic coords="3,316.55,49.37,245.07,590.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Two datasets used to generate the bar charts, showing the overlaid arrangement as an example.</figDesc><graphic coords="4,307.55,316.01,250.58,67.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Drawings of a C3 comparison in the overlaid and adjacent charts.</figDesc><graphic coords="4,323.63,438.53,216.14,88.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Twelve categories of comparisons in two by three bar charts in the adjacent arrangement.</figDesc><graphic coords="5,83.51,49.25,209.90,205.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Heatmap showing occurrences of categories for every comparison type as well as in total across all types (bar chart). Opaque values in the heatmap indicate significant values. Bar chart icons shown on the left are presented in the adjacent arrangement.</figDesc><graphic coords="7,53.99,463.73,250.46,215.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Heatmaps showing (a) the total counts of comparison types for each group (1:M, 1:1, 2:2), (b) per groupings (AG, WG, AE, WE) [no significant counts], and (c) the total count of observations across techniques. Opaque values in the heatmap indicate significant values.</figDesc><graphic coords="7,410.87,55.25,78.50,91.34" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Table 2 .</head><label>2</label><figDesc>Summary results from Experiment 1 (crowdsourced comparisons) compared to summary results from Experiment 2 (expert intuitions). Bar charts in the right-most column show expert preferences for the four arrangements: adjacent (a), overlaid (o), stacked (s), and vertical (v). Type Comparison Comparison Goal Crowdworkers Experts C1 compare the same element across two different groups compare the sales revenue in market 3 from ice cream flavor A to the revenue in market 3 from ice cream flavor B all the same vertical C3 compare one element to other elements, considering both groups compare the average sales revenue in market 1 to the average sales revenue in market 2, across both ice cream flavors overlaid stacked C4 compare one bar to all other bars in the chart, which is often a superlative comparison identify the lowest single sales revenue rating among all six revenues overlaid overlaid C9 compare one element in one group to another element in the same group compare the sales revenue of ice cream flavor B in market 1 to the sales revenue of ice cream flavor B in market 3 vertical overlaid C11 compare one group to another holistically compare the overall ice cream sales in market A to the overall ice cream sales in market B all the same all the same likely to trigger C4 comparisons (p = 0.021), and overlaid arrangements were the least likely to trigger C12 comparisons (p = 0.028).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Multiple choice study design for experts to indicate their preferences in Experiment 2.</figDesc><graphic coords="9,53.99,49.49,513.14,101.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Overview ranking the most frequently made comparisons from Experiment 1 with examples.</figDesc><table><row><cell></cell><cell cols="2">Type %</cell><cell>Examples</cell></row><row><cell>1</cell><cell>C1</cell><cell cols="2">27.82 compare one element in a group to the same</cell></row><row><cell></cell><cell></cell><cell></cell><cell>element in the other group</cell></row><row><cell>2</cell><cell>C3</cell><cell cols="2">16.73 compare one element to the other two elements</cell></row><row><cell></cell><cell></cell><cell></cell><cell>considering both groups</cell></row><row><cell cols="2">3 (tie) C11</cell><cell cols="2">13.36 compare the group A as a whole group B as a</cell></row><row><cell></cell><cell></cell><cell></cell><cell>whole</cell></row><row><cell cols="2">3 (tie) C12</cell><cell cols="2">13.36 compare one element in one group to the other</cell></row><row><cell></cell><cell></cell><cell></cell><cell>elements in the same group</cell></row><row><cell>5</cell><cell>C4</cell><cell>7.64</cell><cell>select one data point and compare it to all the</cell></row><row><cell></cell><cell></cell><cell></cell><cell>other data points</cell></row><row><cell>6</cell><cell>C9</cell><cell>7.36</cell><cell>compare one element in one group to another</cell></row><row><cell></cell><cell></cell><cell></cell><cell>element in the same group</cell></row><row><cell>7</cell><cell>C2</cell><cell>5.00</cell><cell>compare one element to one other element</cell></row><row><cell></cell><cell></cell><cell></cell><cell>considering both groups</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Recommended visual arrangements for various user goals.</figDesc><table><row><cell>User Goal</cell><cell cols="2">Category Type</cell><cell>Recomm.</cell></row><row><cell>compare one data value to multiple other</cell><cell>1:M</cell><cell>C12</cell><cell>adjacent</cell></row><row><cell>values</cell><cell></cell><cell></cell><cell></cell></row><row><cell>compare one element to other elements</cell><cell>2:2/All</cell><cell>C2/C3</cell><cell>overlaid</cell></row><row><cell>considering both groups</cell><cell></cell><cell></cell><cell></cell></row><row><cell>identify maximum and minimum points</cell><cell>1:M</cell><cell>C4</cell><cell>overlaid</cell></row><row><cell>compare one element in one group to an-</cell><cell>1:1</cell><cell>C9</cell><cell>vertical</cell></row><row><cell>other element in the same group</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Analytics</forename><surname>Ibm Watson</surname></persName>
		</author>
		<ptr target="http://www.ibm.com/analytics/watson-analytics/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Q &amp; A</forename><surname>Microsoft</surname></persName>
		</author>
		<ptr target="https://powerbi.microsoft.com/en-us/documentation/powerbi-service-q-and-a/" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<ptr target="http://www.thoughtspot.com/" />
		<title level="m">ThoughtSpot</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Verifying scientific simulations via comparative and quantitative visualization</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ahrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Heitmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Woodring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fasel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ahrens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Geveci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="16" to="28" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Declutter and focus: Empirically evaluating design guidelines for effective data communication</title>
		<author>
			<persName><forename type="first">K</forename><surname>Ajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Knaflic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kemper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization &amp; Computer Graphics</title>
		<imprint>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Weighted graph comparison techniques for brain connectivity analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Alper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;13</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="483" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantic framework for comparison structures in natural language</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bakhshandeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>of the 2015 Conference on Empirical Methods in Natural Language essing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-09">Sept. 2015</date>
			<biblScope unit="page" from="993" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The semantics of gradation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bierwisch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the process of comparing sentences against pictures</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Chase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="472" to="517" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Guidance in the human-machine analytics process</title>
		<author>
			<persName><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Engelke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="166" to="180" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluating the impact of user characteristics and different layouts on an interactive visualization for decision making</title>
		<author>
			<persName><forename type="first">C</forename><surname>Conati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Steichen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Toker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
				<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="371" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The semantics of degree</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cresswell</surname></persName>
		</author>
		<editor>B. H. PARTEE, editor, Montague Grammar</editor>
		<imprint>
			<date type="published" when="1976">1976</date>
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="261" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Datasite: Proactive visual data exploration with computation of insight-based recommendations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Badam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Yalçin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<idno>abs/1802.08621</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scagexplorer: Exploring scatterplots by their scagnostics</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Pacific Visualization Symposium</title>
				<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Foresight: Rapid data exploration through guideposts</title>
		<author>
			<persName><forename type="first">Ç</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Haas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Pedapati</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.10513</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The nature and status of visual resources</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Three perceptual tools for seeing and understanding visualized data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Flexible visual processing of spatial relationships</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Scimeca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Helseth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Kahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Datatone: Managing ambiguity in natural language interfaces for data visualization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual ACM Symposium on User Interface Software Technology</title>
				<meeting>the 28th Annual ACM Symposium on User Interface Software Technology<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015. 2015</date>
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Communicating health risks with visual aids</title>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia-Retamero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Cokely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="392" to="399" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Communicating treatment risk reduction to people with low numeracy skills: a cross-cultural comparison</title>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia-Retamero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Galesic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of public health</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2196" to="2202" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ambiguity detection: Towards a tool explaining ambiguity sources</title>
		<author>
			<persName><forename type="first">B</forename><surname>Gleich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Creighton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Working Conference on Requirements Engineering: Foundation for Software Quality</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="218" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Visual comparison for information visualization</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Jusufi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="289" to="309" />
			<date type="published" when="2011-10">Oct. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">On the give and take between event apprehension and utterance formulation</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Gleitman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>January</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Trueswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of memory and language</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="544" to="569" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploring multiple trees through dag representations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1294" to="1301" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Comparing semantic theories of comparison arnim von stechow</title>
		<author>
			<persName><forename type="first">C</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Heim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Seuren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sternefeld</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The impact of the format of graphical presentation on healthrelated knowledge and treatment choices</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Hawley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zikmund-Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ubel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jancovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fagerlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Patient education and counseling</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="448" to="455" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Toward interface defaults for vague modifiers in natural language interfaces for visual analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Visualization Conference (VIS)</title>
				<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The perceptual proxies of visual comparison</title>
		<author>
			<persName><forename type="first">N</forename><surname>Jardine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Ondov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1012" to="1021" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Lexical ambiguity in statistics: how students use and define the words: association, average, confidence, random and spread</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Rogness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistics Education</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">When (ish) is my bus? user-centered visualizations of uncertainty in everyday, mobile predictive systems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Munson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2016 CHI</title>
				<meeting>of the 2016 CHI</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="5092" to="5103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Projecting the adjective: The syntax and semantics of gradability and comparison</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kennedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="volume">01</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Comparatives, semantics of. Encyclopedia of Language Linguistics</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kennedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-08">08 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Towards understanding how readers integrate charts and captions: A case study with line charts</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.08235</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A semantics for positive and comparative adjectives</title>
		<author>
			<persName><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistics and Philosophy</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Clustering of population pyramids</title>
		<author>
			<persName><forename type="first">S</forename><surname>Korenjak-Ëcerne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kejžar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Batagelj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informatica</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Size scaling in visual pattern recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bundesen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology. Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Effects of spatial separation in visual pattern matching: Evidence on the role of mental translation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bundesen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="719" to="731" />
		</imprint>
	</monogr>
	<note>Journal of experimental psychology. Human perception and performance</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Avoiding drill-down fallacies with vispilot: Assisted exploration of data subsets</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Dev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Elmeleegy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th International Conference on Intelligent User Interfaces, IUI &apos;19</title>
				<meeting>of the 24th International Conference on Intelligent User Interfaces, IUI &apos;19</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="186" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Scattersearch: Visual querying of scatterplot visualizations</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Deconstructing categorization in visualization recommendation: A taxonomy and comparative study</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Karahalios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parameswaran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Vlat: Development of a visualization literacy assessment test</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="551" to="560" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Evaluation of trend localization with multi-variate visualizations</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Livingston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Decker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2053" to="2062" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automating the design of graphical presentations of relational information</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="141" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Show Me: Automatic presentation for visual analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1144" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Spatial alignment facilitates visual comparison</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Matlen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gentner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">443</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Visual routines are associated with specific graph interpretations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Michal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive Research: Principles and Implications</title>
				<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Visual routines for extracting magnitude relations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Michal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Uttal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic bulletin &amp; review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1802" to="1809" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Measures of the benefit of direct encoding of data deltas for data pair relation perception</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nothelfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="311" to="320" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Face to face: Evaluating visual comparison</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ondov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jardine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="861" to="871" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Comparative visualization -approaches and examples</title>
		<author>
			<persName><forename type="first">H.-G</forename><surname>Pagendarm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Post</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="volume">01</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Prolific. acâa subject pool for online experiments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schitter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral and Experimental Finance</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="22" to="27" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Keeping multiple views consistent: Constraints, validations, and exceptions in visualization authoring</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="468" to="477" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">I</forename><surname>Qualtrics</surname></persName>
		</author>
		<author>
			<persName><surname>Qualtrics</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>Provo, UT, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Change detection</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
		<idno type="PMID">11752486</idno>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="245" to="277" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">State of the art: Coordinated multiple views in exploratory visualization</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CMV 2007</title>
				<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="61" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Asymmetric coding of categorical spatial relations in both language and vision</title>
		<author>
			<persName><forename type="first">J</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">464</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Task-based effectiveness of basic visualizations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Saket</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ç</forename><surname>Demiralp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2505" to="2512" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Grading, a study in semantics</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sapir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="93" to="116" />
			<date type="published" when="1944">1944</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Quantifiers in comparatives: A semantics of degree based on intervals</title>
		<author>
			<persName><forename type="first">R</forename><surname>Schwarzchild</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Semantics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Eviza: A natural language interface for visual analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Battersby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gossweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Inferencing underspecified natural language utterances in visual analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Djalali</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Bar and line graph comprehension: An interaction of top-down and bottom-up processes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Freedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in cognitive science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="560" to="578" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">What&apos;s the difference? evaluating variations of multi-series bar charts for visual comparison tasks</title>
		<author>
			<persName><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</title>
				<meeting>the 2018 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Presenting research risks and benefits to parents: does format matter? Anesthesia and analgesia</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Tait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Voepel-Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Zikmund-Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fagerlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page">718</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Envisioning information</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Tufte</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Graphics Press</publisher>
			<pubPlace>Cheshire, Conn.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Visualizing thought. In Handbook of human centric visualization</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="3" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Towards a general-purpose query language for visualization recommendation</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on Human-In-the-Loop Data Analytics</title>
				<meeting>of the Workshop on Human-In-the-Loop Data Analytics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.01330</idno>
		<title level="m">Survey on artificial intelligence approaches for visualization data</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Illusion of causality in visualized data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="853" to="862" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Visual salience and grouping cues guide relation perception in visual data displays</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Stokes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">The curse of knowledge in visual data communication</title>
		<author>
			<persName><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Van Weelden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on visualization and computer graphics</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Capacity for visual features in mental rotation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1241" to="1251" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Bars and lines: A study of graphic communication</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1073" to="1079" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A survey on automatic infographics and visualization recommendations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="24" to="40" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
