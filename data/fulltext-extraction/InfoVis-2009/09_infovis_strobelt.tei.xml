<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Document Cards: A Top Trumps Visualization for Documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendrik</forename><surname>Strobelt</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Oelke</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Rohrdantz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stoffel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Deussen</surname></persName>
						</author>
						<title level="a" type="main">Document Cards: A Top Trumps Visualization for Documents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>document visualization</term>
					<term>visual summary</term>
					<term>content extraction</term>
					<term>document collection browsing</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Document Cards help to display the important key terms and images of a document in a single compact view.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Nowadays, large document collections, such as research paper corpora and news feeds, grow at high rate. Many of these documents contain text and images for describing facts, methods, or telling stories. It is an exhaustive task for a user to get an overview of of a larger collection. To overcome this problem, it is common to represent a document in a different way. For instance, search engines usually show the title of a document together with a small context of the query terms. With this representation a user has to read only a portion of the text and is focused on the relevant parts of the documents, which efficiently allows him or her to differentiate between relevant and non-relevant documents. While this representation is efficient to browse through search results, it is not capable to give a quick overview of a document or even a whole document collection.</p><p>We introduce a novel approach for a compact visual representation of a document, called Document Card (DC) that makes use of important key terms and important images (see <ref type="figure">Fig. 1</ref>). This representation adopts the idea of top trumps game cards, on which expressive pictures and facts provide a combined overview of an object, such as cars. By using terms as well as images, we maintain the informative value of texts and combine it with the descriptive nature of images in one view. Our visualization aims at compact size so it can scale to handle a large number of documents on display devices of different resolutions.</p><p>In Section 2 we give an overview of other work and techniques related to our approach. Our approach is introduced in Section 3. Section 4 contains a detailed description of our technique to create Document Cards. In Section 5 we present an application of Document Cards to a corpus of scientific documents. We conclude with future work in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">General Approaches</head><p>Faced with the task of overviewing a document collection, the usage of technologies integrated in operating systems is a common solution. File browsers like Microsoft Windows Explorer or Apple Finder provide a thumbnail view of the first page of a document file. Setlur et al. <ref type="bibr" target="#b31">[32]</ref> create document icons that include representative images from a web image database found by key text features of a file. Other thumbnail approaches discuss the use of 3D icons, which map each information on a side of a cube (Henry and Hudson <ref type="bibr" target="#b13">[14]</ref>) while Lewis et al. <ref type="bibr" target="#b21">[22]</ref> focus on distinctive icons as a graphical solution for the "lost in hyperspace" problem. Previewing technologies like Apple Cover Flow add the capability to browse through document pages in place. Cockburn et al. <ref type="bibr" target="#b8">[9]</ref> show that representing all pages of a document in one view (Space-Filling Thumbnails) allows fast document navigation.</p><p>Visualizations for small devices aim at compact representations. Breuel et al. <ref type="bibr" target="#b4">[5]</ref> propose to use and rearrange original text snippets from a text image to circumvent OCR parsing problems. Berkner et al. <ref type="bibr" target="#b3">[4]</ref> extend this approach and create combined text-and-image thumbnails called SmartNails. The used images are scaled and cropped to automatically extracted regions of interest. How to find such regions is also described by Suh et al. <ref type="bibr" target="#b34">[35]</ref>. Suh and Woodruff <ref type="bibr" target="#b35">[36]</ref> introduced Enhanced Thumbnails which overlay and highlight extracted keywords on a scaled and saturation reduced version of a web page. The idea of creating thumbnails of PDF files is discussed by Sauer et al. <ref type="bibr" target="#b1">[2]</ref>. They extract images from documents, sort them by their filesize, and arrange the "top few" of them on the frontpage. Berkner <ref type="bibr" target="#b2">[3]</ref> discusses an approach of finding the best scale for a document page relating to its type of content. Lam et al. <ref type="bibr" target="#b20">[21]</ref> introduced the concept of Summary Thumbnails, which represent webpages as thumbnail views, enhanced with shortened text fragments in larger font size. The main layout of the webpage remains (as well as the total line count). Erol et al. <ref type="bibr" target="#b9">[10]</ref> use the audio capability of an handheld device to auto-generate a small film introducing a document. The film contains images, and the highly relevant terms are spoken.</p><p>Russell and Dieberger <ref type="bibr" target="#b26">[27]</ref> describe how to automatically instantiate manually created Summary Design Patterns using texts and images.</p><p>Our approach combines images and key terms in a single Document Card. In contrast to other methods, we build a compact representation of a whole document that combines representative images with expressive key terms. These Document Cards can be used on large displays to browse large document collections as well as on handheld devices to get an overview of a single document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Term Extraction</head><p>Approaches for keyword or key term extraction often originate from the information retrieval field like the prominent TFIDF method ( <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b27">[28]</ref>). An extensive survey on Information Retrieval methods was published by Kageura and Umino <ref type="bibr" target="#b15">[16]</ref>. But also in text mining research key term extraction methods play a role as pointed out by Feldman et al. <ref type="bibr" target="#b11">[12]</ref>. Usually, a measure is defined to score terms with respect to a document or a document collection. A certain number of top scored terms according to the measure are then extracted as key terms.</p><p>Whereas most approaches require a suitable document corpus for comparison in order to extract key terms out of a single document, Matsuo and Ishizuka <ref type="bibr" target="#b23">[24]</ref> describe a method that is able to extract key terms out of a single document without further resources. The approach is based on the co-occurrence of terms in sentences and the χ 2 -measure to determine biased co-occurrence distributions in order to assess the importance of terms.</p><p>Our approach also uses an extension of the χ 2 -measure to identify important key terms. However, we base our extraction method on the structure of the document. The rationale for this is explained in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Image Extraction and Image Classification</head><p>Extracting images from a document format like PDF using standard tools is challenging. Chao and Fan <ref type="bibr" target="#b6">[7]</ref> split PDF Documents into the components: images, vector images, and text. Maderlechner et al. <ref type="bibr" target="#b22">[23]</ref> focus on finding figure captions and mapping them to images. Cohen et al. <ref type="bibr" target="#b17">[18]</ref> mention to use a modified version of open source tools to extract images.</p><p>For image classification Chapelle et al. <ref type="bibr" target="#b7">[8]</ref> suggest Support Vector Machines operating on image histograms. Moreno et al. <ref type="bibr" target="#b24">[25]</ref> and Vasconcelos et al. <ref type="bibr" target="#b36">[37]</ref> suggest to use the Kullback-Leibler divergence as distance measure between two histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Layout</head><p>Placing a set of rectangular images optimally into a given rectangular canvas is known as rectangle packing. It is in the class of NP complete problems. From the wide range of algorithms which provide an approximative solution, three approaches are referenced here. A method from computer graphics uses efficient packing methods to create texture atlases <ref type="bibr" target="#b29">[30]</ref>. Murata et al. <ref type="bibr" target="#b25">[26]</ref> introduced the sequence pairs to transform the problem into a P-admissible solution space problem. The approach generates packings of high quality in reasonable time for offline use (like in VLSI design). Itoh et al. <ref type="bibr" target="#b14">[15]</ref> have shown a fast, geometric algorithm for placing rectangles even in online time. The algorithm does not use global optimization, but produces packings of good quality. A survey of rectangle packing is given in Korf <ref type="bibr" target="#b16">[17]</ref>.</p><p>Seifert et al. <ref type="bibr" target="#b30">[31]</ref> give an overview of recent approaches generating text clouds. Their approach describes an iterative algorithm for optimizing font sizes and string truncation to place text bounding boxes into given polygonal spaces. We adapt this approach in Section 4.4. Feinberg <ref type="bibr" target="#b10">[11]</ref> provides a web service for creating text clouds. The used technique is not publicly described.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN OF THE DOCUMENT CARDS</head><p>Summarization necessarily is a lossy compression and requires a decision of what can be preserved and what has to be excluded. Document Cards try to address this problem with special foci that are reflected in the following constraints and design decisions:</p><p>• Document Cards are fixed size thumbnails that are selfexplanatory. Approaches like <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b20">[21]</ref>, and <ref type="bibr" target="#b9">[10]</ref> preserve the main structure of a document on a fixed size view. But these approaches require interaction, like browsing or listening, to get a global insight into a document. In <ref type="bibr" target="#b2">[3]</ref> the optimal scale for pages are calculated which breaks the constraint of a fixed size representation.</p><p>As Document Cards shall also be applicable on small screen devices like handhelds or mobile phones it is an important feature that they provide meaningful global representations on a given limited space.</p><p>• Document Cards represent the document's content as a mixture of images and important key terms. Erol et al. <ref type="bibr" target="#b9">[10]</ref> evaluated the most important parts of a document for the tasks of searching for it and understanding its content. Namely the top three are: title, figures, and abstract. Since we are aiming at a small representation we include the title (as top one feature), a filtered collection of figures, and we extract important keywords as an approximation for the content. Previous approaches, aiming at even smaller size representations, focus either on the semantic content (Semanticons <ref type="bibr" target="#b31">[32]</ref>) or the contained images and image texts (SmartNails <ref type="bibr" target="#b3">[4]</ref>), but not both. We present novel methods that carefully filter the most meaningful representatives of both categories and combine them in one view.</p><p>• Document Cards should be discriminative and should have a high recognizability. Summary Design Patterns <ref type="bibr" target="#b26">[27]</ref> provide a uniform look on summaries of picture collections. In opposition to that, Document Cards are designed to be easily distinguishable and recognizable. This is supported by the selection of meaningful images. Furthermore, the aspect ratio of images is preserved and the background of Document Cards is color-coded as described in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">AUTOMATIC GENERATION OF DOCUMENT CARDS</head><p>In this section we describe the pipeline for creating Document Cards (see <ref type="figure" target="#fig_0">Figure 2</ref>). We show how to extract text from a PDF file and find the key terms (4.1). Further we present an image and caption extraction algorithm (4.2). We then discuss how images are scaled by their semantical weight and how we classify them (4.3). In Section 4.4, we show how to use the generated input to visualize a document as a Document Card.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Key Term Extraction</head><p>For each document we have to extract the key terms that describe the topics of the document. In the field of biomedical text mining the distribution of keywords in scientific publications has been examined several times. Shah et al. <ref type="bibr" target="#b32">[33]</ref> searched for keywords in five standard sections and came to the conclusion that "information is unevenly distributed across the sections of the article, that is, different sections contain different kind of information". A study by Schuemie et al. <ref type="bibr" target="#b28">[29]</ref> that also examined five standard sections had a similar outcome, which was that "30-40 % of the information mentioned in each section is unique to that section". Both studies come to the conclusion that abstracts, while having the highest keyword density, do not even nearly cover all the information (keywords) contained in a full-text scientific article.</p><p>Based on these findings we decided not to limit the term extraction to abstracts. Instead, we use full-text articles regarding the section boundaries also as topic boundaries. An author usually starts a new section, when writing about a different topic or sub topic. As a result, non-relevant terms will appear equally distributed over all sections of the document, while the important key terms will not. They have higher frequencies in the sections of their particular topics and a lower frequency in the others. Thus, the non-equally distributed terms are the key terms we are looking for.</p><p>At first we have to find the sections in the documents. We extract the text lines of the PDF files and train a machine learning algorithm on geometry, formatting, and text features to identify the headlines of the sections. In the same step we also distinguish between the continuous text of a section and other text information like headers, footers, tables, or captions. Scanning line by line through the document we discover sections by their headlines. A new section is started, when a top-level headline is hit. Afterwards, all the continuous text lines are added to the latest section until a new section is started.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Preprocessing and Candidate Filtering</head><p>The preprocessing comprises sentence splitting, part-of-speech tagging and noun phrase chunking with OpenNLP-Tools <ref type="bibr" target="#b0">[1]</ref> and a base form reduction of words according to Kuhlen's algorithm <ref type="bibr" target="#b19">[20]</ref>.</p><p>Next, in the candidate filtering step we eliminate stopwords and noise. Verbs are also deleted, a decision that is based on the empirical observation that even verbs which have a characteristic distribution are of a rather general nature. For many papers the salient verbs are e.g. "work", "show" or "compute". Whereas approach-specific verbs mostly also appear in their nominalized form. For example, for the paper at hand it would be much more meaningful to get the terms "image extraction" or "term extraction" than the verb "extract".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Special Noun-Phrase Processing</head><p>Compound nouns, noun phrases consisting of at least two terms, have the highest potential to be very descriptive for a certain paper. Among the 130 index terms that the authors of the InfoVis 2008 publications manually assigned to their papers, 92 (about 70 %) correspond to compound nouns, which emphasizes their importance. This is because they often correspond to technical terms that are very specific and descriptive for a described approach.</p><p>At the same time we also consider sub phrases of larger noun phrases. The noun phrase "a term extraction algorithm" has several sub phrases that might be interesting. Our algorithm deletes leftmost articles like "a" and then builds every rightmost sub phrase, e.g. in this case "term extraction algorithm", "extraction algorithm" and "algorithm". In most cases by shortening the noun phrase in this particular way, the shorter representations are generalizations of the longer ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Term Scoring and Term Extraction</head><p>For the term scoring, the PDF file is scanned and the occurrence of every term is counted for each section separately. As a result, we get a vector for every term where each dimension corresponds to a section and each dimension's value is the number of occurrences of that term in the section. We keep only those terms that occur at least seven times in the document. All other terms are considered to be too infrequent to be key terms.</p><p>For each of the remaining vectors we calculate how strongly it deviates from an equal distribution using an extension of the χ 2 -measure:</p><formula xml:id="formula_0">χ 2 sec (t, D) = ∑ s∈D        freq(t,s)−freq(t,D) size(s) size(D) 2 freq(t,s) , if freq(t, s) &gt; 0 0, else ,</formula><p>where D denotes the document, s the section and t the term. Accordingly, freq(t, s) is the occurrence count ( For every section, we calculate the squared deviation of the observed frequency from the expected frequency is summed up, after normalizing it by dividing it by the observed frequency. Usually in the χ 2 -test the normalization is done by dividing by the expected frequency, which is changed here to avoid overestimating terms in very short sections. For example, a term that appears once within a section of 10 words in a paper of 1000 words. The summand for this term and this section would be ((1 − 1 • (10/1000)) 2 )/(1 • (10/1000)) = 98 which is inappropriately high and would distort the overall result. With our normalization, the corresponding summand is only 0.98. The modification of the normalization still scores terms with strongly deviating distributions higher but without the undesired effect of potentially over-scoring terms that appear in very short sections. At the same time, sections where a term is not contained do not contribute to the term score. Hence, high scores are assigned to terms that not only have a skewed distribution but also are present in several sections. This guarantees that terms are preferred that not only appear in one section but ideally play a vital role in distinct parts of the document.</p><p>Despite their descriptive nature, compound nouns are usually not among the highest scored terms according to the described method. To improve the score of the compound nouns, we boost them by doubling their occurrence counts compared to normal terms.</p><p>After scoring the terms with our χ 2 sec scoring function, the top-k terms with the highest scores are extracted. If there are compound nouns in the top-k terms, which are contained by other compound nouns also present in the top-k, then the shorter ones are discarded and replaced by the terms with the next highest scores. For example, if the terms "extraction algorithm" and "algorithm" are present within the top-k terms, we delete the latter one keeping only the longest and thus most specific compound noun. The number k of terms to extract is determined by the available layout space in a DC.</p><p>The strength of our key term extraction approach is the corpus independence. Approaches like TFIDF that use a document corpus for comparison in order to score and extract terms are not applicable if there is no suitable comparison corpus available. In opposition to that, our method does not depend on additional data sources and can be applied only having a document itself. Furthermore, TFIDF prefers to extract terms that discriminate one document from the others and in our approach we aim to extract descriptive terms for single papers that not necessarily have to be discriminating. Otherwise, topics that dominate a document corpus would not be extracted because of their lacking discrimination power. That means, if for example many papers within the InfoVis corpus tackle graph-related problems, we want the corresponding terminology to be extracted. This provides us with the valuable information that graph methods are common to many approaches -a fact that we otherwise might not be aware of.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Comparison to a Section-Based TFIDF Approach</head><p>As we possess section information, it would also be possible to apply a TFISF "term frequency inverse section frequency" approach to extract terms from a single document. In this case for a specific term we get several TFISF values per document, one for each section. Then, these values have to be mapped to a single term score for a term with respect to a document. One obvious option is to take the average TFISF value as term score:</p><formula xml:id="formula_1">avg − tfisf (t, D) = 1 n • ∑ s∈D (tf (t, s)) • is f (t, D)) = is f (t, D) n • ∑ s∈D tf (t, s) isf (t, D) = log n |{s : t ∈ s}| + 1</formula><p>After the transformation of the equation we can single out three factors: ∑ s∈D t f (t, s) is the sum of the frequencies the term t has in the different sections. It is possible to sum up either absolute or relative frequencies. As 1/n is just a constant factor that is the same for all terms the only other relevant parameter is the isf value, which takes into account in how many sections a term is present. A weak point of the formula is the binary nature of this isf : It makes no difference if a term is frequent or infrequent in a section as long as it occurs at least once. This drawback is a main disparity to our χ 2 sec approach. We applied both methods to test documents to review the implications of our idea on a practical scenario. We observed that the avg-TSISF approach tends to prefer terms that appear only in one section, which is not what we are aiming at.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Image Extraction</head><p>To extract the images and their associated captions we make use of the freely available tools ghostscript <ref type="bibr" target="#b12">[13]</ref> and pdftohtml <ref type="bibr" target="#b18">[19]</ref>. Ghostscript provides us with all the necessary information to render a version of a page that only contains the images. Pdftohtml is used to create an xml file describing the position, width, length, and strings of text boxes of each page. We combine the output of both tools to create a schematic map of images and text boxes as shown in <ref type="figure" target="#fig_2">Figure 3</ref>. In the map all image pixels are rendered in black, text boxes in red, and caption candidates in green. Here, the height of the text boxes is increased to receive continuous text clusters. A continuous text cluster is defined as a caption candidate if it starts with a caption indicating keyword such as "figure" or "table". To extract the images, a scanline runs from top to bottom of the schematic map to find the image coordinates. An image is defined as the region between a first image pixel (black pixel) and a line containing a figure reference (green pixel) or a line which contains mostly standard text (mostly red pixels), in case we missed a caption text. For two-column documents we run three scanlines, one for the whole page width and one for each column. <ref type="figure" target="#fig_2">Figure 3</ref> shows examples for which the image extraction is difficult. On the left page the captions are written on top of the images and the images are visually not separated. The page on the right side contains an image that consists of four separate parts but that only has one single caption. The advantage of the approach is that it even performs well for such special cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Image Weight and Image Classification</head><p>Important images are slightly enlarged to make them more prominent. We consider an image as important if an important key term is found in its descriptive text. We use the concatenation of an image's caption and its referencing text as descriptive text. The referencing texts are sentences of the document that refer to the specific figure and are found by a regular expression. To map the importance of an image we define the following scaling function:</p><formula xml:id="formula_2">scale = (1.0 + scale max • w max ) size image = size image • scale,</formula><p>where w max is set to the maximum weight of the key terms found in the descriptive text (as calculated in the term extraction step) and scale max is a constant factor that controls the influence of the key terms with respect to the size of the images. We experimentally set scale max to a value of 0.5. By this method we consider the combination of the original image size and a semantical size boost for later processing.</p><p>Next, we classify the images into one of the following categories:</p><p>• A table (T) is a set of facts systematically displayed. Its colors are mostly black and white.</p><p>• An image of category (A) is a diagram, a sketch, or a graph image which shows a concept or has explaining character. It uses a reduced number of colors.</p><p>• An image of category (B) is a photography or rendered image which shows a real world scenario or an expressive computer generated scenario. It is characterized by many colors, which have a rather complex distribution across the color space.</p><p>In the classification process each image is represented as an HSV color histogram with 8 values per channel and 8 values for grayscale, resulting in 8 3 + 8 = 520 values per histogram. The values of the histogram are normalized by the total number of pixels and sorted in decreasing order. This allows us to compare different images with respect to their distribution of color usage across the color space instead of the specific colors they use. As recommended in <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b24">[25]</ref>, and <ref type="bibr" target="#b7">[8]</ref> we use Support Vector Machines (SVM) as the classification method (in our case the implementation that is provided by the LIBSVM library <ref type="bibr" target="#b5">[6]</ref>) and the Kullback-Leibler divergence as distance function. We use a radial base function in the SVM and train it with 57 representative images from the IEEE Vis 2008 proceedings corpus. In the classification step, the most probable class label is assigned to an image. The usage of the class labels is described in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Layout</head><p>In the previous sections we explained how to extract the images and key terms. The images are resized according to their semi-semantic weight and assigned to one of the image classes. In this section we describe the transformation from these bag of terms and set of images to a compact view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Image Handling</head><p>In each Document Card up to 4 pictures are shown. These are chosen as follows: First, images that have been classified as tables are omitted. The reason for this is that downscaled tables do not provide much information because their contained text in small font size is not readable. Only if no other image is available, a table is shown in the DC. Next, the remaining images are sorted with respect to their size (the size is influenced by their semi-semantic weight as explained in 4.3). We take the first four images of the list to display them in a Document Card. During this process, we check if the following two constraints are fulfilled: a) We want to display at least one image from each category. Thus, if there is no image of category A (or B) included in the list, the last image in the list is discarded and substituted with the the largest image of category A (B, respectively). b) If the area of an image in the list is smaller than 25% of the area of the largest image, the image is discarded. This is done to avoid the insertion of too small images.</p><p>After filtering, the images are packed into the DC canvas. Packing of image bounding boxes to fit optimally in size to a given aspect ratio is an NP complete problem. Therefore, a good approximation is needed, that provides a fast solution with good results. Itoh et al. <ref type="bibr" target="#b14">[15]</ref> have presented such an algorithm which we adopted and extended. They suggest to use a penalty function for each image insertion which respects the bounding box increase and the difference from the aimed bounding box aspect ratio. Our extension takes the original position of an image on a page into account for defining a new penalty function argument. That means, that images appearing in the upper right of the original page tend to appear up right in the summary visualization. This optimizes animation of the interaction part. After arranging the bounding boxes, the calculated layout is scaled to fit into the DC canvas.</p><p>The images are positioned iteratively on the Document Card according to the coordinates that are given by the packing algorithm. At the same time we collect information about the free areas of the canvas that the key terms will be placed in later. This is done as follows: For each insertion of an image the surrounding free space rectangle is split into up to 4 new rectangles located on the top, bottom, left, and right side. In <ref type="figure" target="#fig_3">Figure 4</ref> the procedure is illustrated for an insertion of the first and second rectangle. After inserting the first image at its calculated position, the DC canvas is split into a left, right, top, and bottom section (left side of <ref type="figure" target="#fig_3">Figure 4)</ref>. The second image is placed under the first one in this example. It splits the free space rectangle at the bottom into three new sections: left, right, and bottom (right side of <ref type="figure" target="#fig_3">Figure 4)</ref>. By splitting the canvas with horizontal lines we support the creation of free space rectangles with mostly a width/height ratio larger than one. This is important for placing text items in these free spaces since they have a width/height ratio much larger than one. The following algorithm details the process: a list L i of images with calculated positions; a list L r of free space rectangles; initialize L r with the DC canvas bounding box; for all i in L i do for all r in L r that intersect i do split r into r T , r B , r L , and r R ; add all r X to L r ; remove r from L r ; end for end for 4. <ref type="bibr" target="#b3">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.2 Text Handling</head><p>The term extraction (4.1) outputs a list of terms with associated weight. To place the terms into the canvas, we extend the idea given in <ref type="bibr" target="#b30">[31]</ref>. In order to avoid term overcrowding and to guarantee good readability the number of terms that is shown in a DC depends on the size of the available free area after the image positioning step. The number of terms (n) that is displayed on a DC is determined as follows:</p><formula xml:id="formula_3">n = κ • A DC − A Im • A DC</formula><p>where A DC is the total area of the Document Card, A Im * is the cumulated area of all placed images, and κ is a constant of maximal terms that should fill an empty DC. We use the font size to indicate the relative term weight. Using and mapping different font sizes is a critical part in the layout process because text is less scaleable than graphics. To ensure readability, the variation of the font size of the different key terms has to be limited to a small range. The font size s i for a key term i is calculated as follows:</p><formula xml:id="formula_4">s i = s max • scale i scale i = s min s max + β • w i − w min 1.0 − w min ,</formula><p>where s max is the maximum font size, s min is the minimal font size, w min is the minimal term weight for a document, and w i is the term weight for term i. The value of β can be varied between 0 ≤ β ≤ 1 − s min s max depending on the available free space on the DC. To position the text boxes in the canvas we first sort the free space rectangles that have been collected in the image extraction step by decreasing size. The list of key terms is sorted by term weight. Iterating over the list of terms and rectangles a term is positioned in the center of the first rectangle that is large enough to host it. Afterwards the rectangle is split like in the image extraction step to detect the remaining free space in this rectangle. If there are remaining terms after the procedure that cannot be positioned anymore, β is decreased and the process is repeated. The algorithm terminates when all terms are positioned or β &lt; 0.</p><p>By using this algorithm we try to position the important terms in the middle of free space areas. This will support stability in future advanced (semantic) zooming approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Finishing</head><p>After positioning the images and keyterms, the Document Card is enriched with the document title and the documents author names. We further add a page number list at the right side of each card to show the overall size of a document and to allow navigation as explained in the Application Section <ref type="bibr" target="#b4">(5)</ref>. For better discrimination we color code the background of each DC in the following way: From all images positioned in one DC canvas we evaluate the most frequent color value (H value in HSV color model). We use this color value less saturated as background color.</p><p>We applied the DC approach to the InfoVis proceedings of 2008. <ref type="figure">Figure 6</ref> shows the corpus as a matrix of Document Cards. The tool provides the following interaction features for a Document Card (DC):</p><p>• Hovering over the non-image space in a DC shows the extracted abstract of the document as tooltip.</p><p>• Hovering over an image displays the image's caption as tooltip.</p><p>• Clicking on a page number (right side of a DC) starts a transition to the full page (see for example DC 3 in <ref type="figure">Figure 6</ref> that has been switched to page mode and shows page 2).</p><p>• Clicking on an image starts a transition to the page containing the image.</p><p>• Clicking on a term highlights the term in the overview and in all tooltips for this document. Additionally, all images containing this term in their descriptive text are highlighted. The term density is shown in the page indicator on the right side of a Document Card. The higher the density of the term on a page the less transparent is the corresponding tab. (This technique is shown in DC 12 of <ref type="figure">Figure 6</ref> in which the term "tree diagram" has been selected). The hovering approaches provide readability of the caption and abstract text even if the DC is in small scale. To show the connection between images and terms we introduced the idea of highlighting on term clicking. Our supplementary video illustrates these interaction ideas. <ref type="figure">Figure 6</ref> gives a quick overview of the InfoVis 2008 paper collection. <ref type="bibr" target="#b0">1</ref> Skimming over the DCs it is easily perceivable that many graph-based techniques have been accepted to last year's conference (e.g. DC 0, <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24)</ref>. Such a first impression of the content of the collection is usually based on the images that are depicted. As InfoVis is a visualization conference images are naturally very expressive with respect to what a paper is all about. However, if only the images were given it would be hard to tell in which area of graph-related approaches a paper contributed. The title of the paper and the automatically extracted terms help to clarify this. They reveal for example that DC 0, 4, 7, and 17 are all papers that deal with graph layout algorithms. DC 13 represents a paper that proposes a visualization approach for large power-law graphs. Omitting unimportant information is important here which is also reflected in the terms of its DC (e.g. "simplification method, edge filter, . . ."). On the other hand the papers of DC 22 and 24 conducted user studies related to graph layout and the impact of data transformation techniques respectively. Consequently, terms such as "experiment, study, human observer, and anova test" appear on their DCs. The above examples show that both the graphical and the textual information of a paper are important to convey its content. Finally, DC 14 and 15 are interesting because they do not contain any visualizations at all (but only schematic diagrams). Although this might seem strange at first for a visualization conference there is a simple explanation: Both papers contribute with theoretical work in the context of Information Visualization instead of presenting novel visualization techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Analyzing the InfoVis 2008 proceedings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Applicability on Large and Small Devices</head><p>Document Cards are suitable for both the visualization of single documents on small devices and to provide an overview of large document collections on larger devices. <ref type="figure" target="#fig_4">Figure 5</ref> shows an example for both scenarios. The left side of the figure depicts a mockup of a Document Card on a mobile device. On the right side you can see the whole collection of the IEEE Vis 2008 proceedings (consisting of 46 papers) on a 56 inch display with high resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>Document Cards provide a meaningful and representative small-scale overview of a document that is applicable for a broad range of document types and display sizes. We present a pipeline for the automatic creation of Document Cards with contributions in several subtasks. The main contributions of our approach are novel methods to automatically extract and select the most expressive images and the most descriptive key terms out of a document. The top key terms are extracted by an advanced text mining approach that combines automatic document structure extraction with an extension of the χ 2 -measure. Terms with a characteristic intra-document distribution are extracted which makes the approach independent from further data resources as e.g. corpora for comparison. In addition, meaningful compound nouns get a higher weight in our approach as they are generally very descriptive and document-specific. During image extraction, we combine a novel semi-semantic image weighting with an image classification approach. An image's weight depends on the presence of the previously extracted key terms within its descriptive text. Both images and their descriptive texts (captions and reference sentences) are extracted in a fully automatic way. For this purpose we developed a new method that is capable to solve even problematic cases, e.g. when captions are printed on images. Finally, an image classification is applied with the purpose to capture images that are still meaningful in a small-scale picture. This implies that e.g. we do not consider tables or thin-lined graphs. Furthermore, the classification allows us to prefer the insertion of at least one representative of each image class if the space is too limited to insert all potentially useful images. In application Document Cards support tasks like browsing, recognition, and acquiring an overview of whole sets of documents. Therefore, they were enhanced with a wide range of interaction features. In a preliminary user study the users stated to be more efficient and have more fun browsing paper collections with document cards than with a PDF reader.</p><p>In future work, we aim to include Document Cards in larger visualizations like clusterings, author networks, or citation networks. These techniques can introduce better interaction approaches for full collections. We want to investigate if the embedding of image's references in the document structure can improve the selection process. Furthermore, the creation of an enhanced semantic zooming approach is planned. Depending on the current space availability more or less content will be provided. As part of the interaction improvement and semantic zooming we will investigate cluster-wide text features for each document and the cluster itself and therefore allow a view on a document in its semantical surrounding. Key terms are scheduled to be extracted in a hierarchical manner for clusters and documents possibly combining our approach with a TFIDF-like technique. In addition we will apply image enhancement. Some images with sparse or high frequent content could be enhanced by finding regions of interest and stress these regions by providing more abstraction or highlighting their main structure. As part of image enhancement we will introduce approaches for external image acquisition for text only documents. We will test different layout approaches that amplify the relation between images and texts.  <ref type="figure">Fig. 6</ref>. The IEEE InfoVis 2008 proceedings corpus represented by a matrix of Document Cards (DC). DC 3 has been switched to the page view on page 2. In DC 12 the term "tree diagram" has been clicked. This highlights the image where the term occurs in its caption (on the bottom of DC 12). The frequency of the term on each page is shown on the right side of the DC (the more red, the higher the frequency).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>The Document Card pipeline. Each step is further explained in the sections indicated by the number in the top right corner of each box.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>observed frequency) of term t in section s, freq(t, D) the term's count in document D and size(x) means the number of terms in a text unit x. The part freq(t, D) • size(s)/size(D) thus describes the expected frequency of a term t in a section s, if we assume equal distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>The schematic maps of two document pages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>The split algorithm used for finding empty space rectangles: After insertion of image 1 the canvas is split into 4 regions. The bottom region is further split into 3 new regions on insertion of figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Applications for different screen sizes: On the left side a mockup of a Document Card on a mobile device. On the right side the IEEE Vis 2008 proceedings corpus displayed on a 56 inch display.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Andreas Stoffel, E-mail: andreas.stoffel.ext@siemens.com Manuscript received 31 March 2009; accepted 27 July 2009; posted online 11 October 2009; mailed on 5 October 2009. For information on obtaining reprints of this article, please send email to: tvcg@computer.org .</figDesc><table /><note>• Hendrik Strobelt, Daniela Oelke, Christian Rohrdantz, Daniel A. Keim, and Oliver Deussen are with the University of Konstanz, E-mails: {hendrik.strobelt, daniela.oelke, christian.rohrdantz, daniel.keim, oliver.deussen}@uni-konstanz.de •</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Please note that one of the papers was not automatically parsable and therefore does not show up in the DC matrix.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors gratefully thank Josua Krause for reducing the workload of creating a good prototype. This work has partly been funded by the German Research Society (DFG) under the grant GK-1042, Explorative Analysis and Visualization of Large Information Spaces, Konstanz, and by the German Federal Ministry of Economy and Technology (BMWi) under the THESEUS project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baldridge</surname></persName>
		</author>
		<ptr target="http://opennlp.sourceforge.net/" />
		<title level="m">The opennlp project</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spatial Tools for Managing Personal Information Collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fastrez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hollan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Hawaii Int. Conf. on System Sciences, 4:104b</title>
		<meeting>of Hawaii Int. Conf. on System Sciences, 4:104b</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How small should a document thumbnail be?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Berkner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SPIE</title>
		<meeting>of SPIE</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6076</biblScope>
			<biblScope unit="page" from="127" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Smartnails -Display-and Image Dependent Thumbnails</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Berkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Marle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SPIE</title>
		<meeting>of SPIE</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5296</biblScope>
			<biblScope unit="page" from="54" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Baird</surname></persName>
		</author>
		<title level="m">Paper to PDA. Proc. 16th ICPR</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="476" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">LIBSVM -A Library for Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/˜cjlin/" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Layout and Content Extraction for PDF Documents. Document Analysis Systems VI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="213" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Support Vector Machines for Histogram-Based Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1055" to="1064" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Faster Document Navigation with Space-Filling Thumbnails</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cockburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alexander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CHI</title>
		<meeting>of CHI</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multimedia Thumbnails for Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Erol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Berkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 14th ACM Intern. Conf. on Multimedia</title>
		<meeting>of the 14th ACM Intern. Conf. on Multimedia</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="231" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Wordle -Beautiful Word Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feinberg</surname></persName>
		</author>
		<ptr target="http://wordle.net/" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Text Mining at the Term Level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fresko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kinar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lindell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Liphstat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rajman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Zamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2nd European Symposium on Principles of Data Mining and Knowledge Discovery (PKDD&apos;98)</title>
		<meeting>of the 2nd European Symposium on Principles of Data Mining and Knowledge Discovery (PKDD&apos;98)</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="65" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<ptr target="http://www.ghostscript.com/" />
		<title level="m">Ghostscript</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multidimensional Icons. ACM Trans. on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="133" to="137" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hierarchical Data Visualization Using a Fast Rectangle-Packing Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ikehata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kajinaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="302" to="313" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Methods of Automatic Term Recognition: A Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kageura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Umino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Terminology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">259</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimal Rectangle Packing: Initial Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Korf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 13th Intern. Conf. on Automated Planning and Scheduling (ICAPS03)</title>
		<meeting>of the 13th Intern. Conf. on Automated Planning and Scheduling (ICAPS03)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="287" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extracting Information from Text and Images for Location Proteomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd ACM SIGKDD Workshop on Data Mining in Bioinformatics (BIOKDD03)</title>
		<meeting>3rd ACM SIGKDD Workshop on Data Mining in Bioinformatics (BIOKDD03)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="2" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">PDF to HTML conversion tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kruk</surname></persName>
		</author>
		<ptr target="http://sourceforge.net/projects/pdftohtml/" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Experimentelle Morphologie in der Informationswissenschaft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kuhlen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Verlag Dokumentation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Summary Thumbnails: Readable Overviews for Small Screen Web Browsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CHI</title>
		<meeting>of CHI</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="681" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">VisualIDs: Automatic Distinctive Icons for Desktop Interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosenholtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="page" from="416" to="423" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Finding Captions in PDF-Documents for Semantic Annotations of Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maderlechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Panyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Suda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Structural, Syntactic, and Statistical Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006-01" />
			<biblScope unit="volume">4109</biblScope>
			<biblScope unit="page" from="422" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Keyword Extraction From A Single Document Using Word Co-Occurrence Statistical Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intern. Journal on Artificial Intelligence Tools</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="157" to="169" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 16</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rectangle-Packing-Based Module Placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Murata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fujiyoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakatake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kajitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Intern. Conf. on Computer-Aided Design (ICCAD)</title>
		<meeting>of Intern. Conf. on Computer-Aided Design (ICCAD)</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Synthesizing Evocative Imagery Through Design Patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dieberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Center</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Jose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Hawaii Int. Conf. on System Sciences</title>
		<meeting>of Hawaii Int. Conf. on System Sciences</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Vector Space Model for Automatic Indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="613" to="620" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Schuemie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weeber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J A</forename><surname>Schijvenaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Van Mulligen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Van Der Eijk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jelier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distribution of Information in Biomedical Abstracts and Full-Text Publications. Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="2597" to="2604" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Packing Lightmaps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scott</surname></persName>
		</author>
		<ptr target="http://www.blackpawn.com/texts/lightmaps/" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kump</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kienreich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Granitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
		<title level="m">On the Beauty and Usability of Tag Clouds. Proc. of the 12th Intern. Conf. on Information Visualization (IV)</title>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="17" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Semanticons: Visual Metaphors as File Icons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Albrecht-Buehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Gooch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum (Eurographics)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="647" to="656" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Information Extraction from Full Text Scientific Articles: Where Are the Keywords?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Perez-Iratxeta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Andrade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Statistical Interpretation of Term Specificity and Its Application in Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Spaerck-Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic Thumbnail Cropping and Its Effectiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 16th ACM Symp. on User Interface Software and Technology (UIST)</title>
		<meeting>of the 16th ACM Symp. on User Interface Software and Technology (UIST)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Popout Prism: Adding Perceptual Principles to Overview+Detail Document Interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Woodruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosenholtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CHI</title>
		<meeting>of CHI</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On the Efficient Evaluation of Probabilistic Similarity Functions for Image Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1482" to="1496" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
