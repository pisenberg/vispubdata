<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualizing Volume Data Using Physical Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">R</forename><surname>Nadeau</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">San Diego Supercomputer Center</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Bailey</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">San Diego Supercomputer Center</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Visualizing Volume Data Using Physical Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Computational Geometry and Object Modeling -Hierarchy and geometric transforms</term>
					<term>Object hierarchies</term>
					<term>Curve, surface, solid, and object representations scene graphs, volume graphics, volume visualization, physical models</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Visualization techniques enable scientists to interactively explore 3D data sets, segmenting and cutting them to reveal inner structure. While powerful, these techniques suffer from one serious flaw-the images they create are displayed on a flat piece of glass or paper. It is not really 3D-it only can be made to appear 3D. In this paper we describe the construction of 3D physical models from volumetric data. Using solid freeform fabrication equipment, these models are built as separate interlocking pieces that express in physical form the segmentation and cutting operations common in display-based visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Volume data sets provide a sampled representation of measured or computed quantities that vary across a region of space. Medical scanning technologies, for instance, can produce data sets that depict the inner structure of the body. Computer simulations can produce data describing flow across an airfoil, temperatures in the Pacific Ocean, etc. Data sets such as these exhibit complex inner structure embedded within the volume.</p><p>To reveal this inner structure, visualization techniques can segment and cut away portions of the data. Segmentation assigns an opacity value to individual data values within the volume. Data of interest is given high opacity, while less interesting data is made transparent. By setting different opacity levels for different data values, users can interactively disassemble the data set to reveal, say, the skull in medical data of a human head. Adjusting opacity levels further can remove the skull and reveal the brain, the eyes, or other data set components. <ref type="figure">Figure 1</ref>.1 illustrates these common segmentation and cutting techniques. Here data for the head of the Visible Human Male <ref type="bibr" target="#b4">[5]</ref> is segmented to extract data for the skull, brain, optic nerves, and eyes. In <ref type="figure">Figure 1</ref>.1a, a cutting volume slices open the skull and a transform rotates half of it away to reveal the brain inside. In <ref type="figure">Figure 1</ref>.1b, additional cutting volumes slice the brain and spread the slices apart to reveal the brain's complex inner structure. Segmentation and cutting are obviously powerful ways of exploring a data set.</p><p>However, computer graphics-based exploration has one serious flaw -the images it creates are displayed on a flat piece of glass or paper. The images are not really 3D, only an illusion of 3D created by clever software.</p><p>In contrast, real-world physical models have several visualization advantages:</p><p>• They are in the real world. A physical model can be held, felt, and rotated about in a natural way.</p><p>• Physical models can be viewed interactively regardless of complexity.</p><p>The real world has no polygons/second limitations. Similarly, lighting, shadows, and collisiondetection are all free.</p><p>• Physical model viewing doesn't require expensive graphics hardware. The models can be viewed anywhere, even by people without technical training, such as children in a K-12 classroom.</p><p>Display-based visualization has had the advantage because of its ability to non-destructively segment, cut, and explore data. This is more difficult to do in the real world. Performing segmentation of a real-world head to cleanly extract the skull and brain would be a very destructive (and gruesome) process.</p><p>In this work we leverage the strengths of display-based visualization and real-world physical models. We start by using segmentation and cutting techniques to non-destructively extract data of interest from volumetric data. Then we use the results to manufacture multiple pieces for an interlocking physical model of the segmented data. The user can manipulate these models, in the real world, to gain further insight into the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BUILDING PHYSICAL MODELS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Segmenting the Data</head><p>This work used the head portion of the Visible Human Male data set from the National Library of Medicine <ref type="bibr" target="#b4">[5]</ref>. To manipulate the data, CT and cryosection volumes, as well as a commercially available segmentation volume, were imported into a volume modeling system. The volume modeling system is based upon a volume scene graph <ref type="bibr" target="#b3">[4]</ref>: a hierarchical organization of shapes, groups of shapes, and groups of groups that collectively define the content of a scene. The scene graph's nodes are functions that take a 3D location in space as an argument. When evaluated at such locations, a node function returns a color value. Most functions return values that may vary over space. Procedural texture functions, for instance, use 3D noise, turbulence, or marble vein algorithms to compute a return value. Volume data set functions use the 3D-location argument to select and interpolate voxel values from a data set read from disk.</p><p>Voxelization of a volume scene graph repeatedly evaluates the graph's functions, once for each 3D location in a grid spanning a region of interest. Each evaluation returns an RGB-alpha value that is saved into a voxel in a new discrete volume data set.</p><p>To visualize the Visible Human Male head, CT, cryosection, and segmentation volumes of differing resolutions were imported as leaf nodes in a volume scene graph. Each data set was left in its original resolution, without resampling.</p><p>For the CT data, classification nodes in the scene graph used the data set's scalar values to select RGB-alpha values that gave the skull a high opacity while dropping the rest of the data set to transparency. For cryosection data, scene graph nodes masked the segmentation volume against the cryosection data to extract data for the brain, optic nerves, and eyes. The CT skull was transformed to register it into the coordinate space of the cryosection data.</p><p>Finally, the skull and brain data were composited together to create a scene that was voxelized and volume rendered. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Isovoluming for Manufacturability</head><p>When drawing a graphics scene on a display, an isosurface is an adequate solution. But for manufacturing the fabrication machine must have some sense of what is meant to be solid (inside) and what is meant to be air (outside). Thus, a surface is not enough. Rather, what must be produced is an isovolume <ref type="bibr" target="#b2">[3]</ref>, or what has also been called an interval volume <ref type="bibr" target="#b5">[6]</ref>. This process requires two scalar values to be specified, an S min and an S max . The isovolume will be the solid volume that is between these two isosurfaces.</p><p>It is interesting to note that while most of the visualization world is concerned with polygon decimation, this process can improve the smoothness of the model by applying "polygon incremation" <ref type="bibr" target="#b2">[3]</ref>. This process recursively subdivides boundary triangles to create a surface that is a closer approximation to the true trilinear interpolation function within each voxel cell. Such things are reasonable when you care more about model quality than interaction speed.</p><p>To enable the physical model of the brain to be taken out of the skull, the skull needed to be split in half. Not long ago, the only way to make this happen would have been to generate the isovolume, import it into a CAD solid modeler, and use constructive solid geometry techniques to split the skull and move the two pieces away from each other. The volume scene graph approach, however, is a much more optimal way to go about this. In data handling theory, there is the concept of higher-order data and lower-order, or derived, data. In this case, the original volume data is the higher-order data and the polyhedral isovolume is the derived lower-order data.</p><p>When moving from high order to low order data, some information is, by necessity, removed. In this case, it is the relationship between the data values among the multitude of voxels that is lost. For example, suppose that there was a certain amount of noise in the original volume data set. As a volume, that noise could be filtered out prior to generating the isovolume. But, if the isovolume had been created from the noisy volume first, then chances are slim that the noise could be filtered out of the isovolume's polygons.</p><p>The same can be said for resolution control. While the data is in voxel form it can be filtered, subsampled, or supersampled. The fineness or coarseness of the polyhedral isovolume can be controlled very tightly depending on the resolution of the voxel data that produced it. Isovolume experiments have shown that adding more polygons through the polygon incremation process does not produce as smooth a result as adding more polygons by supersampling the original volume.</p><p>This work used the scene graph to slice the data set into manufacturable pieces. <ref type="figure">Figure 1</ref>.1b shows these pieces, including the skull cut vertically, and the brain cut horizontally into four slices. Arbitrarily oriented flat or curved cutting surfaces could have been used just as easily. <ref type="figure">Figure 2</ref>.2 shows the scene graph to generate these pieces.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Manufacturing the Pieces</head><p>In 1995, the San Diego Supercomputer Center (SDSC) TeleManufacturing Facility (TMF) project was started as a way to produce physical hardcopy to enhance visualization. This project has resulted in hundreds of visualization models being made for researchers all over the country <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>The TMF consists of two fabrication machines, both connected to the Internet to provide access and monitoring from virtually anywhere.</p><p>One machine is a Helisys Laminated Object Manufacturing machine, which makes 3D parts from layers of paper or plastic. The other machine is a Z Corporation Z402 machine, which fabricates from layers of powder. Both machines leave their scrap in place during the build so that overhangs are supported and needn't require any perturbations in the part geometry.</p><p>All rapid fabrication machines are driven by the de facto standard STL file format. The exact format of the STL files can be found at <ref type="bibr" target="#b7">[8]</ref>, but basically it is a list of the 3D triangles that bound the outer skin of the solid. The isovoluming program is set up to produce its list of triangles in the STL format.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Results</head><p>Using the scene graph in <ref type="figure">Figure 2</ref>.2, the CT, cryosection, and segmentation volumes of the Visible Human Male were segmented and cut into pieces. The individual scene pieces were voxelized, isovolumed, and expressed as STL files. The skull halves were fabricated on the Helisys LOM machine, while each of the brain slices were fabricated on the Z402 machine.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CONCLUSIONS</head><p>The volume scene graph approach gives a great deal of flexibility to downstream analyses.</p><p>In the case of 3Dvisualization hardcopy, that flexibility results in better control over the location and orientation of a model's individual pieces. It also gives better control over the smoothness of the resulting isovolume. The physical models produced offer a compelling and natural way to explore the interior of complex volumetric data sets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 . 1 .</head><label>11</label><figDesc>Segmentation and cutting volumes reveal the inner structure of a complex volume data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 2 . 1 .</head><label>221</label><figDesc>1a shows the rendered scene and Figure 2.1b the scene graph. CT Volume Cryo Volume Seg Volume Select Mask Transform Composite Classify CT, cryosection, and segmentation volumes combined by a scene graph to create a scene containing the skull, brain, optic nerves, and eyes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 . 2 .</head><label>22</label><figDesc>The scene graph to cut volume-domain data into manufacturable pieces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 . 3 .</head><label>23</label><figDesc>The Helisys 1015 Laminated Object Manufacturing machine.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 . 4 .</head><label>24</label><figDesc>The Z Corporation Z402 machine.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figures 2.5 and 2.6 show the skull and four brain slices. Images of the cryosection data have been adhered to the slices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 . 5 .</head><label>25</label><figDesc>The fabricated skull and four brain slices within the skull.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 . 6 .</head><label>26</label><figDesc>The fabricated skull and four brain pieces with cryosection slices adhered.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The volume renderer we used was developed by Jon Genetti at the San Diego Supercomputer Center </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TeleManufacturing: Rapid Prototyping on the Internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="20" to="26" />
			<date type="published" when="1995-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Use of Solid Physical Models for the Study of Macromolecular Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Schulten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Structural Biology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="208" />
			<date type="published" when="1998-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Manufacturing Isovolumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Volume Graphics</title>
		<meeting>the International Workshop on Volume Graphics</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="133" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Volume Scene Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">R</forename><surname>Nadeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Volume Visualization and Graphics Symposium</title>
		<meeting>the IEEE Volume Visualization and Graphics Symposium</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The Visible Human Project</title>
		<ptr target="www.nlm.nih.gov/research/visible" />
		<imprint/>
		<respStmt>
			<orgName>National Library of Medicine</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tools for Triangulations and Tetrahedralizations and Constructing Functions Defined over Them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Nielson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scientific Visualization: Overviews, Methodologies, Techniques</title>
		<editor>Gregory Nielson, Hans Hagen, and Heinrich Muller</editor>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="429" to="525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A Touch of Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathy</forename><forename type="middle">A</forename><surname>Sviltil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998-06" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="80" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<ptr target="http://cvp.sdsc.edu" />
		<title level="m">The TMF has been renamed the Center for Visualization Prototypes. For more information on this project and on physical fabrication in general</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
