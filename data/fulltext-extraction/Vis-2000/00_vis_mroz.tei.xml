<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mastering Interactive Surface Rendering for Java-Based Diagnostic Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Mroz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Wegenkittl</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiani</forename><surname>Medgraph</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gesmbh</forename><forename type="middle">Eduard</forename><surname>Gröller</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Graphics</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computer Graphics</orgName>
								<orgName type="institution">Vienna University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Mastering Interactive Surface Rendering for Java-Based Diagnostic Applications</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Picture / Image generation-display algorithms; J.3 [Life and Medical Sciences]: Medical information systems volume visualization</term>
					<term>surface rendering</term>
					<term>medical applications. tomographic data</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The display of iso-surfaces in medical data sets is an important visualization technique used by radiologists for the diagnosis of volumetric density data sets. The demands put by radiologists on such a display technique are interactivity, multiple stacked transparent surfaces and cutting planes that allow an interactive clipping of the surfaces. This paper presents a Java based, platform independent implementation of a very fast surface rendering algorithm which combines the advantages of explicit surface representation, splatting, and shear-warp projection to fulfill all these requirements. The algorithm is implemented within the context of J-Vision, an application for viewing and diagnosing medical images which is currently in use at various hospitals.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>3D imaging in medical applications has now been used for more than a decade in the clinical environment. During this period of time, quality as well as speed of rendering volume data have been significantly improved, starting from early volumetric ray casters <ref type="bibr" target="#b1">[2]</ref> and surface rendering methods <ref type="bibr" target="#b0">[1]</ref> up to nowadays high performance volume and surface visualization methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7]</ref>. Nevertheless, most commercially available diagnostic products do not support interactive methods without massive use of hardware. This limits the use of volume visualization within a hospital to rather few dedicated workstations. Providing the required high performance graphics hardware for PCs at each medical doctor's desk is simply too expensive. This paper describes an algorithm which has been successfully used in the new Java based diagnostic software J-Vision / Diag by TIANI Medgraph. Since it is a software-only approach it is not limited to specialized hardware and runs on any platform which provides a Java runtime environment.</p><p>A standard method used for surface rendering is first-hit ray casting for depicting surfaces implicitly contained in volumetric data sets. On the other hand marching cubes <ref type="bibr" target="#b3">[4]</ref> and related methods create explicit polygonal representations of such surfaces. Although (first hit) ray-casting is a versatile method which is able to provide high-quality images, it is not suited for interactive investigation of real-life data sets on consumer hardware. Although various approaches to improve efficiency of ray-casting exist, high-end multi-processor hardware is required to achieve interactive framerates <ref type="bibr" target="#b6">[7]</ref>. Purely hardware-based solutions which exploit either 3D-£ mroz@cg.tuwien.ac.at Ý Rainer.Wegenkittl@tiani.com Þ groeller@cg.tuwien.ac.at textures or dedicated volume rendering hardware <ref type="bibr" target="#b5">[6]</ref> can not be taken into consideration for a portable cross-platform application. Due to the fact that fast polygon rendering hardware is available on many platforms, explicit surface extraction methods like marching cubes become more and more the method of choice for commercial applications. For storing even optimized triangle-based surface representations huge amounts of memory are required. Mainly the high memory consumption makes a polygonal model less suited for surface rendering within a cross-platform software.</p><p>The demands for a versatile and highly portable surface rendering algorithm can be summed up as following: software only approach: ensures highest portability and guarantees a comparable rendering speed on all platforms. low memory requirements: Modest memory requirements for the surface representation allow in combination with software based rendering to operate the software under low-resource conditions (like on notebooks).</p><p>clipping planes: should be applicable in real-timē high rendering speed: more then 10 frames per seconds on a standard PC for interactive navigation stacked surfaces: to provide context around objects of interest the algorithm should be capable of displaying several semitransparent surfaces.</p><p>Shear-warp <ref type="bibr" target="#b2">[3]</ref> and splatting techniques have proven to be very fast and efficient ways for volume rendering. For the proposed method a combination of these techniques is used which exploits the advantages of both. In combination with a very compact data description and rather low precomputation times, highly interactive surface rendering can be achieved. Section 2 describes J-Vision / Diag as the context in which the surface rendering algorithm is implemented. A description of the algorithm is provided in section 3, while section 4 focuses on available user-scene interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><p>J-Vision / Diag is a Java-based viewing and diagnostic workstation for a TIANI Medgraph PACS (Picture Archiving and Communication System). The software is used by radiologists to view and diagnose images from different modalities like computer tomographs, magnetic resonance tomographs and ultrasonic devices. In addition to basic two dimensional viewing functionalities, e.g.: zooming, filtering, windowing, the software also interprets stacks of images as volumes and displays arbitrary cuts through the volume (multi planar reconstruction, MPR), maximum intensity projections (MIP) and surface renderings. Efficient work flow is achieved by a user interface which makes extensive use of so called hot-regions (clickable areas within the image display area which directly invoke frequently used operations on the data).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Interactive Surface Rendering</head><p>To achieve real-time performance on affordable hardware, our algorithm unifies advantages of explicit surface extraction and representation with the advantages of fast rendering using splatting and shear-warp projection. We use parallel projection, as the examined objects are rather small in size and are viewed only from outside the volume. The creation of an explicit surface representation prior to rendering eliminates the need for surface detection during rendering as required by first-hit ray casting. To obtain a representation for the surface, the volume is scanned for transitions between voxels (=data samples) with a value below and above the threshold. From this a list of voxels belonging to the surface is built. If a voxel has a data value greater or equal than the threshold and has at least one 26connected neighbor below the threshold, it belongs to the surface and is added to the list. The voxels extracted during the scan make up a 6-connected surface within the volume at the specified threshold value. The 6-connectedness of the surface voxels is required to ensure that no holes appear during shear-warp based rendering due to displacement of voxels within successive slices.</p><p>For each surface voxel, it's position and the gradient vector are stored. To obtain a memory-efficient representation, the gradient vector is converted to polar coordinates´Ô Öµ instead of the usuaĺ Ü Ý Þµ representation and stored using 14 bits (7 bits per coordinate, as a tradeoff between shading quality and computational effort for precomputing shading). The storage scheme allows the encoding of 16384 distinct normal vectors which is sufficient for smooth shading of real-life data.</p><p>For rendering, the surface voxel data is replicated into three similar arrays, one for each principal viewing direction. Within each array, the voxels are sorted according to the coordinate corresponding to the axis most parallel to the viewing direction (for simplicity referred to as Þ coordinate. The procedure for the other viewing-axes is analogous). As the sorting produces groups of voxels with an identical Þ coordinate stored at consecutive positions within the array, the Þ coordinate does not have to be stored for each voxel. Instead, voxels with the same Þ coordinate are grouped into a Render-ListEntry which stores the Þ coordinate and pointers to the first and last voxel with this coordinate within the array (see <ref type="figure" target="#fig_1">Figure 1b)</ref>.</p><p>For rendering, the RenderListEntries of all surfaces (as several surfaces can be viewed simultaneously, see <ref type="figure" target="#fig_3">Figure 2</ref>) are merged and sorted by the Þ coordinate into a single list. To be able to distinguish objects during rendering, additional properties like the opacity of the surface are stored at each RenderListEntry.</p><p>To achieve real-time rendering of the surface data, a fast shearwarp projection is used. Lighting of a voxel is performed by evaluating the Phong shading model considering it's normal vector and the current viewing direction. As only a limited number of normal vectors is distinguished and parallel projection with a directional light source is used, the shading for all possible normal vectors (16384) can be easily precomputed. The shading values are stored in a table which can be directly accessed with the 14 bits representation of the gradient vector as an index for obtaining the shaded value for a voxel. The shading table has to be recalculated after each change of the viewing direction or the position of the light source.</p><p>Clipping planes (See <ref type="figure" target="#fig_4">Figure 3a)</ref> operating on our voxel storage scheme can be implemented in a very efficient way. A RenderList-Entry stores voxels with the same depth with respect to the intermediate image plane. The order in which the voxels are projected onto the plane is not relevant, as each of them is projected onto a unique pixel of the intermediate image plane. Thus, as a clipping plane is applied, the voxels within a RenderListEntry can be reordered, in a way, that voxels which are clipped away are moved to the end of the array section which belongs to this RenderList-Entry. By setting a pointer to the last voxel which is not removed at the RenderListEntry, the clipped voxels can be efficiently skipped during rendering (see <ref type="figure" target="#fig_1">Figure 1b)</ref>. The resorting of the voxels into clipped/non clipped voxels requires just a single scan of the array with swapping of pairs of voxels. This approach is able to handle clipping at arbitrary planes or even non-planar objects.</p><p>Many visualization scenarios require not only the clipping and removal of parts of the data but also to display original density values at the clipping plane within the context of the 3D object (See <ref type="figure" target="#fig_4">Figure 3b</ref>). The display of original data on planar sections through the scene can be easily integrated into our surface rendering approach. Usually, only voxels with values above the threshold which defines the surface have to be displayed, providing information on densities within the object. When a new position for a clipping plane is defined, voxels which contain the plane and have a value above the threshold are extracted from the volume and stored in a similar way as surface voxels. Instead of storing gradient vectors, the data value at the voxel is stored. The extracted voxels are again sorted according to their Þ coordinate and grouped into RenderList-Entries, which are merged with the remaining objects of the scene. During rendering, a flag at each RenderListEntry is evaluated to decide whether the value stored at its voxels is a gradient and should be used for shading or if it is a data value which should be immediately written into the intermediate image plane.</p><p>During the warp step of the projection, the intermediate image plane is warped into the final image using bilinear interpolation to account for the size of the final image and the scaling component of the viewing matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Interaction Techniques</head><p>After loading the images from the PACS system, a volume of interest for surface extraction should be defined within the data set. This can be intuitively achieved by zooming and panning into the desired section of the original images and by deselecting those slices, which should not be involved in the 3D display process. If no volume of interest is defined, the whole image sequence is used. The surface display is initialized by selecting the corresponding display mode.  <ref type="table">Table 1</ref>: Rendering Times avoids blurring due to stronger stretching in one direction during the warp step. If a more accurate view of some part of the volume is required, another volume of interest can be constructed at this position and displayed within another view of the workbench.</p><p>To improve the efficiency of working with the data, all frequently used interactions can be carried out by clicking into specific portions of the image. For supporting novice users, graphical tool tips appear if the mouse is moved over such a sensitive "hot region". <ref type="figure" target="#fig_3">Figure 2</ref> shows for example the looking-glass symbol for the zooming region. Clicking on it and dragging the mouse zooms into and out of the data set. To avoid distracting expert users, the display of the hot-region symbols can also be disabled. A large region at the center of the image can be clicked to rotate the object, regions at the top of the image allow to specify the threshold and opacity for the surfaces. As the extraction of a new surface is the only non-interactive operation on the scene (see section 5 for details) the threshold is displayed numerically until the interaction is finished, the corresponding surface appears shortly after finishing the interaction. As most CT-data, which has a well defined tissue to value correspondence, is visualized using surfaces, providing feedback only after the interaction poses no big problem. In addition the surface threshold can be exactly specified using a numerical entry field. Currently, the parameters for two simultaneous surfaces can be defined using hot-regions within the image, which is sufficient for most applications.</p><p>Clipping planes can be defined and moved using six hot-regions at the bottom of the image. Two clipping planes perpendicular to each axis are defined, one for clipping data above, and one for clipping data below a specific coordinate value.</p><p>In addition, the windowing mechanism which is familiar to radiologists can be used to enhance contrast and emphasize features of the original volume data which is displayed on the clipping planes. Ü Ý movements of the mouse are used to define and modify a so called window´ Ûµ which maps all data values below Û ¾ to black, all values above • Û ¾ to white, and the values between Û ¾ and • Û ¾ to a uniform ramp of grays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Rendering and surface extraction times for rows 1 -3 of <ref type="table">Table 1</ref> have been measured on an PII/400 PC using the Java virtual machine 1.1.8 from Sun with a Symantec just-in-time compiler. The corresponding data sets have been resampled to fit into a ¾ ¿ cube. The size of the images is ½¾ ¾ pixels. While the time required for the shear step depends only on the number of projected voxels, the time required for warping the intermediate image plane into the final image and also the time required by Java to transfer the image to the screen buffer (included in the overall frame time in column 6) depends mainly on the size of the image. As interpolation is only performed during the warp step, large images (½¼¾ ¾ for example) generated out of ¾ ¿ data sets are blurred due to strong scaling during interpolation. Row 4 of <ref type="table">Table 1</ref> shows the time for rendering a data set at original resolution ( ½¾ ¾ £½¾ ) on an AMD Athlon 600 PC. As equal voxel size is required in all dimensions, the data set is treated as a ½¾ ¾ £ ¿½ volume during surface extraction.</p><p>Using data at the original resolution gives satisfactory results for In <ref type="table">Table 1</ref> the column "voxels" gives the number of voxels extracted from the volume to represent the surface(s). The time required for extraction includes the computation of gradient vectors using the central difference method.</p><p>The memory requirements for storing a surface are moderate. For each principal viewing direction each voxel stores the two other coordinates (¾ £ bits) and the gradient vector (14 bits). For all three principal directions this sums up to 90 bits per voxel. We can compare this to the requirements of a polygonal model of a surface which uses triangle strips: Making an optimistic assumption, that after an optimization of the surface representation there are approximately just as many vertices in the model as voxels in our surface representation, the model requires at least 24 bytes (192 bits) for each vertex (3*float coordinates, 3*float normal to allow handling by graphics hardware). Additional memory is required for referencing the vertices within the strips (indexed triangle strips). Even without considering the memory required to store this connectivity information for a geometric model, our approach requires significantly less memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we have presented an algorithm for the fast display of surfaces within volumetric data sets. The algorithm has been designed for providing real-time frame rates for viewing medical data within a Java-based diagnostic application. By using purely software-based rendering, the algorithm achieves similar performance on different hardware platforms. By combining the advantages of explicit surface extraction, shear-warp projection and splatting, high frame rates are achieved at low memory cost. The method has been implemented into J-Vision, an application used at the radiology departments of several hospitals for diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Future Work</head><p>Improved gradient estimation schemes could be used to enhance the quality of surface-shading. By including perspective projection, the algorithm could be used for viewing the volume from the insidefor virtual endoscopy for example.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure</head><label></label><figDesc>y, ...) a) J-Vision b) Storage of surface voxels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>with simultaneous views of a data set as a set of slices (top left), using MPR (top right), the surface rendering algorithm discussed in this paper (bottom left) and various variants of MIP<ref type="bibr" target="#b4">[5]</ref>(bottom right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>First, the RenderListEntries are processed in back-to-front order and their voxels are projected (splatted) onto the intermediate image plane. For performance reasons, each voxel is projected onto exactly one pixel of the intermediate image plane, without interpolation. As the scaling component of the viewing matrix is not considered during this step of the projection, neighboring voxels within a slice of the volume are projected onto neighboring pixels of the intermediate image plane. During projection, compositing is performed, blending the old pixel value with the value of the current voxel according to the opacity stored at the currently processed RenderListEntry.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Surface rendering depicting two surfaces: opaque bones and vessels and semi-transparent skin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Interactive clipping planes allow a) insight into objects b) to display density data within an object ½¼¾ ¾ images. The time required to recompute the shading table is negligible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>As no interpolation is used during projection to the intermediate image plane, the voxels should be equal-sized in all dimensions. This</figDesc><table><row><cell>fig. volume size voxels shear 2 ¾ ¾ £ ¾¿¾ 232k 18ms 15ms 50ms 2.0s warp frame extract 3a ¾ ¾ £ ½ 376k 30ms 15ms 61ms 2.2s 3b ¾ ¾ £ ½ 253k 20ms 15ms 53ms 1.8s 3a ½¾ ¾ £ ¿½ 1.8M 90ms 100ms 220ms 15s</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>The work presented in this publication has been funded by the V is M ed project and supported by the Band-Viz project.</p><p>V is M ed is supported by Tiani Medgraph, Vienna, http://www.tiani.com, and the Forschungsförderungsfonds für die gewerbliche Wirtschaft, Austria, http://www.telecom.at/fff/.</p><p>Please refer to http://www.vismed.at for further information on this project. BandViz (http://bandviz.cg.tuwien.ac.at/), is supported by FWF under project number P 12811.</p><p>We want to thank radiologists from the University Clinic Innsbruck and LKH Steyr for providing the data sets used for producing the images.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Surface shading in the cuberille environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Udupa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="33" to="43" />
			<date type="published" when="1985-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ray tracing volume densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kajiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH&apos;84</title>
		<meeting>ACM SIGGRAPH&apos;84</meeting>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast volume rendering using a shearwarp factorization of the viewing transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH &apos;94</title>
		<meeting>ACM SIGGRAPH &apos;94</meeting>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Marching cubes: A high resolution 3D surface construction algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH&apos;87</title>
		<meeting>ACM SIGGRAPH&apos;87</meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="163" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Real time maximum intensity projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Visualization &apos;99, Proceedings of the Joint EUROGRAPHICS -IEEE TCCG Symposium on Visualization</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The volume pro real-time ray-casting system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hardenbergh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH&apos;99</title>
		<meeting>ACM SIGGRAPH&apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">High performance presence-accelerated ray casting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bryson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1999-10" />
			<biblScope unit="page" from="379" to="386" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
