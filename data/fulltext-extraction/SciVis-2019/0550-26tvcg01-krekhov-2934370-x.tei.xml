<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deadeye Visualization Revisited: Investigation of Preattentiveness and Applicability in Virtual Environments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Krekhov</surname></persName>
							<email>andrey.krekhov@uni-due.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Cmentowski</surname></persName>
							<email>sebastian.cmentowski@uni-due.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Waschk</surname></persName>
							<email>andre.waschk@uni-due.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Kr√ºger</surname></persName>
							<email>jens.krueger@uni-due.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">with Center of Visual Data Analysis and Computer Graphics (COVIDAG)</orgName>
								<orgName type="institution">University of Duisburg-Essen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">SCI Institute</orgName>
								<orgName type="institution" key="instit2">University of Utah</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deadeye Visualization Revisited: Investigation of Preattentiveness and Applicability in Virtual Environments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2019.2934370</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Fig. 1</ref><p>. Left: Our experiments in VR with homogeneous and heterogeneous distractors, as we investigate the preattentiveness and robustness of Deadeye in such scenarios. Right: We demonstrate and evaluate volume rendering in VR as a possible real-world application scenario for our technique.</p><p>Visualizations rely on highlighting to attract and guide our attention. To make an object of interest stand out independently from a number of distractors, the underlying visual cue, e.g., color, has to be preattentive. In our prior work, we introduced Deadeye as an instantly recognizable highlighting technique that works by rendering the target object for one eye only. In contrast to prior approaches, Deadeye excels by not modifying any visual properties of the target. However, in the case of 2D visualizations, the method requires an additional setup to allow dichoptic presentation, which is a considerable drawback. As a follow-up to requests from the community, this paper explores Deadeye as a highlighting technique for 3D visualizations, because such stereoscopic scenarios support dichoptic presentation out of the box. Deadeye suppresses binocular disparities for the target object, so we cannot assume the applicability of our technique as a given fact. With this motivation, the paper presents quantitative evaluations of Deadeye in VR, including configurations with multiple heterogeneous distractors as an important robustness challenge. After confirming the preserved preattentiveness (all average accuracies above 90 %) under such real-world conditions, we explore VR volume rendering as an example application scenario for Deadeye. We depict a possible workflow for integrating our technique, conduct an exploratory survey to demonstrate benefits and limitations, and finally provide related design implications.</p><p>Index Terms-Popout, virtual reality, preattentive vision, volume rendering, dichoptic presentation, binocular rivalry</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Highlighting objects of interest in scientific visualizations allows our attention to be attracted and guided. Researchers have uncovered a number of effective ways to make an object pop out, be it color, motion, or flickering. Such visual cues can be recognized by our visual system preattentively, i.e., within a split second, no matter how complex the overall visualization. Hence, advances in the exploration of preattentive Our prior work introduced Deadeye <ref type="bibr" target="#b38">[39]</ref>, a preattentive visualization technique based on dichoptic presentation. Deadeye attracts and guides attention by rendering the target object for one eye only, which works preattentively due to the induced binocular rivalry. One particular benefit to visualizations is that Deadeye does not modify any visual properties of the target object in contrast to other preattentive cues that have to alter the target by recoloring, reshaping, or displacing (3D depth cue). Clearly, such alterations are undesirable, as they might lead to data misinterpretation. Also, by using Deadeye, we do not have to reserve visual dimensions, such as color for highlighting, and can use these variables for, e.g., encoding more data dimensions. Our studies also confirmed that the display of inconsistent stimuli for each eye does not lead to headache or any other physical strain, which is an important consideration for real-world applicability.</p><p>To render the target for one eye only, Deadeye relies on a stereoscopic setup such as a 3D TV with stereo glasses. The only difference  A selection of VR visualizations that can benefit from Deadeye highlighting. (a) Educational visualizations of particle physics <ref type="bibr" target="#b13">[14]</ref>: Deadeye can be used to capture and guide the attention of the students. (b) Immersive graph visualizations <ref type="bibr" target="#b41">[42]</ref>: Utilizing Deadeye during user interaction to highlight the selected vertices and edges. (c) Dinosaur track formation <ref type="bibr" target="#b55">[56]</ref>: Emphasizing 3D pathlines of interest in unsteady flow visualizations.</p><p>between the left and right image is the presence or absence of the target. Hence, one might consider such a setup solely for highlighting purposes as an overkill, and several members of our community proposed applying Deadeye in a truly stereoscopic environment. In such a case, our technique would not require any additional hardware and would perform out of the box. Furthermore, due to the availability nowadays of consumer VR equipment, visualization research increasingly employs virtual environments as a target scenario <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b64">65]</ref>, and having more complex visualizations in VR triggers the need for suitable highlighting approaches.</p><p>Given that community-driven motivation, we revisit Deadeye under stereoscopic conditions. In contrast to more established preattentive cues such as color or flickering, it is rather difficult to predict the behavior of Deadeye in such a setup due to its monocular nature. By removing the object for one eye, we lose the binocular disparity information for the target, which is a crucial part of depth estimation. However, the disparity-based mechanism is not the single point of failure, as our vision system relies on numerous mechanics, such as occlusion geometry <ref type="bibr" target="#b74">[75]</ref>, to estimate the depth of an object, which suggests a successful application of Deadeye in VR scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation for Extending Deadeye to VR</head><p>There are manifold reasons for visualization in VR, such as a better understanding of spatial relationships <ref type="bibr" target="#b63">[64]</ref>, or the increased presence and an improved cognitive map due to natural locomotion (i.e., walking) <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62]</ref>. Nevertheless, these advantages cannot prevent us from possibly getting lost in the amount of visualized data, and, thus, we continue to need robust and intuitive highlighting techniques. And while certain preattentive cues, such as color, are not affected by the transition to VR, temporal approaches, such as flickering, often interfere with aliasing caused by constant micromovements in VR. Hence, we postulate that establishing Deadeye as a validated highlighting approach in VR without occupying any additional visual dimension offers significant benefits for the visualization community, as outlined in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>One possible application scenario of Deadeye is the educational context. Instructors in virtual reality classes need a subtle, yet efficient way to draw the students' attention to a certain element or an area, such as a particle shower caused by a near-light-speed collision in the Belle II experiment <ref type="bibr" target="#b13">[14]</ref>. Similarly, we can utilize Deadeye to highlight particles or pathlines in flow field visualizations <ref type="bibr" target="#b55">[56]</ref>, as our method is not limited to a single target. The only requirement is that the highlighted property, target, or region need to be binary in their nature, as Deadeye either shows or removes it for one eye.</p><p>Such highlighting is also beneficial for visual storytelling, be it for experts or the general audience. One example is the biological exploration of cells in VR to better understand the cellular processes <ref type="bibr" target="#b32">[33]</ref>. Again, Deadeye can be used to emphasize various points of interest, such as the nucleus or endosomes, and help the audience to follow their movement during the visualization.</p><p>Another candidate for our method would be visualizations that involve cluttered, complex graphs. One important reason for such application scenarios is that VR usually allows to perceive and analyze larger graphs compared to non-stereo setups <ref type="bibr" target="#b77">[78]</ref>. Naturally, aspects like layout and interaction <ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref> are the dominant factors that impact the success of such visualizations. However, as color is often overrepresented in these scenarios, we postulate that Deadeye is a valuable alternative to, e.g., highlight the vertices or edges being currently selected by the user. To summarize, we assume that the unique selling point of Deadeye, i.e., the fact that it does not require a dedicated visual dimension, such as color or motion, is of enough value for a number of VR visualizations, which justifies our follow-on research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Key Advances of the Follow-On Research</head><p>In this section, we briefly outline the key novelties to facilitate comprehension. Especially readers that are familiar with the basic idea of Deadeye <ref type="bibr" target="#b38">[39]</ref> will find four key advances in this paper:</p><p>Preattentiveness in VR. As a first step, we explore whether Deadeye is still preattentive in a VR setup, despite being considered a subtle cue <ref type="bibr" target="#b87">[88]</ref>. Apart from the listed benefits for VR visualizations, having Deadeye in VR would also remove its prior disadvantage of requiring extra stereo hardware for highlighting.</p><p>Heterogeneous Distractors. The original studies on Deadeye were executed with one type of objects, i.e., colored circles. And while this is a valid and most commonly used approach for detecting preattentive cues, it is not guaranteed that these cues perform equally well in a heterogeneous setup with varying distractors. As visualizations are rarely limited to homogeneous objects, we need to assure that the method maintains its robustness under such circumstances. Therefore, we extend the initial research scope by studying the performance of Deadeye under different combinations of heterogeneous distractors: color, shape, and 3D depth.</p><p>Deadeye and depth perception. As Deadeye removes the object for one eye, our visual system cannot rely on binocular disparity for depth estimation of the target object anymore. We examine whether our visual system is still able to extrapolate the depth based on additional cues, such as occlusion geometry. This is an important detail, as otherwise, Deadeye might limit our understanding of spatial relationships in VR.</p><p>Evaluation of real-world applicability. We demonstrate how to integrate Deadeye into complex scientific visualizations in VR using the example of volume rendering (cf. <ref type="figure">Figure 1</ref>). In particular, we present a workflow for an intuitive application of such a highlighting feature and conduct an exploratory survey with visualization practitioners. Based on the survey outcomes, we discuss the benefits and drawbacks of Deadeye in such scenarios and generate a set of design implications for future research and applications.  <ref type="bibr" target="#b52">[53]</ref>. Images redrawn from <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREATTENTIVE CUES</head><p>Before exploring the behavior of Deadeye <ref type="bibr" target="#b38">[39]</ref> in a virtual, stereoscopic environment, we briefly introduce the essence of preattentive features and provide a motivation for such research. We will not go into detail regarding the basics of our visual system <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b82">83]</ref> in order to maintain focus on the visualization-related aspects. We recommend the stateof-the-art summary by Healey and Enns <ref type="bibr" target="#b27">[28]</ref> for a broad overview of preattentive research done in past decades.</p><p>In short, our visual system is able to detect certain outstanding features such as color in a glance, i.e., before our eyes initiate a saccadic movement. Consider the example in <ref type="figure" target="#fig_2">Figure 3</ref>: looking at such an image for a split second would suffice to tell whether or not there was a red circle among blue ones. Since a saccade usually needs about 200-250 ms <ref type="bibr" target="#b27">[28]</ref> to initiate, researchers utilize that threshold to determine if a cue is preattentive.</p><p>Apart from color, prior work has already discovered a large set of other preattentive features, including size, density, lighting direction, flicker, or orientation. For a more detailed overview, we refer to the work by Wolfe and Horowitz <ref type="bibr" target="#b81">[82]</ref> and Healey and Enns <ref type="bibr" target="#b27">[28]</ref>. At this point, we also emphasize that preattentive cues differ in their underlying nature, and, thus, the performance or detectability usually depends on various factors, such as the type and heterogeneity of distractors, viewing angle, or lighting condition.</p><p>A straightforward application for preattentive cues in visualization is to draw and guide attention <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b76">77]</ref> due to the nearly instant recognition time. Here, an even more important advantage is that preattentive features perform equally well, no matter how many other objects-also called distractors-are present. In other words, we can confirm a red circle from the previous example in less than 250 ms, even if hundreds of blue elements are on the screen.</p><p>Our community has made extensive use of preattentive cues for different approaches, such as dynamic narrative visualizations in the case of Attractive Flicker <ref type="bibr" target="#b75">[76]</ref> or document representations as done with Popout Prism <ref type="bibr" target="#b68">[69]</ref>. Other examples include the shading-effectsbased Stylized Focus <ref type="bibr" target="#b10">[11]</ref> and the utilization of 3D depth in graph visualizations <ref type="bibr" target="#b2">[3]</ref>. Readers seeking further application examples and higher level design guidelines for such visual features might also be interested in the work by Huber and Healey <ref type="bibr" target="#b29">[30]</ref>. In addition, studies by Gutwin et al. <ref type="bibr" target="#b21">[22]</ref> provide insights into performance differences of preattentive cues in the peripheral sight area. Note that Deadeye also suffers from decreasing performance in areas far from the focus point <ref type="bibr" target="#b38">[39]</ref>, and, if this aspect is of high importance (e.g., multimonitor setups), other cues such as motion or flickering should be favored instead.</p><p>Although we can spot a single cue instantly, searching for a combination of multiple features often results in a serial and no longer parallel process <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b70">[71]</ref><ref type="bibr" target="#b71">[72]</ref><ref type="bibr" target="#b72">[73]</ref><ref type="bibr" target="#b73">[74]</ref><ref type="bibr" target="#b79">80]</ref>. A detailed discussion of that so-called conjunction search is outside the scope of this paper, yet it is important to know about this limitation of preattentive cues when designing complex visualizations. This rule has a few exceptions, i.e., conjunction search setups where parallel processing can be achieved. Prominent examples are the works by M√ºller and Muhlenen <ref type="bibr" target="#b51">[52]</ref> (form and motion) and Nakayama Silverman <ref type="bibr" target="#b53">[54]</ref> (3D depth and color/motion). That latter report was the main motivation for studying conjunction search abilities of Deadeye, since 3D depth and Deadeye both rely on binocular disparities. However, the experiments did not support the hypothesis that Deadeye is suitable for parallel processing when combined with color. Hence, we are not further examining conjunction search in our VR setup, as we do not see any evidence for a change in behavior in this regard.</p><p>To fully understand the underlying mechanisms behind conjunction search and preattentive processing in general, we recommend starting with the Integration Theory by Treisman <ref type="bibr" target="#b73">[74]</ref>. Other fundamental research regarding preattentive models includes the Texton Theory by Julesz et al. <ref type="bibr" target="#b35">[36]</ref> and the Boolean map theory by Huang and Pashler <ref type="bibr" target="#b28">[29]</ref>. As we will not go into detailed explanations of these models, the stateof-the-art paper by Healey and Enns <ref type="bibr" target="#b27">[28]</ref> might be considered as a starting point for obtaining an overview.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">UNDERLYING MECHANICS OF DEADEYE</head><p>The concept behind the original Deadeye visualization technique is to highlight an object by removing it for one eye only. We refer to such a principle when each eye is exposed to a different stimulus as dichoptic presentation. In general, that difference in stimuli leads to binocular rivalry <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b58">59]</ref>, i.e., our vision system enters a context-switching mode that allows us to perceive both monocular images alternately instead of experiencing a superimposition.</p><p>Whether or not binocular rivalry can be perceived in a preattentive manner has been discussed in a number of prior works. Wolfe and Franzel <ref type="bibr" target="#b80">[81]</ref> assumed that such a cue is not preattentive in general, with the exception of the so-called luster effect where the target object is dimmer than the background for one eye and brighter for the other eye. Such luminance variations and luminance disparities in general were subjects of further extensive research <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b69">70]</ref>. Zou et al. <ref type="bibr" target="#b87">[88]</ref> reported that although dichoptic presentation can be preattentive, it is usually too weak and overridden by more pronounced features such as orientation. Consequently, dichoptic presentation has only rarely been employed in visualization or for highlighting purposes in general <ref type="bibr" target="#b83">[84,</ref><ref type="bibr" target="#b84">85]</ref>.</p><p>On the other hand, research by Paffen et al. <ref type="bibr" target="#b57">[58]</ref> and especially the work by Zhaoping <ref type="bibr" target="#b85">[86]</ref> has provided further evidence that binocular rivalry should be reconsidered as a preattentive cue. In particular, Zhaoping confirmed that ocular discontinuities can be used for drawing attention by comparing ocular singletons to orientation singletons and evaluating the role of the primary visual cortex during the construction of related bottom-up saliency maps. The original studies on Deadeye also align with these findings and confirm the achievable preattentiveness. A well-known case of dichoptic presentation is the binocular disparity generated by the horizontal offset of our eyes. That information is processed by our visual system to gather depth information and forms the basis for stereo vision <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49]</ref>. On a side note, a number of related stereo cues such as lighting direction and three-dimensionality have also been proven to be preattentive <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>In contrast to the disparity-based depth perception, da Vinci stereopsis <ref type="bibr" target="#b52">[53]</ref> provides depth information based on monocular vision. This phenomenon is common in daily life, i.e., when an object is partially occluded by another, our vision system perceives monocularly occluded regions as depicted in <ref type="figure" target="#fig_2">Figure 3</ref>. Although receiving little attention by the general public, monocular occlusion plays an important role in our depth perception process <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b66">67]</ref>. Consequently, prior research <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b86">87]</ref> established several models that show how such unpaired image points contribute to depth estimation.</p><p>Regarding Deadeye, one important aspect of da Vinci stereopsis is the classification of monocular areas in valid and invalid combinations as shown in <ref type="figure" target="#fig_2">Figure 3</ref>. Clearly, only valid cases appear in nature. As shown by Shimojo and Nakayama <ref type="bibr" target="#b65">[66]</ref>, such valid regions are not subject to binocular rivalry and usually appear as part of more distant surfaces, whereas invalid regions appear more ambiguous in depth estimation. In the case of Deadeye, the exposed image pair falls into the invalid category. Hence, at first glance, depth estimation for the highlighted object might be error prone. However, more recent research <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b30">31]</ref> has revealed that da Vinci stereopsis works in a rather stimulus-dependent way, i.e., the quantitative depth computation approach depends on the given occlusion configuration. Tsirlin et al. <ref type="bibr" target="#b74">[75]</ref> concluded that occlusion geometry is most likely the main source for depth extraction in such cases. These recent findings allow us to assume that Deadeye-enhanced objects would also perform well regarding depth estimation in VR setups, especially when we consider that such a stereoscopic environment allows us to observe the object in question from multiple perspectives to achieve a more sophisticated depth impression <ref type="bibr" target="#b67">[68]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PREATTENTIVENESS OF DEADEYE IN VR</head><p>We conducted an evaluation to understand whether and how the preattentiveness of Deadeye behaves in a virtual environment. In a first step, we recreated an experiment similar to the original Deadeyes tudy <ref type="bibr" target="#b38">[39]</ref> to generate a set of comparable data. The design of our experiment follows the traditional approach for preattentive cues: series of images-or scenes in our case-are displayed for a short amount of time (100-250 ms), and participants have to decide for each image whether a highlighted object is present or not. If a cue is preattentive, the high success rate (typically &gt; 80%) is maintained independently from the number of overall objects on the screen. Hence, preattentive experiments are performed with a varying number of distractors to verify the performance stability.</p><p>Accordingly, we formulated a first hypothesis H1: Stereoscopic environments do not impact the accuracy of Deadeye in the case of homogeneous distractors. Note that although we utilized stereoscopic equipment in the original experiments to hide the target object for one eye, the image pairs were otherwise identical, i.e., no disparity-based depth cues were present. In contrast, the experiments to be presented utilize a 3D scene that allows spatial vision and where all objects are three-dimensional, as shown in <ref type="figure" target="#fig_3">Figure 4</ref>.</p><p>In a second step, we significantly extended the original setup by utilizing objects that vary in protruding properties, such as color or shape, to explore the robustness of our technique. Note that preattentive cues perform differently under heterogeneous conditions, and understanding such behavior is crucial because visualizations seldom consist of only one type of objects. Since prior research <ref type="bibr" target="#b87">[88]</ref> has demonstrated that dichoptic presentation is a rather weak cue that could be easily overridden by stronger features, we regard an evaluation under heterogeneous conditions as an important milestone for establishing Deadeye as a "working" cue for real-world visualizations. Hence, our second hypothesis is that Deadeye accuracy remains robust in scenarios where distractors and the targets have heterogeneous visual properties (H2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Procedure and Applied Measures</head><p>Our experiments took place in a virtual reality lab. In our recruitment call, we requested normal or corrected to normal visual acuity and no defects of vision as a study prerequisite. Upon entrance, we informed the participants about the overall procedure and administered a questionnaire to obtain general demographic data.</p><p>We then provided the participants an Oculus Go <ref type="bibr" target="#b16">[17]</ref> HMD with a per eye resolution of 1280 x 1440 pixel and briefly explained its usage. The remainder of the study took place in the VR environment, i.e., all trials, briefings, pauses, and questionnaires were done via the HMD to guarantee equal conditions (e.g., between-run delays) for all participants.</p><p>On-screen text briefed the participants that they would see a series of static 3D scenes consisting of floating objects, and one of the objects might pop out. Each scene was shown for a split second, and, subsequently, participants would vote via yes and no buttons whether  <ref type="bibr" target="#b38">[39]</ref> for the 2D case. A repeated measures ANOVA shows no significant difference in accuracy between the sets, supporting our hypotheses that the transition to 3D scenes does not impact the performance of Deadeye and that our technique remains robust even in the presence of strong visual cues such as color or shape.</p><p>they thought that a highlighted object was present. Before each scene, participants saw a crosshair in the middle of the screen and were asked to maintain focus on it. This detail is important to prevent saccadic eye movements such that the eyes would remain in the focus stage when a scene becomes visible. The briefing also mentioned that there would be a training stage before each round where participants would receive audio feedback that indicated the correctness of the given answer. During the real run, the audio would be replaced by a neutral sound to prevent distractions, i.e., reflecting upon wrong answers and lack of concentration as a result.</p><p>The entire study consisted of two parts: Exp-1 with homogeneous distractors and Exp-2 focusing on heterogeneous distractors. Exp-1 consisted of three sets that differed only in the number of displayed objects: 4, 16, and 30. We utilized randomly generated cubes on a 5 x 6 grid with jittering/offset functions as depicted in <ref type="figure" target="#fig_3">Figure 4</ref>. All cubes were aligned on the same depth plane, resulting in a horizontal viewing angle of 14.93 ‚Ä¢ from the focus point (vertical: 12.23 ‚Ä¢ ). Each cube had a size of approximately 1.8 ‚Ä¢ . Each of the three sets included 48 scenes, half of them with a target object at a random position in a randomized order. We exposed each scene for 250 ms to the participants; the previously displayed crosshair lasted for 2500 ms. Furthermore, each set began with a training round with 20 scenes. To summarize Exp-1, we replicated our setup from the previous study as precisely as possible to generate statistically comparable data. The only altered condition was the shift from a 2D image with flat objects to a scene with three- <ref type="figure">Fig. 6</ref>. Excerpt from our VR implementation of the NASA-TLX survey. All briefings, pauses, and questionnaires were done via the HMD to provide same conditions to all participants.</p><p>dimensional objects with binocular disparity.</p><p>Exp-2 included the three sets depth2, depth2-color-shape, and depth3-color in random order. All three sets consisted of 30 objects and varied only in the type and/or depth distribution of utilized elements. All other conditions were similar to Exp-1 to allow direct comparisons. For depth2, we chose the same objects as in Exp-1, but distributed them on two distinct depth planes as shown in <ref type="figure" target="#fig_3">Figure 4</ref> and also included a minor depth jittering function. The distance between the depth planes was twice the cube-side length. The maximum partial occlusion of a far-plane object by a closer one was 10 % of its screen space, i.e., at least 90% of the far object remained visible. For depth2-color-shape, we included different forms of objects and also randomly assigned different colors to see how Deadeye performs in the presence of two rather dominant visual cues. In addition, we kept the depth distribution over two planes. The scenes of depth3-color further increased the depth variance by adding a third plane and increasing the maximum possible occlusion of the furthermost object to 20 %. The objects were all cubes with randomly assigned color.</p><p>Between all sets of our study, we displayed a stereoscopic 3D landscape photo for 30 seconds to provide short pauses and reduce task fatigue, similar to the original Deadeye experiments. We also re-implemented the original questionnaire in VR, as shown in <ref type="figure">Figure 6</ref>, and administered it after Exp-1 and after Exp-2. The questionnaire is based on the NASA-TLX survey <ref type="bibr" target="#b25">[26]</ref>, which includes six subscales: mental demand (low/high), physical demand (low/high), temporal demand (low/high), performance (good/poor), effort (low/high), and frustration level (low/high). Each scale ranges from 0 to 100 in increments of 5. Our questionnaire also contains two additional items on a sevenpoint Likert scale ranging from 0 to 6, with larger numbers indicating a more positive outcome: Clearness: how well have you perceived the highlighted object? and Decision-making: how sure were you that you made the right decisions?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>The quantitative study included twenty-four persons (fifteen females, nine males),  We applied a repeated measures ANOVA with the set type as a within-subject variable to investigate whether the number and kind of distractors influence the accuracy of Deadeye in VR. The result, F(5, 115) = 1.04, p = .397, shows no significant difference. In other words, the performance of the participants was affected by neither increasing the number of cubes nor adding depth layers and modifying the shape and color of displayed objects. Regarding the false negatives to false positives ratio in case of wrong answers as depicted in <ref type="figure" target="#fig_4">Figure 5</ref>, it is more likely to miss a target than to report a false alarm, which is also a common behavior of other preattentive cues.</p><p>We also performed independent samples t-tests to explore whether the transition to VR had an impact on performance. To enable such comparisons, our sets in Exp-1 replicated the prior 2D setup <ref type="bibr" target="#b38">[39]</ref> as close as possible. The results for 4 (t(43) = ‚àí1.97, p = .055), 16 (t(42.18) = ‚àí0.02, p = .988), and 30 objects (t(43) = ‚àí0.85, p = .402) show no significant differences in accuracy between 2D and 3D experiments.</p><p>To evaluate the subjective perception of Deadeye, we conducted a paired-samples t-test to compare the outcomes of the NASA-TLX questionnaire for Exp-1 and Exp-2, as shown in <ref type="figure" target="#fig_6">Figure 7</ref>. Physical demand (t(23) = ‚àí2.22, p = .037) and temporal demand (t(23) = 2.72, p = .012) are significantly different. Physical demand was reported to   <ref type="figure" target="#fig_7">Figure 8</ref>. We found no significant differences between Exp-1 and Exp-2, or between Exp-1 and our prior 2D results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>Our results support our assumption that a virtual environment does not limit the preattentive nature of Deadeye, because the feature is still recognized with an average accuracy of ‚àº 90%. In particular, the outcomes of our independent samples t-tests for the sets of Exp-1 and the respective sets of the prior 2D experiment support our hypothesis H1, i.e., the transition to fully stereoscopic environments does not impact the behavior of Deadeye in the case of homogeneous distractors.</p><p>The behavior regarding wrong answers also remains unchanged: about ‚àº 65% of the errors were false negatives, which is quite common for preattentive cues. In other words, it is easier to overlook a highlighted object rather than it is to mistakenly call out a false alarm in the absence of a highlight.</p><p>In our opinion, the most important finding of our experiment is that the performance of Deadeye was not impacted by heterogeneous distractors, because our evaluation did not reveal any significant differences in performance and fully supported our second hypothesis H2. We intentionally picked strong visual attributes for our distractors, such as shape and color, because previous work suggested that the preattentive character of binocular rivalry might be easily overridden <ref type="bibr" target="#b87">[88]</ref>. However, Deadeye performed surprisingly robustly, which allows us to suggest the technique as a suitable highlighting method for real-world applications. Clearly, an unstable performance under heterogeneous conditions would have significantly limited the potential of Deadeye, because visualizations, in most cases, involve a complex interplay among multiple visual attributes.</p><p>Furthermore, we made two rather unexpected observations during Exp-2. First, the performance of the depth3-color set surpassed our expectations. We suspected that target objects on the most distant depth plane would perform significantly worse due to the small screen size and the partial occlusion. However, as shown in <ref type="figure" target="#fig_9">Figure 9</ref>, a detailed analysis of missed target locations did not reveal any error trend toward a specific depth plane. Second, we assumed that thinner objects, i.e., cylinders in the depth2-color-shape set, might perform worse due to the influence of aliasing ("shimmering") caused by slight HMD movement. Yet again, analyzing the missed target locations did not reveal any relation between shape and error rate. The only notable connection between the target position and its likeliness to be overlooked is the angular distance from the focus point, i.e., Deadeye performance decreases for objects in the outer columns. At this point, we will not go into detail regarding this finding, because it was already described and analyzed in the original Deadeye paper <ref type="bibr" target="#b38">[39]</ref>. Furthermore, as the visual quality of current HMDs is very limited in peripheral areas, this aspect is of low importance compared to non-VR, multi-monitor setups.</p><p>Interestingly, a closer inspection of the NASA-TLX questionnaire outcomes does not give us a clear picture regarding the actual exertion induced by Deadeye. Although the average values are positive compared to other visual cues <ref type="bibr" target="#b21">[22]</ref>, we point our readers at the rather large standard deviations. For each subscale, the answers provided by the participants always contained both extreme values, i.e., 0 and 100. We suppose that such a spread is due to the subtle nature of Deadeye and our inability to put the perceived effect into words. This presumption is also underpinned by our custom questions that reflect an average confidence of participants regarding their made decisions.</p><p>As a side note, we attribute the significant differences for physical and mental demand between Exp-1 and Exp-2 to possible sequence effects of our study. Temporal demand decreased over time, because participants got used to the fast pace of the trials. In contrast, physical demand increased with the duration of the experiment, because the HMD is still an uncomfortable device when worn over a longer period of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">INTEGRATION INTO VR VOLUME RENDERING</head><p>In addition to rather fundamental studies on preattentiveness, we now consider volume rendering in VR as a real-world application scenario of Deadeye. We present an integration example and an exploratory study to demonstrate the benefits and limitations of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementation</head><p>Given a volume rendering system with VR support (cf. <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b64">65]</ref>), the technical implementation of Deadeye can be done in the following way. For simplicity, let us assume that Deadeye should be achieved by removing the target for the right eye. To remove the footprint of the target volume regions for the right eye, we store a per-voxel mask volume on the GPU along with the volume data. During GPU-based ray-casting (cf. <ref type="bibr" target="#b39">[40]</ref>), we compare this mask value against a global constant in the shader, which whether the rendering is done for the left or right eye. A voxel is skipped if the mask is set and rendering is done for the right eye.</p><p>The generation of such a mask volume depends on the application domain. For instance, in the case of already segmented <ref type="bibr" target="#b44">[45]</ref> data sets, the per-voxel segment ID of the region of interest can be utilized. Another option is to interactively create and modify the mask volume by "erasing" the target for one eye directly in VR, as done in our study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Procedure of the Study</head><p>To gather more information about the behavior of Deadeye in realworld-conditions, we conducted a semistructured exploratory study based on medical volume rendering in VR. Our main goal was to determine possible limitations of our preattentive highlighting method and to generate a preliminary set of design guidelines for the application of Deadeye in such scenarios.</p><p>Since we were interested in feedback from people who are already familiar with volume rendering, we decided to recruit our participants manually via direct e-mail requests to limit the discard rate. The experiment took place in our VR lab and was supervised by two researchers. One of them was responsible for briefing and interviewing the participant during the experiment. All participants agreed that we would perform an audio recording of the whole session to facilitate the final evaluation. The second researcher monitored the volume rendering application and executed certain requests from participants, such as resetting the highlighted regions or switching between data sets. We intentionally reduced the direct interactions of the participants with the software to a minimum to focus on the highlighting aspect.</p><p>After assessing the demographic data and conducting a hole-inthe-card-test for eye dominance (Dolman method, e.g., <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b59">60]</ref>), we equipped our participants with an HTC Vive Pro <ref type="bibr" target="#b11">[12]</ref> with a wireless adapter and explained the remainder of the study. For volume rendering, we used a VR-optimized, GPU-based ray caster implementation that guaranteed a minimum refresh rate of 90 frames per second. We used two data sets to simulate common medical situations, a CT scan of a human head (+neck/shoulders), and a CT scan of a human torso; both are subsets from the frozen CT visible human data set <ref type="bibr" target="#b0">[1]</ref>. In the first part of the study, participants explored both data sets with a medical greyscale transfer function. For the second part, we applied a transfer function that included color to explore its interplay with Deadeye. Each of these four scenarios (2x greyscale, 2x colored; cf. <ref type="figure" target="#fig_10">Figure 10</ref>) consisted of the following tasks:</p><p>Detection -we displayed two different presets (scale, orientation, clip plane); each preset included between one and four Deadeyeenhanced regions. Assignment: Tell whether and how many parts of the data set pop out. Describe where the highlighted elements lie in depth relative to their surrounding.</p><p>Application -participants were able to apply Deadeye on their own using the trigger button of the controller similar to 3D painting. Assignment: Pick two regions of interest and highlight them as precisely as possible.</p><p>Comparison -we displayed two presets that utilized alternative popout techniques, color and flickering, to highlight between one and four regions. In the case of colored scenarios, only flickering was applied. Assignment: Locate the highlighted regions. Describe your perceived benefits and drawbacks compared to Deadeye.</p><p>During each assignment, we explicitly asked the participants to provide feedback in a think-aloud manner if possible. We did not impose any time limit for the scenarios and encouraged brief pauses between them. Upon completion of the experiment, we offered the opportunity to provide any additional feedback if desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Findings</head><p>The exploratory study included nine participants (three females, six males), aged 29 to 45 (M = 36.67, SD = 5.68) participated in the exploratory study. All had prior experience with volume rendering, and six of the nine participants had used VR HMDs before. The majority (N = 7) had a right dominant eye, and all participants reported normal or corrected to normal visual acuity. In the remainder of this section, we group the obtained results by the respective task to provide a structured exposition.</p><p>Detection. In all four scenarios, participants delivered solid performances in spotting and pointing at highlighted regions via a selection ray. Only two participants made a false negative error each. Both participants missed the same small, thin region located rather deep within the data set. Four participants told us that they were able to spot target regions easier when the data sets were colored (P3). All participants were able to describe the relative depth of the highlighted objects relative to the surrounding elements. Four participants stated that they had to move the head a little bit to view the object from different angles to be 100 % sure (P7).</p><p>We received differing comments regarding the perception of the highlighted object. All but one participant utilized the adjective transparent in certain variations, e.g., pseudo-transparent (P1) or semitransparent (P6). All participants stated that they could see the target as well as the objects behind it (P3). Seven participants emphasized that they seemed to be able to decide whether they want to "see" the highlighted region or suppress it by focusing on the background objects (P4). Note that this observation aligns with general binocular rivalry behavior where we perceive both monocular images alternately instead of seeing a superimposition. Two participants were particularly intrigued by that behavior, describing it as a kind of willpower-dependent rendering where one could mentally alter the perceived visualization similar to ambiguous image puzzles (P8). Three participants also noticed that one could modify the transparency level of the highlighted object by rotating the head (P9). This phenomenon is caused by the rather limited field of view of the HMD, i.e., when we look at an object from a sufficiently large angle, that area is no more present for the eye that is further away. Hence, binocular rivalry becomes disabled, and we perceive a valid monocular image from the nearer eye that either contains the object or not.</p><p>At the end of the detection assignment, we also varied the eye for which the object would be removed. However, participants were indecisive, and only three of them expressed a weak tendency toward the object removal for their dominant eye. Other participants stated that they felt a slight difference, but cannot say which option is better (P4).</p><p>Application. All participants were able to manually apply Deadeye onto self-chosen regions of interest. However, the majority (N = 8) perceived the task as rather challenging especially when moving the controller in the depth dimension (P2). One participant compared it to a VR painting tool: It feels the same as 3D painting in VR, which was not very intuitive to me, either (P5). Seven participants told us that they intuitively closed one eye from time to time to verify the result and speed up the highlighting because it feels more controlled that way (P3). No participants attested to any negative feelings about that one-eye trick. As expected, all participants stated that applying Deadeye is easier for colored data sets because one could just pick a region of a specific color which already has a clear visual separation from the surroundings (P1).</p><p>Comparison. In the case of greyscale scenarios, all participants preferred color over Deadeye for two reasons. First, color as highlight is more prominent, straightforward, and already known (P6). Second, as pointed out by six participants, color, in contrast to Deadeye, is not binary. One could utilize a meaningful color scheme for highlighting different regions and even have gradients and interpolations if needed (P9). Deadeye instead is either active or not, without any possibility of providing an additional meaning or more granular differentiation (P7). However, color is not applicable as a preattentive highlighting method in the case of colored data sets, which is an important limitation compared to Deadeye.</p><p>When comparing Deadeye to flickering as a highlighting method, the majority (N = 8) preferred Deadeye; one participant remained indecisive. The most prominent reason for that preference was that flickering is often affected by aliasing and other artifacts (P2) that occur because such a VR experience is never a static scene due to the permanent view changes. Hence, the preattentiveness of temporal effects such as animation or flickering can be rather weakened in such setups, whereas the performance of Deadeye remains stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Discussion and Design Implications</head><p>The results of both studies support our vision that Deadeye is applicable as a preattentive visualization technique in real-world scenarios. Even in complex visualizations such as volume-rendered CT scans, we can still recognize the highlighted region and identify its depth. Although disparity-based depth perception is limited, our vision system is still capable of utilizing less straightforward cues such as occlusion geometry. Furthermore, if in doubt, we can easily refine our depth estimation of a region by slightly moving our head to generate different view angles.</p><p>One interesting aspect of Deadeye is that we can look behind the highlighted target by focusing on objects that lie behind it. This multistable perception-induced by binocular rivalry-can be regarded as a benefit or drawback depending on the use case. On one hand, such conditional perception allows us to gather additional information without any interaction with the underlying system. In particular, we think of scenarios with very limited interaction possibilities due to, e.g., asepsis requirements. In such cases, having the ability to see or fade out certain elements by simply focusing on the region of interest might be a valuable technique. On the other hand, the focus-dependent approach is mentally more demanding compared to alternatives such as semitransparency or hiding/showing an object via user input. Although the fatigue results of the NASA-TLX questionnaire are quite reasonable, we expect that a longer, active use of the described switching between highlighted target and background might lead to significant exhaustion. As that phenomenon is less related to the highlighting aspect of Deadeye per se, we would rather consider a more fine-grained exploration as possible follow-up research.</p><p>Ultimately, the question remains whether one should pick Deadeye or one of the more common preattentive techniques to draw and guide attention in VR visualizations. According to our qualitative evaluation, people prefer color over Deadeye in the case of greyscale scenarios. In our opinion, the most important advantage of color is its nonbinary nature, i.e., we can encode additional information into the highlighted target and differentiate between multiple targets by utilizing diverse colors. However, many visualizations are not greyscale, and applying our technique in such cases has clear advantages over other preattentive approaches: Deadeye does not alter any visual properties such as size or shape; performs well in complex, heterogeneous environments; and is straightforward to implement in stereoscopic setups. Compared to temporal approaches such as flickering, Deadeye does not suffer from typical VR-related issues such as aliasing due to constant movements of the HMD. To summarize, even though color is still superior in greyscale use cases, we emphasize the applicability and usefulness of Deadeye in colored scenarios and consider the technique as a viable addition to our visualization toolbox.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>This work explored the performance of Deadeye in virtual environments. Initially, Deadeye was introduced as a preattentive technique for drawing attention in 2D visualizations by removing the object of interest for one eye only. The major drawback for real-world usage was the requirement for extra stereoscopic equipment for highlighting, without taking any further advantage of such a setup. Hence, as a natural next stage of our research, we have now applied Deadeye in stereoscopic environments to study its interplay with 3D visualizations.</p><p>The paper made two contributions. First, the results from our preattentive tests with homogeneous and heterogeneous distractors confirmed that Deadeye behaves preattentively in VR, and, even more important, maintains its robustness in more complex setups with distractors varying in significant visual properties such as depth, color, and shape. Second, we demonstrated how Deadeye can be integrated into VR visualizations using the example of volume rendering. The outcomes of the exploratory study underpinned the highlighting capabilities of Deadeye and confirmed our ability to estimate depth of objects highlighted in this manner. Especially in colored visualizations, Deadeye was perceived as a valuable extension to our visualization toolkit, as the technique does not alter any visual properties, maintains robustness under common issues such as aliasing ("shimmering"), and comes with a straightforward implementation.</p><p>For our future work, we are particularly motivated by an observation during the presented volume rendering study: our participants noticed that the highlighted object could be faded in or out depending on focus, i.e., concentrating on the objects behind the target allows the user to suppress the target completely and see the background only, and vice versa. As possible follow-up research, we suggest investigating this multistable perception phenomenon in more detail to show its full potential for scientific visualizations beyond pure highlighting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Manuscript received 31</head><label>31</label><figDesc>Mar. 2019; accepted 1 Aug. 2019. Date of publication 16 Aug. 2019; date of current version 20 Oct. 2019. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org, and reference the Digital Object Identifier below. Digital Object Identifier no. 10.1109/TVCG.2019.2934370</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. A selection of VR visualizations that can benefit from Deadeye highlighting. (a) Educational visualizations of particle physics [14]: Deadeye can be used to capture and guide the attention of the students. (b) Immersive graph visualizations [42]: Utilizing Deadeye during user interaction to highlight the selected vertices and edges. (c) Dinosaur track formation [56]: Emphasizing 3D pathlines of interest in unsteady flow visualizations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>(a) Color as a cue: The red circle can be recognized preattentively independent of the number of blue distractors. (b) Da Vinci stereopsis: The near surface results in different occlusions for both eyes, which leads to monocular regions in the far plane. (c) Valid and invalid setups of unpaired image points in da Vinci stereopsis according to Nakayama and Shimojo</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Top: Exp-1 with an increasing number of homogeneous distractors on the same depth plane with a slight positional jittering applied to each cube. Bottom: Exp-2 with heterogeneous distractors, from left to right: depth2 (two depth planes), depth2-color-shape (two depth planes, different color and shape), and depth3-color (three depth planes, different color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Average accuracies for Exp-1 and Exp-2 compared to our previous results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>aged 18 to 43 (M = 26.71, SD = 6.82). All reported normal or corrected to normal visual acuity and no defects of vision. The presented results are based on the automated logging of our VR application. All variables were normally distributed according to Kolmogorov-Smirnov tests. The average accuracies, as depicted in Figure 5, for Exp-1 (4 objects: M = 0.93, SD = 0.08; 16 objects: M = 0.91, SD = 0.09; 30 objects: M = 0.91, SD = 0.07) and Exp-2 (depth2: M = 0.93, SD = 0.08; depth2-color-shape: M = 0.91, SD = 0.06; depth3-color: M = 0.90, SD = 0.06) are similar to the values of other preattentive cues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Results of the NASA-TLX survey for Exp-1 and Exp-2 compared to the prior values of the 2D case. Lower values are preferable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .</head><label>8</label><figDesc>Results of our custom questions. Larger numbers indicate a more positive outcome.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>be significantly higher (M = 39.58, SD = 18.65 vs M = 26.88, SD = 23.35) in Exp-2, whereas temporal demand was significantly higher in Exp-1 (M = 48.33, SD = 20.62 vs M = 38.13, SD = 24.44). Furthermore, we applied independent samples t-tests to compare the NASA-TLX results of Exp-1 with the prior 2D experiment and found no significant differences between any of the subscales. In a similar way, we compared our custom questions regarding clearness (Exp-1: M = 3.83, SD = 1.90; Exp-2: M = 3.54, SD = 1.35) and decision-making (Exp-1: M = 3.58, SD = 1.44; Exp-2: M = 3.00, SD = 1.29) as can be seen in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Average success rates for the detection of a Deadeye-enhanced object at each position. The matrices indicate an increase of the error rate with increasing distance from the focus point and no notable difference regarding the target's depth location.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 10 .</head><label>10</label><figDesc>Participants went through four different visualization scenarios based on the visible human data set: head including neck and shoulders, and torso, both with greyscale and color transfer functions. Each scenario consisted of three tasks: spotting Deadeye and determining the depth of the target (Detection), interactively applying Deadeye (Application), and comparing Deadeye to flickering and color (in greyscale scenarios only) as alternative highlighting approaches (Comparison).</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We are immensely grateful to Christine Pickett for her comments that greatly improved the manuscript. We would also like to show our gratitude to the anonymous reviewers of the original Deadeye paper and the IEEE VIS community for motivating us to explore Deadeye in virtual reality environments. This research was made possible in part by Award Number R01NR014852 from the NINR -National Institute of Nursing Research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The visible human project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Ackerman</surname></persName>
		</author>
		<idno type="DOI">10.1109/5.662875</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="504" to="511" />
			<date type="published" when="1998-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Binocular rivalry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Alais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Blake</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stereoscopic highlighting: 2d graph visualization on stereo displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hollerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kuchera-Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Forbes</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2011.234</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2325" to="2333" />
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nonlinear combination of luminance excursions during flicker, simultaneous contrast, afterimages and binocular fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Anstis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="523" to="539" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Solving da vinci stereopsis with depth-edgeselective v2 cells</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Assee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Qian</surname></persName>
		</author>
		<idno>doi: 10. 1016/j.visres.2007.07.003</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="2585" to="2602" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A neural theory of binocular rivalry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">State-of-the-art in visual attention modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2012.89</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="207" />
			<date type="published" when="2013-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A laminar cortical model of stereopsis and 3d surface perception: Closure and da vinci stereopsis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spatial vision</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="515" to="578" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stereoscopic offset makes objects easier to recognize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caziot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Backus</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0129101</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">129101</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Association of ocular dominance and anisometropic myopia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-W</forename><surname>Hsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-M</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Investigative ophthalmology &amp; visual science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2856" to="2860" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Directing gaze in 3d models with stylized focus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decarlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Morley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santella</surname></persName>
		</author>
		<idno type="DOI">10.2312/EGWR/EGSR06/377-387</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Eurographics Conference on Rendering Techniques, EGSR &apos;06</title>
		<meeting>the 17th Eurographics Conference on Rendering Techniques, EGSR &apos;06<address><addrLine>Aire-la-Ville, Switzerland, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="377" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">HTC Vive Pro. Website</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Corporation</surname></persName>
		</author>
		<ptr target="https://www.vive.com/" />
		<imprint>
			<date type="published" when="2019-03-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Binocular brightness combinations: Additive and nonadditive aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>De Weert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J M</forename><surname>Levelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="551" to="562" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Belle2vr: A virtual-reality visualization of subatomic particle physics in the belle ii experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Duer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Piilonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Glasson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer graphics and applications</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="33" to="43" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Influence of scene-based properties on visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">247</biblScope>
			<biblScope unit="issue">4943</biblScope>
			<biblScope unit="page">721</biblScope>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sensitivity to three-dimensional orientation in visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="323" to="326" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<ptr target="https://www.oculus.com/go/" />
		<title level="m">Facebook Technologies. Oculus Go. Website</title>
		<imprint>
			<date type="published" when="2019-03-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The psychophysics of detecting binocular discrepancies of luminance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Formankiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mollon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1929" to="1938" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Visual attention and consciousness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Monocular discs in the occlusion zones of binocular surfaces do not have quantitative depth-a comparison with panum&apos;s limiting case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gillam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Blackburn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1009" to="1019" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Quantitative depth for a phantom surface can be based on cyclopean occlusion cues alone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gillam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="112" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Peripheral popout: The influence of visual angle and stimulus intensity on popout effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cockburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coveney</surname></persName>
		</author>
		<idno type="DOI">10.1145/3025453.3025984</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, CHI &apos;17</title>
		<meeting>the 2017 CHI Conference on Human Factors in Computing Systems, CHI &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="208" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Formalizing emphasis in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Perin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kusalik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="717" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Visual quality adjustment for volume rendering in a head-tracked virtual environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>H√§nel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Weyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hentschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Kuhlen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1472" to="1481" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The role of monocularly visible regions in depth and surface perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Wilcox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2666" to="2685" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Development of nasa-tlx (task load index): Results of empirical and theoretical research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Staveland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in psychology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="139" to="183" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An integrative model of binocular vision: a stereo model utilizing interocularly unpaired points produces both depth and binocular rivalry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="2367" to="2380" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attention and visual memory in visualization and computer graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Enns</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2011.127</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1170" to="1188" />
			<date type="published" when="2012-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A boolean map theory of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pashler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">599</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualizing data with motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization, 2005. VIS 05. IEEE</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="527" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Depth asymmetry in da vinci stereopsis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>H√§kkinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nyman</surname></persName>
		</author>
		<idno type="DOI">10.1016/0042-6989(96)00099-5</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="3815" to="3819" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Computational modelling of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature reviews. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">194</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Journey to the centre of the cell: Virtual reality immersion into scientific data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ariotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lilja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Traffic</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="110" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Binocular depth perception of computer-generated patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bell Labs Technical Journal</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1125" to="1162" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Foundations of cyclopean perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Textons, the elements of texture perception, and their interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Julesz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5802</biblScope>
			<biblScope unit="page" from="91" to="97" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Gpubased high-quality volume rendering for virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kratz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fuhrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Splechtna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>B√ºhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Augmented Environments for Medical Imaging and Computer Aided Surgery (AMI-ARCS)</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Gullivr: A walking-oriented technique for navigation in virtual reality games based on virtual body resizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krekhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cmentowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Emmerich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Masuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kr√ºger</surname></persName>
		</author>
		<idno type="DOI">10.1145/3242671.3242704</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play, CHI PLAY &apos;18</title>
		<meeting>the 2018 Annual Symposium on Computer-Human Interaction in Play, CHI PLAY &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="243" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deadeye: A novel preattentive visualization technique based on dichoptic presentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krekhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kr√ºger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="936" to="945" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Acceleration techniques for gpu-based volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th IEEE Visualization 2003 (VIS&apos;03)</title>
		<meeting>the 14th IEEE Visualization 2003 (VIS&apos;03)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Spherical layout and rendering methods for immersive graph visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O.-H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Muelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Pacific Visualization Symposium (PacificVis)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="63" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A Study of Layout, Rendering, and Interaction Methods for Immersive Graph Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O.-H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Muelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1802" to="1815" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A study of layout, rendering, and interaction methods for immersive graph visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O.-H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Muelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1802" to="1815" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Effects of immersion on visual analysis of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sensharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Schiffbauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions On Visualization &amp; Computer Graphics</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="597" to="606" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A survey on deep learning in medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A A</forename><surname>Setio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghafoorian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>S√°nchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="60" to="88" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Binocular matching of dissimilar features in phantom stereopsis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Schor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="633" to="644" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">What is rivalling during binocular rivalry?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Logothetis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Leopold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Sheinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">380</biblScope>
			<biblScope unit="issue">6575</biblScope>
			<biblScope unit="page">621</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A computational theory of human stereo vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Royal Society of London. Series B. Biological Sciences</title>
		<meeting>the Royal Society of London. Series B. Biological Sciences</meeting>
		<imprint>
			<date type="published" when="1156" />
			<biblScope unit="volume">204</biblScope>
			<biblScope unit="page" from="301" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Cooperative computation of stereo disparity. From the Retina to the Neocortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
			<biblScope unit="page" from="239" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Visual search for a conjunction of movement and form is parallel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcleod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Driver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Crisp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">332</biblScope>
			<biblScope unit="issue">6160</biblScope>
			<biblScope unit="page" from="154" to="155" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Extending a virtual reality nasal cavity education tool with volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mil√°n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stefan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="811" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Visual search for conjunctions of motion and form: The efficiency of attention to static versus moving items depends on practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>M√ºller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Von Muhlenen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="385" to="408" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Da vinci stereopsis: Depth and subjective occluding contours from unpaired image points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimojo</surname></persName>
		</author>
		<idno>doi: 10.1016/ 0042-6989(90</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">90161</biblScope>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
	<note>Optics Physiology and Vision</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Serial and parallel processing of visual feature conjunctions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Silverman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="issue">6059</biblScope>
			<biblScope unit="page" from="264" to="265" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Scanpaths in saccadic eye movements while viewing and recognizing patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Noton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stark</surname></persName>
		</author>
		<idno type="DOI">10.1016/0042-6989(71</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="90213" to="90219" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Developing virtual reality visualizations for unsteady flow analysis of dinosaur track formation using scientific sketching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Novotny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tveite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gatesy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Drury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Falkingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2145" to="2154" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">On the preattentive accessibility of stereoscopic disparity: Evidence from visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>O'toole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="218" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Paffen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Hessels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Der Stigchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="256" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Interocular conflict attracts attention. Attention</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A search asymmetry for interocular conflict</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L E</forename><surname>Paffen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T C</forename><surname>Hooge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Benjamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hogendoorn</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-011-0100-3</idno>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1042" to="1053" />
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The dominant eye</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Porac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Coren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">880</biblScope>
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">The benefits of using a walking interface to navigate virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Ruddle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lessels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Walking improves your cognitive map in environments that are large-scale and large in extent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Ruddle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>B√ºlthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Direct volume rendering in virtual reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Scholl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bildverarbeitung f√ºr die Medizin</title>
		<editor>A. Maier, T. M. Deserno, H. Handels, K. H. Maier-Hein, C. Palm, and T. Tolxdorff</editor>
		<meeting><address><addrLine>Berlin Heidelberg; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="297" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The benefits of immersion for spatial understanding of complex underground cave systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schuchardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 ACM symposium on Virtual reality software and technology</title>
		<meeting>the 2007 ACM symposium on Virtual reality software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="121" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Medvis: A real-time immersive visualization environment for the exploration of medical volumetric data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Boulanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference BioMedical Visualization: Information Visualization in Medical and Biomedical Informatics</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="63" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Real world occlusion constraints and binocular rivalry. Vision research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="69" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Interocularly unpaired zones escape local binocular matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1875" to="1881" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">An occlusion-related mechanism of depth perception based on motion and interocular sequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">333</biblScope>
			<biblScope unit="issue">6170</biblScope>
			<biblScope unit="page">265</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Popout prism: Adding perceptual principles to overview+detail document interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Woodruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosenholtz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;02</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;02<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Brightnesses, luminances, and fechner&apos;s paradox</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Y</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Galanter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="297" to="300" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Serial vs. parallel processing: Sometimes they look like tweedledum and tweedledee but they can (and should) be distinguished</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Townsend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="54" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Feature analysis in early vision: Evidence from search asymmetries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gormican</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Illusory words: The roles of attention and of top-down constraints in conjoining letters to form words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Souther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A feature-integration theory of attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gelade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="136" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Da vinci decoded: Does da vinci stereopsis rely on disparity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsirlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Wilcox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Allison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2" to="2" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Attractive flicker: Guiding attention in dynamic narrative visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Waldner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Muzic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Purgathofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2456" to="2465" />
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Information visualization: perception for design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Evaluating stereo and motion cues for visualizing information nets in three dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Franck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="140" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Stereo algorithm that extracts a depth cue from interocularly unpaired points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="569" to="578" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Guided search: an alternative to the feature integration model for visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Cave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">419</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Binocularity and visual search. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Franzel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="81" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Five factors that guide attention in visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">58</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Eye movements during perception of complex objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yarbus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eye movements and vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1967" />
			<biblScope unit="page" from="171" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Spectacularly Binocular: Exploiting Binocular Luster Effects for HCI Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>School of Computing, Natuanal University of Singapore</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Beyond stereo: An exploration of unconventional binocular presentation for novel visual experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1145/2207676.2208638</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;12</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2523" to="2526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Attention capture by eye of origin singletons even without awareness-a hallmark of a bottom-up saliency map in the primary visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhaoping</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A cooperative algorithm for stereo matching and occlusion detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="675" to="684" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Binocularity and visual search-revisited. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Utochkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="473" to="483" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
