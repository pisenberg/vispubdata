<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DimReader: Axis lines that explain non-linear projections</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Faust</surname></persName>
							<email>rjfaust@email.arizona.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Glickenstein</surname></persName>
							<email>glickenstein@math.arizona.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Scheidegger</surname></persName>
						</author>
						<title level="a" type="main">DimReader: Axis lines that explain non-linear projections</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Non-linear dimensionality reduction, auto-differentiation</keywords>
			</textClass>
			<abstract>
				<p>Comparing a Dimension Across Projections (Coordinate axes for petal length) t-SNE LLE Isomap B A Discovering Perturbations C Fig. 1. DimReader explains non-linear dimensionality reduction methods by illustrating the effects of user-designed perturbations of the input dataset. It provides an answer to the question &quot;if the input data had been slightly different in a particular way, how would the plot have changed?&quot;. In the case of traditional scatterplots, it recovers exactly the axis lines being displayed. In the case of non-linear methods, DimReader recovers generalized axes, which indicate how dimensions of interest behave. Examples of these axes are shown in (A) for the x, y, and z dimensions of the S Curve (an S shaped 3 dimensional manifold). These axes also allow for the comparison of different projection methods. This is exemplified in (B), where the petal length axis of the iris dataset is shown for three projections. Petal length is well behaved in t-SNE but not in the other projections. We also provide a technique for discovering good perturbations of the input (perturbations that change the projection the most). The top of (C) shows an example of a discovered perturbation. In context, shown at the bottom of (C), this perturbation shows us that t-SNE is sensitive to flat shoes v.s. heels. The perturbation wants to change the original image from a heel to a flat by filling in the arch.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>One of the central promises of data visualization is that its techniques will help users and analysts make sense of large, complicated datasets. Data visualization, and specifically techniques in dimensionality reduction, are routinely used in practice during exploratory data analysis of challenging datasets.</p><p>Classical linear methods such as Principal Components Analysis have existed for more than a century, but recent advances from non-linear methods that started with Tenenbaum et al's Isomap <ref type="bibr" target="#b46">[47]</ref> have revolutionized the practice of dimensionality reduction. The potential to understand high dimensional data via low-dimensional representations is clearly attractive. But just what, exactly, are these non-linear dimensionality reduction (NDR) methods showing? This is the fundamental question that drives the work we report here. Data scientists and analysts use NDR's in an attempt to create a nice 2-dimensional representations for their data in hopes of learning some of the underlying structure of the data. The NDR's often result in nice pictures but give no indication why the NDR placed things the way it did and no context to the input.</p><p>Consider van der Maaten and Hinton's t-SNE, arguably the most powerful and currently most popular method for NDR <ref type="bibr" target="#b34">[35]</ref>. Although practical experience attests to t-SNE's power to uncover cluster relationships in very challenging datasets, its sensitivity to the hyper-parameters is remarkable <ref type="bibr" target="#b51">[52]</ref>. If small changes in parameter settings produce plots that are fundamentally different, we must ask ourselves: are some results generated by NDR methods just bad? Do different parameter settings show different features of the data? More importantly, how do we even answer these questions?</p><p>In this work, we design data transformations, which induce transformations on the visualization itself, elucidating the behavior of the NDR method (this is the perspective introduced by Kindlmann and Scheidegger's algebraic design process <ref type="bibr" target="#b30">[31]</ref>). Specifically, we use infinitesimal perturbations -small changes of the data in its original space -to produce infinitesimal changes of the visualization. We then show how these visualization changes can be interpreted as producing effective, non-linear axis legends. In this way, our non-linear axes explain the NDR plot in the same way that axis legends explain the positional encoding in scatterplots. As a result, analysts can understand and evaluate dimensionality reduction plots similarly to how they evaluate linear methods. In fact, we show in Section 3 that our methods exactly recovers the gridlines of typical scatterplots. DimReader is quite general, and can be applied to many different NDR techniques, only requiring access to the source code of its implementation. Specifically, we use a method known as automatic differentiation to produce the necessary gradients for calculating the infinitesimal changes of the visualization <ref type="bibr" target="#b25">[26]</ref>. An overview of the process is given in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>In summary, our contributions are:</p><p>• A general framework to explain plots generated by non-linear dimensionality reduction, using infinitesimal perturbations</p><p>• A practical implementation of the framework using automatic differentiation</p><p>• A method for discovering good perturbations for a given dataset, useful when the input lacks easily interpretable dimensions (and hence, lacks easily-defined perturbations)</p><p>• An experimental study of the effectiveness and efficiency of Dim-Reader using three well-known NDR methods: Isomap <ref type="bibr" target="#b46">[47]</ref>, LLE <ref type="bibr" target="#b38">[39]</ref>, and t-SNE <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Projection methods have received a considerable amount of attention in information visualization. In this section, we review the work that is most directly related to our research, but cannot hope to cover the entirety of the field. For a comprehensive view on multidimensional scaling and dimensionality reduction, we recommend Born and Grönen's textbook <ref type="bibr" target="#b4">[5]</ref>, and Fodor's survey <ref type="bibr" target="#b22">[23]</ref>.</p><p>Projection methods in information visualization The observation that pairwise similarities (or distances) can be converted into low-dimensional representations by a mathematical formulation comes from Torgerson and his now-classical theory of multidimensional scaling <ref type="bibr" target="#b47">[48]</ref>. In information visualization, force-directed methods have long been used as a dimensionality reduction technique, from fullyautomatic methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b35">36]</ref>, to methods which take some amount of interaction, either through placement of exemplar points <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b36">37]</ref> or through direct interaction with projection parameters <ref type="bibr" target="#b28">[29]</ref>. Although interactive methods offer a better hope for understandability because the perturbation analysis we discuss can happen "in the analyst's head" during interaction, we argue that the visual encoding these techniques provide can still be unclear. The technique we propose here can be applied to essentially all of the methods above, and offers an attractive complement to both automated and interactive projection methods.</p><p>Perturbation Analysis for data science The idea of understanding a system by examining its behavior under perturbations is wellestablished in the engineering and statistics literature. In the 1970's, Cook introduced the notion we now know as Cook's distance <ref type="bibr" target="#b16">[17]</ref>, which measures the influence of a point on the parameters of linear regression models. In the context of visualization, Bergner et al. point to sensitivity analysis as one of the requirements in understanding computer simulations <ref type="bibr" target="#b3">[4]</ref>. In this paper, we use perturbation analysis as a central tool to recover readable axes from NDR methods, in a sense incorporating sensitivity analyses into familiar visual metaphors.</p><p>Automatic Differentiation Perturbation analysis is clearly an important tool for understanding systems, but the issue of how to implement it in existing computer systems is crucial. Automatic differentiation (which we explain in detail in Section 3) provides a way to compute derivatives of arbitrary functions in a computer program, provided access to the source code (or similar structural information about the computation) is available <ref type="bibr" target="#b25">[26]</ref>. To the best of our knowledge, the most mature software library employing automatic differentiation is Ceres, written in C++ and employing template metaprogramming <ref type="bibr" target="#b0">[1]</ref>. DimReader is implemented in Python for simplicity and terseness, but could easily be redesigned in C++.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Guidance and validation of projection results</head><p>One of the issues with NDR is that it's hard to know what a plot is actually showing <ref type="bibr" target="#b49">[50]</ref>. This has resulted in a variety of papers which offer guidance and design principles on how to interpret projections, based on a combination of real-world experience, synthetic examples, and theoretical arguments <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>. This work is essential to the current practice, we argue, because current NDR methods do not offer explanations of their own results -there are much fewer research papers offering guidance for understanding and interpreting traditional scatterplots. As we show in Section 4, our technique provides a way for a projection method to explain itself. Although analyst guidance and validation will always be a part of a well-designed analysis infrastructure, our technique could mitigate some of the problems that have been observed in deployed systems, where projection methods are ultimately discarded because of readability issues <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b26">27]</ref>.  <ref type="figure">Fig. 3</ref>. An overview of DimReader. For a given NDR method, we 1) compute its position using the original implementation; 2) compute perturbation directions for the input points with the transformed version of the implementation which uses dual numbers (We discuss how to choose appropriate perturbations in Section 3.2.2); 3) compute the scalar field whose gradient best matches the perturbation vectors in a least-squares sense; and finally 4) compute its isocontours. Section 3 explains these steps in detail.</p><p>Augmented visual representations There is another avenue of attack on the readability problem of NDR methods. Often, researchers will augment the results of the projections with visual diagnostics that pinpoint potential problems. Seifert et al. augment the projection by showing how the projection's stress (roughly the discrepancy between source-space distances and target-space distances) varies spatially in the NDR plot <ref type="bibr" target="#b43">[44]</ref>. In <ref type="bibr" target="#b2">[3]</ref> and <ref type="bibr" target="#b33">[34]</ref>, the projection is augmented to show uncertainty measures and distortions in NDR's respectively. Cutura et. al's VisCoDeR allows users to compare and explore different dimensionality reductions by augmenting the projection to allow users to explore how dimensions are mapped in the dimensionality reduction results as well as the high-dimensional proximity of projected points to a selected point in the projection <ref type="bibr" target="#b18">[19]</ref>. Stahnke and co-authors described methods to probe a projection, through carefully designed user interactions and custom visual encodings <ref type="bibr" target="#b45">[46]</ref>. Our method for extracting effective axes can be seen as a way to allow any NDR method to augment itself with metaphors that have a well-defined analogy in the linear case, as can be seen in Section 4, and Explainable visualizations Every plot assumes an audience that can read it, and visualization literacy remains an active area of research <ref type="bibr" target="#b5">[6]</ref>. Often, novel metaphors are necessary because of the data or task complexity <ref type="bibr" target="#b7">[8]</ref>. We argue that generalizing well-established techniques such as axis legends to NDR can help explain those techniques. Gleicher's Explainers take user interaction to design specific projections for input data <ref type="bibr" target="#b23">[24]</ref>. In contrast, our technique extracts axes inherent in the non-linear projections. Coimbra et al. explain projections through enhanced biplots <ref type="bibr" target="#b15">[16]</ref>. Similar to our technique, they show axes for the dimensions of the input data in the low dimensional plot. Because of the non-linearity of these dimensionality reductions, the biplot axis will change based on the projected position of the sampled point whereas our technique captures the axis lines for the entire projection. A similar approach is proposed by Cavallo and Demiralp in Prolines, a technique for interacting with data points in both low-and high-dimensional spaces <ref type="bibr" target="#b10">[11]</ref>. Prolines allow efficient, direct manipulation of the output points, but require access to efficient forward and backward projection, limits its applicability. Flow-based scatterplots <ref type="bibr" target="#b12">[13]</ref> and Generalized Sensitivity Scatterplots <ref type="bibr" target="#b13">[14]</ref> show the sensitivity of a dimension in a scatterplot with respect to other dimensions in the dataset. Similar to our technique, these methods use derivatives to determine the sensitivities. Our technique differs by showing sensitivity of the projection with respect to the original data rather than sensitivity between dimensions in the original data. The data context map from Cheng et. al. provides a way to simultaneously look at clusters of data points and the location of the most dominant values of each attribute with the assumption that the attribute values always decrease as points move farther away from it. <ref type="bibr" target="#b14">[15]</ref>. Our technique differs by showing the behavior of a dimension throughout the entire projection, not just the location of the most dominant value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TECHNIQUE</head><p>Our technique is broken into two parts: (1) explaining an NDR method using a known perturbation (DimReader ) and (2) searching for good perturbations when there is no known perturbation (after which Dim-Reader can be applied).</p><p>In principle, all that DimReader requires is the ability to compute derivatives of the projection coordinates with respect to each of the input points. For extremely simple techniques (such as scatterplots and other fixed linear projections), these derivatives can easily be evaluated in closed form. However, more sophisticated methods such as Isomap, LLE, and t-SNE involve long computation chains, for which the evaluation of the derivative would introduce significant development overhead. Instead of trying to solve them in closed form, we take central advantage of automatic differentiation. <ref type="bibr" target="#b25">[26]</ref>. As we describe next, automatic differentiation allows us to calculate the derivative of a projection with minimal implementation effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Automatic Differentiation</head><p>In this paper, we use a particular form of automatic differentiation known as forward-mode automatic differentiation. In what follows, we will refer to it as "autodiff".</p><p>In forward-mode autodiff, the program's derivative with respect to a specified variable is computed alongside the function value, by using an extended number system. In this system, we replace numbers in the program with dual numbers that have the form x = (a, b) where a holds the original value of the number and b carries the derivative of x with respect to our variable of interest. When we initialize a variable y, we set b to one if that is the variable we want to differentiate with respect to (since dy/dy = 1) and zero otherwise. When the projection is run with dual numbers in place of regular numbers, in addition to calculating the projected points, it calculates their derivatives through applications of the chain rule and derivative rules (product rule, quotient rule, etc.).</p><p>Note that autodiff is always performed at a specific value, and with respect to a specific variable. It produces two numbers as a result: the function value and the partial derivative with respect to the chosen variable. This has two important consequences for our design. First, we need to decide over exactly which variables we will take derivatives. Second, we need to execute the program many times in order to evaluate many different derivatives. This will become important in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">DimReader Process 3.2.1 Overview of the process</head><p>To apply DimReader to an NDR method, there are four steps. Each of these steps is discussed in a subsection below.</p><p>• A user chooses a perturbation of interest, which defines an infinitesimal change for each data point (possibly in different directions).</p><p>• The NDR method is executed many times using dual numbers, from which we obtain the perturbation vectors, one for each input point.  <ref type="figure">Fig. 4</ref>. Although a basic implementation of DimReader is easy to understand (top), it only extracts one perturbation vector at a time. A more efficient implementation (bottom) extracts half of the perturbation vectors from the input at once. To remove possible correlations between the outputs, we choose which points to include at random, and iterate until all points have been included. The expected time in this case is logarithmic on the size of the input point dataset.</p><p>• From the perturbation vectors, a scalar field whose gradient matches the perturbation vectors is computed. • The isolines of this scalar field, which are perpendicular to the gradient, are extracted using Marching Squares. They form the effective axes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Choosing which perturbation to use</head><p>The first step of our method involves a choice of the perturbation of the dataset. A perturbation is a small change to a specific dimension (or set of dimensions) for each data point in the original, high-dimensional space. Thus, the choice of perturbation corresponds, effectively, to an analyst answering the following question: "if each data point were slightly different in this specific way, what would happen to the visualization?" In order to recover different features of the NDR method and its effect on the dataset of interest, different perturbations can be designed. In the following, we discuss choosing a perturbation in a dataset with interpretable dimensions. We discuss discovering perturbations for other datasets in Section 3.4. In automatic differentiation, perturbations are represented by the derivative part of the dual number for the original data points. The perturbation of a data point with d dimensions has the form of a unit vector with d elements where the value of each element specifies how much the corresponding dimension is perturbed relative to the rest of the dimensions. Datasets with interpretable dimensions Some datasets have interpretable columns. Take the iris dataset, for example, which is used in <ref type="figure" target="#fig_0">Figure 2</ref>. In that case, a perturbation that changes each of the input points in the direction of a given dimension will reconstruct, for an NDR method, curved axes lines that correspond, roughly to the linear grid lines in scatterplots. Concretely speaking, we evaluate each input point</p><formula xml:id="formula_0">p i as (p i , (0, • • • , 0, 1, 0, • • • , 0)),</formula><p>where the value 1 is positioned at the dimension of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Extracting derivatives from NDR methods</head><p>In this section, we describe two techniques used in DimReader to extract the perturbation vectors ,the changes to the projected coordinates resulting from a perturbation on the input, for a given projection. The first technique is simple, straightforward, and provides a good intuition for the overall strategy. Unfortunately, this technique requires as many executions of the NDR method as there are input points in the dataset, which often means the overall performance can suffer. The second technique, on the other hand, only requires as many runs as the logarithm of the number of input points. We give pseudo-code for the two approaches in <ref type="figure">Figure 4</ref>.  DimReader needs access to the source code for the NDR method at this step so the method can be executed with dual numbers. In principle, the source code can be executed without any modifications aside from converting the input points into dual numbers. In practice, some issues arise because of efficiency concerns and library limitations. We discuss these issues at length in Section 4.</p><p>Perturbing one point at a time After a perturbation is chosen, the NDR technique is executed with automatic differentiation for every point in the dataset. On execution i, the point p i is perturbed (that is, we replace p i with (p i ,p i ) wherep i is the specified perturbation of p i ). The NDR technique will return the projection coordinates, v, for all points, along with the derivative of the projection coordinates with respect to the perturbation of p i , dv d p i . We use the derivative of each coordinate in the reduced point v i as the vector that describes the change in the coordinate, and discard the rest of the information of the run. The pseudocode for this is given on the top half of <ref type="figure">Figure 4</ref>.</p><p>Perturbing many points at a time The method described above is inefficient, requiring O(n) evaluations of the NDR method. A naive attempt to optimize the method would evaluate the projection derivatives with respect to all of the points (and hence all of the per-point perturbations) at once, and only run the autodiff version of the code once. Unfortunately, this does not work for many perturbations, because most DR methods are invariant to dataset translations. The perturbation of only one input point at a time offers interesting insight into the NDR method, but if we move all of the points at once in the same direction, NDR methods such as Isomap, LLE, and t-SNE will produce exactly the same projection (the perturbation vectors will be all zeros).</p><p>We solve this problem by adding a small amount of randomization. Instead of perturbing one point at a time, we can choose half of the points at random to perturb, while the other half does not change. We then store the projection vectors for the points we chose to perturb, and repeat the process until we have actually perturbed all of the input points. After each round, we expect to halve the number of unperturbed points, which gives an expected number of repeated runs which is logarithmic on the number of input points. The pseudocode for this is given on the bottom half of <ref type="figure">Figure 4</ref>. We found that the DimReader plots produced by perturbing many points at a time are indistinguishable from the plots produced by perturbing one point at a time.</p><p>Ignoring changes in unperturbed points In some cases, perturbing a point p i has an effect on points other than its corresponding projected point v i . However, the effects on other points are small enough that we can effectively ignore them. In <ref type="figure" target="#fig_4">Figure 5</ref>, we show that the effect of perturbing each point p i on the other points, v j (i = j) tends to be near zero and very rarely is significant. We show this result for the iris dataset, but have found it to be true in general for t-SNE in all datasets we checked. Intuitively, we expect a good dimensionality reduction to be robust to a small change in a single point, and thus the residual effect on the rest of the points to be insignificant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Reconstructing the direction field</head><p>Once we have the projected points and their derivatives (that is, the perturbation vectors), we need to reconstruct the direction field, in order to extract perpendicular lines. We achieve this by computing a scalar field whose gradient best matches the vectors. We use a simple least-squares reconstruction technique, adapted from Ferreira et al.'s vector-field clustering work <ref type="bibr" target="#b21">[22]</ref>, which we illustrate in <ref type="figure" target="#fig_5">Figure 6</ref>. We first decompose the output plane in a rectangular grid, and split each grid square into two triangles, giving a triangular mesh of the output space. The resolution of this grid needs to be decided ahead of time, and we use a 10x10 grid in our examples for this paper. We model a scalar field on the output plane as a piecewise-linear function on the grid values. Each point and its perturbation vector is interpreted as a linear constraint on the vertices of its corresponding triangle. To find the best-fitting scalar field, we solve it in a least-squares sense, regularizing the system to ensure a unique solution <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.5">Extracting perpendicular lines</head><p>The final step is quite simple. With the scalar field expressed as values in a triangular mesh, we can use marching squares to extract isocontours <ref type="bibr" target="#b1">[2]</ref>. By construction, the gradient of this scalar field matches the perturbations. Since isolines are perpendicular to a function's gradient <ref type="bibr" target="#b40">[41]</ref>, the resulting curves will tend to be perpendicular to the perturbations. As we show in <ref type="figure" target="#fig_0">Figure 2</ref>, these isoline can be thought of as generalized axes lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interpreting DimReader Plots</head><p>In our plots, the projected points would move perpendicular to the isolines nearest to them if the input were perturbed in the specified way. An increase in the corresponding dimension would move the point from light to dark. The relative density of the isocontours can be interpreted similarly to the behavior in scalar fields. Narrowly-spaced isocontours indicate a high sensitivity to changes in the independent variable, (in our case, projection coordinates). Widely-spaced isocontours indicate low spatial sensitivity: a change in the projection coordinates is not expected to change the outcome variable by much. Curved isolines indicate that the same perturbation has a different effect on different points. Isolines that fan out (go from narrowly-spaced to widely-spaced as in <ref type="figure">Figure 8</ref>) indicate that the sensitivity of the plot is changing from more sensitive on one side to less sensitive on the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discovering Good Perturbations</head><p>We may not always know good perturbations for a dataset, such as the MNIST digits where it is not clear what the best way to perturb each image would be. To help solve this problem, we offer two methods to  <ref type="figure">Fig. 7</ref>. Extracting axes from the Iris dataset with four projections: PCA, Isomap, LLE, and t-SNE. We only show petal length and sepal width because petal width is extremely similar to petal length and sepal length is very similar to sepal width. We discuss how to interpret these plots in Section 4.1 recover good perturbations. We define good perturbations as perturbations on the input that change the projection the most under the given constraints. Both of the methods require that we have a tangent map, M, for the projection. The tangent map allows for efficient calculation of the perturbation vector,v, for a given projection, without running the projection itself. Given a perturbation on the inputp, M •p results in the perturbation vectorv, i.e.v = dv/d p where v is the projected coordinates. The vectorp consists of the perturbation of each input point concatenated into a single vector (end to end) and the perturbation vectorv consists of the perturbation vectorv i of each projected point (v i ) concatenated into a single vector. A single column of M can be recovered by a perturbation vector that has a single entry of 1 and the rest zeros (i.e. perturbing a single dimension of a single point). By doing this for each dimension of every point, the entire tangent map can be recovered.</p><p>One observation about the tangent map is that the values we need for calculating the perturbation vectors lie in k × d blocks along the diagonal, where k is the dimension of the projection (typically 2) and d is the dimension of the input data. Because we ignore the effect a given perturbation on all other points (as discussed in 3.2.2), we set the rest of the matrix to zero. We exploit the block structure of the tangent map in both of our methods for finding the best perturbation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Perturb all points in the same direction</head><p>The first method for recovering the best perturbation is to find the single perturbation that when applied to all points changes the projection the most. The formulation for this method is:</p><formula xml:id="formula_1">argmax v∈R d ∑ ||B iv || 2 s.t ||v 2 || = 1</formula><p>where B i is the block on the diagonal of M for point i. This can be rewritten as ∑ iv T B T i B iv + λ (v Tv − 1). To find the maximum, we take the derivative with respect tov and set it to zero:  <ref type="figure">Fig. 8</ref>. The best perturbation for the iris dataset. The left plot is the Dim-Reader plot for this perturbation. In the two plots on the right, the color of each point shows how much the point is perturbed for the specified dimension. We see that the sepal width and sepal length are perturbed more in the Red cluster (the Setosa cluster) than the petal dimensions which means that, for this cluster, the projection is sensitive to changes in the Sepal dimensions. The perturbations for the points in the other cluster are insignificant. This tells us that perturbing only the Setosa points will change the projection the most.</p><formula xml:id="formula_2">d dv ∑ iv T B T i B iv + λ (v Tv − 1) = ∑ 2B T i B iv − λ 2v = 0.</formula><p>eigenvalue. This gives us a single perturbation,v, that when applied to all points maximizes the change in the projection.v is constrained to have unit length to prevent the method from choosing an arbitrarily large perturbation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Perturb each point individually</head><p>The second method for recovering the best perturbation is to find different perturbations for each point that collectively change the projection the most constrained so that points that are projected to similar places have similar perturbations. The formulation is as follows:</p><formula xml:id="formula_3">argmax v∈R d ∑ i ||B ivi || 2 − λ ∑ i ∑ j ||v i −v j || 2 S(i, j) s.t ||v 2 || = 1</formula><p>where B i is the block on the diagonal for point i,v i is the perturbation for the point i, λ is a free parameter for how much smoothing we want, and S(i, j) is the similarity between the projection of points i and j, p i and p j . This similarity is defined as S(i, j) = e −||p i −p j || 2 /σ 2 . σ 2 is a free parameter set by the user that determines how close points have to be in the projection to be considered similar. We can rewrite the above equation as follows: Furthermore, the equation can be rewritten in terms of the whole matrix, M, and the entire perturbation vector,v giving us the following equation which incorporates the constraint on the length ofv:</p><formula xml:id="formula_4">argmax v∈R d ∑ iv i B T i B ivi − λ ∑ i ∑ j v i −v j ,v i −v j S(i, j) s.t ||v 2 || = 1 We observe that ∑ i ∑ j v i −v j ,v i −v</formula><formula xml:id="formula_5">argmax v∈R dv T M T Mv − λv T L sv − λ 2v Tv − 1</formula><p>Taking the derivative with respect tov and setting it to zero, we get</p><formula xml:id="formula_6">v T (M T M − λ L s ) − λ 2v = 0</formula><p>The entire perturbation vector,v, is the eigenvector of the matrix M T M − λ L s with the largest eigenvalue.</p><p>Choosing λ and σ . σ controls the width of a gaussian centered on each point. Examining the results of the projection itself gives some information about plausible values for σ . For example, points outside further than three standard deviations from each other are essentially treated independently, but at the same time, we don't want a σ that creates a gaussian which covers the entire projection. For choosing λ , we should be looking at the resulting perturbations. If a single point is heavily dominating the perturbation (i.e. it moves much more than the rest of the points) then λ is likely too small. In contrast, if all points are perturbed in almost exactly the same way, this is an indication that λ may be too large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION AND EXPERIMENTS</head><p>In this section, we discuss the implementation of our techniques along with a suite of experiments designed to explore the capabilities, performance, and limitations of DimReader. We will show how DimReader directly addresses the following gaps identified in Sedlmair et al.'s interview study about gaps between theory and practice in dimensionality reduction (DR) <ref type="bibr" target="#b41">[42]</ref>. These include the interpretation gap: "what do the results mean?"; guidance gap, "what algorithm to use?", and the non-linear unmapping gap: "how do projection dimensions relate to input dimensions?".</p><p>Our current prototype for DimReader is implemented in Python and numpy <ref type="bibr" target="#b50">[51]</ref>. Our t-SNE implementation is closely based on van der Maaten's Python code <ref type="bibr" target="#b48">[49]</ref>, while the LLE and Isomap implementations are from-scratch. The entire method takes about 3,500 lines of Python, including implementations of Marching Squares, the classes for autodiff, and the linear solvers described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">DimReader</head><p>In the following we look at a well known dataset, the iris dataset, with known perturbations, and simple projection algorithms, in order to better understand the behavior of the technique <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Linear projections</head><p>We start with showing results of linear projections as a basic sanity check on the behavior of DimReader. <ref type="figure">Figure 7</ref> shows a typical example of the axes reconstructed by DimReader when using linear projections. Since linear projections can be exactly represented by a matrix multiplication, the derivatives of input points position with respect to one direction will always be constant vectors. As a result, the reconstructed scalar field is almost (except for the influence of the regularization terms) a linear ramp, and so the contour lines are evenly spaced and parallel, which indicate that changes in the input variable will behave identically across the entire field. Despite their limited power, this property is one of the main advantages of linear projections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Isomap</head><p>Isomap was one of the first NDR techniques to recover curved manifolds well in practice <ref type="bibr" target="#b46">[47]</ref>. Isomap builds a weighted graph which approximates the manifold, where edges have weight equal to the distance between points, and each point has edges to its k nearest neighbors (k is specified by the user). The global distance between two points is defined to be the shortest-path metric on the graph. The low-dimensional projection is constructed from the shortest-path metric using classical MDS <ref type="bibr" target="#b4">[5]</ref>.</p><p>We implemented Isomap not only because of its historical significance and relatively high-quality results, but also because it highlights an interesting property of automatic differentiation: it works over code bases that we tend to not think of as differentiable. Specifically, the operations in Dijkstra's algorithm for shortest paths are all well defined for dual numbers, and so we naturally can extract the sensitivity of shortest-path distances with respect to changes in the input points <ref type="bibr" target="#b17">[18]</ref>.</p><p>Interaction with numerical linear algebra routines The final step of Isomap is Classical MDS, and this presents unique challenges for our autodiff implementation based on operator overloading. Specifically, Classical MDS requires the computation of eigenvectors, and since Python libraries for numerical linear algebra are implemented through high-performance libraries like Lapack, the operatoroverloading functionality is not present. To solve this issue, we implement the eigenvalue computation through power iterations <ref type="bibr" target="#b24">[25]</ref>, since matrix-vector multiplication of dual numbers has efficient dual-number implementations in terms of matrices of values and ε terms. <ref type="figure">Fig. 9</ref>. An overview of perturbations for points in the(A) MNIST digits and (B) MNIST fashion. There is structure in the perturbations that our technique discovers. They often resemble their true digit (or clothing article) but with some variation. Darker areas are perturbed more than lighter areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head><p>Isomap Experiments Because Isomap uses classical MDS (which is essentially a linear projection), we should expect that, to some degree, Isomap would behave much like linear projections. This is indeed the case with simpler datasets, such as the Iris dataset, shown in <ref type="figure">Figure 7</ref>. However, there are some interesting differences. Consider the generalized axis for the "sepal width" variable which DimReader recovers. Even though the point positions generated by Isomap are quite similar to that of PCA, the sensitivity of the projection differs dramatically from the cluster of Setosa samples to that of Virginica and Versicolor samples. Even more interestingly, it seems that the sensitivity is caused by only some of the Setosa samples. This differentiation is not present in the linear projection, and would not be clear from the Isomap plot alone. In this example, DimReader helps overcome Sedlmair's interpretation gap by providing an explanation for why Isomap spread the points in the Setosa cluster (Isomap is sensitive to differences in the Sepal Width in this cluster) that would otherwise be unknown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Locally Linear Embedding</head><p>The next algorithm we highlight is Roweis and Saul's Locally Linear Embedding <ref type="bibr" target="#b38">[39]</ref> (LLE). Like Isomap, LLE uses a nearest-neighbor graph to recover a global view of the dataset. LLE computes edge weights for the nearest neighbor graph, such that each vertex can be best reconstructed by a linear combination of its neighbors using those weights. On a second step, the projection coordinates are recovered by finding positions on the plane that best respect the weights.</p><p>Interaction with numerical linear algebra routines Similarly to Isomap, our autodiff implementation of LLE involves a small degree of adaptation. In the case of Isomap, we required the computation of the largest eigenvalues of a matrix. In the case of LLE, we need to compute the smallest non-zero eigenvalues. Our implementation uses inverse power iteration <ref type="bibr" target="#b24">[25]</ref>. Inverse power iteration, in turn, requires a linear system solver, which presents similar issues for dual number implementations. Our solution is to implement a black-box linear system solver using conjugate gradients <ref type="bibr" target="#b44">[45]</ref>.</p><p>LLE Experiments Locally Linear Embedding is a popular method due to its performance <ref type="bibr" target="#b38">[39]</ref>, but is known to produce distorted projections <ref type="bibr" target="#b19">[20]</ref>. In this section, we illustrate how DimReader might help pinpoint such problems. Consider the projection of the iris dataset in <ref type="figure">Figure 7</ref>. Note that neither of the recovered axes quite cross the projection perpendicularly on the left side of the arc (the Versicolor and Virginica cluster): no direction of perturbation on the input moves the points diagonally along that cluster. This suggests that the shape of the cluster is an artifact of the projection method. Compare this with the Isomap projection in <ref type="figure">Figure 7</ref>: Isomap has perturbations which cross each of the clusters perpendicularly (Sepal Width for Setosa and Sepal Length for Versicolor and Virginica). Thus, Isomap is more faithful to the underlying data than LLE. This is evidence that DimReader helps bridge Sedlmair et. al's guidance gap <ref type="bibr" target="#b41">[42]</ref>, giving an indication for which NDR algorithm performs better for this data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">t-SNE</head><p>t-SNE is among the most powerful techniques for dimensionality reduction, and also one of the hardest to interpret appropriately <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b51">52]</ref>. As such, it is a natural target for DimReader. In addition, t-SNE is significantly different from Isomap and LLE in both formulation and implementation. This provides us with an opportunity to explore practical issues of using DimReader to explain its results.</p><p>We highlight two separate issues to discuss: the presence of multiple local minima, and its formulation in terms of the gradient of an energy function. While the first issue presents challenges for implementations that depend on repeated executions, the second issue allows us to achieve a significant speedup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple minima</head><p>The energy function that t-SNE minimizes has more than one local minimum. This means that any source of randomness in the implementation will cause multiple runs to possibly diverge, presenting a challenge for our approach. Most implementations of t-SNE require an initial guess for the projection, and we take central advantage of this. Specifically, in our first execution of t-SNE we use a random initial guess and regular floating-point numbers to calculate a local minimum that is then used as the initial guess for subsequent runs. In the initial run we also capture variables that serve as parameters for subsequent runs to ensure that they reach the same local minimum.</p><p>Gradient descent t-SNE is implemented as an explicit gradient descent formulation through an additive update of the parameters. Specifically, the main loop of t-SNE is roughly as follows: pos = initial_guess g = gradient(energy(pos), pos) while mag(g) &gt; epsilon: pos = pos -rate * g g = gradient(energy(pos), pos)</p><p>As a result, when the loop exits, we know that the gradient of the energy with respect to the position will be close to zero. This means that to recover any one perturbation of the t-SNE formulation with respect to an input point, all that is required is to run one single iteration of t-SNE with dual numbers. By providing the dual-number implementation the result of the execution of the floating-point implementation (as explained in the previous paragraph), the loop will execute at most once before exiting -in fact, in order for the sensitivity of the positions with respect to the input to be recorded in the pos variable, we must force the loop to execute at least once. Still, since t-SNE typically executes between 100 and 1000 iterations in this loop, this simple optimization achieves a significant speedup. t-SNE Experiments T-SNE is often considered to be the state of the art in NDR methods, but one of the main objections to its use in practice is the opaque nature of its optimization criteria <ref type="bibr" target="#b51">[52]</ref>. It is unclear how effectively the projection recovers high dimensional information. Consider the t-SNE axes in <ref type="figure">Figure 7</ref>. t-SNE is detecting variation in the petal length and petal width of the Virginica and Versicolor cluster and subsequently spreading the cluster based on these dimensions. This helps explain how petal length behaves in the projection, providing evidence that DimReader helps bridge the non-linear unmapping gap <ref type="bibr" target="#b41">[42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Discovering Perturbations</head><p>The implementation of the equations in 3.4 for discovering perturbations is straightforward as long as the machine has sufficient memory to hold the expanded laplacian matrix, L s . This matrix becomes very large for very high-dimensional data and thus requires significant memory. To solve this problem, we were again able to exploit the block structure of the tangent map as well as the structure of the Laplacian matrix: the diagonal values are ∑ j =i S i, j and the off diagonal values are −S i, j . We implemented a version of power iteration that does not require access to the matrix M T M − λ L s but instead requires a function that, when given a vector v, returns calculates elements of the output vector individually and thus does not require the entire L s matrix.</p><formula xml:id="formula_7">(M T M − λ L s )v. The multiplication function PCA t-SNE U X V</formula><p>Using this method, we uncovered perturbations for several datasets projected with t-SNE. In the following experiments, we use the method in Section 3.4.2 to find individual perturbations for each point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Iris</head><p>We first look at the best perturbation for the Iris dataset. <ref type="figure">Figure 8</ref> shows the DimReader plot for this perturbation as well as a plot for each dimension that shows how much that dimension was perturbed in each point through the color (the darker purple a point is, the more it was perturbed). The DimReader plot shows that the best perturbation only perturbs points in the Setosa (red) cluster. In the individual dimension plots, the Setosa cluster is perturbed primarily in the Sepal length and Sepal width dimensions which tells us that in this projection, points in the Setosa cluster are sensitive to changes in the Sepal dimensions. Comparing 8 to the t-SNE plots in <ref type="figure">Figure 7</ref>, the movement of the Setosa cluster with the discovered perturbation is similar to the movement when the sepal width or sepal length is perturbed. <ref type="figure">Figure 9</ref> (A) shows an sample of discovered perturbations in the projection. The perturbation images often resemble a variation of their corresponding digit or a nearby digit (due to the constraints defined in Section 3.4.2). These perturbations show us that t-SNE is capturing meaningful information about the dataset. In <ref type="figure">Figure 9 (A)</ref>, the perturbation that moves the "seven" the most turns the "seven" into a "two" and moves it toward the cluster of "two"s. Thus, DimReader, is showing evidence that t-SNE is capturing information about what constitutes a "two" and is using that information to separate out the two's into their own (imperfect) cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">MNIST Digits</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">MNIST Fashion</head><p>The MNIST Fashion dataset is similar to the digits dataset in that each point represents a 28 × 28 pixel image and there are 10 different classes of images (articles of clothing) but is more complicated than the digits dataset. A t-SNE plot with selected perturbations found by our technique is shown in <ref type="figure">Figure 9</ref> (B). Just as in the digits perturbations, there is structure in these perturbations. In the example in <ref type="figure">Figure 1</ref> (C), our technique is finding perturbations that capture information about how t-SNE is projecting the data. DimReadertells us, that for the heel in the middle, the perturbation that moves this point the most, changes it from a heel into a flat shoe. This also shows us that t-SNE understand the difference between flat shoes and heels and is able to separate them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Synthetic Examples</head><p>In this section we will look at the DimReader plot with two synthetic examples, the swiss roll and the interlocked rings, and compare them to the value heatmaps for each dimension from Stahnke et. al's Probing Projections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Swiss Roll</head><p>The swiss roll dataset is calculated from the equations x = u cos(u), y = u sin(u), z = v where 3π 2 ≤ u ≤ 9π 2 and 0 ≤ v ≤ 15. <ref type="figure" target="#fig_8">Figure 10</ref> shows perturbations of the U,V, and X dimensions.</p><p>PCA In the v dimension, the DimReader plot shows that increasing the v in the original data moves the projected points to the left. In comparison, the value heatmap for the v dimension is difficult to read due to the high variance in v between neighboring points. This highlights a fundamental difference between DimReader and value heatmaps: DimReader is showing what the projection is doing while value heatmaps show the values of a dimension based on the placement of points. If we created a projection that simply mapped each point to its PCA coordinates through a table lookup, the value heatmaps would not change whereas the DimReader plots would show nothing because changing any of the dimensions would not change the projection.</p><p>The DimReader plot for the u dimension shows that changing the u dimension would move the point along the spiral, from red to blue. The isolines, however, are irregular from green to orange. These irregularities could be due to the resolution of the grid or the regularization. One direction for future work is to automatically determine the appropriate grid resolution and regularization for a projection. t-SNE In the DimReader plot for t-SNE, the u dimension behaves exactly as we would expect, increasing as we move from red to blue. The spacing of the lines around the curve, specifically how the curves are wider on the outside than on the inside, indicates the bending does not reflect the underlying data but rather is caused by the projection.</p><p>In the DimReader plot for v, t-SNE has flipped the green and yellow segment (the points move to the bottom left rather than the upper right). This appears less clear from the value heatmap alone.</p><p>In the plots for x, the highest values in the heatmap do not match the area in the DimReader plot where the biggest change occurs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Interlocked Rings</head><p>The DimReader plots and value heatmaps generated for the interlocked rings dataset are shown in <ref type="figure" target="#fig_9">Figure 11</ref>.</p><p>PCA The PCA plots from DimReader show that changing X or Z would move the points upward and changing the Y dimension move points to the right. Again, the plots here highlight the difference between our technique and the value heatmaps: the heatmaps of x and z tell us that the x and z values are only changing over one ring each whereas our technique is showing that PCA will move the rings vertically if the x or z dimension is changed. DimReader shows what the projection does, whereas heatmaps shows where the values go.</p><p>t-SNE T-SNE has separated the two rings well. In the DimReader plot of the X dimension, the red ring will move from left to right when the X dimension is changed. Comparing the X dimension to the Y dimension, for the red ring, the two axes are nearly perpendicular to one another. This suggests that t-SNE is primarily using these two dimensions for projecting the red ring. Furthermore, in the red ring the X dimension changes much quicker than the Y dimension (the lines are closer together) which indicates that t-SNE is distorting the shape of the red ring. Similar observations can be made about the green ring with the Y and Z dimensions. Again, the Y and Z are nearly perpendicular in the green ring. In the Y dimension, the axes change their behavior when they reach the gap in the green ring. Points in this region move more slowly when changed which in turn tells us that this is likely a tear in the ring caused by t-SNE that does not reflect the structure of the underlying data. It is not as clear from the value heatmaps that the gap is a tear in the data caused by the projection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Known Perturbations</head><p>In this section, we report performance figures for the prototype implementation of DimReader. Although we were reasonably careful with algorithmic and high-level design decisions that impact performance, we did not make a significant effort to make DimReader fast. We expect carefully-implemented versions of our proposal in high-performance languages such as C++ or Java to be significantly faster, possibly by an order of magnitude (typically the performance difference between Python and aggressively optimized, compiled languages).</p><p>A table showcasing typical results is included in <ref type="figure" target="#fig_0">Figure 12</ref>. The performance of DimReader for a given NDR method is dependent on two main factors: the number of input points and the overhead incurred by dual numbers. We need to execute a number of repeated runs proportional to the base-2 logarithm of the number of input points, and that is essentially unavoidable. We note that for the case of LLE and t-SNE, the optimizations we described in the previous section make the execution of the dual-number version of the projection much faster than that of the regular numbers. As a result, DimReader can extract axes with a relatively small performance overhead.</p><p>For cases such as Isomap, on the other hand, where we performed no such optimizations, the performance of our method suffers a bit. We argue that this is an acceptable tradeoff: DimReader still works in an acceptable amount of time in the general case, but more careful implementations can be significantly more efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Discovering Perturbations</head><p>The most expensive part of searching for a perturbation is calculating the tangent map. The tangent map is n * d × n * d and requires d executions of DimReader to build it. For datasets with a large number of data points and dimensions, this quickly becomes slow. Once we have the matrix, the performance for finding the best perturbation largely depends on whether or not we can the expanded Laplacian matrix, L s , (described in Section 4.2) in memory. If we can't and have to use power iteration, the performance depends on the speed of our multiplication function as well as the amount of time it takes power iteration to converge. We did not make a significant effort to increase the performance for calculating the matrix or searching for perturbations; this remains for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>Can we trust DimReader plots? While we have shown that Dim-Reader can help determining how NDR plots can be trusted, a natural question to ask is: can the DimReader plots themselves be trusted? One natural scenario in which this comes up is when perturbation vectors of nearby projections disagree with one another. It's always possible to show the vectors themselves as a diagnostic of the quality of the reconstructed axis lines, but a proper, user-centric evaluation of the settings in which DimReader's axes are more informative than naked NDR plots is clearly necessary, and will be the subject of future work.</p><p>Inverse readings DimReader enables interpretation of forward transformations: given a perturbation of an input and a visualization, DimReader provides an answer. But a different natural reading is the inverse: given a projected point and a direction of movement in the projection, what changes in the data could generate such movement? In principle, the derivative information obtained by autodiff also captures this inverse relationship <ref type="bibr" target="#b9">[10]</ref>, but the fact that we are dealing with projections makes the problem fundamentally harder. A full investigation is beyond the scope of this work.</p><p>More algorithms, better infrastructure While DimReader shows that it is possible to adapt a large number of existing NDR methods to run within an autodiff framework, one goal is to provide DimReader axes to as much existing visualization infrastructure as practically possible. In such scenarios, reducing the implementation effort even further would be desirable. The majority of our difficulties porting algorithms to automatic differentiation arose due to difficulties in evaluating derivatives of linear-algebraic concepts, such as solutions of a linear system and eigenvectors. Some of these have explicit formulas <ref type="bibr" target="#b37">[38]</ref>, but incorporating them in an autodiff system effectively and efficiently is a fundamental challenge beyond the scope of our work. We note, in addition, that our choice of automatic differentiation is not strictly necessary. Other methods exist to evaluate function derivatives, including manual derivation of the expressions. When using DimReader with a specific NDR method, these alternatives might be more attractive. This might be particularly true whenever approximations of the derivative can be computed more efficiently than autodiff.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we identified infinitesimal perturbations as a tool to enable interpretation of NDR plots, and presented DimReader, a technique that produces generalized axes for studying such perturbations. While much work remains to be done, DimReader strikes a favorable balance between generality and power, highlighting strengths and weaknesses of a variety of NDR methods, and providing a novel perspective into what NDR methods are actually visualizing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>in sepal length" Transformation in original space: … induces transformation in scatterplot: "dot moves horizontally to the right" scatterplot lines of sepal length axis are perpendicular to movement t-SNE … induces transformation in t-SNE: "dot moves in a non-predictable way" lines of generalized sepal length axis are perpendicular to movement Dataset point in dataset In traditional scatterplots, the grid lines (or axes lines) exist to explain what the plot is showing. Equivalently, they capture infinitesimal perturbations of the dataset in specific directions, because they are always perpendicular to the directions of movement. DimReader extends the same principle to non-linear dimensionality reduction (NDR) methods, and recovers generalized axis lines, which help explain NDR methods in terms of interpretable data transformations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 7 specifically. In Section 4.3, we provide a more direct comparison to some of the methods used in Stahnke et al.'s work.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(A) Values of Perturbations on Corresponding Projected Point (B) Values of Perturbations on All Other Projected Points</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>(A)  shows the effect sizes of perturbing point p i on its corresponding projected point, v i . DimReader uses these values in its computations: note their large magnitude (values outside of the displayed range are clamped at -.5 and .5). (B) shows the effects sizes of perturbing point p i on all projected points aside from v i . DimReader assumes these values are zero and discards them: note their small magnitude.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>An illustration of the process to recover generalized axes. Given the point positions and perturbation vectors (a), we construct a triangular mesh and interpret each vector as a linear constraint on the gradient of a function (b), which gives values on each of the vertices (c). From these values, we can extract lines perpendicular to the perturbation vectors using marching squares.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>j S(i, j) takes form similar to a Laplacian matrix, L s multiplied by the entire perturbation vector v (the concatenation of all of the individual perturbations,v i ) on both sides: v T L sv . L s differs from a standard Laplacian matrix in that rather than having diagonal values ∑ j =i S(i, j) and off diagonal values −S(i, j), it has diagonal values I * ∑ j =i S(i, j) and off diagonal values I * −S(i, j) where I is d × d identity matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 10 .</head><label>10</label><figDesc>DimReader axes and value heatmaps for the u,v, and x dimensions of the swiss roll. A discussion of these plots is in Section 4.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 11 .</head><label>11</label><figDesc>DimReader axes and value heatmaps for the x, y, and z dimension of the interlocked rings. A discussion of these plots is in Section 4.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>Performance figures for the MNIST digits dataset and the S-Curve dataset, for progressively larger samples and three different NDR methods. All figures are reported in seconds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc># project uses autodiff dx, dy = projection.derivative[i]   projectionVectors[i] = vector(dx, dy) return projectionVectors # Improved method, O(log(numPoints)) runs counts = zero_array(numPoints) projectionVectors = zero_matrix(numPoints, 2) while any(counts &lt; 1): points = copy(inputPoints) for i in range(numPoints):</figDesc><table><row><cell>if random() &lt; 0.5: # perturb each point with probability 0.5</cell></row><row><cell>perturbed[i] = true</cell></row><row><cell>points[i] = perturb(inputPoints[i], perturbation)</cell></row><row><cell>projection = project(points) # project uses autodiff</cell></row><row><cell>for i in range(numPoints):</cell></row><row><cell>if perturbed[i]: # only store vectors of perturbed points</cell></row><row><cell>dx, dy = projection.derivative[i]</cell></row><row><cell>projectionVectors[i] += vector(dx, dy)</cell></row><row><cell>counts[i] += 1</cell></row><row><cell>for i in range(numPoints): # average all perturbations performed</cell></row><row><cell>projectionVectors[i] /= counts[i]</cell></row><row><cell>return projectionVectors</cell></row></table><note># Basic method, O(numPoints) runs for i in range(0, numPoints): points = copy(inputPoints) points[i] = perturb(points[i], perturbation) projection = project(points)</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We acknowledge fruitful discussions of dimensionality reduction with Sean Stephens, Luiz Gustavo Nonato, and Joshua Levine on the energy formulation of t-SNE. This work has been partially supported by the NSF under the TRIPODS program, award number CCF-1740858, and IIS-1513651.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mierle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Others</forename><surname>Ceres</surname></persName>
		</author>
		<ptr target="http://ceres-solver.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Interactive computer graphics: A top-down approach using OpenGL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Angel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visualizing distortions and recovering topology in continuous projection techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aupetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">7-9</biblScope>
			<biblScope unit="page" from="1304" to="1330" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Paraglide: Interactive parameter space partitioning for computer simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bergner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Abdolyousefi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1499" to="1512" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Modern multidimensional scaling: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Groenen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A principled way of assessing visualization literacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1963" to="1972" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Overview: The design, adoption, and analysis of a visual document mining tool for investigative journalists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2271" to="2280" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A multi-level typology of abstract visualization tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Visualization methodology for multidimensional scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Swayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Classification</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="43" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Carmo</surname></persName>
		</author>
		<title level="m">Differential geometry of surfaces. Differential Forms and Applications</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="77" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A visual interaction framework for dimensionality reduction based data exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cavallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ç</forename><surname>Demiralp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A linear iteration time layout algorithm for visualising highdimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chalmers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th conference on Visualization&apos;96</title>
		<meeting>the 7th conference on Visualization&apos;96</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page">127</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Flow-based scatterplots for sensitivity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology (VAST), 2010 IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The generalized sensitivity scatterplot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1768" to="1781" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The data context map: Fusing data and attributes into a unified display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="130" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Explaining three-dimensional dimensionality reduction plots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Coimbra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Telea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="172" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Detection of influential observation in linear regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="18" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Introduction to algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Cormen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Viscoder: A tool for visually comparing dimensionality reduction algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cutura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Holzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aupetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grimes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5591" to="5596" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Observation-level interaction with statistical models for visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>House</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology (VAST), 2011 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="121" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Vector field k-means: Clustering trajectories by fitting multiple vector fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Klosowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3pt2</biblScope>
			<biblScope unit="page" from="201" to="210" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A survey of dimension reduction techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">K</forename><surname>Fodor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Center for Applied Scientific Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>Lawrence Livermore National Laboratory</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Explainers: Expert explorations with crafted projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2042" to="2051" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Van Loan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matrix computations</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2012" />
			<publisher>JHU Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Evaluating derivatives: principles and techniques of algorithmic differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Griewank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Walther</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>SIAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Personal communication</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Glimmer: Multilevel mds on the gpu</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Olano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="261" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ipca: An interactive system for pca-based visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ziemkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="767" to="774" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Local affine multidimensional projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Joia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Coimbra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Cuminato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Nonato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2563" to="2571" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An algebraic process for visualization design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheidegger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2181" to="2190" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The need for verifiable visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Quality assessment of nonlinear dimensionality reduction based on k-ary neighborhoods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Challenges for Feature Selection in Data Mining and Knowledge Discovery</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="21" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Checkviz: Sanity check and topological clues for linear and non-linear mappings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lespinats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aupetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="113" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A hybrid layout algorithm for sub-quadratic multidimensional scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chalmers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2002. INFOVIS 2002. IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="152" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Least square projection: A fast high-precision multidimensional projection technique and its application to document mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Nonato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Minghim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Levkowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="564" to="575" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The matrix cookbook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Pedersen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
		<respStmt>
			<orgName>Technical University of Denmark</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Nonlinear dimensionality reduction by locally linear embedding. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Visual interaction with dimensionality reduction: A structured literature analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peltonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="241" to="250" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Div, grad, curl, and all that</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Schey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<pubPlace>Norton</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dimensionality reduction in the wild: Gaps and guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<idno>TR-2012-03</idno>
	</analytic>
	<monogr>
		<title level="j">Dept. Comput. Sci., Univ. British Columbia</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Empirical guidance on scatterplot and dimension reduction technique choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2634" to="2643" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stress maps: analysing local phenomena in dimensionality reduction based visualisations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sabol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kienreich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. symposium on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">An introduction to the conjugate gradient method without the agonizing pain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Shewchuk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon University. Department of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Probing projections: Interaction techniques for interpreting arrangements and errors of dimensionality reductions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stahnke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dörk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="629" to="638" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">A global geometric framework for nonlinear dimensionality reduction. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Multidimensional scaling of similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Torgerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="379" to="393" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">A Python implementation of t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<ptr target="https://lvdmaaten.github.io/tsne/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Making machine learning models interpretable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vellido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Martín-Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Lisboa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESANN</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="163" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The numpy array: a structure for efficient numerical computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Walt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Colbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="22" to="30" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">How to use t-sne effectively</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vigas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Johnson</surname></persName>
		</author>
		<ptr target="http://distill.pub/2016/misread-tsne" />
	</analytic>
	<monogr>
		<title level="j">Distill</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
