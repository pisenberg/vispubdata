<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays Hariharan Subramonyam, Student Member, IEEE, and Eytan Adar a Original bar chart with no annotations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August September October November December January February March</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>25</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>75 O</surname></persName>
						</author>
						<title level="a" type="main">SmartCues: A Multitouch Query Approach for Details-on-Demand through Dynamically Computed Overlays Hariharan Subramonyam, Student Member, IEEE, and Eytan Adar a Original bar chart with no annotations</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published">August September October November December January February March</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graphical overlays</term>
					<term>details-on-demand</term>
					<term>graph comprehension</term>
				</keywords>
			</textClass>
			<abstract>
				<p>On the edge of 1.5 o C Threshold : Which months are above the 1.5 o C threshold ? Greater/ Lesser: Which months have temperature higher than that of September? b c Diff : What is the di erence in temperature between February (Highest) and July (Lowest) ? d Diff (query expansion): What is the di erence in temperature between February (Highest) and August? e Diff (drill-down): What is the di erence in temperature between February (Highest) and March? f Rank : What is the rank of each month based on temperature, lowest to highest ? Rank (drill-down): What is the rank for July? g h Mean: What is the mean temperature across all months ? i +.0 o +.25 o +.5 o +.75 o +1.0 o +1.25 o +1.5 o +1.75 o</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The use of details-on-demand (DoD) in interactive visual exploration serves an important role for analysis. Unfortunately, many implemen- tations of DoD only provide a narrow set of details for a small set of demands (i.e., selection targets). Most conventional DoD implementations use dynamic tooltips that appear when the end-user hovers over a graphical mark. However, there are many situations in which it would be useful to expand both the 'breadth' and 'depth' of DoDs. For example, when comparing two bars, the end user may 'demand' the difference between the two encoded values. On a scatter plot, they may want the distribution between two intervals as detail. Such details are desirable because, as Wilkinson observed, "once coordinates are known and scales calculated, every measurement. . . is a simple affine transformation for a system that is capable of doing linear algebra in the head," but that this is, "obviously not human. . . " <ref type="bibr" target="#b69">[70]</ref>. DoDs can pro-vide accurate access to this information without increasing cognitive load. Critically, DoDs can be presented in a way that does not distract the end-user from analysis tasks by calling attention away from the focus area (e.g., selecting from menus, looking at other panels, etc.). To generalize this idea, we describe SmartCues, an interaction technique and library for dynamically computing and displaying DoDs. With increasing complexity, DoD displays become difficult to implement and use. 'Summoning' a DoD requires that (a) the end-user specifies their selection, that (b) they potentially indicate the type of detail they want (disambiguation), and (c) the detail be displayed appropriately. All three pieces are largely trivial in the case of simple DoD. The end-user hovers over, or clicks on, the shape; the detail information is constrained to a small set of facts (e.g., the value of the bar); and the presentation is a simple tooltip or dynamic annotation. Contrast this to even a slightly more complex task of identifying the mean value for two bars in a bar chart <ref type="figure">(Figure 1d</ref>). The viewer must now specify the targets which, if conventionally implemented, would require two clicks. Either the end-user or the system must identify the specific comparison the end-user is interested in or display them all (e.g., do they want the average? the difference? the rank difference?). Finally, the system must determine the best visual representation of this information (is it an annotation connecting the two bars with the value in between? is it a tooltip? is it another visualization? is it an overlaid bar?).</p><p>Our solution to this increasingly complex problem is SmartCues. For the end-user, SmartCues supports sophisticated selections and 'detail queries' through the (optional) use of multitouch gestures. Detail targets/selection can range from: single elements, such as a bar; global selections, such as all pie segments; and everything in between (e.g., two points or a range in scatter plot). For the developer, SmartCues addresses the complex process of DoD implementation by providing a clear way to build (i) interactions controls, (ii) detail models, and (iii) overlay views. SmartCues is intended to work across a wide array of visualization types, and we have created prototypes for each of the system components. SmartCues can be utilized for both analytic and communicative scenarios. Details are presented as data-aware annotations (e.g., text labels and arrows) <ref type="bibr" target="#b30">[31]</ref> and by using 'un-committed' retinal channels (e.g., color) or additional marks. Collectively, we refer to such displays as detail overlays. <ref type="figure">Figure 1</ref> provides an example of SmartCues. The original visualization (a), "On the edge of 1.5째C," shows the global monthly temperature anomalies in 2016 referenced to the 1881-1910 baseline <ref type="bibr" target="#b18">[19]</ref>. Certain perceptual tasks-such as determining which month was highest; determining which month was lower given a pair; or even reading the value for a specific month-are effectively enabled by this display. However, as with all visualizations, this one sacrifices both expressiveness and effectiveness for certain information <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b72">73]</ref>. Accurately calculating the difference between bars that are very far away is more difficult. SmartCues directly supports this by allowing the end-user to simultaneously tap the two bars (e.g., <ref type="figure">Figure 1d</ref>). This action will produce a graphical overlay with the information. SmartCues can be used to implement many other types of DoD interactions even on this simple visualization. For example, dragging a line from the y-axis ( <ref type="figure">Figure 1b)</ref> will indicate a request for a 'threshold detail' which displays a color overlay indicating bars exceeding the threshold. Horizontally dragging across multiple bars ( <ref type="figure">Figure 1i</ref>) displays an overlay for the mean. A diagonal drag <ref type="figure">(Figure 1g</ref>-h) produces a color overlay for rank. Each detail allows us to 'recover' some effectiveness through natural interactions and details display in a salient way. <ref type="figure">Figure 1c</ref> demonstrates a 'combined' SmartCues interaction that includes both selection and detail query. By clicking/tapping on a bar (the selection) and gesturing upwards, the end-user is requesting a comparison of all other months in relation to the selection (e.g., higher or lower). While we have created a set of SmartCues for various chart types, the developer/designer can ultimately decide which to enable, disable, modify, or add. Our prototype architecture is intended to support this extensibility.</p><p>SmartCues offers additional features to support DoD complexity. To handle many interactions that may become ambiguous in 'querying' for a detail, SmartCues both ranks likely detail targets as well as providing interaction methods to resolve ambiguity. SmartCues can also de-clutter displays that contain too many DoD overlays. Either due to multiple requests or ambiguity, visualizations can become cluttered with too many details, increasing cognitive load and perceptual tasks (e.g., due to label overlap, distracting arrows, etc.). SmartCues works to reduce this clutter by 'collapsing' multiple details into alternative views. For example, the end-user may ask for a comparison detail for temperature for February and July ( <ref type="figure">Figure 1d</ref>) by touching both bars. If they repeat this for February and August, SmartCues can anticipate that the intent is to compare February to all other months. Instead of showing two comparisons, SmartCues can create an overlay that 'pre-fetches' all relevant comparisons and integrates them in a more effective overlay as in <ref type="figure">Figure 1e</ref>. This process is achieved by considering query patterns in predicting future demand.</p><p>Our key contribution is introducing a framework by which developers and end-users can have access to complex DoD interactions. We provide a number of extensible implementations of interaction controls ('WIMP' and 'natural' gestures) and detail models (simple data lookups and statistical functions). By necessity, both interactive controls and overlays are chart dependent. We demonstrate SmartCues on bar charts, line charts, and scatter plots. From these implementations, we identify generalizable techniques and guidelines to adapt SmartCues to new charts. Through SmartCues, we introduce mechanisms for dealing with ambiguity and to 'compress' multiple overlays dynamically. We show with a lab-study that SmartCues interactions can be learned and enhance effectiveness for chart comprehension tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We situate our work in the context of graph comprehension and review current implementations of DoD in facilitating those tasks. We also describe existing annotation systems in the context of DoD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Details-on-Demand Interactions</head><p>Broadly, graph comprehension includes tasks ranging from simple value extraction and pattern detection tasks (i.e., visual queries), to intermediate tasks such as interpolation and finding relationships in data, and advanced extrapolation tasks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25]</ref>. Prior work has shown that decoding visual information can be complex and inaccurate <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b60">61]</ref>. The time taken to interpret a graph is proportional to the number of unique quantitative relations depicted in the graph <ref type="bibr" target="#b13">[14]</ref>. For certain tasks, accuracy decreases when the distance between two values being judged increases along the perpendicular axis <ref type="bibr" target="#b17">[18]</ref>. Furthermore, while visual structures are better at expressing relational information, tables perform better when tasks involve retrieval of specific values <ref type="bibr" target="#b19">[20]</ref>. DoD interactions, in general, address this problem by surfacing data from underlying tables in context of visualizations <ref type="bibr" target="#b58">[59]</ref>.</p><p>Current approaches to DoD can be broadly classified into two types: (1) selection based approaches (hover, single-and double-clicks) in which one or more visual objects (marks) are selected to retrieve attribute level details <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b61">62]</ref>, and (2) zoom based approaches in which entire visualizations undergo transformation to bring details into view <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27]</ref>. Segel and Heer <ref type="bibr" target="#b57">[58]</ref> analyzed a large number of narrative visualizations in which they find hover-style tooltips to be a common interaction pattern for DoD. Beyond tooltips, details are also presented using sophisticated HTML pop-ups with added interactivity <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, are displayed as table views <ref type="bibr" target="#b61">[62]</ref>, and even rendered using summary visualizations such as histograms <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b64">65]</ref>. With SmartCues, we have endeavored to build the same type of support for exploration but have focused on using overlays that do not require secondary windows or visualizations. Rather, SmartCues interactions overlay detail annotations directly onto the original chart.</p><p>Zoom-for-detail style interactions take a different approach by loading details dynamically as the end-user 'magnifies' the visualization's drawing surface. Examples include tap-and-hold interactions for scatter plots <ref type="bibr" target="#b12">[13]</ref>, ontology details in a radial visualization <ref type="bibr" target="#b26">[27]</ref>, and approaches that re-encode data (e.g., from aggregate to individual marks) during zoom interactions <ref type="bibr" target="#b23">[24]</ref>. The Magic-Lens system offers a (zoom) fo-cus+context by using a magnifying-glass 'lens' to modify the view under inspection with additional information <ref type="bibr" target="#b63">[64]</ref>.The challenge for zoom-based-interactions is that they require reconfiguring the display and require readers to perform perceptual realignment with the newly adjusted view, which can be costly <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b49">50]</ref>. In other words, the overall context of the visualization is lost, making it harder to perform subsequent tasks. Additionally, in many domains (e.g., stock price, sensor data), details, as applied to raw data points, are of little interest, and detail level tasks commonly refer to some analytic operation over a subset of raw data <ref type="bibr" target="#b36">[37]</ref>. In such cases, details are often presented as an annotation. For these reasons, we focus on 'in-context' details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Annotations</head><p>While not all annotations are details and not all details can be presented as annotations, the overlap is significant. In designing SmartCues interactions and overlays, we leverage existing work on annotation creation and annotation representation. Annotations boost the "natural perceptibility profile" of graphics <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b44">45]</ref>. Existing work on annotations include both systems <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref>, and techniques for placement and representation of annotations <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b16">17]</ref>. Work on placement and aesthetics of annotations (e.g., <ref type="bibr" target="#b0">[1]</ref>) have demonstrated that the placement of an annotation is most effective when they coincide with corresponding graphical properties (e.g., graph shape). This work informs our design.</p><p>The space of annotations can be broadly classified into three categories: (1) annotations for recording and communicating insights (to self or others), <ref type="bibr" target="#b1">(2)</ref> annotations that provide external context, and <ref type="formula">3</ref>annotations that aid graph comprehension (the category most related to SmartCues). Orthogonally, we can also classify annotations based on what they 'bind' to. The general form can include any notation on the chart (including 'scribbles,' per Wilkinson <ref type="bibr" target="#b69">[70]</ref>). The more specific variant is bound to data (Annotation Guides <ref type="bibr" target="#b69">[70]</ref> or Data-Aware Annotations <ref type="bibr" target="#b30">[31]</ref>). Systems such as Sense.us <ref type="bibr" target="#b31">[32]</ref> fall into the communicative-general category by offering free-form drawing and textual annotations in collaborative (communicative) settings. Contextifier <ref type="bibr" target="#b33">[34]</ref> is an external-specific system which automatically generates annotations that connect a temporal visualization (stock data) with a textual story (a news article). In this taxonomy, SmartCues annotations are in the comprehension-aid-specific category. SmartCues are connected to data and are intended to boost the effectiveness of visualizations.</p><p>Human-driven annotation creation systems such as Click2Annotate <ref type="bibr" target="#b15">[16]</ref> and ChartAccent <ref type="bibr" target="#b51">[52]</ref> motivate our design of selection and rendering. The designer's task of creating an annotation is similar to the end-users use of DoD (in that similar types of selection and rendering are needed). Click2Annotation takes a semi-automatic approach to instantiate textual "fact" templates (dimension oriented facts, data item-oriented facts, and compound facts) based on end-user selection <ref type="bibr" target="#b15">[16]</ref>. While the interaction metaphor is similar to our own, annotations are not overlaid on the graph and are meant for insight externalization and capture. Annotations become "guides" when they are driven by data <ref type="bibr" target="#b69">[70]</ref>, and the system that is closest to ours in annotation guides is <ref type="bibr" target="#b38">[39]</ref>. In Graphical Overlays, Kong and Agrawala present an automated approach to generating annotation guides (reference structures, highlights, numerical data labels, summary statistics, and descriptive text). When 'correct,' automated annotations <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b38">39]</ref> can be informative. However, they may also introduce clutter and noise. DoD approaches, such as ours, are inherently end-user driven in that the annotations are dynamically invoked based on end-user comprehension needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Direct Manipulation Querying Techniques</head><p>Direct manipulation (DM) techniques are a natural way of interacting with visual information <ref type="bibr" target="#b59">[60]</ref>. They minimize the distance between the intent and execution of the intent, particularly in a visualization context <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b41">42]</ref>. In SmartCues, we take a DM approach to constructing annotation queries. Sadana and Stasko present a set of interactions (selection, zoom, filters) to execute data-centric and view-driven tasks on scatterplots <ref type="bibr" target="#b53">[54]</ref>. TouchWave, a system closest to ours, demonstrates multi-touch interactions on stacked graphs to improve legibility and effectiveness of "comparison" tasks between different layers of the stacked graph <ref type="bibr" target="#b7">[8]</ref>. In contrast, TableLens fuses symbolic and graphical representations, allowing users to switch between visual patterns and textual details using various "flick" gestures <ref type="bibr" target="#b50">[51]</ref>.</p><p>Other work has focused on extending the capabilities of DM techniques <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33]</ref>, and at developing gestural frameworks for DM querying <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b70">71]</ref>. Heer et al. present a generalized selection technique that allows users to interactively expand query parameters through query relaxation <ref type="bibr" target="#b29">[30]</ref>. In SmartCues, we take a similar "query-by-example" approach to expand the scope of annotation queries. Additionally, for queries with a similar "signature," we take a mixed-initiative-like approach to allow readers to directly select the desired query operator when confidence in the correct detail is low <ref type="bibr" target="#b32">[33]</ref>. While our underlying framework is not restricted to touch gestures, our current implementation uses multi-touch gestures for DM. We are motivated by past work comparing traditional desktop interfaces and FLUID (touch) interfaces, which found that gestural interactions were better suited for problemsolving tasks focused on data <ref type="bibr" target="#b20">[21]</ref>. In designing SmartCues, we have incorporated work on eliciting natural gestures <ref type="bibr" target="#b70">[71]</ref> and data-aware gestural query specification <ref type="bibr" target="#b48">[49]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN CONSIDERATIONS</head><p>SmartCues is composed of three main components that correspond to end-user-facing interactions (interaction controls), internal detail model (functions that calculate what to display), and overlay views (what is displayed). For each, we define a set of guidelines that motivate our design of SmartCues and inform future additions.</p><p>Interaction Controls: While many of the interactions described in SmartCues can be implemented through mouse-driven interactions, these are not always the most effective. For the most narrow types of DoD (e.g., a single numerical lookup on a single target), a basic mouse hover may be sufficient to drive a tooltip display. However, with multiple selections and more complex detail options, a standard 'WIMP' display may not be effective <ref type="bibr" target="#b41">[42]</ref>. Gestural and multi-touch interfaces can support these more sophisticated DoD queries by allowing for multiple simultaneous selections and detail request with few motions. However, gestural interfaces benefit from a correspondence of the gesture to the associated action or selection <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b70">71]</ref>. That is, gestures should be as natural (D1) as possible. Because gestures are potentially ambiguous <ref type="bibr" target="#b56">[57]</ref> and can map to multiple possible detail requests, we prefer interactions that minimize (interaction) ambiguity (D2).</p><p>Detail Model: The use of gestures, as well as our desire to support a broad array of detail types, complicates the design of our internal detail model. While not all details need be as quickly accessible as mousehover based tooltips, ease and rapidity of access is often expected in modern interfaces. A very specific query 'language' may result in high precision, but may not be satisfactory in other dimensions such as learnability and cognitive load <ref type="bibr" target="#b28">[29]</ref> or access speed. The notion of fast access provides us with the guideline of reducing time-to-detail (D3). An alternative to a formal language, which we adopt, is to model the problem as a search task. A simpler, but more ambiguous, detail 'language' can provide the desired simplicity and speed. However, as with interactions, our goal is to minimize (detail) ambiguity (D4).</p><p>SmartCues was conceived to support access to a wide array of datadriven details (i.e., those that can be looked up from a table or determined through mathematical, logical or statistical operations on that data). For example, for a bar chart showing sugar quantities for cereal, an end-user may expect that clicking or hovering over the Cheerios bar will display a textual annotation with sugar amount. If the end-user clicks on both Chex and Cheerios simultaneously, they may reasonably expect that the annotation would be the difference in sugar amounts. SmartCues, does support a broader definition of details, but these may counter our naturalness guideline (D1). For example, clicking on Cheerios' sugar bar may display the amount of protein, and clicking on the two bars may display the difference between protein amounts. However, our belief that as these details deviate from what is expressed <ref type="bibr" target="#b46">[47]</ref>, they become hard for the end-user to anticipate. Put another way, we focus on DoD overlays that boost effectiveness, not expressiveness (D5). Though again, we emphasize that alternative DoD views are possible (e.g., a side panel rather than an overlay), and may be useful if end-users expect such details.</p><p>Overlay View: There are a variety of ways details can be produced for display. We restrict ourselves to forms that can be presented in the context of the original visualizations. Consistent with our guideline D3, we prefer for details to be presented rapidly without significant cognitive overhead. Presenting a secondary visualization (e.g., in another window) can increase this cost <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b68">69]</ref>. Other interactions (e.g., reconfiguration, transformation, filter, etc. <ref type="bibr" target="#b71">[72]</ref>) may similarly require a high cognitive overhead to process the new or adjusted view <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b49">50]</ref> Rather we adopt the techniques used by others to present details through data-driven annotations <ref type="bibr" target="#b30">[31]</ref> and graphical overlays. Both textual and graphical (e.g., trend lines) annotations can be produced by SmartCues. The specific implementation is visualization dependent (e.g., a difference between two pie segments or two bars is represented differently). This approach requires defining a way of presenting details that is uncluttered but with a clear connection to the selection (D6) and that does not collide with retinal variables (e.g., color) that are already dedicated to encoding values (D7). Finally, even though SmartCues ranks details by those most likely to be correct, mistakes need to be resolved. To deal with the inherent ambiguity of the 'query,' it is necessary to define mechanisms for displaying different details simultaneously or interactively resolving (display) ambiguity (D8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SMARTCUES ARCHITECTURE</head><p>Building on our design guidelines, here we describe each of the three main components of SmartCues ( <ref type="figure" target="#fig_0">Figure 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SmartCues Detail Model</head><p>Before describing the interaction model and graphical overlay, it is worth considering the internal details model of SmartCues. This representation will dictate both how the end-user will query for details and how the details will be displayed.</p><p>As shown in <ref type="figure" target="#fig_0">Figure 2c</ref>, data-bound to a two-dimensional graphcan be characterized by its dependent variable x, the independent variable y, and data entities (data rows) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b65">66]</ref>. Detail queries naturally correspond to these three components. Our analysis of existing DoD implementations and data-aware annotations showed that detail types can be mapped to Bertin's "reading levels <ref type="bibr" target="#b8">[9]</ref> as well as Ren et al.'s data item, set, and series categories <ref type="bibr" target="#b51">[52]</ref>. Elementary level details, such as value look-ups, correspond to a single data entity. Intermediate level details either map to a pair of data entities (e.g., relationship or comparison type details) or may be computed over a series of entities that are subset by independent and dependent variables (e.g., threshold, distribution, etc.). Global level details such as minima, maxima, or mean take all of the data entities into consideration. Therefore, at the lowest level, detail queries can be modeled as functions that take two arguments: data entities and variable values. Or more formally: </p><formula xml:id="formula_0">W hatIsDetail v (</formula><formula xml:id="formula_1">v , . . . , bar n v }, k)</formula><p>takes an additional parameter k and finds all entities whose value, v, is larger than k. Finally, WHATISMAX({bar 0 v , . . . , bar n v }) is a global question that produces the maximum v over all the bars in a bar chart. By specifying detail queries in terms of entities and variables, we also constraint that details be computed over what is already encoded (D5).</p><p>A key detail about our specification is that functions may not have a unique signature for any particular graph type. For example, WHATIS-THEMEDIAN, WHATISTHEMODE, WHATISTHEMEAN, can all operate on the same selection and will return the same value type. If the request were made through a programming interface, there would be no ambiguity as the function names are all different. Similarly, if the interface had an option for specifying which detail the end-user wanted (e.g., through a menu or drop down box), there would be no ambiguity. However, to satisfy our design guidelines-in particular D3 (reducing time-to-detail)-we provide access to our detail signatures through a 'fuzzy' search engine pattern. That is, details can be requested with underspecified 'queries.' For example, WHATIS*(bar i v ), will find all detail functions that take one selection as input. This simplifies the task of picking the right function but also introduces ambiguity.</p><p>SmartCues attempts to address this in a number of ways (to satisfy D4). By default, SmartCues allows end-users to choose from a list of detail functions that match the query signature ( <ref type="figure" target="#fig_1">Figure 3g</ref>). In addition, we use past selection, and history of detail queries to rank all the matching detail functions. For example, if a query matches prior query signature SmartCues automatically presents that detail based on utility. In other cases, the list is ranked by frequency. Additionally, as discussed in the next section, we can also reduce ambiguity by selecting a good query language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SmartCues Interaction Controls</head><p>Recall that for our end-users we would like to identify a set of natural interactions (D1) that are simultaneously low-ambiguity (D2) and help maintain fast access to details (D3). Complex menus or additional panels with faceted views can eliminate ambiguity but fail to satisfy our other two objectives.</p><p>Rather, we have opted to implement touch-based interactions <ref type="figure" target="#fig_0">(Figure 2a)</ref> as our 'query language' of choice. Our goal is to produce a set of interactions that can be translated into a query applied to the details database <ref type="figure" target="#fig_1">(Figure 3)</ref>. Ideally, such a language would support the selec- tion of the data entities, variables/parameters, and the detail function itself. A gesture-based technique can be effective for this purpose as it allows for direct interaction with the chart. The components that define our details model (data entities and variables) directly map to elements of graph composition <ref type="figure" target="#fig_0">(Figure 2b</ref>). Data entities are visually encoded as 'marks' on a two dimensional plane, while independent and dependent variables are represented as axes or legends. Collectively these form the interaction controls (widgets) for SmartCues and can be generalized across all chart types.</p><p>To guide the design of our gestures we utilized principles of natural scan paths and anchoring (or gaze fixation) from the graph comprehension literature <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b65">66]</ref>. According to the task anchoring framework <ref type="bibr" target="#b65">[66]</ref>, graph readers anchor on marks and axes values when extracting different classes of information. For example, to locate a point on a line graph, readers anchor on the x-axis value followed by projection onto the line. Relationship comparison involves pairwise entity anchoring. In SmartCues we align our gestures to analogous visual 'anchor' points. The single 'touch' (tap) gesture, the most basic of gestures, is used for selecting marks or axes anchor points <ref type="figure" target="#fig_1">(Figure 3ab)</ref>. This gesture alone covers a variety of DoD tasks across different reading levels. For example, touching on a single bar generates a query W hatIsDetail({bar i }). Similarly tapping on the y-axis value (k) on a bar chart generate a query W hatIsDetail({bar 0 v , . . . , bar n v }, k). By design, when the 'entities' parameter is not specified by gestures, the query defaults it to all marks on the chart. This both simplifies gesture selections and maintains that queries be data-aware.</p><p>To support tasks that involve pairs of marks or range of values, SmartCues also supports simultaneous multi-tap gestures <ref type="figure" target="#fig_1">(Figure 3c-d)</ref>.</p><p>Tapping on a pair of bars fires a query W hatIsDetail({bar i , bar j }). Similarly selecting two values on the y-axis generates the query W hatIsDetail({bar 0 v , . . . , bar n v }, y 1 , y 2 ). While it is desirable to limit gestures to single and multi-touch, to account for ambiguity, we extend gestures for certain DoD functions as well. Particularly for statistical DoDs such as mean and regression, the query involves all entities and no variables. A simple tap gesture anywhere on the plane would be highly ambiguous. For this reason, we also supports simple 'swipe'</p><p>gestures to reduce ambiguity of detail type <ref type="figure" target="#fig_1">(Figure 3e-f)</ref>. Prior work on gesture elicitation <ref type="bibr" target="#b70">[71]</ref> has shown that directional swipe gestures are favored when they correspond to graph semantics (e.g., diagonal downward gesture for downward trends). In SmartCues, directional swipe gestures closely align with visual features of the graph and its corresponding overlays. Tapping on the bar chart and sliding to the right, for example, represents the query for 'mean.' Similarly swiping diagonally upwards or downwards translates to ranking queries.</p><p>Directional swipe gestures may also be combined with anchor selection when appropriate. For example, tapping on a bar <ref type="figure" target="#fig_1">(Figure 3e</ref>) and then brushing upwards indicates a request for threshold information relative to the tapped-on-bar. The tap indicates the selection, which would ordinarily be interpreted as a request for details on that bar. However, the upward motion indicates that it is a threshold constraint.</p><p>In some situations, a single gesture is unnatural or may be overly complex. For example, we may want to compare the difference between bar i and all other bars in a bar chart. However, there may not be a single natural gesture for this (i.e., what should the end-user select and how should they move their hand?). A more natural solution is to repeatedly use the WHATISDIFFERENCE({bar i v , bar j v }) gesture (i.e., tapping on bars i, which is fixed, and j which is varied). This achieves the endusers goal but is inefficient. Instead, SmartCues is designed to observe the sequence of queries and infer a higher-level detail request that would 'encapsulate' repeated queries. <ref type="figure">Figure 1d</ref>-f illustrates this. After consecutive queries of the same sort , SmartCues will generalize the query from WHATISDIFFERENCE to WHATISDIFFERENCETOALL. A future extension may be to use generalized selection <ref type="bibr" target="#b29">[30]</ref> where repeated tapping or long press expands a selection or detail query.</p><p>We have developed a gestural query language consisting of simple tap and swipe gestures <ref type="figure" target="#fig_0">(Figure 2a</ref>). Because the design of our interactions correspond to anchoring strategies for graph comprehension, the tap gestures carry the same meaning regardless of the chart-type. This makes it easier to implement and use SmartCues on new chart types. However, the directional swipe gestures are chart specific. Notably, the same gesture may mean different things on different charts. For example, a diagonal move from the bottom-left to top-right on a bar chart is a request for rank ordering. The same gesture on a scatter plot is a request for a regression line. While the two share a gesture, the semantics in the context of a chart type is either apparent or can be easily learned. We validated, and modified, our initial gesture set based on feedback from an elicitation protocol (described in Sec. 6.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overlay Views</head><p>A final step in the SmartCues framework is determining the best way to present the details (if the gesture is the query, and details are the documents, then the overlay is the search engine result page). For simple queries (e.g., elementary DoDs) we might imagine placing textual annotations near the element the end-user tapped on (similarly to a hover tooltip). As long as the label was near the target or connected by an arrow or some other mark, Gestalt heuristics would lead to a correct association between detail and mark (proximity or connectedness). However, any details that involve more than one target or that have a complex 'return value' (e.g., parameters for a regression model) will most likely require different overlay that are specific to chart types. In SmartCues, we have implemented DoD rendering as data-aware overlays. This is consistent with the different grammar-of-graphics style formalism and allow us to layer multiple detail views in the same chart (note that overlays fade).</p><p>To inform the design of our overlays, we did a qualitative analysis of existing charts (98 collected from news and visualization sites) and annotation literature <ref type="bibr" target="#b51">[52]</ref>. For our analysis, we selected only those visualizations that annotated details about what is already encoded in the visualization. For each annotation, we decomposed (reverseengineered) it into the data-type of the detail that is annotated, and the function and visualization components that computed (or produced) the annotation. From this, we determined that there are three distinct 'types' of detail overlays <ref type="figure" target="#fig_0">(Figure 2d</ref>). The first, as discussed above, are textual annotations and cater to single-valued details. The second type are visually encoded annotations and are used to display multi-  valued details (e.g., all outliers on a scatter plot, all bars above the mean threshold, etc.). Here, textual annotations alone cannot effectively show the details. To make the information visually perceptible, they are often encoded as modifications to the original mark itself through unused retinal variables (changes in shape, color, etc.). For example, in <ref type="figure">Figure 1g</ref>, textually annotating the rank of each bar is not as effective (for some tasks) as using an overlaid gradient scale (encoding the rank). Labels and gradients can be used, when appropriate, to doubleencode the rank information. In this example, the overlay leverages the unbound color property of the marks to allow comparison of adjacent marks. It is possible that color or all other visual attributes are used up by the visualization. In such cases, alternatives include encoding the labels, placing additional glyphs, or interactivity. SmartCues overlays are intended to take into account what else is being displayed and how.</p><p>The third class of annotations, what we refer to as 'multi-layered annotations' refer to overlays that are connected at the data level. For example, a scatter plot that shows an annotation for moving average and also displays the difference between individual points and the average value. This is an example of static multi-layer overlay, but other examples use interactivity to reveal subsequent overlays (e.g., differently colored outliers on a scatter plot, whose values are retrieved through tooltips). To fulfill our design guideline D8, we encode complex multivalued details into higher level annotations, and allow end-users to interactively drill-down to individual details (e.g., <ref type="figure">Figure 1</ref> e-f).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">UTILIZING THE SMARTCUES LIBRARY</head><p>We implemented SmartCues as a reusable Web-based library. Our implementation offers a collection of detail models, interactions, and overlay views for a set of standard chart types (bar chart, scatter plot, and line chart). More critically, it is possible to adapt and extend this library for other chart types or additional DoDs. Here we briefly describe key implementation details. Complete documentation is available on our demo site at www.smartcues.info. <ref type="figure" target="#fig_2">Figure 4</ref> illustrates the key components of the SmartCues library. The detail models and overlay views are implemented within the core DoD generator library (d3.annotator.js) using D3 <ref type="bibr" target="#b9">[10]</ref>. The interaction controls are built as a standalone multi-touch library (d3.annotator.touches.js). This separation allows for extensibility for other interaction modalities. Execution flows as follows: The touch wrapper (a) captures a valid gesture and invokes the corresponding chart's query request builder by passing gesture attributes (data marks and variable values). The resulting request is (b) sent to the routing module of the DoD generator library. Based on the chart type, query specification, and a set of decision rules (multi-layer overlay, history, query generalization support, etc.), the routing module invokes the correct function within the (c) charting sub-module. The results of this function is passed on to the corresponding overlay, which finally renders the computed detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Touch Wrapper</head><p>In SmartCues, touch interactions are implemented using the hammer.js <ref type="bibr" target="#b55">[56]</ref> and gestrec <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b66">67]</ref> multi-touch libraries. Given a D3 chart (SVG), this module adds interaction controls to different chart components (marks, axes, plane). When a gesture is invoked, the query builder-a sub-module that handles all gesture events-translates gestures and targets into DoD queries. As shown in <ref type="figure" target="#fig_2">Figure 4a</ref>, each chart type implements its own interaction controls and query builder sub-modules. The library also offers configuration support in which consumers (endusers or developers) can enable/disable certain DoD queries based on domain context. While a visualization designer can choose to manually add gestures to a visualization, our module reduces the implementation cost from several hundred lines of code to around four lines. As an example, the code to implement all of the touch annotations for a standard (D3) bar chart is:</p><p>var barAnnotator = d3.annotator.touches('bar') .attr("label", &lt;x-axis property&gt;) .attr("value", &lt;y-axis property&gt;); &lt;chart-svg&gt;.call(barAnnotator);</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Core DoD Generator</head><p>This module handles all of the DoD computation, generation and rendering of overlay views. It consists of three main sub-modules: (1) the query router, (2) a history module, and (3) a collection of chart sub-modules, one per chart type. Each chart sub-module implements a collection of detail models and overlay generation logic. The detail models and overlay views are decoupled so that multiple detail models can invoke the same overlays. When a DoD overlay is requested, the query router performs a predicate match against all detail models for the chart. Additionally, the routing algorithm considers history data and also determines if the query extends an already rendered overlay (drill-down). If a single detail model is matched, the function is directly invoked. If there is a conflict, the router returns a set of potential DoD models which are presented to the end-user through a pop-up widget. The end user can choose which model to apply. Once the details are computed, the overlay module parses the underlying SVG structure to determine the placement and rendering of overlays.</p><p>Our library allows for customization of both the detail models and overlays. For detail models, developers can pass in custom functions as predicates, set overlays to manual or auto-clear modes, and configure all of the CSS-style attributes of the overlay including color, thickness, font-size etc. Further, they can extend SmartCues to new chart types by providing detail models and overlay views. Here our core library offers support with placement of overlays and routing gestures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Chart-Specific SmartCues</head><p>Our library implements annotations and gestures for commonly used chart types including bar charts, scatter plots, and line graphs. These can be used out-of-the-box. Here we describe scenarios to illustrate how SmartCues can support different graph comprehension tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Scenario 1:</head><p>On the edge of 1.5째C <ref type="figure">Figure 1</ref> compares temperature anomalies for the year 2016, drawing attention to the fact that some months are close to or have exceeded the 1.5째C warming threshold-agreed to by COP 21 negotiators in Paris (Climate Central <ref type="bibr" target="#b18">[19]</ref>). Starting with an unannotated visualization, the reader first queries for all months that exceeded the warming threshold by performing a 'tap' gesture at 1.5째label on the y-axis. In response, the core DoD generator renders a SmartCues at that threshold (a horizontal line parallel to the x-axis), and also highlights all bars NFL field-goal percentage for all kicks vs. average kick distance that exceeded that value, in this case February is highlighted <ref type="figure">(Fig 1b)</ref>. Next, the reader sees that the temperature increase is not linear with the current ordering of bars. She performs a diagonal swipe-up gesture to get the ranks of all bars <ref type="figure">(Figure 1g</ref>). The overlay color encodes each bar on a gradient scale. From here, the reader confirms that July has the lowest rise in temperature by tapping on the bar <ref type="figure">(Figure 1h)</ref>. Further, the reader wishes to compare the highest and lowest months. She brings up the 'diff' overlay by simultaneously placing two fingers on February and July. This query renders the horse-shoe like overlay connecting the two bars <ref type="figure">(Figure 1d</ref>). Using our query-by-example interaction, she queries for the difference between February and all other months <ref type="figure">(Figure 1e</ref>). This tells her that there is only a marginal difference between February and March <ref type="figure">(Figure 1f</ref>). Finally, she queries for the mean temperature rise by performing a horizontal swipe gesture across all bars <ref type="figure">(Figure 1i)</ref>. The corresponding annotation also shows that six of the twelve months are above the mean value of 1.25. In this manner, the reader is able to explore several facts about this chart, quickly and accurately, using SmartCues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Scenario 2: NFL Field-goal vs. kick distance</head><p>In this visualization, data about field goal percentage is plotted against attempted kick distance for the past fourteen NFL seasons, on a scatter plot (FiveThirtyEight <ref type="bibr" target="#b47">[48]</ref>). Here, the reader is interested in comparing kick distances against goal percentage. She first spots that 2013 has the highest field goal percentage. As shown in <ref type="figure" target="#fig_3">Figure 5a</ref>, she 'taps' on the point to see the exact kick distance and field goal percentage.</p><p>She then uses multi-touch gestures to get the difference between 2013</p><p>and 2008 which has the second highest goal percentage <ref type="figure" target="#fig_3">(Figure 5b)</ref>. The resulting DoD consists of a line connector between 2008 and 2013 and a label showing the x and y values. Lastly, in this chart there is no apparent spatial ordering of points which makes it difficult for her to compare changes between consecutive years. To solve this perceptual issue, the reader performs a zig-zag swipe gesture to bring up a line annotation that connects all years in a sequential order, and then taps on a line segment connecting two years to know the change between the those years ( <ref type="figure" target="#fig_3">Figure 5c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Scenario 3: Historic Snowfall in New York</head><p>In this third scenario, historic snowfall data for the month of March is plotted on a scatter plot for the city of New York (FiveThirtyEight <ref type="bibr" target="#b22">[23]</ref>). Unlike the previous scatter plot in which we examined the relationship between different data points on the plot, in this scenario we look at 'distribution' of points at different levels of snowfall. Starting with an unannotated chart, the reader first wishes to know how many years saw a snowfall above 20 inches. She does this by 'touching' on the the y-axis values 20 and 40 (the highest on the scale). This renders a DoD overlay that contains that range along with a label showing the exact count <ref type="figure" target="#fig_3">(Figure 5d</ref>). Next she wishes to retrieve summary statistics across all observations. To do this, she performs a horizontal swipe gesture across the chart. The resulting overlay displays median and IQR for the chart along with outliers encoded in a different color <ref type="figure" target="#fig_3">(Figure 5e</ref>). Lastly, she can examine the relationship between year and amount of snowfall using linear regression. Here she performs a diagonal swipe gesture which overlays the scatter plot with regression line. Further, she can then predict snowfall for any year by tapping on that year on the x-axis <ref type="figure" target="#fig_3">(Figure 5f</ref>). This gesture renders a label with the predicted value from the regression equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">Scenario 4: High school graduates enrolled in college</head><p>In this last example, we demonstrate DoDs for a line chart showing percentage of high school graduates enrolled in college across different years (FiveThirtyEight <ref type="bibr" target="#b14">[15]</ref>). Here the reader, who is aware of the 2008 recession, is curious to know the rise in college enrollment compared to previous year (i.e., 2007). To do this, she simultaneously taps on the two x-axis value. The resulting overlay consists of perpendicular lines from the x-axis which intersect at the corresponding points on the line chart, and also a label showing the actual change between the two years ( <ref type="figure" target="#fig_3">Figure 5g</ref>). Next she wishes to know the same detail for 1996-1997. In response, SmartCues infers query expansion, and generates change overlays across consecutive years <ref type="figure" target="#fig_3">(Figure 5h</ref>). The overlays are color coded to show rise or fall in enrollment, with darker gradients for steeper changes. The reader 'taps' on the overlay at 1996-1997 to see the actual change data. Finally, she wants to know in which years the enrollment rates were greater than 65 percent? She taps on the label for 65% along the y-axis which generates a threshold overlay, highlighting years above that value <ref type="figure" target="#fig_3">(Figure 5i</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>To evaluate SmartCues, we implemented our library on standard chart types including bar chart, scatter plot, and line graph. From an initial pilot we found that because annotations were always 'right' (in that they simply reflected the data), correct recall of the gesture was predictive of successfully completing the task. Hence, we focus on two questions:</p><p>(1) Can end-users easily learn the direct manipulation gestures for different chart types? and (2) Are they able to invoke the right set of annotations to answer chart comprehension tasks?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Procedure</head><p>We conducted our study with 19 participants, a majority of whom were graduate students, and had prior experience working with charts. Twelve participants reported that they engaged with visualizations in the week prior to the study, and six within the past month. Each session lasted 45-60 minutes and participants were paid $15 for their time.</p><p>The study was conducted in a lab setting using one of two full-HD multi-touch devices (HP's Sprout, and Microsoft's Surface Book).</p><p>After completing a pre-test questionnaire, participants received a guided tutorial of the system using a simple, artificial dataset about students. The study coordinator first explained the interaction controls available for each chart type and demonstrated each gesture. Participants were required to practice this gesture on a different machine and successfully complete a set of practice questions. All tasks-training and test-required that the participants interactively query for different annotations similar to the ones illustrated in <ref type="figure" target="#fig_3">Figures 1 and 5</ref>.</p><p>For bar charts, we used a Coffee Sales dataset consisting of sales data for 20 states across the US (also binned into Central, West, East, and South). Example tasks include: "How many states sold more than 40,000 units of coffee?" and "What is the difference in sales between West and all other regions?" For scatter plots, we used an emotion classification dataset (for distribution-related tasks), and a Cricket Chirp-Temperature dataset (for comparison tasks). The speech Emotion Classification consisted of 132 observations plotted by time vs. predicted excitation. The Cricket dataset included 14 observations plotting chirps made at different temperatures. Scatter plot questions included: "At what time interval was the speaker most excited?" and "What is the difference in number of chirps between 57째and 64째?" For line graph tasks, we used another Sales dataset plotting percentage profit across all months (12 data points). Tasks for line graph included: "For the month with the highest drop in profit, by what percentage did the profit decrease from previous month?" The tasks were distributed such that we covered all detail models across chart types, and consisted of ten tasks for bar charts, five for scatter plots, and five for line graphs.</p><p>We used more tasks for bar charts to test the large number of DoD features implemented in SmartCues for that chart type.</p><p>In addition to the actual responses for each task (collected on paper), we logged the gestures they performed using SmartCues. Finally, all participants filled out a post-test usability questionnaire to report their experience with SmartCues, and provide any open-ended feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Gesture Elicitation</head><p>In addition to evaluating SmartCues broadly, we also tested our gesture choices (to validate our naturalness criteria, D1). The pre-test questionnaire had participants come up with their own gestures for a set of chart comprehension tasks (mean, rank, difference, etc.). Participants were given paper forms in which each task was accompanied by an outline of the corresponding chart type. We first briefed them about different chart components (i.e., marks, axes, and plane). They were then asked to imagine multi-touch interactions for those tasks, and represent them on the chart outline by drawing circles for touch-points, and arrows to indicate motion. As an example, we showed them how they could find the mean on a bar chart by tapping on the left end (circle) of the chart, and by swiping right (right-pointing-arrow from circle). The results from the post-test questionnaire, and our analysis of the pre-test responses, showed that the gestures implemented in SmartCues are identical (16%), or similar (79%), to how participants envisioned them to be. We determined similarity qualitatively based on gesture targets (marks, axes values, and plane) and also type of gesture uses (tap vs. swipe). Gestures were considered different if they corresponded to different interaction controls, and similar if the targets were same as ours but type or direction of gestures were different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head><p>To measure performance, we analyzed the logs for the set of (timestamped) gestures performed. We awarded credit for the correct gesture usage, and for any alternate gestures that produced the same result. For example, in Task 11: "How may observations have a predicted excitation above 70% ?", participants opted for repeating the y-interval gesture three times (70-80, 80-90, 90-100) on the scatter plot, instead of directly invoking the y-range query. This may be due to the fact that selecting range was harder (size of touch target) when compared to pointing at intervals. As shown in <ref type="figure" target="#fig_4">Fig 6</ref>, a majority of participants were able to invoke the correct gestures within a reasonable amount of time. The average time across all tasks and participants was 20.31 seconds (sd=12.12 seconds). For Task 9: "How many products have higher sales when compared to Chamomile?" several participants failed to invoke the 'swipe-up' gesture on the bar of a bar chart. One explanation for this could be that the gesture has the constraint selection (the bar's value) encoded within the gesture itself, which may make it less intuitive. An alternative may be to first tap on the bar and then swipe. For Task 14, which was a multi-layer annotation interaction, the captured data was noisy because they were triggered on top of overlay.</p><p>On a 7-point Likert-type scale (1-strongly disagree to 7-strongly agree), participants rated system along the following attributes: ease-ofuse (쨉=5.57, sd=0.76), learnability (쨉=5.63, sd=1.11), intuitiveness of task-gesture mapping (쨉=5.84, sd=1.14), and ease of understanding the annotations (쨉=6.31, sd=0.74). In providing general feedback about SmartCues, a participant mentioned "[I like]the fact that I could play with the graphs to get information really fast and that I could easily switch contexts for multiple insights. . . ," and "[I like] the simplicity of system and speed of getting results." One participant requested support for more complex statistical functions, and a few others expressed the need for better gesture recognition for small touch targets ("In a scatter plot, I noticed the labels were quite close to each other. So I guess unintentionally, a person may press some other label"). Lastly we also observed that few participants did not engage both hands while interacting with the system, as one participant expressed "its hard to hold onto 2 distant bars to get the difference between them." We plan to incorporate this feedback in our future iterations through autocomplete-like cues for gestures, and also to look at improving multi-touch affordances of different visualizations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION 7.1 Assumptions and Limitations</head><p>Our implementation of SmartCues formulates DoD as a search process. As with any search logic, the more 'complete' the query, the more precise, and unambiguous the response. In our implementation we favor simple touch and swipe gestures that align with visual anchoring processes that are natural to graph comprehension (D1). We tradeoff ambiguity (D3) and time-to-detail (D3) for simplicity. While a more complex gestural language may reduce ambiguity, it will likely increase learning cost and may not generalize as well across chart types. We found that ambiguity is low for single and multi-target details as the visual encodings afford specific comparisons and selection targets. However, global-level queries, which do not target specific on-screen marks can lead to ambiguity. Our architecture supports extensions including probabilistic approaches to ambiguity resolutions <ref type="bibr" target="#b56">[57]</ref>, or alternate query modalities such as natural language (e.g. <ref type="bibr" target="#b25">[26]</ref>). As with with any gesture based system, learnability and discoverability pose limitations to SmartCues query language. While the results from our study showed that readers were able to invoke the right gestures post-training, in-the-wild deployment will require additional scaffolding. Specifically, learnability requires that (1) readers develop cognitive mapping between gestures and actions, and (2) are able to perform the gestures with ease <ref type="bibr" target="#b6">[7]</ref>. Our gestures are limited to simple touch and swipe, but developing gesture-query mapping can be a challenge. Our design of overlays which closely correspond to gesture targets (D6) could help in establishing such mappings. A possible solution is to use interactive hints (e.g., <ref type="bibr" target="#b37">[38]</ref>) and display available gesture icons similar to <ref type="bibr" target="#b2">[3]</ref> in order to improve discoverability. Lastly, our current implementation focuses on overlays that yield an effectiveness boost (D5). We do not directly consider how our design plays with visual transformations or other communication-type annotations. However, because our annotations are data-driven, we believe the library can be extended to handle visual transformations and collision with other annotation types. We plan to explore these options in future iterations. By making our library available, we hope to gain additional insights on real-world deployment and use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Guidelines for Extending SmartCues</head><p>In addition to the general design considerations for SmartCues, here were offer guidelines for extension to novel chart types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Scope of DoD Queries</head><p>Not all SmartCues detail types or gestures need to be enabled for any specific chart or system. Visualizations are selected such that that they convey a specific set of insights to readers (comparison, distribution, relationship, composition, etc). Broadly, those insights define the scope for SmartCues. From the reader's perspective, a simplified view of graph comprehension process is that it consists of insight acquisitionsthe extraction of expressed facts from the visualization. While typically a 'visual querying' process, not all insights can be extracted accurately and quickly by the reader (i.e., effectiveness criteria). When selecting detail models, visualization designers should prioritize those details that have low degree of effectiveness. For example, a 'rank' query in an already sorted bar chart may not boost effectiveness. Further, use of SmartCues can lower transformation cost from sort and filter type transformations. Designers should prioritize details that reduce transformation cost. For example, using distribution details overlaid on scatter plots may avoids chart transformation to histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">Specification of Detail Models</head><p>When defining parameters for detail models, only those parameters that need to be specified by the reader should be included. To allow for simple gestures, other parameters should be assigned a default value. This minimizes time-to-detail without requiring complex queries. For global level queries, detail specifications should be aligned such that the gestures closely comply with all conflicting details (e.g., horizontal swipe gesture for mean, median, and mode). For domain specific visualizations, details can include specific computation that are also visually calculable. For example, a scatter plot of height vs. weight can return the BMI in addition to the specific height, weight values. When detail models align with tasks that a visualization affords, it becomes more intuitive for end users to query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.3">Integration with other gesture operations</head><p>One application for SmartCues is to promote reader engagement with otherwise static visualizations through 'active reading' <ref type="bibr" target="#b67">[68]</ref>. However, visualization systems commonly require added interactivity such as filtering, brushing and linking, and other view transformation. When such interactions are also implemented using touch gestures (e.g., <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b54">55]</ref>) they may collide with SmartCues's query language. One recommendation is to implement SmartCues interactions in a special mode that can be controlled by the reader. This is desirable as SmartCues interactions and overlays are designed to avoid context switches such as view transformations. A second alternative is to explore analogous gestures such as long press instead of tap, pan-start and end instead of two-finger touch, and other naturalistic behavior such as 'clutching <ref type="bibr" target="#b54">[55]</ref>' the corner of the tablet device to distinguish other gestures from SmartCues queries. A third option, is to further integrate the existing gestures into SmartCues by using our widget menu to handle conflicts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>Visualizations cannot support all information tasks equally well, partly due to the perceptual and cognitive limitations of the human reader. SmartCues is our solution to boost the effectiveness of visual inferential tasks by making explicit what is 'hinted' at in the visual encoding. SmartCues are queried using simple touch gestures that closely align with visual scanning processes, and are presented in situ to provide quick access to a variety of insights. We demonstrate the approach through a lab study and illustrate how detail models, interaction, and overlays can be added to other chart types. By supporting both broader and deeper notion details, SmartCues provide a new way to satisfy the final step of the mantra: "overview first, zoom and filter, then details on demand" <ref type="bibr" target="#b58">[59]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Overview of SmartCues architecture. (a) Multi-touch gestures allow direct-manipulation interactions with (b) chart controls. (c) Interactions correspond to detail model selection and detail computation. (d) Results (details) are rendered as overlay views.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Gestures and corresponding query expressions for a bar chart.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Overview of the SmartCues library: (a) The touch wrapper binds gestures to charts, and generates detail queries. (b) Core DoD generator module routes the query to the right detail model and (c) charting submodules executes the queries and generate DoD overlays.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Example SmartCues showing both interaction controls and overlay views for different chart types. These, and other interactive examples can be accessed from our demo site at www.smartcues.info. Note that the original charts are greyed out for clarity of overlays.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Results from log data: (Top) Total number of participants who used the correct gestures for each task [n = 19]. (Bottom): Time taken for each task across all participants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>{Entities}, {Variables} * ). Because SmartCues details are 'data-aware,' the entities argument is required, but variables are optional. The return value of DoD functions are varied. They can range from ordinal (e.g., what is the rank?) to boolean masks (e.g., which bars are larger than 5?) to vectors (e.g., what is the linear correlation?). This formalization allows us to express detail queries across all reading levels. For example, WHATISBARVALUE({bar i v }) is an elementary question that retrieves the value, v, for entity corresponding to bar i in a bar chart. The question WHATISDIFFERENCE({bar i v , bar j v }) is an intermediate question that determines the numerical difference between the values encoded by two bars, i and j. The threshold query WHICHISLARGER({bar 0</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Touch Wrapper (d3.annotator.touches.js)</figDesc><table><row><cell></cell><cell>Bar Chart</cell><cell>Chart</cell></row><row><cell></cell><cell>Input Controls</cell><cell></cell></row><row><cell>Chart</cell><cell>Query Builder</cell><cell></cell></row><row><cell></cell><cell cols="2">Core DoD Generator (d3.annotator.js)</cell></row><row><cell></cell><cell>Query Router</cell><cell>History Module</cell></row><row><cell>Data Data</cell><cell>Bar Chart</cell><cell>Chart</cell></row><row><cell></cell><cell>Detail Models</cell><cell></cell></row><row><cell></cell><cell>Overlay</cell><cell></cell></row><row><cell></cell><cell>Generator</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was partially supported by the NSF under grant IIS-1421438. We thank the anonymous reviewers and our study participants for their time and helpful feedback. We also thank Licia He, Matthew Kay, Sile O'Modhrain, and Arjun Srinivasan for their advice and input.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Points, lines and arrows in statistical graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Acart체rk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theory and Application of Diagrams</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="95" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multimodal comprehension of graphics with textual annotations: The role of graphical means relating annotations and graph lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Acarturk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Habel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cagiltay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theory and Application of Diagrams</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="335" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards learnable gestures for exploring hierarchical information spaces at a large public display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ackad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomitsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI14 Workshop on Gesture-based Interaction Design</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page">57</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spotfire: an information exploration environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ahlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGMOD Record</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="25" to="29" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ivee: An information visualization and exploration environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ahlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wistrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Low-level components of analytic activity in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2005. INFOVIS 2005. IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="111" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning and performance with gesture guides</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">F</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1109" to="1118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Touchwave: kinetic multi-touch manipulation for hierarchical stacked graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM international conference on Interactive tabletops and surfaces</title>
		<meeting>the 2012 ACM international conference on Interactive tabletops and surfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Semiology of graphics: diagrams, networks, maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bertin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>University of Wisconsin press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">D 3 data-driven documents. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A multi-level typology of abstract visualization tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Design study: Using multiple coordinated views to analyze geo-referenced high-dimensional datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Brodbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Girardin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coordinated and Multiple Views in Exploratory Visualization</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="104" to="111" />
		</imprint>
	</monogr>
	<note>Proceedings. International Conference on</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">User interaction with scatterplots on small screens-a comparative evaluation of geometric-semantic zoom and fisheye distortion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Buering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gerken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Reiterer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="829" to="836" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A model of the perceptual and conceptual processes in graph comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Applied</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">75</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">More high school grads decide college isnt worth it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Casselman</surname></persName>
		</author>
		<ptr target="http://53eig.ht/1tyXZd1" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Click2annotate: Automated insight externalization with rich semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barlowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology (VAST), 2010 IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="155" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An empirical study of algorithms for point-feature label placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="232" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graphical perception: Theory, experimentation, and application to the development of graphical methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical association</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">387</biblScope>
			<biblScope unit="page" from="531" to="554" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Flirting with the 1.5  c threshold</title>
		<ptr target="http://www.climatecentral.org/news/world-flirts-with-1.5C-threshold-20260" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Climate Central</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graphs and tables: a four-factor experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Thakur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="76" to="87" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Touchviz: a case study comparing two interfaces for data analytics on tablets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Herron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2301" to="2310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Communicative signals as the key to automated understanding of simple bar charts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Elzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carberry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Demir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theory and Application of Diagrams</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="25" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">New york and philadelphia are in the middle of historically snowy months</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Enten</surname></persName>
		</author>
		<ptr target="http://53eig.ht/1Ey6k2L" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Clockmap: Enhancing circular treemaps with temporal glyphs for time-series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mansmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EuroVis Short Papers, Eurographics</title>
		<meeting>EuroVis Short Papers, Eurographics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="97" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Making sense of graphs: Critical factors influencing comprehension and instructional implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Friel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Curcio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Bright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal for Research in mathematics Education</title>
		<imprint>
			<biblScope unit="page" from="124" to="158" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Datatone: Managing ambiguity in natural language interfaces for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp;#38; Technology, UIST &apos;15</title>
		<meeting>the 28th Annual ACM Symposium on User Interface Software &amp;#38; Technology, UIST &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semantic zoom: A details on demand visualisation technique for modelling owl ontologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Theron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Highlights in Practical Applications of Agents and Multiagent Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="85" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Eye tracking for visualization evaluation: Reading values on linear versus radial graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Helfman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information visualization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="182" to="195" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Usability analysis of visual programming environments: A cognitive dimensions framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Petre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages &amp; Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="174" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generalized selection via interactive query relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="959" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Interactive dynamics for visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="45" to="54" />
			<date type="published" when="2012-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Voyagers and voyeurs: supporting asynchronous collaborative information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Vi챕gas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1029" to="1038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Principles of mixed-initiative user interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Contextifier: Automatic generation of annotated stock visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<biblScope unit="page" from="2707" to="2716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A deeper understanding of sequence in narrative visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2406" to="2415" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kandogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology (VAST), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Challenges in visual data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mansmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2006. IV 2006. Tenth International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dimpvis: Exploring time-varying information visualizations by direct manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kondo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2003" to="2012" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Graphical overlays: Using layered elements to aid chart reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2631" to="2638" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Understanding charts and graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="185" to="225" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A framework of interaction costs in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1149" to="1156" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Beyond mouse and keyboard: Expanding design considerations for information visualization interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2689" to="2698" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Protractor: a fast and accurate gesture recognizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2169" to="2172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A cognitive model for understanding graphical perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Lohse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="353" to="388" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Cueing complex animations: Does direction of attention foster learning processes? Learning and Instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Boucheix</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="650" to="663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Interac-tion+: Interaction enhancement for web-based visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Visualization Symposium (PacificVis</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Automating the design of graphical presentations of relational information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Transactions On Graphics (Tog)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="141" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">The haters are losing the war on kickers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Morris</surname></persName>
		</author>
		<ptr target="http://53eig.ht/1PbD1rX" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mandel</surname></persName>
		</author>
		<title level="m">Gestural query specification. Proceedings of the VLDB Endowment</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="289" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">A theory of graph comprehension. Artificial intelligence and the future of testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pinker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="73" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The table lens: merging graphical and symbolic representations in an interactive focus+ context visualization for tabular information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="318" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Chartaccent: Annotation for data-driven storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hllerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Pacific Visualization Symposium (PacificVis)</title>
		<imprint>
			<date type="published" when="2017-04" />
			<biblScope unit="page" from="230" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Kinetica: naturalistic multi-touch data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Rzeszotarski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kittur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd annual ACM conference on Human factors in computing systems</title>
		<meeting>the 32nd annual ACM conference on Human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="897" to="906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Designing and implementing an interactive scatterplot visualization for a tablet computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 International Working Conference on Advanced Visual Interfaces</title>
		<meeting>the 2014 International Working Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="265" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Expanding selection for information visualization systems on tablet devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM on Interactive Surfaces and Spaces</title>
		<meeting>the 2016 ACM on Interactive Surfaces and Spaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Thoburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tangelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hammer</surname></persName>
		</author>
		<ptr target="http://hammerjs.github.io" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Monte carlo methods for managing interactive state, action and feedback under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mankoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual ACM symposium on User interface software and technology</title>
		<meeting>the 24th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="235" to="244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Narrative visualization: Telling stories with data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1139" to="1148" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings., IEEE Symposium on</title>
		<meeting>IEEE Symposium on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
	<note>Visual Languages</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Direct manipulation for comprehensible, predictable and controllable user interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd international conference on Intelligent user interfaces</title>
		<meeting>the 2nd international conference on Intelligent user interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="33" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">An information-processing analysis of graph perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Simkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">398</biblScope>
			<biblScope unit="page" from="454" to="465" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Dust &amp; magnet: multivariate information visualization using a magnet metaphor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Soo</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Melton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information visualization</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="239" to="256" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">User-adaptive information visualization: using eye gaze data to infer visualization tasks and user cognitive abilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steichen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Conati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 international conference on Intelligent user interfaces</title>
		<meeting>the 2013 international conference on Intelligent user interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="317" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The movable filter as a user interface tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Bier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="306" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tableau</surname></persName>
		</author>
		<ptr target="https://vizable.tableau.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Processing of graphical information: A decomposition taxonomy to match data extraction tasks and graphical representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Benbasat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="416" to="439" />
		</imprint>
	</monogr>
	<note>Information Systems Research</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">UW Interactive Data Lab</title>
		<ptr target="https://github.com/uwdata/gestrec" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Active reading of visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Perin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pusch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="770" to="780" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Guidelines for using multiple views in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Q</forename><surname>Wang Baldonado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Woodruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuchinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Working Conference on Advanced Visual Interfaces, AVI &apos;00</title>
		<meeting>the Working Conference on Advanced Visual Interfaces, AVI &apos;00<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">The grammar of graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Eliciting multi-touch selection gestures for interactive data graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Willett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Short-Paper Proceedings of the European Conference on Visualization (EuroVis). Eurographics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Toward a deeper understanding of the role of interaction in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1224" to="1231" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Measuring effective data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Visual Computing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="652" to="661" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
