<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Reasoning Strategies for Effect Size Judgments and Decisions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kale</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kay</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Hullman</surname></persName>
						</author>
						<title level="a" type="main">Visual Reasoning Strategies for Effect Size Judgments and Decisions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Uncertainty visualization</term>
					<term>graphical perception</term>
					<term>data cognition</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Uncertainty visualizations often emphasize point estimates to support magnitude estimates or decisions through visual comparison. However, when design choices emphasize means, users may overlook uncertainty information and misinterpret visual distance as a proxy for effect size. We present findings from a mixed design experiment on Mechanical Turk which tests eight uncertainty visualization designs: 95% containment intervals, hypothetical outcome plots, densities, and quantile dotplots, each with and without means added. We find that adding means to uncertainty visualizations has small biasing effects on both magnitude estimation and decision-making, consistent with discounting uncertainty. We also see that visualization designs that support the least biased effect size estimation do not support the best decision-making, suggesting that a chart user&apos;s sense of effect size may not necessarily be identical when they use the same information for different tasks. In a qualitative analysis of users&apos; strategy descriptions, we find that many users switch strategies and do not employ an optimal strategy when one exists. Uncertainty visualizations which are optimally designed in theory may not be the most effective in practice because of the ways that users satisfice with heuristics, suggesting opportunities to better understand visualization effectiveness by modeling sets of potential strategies.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Many visualization authors perceive visualizing uncertainty as an exception, rather than a norm <ref type="bibr" target="#b24">[25]</ref>. However, the common practice of omitting uncertainty information from visualizations and focusing attention on point estimates leads to "incredible certitude" <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>, the unwarranted impression that error is minimal or not important. To enable informed judgments and decisions, a common suggestion is to present uncertainty information alongside point estimates, for example, by showing intervals in which estimates could fall <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b51">52]</ref>.</p><p>However, presenting uncertainty alongside point estimates may not lead users to incorporate uncertainty information into their judgments. A large body of work on biases due to heuristics (e.g., <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref>), also commonly known as satisficing <ref type="bibr" target="#b44">[45]</ref>, shows that people often avoid or discount uncertainty information. This suggests that chart users may ignore uncertainty in favor of means even when both are presented <ref type="bibr" target="#b25">[26]</ref>.</p><p>Different visualization design choices make the mean more or less salient. Imagine a continuum of uncertainty visualization designs representing how perceptually difficult it is to decode the mean from a chart. At one extreme are hypothetical outcome plots or HOPs <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref> where the mean is only encoded implicitly as the average of a set of outcomes presented across frames of an animation. At the other extreme are direct encodings of point estimates presented alongside uncertainty (e.g., represented as error bars). We expect that the salience of the mean in uncertainty visualization designs and other factors such as frequency-framing of probability <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref> influence the degree to which users focus on means and ignore uncertainty. How might chart users who focus on means judge effect size? Imagine a user viewing visualizations like those in <ref type="figure">Figure 1</ref>. Discounting uncertainty may manifest as using distance between means or gist estimates of distance between distributions as a proxy for effect size and not judging distance relative to the width of distributions. Using only distance as a proxy for effect size may be misleading <ref type="figure">(Fig. 2)</ref> because the distance between distributions depends on a number of factors, including the variance of distributions and the visualization author's choice of axis scale as noted by previous work <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b60">61]</ref>.</p><p>We investigate a scenario where distance heuristics lead to a predictable pattern of bias in order to measure how different visualization designs impact users' reliance on distance as a proxy for effect size. Users are shown charts depicting various effects on a fixed axis <ref type="figure">(Fig. 2</ref>) such that when distributions have lower variance, visual distance between means is small regardless of effect size, but distances correspond to effect size more consistently at higher variance. In this scenario, we expect that adding means to uncertainty visualizations leads users to <ref type="figure">Fig. 2</ref>: Intervals with means showing two levels of effect size (72% and 95% Pr(S)) at low and high variance. Using visual distance between means as a proxy for effect size should result in greater bias toward underestimating effect size at lower variance than at higher variance.</p><p>underestimate effect size at lower variance. Conversely, adding means may reduce this underestimation bias at higher variance.</p><p>We contribute a pre-registered experiment on Mechanical Turk investigating how uncertainty visualization design impacts lay users' judgments and decisions from effect size. We find that visualization designs which support magnitude estimation are not necessarily best suited as decision aids. Quantile dotplots lead to the least bias in magnitude estimation, but other visualizations lead to the least bias in decision-making. On a fixed axis scale, densities without means support unbiased decisions at lower variance, and users show substantial bias with all visualizations at higher variance. Visualization effectiveness for decision-making depends on the level of variance in data relative to the axis scale. Adding means has a negligible impact on magnitude estimation, but in most cases it leads to less utility-optimal decisions.</p><p>In a qualitative analysis of users' strategy descriptions, we find that few users apply the optimal strategy for reading an uncertainty visualization when one exists. Instead, the majority of users appear to satisfice <ref type="bibr" target="#b44">[45]</ref> by using a small set of heuristics. We find that the majority of users report relying on visual distance between distributions regardless of uncertainty information, an observation that is consistent with the biases in our quantitative results. We also find that many users switch between strategies. This suggests that many uncertainty visualizations may not be interpreted in ways that researchers and designers expect, and characterizing possible strategies may lead to design recommendations based on how users reason in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND: VISUALIZING UNCERTAINTY</head><p>In communicating the results of statistical analysis, visualization authors commonly represent uncertainty as a range of possible values as recommended by numerous experts (e.g., <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b51">52]</ref>). Other conventional uncertainty representations commonly used in statistical analysis include aggregate encodings of distributions such as boxplots <ref type="bibr" target="#b52">[53]</ref>, histograms <ref type="bibr" target="#b41">[42]</ref>, and densities <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b47">48]</ref>. Frequency-based uncertainty visualizations build on a large body of work suggesting that framing probabilities as frequencies of events improves statistical reasoning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">41]</ref>. These include hypothetical outcome plots (HOPs) <ref type="bibr" target="#b25">[26]</ref>, which encode possible outcomes as frames in an animation, and quantile dotplots <ref type="bibr" target="#b33">[34]</ref>, which quantize a distribution of possible outcomes and represent each quantile as a discrete dot. A growing body of work suggests that lay and expert audiences commonly misinterpret interval representations of uncertainty <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b46">47]</ref> and that other uncertainty visualization formats such as gradient plots <ref type="bibr" target="#b9">[10]</ref>, violin plots <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b25">26]</ref>, HOPs <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref>, and quantile dotplots <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b33">34]</ref> lead to more accurate interpretation and performance on various tasks.</p><p>In our study, we compare two frequency-based visualizations, quantile dotplots and HOPs, with two more conventional uncertainty representations, intervals and densities. By testing each with and without added means, we investigate the extent to which users of these uncertainty visualizations differ in their tendency to ignore uncertainty.</p><p>When chart users don't know how to interpret uncertainty, prior work <ref type="bibr" target="#b25">[26]</ref> suggests that they may substitute a judgment of the mean difference between distributions for more complicated judgments about the reliability of effects. This visual distance heuristic motivates design principles, for example, that the quantitative axis on a bar chart should always start at zero <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b23">24]</ref>, or that axis scales should align visual distance with effect size <ref type="bibr" target="#b60">[61]</ref>. Axis scale impacts the perceived importance of effect size regardless of chart type (e.g., lines versus bars) and despite attempts to signal that an axis does not start at zero (e.g., breaking the axis) <ref type="bibr" target="#b8">[9]</ref>. Rescaling the axis on a chart that displays inferential uncertainty (e.g., 95% confidence intervals) to the scale implied by descriptive uncertainty (e.g., 95% predictive intervals) can reduce bias in impressions of effect size <ref type="bibr" target="#b20">[21]</ref>. In our study, we investigate the visual distance heuristic by asking users to compare distributions with different levels of variance on a common scale <ref type="figure">(Fig. 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>We tested how adding means to different uncertainty visualizations impacts users' estimates and incentivized decisions from effect size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Tasks &amp; Procedure</head><p>Our task was like a fantasy sports game. We showed participants charts comparing the predicted number of points scored by their team with and without adding a new player (e.g., <ref type="figure">Fig. 2</ref>). Participants estimated the effect size of adding the new player and decided whether or not to pay to add the new player to their team.</p><p>Effect Size Estimation: We asked participants to estimate a measure of effect size called probability of superiority or common language effect size <ref type="bibr" target="#b39">[40]</ref>: "How many times out of 100 do you estimate that your team would score more points with the new player than without the new player?" We elicited probabilities as "times out of 100" based on literature in statistical reasoning (e.g., <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20]</ref>) suggesting that people reason more accurately with probabilities when they are framed as frequencies. Probability of superiority, the percent of the time that outcomes for one group A exceed outcomes for another group B, is a proxy for standardized mean difference μA−μB σA−B <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>, the difference between two group means relative to uncertainty in the estimates. Using synthetic data (see Section 3.5), we evaluated bias in effect size estimates compared to a known ground truth.</p><p>Intervention Decisions: We also asked participants to make binary decisions indicating whether they would "Pay for the new player," or "Keep [their] team without the new player." On each trial, the participant's goal was to win an award worth $3.17M, and they could pay $1M to add a player to their team if they thought the new player improved their chances of winning enough to be worth the cost. There were four possible payouts in each trial:</p><p>1. The participant won without paying for a new player (+$3.17M).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>The participant paid for a new player and won (+$2.17M).</p><p>3. They failed to win without paying for a new player ($0). 4. The participant paid for a new player and failed to win (-$1M). The user could only lose money if they paid for the new player. <ref type="bibr" target="#b0">1</ref> We set up the incentives for our task so that a risk-neutral chart user should pay for a new player only when effect size was larger than 74% probability of superiority or Cohen's d of 0.9, the average effect size in a recent survey of studies in experimental psychology <ref type="bibr" target="#b43">[44]</ref>. This enabled us to evaluate intervention decisions compared to a utility-optimal standard.</p><p>Feedback: At the end of each trial we told users whether or not their team scored enough points to win an award, using a Monte Carlo simulation to generate a win or loss based on the participant's decision.</p><p>We split feedback into two tables. One showed the change in account value for the current trial. The other showed cumulative account value and how this translated into a bonus in real money. By showing probabilistic outcomes, instead of the expected value of decisions, feedback gave participants a noisy signal of how well they were doing, mirroring real-world learning conditions for decisions under uncertainty.</p><p>Payment: Participants received a guaranteed reward of $1 plus a bonus of $0.08 • (account − $150M), where $0.08 per $1M was the exchange rate from account value to real dollars, account was the value of their fantasy sports account at the end of the experiment, and $150M was a cutoff account value below which they receive no bonus. These values were carefully chosen to result in bonuses between $0 and $3, such that participants who guessed randomly and experienced unlucky probabilistic outcomes would receive no bonus, and participants who responded optimally would be guaranteed a bonus.</p><p>User Strategies: To supplement our quantitative measures with qualitative descriptions of users' visual reasoning, at the end of each of the two block of trials, we asked users, "How did you use the charts to complete the task? Please do your best to describe what sorts of visual properties you looked for and how you used them."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Formalizing a Class of Decision Problems</head><p>Our decision task represents a class of decision problems where one makes a binary decision about whether or not to invest in an intervention that changes the probability of an all-or-nothing outcome. For example, this class of problems includes medical decisions about treatments that may save someone's life or cure them of a disease, organizational decisions about hiring personnel to reach a contract deadline, and personal decisions such as paying for education to seek a promotion. Previous decision-making literature examines similar problems in the context of salting the road in freezing weather <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, voting in presidential elections <ref type="bibr" target="#b58">[59]</ref>, and willingness to pay for interventions in a fictional scenario <ref type="bibr" target="#b20">[21]</ref>. The key similarity between these decision problems is that their incentive structures imply a common utility function.</p><p>A utility function defines optimal (i.e., utility maximizing <ref type="bibr" target="#b56">[57]</ref>) decisions for a risk-neutral observer, providing a normative benchmark used to measure bias in decision-making. Comparing behavior to a risk-neutral benchmark is a common practice in judgment and decisionmaking studies <ref type="bibr" target="#b0">[1]</ref>, often used to measure risk preferences <ref type="bibr" target="#b57">[58]</ref> or attitudes that make a person more or less inclined to take action than they should be based on a cost-benefit analysis. In the class of decision problems we investigate, the implied utility function depends on both the amount of money one stands to win or lose (e.g., the value of an award and the cost of a new player) and the effect size (e.g., the difference in team performance with versus without a new player).</p><p>Let v be the value of an award. Let c be the cost of adding a new player to the team. The utility-optimal decision rule is to intervene if v • Pr(award|¬player) &lt; v • Pr(award|player) − c where Pr(award|¬player) is the probability of winning an award without a new player, and Pr(award|player) is the probability of winning an award with a new player. Assuming a constant ratio between the value of the award and the cost of intervention k = v c , we express the decision rule in terms of the difference between the probabilities of winning an award with versus without a new player:</p><formula xml:id="formula_0">Pr(award|¬player) + 1 k &lt; Pr(award|player)</formula><p>The threshold level of effect size above which one should intervene depends on the incentive ratio k and the probability of a payout without intervention Pr(award|¬player). In our study, we fixed the incentives k = 3.17 and the probability of winning an award without a new player Pr(award|¬player) = 0.5 so that users would not have to keep track of changing incentives, and effect size alone was the signal that users should base decisions on. <ref type="bibr" target="#b1">2</ref> This enabled a controlled evaluation of how users translate visualized effect size into a sense of utility. By modeling a functional relationship between effect size and utility, we go beyond prior work which either does not vary the effectiveness of interventions (e.g., <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b58">59]</ref>) or examines only two levels of effect size as a robustness check for statistical tests (e.g., <ref type="bibr" target="#b20">[21]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Design</head><p>We assigned each user to one of four uncertainty visualization conditions at random, making comparisons of uncertainty visualizations between-subjects. On each trial, users made a probability of superiority estimate and an intervention decision. We asked users to make repeated judgments for two blocks of 16 trials each. In one block, we showed the users visualizations with means added, and in the other block there were no means. We counterbalanced the order of these blocks across participants. Each of the 16 trials in a block showed a unique combination of ground truth effect size (8 levels) and variance of distributions (2 levels), making our manipulations of ground truth, variance, and adding means all within-subjects. The order of trials in each block was randomized. In the middle of each block, we inserted an attention check trial, later used to filter participants who did not attend to the task. Users always saw an attention check at 50% probability of superiority with means and at 99.9% without means. Hence, each participant completed 17 trials per block and 34 trials total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Uncertainty Visualization Conditions</head><p>We evaluated visualizations intended to span a design space characterized by the visual salience of the mean, expressiveness of uncertainty representation, and discrete versus continuous encodings of probability. As described above, we showed four uncertainty visualization formats-intervals, hypothetical outcome plots (HOPs), density plots, and quantile dotplots-with and without separate (i.e., extrinsic) vertical lines encoding the mean of each distribution. We expected that adding means would bias effect size estimates toward discounting uncertainty and that this effect would be most pronounced for uncertainty visualizations in which the mean is not intrinsically salient.</p><p>Intervals: We showed users intervals representing a range containing 95% of the possible outcomes ( <ref type="figure">Fig. 1</ref>, left column). In the absence of a separate mark for the mean, the mean was not intrinsically encoded, and the user could only find the mean by estimating the midpoint of the interval. Intervals were not very expressive of probability density since they only encoded lower and upper bounds on a distribution.</p><p>Hypothetical Outcome Plots (HOPs): We showed users animated sequences of strips representing 20 quantiles sampled from a distribution of possible outcomes ( <ref type="figure">Fig. 1</ref>, left center column), matching the data shown in quantile dotplots. Animations were rendered at 2.5 frames per second with no animated transitions (i.e., tweening or fading) between frames, looping every 8 seconds. We shuffled the two distributions of 20 quantiles using a 2-dimensional quasi-random Sobol sequence <ref type="bibr" target="#b45">[46]</ref> to minimize the apparent correlation between distributions. Like intervals, HOPs did not make the mean intrinsically salient, as means were implicitly encoded as the average position of an ensemble of strips shown over time. However, HOPs were more expressive of the underlying distribution than intervals and expressed uncertainty as frequencies of events, so they conveyed an experience-based sense of probability.</p><p>Densities: We showed users continuous probability densities where the height of the area marking encoded the probabilities of corresponding possible outcomes on the x-axis ( <ref type="figure">Fig. 1</ref>, right center column). Unlike intervals and HOPs, the mean was explicitly represented as the point of maximum mark height because distributions were symmetrical, so means were intrinsically salient. Densities were also the most expressive of the underlying probability density function among the uncertainty visualizations we tested.</p><p>Quantile Dotplots: We showed users dotplots where each of 20 dots represented a 5% chance of a corresponding possible outcome on the x-axis ( <ref type="figure">Fig. 1</ref>, right column). Like densities, because distributions were symmetrical and dots were stacked in bins to express this symmetry, real-world settings which is difficult to measure on crowdsourcing platforms. the mean was explicitly represented as the point of maximum height and was thus intrinsically salient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Generating Stimuli</head><p>We generated synthetic data covering a range of effect size, so there were an equal number of trials where users should and should not intervene. Recall that 50% corresponded to a new player who did not improve the team's performance at all, 100% corresponded to a definite improvement in performance, and 74% was the utility-optimal decision threshold. We sampled eight distinct levels of ground truth probability of superiority, four values between 55% and 74% and four values between 74% and 95%, such that there are an equal number of trials above and below the utility-optimal decision threshold. Prior work in perceptual psychology <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b61">62]</ref> suggests that the brain represents probability on a log odds scale. For this reason, we converted probabilities into log odds units and sampled on this logit-transformed scale using linear interpolation between the endpoints of the two ranges described above. We added two attention checks at probabilities of superiority of 50% and 99.9%, where the decision task should have been very easy, to allow for excluding participants who were not paying attention.</p><p>To derive the visualized distributions from ground truth effect size, we made a set of assumptions. We assumed equal and independent variances for the distributions with and without a new player σ 2 team such that σ 2 di f f = 2σ 2 team where σ 2 di f f was the variance of the difference between distributions. We tested two levels of variance, setting the standard deviation of the difference between distributions σ di f f to a low value of 5 or a high value of 15. These levels produced distributions that looked relatively narrow or wide compared to the width of the chart, making visual distance between distributions an unreliable cue for effect size such that at low variance large effect sizes corresponded to distributions that looked close together.</p><p>We determined the distance between distributions, or mean difference μ di f f , using the formula</p><formula xml:id="formula_1">μ di f f = d • σ di f f</formula><p>where d were ground truth values as standardized mean differences (i.e., Cohen's d <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>). The mean number of points scored without the new player was held constant μ without = 100, which corresponded to a 50% chance of winning the award. We calculated mean for the team with a new player μ with = μ without + μ di f f . We rendered our chart stimuli using the parameters μ with , μ without , and σ team to define the two distributions on each chart. Holding the chance of winning without a new player constant at 50% <ref type="figure">(Fig. 2</ref>, blue distributions) is an experimental control that enables us to compare a user's preference for new players across trials using a coin flip gamble as the alternative choice, which is common in judgment and decision-making studies <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Modeling</head><p>We wanted to measure how much users underestimate effect size in their probability of superiority responses, how much they deviate from a utility-optimal criterion in their decisions, and how sensitive they are to effect size for the purpose of decision-making. To measure underestimation bias, we fit a linear in log odds model <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b61">62]</ref> to probability of superiority responses, and we derive slopes describing users' responses as a function of the ground truth <ref type="figure" target="#fig_1">(Fig. 3</ref>). To measure bias and sensitivity to effect size in decision-making, we fit a logistic regression to intervention decisions, and we derive points of subjective equality and just-noticeable differences describing the location and scale of the logistic curve as functions of effect size <ref type="figure">(Fig. 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.1">Approach</head><p>We used the brms package <ref type="bibr" target="#b4">[5]</ref> in R to build Bayesian hierarchical models for each response variable: probability of superiority estimates and decisions of whether or not to intervene. We started with simple models and gradually added predictors, checking the predictions of each model against the empirical distribution of the data. This process of model expansion <ref type="bibr" target="#b14">[15]</ref> enabled us to understand the more complex models in terms of how they differ from simpler ones.</p><p>We started with a minimal model, which had the minimum set of predictors required to answer our research questions, and built toward a maximal model, which included all the variables we manipulated in our experiment. We specified the minimal and maximal models for each response variable in our preregistration. <ref type="bibr" target="#b2">3</ref> Expanding models gradually helped us determine priors one-at-atime. Each time we added a new kind of predictor to the model (e.g., a random intercept per participant), we honed in on weakly informative priors using prior predictive checks <ref type="bibr" target="#b14">[15]</ref>. We centered the prior for each parameter on a value that reflected no bias in responses. We scaled each prior to avoid predicting impossible responses and to impose enough regularization to avoid issues with convergence in model fitting. We documented priors and model expansion in Supplemental Materials. <ref type="bibr" target="#b3">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.2">Linear in Log Odds Model</head><p>We use the following model (Wilkinson-Pinheiro-Bates notation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b59">60]</ref>) for responses in the probability of superiority estimation task: We apply a logit-transformation to both response Pr(S) and true Pr(S) , changing units from probabilities of superiority into log odds, because prior work suggests that the perception of probability should be modeled as linear in log odds (LLO) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b61">62]</ref>. We model effects on both μ and σ because we noticed in pilot studies that the spread of the empirical distribution of responses varies as a function of the ground truth, visualization design, and trial order. However, we are most interested in effects on mean response. The term logit(true Pr(S) ) * means * var * vis * order tells our model that the slope of the LLO model varies as a joint function of whether or not means were added, the level of variance, uncertainty visualization, and block order (i.e., all of these factors interacted with each other). This enables us to answer our core research questions, while controlling for order effects. The term logit(true Pr(S) ) * vis * trial models learning effects, so we isolate the impact of uncertainty visualizations. In both submodels, we added within-subjects manipulations as random effects predictors as much as possible without compromising model convergence.</p><formula xml:id="formula_2">logit(response Pr(S) ) ∼Normal(μ, σ ) μ =logit</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.3">Logistic Regression</head><p>We use this model to make inferences about intervention decisions:</p><p>intervene ∼Bernoulli(p) logit(p) =evidence * means * var * vis * order +evidence * vis * trial + evidence * means * var + evidence * trial worker Where intervene is the user's choice of whether or not to intervene, p is the probability that they intervene, and evidence is a logittransformation of the utility-optimal decision rule (see  Motivation: We logit-transform our evidence scale because internal representations of probabilities are thought to be on a log odds scale <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b61">62]</ref>, such that linear changes in log odds appear similar in magnitude. The term evidence * means * var * vis * order tells our model that the location and scale of the logistic curve vary as a joint function of whether or not means were added, the level of variance, uncertainty visualization, and block order. Mirroring an analogous term in the LLO model, this enables us to answer our core research questions, while controlling for order effects. The term evidence * vis * trial models learning effects. As with the LLO model, we specify random effects per participant through model expansion by trying to incorporate as many within-subjects manipulations as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Derived Measures</head><p>From our models, we derive estimates for three preregistered metrics that we use to compare visualization designs.</p><p>Linear in log odds (LLO) slopes measure the degree of bias in probability of superiority Pr(S) estimation <ref type="figure" target="#fig_1">(Fig. 3)</ref>. A slope of one indicates unbiased performance, and slopes less than one indicate the degree to which users underestimate effect size. <ref type="bibr" target="#b4">5</ref> We measure LLO slopes because they are very sensitive to the expected pattern of bias in responses, giving us greater statistical power than simpler measures like accuracy. Specifically, LLO slope is the expected increase in a user's logit-transformed probability of superiority estimate, logit(response Pr(S) ), for one unit of increase in logit-transformed ground truth, logit(true Pr(S) ). Using a linear metric (i.e., slope in logitlogit space) to describe an exponential response function in probability units comes from a theory that the brain represents probabilities on a log odds scale <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b61">62]</ref>. The LLO model <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b61">62]</ref> can be thought of as a generalization of the cyclical power model <ref type="bibr" target="#b22">[23]</ref> that allows a varying intercept or a modification of Stevens' power law <ref type="bibr" target="#b48">[49]</ref> for proportions. <ref type="figure">Fig. 4</ref>: Logistic regression fit for one user. We derive point of subjective equality (PSE) and just-noticeable difference (JND) by working backwards from probabilities of intervention to levels of evidence.</p><p>Points of subjective equality (PSEs) measure bias toward or against choosing to intervene in the decision task relative to a utilityoptimal and risk-neutral decision rule (see Section 3.2). PSEs describe the level of evidence at which a user is expected to intervene 50% of the time <ref type="figure">(Fig. 4)</ref>. A PSE of zero is utility-optimal, whereas a negative value indicates that a user intervenes when there is not enough evidence, and a positive value indicates that a user doesn't intervene until there is more than enough evidence. In our model, PSE is −intercept slope where slope and intercept come from the linear model in logistic regression.</p><p>Just noticeable-differences (JNDs) measure sensitivity to effect size information for the purpose of decision-making <ref type="figure">(Fig. 4)</ref>. They describe how much additional evidence for the effectiveness of an intervention a user needs to see in order to increase their rate of intervening from 50% to about 75%. A JND in evidence units is a difference in the log probability of winning the award with the new player. We chose this scale for statistical inference because units of log stimulus intensity are thought to be approximately perceptually uniform <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b55">56]</ref>. In our model, JND is</p><formula xml:id="formula_3">logit(0.75) slope</formula><p>where slope is the same as for PSE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Participants</head><p>We recruited users through Amazon Mechanical Turk. Workers were located in the US and had a HIT acceptance rate of 97% or more. Based on the reliability of inferences from pilot data, we aimed to recruit 640 participants, 160 per uncertainty visualization. We calculated this target sample size by assuming that variance in posterior parameter estimates would shrink by a factor of roughly 1 √ n if we collected a larger data set using the same interface. Since we based our target sample size on between-subjects effects (e.g., uncertainty visualization), our estimates of within-subjects effects (e.g., adding means) were very precise.</p><p>We recruited 879 participants. After our preregistered exclusion criterion that users needed to pass both attention checks, we slightly exceeded our target sample size with 643 total participants. However, we had issues fitting our model for an additional 21 participants, 17 of whom responded with only one or two levels of probability of superiority and 4 of whom had missing data. After these non-preregistered exclusions, our final sample size was 622 (with block order counterbalanced). All participants were paid regardless of exclusions, on average receiving $2.24 and taking 16 minutes to complete the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.9">Qualitative Analysis of Strategies</head><p>Using the two strategy responses we elicited from each user, we conducted a qualitative analysis to characterize users' visual reasoning strategies based on heuristics they used with different visualization designs (with and without means) and whether they switched strategies.</p><p>The first author developed a bottom-up open coding scheme for how users described their reasoning with the charts. Since some responses were uninformative about what visual properties of the chart a user considered (e.g., "I used the charts to estimate the value added by the new player."), we omitted participants for whom both responses were uninformative from further analysis. Excluding 180 such participants resulted in a final sample of 442 for our qualitative analysis.</p><p>We used our open codes to develop a classification scheme for strategies based on what visual features of charts users mentioned, whether they switched strategies, and whether they were confused by the chart or task. We coded for the following uses of visual features:</p><p>• Relative position of distributions • Means, whether users relied on or ignored them • Spread of distributions, whether users relied on variance, ignored it, or erroneously preferred high or low variance • Reference lines, whether users relied on imagined or real vertical lines (e.g., the annotated decision threshold in <ref type="figure">Fig. 1 &amp; 2)</ref> • Area, whether users relied on the spatial extent of geometries • Frequencies, whether users of quantile dotplots or HOPs relied on frequencies of dots or animated draws Thus, we generated a spreadsheet of quotes, open codes, and categorical distinctions which enabled us to provide aggregate descriptions of patterns and heterogeneity in user strategies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Probability of Superiority Judgments</head><p>For each uncertainty visualization, adding means at low variance decreases LLO slopes. Recall that a slope of one corresponds to no bias, and a slope less than one indicates underestimation. When we average over uncertainty visualizations, adding means at low variance reduces LLO slopes for the average user, indicating a very small 0.8 percentage points increase in probability estimation error.</p><p>At high variance, the effect of adding means changes directions for different uncertainty visualizations. Adding means decreases LLO slopes for HOPs, whereas adding means increases LLO slopes for intervals and densities. Because differences in LLO slopes represent changes in the exponent of a power law relationship, these slope differences of similar magnitude indicate a very small increase in probability of superiority estimation error of 0.3 percentage points for HOPs and small reductions in error of about 1.5 and 1.0 percentage points for intervals and densities, respectively.</p><p>Users of all uncertainty visualizations underestimate effect size. When we average over variance, users show an average estimation error of 8.6, 14.0, 14.8, and 12.4 percentage points in probability of superiority units for quantile dotplots, HOPs, intervals, and densities, respectively, each without means. In this marginalization, adding means only has a reliable impact on LLO slopes for HOPs, but the difference is practically negligible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Intervention Decisions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.1</head><p>Points of Subjective Equality For each uncertainty visualization, adding means at low variance increases PSEs. This results in different effects depending on whether the visualization with no means has a PSE below or above utility-optimal. Recall that a PSE of zero is utility-optimal, a negative PSE indicates intervening too often, and a positive PSE indicates not intervening often enough. Users of quantile dotplots with no means have negative PSEs which become unbiased when we add means. Users of HOPs and intervals with no means have positive PSEs, biases which increase when we add means. Users of densities with no means have PSEs near zero and become more biased when we add means. Only the effect for quantile dotplots is reliable. When we average over uncertainty visualizations, at low variance the average user may have a PSE 0.6 percentage points above utility-optimal with no means, and adding means increases this mild bias by about 1.7 percentage points in terms of the probability of winning.</p><p>At high variance, adding means decreases PSEs. Since PSEs for all uncertainty visualizations with no means are below optimal, adding means increases biases in all conditions, however, the effect is only reliable for intervals. When we average over uncertainty visualizations, at high variance the average user has a negative PSE 9.5 percentage points below utility-optimal with no means, and adding means increases this bias by about 2.1 percentage points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.2</head><p>Just-Noticeable Differences At low and high variance, the effects of adding means on JNDs are mostly unreliable. Recall that smaller JNDs indicate that a user is sensitive to smaller differences in effect size for the purpose of decision-making. Adding means only has a reliable effect on JNDs for intervals at high variance, where it reduces JNDs by 1.2 percentage points in terms of the probability of winning.</p><p>When we average over variance, quantile dotplots with means lead to the smallest JNDs, and users of HOPs with or without means have the largest JNDs, a difference of about 1 percentage point in terms of the probability of winning. Quantile dotplots with or without means have reliably smaller JNDs than other conditions, with the exception of unreliable differences between quantile dotplots with no means and densities with or without means.</p><p>*Probability densities of model estimates show posterior distributions of means conditional on the average participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>Among the uncertainty visualizations we tested, quantile dotplots lead to the least biased probability of superiority estimates. This is not surprising given previous work (e.g., <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref>) showing that frequency-based visualizations are effective at conveying probabilities. However, it is surprising that users do not perform reliably differently with frequency-based HOPs than with intervals or densities. HOPs directly encode probability of superiority by how often the draws from the two distributions change order, whereas in all other conditions users would need to calculate effect size analytically from visualized means and variances to arrive at the "correct" inference, although we doubt that users engage in such explicit mathematical reasoning. In Section 5, we present descriptive evidence of heuristics that users employ with different visualization designs, which helps to explain these results.</p><p>In most cases, the small effects on LLO slopes when adding means to uncertainty visualizations are probably negligible. However, they are consistent with the pattern of behavior we expect if users rely on visual distance between distributions as a proxy for effect size. When variance is lower relative the axis scale, distances between distributions look small even for large effects <ref type="figure">(Fig. 2, top)</ref>, and users tend to underestimate effect size more when means are added. When variance is higher relative the axis scale, distances between distributions roughly correspond to effect size <ref type="figure">(Fig. 2, bottom)</ref>, and users tend to underestimate effect size less when means are added, at least for densities and intervals.</p><p>Our results suggest that the best visualization design for utilityoptimal decision-making probably depends on the level of variance relative to the axis scale. At lower variance, when multiple levels of variance are shown on a common scale, densities without means or quantile dotplots with means lead to the least bias in decisions. At higher variance, users are biased toward intervening in all conditions, and both densities without means and intervals without means lead to the least bias. The impact of means also depends on variance and axis scaling, such that when we average across uncertainty visualizations, adding means exacerbates biases that exist when means are absent. The effect of variance on PSEs (see Supplemental Materials) is large, such that users intervene more often at higher variance than at lower variance. One possible explanation for this is that users rely on distance between distributions as a proxy for effect size and make decisions as if effects are larger when distributions are further apart <ref type="figure">(Fig. 2)</ref>.</p><p>Reported effects of visualization design on JNDs may not be practically important. All differences in JNDs between visualization designs are smaller than the difference between high versus low variance (see Supplemental Material). Smaller JNDs at high variance may reflect the fact that our high variance charts use white space more efficiently.  Different visualization designs lead to the best performance on our magnitude estimation and decision-making tasks. To explore this decoupling of performance across tasks, we calculate average posterior estimates of our derived measures-LLO slope, PSE, and JND-for each individual user and compare them. <ref type="figure" target="#fig_2">Figure 5</ref> shows that many individuals who are poor at magnitude estimation (i.e., LLO slopes below one) do well on the decision task (i.e., PSEs and JNDs near zero).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparing Magnitude Estimation &amp; Decision-Making</head><p>One possible explanation for this decoupling of performance on our two tasks is that users may rely on different heuristics to judge the same data for different purposes. This is consistent with Kahneman and Tversky's <ref type="bibr" target="#b30">[31]</ref> distinction between perceiving the probability of an event to be p and weighting the probability of an event in decision-making as π(p), which suggests that decision weights reflect preferences based on probabilities and risk atti-tudes <ref type="bibr" target="#b57">[58]</ref>. Recent work in behavioral economics <ref type="bibr" target="#b34">[35]</ref> suggests that biases in decision-making are partially attributable to imprecision in an individual's subjective perception of numbers (i.e., "number sense"). Since JNDs reflect the precision of perceived effect size implied by one's decisions and PSEs represent bias in decision-making, we can investigate this relationship within individual users in our study <ref type="figure" target="#fig_3">(Fig 6)</ref>. In agreement with prior work, we see that greater sensitivity to effect size for decision-making (i.e., JNDs close to zero) predicts more utilityoptimal decisions (i.e., PSEs close to zero). Although, based on the decoupling of LLO slopes and JNDs, it also seems clear that a user's internal sense of effect size is not necessarily identical when they use the same information for different tasks. We should be mindful that perceptual accuracy may not feed forward directly into decision-making.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VISUAL REASONING STRATEGIES</head><p>We use qualitative analysis of reported strategies to identify ways that users judge effect size by comparing distributions, giving us a vocabulary for how visualization design choices impact their interpretations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Prevalent Strategies</head><p>The strategies we identify are not mutually exclusive. We count a user as employing a strategy if they mention it in either of their responses.</p><p>Only Distance: About 62% of users (275 of 442) rely on "how far to the right" the red distribution is compared to the blue one without mentioning that they incorporate the variance of distributions into their judgments <ref type="figure">(Fig. 2)</ref>. Roughly 69% of these users (190 of 275) describe making a gist estimate of distance between distributions, with 46% (126 of 275) saying they rely on the mean difference specifically, and 13% (36 of 275) saying they rely on both gist distance and mean difference. Strategies which involve only the distance between distributions should result in a large bias toward underestimating effect size, which is what we see in our aggregated quantitative results.</p><p>Distance Relative to Variance: Only about 8% of users (35 of 442) mention that their interpretations of distance depend on the spread of distributions, suggesting that perhaps very few untrained users are sensitive to the impact of variance on effect size. If users estimate standard deviation and mean difference between distributions, they could use this information to calculate effect size analytically. However, we think it is far more likely that these users judge the distance between distributions relative to the spatial extent of uncertainty visualizations, which should result in underestimation bias which is similar to but less pronounced than with judgments of only distance.  Cumulative Probability: A substantial 36% of users (160 of 442) estimate the cumulative probability of winning the award with and/or without the new player. This strategy involves judging the distance, proportion of area, or frequency of markings across the threshold number of points to win (e.g., <ref type="figure" target="#fig_4">Fig. 7</ref>). These users may be confusing cumulative probability of winning the award, which is the best cue in the decision task, with probability of superiority (i.e., probability that team does better with the new player than without), which is what we ask for in the estimation task. However, since the probability of winning increases monotonically with probability of superiority, this strategy should theoretically result in milder underestimation bias than distance-based strategies.</p><p>Distribution Overlap: About 7% of users (31 of 442) describe judging the overlap between distributions. While similar to distancebased strategies, users conceptualize this strategy in terms of area rather than the gap between distributions <ref type="figure" target="#fig_5">(Fig. 8)</ref>. For example, one user said they use HOPs "only to see how much of an overlap [there is] between the two areas," suggesting that they imagine contours of distributions over the sets of animated draws. This strategy probably results in underestimation bias similar to judging distance relative to variance. Frequency of Draws Changing Order: This strategy is only relevant to the HOPs condition, where only about 16% of users (19 of 121) employed it. It involves judging the number of animated frames in which the draws from the two distributions switch order <ref type="figure" target="#fig_6">(Fig. 9)</ref>. This is the best way to estimate probability of superiority from HOPs <ref type="bibr" target="#b25">[26]</ref>. If we think of the user as accumulating information across frames, the precision of their inference is mostly limited by the number of frames they watch. For example, in <ref type="figure" target="#fig_6">Figure 9</ref> red scores higher than blue in 6 of the 8 frames, and watching only 8 frames limits the precision of this inference to increments of <ref type="bibr" target="#b0">1</ref> 8 . The fact that only a handful of HOPs users employ this strategy helps to explain why the performance of HOPs users is worse than expected.</p><p>Switching Strategies: A substantial 29% of users (129 of 442) switch between strategies in the middle of the task. For example, one user of intervals without means described a mix of cumulative probability and distribution overlap strategies: "If the red <ref type="bibr">[distribution]</ref> was completely past the dotted line then I would buy the new player no matter what. If there were overlaps with blue I would just risk assess to see if it was worth it to me or not." While more of a metastrategy, our observation that a significant proportion of users switch is important because it suggests that judgment processes involved in graphical perception may not be consistent within each user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Impacts of Visualization Design Choices</head><p>Users rely on visual features (Section 3.9) and strategies (Section 5.1) to varying degrees depending on visualization design <ref type="table" target="#tab_3">(Table 1)</ref>.</p><p>Intervals: Roughly 75% of intervals users (85 of 112) rely on relative position as a visual cue for effect size compared to 69% with densities (68 of 99), 61% with HOPs (74 of 121), and 59% with quantile dotplots (65 of 110). Of intervals users who look at relative position, about 87% (74 of 85) employ an only distance strategy, while only about 13% (11 of 85) judge distance relative to variance . In other words, only about 10% of intervals users (11 of 112) incorporate variance into their judgments of distance. About 28% of intervals users (31 of 112) report looking at area, with about 55% of these users (17 of 31) employing a distribution overlap strategy.</p><p>HOPs: About 61% of HOPs users (74 of 121) look at relative position to judge effect size. Of HOPs users who rely on relative position, merely 3% (2 of 74) use a distance relative to variance strategy. However, looking at relative position is not mutually exclusive with looking at frequency of draws, which 45% of HOPs users (54 of 121) rely on as a visual feature. Among HOPs users who rely on frequencies, about 69% (37 of 54) employ a cumulative probability strategy, while about 35% (19 of 54) rely on the optimal strategy of counting the frequency of draws changing order. Roughly 40% of HOPs users (48 . That most HOPs users rely on relative position, and that those who do rely on frequency are more likely to switch to or from relying on the mean, helps to explain poor performance with HOPs. Densities: About 69% of densities users (68 of 99) rely on relative position as a visual cue. Of densities users who look at relative position, only about 13% (9 of 68) employ a distance relative to variance strategy. As one might expect, a substantial 36% of densities users (36 of 99) rely on area as a cue, compared to 10% of quantile dotplots users <ref type="bibr">(11 of 110)</ref>. Among densities users who rely on area, about 53% (19 of 36) employ a cumulative probability strategy, while about 28% (10 of 36) employ a distribution overlap strategy. Interestingly, about 27% of densities users (27 of 99) mention relying on the spread of distributions as a cue, more than the 21% of users with intervals (24 of 112), 21% with HOPs (25 of 121), and 10% with quantile dotplots (11 of 110) who report relying on the same cue.</p><p>Quantile Dotplots: Roughly 59% of quantile dotplots users (65 of 110) describe looking at relative position to judge effect size, similar to 61% of users with HOPs (74 of 121) and less than the 69% of densities users (68 of 99) and 76% of intervals users (85 of 112) who report using the same cue. Merely 6% of quantile dotplots users who rely on relative position (4 of 65) employ a distance relative to variance strategy. 37% of quantile dotplots users (41 of 110) rely on frequency as a visual cue by counting dots. About 81% of quantile dotplots users who rely on frequency (33 of 41) employ a cumulative probability strategy.</p><p>Adding Means: A substantial 35% of users (155 of 442) describe relying on the mean as a cue for effect size. If we split users based on whether or not they start the task with means, about 31% of users (67 of 218) switch strategies when means are added to the charts halfway through the task, compared to 10% (23 of 224) who switch strategies when means are removed. This asymmetry in strategy switching suggests that means are "sticky" as a cue: Among the 15% of users (67 of 442) who start with and rely on means, about 66% (44 of 67) attempt to visually estimate means after means are removed from charts, almost twice as many as the 34% (23 of 67) who switch to relying on other cues. However, the impact of adding means on performance depends on what other strategies a user is switching between. Among the 20% of users (90 of 442) who rely on means and switch strategies, about 44% (40 of 90) just incorporate the mean into judgments of relative position without relying on other visual cues. Other groups of users switch between relying on means and less similar visual cues, with 34% (31 of 90) also mentioning frequency and 12% (11 of 90) mentioning area. That many users switch between relying on relative position and means, and that strategies are heterogeneous, helps to explain why the average impact of means on performance is small in our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">GENERAL DISCUSSION</head><p>Our results suggest that design guidelines for visualizing effect size should depend on the user's task, the variance of distributions, and design choices about axis scales. To provide concrete design guidelines while acknowledging the inherent complexity of our results, we present high-level take-aways for designers alongside relevant caveats.</p><p>Quantile dotplots support the most perceptually accurate distributional comparisons, at least among the visualization designs we tested. Caveat: Asking users to perform two tasks may have led users to rely on relatively simple strategies like cumulative probability more than strategies which require more mental energy like frequency of draws changing order. Conditions of high cognitive load seem to favor uncertainty visualizations like quantile dotplots over HOPs.</p><p>Densities without means seem to support the best decisionmaking across levels of variance. On a fixed axis scale, densities without means and quantile dotplots with means perform best at lower variance, while densities without means and intervals without means perform best at higher variance. No visualization design we tested eliminated bias in decision-making at higher variance. Caveats: The visualization design that leads to the least bias in decision-making depends on the variance of distributions relative to axis scale. Future work should investigate bias in decision-making over a gradient of variances shown on a common scale, including charts with heterogeneous variances, as this would enable more exhaustive design recommendations.</p><p>Adding means leads to small biases in magnitude estimation and decision-making from distributional comparisons, leading users to underestimate effect size and make less utility-optimal decisions in most in most cases we tested. Caveats: Although the biasing effects of means are mostly negligible, our estimates of these biases are probably very conservative for two reasons: (1) added means were only highly salient in the HOPs condition; and (2) in the absence of added means, users already tend to rely on relative position, a cue which the mean merely reinforces. The effects of adding means on decision quality reverse at high versus low variance, so these biases may disappear for specific combinations of variance and axis scale.</p><p>Users rely on distance between distributions as a proxy for effect size, so designers should note when this will be misleading and encourage more optimal strategies. Our quantitative analysis shows that adding means induces small but reliable biases in magnitude estimation, consistent with distance-based heuristics. Our qualitative analysis of strategies verifies that the majority of users (357 of 442; 80.8%) rely on distance between distributions or mean difference to judge effect size. Caveats: Subtle design choices probably impact the tendency to rely on distance heuristics versus other strategies. For example, including a decision threshold annotation on our charts <ref type="figure">(Fig. 2</ref>) may have encouraged users to judge effect size as cumulative probability, rather than probability of superiority, contributing to underestimation bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Limitations</head><p>We only tested symmetrical distributions, and this may limit the generalizability of our inferences. Although we speculate that chart users may rely on central tendency regardless of the family of a distribution, reasoning with multi-modal distributions in particular may involve different strategies not accounted for in the present study.</p><p>Because we rely on self-reported strategies in our qualitative analysis, our findings only reflect conscious strategies. This leaves out implicit or automatic information processing such as visual adaptation <ref type="bibr" target="#b31">[32]</ref> and ensemble processing <ref type="bibr" target="#b50">[51]</ref>, except in rare cases where users report trying to "roughly average" predictions presented as HOPs.</p><p>Our choice to incentivize the decision-making task but not magnitude estimation may have contributed to the decoupling of performance on our two tasks. We cannot disentangle this possible explanation from evidence corroborating Kahneman and Tversky's <ref type="bibr" target="#b30">[31]</ref> distinction between perceived probabilities and decision weights (see Section 4.4).</p><p>We control the incentives for our decision task rather than manipulating them, in part because it is not feasible to test dramatically different incentives on Mechanical Turk. As such the risk preferences that we measure as PSEs are representative of users optimizing small monetary bonuses, and they may not capture how people respond to visualized data in crisis situations when lives, careers, or millions of dollars are at stake. However, by devising a task that is representative of a broad class of decision problems (see Section 3.2), we make our results as broadly applicable as possible. We speculate that the relative impacts of visualization designs on risk preferences should generalize to decision problems with similar utility functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Satisficing and Heterogeneity</head><p>The visual reasoning strategies that chart users rely on when making judgments from uncertainty visualizations may not be what visualization designers expect. We present evidence that, in the absence of training, users satisfice by using suboptimal heuristics to decode the signal from a chart. We also find that not all users rely on the same strategies and that many users switch between strategies. Satisficing and heterogeneity in heuristics make it difficult both to anticipate how people will read charts and to study the impact of design choices. Conventionally, visualization research has characterized visualization effectiveness by ranking visualization designs based on the performance of the average user (e.g., <ref type="bibr" target="#b6">[7]</ref>). However, in cases like the present study where users are heterogeneous in their strategies, these averages may not account for the experience of very many users and are probably an oversimplification. Visualization researchers should be mindful of satisficing and heterogeneity in users' visual reasoning strategies, attempt to model these strategies, and try to design ways of training users to employ more optimal strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Toward Better Models of Visualization Effectiveness</head><p>Because some users seem to adopt suboptimal strategies or switch between strategies when presented with an uncertainty visualization, models of visualization effectiveness which codify design knowledge and drive automated visualization recommendation and authoring systems should represent these strategies. We envision a new class of behavioral models for visualization research which attempt to enumerate possible strategies, such as those we identify in our qualitative analysis, and learn how often users employ them to perform a specific task when presented with a particular visualization design. Previous work <ref type="bibr" target="#b26">[27]</ref> demonstrates a related approach by calculating expected responses based on a set of alternative perceptual proxies for visual comparison and comparing these expectations to users' actual responses. Like the present study, this work describes the correspondence between expected patterns and user behavior. Instead, we propose incorporating functions representing predefined strategies into predictive models which estimate the proportion of users employing a given strategy.</p><p>In a pilot study, we attempted to build such a model: a Bayesian mixture model of alternative strategy functions. However, because multiple strategies predict similar patterns of responses, we were not able to fit the model due to problems with identifiability. This suggests that the kind of model we propose will only be feasible if we design experiments such that alternative strategies predict sufficiently different patterns of responses. The approach of looking at the agreement between proxies and human behavior <ref type="bibr" target="#b26">[27]</ref> suffers the same limitation, but there is no analogous mechanism to identifiability in Bayesian models to act as a fail-safe against unwarranted inferences. Future work should continue pursuing this kind of strategy-aware behavioral modeling.</p><p>We want to emphasize that the proposed modeling approach is not strictly quantitative, as the definition of strategy functions requires a descriptive understanding of users' visual reasoning. As such this approach offers a way to formalize the insights of qualitative analysis and represent the gamut of possible user behaviors inside of visualization recommendation and authoring systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We contribute findings from a mixed design experiment on Mechanical Turk investigating how visualization design impacts judgments and decisions from effect size. Our results suggest that visualization designs which support the least biased estimation of effect size do not necessarily support the best decision-making. We discuss how a user's sense of the signal in a chart may not necessarily be identical when they use the same information for different tasks. We also find that adding means to uncertainty visualizations induces small but reliable biases consistent with users relying on visual distance between distributions as a proxy for effect size. In a qualitative analysis of users' visual reasoning strategies, we find that many users switch strategies and do not employ an optimal strategy when one exists. We discuss ways that canonical characterizations of graphical perception in terms of average performance gloss over possible heterogeneity in user behavior, and we propose opportunities to build strategy-aware models of visualization effectiveness which could be used to formalize design knowledge in visualization recommendation and authoring systems beyond context-agnostic rankings of chart types.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Section 3.2): evidence = logit(Pr(award|player)) − logit(Pr(award|¬player) + 1 k )This gives us a uniformly sampled scale of evidence where zero represents the utility-optimal decision threshold. All other factors are the same as in the LLO model (see Section 3.6.2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Linear in log odds (LLO) model: fits for average user of quantile dotplots and intervals compared to a range of possible slopes (top); predictive distribution and observed responses for one user (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 :</head><label>5</label><figDesc>PSEs and JNDs vs LLO slopes per user.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 :</head><label>6</label><figDesc>JNDs vs PSEs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7: Cumulative probability strategy with quantile dotplots.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 :</head><label>8</label><figDesc>Overlap strategy with densities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 :</head><label>9</label><figDesc>Frequency of draws changing order strategy with HOPs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• AlexKale  is with the University of Washington. E-mail: kalea@uw.edu. • Matthew Kay is with the University of Michigan. E-mail: mjskay@umich.edu. • Jessica Hullman is with Northwestern University. E-mail: jhullman@northwestern.edu.</figDesc><table /><note>Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>(true Pr(S) ) * means * var * vis * order +logit(true Pr(S) ) * vis * trial + logit(true Pr(S) ) * trial + means * var worker log(σ ) =logit(true Pr(S) ) * vis * trial +means * order + logit(true Pr(S) ) +trial workerWhere response Pr(S) is the user's probability of superiority response, true Pr(S) is the ground truth probability of superiority, trial is an index of trial order, means is an indicator for whether or not extrinsic means are present, var is an indicator for low versus high variance, vis is a dummy variable for uncertainty visualization condition, order is an indicator for block order, and worker is a unique identifier for each participant used to model random effects. Note that there are submodels for the mean μ and standard deviation σ of user responses.</figDesc><table /><note>Motivation:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Interaction effects on linear in log odds slopes</figDesc><table><row><cell></cell><cell>Uncertainty</cell><cell>Difference in slope</cell><cell cols="4">Uncertainty in model estimates of</cell></row><row><cell></cell><cell>Visualizations</cell><cell>with Means Added</cell><cell cols="4">Average Slope in each condition*</cell></row><row><cell>Low Variance</cell><cell>Intervals HOPs Densities Quantile Dotplots</cell><cell>0.033 [ 0.055, 0.013] 0.023 [ 0.043, 0.003] 0.043 [ 0.075, 0.013] 0.025 [ 0.048, 0.002]</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Average over Vis</cell><cell>0.031 [ 0.044, 0.020]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>High Variance</cell><cell>Intervals HOPs Densities Quantile Dotplots</cell><cell>0.045 [ 0.024, 0.064] 0.038 [ 0.071, 0.004] 0.038 [ 0.014, 0.063] 0.006 [ 0.029, 0.018]</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Average over Vis</cell><cell>0.010 [ 0.003, 0.023]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Average over Variance</cell><cell>Intervals HOPs Densities Quantile Dotplots</cell><cell>0.007 [ 0.013, 0.026] 0.041 [ 0.067, 0.015] 0.011 [ 0.005, 0.027] 0.020 [ 0.038, 0.001]</cell><cell>0.2</cell><cell>0.3</cell><cell cols="2">Bias toward underestimation 0.4 0.6 0.7 0.5</cell></row><row><cell></cell><cell cols="5">Interaction effects on points of subjective equality (PSEs)</cell></row><row><cell></cell><cell>Uncertainty</cell><cell>Difference in PSEs</cell><cell cols="4">Uncertainty in model estimates of</cell></row><row><cell></cell><cell>Visualizations</cell><cell>with Means Added</cell><cell cols="4">Average PSE in each condition*</cell></row><row><cell></cell><cell>Quantile Dotplots</cell><cell>0.252 [ 0.082, 0.435]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Low Variance</cell><cell>Intervals HOPs Densities</cell><cell>0.125 [ 0.144, 0.433] 0.091 [ 0.160, 0.353] 0.133 [ 0.030, 0.314]</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Average over Vis</cell><cell>0.150 [ 0.027, 0.281]</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Quantile Dotplots</cell><cell>0.043 [ 0.156, 0.073]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>High Variance</cell><cell>Intervals HOPs Densities Average over Vis</cell><cell>0.160 [ 0.277, 0.040] 0.098 [ 0.267, 0.060] .116 [ 0.238, 0.002] 0.105 [ 0.175, 0.036]</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>-1.0</cell><cell>-0.5</cell><cell>0</cell><cell>0.5</cell><cell>1.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Bias toward intervention</cell><cell>Bias against intervention</cell></row><row><cell></cell><cell cols="5">Interaction effects on just-noticeable differences (JNDs)</cell></row><row><cell></cell><cell>Uncertainty Visualizations</cell><cell>Difference in JNDs with Means Added</cell><cell cols="4">Uncertainty in model estimates of Average JND in each condition*</cell></row><row><cell>Low Variance</cell><cell>Intervals HOPs Densities Quantile Dotplots</cell><cell>0.019 [ 0.108, 0.073] 0.055 [ 0.216, 0.116] 0.014 [ 0.158, 0.139] 0.013 [ 0.085, 0.125]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>High Variance</cell><cell>Intervals HOPs Densities Quantile Dotplots</cell><cell>0.105 [ 0.169, 0.049] 0.018 [ 0.068, 0.110] 0.041 [ 0.103, 0.020] 0.032 [ 0.083, 0.021]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Average over Variance</cell><cell>Intervals HOPs Densities Quantile Dotplots</cell><cell>0.014 [ 0.080, 0.059] 0.002 [ 0.092, 0.104] 0.080 [ 0.177, 0.014] 0.025 [ 0.083, 0.034]</cell><cell>0.2</cell><cell>0.4</cell><cell cols="2">Greater sensitivity to evidence 0.6 0.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Frequency of strategies used per uncertainty visualization. mention switching strategies compared to 31% with intervals (35 of 112), 23% with densities (23 of 99), and 21% with quantile dotplots (23 of 110). Among HOPs users who switch strategies, about 81% (39 of 48) rely on the mean as a cue. Strategy switching involves the mean for about 30% of HOPs users who rely on relative position (22 of 74) compared to 43% of HOPs users who rely on frequency(23  of 54)</figDesc><table><row><cell>Strategy</cell><cell>Intervals</cell><cell cols="4">HOPs Densities Dotplots Overall</cell></row><row><cell>Distance</cell><cell>73</cell><cell>77</cell><cell>61</cell><cell>64</cell><cell>275</cell></row><row><cell>Rel. to Var.</cell><cell>11</cell><cell>9</cell><cell>10</cell><cell>5</cell><cell>35</cell></row><row><cell>Cumulative</cell><cell>34</cell><cell>50</cell><cell>30</cell><cell>46</cell><cell>160</cell></row><row><cell>Overlap</cell><cell>17</cell><cell>2</cell><cell>9</cell><cell>3</cell><cell>31</cell></row><row><cell>Draw Order</cell><cell>0</cell><cell>19</cell><cell>0</cell><cell>0</cell><cell>19</cell></row><row><cell>Switching</cell><cell>35</cell><cell>48</cell><cell>23</cell><cell>23</cell><cell>129</cell></row><row><cell>Total</cell><cell>112</cell><cell>121</cell><cell>99</cell><cell>110</cell><cell>442</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In pilot studies, we tested how framing outcomes as winning versus losing awards impacted user behavior and found that participants had greater preference for intervention when it was described as increasing the certainty of gains, consistent with prior work by Tversky and Kahneman<ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b54">55]</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In pilot studies, we tried manipulating k and Pr(award|¬player) and found that these changes had little impact on the effectiveness of different uncertainty visualizations for supporting utility-optimal decision-making. In light of prior work showing that Mechanical Turk workers do not respond to changes of incentives<ref type="bibr" target="#b49">[50]</ref>, we suspect that these manipulations might have an impact in</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://osf.io/9kpmb 4 https://github.com/kalealex/effect-size-jdm</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">LLO slopes less than one represent bias toward the probability at the intercept, logit −1 (intercept), which is close to Pr(S) = 0.5 in our study.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the members of the UW IDL and Vis-Cog Lab, as well as the MU Collective at Northwestern for their feedback. This work was supported by a grant from the Department of the Navy (N17A-T004).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Thinking and deciding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Raindrop plots: A new way to display collections of likelihoods and distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Barrowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Myers</surname></persName>
		</author>
		<idno type="DOI">10.1198/0003130032369</idno>
	</analytic>
	<monogr>
		<title level="j">American Statistician</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="268" to="274" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Researchers Misunderstand Confidence Intervals and Standard Error Bars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<idno type="DOI">10.1037/1082-989X.10.4.389</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="389" to="396" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Brinton</surname></persName>
		</author>
		<title level="m">Graphic Presentation. Brinton Associates</title>
		<imprint>
			<date type="published" when="1939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">brms: Bayesian Regression Models using &apos;Stan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-C</forename><surname>Bürkner</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Developing Simulation Activities to Improve Students &apos; Statistical Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Garfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Delmas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Technology in Mathematics Education</title>
		<meeting>the International Conference on Technology in Mathematics Education</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="2" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graphical perception: Theory, experimentation, and application to the development of graphical methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American statistical association</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">387</biblScope>
			<biblScope unit="page" from="531" to="554" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">It&apos;s the effect size, stupid: What effect size is and why it is important</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Coe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Truncating the Y-Axis: Threat or Menace?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Error bars considered harmful: Exploring alternate encodings for mean and error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346298</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2142" to="2151" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The New Statistics: Why and How</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797613504966</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="29" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Inference by Eye</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Finch</surname></persName>
		</author>
		<idno type="DOI">10.1037/0003-066X.60.2.170</idno>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="170" to="180" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Arguments for and Against Standardized Mean Differences (Effect Sizes)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cummings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Archives of Pediatrics and Adolescent Medicine</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="592" to="596" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Uncertainty Displays Using Quantile Dotplots or CDFs Improve Transit Decision-Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Walls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Munson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kay</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173574.3173718</idno>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Computer-Human Interaction</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>April. Montreal</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Visualization in Bayesian workflow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Betancourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<idno type="DOI">10.1111/rssa.12378</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series A: Statistics in Society</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="389" to="402" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using Icon Arrays to Communicate Medical Risks: Overcoming Low Numeracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galesic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garcia-Retamero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0014474</idno>
	</analytic>
	<monogr>
		<title level="j">Health Psychology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="216" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">How to Improve Bayesian Reasoning Without Instruction: Frequency Formats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.102.4.684</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="684" to="704" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the Shape of the Probability Weighting Function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-89824-785</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="129" to="166" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust misinterpretation of confidence intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoekstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-013-0572-3</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1157" to="1164" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using natural frequencies to improve diagnostic inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<idno type="DOI">10.1097/00001888-199805000-00024</idno>
	</analytic>
	<monogr>
		<title level="j">Academic medicine: Journal of the Association of American Medical Colleges</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="538" to="540" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How visualizing inferential uncertainty can mislead readers about treatment effects in scientific results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hofman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313831.3376454</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sequentially Simulated Outcomes: Kind Experience Versus Nontransparent Description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Soyer</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0023265</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="434" to="463" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bias in Proportion Judgments: The Cyclical Power Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Hollands</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Dyre</surname></persName>
		</author>
		<idno>doi: 10. 1037//0033-295X.107.3.500</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="500" to="524" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">How to Lie with Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>WW Norton &amp; Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Why Authors Don&apos;t Visualize Uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hypothetical Outcome Plots Outperform Error Bars and Violin Plots for Inferences about Reliability of Variable Ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0142444</idno>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">142444</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The Perceptual Proxies of Visual Comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jardine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ondov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934786</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1012" to="1021" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Decisions With Uncertainty: The Glass Half Full</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joslyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leclerc</surname></persName>
		</author>
		<idno type="DOI">10.1177/0963721413481473</idno>
	</analytic>
	<monogr>
		<title level="j">Current Directions in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="308" to="315" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Uncertainty forecasts improve weatherrelated decisions and attenuate the effects of forecast error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Joslyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Leclerc</surname></persName>
		</author>
		<idno>doi: 10.1037/ a0025185</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Applied</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="126" to="140" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow. Farrar, Straus and Giroux</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Prospect Theory : An Analysis of Decision under Risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Y D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="292" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adaptation and learning priors in visual inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VisXVision Workshop at IEEE VIS 2019</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hypothetical outcome plots help untrained observers judge trends in ambiguous data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. Visualization &amp; Comp. Graphics (Proc. InfoVis)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">When (ish) is My Bus? User-centered Visualizations of Uncertainty in Everyday, Mobile Predictive Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Munson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM annual conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 ACM annual conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Risk Aversion as a Perceptual Bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Khaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Woodford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Bayesian Cognition Approach to Improve Data Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Walls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krafft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Communicating uncertainty in policy analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Manski</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1722389115</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">The Lure of Incredible Certitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Manski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Working Paper</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The lure of incredible certitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Manski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economics &amp; Philosophy</title>
		<imprint>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A common language effect size statistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Mcgraw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Assessing the effect of visualizations on Bayesian reasoning through crowdsourcing to cite this version</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Micallef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2536" to="2545" />
			<date type="published" when="2012" />
			<publisher>Institute of Electrical and Electronics Engineers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Contributions to the Mathematical Theory of Evolution. II. Skew Variation in Homogeneous Material</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page" from="343" to="414" />
			<date type="published" when="1895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Debroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Authors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Heisterkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Willigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R-Core</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>nlme: Linear and Nonlinear Mixed Effects Models</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The meaningfulness of effect sizes in psychological research: Differences between sub-disciplines and the impact of potential biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Schwarz</surname></persName>
		</author>
		<idno>doi: 10. 3389/fpsyg.2019.00813</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Rational Choice and the Structure of the Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000013</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="138" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Uniformly distributed sequences with an additional uniform property</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Sobol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">U.S.S.R. Comput. Maths. Math. Phys</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="236" to="242" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The illusion of predictability: How regression statistics mislead experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijforecast.2012.02.004</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="712" to="714" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Surgical Audit: Statistical Lessons from Nightingale and Codman</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series A (Statistics in Society</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="58" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">On the psychophysical law</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="153" to="181" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Please participate in Part 2: Maximizing response rates in longitudinal MTurk designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stoycheff</surname></persName>
		</author>
		<idno type="DOI">10.1177/2059799116672879</idno>
	</analytic>
	<monogr>
		<title level="j">Methodological Innovations</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Four types of ensemble coding in data visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Guidelines for evaluating and expressing the uncertainty of NIST measurement results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Kuyatt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Exploratory data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Addison-Wesley Pub</publisher>
			<pubPlace>Reading, Mass</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Judgment under Uncertainty: Heuristics and Biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">4157</biblScope>
			<biblScope unit="page" from="1124" to="1131" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The Framing Of Decisions And The Psychology Of Choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">211</biblScope>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page" from="453" to="458" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Why do we perceive logarithmically? Significance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-02" />
			<biblScope unit="page" from="28" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rubinstein</surname></persName>
		</author>
		<title level="m">Theory of Games and Economic Behavior</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1944" />
		</imprint>
	</monogr>
	<note>60th Anniversary Commemorative Edition</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">From Subjective Probabilities to Decision Weights: The Effect of Asymmetric Loss Functions on the Evaluation of Uncertain Outcomes and Events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">U</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="228" to="242" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Projecting confidence: How the probabilistic horse race confuses and demobilizes the public</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Westwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Messing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lelkes</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.3117054</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Politics</title>
		<imprint>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Symbolic Description of Factorial Models for Analysis of Variance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series C (Applied Statistics)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="392" to="399" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Introducing hat graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Witt</surname></persName>
		</author>
		<idno type="DOI">10.1186/s41235-019-0182-3</idno>
	</analytic>
	<monogr>
		<title level="m">Cognitive Research: Principles and Implications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Ubiquitous log odds: A common representation of probability and frequency distortion in perception, action, and cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Maloney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lange</surname></persName>
		</author>
		<idno>doi: 10. 3389/fnins.2012.00001</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
