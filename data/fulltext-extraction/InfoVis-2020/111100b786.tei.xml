<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Investigating Visual Analysis of Differentially Private Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sarvghad</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerome</forename><surname>Miklau</surname></persName>
						</author>
						<title level="a" type="main">Investigating Visual Analysis of Differentially Private Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Differential privacy, information visualization</keywords>
			</textClass>
			<abstract>
				<p>Differential Privacy is an emerging privacy model with increasing popularity in many domains. It functions by adding carefully calibrated noise to data that blurs information about individuals while preserving overall statistics about the population. Theoretically, it is possible to produce robust privacy-preserving visualizations by plotting differentially private data. However, noise-induced data perturbations can alter visual patterns and impact the utility of a private visualization. We still know little about the challenges and opportunities for visual data exploration and analysis using private visualizations. As a first step towards filling this gap, we conducted a crowdsourced experiment, measuring participants&apos; performance under three levels of privacy (high, low, non-private) for combinations of eight analysis tasks and four visualization types (bar chart, pie chart, line chart, scatter plot). Our findings show that for participants&apos; accuracy for summary tasks (e.g., find clusters in data) was higher that value tasks (e.g., retrieve a certain value). We also found that under DP, pie chart and line chart offer similar or better accuracy than bar chart. In this work, we contribute the results of our empirical study, investigating the task-based effectiveness of basic private visualizations, a dichotomous model for defining and measuring user success in performing visual analysis tasks under DP, and a set of distribution metrics for tuning the injection to improve the utility of private visualizations.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In this paper, we present the results of an empirical study that investigates challenges and opportunities for visual data analysis under Differential Privacy (DP), an emerging model for protecting sensitive data from leakage <ref type="bibr" target="#b13">[15]</ref>. Due to its strong guarantee of preserving individuals' privacy, Differential Privacy has recently been adopted by many industry leaders such as Google <ref type="bibr" target="#b14">[16]</ref> and Apple <ref type="bibr" target="#b17">[18]</ref> and government institutions such as the U.S. Census Bureau <ref type="bibr">[1,</ref><ref type="bibr" target="#b18">19]</ref>. This rising popularity makes the investigation of DP in the context of visual data analysis a relevant and timely problem. Additionally, in the face of the current COVID-19 pandemic and possible similar future crises, it is critical to investigate privacy-preserving data sharing and analysis methods to enable us to synergize global efforts to combat these crises.</p><p>Differential privacy typically functions by adding carefully calibrated noise to data that blurs information about individuals while preserving overall statistics about the population. A higher level of noise translates to a higher level of privacy protection. However, the injection of noise results in the alteration of data values and distribution shape.</p><p>Depending on the magnitude of data perturbation, moderate to extreme visual discrepancies can happen between a private visualization and its non-private counterpart. <ref type="figure">Fig. 1</ref> shows an example of such effects. This figure also shows the difference in the notion of "success" between private and non-private visualizations. A user's success performing a visual analysis task on histogram A depends on correct perception and decoding of visually encoded information. In this case, the measurement of success is binary with values of pass/fail. However, a user's success performing a similar task on histogram B depends not only on perceptual accuracy but also on the magnitude of data perturbation. Even when a user achieves perceptual accuracy and correctly identifies the visual artifact of interest (e.g., the smallest bar in the histogram), any readings from the target will still be different from the non-noisy data. Depending on the distance between noisy and non-noisy values, the user can achieve degrees of success. In this case, accuracy is a fuzzy variable with degrees of a pass or fail. This phenomenon imposes a grand challenge and raises a critical question: is it possible to perform visual data analysis on differentially private visualizations and trust the outcomes? For instance, do patterns in a private line chart indicating improvements in patients' conditions on specific treatment match similar patterns in the non-private line chart? Existing work in the confluence of privacy and visual data analysis has been mainly focused on the use of syntactic privacy models such as k-anonymity and l-diversity (e.g., <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b6">8,</ref><ref type="bibr" target="#b45">45]</ref>) and we know little about the challenges and opportunities of supporting visual data analysis under differential privacy. To fill this gap, we investigated the following two research questions:</p><p>• (RQ1) What is the relationship between the noise-injection level, visualization type, data analysis task, and users' performance (accuracy and time to complete tasks)?</p><p>• (RQ2) Is it possible to tune noise injection to improve the utility of private visualizations?</p><p>To investigate RQ1, we performed a crowd-sourced user study and examined the effects of three privacy levels (high, low, non-private) for combinations of eight analysis tasks and four visualization types (bar chart, pie chart, line chart, scatter plot). A central challenge in this phase was the assessment of a user's accuracy and task success. Injection of noise and consequent perturbations of data and visual patterns can result in erroneous findings, even if a user's answer to a task is correct based on the private visualization presented to the user. We set forward a dichotomous assessment method that measures accuracy and task success based on the notions of perceptual and perturbation accuracy. A detailed description of this method is presented in Section 4.8. In our study, we only considered univariate visualization. The main rationale behind this decision was to eliminate the possible interactions between two sets of noisy variables and their possible effects on participants' performance. We measured the task success rate and response time for 204 participants. We found that the rate of user success dropped for all tasks as the noise level increased. However, the rate of decline was not consistent across all tasks. In particular, "summary tasks" (e.g., Characterize Distribution) seem to be less sensitive to the injection of noise in comparison to "value tasks" (e.g., Compute Derived Value).</p><p>There has been prior research on designing differentially private algorithms <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b28">29]</ref>, and on the comparison of algorithm performance <ref type="bibr" target="#b20">[21]</ref> for answering range queries. However, it is unclear how noise injection influences downstream visual tasks. Given a certain privacy protection level, various differentially private noise injection <ref type="figure">Fig. 1</ref>: On the right-hand side, histogram B (bottom) is the private counterpart of the histogram A (top). Data perturbation caused by the injection of noise has resulted in noticeable alterations in visual patterns and data values. Consequently, the utility of histogram B for supporting several visual analysis tasks is compromised. For instance, for the task, "identify the group with smallest value" using histogram B, even if the user correctly identifies the bar with the red border as the smallest, still, his finding is erroneous based on the non-private histogram, A.</p><p>algorithms could produce completely different outputs. When visualized, some outputs could contain visual artifacts that make visual tasks substantially harder for users. We investigated the possibility of tuning noise injection through wisely choosing algorithms to improve perceptual accuracy for specific visual tasks. We introduced three basic distribution metrics to quantify the shape of noisy algorithm outputs, measuring to what extent they preserve prominent visual features essential for a specific task. Peakedness Score, Anomaly Score, and Clusteredness Score respectively quantify to what extent there exists a single peak, an anomaly data point, and clear cluster boundaries. Then we performed several rounds of simulations using three popular differentially private algorithms Laplace <ref type="bibr" target="#b13">[15]</ref>, DAWA <ref type="bibr" target="#b28">[29]</ref>, and MWEM <ref type="bibr" target="#b19">[20]</ref> and compared the perceptual distribution metrics of their noisy output. The results of these simulations indicate that the Laplace mechanism works better across different tasks compared with the more complex DAWA and MWEM algorithms.</p><p>Our work is the first on differential privacy and visual data analysis that provides an understanding of task-based effectiveness of private visualizations and creates the possibility of managing noise injection based on analysis tasks and visualization. The main contributions of this work are:</p><p>• The results of an empirical study, investigating the task-based effectiveness of basic private visualizations.</p><p>• A dichotomous model for defining and measuring user success in performing visual analysis tasks under DP.</p><p>• A set of distribution metrics for tuning the injection to improve the utility of private visualizations.</p><p>In the rest of this paper, we first provide a more detailed explanation of differential privacy followed by prior research related to our work. Next, we present detailed descriptions of work performed to investigate RQ1 and RQ2. Finally, we present a comprehensive discussion of findings and a set of empirical guidelines. We conclude the paper with the limitations of our work and plans for future investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">DIFFERENTIAL PRIVACY</head><p>Differential privacy is classically defined for input data represented as a single table, in which each row contains information about an individual. The formal definition is as follows <ref type="bibr" target="#b13">[15]</ref>:</p><p>A randomized algorithm A satisfies ε-differential privacy if for all databases D and D that differ on one record, and for any subset of outputs S ⊆ Range(A),</p><formula xml:id="formula_0">Pr(A(D) ∈ S) ≤ e ε × Pr(A(D ) ∈ S)</formula><p>Since differentially private algorithms are randomized, we can think of the algorithm's output, on a given input, as a probability distribution over possible outputs. The definition requires that, if the algorithm runs on any two databases that differ on the details of any individual's record, the output distributions will be "close", where close is formalized by the e ε term. Consequently, seeing the output of the algorithm cannot reveal much about any single contributor's data. The privacy parameter ε, therefore, controls the level of privacy protection: smaller ε means a stricter limit on privacy loss and, in general, this means the algorithm output will be able to communicate less information about the underlying data.</p><p>The data owner must choose an ε value to grant to a user of sensitive data. This parameter can be thought of as a privacy loss "budget". Granting a higher ε to a user means they can receive more accurate results from the private algorithm. In the research literature, a common value for ε is 0.1, in which case e ε ≈ 1.1 and the likelihood of any output cannot differ by more than about 10% on inputs that differ by one record. In practical deployments, higher ε values have been used and may still provide reasonable privacy protection. In this paper, we explore a range of ε values because it is one factor that impacts the effectiveness of private visualizations.</p><p>Laplace Mechanism A standard method for achieving differential privacy is the Laplace Mechanism (although there are many other mechanisms). When the Laplace Mechanism is used to answer a query over a sensitive database (e.g., how many people have the marital status of "divorced") the true query result is computed on the data and then carefully calibrated noise is added to the answer before it is returned to the user. In particular, a sample is drawn from the Laplace distribution with mean zero and a specified scale factor determined by the ε parameter and a property of the query called its sensitivity. The process is ε-differentially private, and the resulting "noisy" query answer may be shared with the user. The formal definition of the Laplace mechanism is as follows <ref type="bibr" target="#b13">[15]</ref>:</p><p>Let f (D) denote a function on D that outputs a vector in R d . The Laplace Mechanism is:</p><formula xml:id="formula_1">A LM (D) = f (D) + (Z 1 , ..., Z d ) where Z i are i.i.d random variables from Laplace(Δ f /ε).</formula><p>Above, Laplace(b) denotes the Laplace probability distribution centered at 0 with scale b, and Δ f is called the sensitivity of f and is the maximum difference in f between any two databases D and D that differ only by a single record:</p><formula xml:id="formula_2">Δ f = max D,D f (D) − f (D ) 1 .</formula><p>The Laplace Mechanism is commonly used when f is a histogramgenerating function, which counts the number of records in a set of disjoint ranges or categories. In this case, adding or removing a single record to the input will only affect the counts in one of the histogram bins by precisely 1. Thus the sensitivity of f is 1, and the Laplace Mechanism adds random noise sampled from Laplace(1/ε) to each histogram bins and releases the noisy histogram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 1 Consider the Census data introduced above and the vector-valued histogram function that returns the count of people with each of seven possible marital statuses.</head><p>If the true counts are 100, 51, 9, 45, 134, 123, 12 the noisy counts returned by the Laplace Mechanism using ε = 1.0 might be 102.1, 49.9, 9.6, 44.4, 134.9, 121.5, 11.0 , the result of adding independent samples to each count from the distribution Laplace(1). With 95% confidence, samples from this distribution will fall within −3 and 3, which is modest noise and, for example, would allow us to reliably identify the fifth status as the most frequent. Using ε = .1, the confidence interval is <ref type="bibr">[−30, 30]</ref>, and such random noise could distort conclusions on the most frequent status.</p><p>Using a smaller privacy parameter produces noisier output and, therefore, less utility. However, the relationship between privacy and utility could depend on the design of the private algorithm, the task being performed, and the underlying input data. One major goal of this work is to better understand this tradeoff for private visualization.</p><p>The differential privacy research community has worked actively on designing algorithms that offer the highest accuracy for a given degree of privacy protection. Much of this work is task and domainspecific. For example, there are algorithms for privately releasing sets of aggregate statistics (e.g., <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b50">49,</ref><ref type="bibr" target="#b51">50]</ref>), algorithms for private learning classifiers (e.g., <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b36">37]</ref>), and algorithms for privately analyzing motifs in graphs (e.g., <ref type="bibr" target="#b25">[26]</ref>). While differentially private algorithm design has been a subject of intense research effort in recent years, the task of presenting or exploring data through visualization, under the constraint of privacy, has received far too little attention given its obvious importance for users trying to gain insights from data. <ref type="figure">Fig. 2</ref> provides an overview of the private visualization pipeline. Sensitive input data is privatized, for a given ε, using some differentially private algorithm, to getD. This noisy estimate of the true data is used as input to a visualization tool, which produces a visualization as output. BecauseD is differentially private, the resulting visualization enjoys this property as well. Users then use the visualization for analysis and decision making. We observe that two types of error can impact the user's success in performing an analysis task: 1) errors caused by the injection of noise and resulting alterations of data values and visual patterns, and 2) perceptual and cognitive errors. Part of our investigation aims at understanding the two uncertainty sources and how they interact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Privacy-preserving visualizations</head><p>The goal of a privacy-preserving visualization is to protect individuals' identities and sensitive information from exposure while still allowing users to make sense and gain knowledge from it. Some prior work in this area has investigated the use of visual uncertainty for preserving privacy. Dasgupta and Kosara <ref type="bibr" target="#b11">[13]</ref> introduced a pixel-based clustering technique for parallel coordinates called "Screen-Space Sanitization" that combines pixels to increase visual uncertainty in areas of visualization where privacy could be breached. Using a similar approach, Archambault et al. <ref type="bibr" target="#b2">[4]</ref> and Oksanen et al. <ref type="bibr" target="#b33">[34]</ref> suggest the aggregation of visual components for building privacy-preserving histograms and heatmaps. Deliberate reduction of visual accuracy increases visualization uncertainty and reduces the possibility of guessing the exact values, but does not satisfy a rigorous definition of privacy that can provably resist attacks.</p><p>Data sanitization techniques (e.g., k-anonymity, l-diversity, and tcloseness) have also been investigated for building private visualizations. GraphProtector <ref type="bibr" target="#b45">[45]</ref> supports building privacy-preserving graphs of social networks. Users can combine multiple privacy protection schemes as a hybrid approach to fine-tune privacy protection. Chou et al. utilize data sanitization to build private Sankey and Iceplot visualizations for representing temporal event sequence data <ref type="bibr" target="#b6">[8]</ref> and constructing private network visualizations <ref type="bibr" target="#b5">[7]</ref>.</p><p>Bhattacharjee et al. <ref type="bibr" target="#b3">[5]</ref> provided a thorough and systematic analysis of state-of-the-art approaches, methods, and techniques used in privacy-preserving data visualization, and reflected on a wide range of challenges and research opportunities. Prior work mainly assumes that the data owner designs and deploys privacy mechanisms specific to the domain and visualization types, and the end-user consumes the private visualization product. This approach enables building effective private visualizations for specific tasks, visualizations types, and data domains. However, it may not work in exploratory data analysis where a user's questions and tasks are not known in advance. Currently, we lack a domain-agnostic understating of the relationship between tasks, visualizations, and privacy. The majority of prior work has also been focusing on using syntactic privacy models based on anonymization, which have fallen prey to a range of attacks <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>To fill these gaps, we investigate the use of differential privacy in exploratory data analysis. Wang et al. <ref type="bibr" target="#b46">[46]</ref> developed a visualization technique that helps users to dynamically gauge the loss of utility for a single task by anonymizing multi-attribute tabular data through building matrix-based and tree-based models for utility and privacy. In this work, we aim to better understand the relationships between noise level, task, visualization, and participants' performance. Instead of proposing an approach to modify a specific visualization technique that meets the privacy guarantee, we investigate a more general pipeline of private visualization where we can easily swap in different private algorithms or visualization techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Privacy-Utility trade-off</head><p>There is an inevitable privacy-utility trade-off associated with all privacy-preserving mechanisms. Typically, a stricter guarantee of privacy results in more loss of information and hence lowers the accuracy and reduces analysis utility. For example, in the differential privacy model, using a smaller ε provides a stronger privacy guarantee, but reduces the accuracy of data analysis due to larger perturbation of data.</p><p>Deploying privacy mechanisms while balancing the privacy-utility tradeoff is a non-trivial task. It requires proper measurements and an understanding of both privacy and utility. The data mining community has proposed several metrics for evaluating the utility and quality of data after anonymization/privacy-preservation methods are applied. For example, DPBENCH <ref type="bibr" target="#b20">[21]</ref> is a principled framework for evaluating differential privacy algorithms for answering 1-D and 2-D range queries. Dasgupta et al. <ref type="bibr" target="#b11">[13]</ref> consider discernibility as a utility metric that measures the number of records that cannot be distinguished from one another. In the visualization field, Dasgupta et al. <ref type="bibr" target="#b10">[12]</ref> state that utility can be regarded as a function of visual uncertainty. They introduce metrics for quantifying the visual uncertainty in cluster-based visualizations such as scatterplot and parallel coordinates.</p><p>An investigation by Zhang et al. <ref type="bibr" target="#b52">[51]</ref> shows that the utility of performing visual tasks does not line up well with accuracy measures commonly used for algorithms answering range queries. In fact, the authors of <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b6">8,</ref><ref type="bibr" target="#b29">30]</ref> argue that the evaluation of utility should depend on user analytical tasks and how accurately they can be performed. Prior research (e.g., <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b6">8,</ref><ref type="bibr" target="#b10">12]</ref> has only investigated the impact of privacy on utility for a specific task, data, and visualization type. Taking a domain-and data-agnostic approach, in this work, we investigate the privacy-utility tension for basic data exploration tasks and visualization types.</p><p>Outside the realm of privacy, Saket et al. <ref type="bibr" target="#b38">[39]</ref> conducted a study to investigate the effectiveness of five basic visualization types in relation to ten common data exploration tasks. The effectiveness of visualization consists of three main metrics: the success rate of performing the task, the performance time, and user preference. Results show that the effectiveness of visualization varies significantly across tasks. To understand the effectiveness of private visualizations and how conclusions might change under privacy, we use a similar experimental design like the set of tasks and visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Communicating uncertainty under DP</head><p>Differentially private data, like data generated from many other privacypreserving techniques, is inherently uncertain. DP mechanisms achieve the privacy guarantee by adding noise to computations on the sensitive data, making any single output a random instance of some underlying distribution. Therefore, dealing with uncertainty is an essential aspect of differentially private data visualization.</p><p>There has been a rich line of work on visualizing under uncertainty. One common solution is to present the level of uncertainty explicitly. The uncertainty statistic can be represented as an overlaying layer encoded in the formats of error bars or summary plots <ref type="bibr" target="#b37">[38]</ref>. Sanyal et al. <ref type="bibr" target="#b39">[40]</ref> investigated the effectiveness of different glyphs and markers in conveying uncertainty. However, error bars can be hard to read in multidimensional visualizations. An alternative is to color-code uncertainty information. Maceachren et al. <ref type="bibr" target="#b30">[31]</ref> used hue and saturation to indicate Ꜫ <ref type="figure">Fig. 2</ref>: The pipeline of generating private visualizations. First, sensitive data D is privatized to getD by adding carefully calibrated noise using a differentially private algorithm. Next, privatized data is visualized using a visualization engine. Finally, a user performs data analysis tasks on private visualizations. Two major sources of error can impact the user's success in performing the task: 1) data perturbation errors caused by the injection of noise and alteration of data values and visual patterns, and 2) perceptual errors. The second type of error is common between private and non-private visualizations.</p><p>uncertainty levels, and Hengl et al. <ref type="bibr" target="#b22">[23]</ref> proposed mixing white pixels to represent high uncertainty. A critical first step towards communicating uncertainty is selecting metrics (e.g., standard deviation) to quantify uncertainty. This can be challenging for differentially private output. For simple algorithms like the Laplace mechanism <ref type="bibr" target="#b13">[15]</ref>, we could easily derive scale and variability of the noise from the privacy parameters. However, the computation of such uncertainty for complex algorithms can be hard. For example, the DAWA <ref type="bibr" target="#b28">[29]</ref> algorithm first applies grouping based on the characteristics of the input data distribution to achieve better accuracy. Thus each data group has different uncertainty levels and carefully designed approaches are needed to calculate these local uncertainty statistics privately.</p><p>In this work, we do not attempt to display uncertainty information to eliminate possible interference with users' task performance. Investigating methods and effects of communicating uncertainty for private visualizations a goal for our future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RQ1: INVESTIGATING THE UTILITY OF PRIVATE VISUALIZA-</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TIONS</head><p>To investigate RQ1, we conducted a crowd-sourced empirical study on Amazon Mechanical Turk 1 . The rest of this section provides detailed information about the design of the study, the data analysis process, and our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>IPUMS-CPS <ref type="bibr" target="#b40">[41]</ref> is a collection of datasets that harmonizes microdata from the monthly U.S. labor force survey and the Census Current Population Survey (CPS), covering the period 1962 to the present. We used a data extract which is a subset of the Annual Social and Economic (ASEC) data from 2010. We chose this population survey data for two main reasons. First, it is similar to the data that could soon be protected (by the U.S. Census Bureau) using differential privacy. Second, it contains data attributes with which many study participants will be familiar, hence reducing the chance of failed tasks due to a user's unfamiliarity with the data semantics.</p><p>The data extract contains personal survey information on 159,277 individuals, each contributing one row to the dataset. For our experiment, we selected a subset of numerical and categorical attributes: Age, Sex, Race, Marital status, Education status, and Total income. Selected data were organized in a tabular format where each row represented information about an individual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Private algorithm</head><p>We selected the Laplace Mechanism as the privacy algorithm in our study. Although there are several other algorithms (i.e., <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29]</ref>) for generating private histograms, Laplace is relatively simple, fast, and competitive for the task of generating a single private histogram <ref type="bibr" target="#b20">[21]</ref>. It offers a good compromise in terms of speed and utility and acts as a building block for many more complex algorithms.</p><p>In a post-processing step, we modified the output of the Laplace mechanism and replaced all the negative counts with zeros. The rationale behind this decision was to eliminate the change of producing private histograms with negative values for some of the bins which are clearly invalid. As introduced in Section 2, the differential privacy guarantee will not be compromised by this simple post-processing step. We consider the non-negative histogram to be the final privatized data and use it in later visualization steps. Since all differentially private algorithms are randomized, any single output is only a random sample from a distribution. For each experimental setting, we choose five random seeds that define randomized trials. Visualizations and tasks are judged on the average performance over these random trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Privacy Parameter Setting</head><p>In this study, we considered three privacy levels of privacy parameter: 1) ε = ∞, 2) ε = 0.01, and 3) ε = 0.001. As mentioned in Section 2, a smaller privacy parameter enforces stronger privacy. An ε = ∞ results in a non-private visualization which offers no privacy guarantee but also implies no noise. This non-private setting provided a baseline against which we assessed the utility of private visualizations. The value ε = 0.001 offers a stronger privacy guarantee and requires more distortion of the data compared to the value ε = 0.01. Both values might be considered low ε in practice. However, we are studying the release of a single visualization while in practice many releases would be made and a global ε bound needs to govern all interactions. In addition, the impact of noise is dependent on the size of the dataset thus the choice of ε is also dependent on the dataset. The selection of these ε thresholds was based on experimentation and preliminary testing with the study dataset. In particular, we paid careful attention that selected ε values offer strong privacy but are not too strict that the noise added leads to completely useless private visualizations.</p><p>Our goal in this work is to understand the regime in which noise from the privacy mechanism impacts the utility of private visualizations. As such, these carefully engineered ε values suit our purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Participants</head><p>We recruited a total of 204 subjects based in the U.S., with an approval rate greater or equal to 95%. Each subject was allowed to participate in the study only once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Tasks</head><p>Following prior research on task-based effectiveness of basic visualizations <ref type="bibr" target="#b38">[39]</ref>, we used the Amar et al. <ref type="bibr" target="#b1">[3]</ref> taxonomy of low-level data analysis tasks for selection of study tasks. Those tasks are real-world tasks users came up with while exploring datasets with different visualizations tools and have been used in different studies for visual effectiveness evaluation. We excluded two tasks Find Correlation and Order which involve two variables and could not be performed on univariate visualizations. The 8 selected low-level tasks act as building blocks of more complex tasks. The following is a list of selected tasks. For each task, we also provide a concise explanation of how they were used, along with an example. We use the term "visualization feature" in the following descriptions to refer to element(s) in visualization such as: a bar in a bar chart, a group of points in a scatter plot, or a peak in a line chart: Find Anomalies We asked participants to find visualization features with abnormal values. We manually modified the visualizations to include easy-to-detect anomalies like zero counts and extremely large counts. For example, which Age Range has abnormal Group Size?</p><formula xml:id="formula_3">Retrieve</formula><p>Cluster We asked participants to put visualization features of similar values into the same cluster and report the number of clusters. For example, what is the number of clusters based on the Group Sizes of Income groups?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Visualization types</head><p>In this study, following prior empirical work <ref type="bibr" target="#b38">[39]</ref>, we examined four visualization techniques that are commonly incorporated in various visualization dashboards <ref type="bibr" target="#b27">[28]</ref>: bar chart, pie chart, line chart, and scatterplot. To generate the visualizations, we took the private output of the Laplace mechanism and used the Matplotlib <ref type="bibr" target="#b23">[24]</ref> visualization library to plot the privatized data. To maintain visual consistency, we fixed the chart size to be 500 by 350 pixels and the font size 12. We used Matplotlib's default color palette to generate pie charts and the same blue color for visual elements in other plots. The participants only viewed the final visualization and were not aware of the existence (or lack thereof) of noise in the encoded data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Experimental procedure</head><p>Instructions and warm-up tasks At the beginning of each study session, a participant was given a brief written description of the purpose of the study, the data that would be collected, and their rights, together with a consent form. Upon consenting to participate, the participant was given information about the workflow of the study and a quick optional tutorial explaining the visualization techniques used in the study. Next, the participant performed a short warm-up session answering one sample question for each task. Warm-up questions were similar to the actual study questions but performed on a manually synthesized dataset. During the warm-up practice, the participant received feedback on whether their answer was correct along with corresponding explanations. After the successful completion of the warm-up session, the participant moved on to the actual study tasks.</p><p>Main questions For each combination of task, visualization, and privacy level, we sampled 3 univariate histograms from 3 different attributes. As introduced in Section 2, differentially private algorithms are randomized, making every output a single sample of a probability distribution. Thus, for each experimental configuration, we generated five differentially private outputs using different random seeds. This results in a total of 180 different questions (4 Visualizations × 3 Histograms × 3 Privacy Levels × 5 Random Seeds) for each task.</p><p>In the main experiment, each participant answered a sequence of 48 multiple-choice questions, organized as 6 randomly sampled questions for each of the 8 tasks. For each question, we showed the user a single private visualization together with a brief description of the task and data. Given the visualization, we asked the participant to answer a single question associated with one of the eight tasks outlined above. The participant would move on to the next question after submitting their answer to the current question. The average completion time for the study was around 15 minutes, and we paid each user two dollars.</p><p>Validation Low-quality responses are not rare in online crowdsourcing studies. To have a better sense of the overall quality of a user's responses, we introduced validation questions as recommended in <ref type="bibr" target="#b34">[35]</ref>. For each worker, we randomly injected four validation questions, which are exact replicates of the warm-up questions seen before in the instructions. We considered the responses provided by a worker valid only if they answered three out of the four validation questions correctly. Otherwise, all responses from the worker would be discarded since they either failed to understand the task or perhaps made selections randomly.</p><p>Data collection Throughout the study, we collect worker responses to the multiple-choice questions and record the time they used to answer each question. At the end of the study, we ask the worker to fill out a simple demographic questionnaire asking about their gender and approximate age. Finally, we ask them to rate the overall difficulty of the question on a ten-point scale and provide short text feedback if they choose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Data analysis</head><p>We collected responses from a total of 204 MTurk workers and filtered out low-quality data according to the validation criteria described in Section 4.7. Among these workers, 176 finished the study and provided valid responses (105 male, 69 female, 2 other). 73% workers are in the age range from 18 to 40 years old; the rest are above the age of 40. On a scale of 1-10 (where 10 is the most difficult), the workers reported an average difficulty score of 4.25 (out of a maximum of 10). This shows our questions have a reasonable level of difficulty and that most people did not find the tasks confusingly difficult or trivially easy.</p><p>We analyzed collected data to quantify participants' performance in terms of time and accuracy under different experimental conditions. While the analysis of performance time was a straightforward process, the assessment of accuracy was challenging. Typically, a user's success in performing a task on a non-private visualization is assessed by determining whether the user 1) correctly identifies the visual artifact(s) of interest as requested by the task, and 2) correctly decodes the visualization to retrieve or derive values and draw conclusions. However, a similar assessment of user success cannot be used under private visualization. Due to the injection of noise and consequent perturbation of data, evaluating only the two aspects cannot guarantee user success in visual tasks with respect to the underlying sensitive data. In this work, we evaluate task success in terms of perceptual accuracy and perturbation accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.1">Dichotomous assessment of task success under DP</head><p>Perceptual accuracy To capture the information loss in human perception and cognition while performing visual tasks, we measure the  perceptual accuracy defined as the rate of "perceptual successes". Here we compare the participants response with the task answer based on the encoded data, whether or not noise has been added to the visualized data. The response is considered a perceptual success if it matches the encoded answer, although it could be different from the answer based on the true data. For instance, if a user task was to "find the group with largest value" using a private bar chart, we considered the user perceptually accurate only if they successfully found the highest bar in the noisy bar chart. Perceptual accuracy describes a users ability to perform visual tasks, consistent with the assessment of visual effectiveness in prior work <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>Perturbation accuracy Continuing with the example task of finding the group with the maximum count, there are other potential sources of task failure. Even if the user had a perceptual success, there are chances that the highest bar in the private visualization is different from the one in the non-private visualization due to noise injection. In such a case, the user still failed to gain accurate information from the non-private data source. To isolate and measure the information loss from noise injection of the private algorithms for data exploration tasks, we introduce the notion of a perturbation failure. We compare the results of performing a task on the non-private sensitive data and its privatized counterpart after noise injection. If there is a mismatch, then it is considered a perturbation failure. Perturbation accuracy for a task is defined to be the rate of perturbation success after noise injection.</p><p>Perturbation for privacy may dramatically change the overall patterns of data, causing failures for summary tasks. It may also lead to changes in individual values, making tasks related to value retrieval fail. Due to the injection of noise, exact retrieval of data value is not feasible.</p><p>Taking a heuristic approach, we considered an error tolerance range to decide if the distance between the non-private and private answers was acceptable. More specifically, we considered a range of ± 1K in which estimation errors were tolerated. For instance, for the non-noisy value of 10K, we accepted any answer in the range of [9K-11K] as acceptable. This error tolerance range was based on careful experimentation with our dataset and consideration of the range and distribution of data values. The histograms used in the study have average values of around 10K to 20K, so the tolerance range is approximately 5% to 10% of the data values.</p><p>We consider a visual task successful if both the perturbation and perceptual conditions are satisfied, meaning the information needed to perform the specific task is preserved after the perturbation and the user successfully performs the task on the noisy data. We evaluate all the tasks in relation to perceptual accuracy and perturbation accuracy using this dichotomous model.</p><p>In the analysis of perceptual effectiveness, we conducted a one-way repeated measures analysis of variance (ANOVA) for each task to test the differences of effectiveness across different visualizations and tasks. The performance time data was not normally distributed, so it was log-transformed to meet the normality assumption. In the analysis of perturbation error, to avoid the influence of perceptual uncertainty, we <ref type="figure">Fig. 4</ref>: Perceptual accuracy for different analysis tasks, visualization types using different privacy budget. As the privacy level gets stricter (less privacy budget), the perceptual accuracy changes for some configurations. The noise added for privacy protection needs influences people's ability to perform visual tasks. conduct the task using only the data values without any visualization. The calculation of perturbation accuracy is done off-line and involves no users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Findings</head><p>First, we investigate the perceptual effectiveness of the four visualization types and compare the success rate and (log-transformed) response time. Consistent with effectiveness comparisons conducted in an earlier study <ref type="bibr" target="#b38">[39]</ref>, we found that bar chart and scatterplot are the visualization types that are most accurate and have the best response times, while pie chart has the worst response time but higher accuracy than line chart. <ref type="table" target="#tab_2">Table 1</ref> shows detailed comparisons with the results of ANOVA tests.</p><p>Next, <ref type="figure" target="#fig_0">Fig. 3</ref> shows the perturbation accuracy trends with varying privacy levels across analysis tasks. For all the tasks, task success rates on perturbed data drop as we move to higher noise levels (i.e., smaller ε). This was an expected outcome since the privacy-utility tension is a known phenomenon under differential privacy. While the rates of accuracy decline seem to be almost consistent within the tasks, there are noticeable differences between them. In particular, we found perceptible differences between summary tasks, including Filter, Characterize Distribution, Find Anomalies, Find Maximum, and value tasks including Retrieve value, Compute Derived Value, and Determine Range. At a similar level of noise, the rates of accuracy loss for value tasks are higher than those of summary tasks. This finding suggests that different tasks might have varying degrees of noise tolerance. The task Cluster showed a mixed pattern where the success rate was highly preserved for a lower level of noise but then sharply plummeted as the noise increased.</p><p>Furthermore, we want to see if noise injection influences the users' ability to perform visual tasks. Small multiples in <ref type="figure">Fig. 4</ref> show the further breakdown of perceptual accuracy over different privacy levels. We omit the result for performance time because there is no significant difference in participant response time across different noise levels. It is interesting to see that the average perceptual accuracy drops slightly as we move to stricter privacy levels (i.e., smaller privacy budgets) for many tasks and visualizations. For task Characterize Distribution, the privacy budget has significant impact on the visual accuracy of scatterplot (F 2,14 = 2.99, p &lt; 0.1). For task Determine Range, the privacy budget used influences visual accuracy of bar chart (F 2,14 = 4.94, p &lt; 0.1). For task Cluster, visual perception of both scat-terplot (F 2,14 = 5.64, p &lt; 0.1) and bar chart (F 2,14 = 7.13, p &lt; 0.1) are influenced by the noise level. This shows that visual tasks, especially the more complex summary tasks, can become harder for people when the underlying data is noisy. In other words, the information loss from data perturbation could lead to a higher level of uncertainty in visual perception. However, unlike perturbation accuracy, the influence of noise injection isn't always monotonic. Users' ability to accurately perceive information from visualizations could increase or decrease as more noise is added. To better understand this effect, we conduct a second phase of our study in the next section. shows our proposed model for tuning noise injection to tasks using our suggested distribution metrics. First, sensitive data is privatized using alternative DP algorithms (e.g. Algorithms 1, 2 &amp; 3). All the privatized data meet a certain required level of privacy (similar ε). Next, based on the task at hand (e.g., Find the group with maximum value), the related distribution metric (e.g., Peakedness Score) is utilized to calculate a score for each set of privatized data. The privatized dataset with the highest score offers a data distribution shape that will better support the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RQ2: TAILORING NOISE INJECTION TO ANALYSIS TASK</head><p>Prior work in data visualization has shown that characteristics of underlying data such as distribution shape impact visualization in perceptible ways <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b43">43]</ref>. As a simple example, it is easier to find the bin with maximum value in a unimodal histogram with values 11, 10, 30, 12 than a flat histogram with values 11, 10, 13, 12 . The same level of privacy protection can be achieved by various DP algo- rithms (e.g., <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29]</ref>). However, depending on the specific mechanism chosen, the injection of noise can lead to entirely different data distributions, which are consequently reflected in private visualizations. Drawing on the findings from both fields, we investigated the possibility of tuning the noise injection to result in a private data distribution that will facilitate performing a certain task assuming we have the advanced knowledge of the task at hand and privacy level required.</p><p>In this work, we suggest a way of tuning the noise injection for summary tasks. <ref type="figure" target="#fig_1">Fig. 5</ref> provides a schematic of our approach. At the core of our model lie "distribution metrics" that quantify the distribution shape of private data. This enables us to compare the privatized output of several algorithms and select one that would best support a task. In the following section, we provide details of our suggested metrics:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Distribution Metrics</head><p>Inspired by prior work on Scagnostics (e.g., <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b48">47,</ref><ref type="bibr" target="#b49">48]</ref>), we suggest three distribution metrics which quantify the shape of the data distribution. Each metric is designed and corresponds to a specific summary task. The reason for focusing on summary tasks was that the success of these tasks mainly relies on the user's perceptual accuracy which in turn is related to the shape of the data distribution <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b44">44]</ref>. While for value tasks, there are no consistent relationships between peoples ability to read a single data point and the overall data distribution.</p><p>Peakedness Score: this metric is designed for the Find Maximum task. For x, it is calculated as:</p><formula xml:id="formula_4">P = m 1 ∑ n i=1 x i + 1 − m 2 m 1</formula><p>where m 1 , m 2 are the largest and second largest value of the distribution x. For higher Peakedness Scores, the max point stands out more and it is easier to perform the task Find Maximum accurately.</p><p>Anomaly Score: this metric is designed for the Find Anomaly task. It is calculated as:</p><formula xml:id="formula_5">A = max(|x i − mean( x)|) std( x)</formula><p>it finds the furthest point from the sample mean and normalizes the distance by the standard deviation of the distribution. The higher the score is, the more likely the point is an outlier and it is easier for a user to detect it visually.</p><p>Cluster Score: this metric is designed for the task Cluster. It is calculated using weights from soft clustering which yield soft assignments of data points to clusters. We generate the soft clustering weights from existing clustering results. In this work, we use the Mean-shift <ref type="bibr" target="#b7">[9]</ref> clustering algorithm which iteratively moves data points towards the mode. Unlike many other popular cluster algorithms, it does not require a pre-specified number of clusters. More specifically, given data x, each data point x i is assigned to a cluster Clu( j) using the hard mean-shift clustering. The soft assignment weight is the likelihood that a data point i belongs to cluster j:</p><formula xml:id="formula_6">L i, j = 1 ∑ c k=1 ( xi−c j xi−ck ) 2</formula><p>where c j refers to the center of the jth cluster.</p><p>The Cluster Score of a distribution is the sum of likelihoods for all data points in the assignment,</p><formula xml:id="formula_7">L = ∑ c i=1 L i,Clu(i)</formula><p>where Clu(i) is the assigned cluster index for each data point i. Similarly, the higher the clustering score, the more likely there will be coherent clusters with clear boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Preliminary Evaluation</head><p>To assess the feasibility of using our suggested model to tune the injection of noise for summary tasks, we investigate the influence of privacy mechanisms on the data distribution. More specifically, we chose three representative differentially private algorithms and empirically compare their output at the same privacy levels over multiple runs.</p><p>With metrics to measure the visual difficulty of data distributions, we still need to understand how noise injection influences these metrics and later visual perception. Next, we compare three widely used differentially private algorithms in terms of their impact on different distribution metrics. Besides the Laplace algorithm, we also consider the MWEM <ref type="bibr" target="#b19">[20]</ref> algorithm which iteratively updates the histogram using noisy data estimations and the DAWA <ref type="bibr" target="#b28">[29]</ref> algorithm which forms carefully chosen groups before noise injection.</p><p>We run these algorithms over 4 input histograms from the census data and measure the metrics of the noisy histogram. The upper row in <ref type="figure" target="#fig_2">Fig. 6</ref> shows average distribution metric scores over all the input histograms and 10 random trials for each configuration. The lower row shows their perturbation accuracy for the corresponding task.</p><p>A good private algorithm should push the distribution towards the easy side of the spectrum as much as possible while at the same time preserving the underlying task answer. In other words, we want algorithms that produce outputs with good distribution metrics which lead to good perceptual accuracy. But we do not want the algorithm to be exaggerating the visual pattern too much and causing a perturbation failure. For example, for task Find Maximum, the Peakedness Score is high using the privacy parameter 0.001. While at the same time, the perturbation accuracy is low, showing that the noise shifted the distribution too much and created an easy-to-perceive but incorrect peak. Thus, in this case, MWEM is not a good algorithm choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Findings</head><p>For the three summary tasks considered, the MWEM algorithm tends to provide the lowest perturbation accuracy and only provides better perceptual metrics for one task: Find Maximum. For the task Find Anomalies, DAWA and Laplace have comparable perturbation accuracy, and DAWA tends to produce higher perceptual metrics with a lower privacy budget. So it is best to use DAWA as the DP mechanism for this task to gain good end-to-end visual utility, outperforming Laplace by a small margin. For task Find Maximum and Cluster, Laplace has noticeably higher perturbation accuracy than the other two algorithms, making it a wise choice. In real-world data exploration, it is not always clear what the downstream tasks are. Our findings show that despite its simplicity, the Laplace mechanism is a safe general choice for DP algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>In this section, we reflect on our findings and discuss strategies to better support visual data analysis under differential privacy.</p><p>The findings of our study show that the rate of perturbation accuracy loss (for the same level of noise) differs between summary and value tasks. In particular, summary tasks seem to be more tolerant of the injection of noise while value tasks are noticeably more sensitive. This finding has an important implication: it enables users to more efficiently manage their assigned privacy budget while analyzing data. For instance, based on the knowledge that the summary task Find Anomalies is highly resistant to high levels of noise, they can spend a smaller fraction of their budget on this task. Considering that the amount of privacy budget assigned to a user has a limit, efficient budget management is very important. Similarly, understanding the higher sensitivity of value tasks to the injection of noise and their higher rate perturbation accuracy loss can benefit users. In this case, such knowledge can inhibit performing queries that would result in futile outcomes. For example, consider the value task Determine Range, with a severe loss of accuracy under high-levels of noise, the user can decide to increase the privacy budget spent on the task to get more reliable answers or avoid the task altogether. In the setting of our study, performing a task like Filter, Find Maximum or Find Anomalies with privacy parameter 0.001 only introduces less than 10% additional error compared to using privacy parameter 0.01 but saves 90% of the privacy budget. However, for a value task such as Retrieve value, the accuracy drop can be as significant as 60%, and it is worth spending more privacy budget to get acceptable accuracy.</p><p>Although various differentially private algorithms have been designed to achieve higher query accuracy, it remains unclear which algorithms or noise injection mechanism will better facilitate downstream visual analysis. Newer and complex algorithms like <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29]</ref> apply specialized techniques to increase the accuracy of target workload queries. However, our initial investigation shows that these techniques can produce visual artifacts that make the data "harder" when used in visual analysis tasks. For example, the MWEM algorithms can produce plateau-shaped distribution since it updates queries in groups identified by workload queries. Our findings show that, without a specific task, the simplest Laplace mechanism is the safe choice for private visualization.</p><p>Our work is the first in the confluence of differential privacy and visual data analysis that enables managing the privacy budget based on analysis tasks and visualization. This might be even more important for exploratory visual data analysis (EVDA). EVDA revolves around the continued formulation and evaluation of questions and hypotheses by the user. Many times, an analysis avenue does not result in any interesting insights and knowledge, and users move on to investigating other aspects of data. Under such conditions, the effective management of the privacy budget is even more critical. In practical data exploration, we do not always know the exact sequence of operations to perform ahead of time. So it can be hard to generate an optimal global allocation of privacy budget. However, with the knowledge about noise tolerance of tasks, we could go with a greedy approach trying to avoid spending too much of the privacy budget at each step in the iterative process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">LIMITATIONS AND FUTURE WORK</head><p>In designing this study, we paid careful attention to meet a high-level of internal and external validity. However, similar to any other empirical study, our findings, their implications, and derived guidelines and suggestions are subject to some limitations.</p><p>To investigate RQ1, we only considered the Laplace algorithm due to its relative ease of implementation, acceptable performance, and insensitivity to the dataset size. In the second part of this work (RQ2), we included two other algorithms MWEM and DAWA. However, there are several existing DP algorithms that could be utilized for generating private visualizations. One of our future directions is to extend the evaluation of RQ1 by including a more extensive range of DP algorithms.</p><p>In this study, we only investigate univariate visualizations. While univariate visualizations such as histograms are widely used, it remains important to extend our investigation to multivariate private visualizations. Multivariate private visualizations introduce several challenges such as: a wider variety of potential visualization types, more complex privacy algorithms to cope with sparser data, and, typically, greater noise relative to the magnitude of plotted statistics.</p><p>Since private data has inherent uncertainty, as future work, we also plan to investigate visualization techniques that use additional visual channels like error bars, summary plots <ref type="bibr" target="#b37">[38]</ref>, hue, and saturation of colormap <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b30">31]</ref> to encode the uncertainty.</p><p>We used simulations as the first step towards the assessment of our proposed distribution metrics. These preliminary evaluations provide initial evidence of the utility of these metrics. However, further user studies are required for assessing their practical usefulness. As part of our future work, we intend to evaluate these metrics while participants are performing open-ended visual data exploration. We aim to understand if the findings of this study will enable them to manage their privacy budget more efficiently, and also select DP settings that will improve their performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>In this work, we present the results of a crowd-sourced empirical study that investigates visual data analysis under Differential Privacy. We examine the effects of privacy levels (high, low, non-private), eight different analysis tasks, and four visualization types on participants' performance. Our findings show that summary tasks are more tolerant of the higher levels of noise than the value tasks. One of the main implications of understanding the relationship between task, level of noise, and accuracy is that it enables analysts to more efficiently manage and allocate their privacy budget. In this work, we also introduce a set of metrics that can be used to analyze the shape of data distribution before the injection of noise. The outcome of this analysis can then be used for tuning the DP model, such as the selection of a DP algorithm that provides better utility by reducing perceptual errors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 :</head><label>3</label><figDesc>Perturbation accuracy of different tasks for the non-private case (ε=inf), a low privacy level (privacy parameter ε = 0.01) and a high privacy level (privacy parameter ε = 0.001). Accuracy decreases as we spend less privacy budget. But the accuracy drop is more severe for tasks involving numerical value retrieval or estimation (e.g. Retrieve Value, Compute Derived Value)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 :</head><label>5</label><figDesc>This figure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 :</head><label>6</label><figDesc>(a) Task Find Maximum (b) Task Find Anomalies (c) Task Cluster For the three summary tasks considered, the upper row shows distribution metrics for different algorithms and the lower row shows task success rate from data perturbation at the corresponding privacy level.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• Dan Zhang is with University of Massachusetts, Amherst. E-mail: dzhang@cs.umass.edu. • Ali Sarvghad is with University of Massachusetts, Amherst. E-mail: asarv@cs.umass.edu. • Gerome Miklau is with University of Massachusetts, Amherst. E-mail: miklau@cs.umass.edu.</figDesc><table /><note>Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Value We asked participants to retrieve the value of a certain visualization feature. For example, what is the number of people in the Age Range 15-20?</figDesc><table><row><cell>Filter Given a range, we asked participants to identify visualization</cell></row><row><cell>features in that range. For example, which Age Ranges have</cell></row><row><cell>Group Size between 25,000 and 35,000?</cell></row></table><note>Compute Derived Value We asked participants to derive a new value using the visualization. For example, what is the sum of Group Sizes for Marital Status Single and Divorced? Find Maximum We asked participants to find the visualization feature with the largest value. For example, which Income Range has the largest Group Size? Determine Range For a set of visualization features, we asked partic- ipants to identify the range of their values. For example, what is the range of Group Sizes for all Age Ranges? Select the correct pair of minimum and maximum Group Size. Characterize Distribution Given a condition, we asked participants to identify the distribution of values based on the condition. For example, what is the percentage of Income Ranges that have Group Size larger than 25K?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Perceptual accuracy and response time comparison for each task showing visualization types that are significantly better or worse than others in terms of both accuracy and response time.</figDesc><table><row><cell>Task</cell><cell></cell><cell cols="2">Perceptual accuracy</cell><cell></cell><cell cols="2">Response time</cell></row><row><cell></cell><cell>Better</cell><cell>Worse</cell><cell>ANOVA</cell><cell>Faster</cell><cell>Slower</cell><cell>ANOVA</cell></row><row><cell>Retrieve Value</cell><cell>pie chart</cell><cell>-</cell><cell>F 3,44 = 2.61, p &lt; 0.05</cell><cell>bar chart</cell><cell cols="2">line chart F 3,44 = 4.71, p &lt; 0.01</cell></row><row><cell>Filter</cell><cell cols="2">scatterplot -</cell><cell>F 3,44 = 5.35, p &lt; 0.01</cell><cell>scatterplot</cell><cell>-</cell><cell>F 3,44 = 6.81, p &lt; 0.01</cell></row><row><cell>Compute Derived Value</cell><cell>-</cell><cell>-</cell><cell>F 3,44 = 1.19, p &gt; 0.05</cell><cell>-</cell><cell>pie chart</cell><cell>F 3,44 = 4.64, p &lt; 0.01</cell></row><row><cell>Find Maximum</cell><cell>-</cell><cell>-</cell><cell>F 3,44 = 0.90, p &gt; 0.05</cell><cell>-</cell><cell>pie chart</cell><cell>F 3,44 = 3.47, p &lt; 0.05</cell></row><row><cell>Determine Range</cell><cell>-</cell><cell>-</cell><cell>F 3,44 = 0.28, p &gt; 0.05</cell><cell>-</cell><cell>pie chart</cell><cell>F 3,44 = 4.50, p &lt; 0.01</cell></row><row><cell cols="2">Characterize Distribution -</cell><cell cols="2">line chart F 3,44 = 12.14, p &lt; 0.01</cell><cell>scatterplot, barchart</cell><cell>pie chart, line chart</cell><cell>F 3,44 = 15.38, p &lt; 0.01</cell></row><row><cell>Find Anomalies</cell><cell>-</cell><cell>pie chart</cell><cell>F 3,44 = 8.86, p &lt; 0.01</cell><cell>-</cell><cell>pie chart</cell><cell>F 3,44 = 35.57, p &lt; 0.01</cell></row><row><cell>Cluster</cell><cell cols="2">scatterplot -</cell><cell>F 3,44 = 3.74, p &lt; 0.01</cell><cell>scatterplot</cell><cell>pie chart</cell><cell>F 3,44 = 22.84, p &lt; 0.01</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.mturk.com</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We appreciate the comments of each of the anonymous reviewers. This material is based upon work supported by the National Science Foundation under Grant Nos. 1409143, 1741254.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Differentially private histogram publishing through lossy compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Acs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Castelluccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE 12th International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Low-level components of analytic activity in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization, 2005. INFOVIS 2005</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="111" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Archambault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hurley</surname></persName>
		</author>
		<title level="m">Visualization of trends in subscriber attributes of communities on mobile telecommunications networks. Social Network Analysis and Mining</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">205</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Privacy-preserving data visualization: Reflections on the state of the art and research opportunities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bhattacharjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">STAR</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The cost of privacy: destruction of datamining utility in anonymized data publishing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brickell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="70" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Privacy preserving visualization for social network data with ontology information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-K</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Pacific Visualization Symposium (PacificVis)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Privacy preserving visualization: A study on event sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-K</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mean shift: A robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Differentially private spatial decompositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Procopiuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE 28th International Conference on Data Engineering</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="20" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Timeseer: Scagnostics for high-dimensional time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="470" to="483" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring privacy and utility in privacy-preserving visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="35" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive privacy-preserving visualization using parallel coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2241" to="2248" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Revealing information while preserving privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dinur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="202" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Calibrating noise to sensitivity in private data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nissim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of cryptography conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="265" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rappor: Randomized aggregatable privacy-preserving ordinal response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ú</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pihur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Korolova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m">ACM SIGSAC conference on computer and communications security</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1054" to="1067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Data mining with differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schuster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="493" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Apple&apos;s &apos;differential privacy&apos; is about collecting your data-but not your data. Wired</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Greenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-06-13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Utility cost of formal privacy for releasing national employer-employee statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Machanavajjhala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Abowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kutzbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vilhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM International Conference on Management of Data</title>
		<meeting>the 2017 ACM International Conference on Management of Data</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1339" to="1354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A simple and practical algorithm for differentially private data release</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ligett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mcsherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2339" to="2347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Principled evaluation of differentially private algorithms using dpbench</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Machanavajjhala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 International Conference on Management of Data</title>
		<meeting>the 2016 International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="139" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Boosting the accuracy of differentially private histograms through consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>PVLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Maps are not what they seem: representing uncertainty in soil-property maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hengl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Toomanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Accuracy</title>
		<meeting>Accuracy</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="805" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Matplotlib: A 2d graphics environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Hunter</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2007.55</idno>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="90" to="95" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A practical differentially private random decision tree classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jagannathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pillaipakkamnatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE International Conference on Data Mining Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="114" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Private analysis of graph structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Raskhodnikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yaroslavtsev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1146" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Assessing effects of task and data distribution on the effectiveness of visual encodings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="157" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Vlat: Development of a visualization literacy assessment test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="551" to="560" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A data-and workload-aware algorithm for range queries under differential privacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>PVLDB</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the tradeoff between privacy and utility in data publishing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visualizing geospatial information uncertainty: What we know and what we need to know</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Maceachren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hopper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gahegan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hetzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cartography and Geographic Information Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="139" to="160" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Robust de-anonymization of large sparse datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
		<idno type="DOI">10.1109/SP.2008.33</idno>
	</analytic>
	<monogr>
		<title level="m">SP 2008. IEEE Symposium on</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="111" to="125" />
		</imprint>
	</monogr>
	<note>Security and Privacy</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">De-anonymizing social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shmatikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Security and Privacy</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Methods for deriving and calibrating privacy-preserving heat maps from mobile sports tracking application data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oksanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sainio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Westerholm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Transport Geography</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="135" to="144" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Kellogg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ways of Knowing in HCI</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2014" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards understanding human similarity perception in the analysis of large sets of scatter plots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3659" to="3669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Semisupervised knowledge transfer for deep learning from private training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05755</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visualizing summary statistics and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Riesenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="823" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Task-based effectiveness of basic visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saket</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Demiralp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A user study to compare four uncertainty visualization methods for 1d and 2d datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Amburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moorhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1209" to="1218" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Integrated public use microdata series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R S R</forename><surname>Sarah Flood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Warren</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>current population survey: Version 6.0 [dataset</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<idno type="DOI">10.18128/D030.V6.0</idno>
		<ptr target="https://doi.org/10.18128/D030.V6.0" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Scatterplots: Tasks, data, and designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="402" to="412" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Discriminability tests for visualization effectiveness and scalability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Veras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="749" to="758" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Advancing data curation with metadata and statistical relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Visengeriyeva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Graphprotector: A visual interface for employing and assessing multiple privacy preserving graph algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-K</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="203" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-K</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A utility-aware visual approach for anonymizing multi-attribute tabular data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="351" to="360" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Graph-theoretic scagnostics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization, 2005. INFOVIS 2005</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="157" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scagnostics distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="473" to="491" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Differential privacy via wavelet transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="225" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">DPCube: Differentially private histogram release through multidimensional partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goryczka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of Data Privacy</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Challenges of visualizing differentially private data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miklau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O'connor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
