<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename><surname>Tang</surname></persName>
							<email>tangtan@zju.edu.cn.y.wu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renzhong</forename><surname>Li</surname></persName>
							<email>renzhongli@zju.edu.cn.y.wu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinke</forename><surname>Wu</surname></persName>
							<email>xinkewu@zju.edu.cn.y.wu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhan</forename><surname>Liu</surname></persName>
							<email>shliu@zju.edu.cn.y.wu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Knittel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Koch</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ertl</surname></persName>
							<email>thomas.ertl@vis.uni-stuttgart.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyun</forename><surname>Yu</surname></persName>
							<email>lingyun.yu@xjtlu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiran</forename><surname>Ren</surname></persName>
							<email>renpeiran@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingcai</forename><surname>Wu</surname></persName>
							<email>ycwu@zju.edu.cn.y.wu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">T</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">J</forename><surname>Knittel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">L</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">P</forename><surname>Ren</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">are with Zhejiang Lab and State Key Lab of CAD&amp;CG</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">VIS/VISUS</orgName>
								<orgName type="institution">University of Stuttgart</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Software Engineering</orgName>
								<address>
									<settlement>Xi&apos;an Jiaotong-Liverpool University</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Storyline visualization</term>
					<term>reinforcement learning</term>
					<term>mixed-initiative design</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Example storyline visualizations created using PlotThread. The layouts are generated through a collaborative design between the AI agent and designers, while the styles and visual labels are customized manually to embellish the storylines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ing software evolutions <ref type="bibr" target="#b29">[31]</ref>. However, designing storyline visualizations has long been considered as a difficult and tedious task which involves balancing the trade-off between narrative constraints <ref type="bibr" target="#b43">[45]</ref> and aesthetic goals <ref type="bibr" target="#b23">[25]</ref>. To illustrate the evolutions of entity relationships, two primary narrative constraints <ref type="bibr" target="#b43">[45]</ref> should be followed:</p><p>• C1 the lines that represent characters who appear in the same scene should be grouped. • C2 otherwise, the grouped lines should be divided. Inspired by graph layouts <ref type="bibr" target="#b40">[42]</ref>, it is necessary to minimize line crossings and deviations to avoid dense visual clutter. Thus, three aesthetic goals <ref type="bibr" target="#b42">[44]</ref> are proposed to create legible layouts:</p><p>• G1 reducing line crossings • G2 reducing line wiggles • G3 reducing white space To ease the difficulty of designing storyline visualizations, previous studies <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b42">44]</ref> have developed optimization-based methods that produce storylines according to the design factors mentioned above. However, these methods mainly focus on producing aesthetic and legible layouts without considering the whole design space of storylines. With limited design choices, the storylines generated by the optimization models cannot cover the diverse narrative elements compared to the manually-created ones <ref type="bibr" target="#b43">[45]</ref>. For example, the hand-drawn storylines <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b43">45]</ref> adopt various layouts to indicate different plots.</p><p>To support the design of expressive storylines from the narrative aspect, researchers <ref type="bibr" target="#b43">[45]</ref> developed iStoryline that incorporates human design knowledge and creativity into the optimization models. Specifically, iStoryline formulates user interactions as mathematical constraints to control the optimization model <ref type="bibr" target="#b23">[25]</ref> so that users can focus on constructing storyline layouts that conform to their understandings of the stories. However, the interactions proposed in iStoryline mainly concentrate on modifying the local regions, which makes it time-consuming and labor-intensive to customize the overall layouts. For example, users may need to take a considerable number of actions to refine storyline layouts, which hinders the efficient exploration of the design space. Besides, the unpredictability of the optimization process may give rise to unexpected results, which requires trial-and-error practices to obtain the desired storylines.</p><p>To facilitate the easy design of storyline layouts, we envision whether a human-AI (Artificial Intelligence) collaborative approach can be helpful. Specifically, we intend to employ machine learning to develop an intelligent agent. Similar to a recommendation engine, the agent can reduce human efforts by providing users possible suggestions of compelling storylines that follow the aesthetic goals (G1 to G3). However, we are not aware of any prior work on designing storylines using machine learning, which raises two major challenges:</p><p>Model Architecture Storylines depict the temporal relationships <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b42">44]</ref> among entities that are inherently different from the Euclidean data (e.g., images, videos, and texts) that can be processed by existing machine learning applications <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b44">46]</ref>. Thus, it remains unclear whether storylines can be generated using machine learning or how to extend the existing models to deal with storylines. Recent studies <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b44">46]</ref> have adapted neural networks for graph drawings, but they mainly focus on the topological structure of graph layouts. While storylines and graphs pursue some common aesthetic goals (e.g., minimizing crossings <ref type="bibr" target="#b8">[10]</ref>), storylines require a higher aesthetic standard for legible layouts. Moreover, it is also necessary to develop a novel learning framework that takes narrative constraints into considerations for the storyline generation problem.</p><p>Model Training Training a machine learning model requires an appropriate loss function and a high-quality benchmark dataset <ref type="bibr" target="#b10">[12]</ref>. In image classification, for instance, the loss function can be easily defined as counting incorrect labels while the training data can be obtained by labeling real-world images <ref type="bibr" target="#b13">[15]</ref>. However, the training of the storyline model becomes more complicated than typical machine learning tasks. First, it is challenging to define "correct" layouts in terms of the different narratives since designers usually have different understandings about the stories. Thus, it is difficult to identify a unique loss function for the storyline generation problem. Second, there are not enough storyline visualizations available to train a machine learning model, even though previous work <ref type="bibr" target="#b43">[45]</ref> extended the collection of hand-drawn storylines.</p><p>In this work, we propose a novel reinforcement learning framework that trains an AI agent to design storylines "like" human designers. To support the collaborative design, the agent should follow two principles:</p><p>• D1 Storylines generated by agents should resemble the ones on which users are currently working to preserve their mental map. • D2 The agent should share the same action space as human users so that they can work on the same canvas collaboratively. Thus, the goal of the AI agent is to imitate and improve users' intermediate results instead of generating storylines from scratch. To achieve this goal, the agent should be capable of decomposing a given storyline into a sequence of actions, understanding the state of intermediate layouts, and have a foresightful plan for future actions. Therefore, we employ Reinforcement Learning (RL) to solve the challenges. Specifically, we define the states as the intermediate storyline layouts and define the actions of the agent as the same interactions implemented by iStoryline due to its success in producing diverse storylines that conform to different narratives. We further define loss function by maximizing the accumulative rewards that are vital for training RL models. To obtain sufficient training data, we follow the common practices <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b44">46]</ref> that generate well-optimized storylines with diverse visual layouts using the existing optimization approach <ref type="bibr" target="#b23">[25]</ref>.</p><p>As a proof of concept, we implement PlotThread that integrates the agent into the authoring process of storyline visualizations. We extend the interaction set of iStoryline to support a more flexible design of storylines and foster close collaboration between the agent and designers. We present the usage of PlotThread through a set of use cases (see <ref type="figure">Fig. 1</ref>) and validate its usability via expert interviews.</p><p>The main contributions are summarized as follows:</p><p>• We propose a novel reinforcement learning framework and generate a collection of high-quality storylines to train an agent that supports the collaborative design of storylines with designers. • We develop PlotThread, a mixed-initiative system that facilitates the easy creation of expressive storyline visualizations, and demonstrates its usage through a set of use cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We summarize critical techniques used in producing storyline visualizations and the state-of-the-art reinforcement learning techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Storyline Visualization</head><p>Storyline visualizations have become prevalent in revealing the evolution of stories <ref type="bibr" target="#b23">[25]</ref> and presenting various narrative elements <ref type="bibr" target="#b43">[45]</ref>.</p><p>To ease the difficulties in designing storyline layouts, researchers have proposed many (semi-) automatic approaches <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b42">44</ref>] that achieve the trade-off between aesthetic goals and narrative constraints using optimization models. Ogawa and Ma <ref type="bibr" target="#b29">[31]</ref> firstly proposed an automatic approach for generating storyline visualizations but their algorithm failed to produce aesthetic layouts due to the ignorance of the heuristic criteria. Tanahashi and Ma <ref type="bibr" target="#b42">[44]</ref> suggested a more comprehensive set of design considerations for storyline visualizations and proposed a layout generation approach based on genetic algorithms. Despite the success of producing relatively aesthetically-appealing and legible storyline layouts, their technique is inefficient to support interactive editing of storyline visualizations. For a better performance in both efficiency and the overall aesthetic quality, StoryFlow <ref type="bibr" target="#b23">[25]</ref> was developed to generate storyline visualizations using a hybrid approach that combines discrete and continuous optimization models. Moreover, it supports real-time interactions (e.g., bundling, removing, straightening) for users to edit storyline layouts. However, the automatically-generated storylines are not comparable to the hand-drawn illustrations <ref type="bibr" target="#b43">[45]</ref> in terms of the expressiveness because the automatic methods cannot cover abundant narrative elements, including plots, tones, etc.</p><p>To create more meaningful storyline visualizations that conform to designers' requirements, Tang et al. <ref type="bibr" target="#b43">[45]</ref> extended the design space of storylines that associates narrative elements with visual elements. They further developed iStoryline that integrates a set of high-level postediting interactions to support the flexible customization of storyline layouts. They developed a set of easy-to-use high-level interactions, but it is still inefficient to explore the design space and construct the overall layout using these fine-grained interactions. iStoryline automatically translates the high-level interactions into mathematical constraints which are further integrated into the optimization model <ref type="bibr" target="#b23">[25]</ref> to generate storyline layouts. However, users may obtain unexpected layouts due to the unpredictability of the optimization process, which requires trial-and-error practices to refine the results. To improve user experiences, we employ reinforcement learning to reduce users' effort in iteratively refining storyline visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Reinforcement Learning</head><p>Reinforcement learning refers to a system where an agent performs a task using a set of actions in an environment that can be represented by a set of states <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b47">49]</ref>. The learning process can be depicted by an agent predicting the "next" action based on the observed "current" state and obtain a reward <ref type="bibr" target="#b38">[40]</ref>, and the goal of the agent is to maximize cumulative rewards. Due to the emergent development of deep learning techniques <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b34">36]</ref>, deep reinforcement learning <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b45">47]</ref> (DRL) has burgeoned in fields like games <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b25">27]</ref> and painting <ref type="bibr" target="#b13">[15]</ref>. Mnih et al. <ref type="bibr" target="#b25">[27]</ref> proposed a deep Q-network to perform a group of challenging tasks in classic 2D games for the Atari 2600 console <ref type="bibr" target="#b3">[5]</ref> and achieved great success in surpassing the previous algorithms when performing the same tasks. To simulate a semi-realistic 3D world, Kempaka et al. <ref type="bibr" target="#b15">[17]</ref> introduced a new AI research platform called ViZDoom and further employed deep Q-learning and experience replay to train competent agents. To demonstrate how to teach machines to paint like human painters, Huang et al. <ref type="bibr" target="#b13">[15]</ref> employed a neural renderer in model-based DRL to train an agent that creates fancy drawings using a small group of strokes. Despite that reinforcement learning has become prevalent in various fields, we are not aware of any prior works on designing storylines. The issue of producing storylines is similar to the graph drawing problem <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b44">46]</ref> because their ultimate goal is to obtain welldesigned layouts. To achieve this goal, Wang et al. <ref type="bibr" target="#b44">[46]</ref> employ a graph-LSTM-based model to map graph structures to graph layouts directly, and Kwon et al. <ref type="bibr" target="#b16">[18]</ref> employ a deep generative model that uses an encoder-decoder framework to map training datasets into a latent space. However, the existing approaches are not applicable to our work because storylines pursue higher aesthetic criteria <ref type="bibr" target="#b33">[35]</ref> and need to balance narrative constraints <ref type="bibr" target="#b43">[45]</ref>. Thus, we intend to develop a novel reinforcement learning framework that trains an AI agent to design storylines like human users to support collaborative design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PLOTTHREAD</head><p>We develop a mixed-initiative tool <ref type="bibr" target="#b37">[39]</ref>, PlotThread, to facilitate the easy creation of storyline visualizations. We believe it is essential to combine both human and AI intelligence so that designers can produce creative storylines based on their design preferences and understandings about stories while the agent can reduce labor-intensive efforts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Design Considerations</head><p>The mixed-initiative application <ref type="bibr" target="#b19">[21]</ref> refers to a system where automated services (e.g., agents) and users work iteratively (i.e., taking turns) to perform tasks in the same context <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b28">30]</ref>. Design principles for mixed-initiative systems have been explored <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b12">14]</ref> to achieve effective collaboration between users and computers. To guide the design of PlotThread, we summarize two primary design considerations: DC1. Support a smooth collaborative design workflow. The AI agents could act as a stimulus for lateral thinking <ref type="bibr" target="#b6">[8]</ref> to inspire cocreativity <ref type="bibr" target="#b46">[48]</ref>. To foster effective human-AI collaboration, it is necessary to place the human at the center of visualization designs, while the AI agent should assist, rather than replace the designers <ref type="bibr" target="#b46">[48]</ref>. Hence, users should be granted enough control in the decision-making stage. One common practice is that the user takes the task-initiate <ref type="bibr" target="#b28">[30]</ref> in customizing an initial layout. Then, the agent proactively contributes to the design process by improving users' intermediate results and providing alternative designs based on users' input layouts. Moreover, users should be capable of further modifying and improving the AI-generated storyline instead of merely accepting or rejecting it. To follow this practice, it is essential to seamlessly integrate the AI agent into the authoring process and provide a smooth co-design workflow. <ref type="figure">Fig. 2</ref>. System workflow that supports a smooth and iterative co-design process between users and the AI agent. Users start the design process by customizing an initial storyline while the AI agent provides a set of suggestive alternative designs according to the user-specified layout.</p><p>DC2. Balance fine-grained and high-level interactions. It is burdensome for users to create storyline layouts while pursuing the aesthetic goals (G1 to G3). For reducing human efforts, the previous study <ref type="bibr" target="#b43">[45]</ref> proposed high-level interactions that can invoke the optimization model to re-layout storylines. The high-level interactions enable users to change the overall layouts while the aesthetic quality is ensured by the optimization model <ref type="bibr" target="#b23">[25]</ref>. While they are easy to use, the high-level interactions cannot fully support users' design requirements due to their limited flexibility. Conversely, fine-grained interactions focus on modifying the individual lines, so they are flexible enough to support various design requirements. However, they are also tedious and even require professional skills. Since "users may often wish to complete or refine an analysis provided by an agent" <ref type="bibr" target="#b11">[13]</ref>, we need to achieve a better balance between the high-level and fine-grained interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System Workflow</head><p>Our system has two actors, namely users and AI agents (see <ref type="figure">Fig. 2</ref>), to support the collaborative design of storyline visualizations. The existing storyline tools <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b43">45]</ref> employ a solo-authoring workflow where users are the only actor to invoke the design process while computers mainly provide flexible design tools to ease users' efforts. By incorporating the AI agent, we transformed the typical solo-authoring workflow into a divergent, collaborative design workflow where the agent can help users to explore the design space by providing alternative layouts. Following DC 1, users should first input a story script (see Appendix A1) into the system and an initial layout would be automatically generated by the storyline optimization model <ref type="bibr" target="#b43">[45]</ref> which conforms to the three aesthetic goals. Users can next modify the initial layout and then trigger the AI agent to generate various storylines proactively. The AI-generated storylines are displayed in a list so that diverse designs can inspire users. By default, we recommend the storyline layout which looks most similar to the user-specified one. Next, users can simply go ahead for further refinements or smoothly switch between different AI layouts. They can also reset to the original storyline when they are unsatisfied with the AI layouts. Compared with the solo-authoring workflow, the co-design workflow may invoke more novel and creative ideas because both users and AI agents can contribute to the design of storylines <ref type="bibr" target="#b46">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interactions</head><p>The core part of a mixed-initiative system entails user interactions which are vital to integrate human-AI co-creativity into the authoring process <ref type="bibr" target="#b18">[20]</ref>. To ease the difficulty of constructing storyline layouts, we first implement three high-level interactions inherited from a previous study <ref type="bibr" target="#b43">[45]</ref>, namely, shifting, bending, and scaling. Second, to support the design of expressive storylines, we also propose a set of novel interactions. According to DC2, the new interactions should enable users to modify the overall layouts without considerable efforts in designing the individual lines. Moreover, they should be more flexible than the high-level interactions since they do not invoke any storyline optimization model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">High-level Interactions</head><p>We only inherit the three interactions from the previous study <ref type="bibr" target="#b43">[45]</ref> because they can formulate user interactions as mathematical constraints which are further integrated into the optimization model to control the generation of storyline layouts. . PlotThread is composed of a menubar for (a) loading story scripts, setting canvas, and exporting storylines; (l) a toolbar that provides a set of easy-to-use interactions (b) to (i); The red lines indicate the interactions that change original layouts (black lines) into desired layouts (blue lines). (j) buttons for activating and stopping the AI agent and (k) a panel for presenting AI-generated layouts; (m) a setting panel for changing the parameters of storylines and (n) an embellishing panel for inserting icons or images into the canvas.</p><p>Shifting. The relationships among characters are visually revealed by the spatial proximity of the corresponding lines. To define the characters' relationship, shifting <ref type="figure" target="#fig_0">(Fig. 3b</ref>) enables users to drag an individual line to re-order the characters freely.</p><p>Bending. The plot evolution can be indicated by the overall layout of the storyline visualizations. For example, users can arrange the line groups in a certain direction to suggest that the story evolves into a positive or negative ending. Bending <ref type="figure" target="#fig_0">(Fig. 3d</ref>) enables users to easily bend a straight line into a curving line while the associated groups will be transformed automatically.</p><p>Scaling. The white space can be used to present different narrative elements, such as emphasizing separations between characters to present their relationships or making room for inserted images. Scaling <ref type="figure" target="#fig_0">(Fig. 3c</ref>) enables users to control the size of white space between lines or groups by dragging and moving the groups of lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Extended Interactions</head><p>We propose four types of extended interactions to support the design space <ref type="bibr" target="#b43">[45]</ref> that describes the design of storylines at four levels, namely, character, relationship, plot, and structure levels.</p><p>Transforming <ref type="figure" target="#fig_0">(Fig. 3g</ref>) is designed to change the overall trend of storyline layouts, which is at the plot level. Users should first select the scope with a circular brush, and then sketch a trajectory as the trend of the target layout. The specified path will be segmented automatically to guide the translation of line groups of the original storyline.</p><p>Attracting / Repelling <ref type="figure" target="#fig_0">(Fig. 3f and 3e</ref>) are designed to indicate the closeness between the line groups, which is at the structure level. After selecting line groups with a circular brush, users can draw a straight line to indicate whether the selected lines should be attracted or repelled.</p><p>Relating <ref type="figure" target="#fig_0">(Fig. 3h</ref>) is designed to assist users in visually presenting the relationships among characters using various visual elements, such as merged or twined lines <ref type="bibr" target="#b43">[45]</ref>, which is at the relationship level. After selecting the desired visual elements, users can choose the group of lines they want to relate with each other.</p><p>Stylishing <ref type="figure" target="#fig_0">(Fig. 3i</ref>) is developed for users to decorate the lines with diverse stroke styles (e.g., dash and zigzag), which is at the character level. Users first need to select a line style and then brush the target line which they want to embellish. Users can also highlight certain events or characters by directly inserting graphics or icons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Interface</head><p>Users first need to load data ( <ref type="figure" target="#fig_0">Fig. 3a)</ref> that are scripts recording characters and their scenic interactions. The AI-based creator can be triggered ( <ref type="figure" target="#fig_0">Fig. 3j</ref>) at any time during the authoring process and then provides a list of suggestive layouts based on users' layouts. As shown in <ref type="figure" target="#fig_0">Fig. 3k</ref>, the user-specified layout is shown at the top of the list to be compared with alternative layout designs. To inspire lateral thinking <ref type="bibr" target="#b6">[8]</ref>, we not only present the "final" layout that looks most similar to the user layout but also exhibit the intermediate layouts that demonstrate how the AI agent modifies storylines. Users can freely browse and adopt alternative layouts. We develop two panels ( <ref type="figure" target="#fig_0">Fig. 3m and 3n</ref>) to support the creative design of storylines where users can insert images, add icons, and change model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROBLEM OVERVIEW</head><p>Following the two principles (D1 and D2) of collaborative design, our goal is to train an agent that learns how to resemble users' intermediate layouts using a set of user-shared interactions. Furthermore, we want to leverage the aesthetic goals (G1 to G3) to produce well-optimized layouts. Thus, the agent is trained to predict the high-level interactions that can modify an automatically-optimized layout to resemble a user-created layout. The high-level interactions preserve the aesthetic quality of layouts as much as possible since we employ the optimization model <ref type="bibr" target="#b23">[25]</ref> to re-generate storyline layouts.</p><p>The problem is formulated as follows: given a user layout L u crafted by a user and an origin layout L o generated by the optimization model <ref type="bibr" target="#b23">[25]</ref>, the agent predicts the actions used to modify L o according to L u . Like human designers, the agent is designed to predict the "next" action by observing the "current" layout and imitating the user layout. To avoid local minima, the agent should balance current actions and future actions by maximizing the cumulative rewards after finishing the given number of actions, rather than the current gain. Inspired by the similar task of reproducing paintings <ref type="bibr" target="#b13">[15]</ref>, we employ reinforcement learning to achieve this long-term delayed-reward design.</p><p>In this section, we describe the entire process for designing the reinforcement learning framework from constructing storyline layouts, generating training datasets, building neural networks, and learning the storyline agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Storyline Layout Construction</head><p>Storyline visualizations depict how characters interact with each other. Generally, each line represents a character, and a group of lines indicates that the associated characters are together at a given time slot <ref type="bibr" target="#b26">[28]</ref>. Given a story with N characters and M time slots, the path of the i-th character C i can be described as a sequence of points [y 0</p><formula xml:id="formula_0">i , y 1 i ..., y M−1 i ]</formula><p>. The overall layout can be denoted as a set of characters L = {C i } N−1 i=0 which can be further depicted as</p><formula xml:id="formula_1">M pos = [y j i ] i=0,...,N−1; j=0,...,M−1<label>(1)</label></formula><p>The main difficulty in obtaining a storyline layout is the calculation of its position matrix M pos , which pursues the maximization of the aesthetic metrics (G1 to G3) while satisfying the primary narrative constraints (C1 and C2). Given that the performance of the existing storyline algorithms <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b43">45]</ref> has been considerably improved, we adopt iStoryline <ref type="bibr" target="#b43">[45]</ref> as the renderer to calculate the layout. First, iStoryline is implemented on the basis of StoryFlow to achieve a real-time generation for a large collection of storylines <ref type="bibr" target="#b23">[25]</ref>, which is vital for training an agent that needs to reproduce storylines for over thousands of hundreds of times. Second, iStoryline extends the optimization model of StoryFlow to integrate a more diverse set of narrative constraints, which is crucial for the agent to fully explore the overall design space and customize storyline layouts without losing too much aesthetic quality.</p><p>In PlotThread, we inherit three high-level interactions, namely, shifting, bending, scaling, from iStoryline, which insert three novel types of narrative constraints to the three optimization stages, namely ordering, alignment, and compaction <ref type="bibr" target="#b43">[45]</ref>. Next, we introduce how these high-level interactions are incorporated into the optimization model to enable an efficient customization of storyline layouts.</p><p>Shifting determines the vertical order of characters using a constrained crossing minimization algorithm <ref type="bibr" target="#b9">[11]</ref>, which generates ordering constraints using a set of order pairs</p><formula xml:id="formula_2">[o j i , o j i ] i,i &lt;N; j&lt;M where o j</formula><p>i indicates the order of the i-th character at the j-th time slot. The constraint suggests that the i-th character should be "ahead" of the i -th character at the j-th time slot. After solving the ordering algorithm <ref type="bibr" target="#b9">[11]</ref>, the order of characters during the whole timeline can be obtained using</p><formula xml:id="formula_3">M order = [o j i ] i=0,...,N−1; j=0,...,M−1 (2)</formula><p>Bending determines the straightness of characters along the timeline via the dynamic programming algorithm <ref type="bibr" target="#b23">[25]</ref>, which generates alignment constraints using a set of indicators [e j i ] i&lt;N; j&lt;M . The variable e j i is set to 1 when the i-th character are aligned at both the j-th and its previous time slots. By default, the indicators at the first time slot are set to 1 so that {e 0 i = 1} i=0,...,N−1 . After solving the dynamic programming <ref type="bibr" target="#b23">[25]</ref>, the alignment situations can be obtained using</p><formula xml:id="formula_4">M align = [e j i ] i=0,...,N−1; j=0,...,M−1<label>(3)</label></formula><p>Scaling determines the white space among characters through the least-square method <ref type="bibr" target="#b23">[25]</ref>, which generates compaction constraints using a set of inequalities</p><formula xml:id="formula_5">{d 1 &lt; |y j i − y j i−1 | &lt; d 2 } i&lt;N; j&lt;M where d 1 and d 2</formula><p>are numerical values to indicate the lower and upper bounds of the white space among the i-th and its last characters. After obtaining the results (Eq. 2 and 3) of the two previous optimization stages, the position matrix (Eq. 1) can be obtained by solving a constrained convex optimization problem which is detailed in Appendix A2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Training Data Collection</head><p>Training neural networks require a large number of high-quality datasets <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b22">24]</ref>. Although Tang et al. <ref type="bibr" target="#b43">[45]</ref> have extended the collection of hand-drawn storyline illustrations, the size of the dataset is too small for a machine learning task. Moreover, the manual production of training data is a labor-intensive task which requires considerate time and human resource. Inspired by the recent studies on graph drawings <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b44">46]</ref>, we generate a set of well-optimized storyline layouts using the optimization model <ref type="bibr" target="#b23">[25]</ref>. Although automatically-generated storylines are not comparable to the hand-drawn illustrations in terms of both aesthetic quality and expressiveness <ref type="bibr" target="#b43">[45]</ref>, our goal is to train an agent that can imitate users' layouts instead of generating storylines that are comparable or superior to hand-drawn ones.</p><p>To obtain considerate and diverse datasets, researchers have employed a grid search that applies different combinations of random parameters on the graph models <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b44">46]</ref>. Following this common practice, we use iStoryline <ref type="bibr" target="#b43">[45]</ref> to generate the training datasets due to its ability to produce aesthetic storyline layouts in a short time. Notice that iStoryline only receives two parameters, namely inner gap and outer gap, to determine the white space between individual lines and the groups of lines, respectively. Thus, merely modifying the model parameters cannot produce sufficient storylines with diverse layouts. We apply random searching in generating different narrative constraints described in Sec. 5.1, which are further integrated into the optimization model <ref type="bibr" target="#b23">[25]</ref> to control the diversity of storyline layouts. Mathematically, the training data is a set of storyline pairs &lt; L o , L u &gt; where L o is the origin layout generated by the optimization model directly, and L u is the "user" layout simulated by inserting randomly-selected narrative constraints into the optimization model <ref type="bibr" target="#b23">[25]</ref>. However, the simulated "user" layout L u may not be visually "better" than the origin layout L o because more narrative constraints are used to restrict the optimization of storylines. Since the goal of the AI agent is to provide a list of possible layouts according to users' layouts, the key of our RL model is to teach the agent to refine origin layouts and imitate users' layouts instead of producing extremely-optimized storylines.</p><p>Following the design considerations mentioned above, we first extract story scripts that describe characters and their scenic interactions from the hand-drawn illustrations 1 . Each story script records a set of time slots that indicate who are together at a given time. To ensure the diversity of training data, we evenly produce three groups of narrative constraints, namely, ordering, alignment, and compaction constraints with random parameters. We then randomly select K constraints from the three groups to obtain different layouts for the same story script. The selected constraints are the ground truth that the agent needs to learn and predict when modifying origin layouts L o to imitate user layouts L u . The variable K indicates how many steps the agent can have to reproduce user layouts. In our case, we set K = 15 because the agent should complete the authoring task within reasonable time to avoid losing users' attention. We obtain 20 story scripts from the published gallery and generate 1000 storyline layouts for each story. In total, we generate 20000 layouts to train the AI agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Model Architecture</head><p>Given a user layout L u and an origin layout L o , the agent aims to predict a sequence of actions {a k } K−1 k=0 where rendering a k on L (k) leads to L (k+1) . The initial layout L (0) can be obtained from the origin layout L o . The final layout L (K−1) can be obtained by rendering the consecutive actions, which should be visually similar to L u as much as possible. This design issue can be formulated as a Markov Decision Process <ref type="bibr" target="#b13">[15]</ref> with a state space S, an action space A, a transition function T (s t , a u ) and a reward function R(s t , a u ) <ref type="bibr" target="#b32">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">State and Transition Function</head><p>The state space describes all possible layouts that an agent can obtain after rendering actions. Mathematically, we define a state s u = (L (k) , L u , k) where L <ref type="bibr">(k)</ref> and L u refer to the layouts that can be represented by the position matrix M pos and the variable k indicates the k-th step for the agent. We further define the transition function s k+1 = T (s k , a k ) that describes the transition process between states s k and s k+1 , which is implemented by applying action a k on state s k . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Action</head><p>To support the collaborative design, we define the action space as the high-level interactions (discussed in Sec. 5.1) for three reasons. First, it is necessary for the agent to share the same action space with users so that they can work concurrently to design storyline visualizations. Second, the high-level interactions are implemented on the basis of the constrained optimization model <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b43">45]</ref> so that the agent can produce well-optimized layouts in terms of the aesthetic goals. Third, it is sufficient to modify storyline layouts with these interactions so that we do not include the other interactions proposed in PlotThread. Formally, an action a k of the storyline agent is a set of parameters that define a narrative constraint (e.g., ordering, alignment, compaction constraint). The behaviors of the agent can be further described using a policy function P : S → A that maps states to deterministic actions <ref type="bibr" target="#b38">[40]</ref>. After predicting action a k at step k, the state can evolve using the transition function s k+1 = T (a k , s k ), which runs for K steps <ref type="bibr" target="#b45">[47]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Reward</head><p>Reward is a stimulus for the agent to improve its prediction ability <ref type="bibr" target="#b25">[27]</ref>. Our goal is to guide the agent to resemble the layout on which users are working and produce alternative layouts to inspire co-creativity. We formulate the reward as the similarity between the user layout L u and the layout L (k) produced by the agent at step k. To quantify the layout similarity, we follow the well-established framework <ref type="bibr" target="#b23">[25]</ref> that measures storyline layouts in three aspects:</p><p>Ordering Feature The first step to obtain an aesthetic storyline layout is to determine the vertical order of characters. The ordering variable o j i (L) indicates the ranking position of the i-th character at the j-th time slot for the layout L. Based on that, we formulate the ordering similarity between the user layout L u and the layout L (k) at step k as</p><formula xml:id="formula_6">S (k) order = Comp(M Lu order , M L (k) order )<label>(4)</label></formula><p>Alignment Feature After obtaining the orders of characters, the second step is to determine the alignment situation of characters along the whole timeline. Given a layout L, the alignment variable e j i (L) indicates whether the i-th character is aligned at the j-th time slot and the previous slot. Following the same mathematical notations, we quantify the alignment similarity as</p><formula xml:id="formula_7">S (k) align = Comp(M Lu align , M L (k) align )<label>(5)</label></formula><p>Position Feature The last step for generating storyline layouts is to calculate the exact positions of characters by minimizing the white space of the overall layout. The position variable e j i (L) suggests that the position of the i-th character at the j-th time slot in the layout L. We calculate the position difference of the two layouts using</p><formula xml:id="formula_8">D (k) pos = Dist(M Lu pos , M L (k) pos )<label>(6)</label></formula><p>where Comp(•) is a counting function that self increment one if the corresponding values of two matrices are the same and Dist(•) is a distance function that calculates the difference between two matrices using Euclidean metric. We further employ sigmoid function S(•) <ref type="figure">Fig. 5</ref>. Learning algorithm for the AI agent: (a) use the optimization model <ref type="bibr" target="#b23">[25]</ref> to produce storylines; (b) measure the similarity between user-specified and "current" layouts to obtain the reward; (c) calculate the critic value to predict the "next" action.</p><p>to normalize the three visual features. Based on that, we define the similarity between the user layout L u and the k-th step layout L (k) using a linear scheme S(k) = ω 1 S(S</p><formula xml:id="formula_9">(k) order ) + ω 2 S(S (k) align ) + ω 3 S(D (k)</formula><p>pos ). The reward at k-th step can be obtained using r(s k , a k ) = S(k) − S(k + 1). To make the final result resemble the user layout, we maximize the cumulative rewards in the whole episode using a discounted scheme that R k = ∑ K k =k γ k r(s k , a k ) with a discounting factor γ ∈ [0, 1]. The default parameters [ω 1 , ω 2 , ω 3 , γ] are set to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">Network Architecture</head><p>Due to the high variability and complexity of narratives, we first normalize the input layout into a H × H matrix which can be regarded as a one-channel image (By default, we set H = 100). To extract the visual features from storyline layouts, we employ the network structure that is similar to ResNet-18 <ref type="bibr" target="#b10">[12]</ref>. Given that storyline layouts are less complicated than real-world images, we simplify the network structure by removing all convolution layers to preserve visual information. In our experiments, we discover that the fully-connected layers are capable of predicting actions for generating storyline layouts. To ease the difficulty of exploring the mix-type action space and stabilize learning, we separate the network architecture into three parallel components <ref type="bibr" target="#b15">[17]</ref> that aim at exploring the different parts of the action space. Specifically, every component is designed only to explore the action space of one of the high-level interactions (see <ref type="figure" target="#fig_1">Fig. 4</ref>). In the end, we employ a greedy function to calculate the reward and determine the action.</p><formula xml:id="formula_10">R k = K ∑ k =k γ k max a k r(s k , a k )<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Learning</head><p>We first introduce the standard setting for reinforcement learning <ref type="bibr" target="#b39">[41]</ref> where an agent interacts with an environment over a certain number of time steps, and then describe how to train the agent using the state-ofthe-art framework, namely, asynchronous advantage actor-critic <ref type="bibr" target="#b24">[26]</ref>. In a typical actor-critic model <ref type="bibr" target="#b30">[32]</ref>, researchers usually employ two neural networks to present actor and critic, respectively (see <ref type="figure">Fig. 5</ref>). An actor observes the environment by receiving an state s k and then predict an action a k at time step k, while a critic obtains the state s k to predict cumulative reward in the future. In general, the policy function π(a t |s t , θ π ) characterizes the actor's behaviors which can be formulated as a mathematical probability function. Since an agent aims to maximize the expected cumulative reward <ref type="bibr" target="#b14">[16]</ref>, the value of state s k under policy π can be defined as V π (s, θ V ) = E(R k |s k = s) that is the expected return for following policy π from state s. Hence, the problem of training a storyline agent is to obtain the parameters (θ π , θ V ) of the neural networks for the policy function π and the value function V . The updates on the model parameters <ref type="bibr" target="#b4">[6]</ref> can be written as </p><formula xml:id="formula_11">Δθ π ← Δθ π + ∇ θπ logπ(a k |s k ; θ π )(R k −V (s k ; θ V )) Δθ V ← Δθ V + ∂ (R k −V (s k ; θ V )) 2 ∂ θ V</formula><p>where Δθ π and Δθ V are the updates applied to the model parameter θ π and θ V , respectively.</p><p>However, training an agent in a complicated high-dimensional mix-type action space is difficult due to the unstable learning problem and the requirements of large computational resources <ref type="bibr" target="#b24">[26,</ref><ref type="bibr" target="#b48">50]</ref>. To overcome these issues, Minih et al. <ref type="bibr" target="#b24">[26]</ref> propose a novel asynchronous framework that enhances the existing RL algorithms, such as Q-learning <ref type="bibr" target="#b20">[22]</ref>, and actor-critic methods <ref type="bibr" target="#b30">[32]</ref>. The key idea is to use asynchronous actor-learners that run in parallel to explore different parts of the environment <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b24">26]</ref>. Instead of using different machines, the actor-learners are running on the different processes to remove the communication costs and improve training efficiency. Moreover, the researchers observe that it is more likely for the multiple actor-learners to be uncorrelated than a single agent when applying the overall changes to the model parameters. The updates applied to the parallel agent <ref type="bibr" target="#b24">[26]</ref> will be updated on the main agent to combine the asynchronous changes of the model parameters on different processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>Implementation. We employ a client-server architecture to develop PlotThread. The web interface is implemented using TypeScript <ref type="bibr" target="#b1">[3]</ref> and ECharts.js <ref type="bibr" target="#b7">[9]</ref> while the server side is implemented using Python and the popular machine learning library PyTorch <ref type="bibr" target="#b0">[2]</ref>. To support the flexible customization of storyline visualizations, we adopt the well-established graphic library, namely Paper.js <ref type="bibr">[1]</ref>. We also develop a storyline layout optimizer which is implemented using C# to modularize PlotThread.</p><p>To validate the effectiveness of the reinforcement learning (RL) model, we conduct both quantitative and qualitative experiments on four datasets. The input stories are visualized using the optimization model <ref type="bibr" target="#b23">[25]</ref> in <ref type="figure" target="#fig_2">Fig. 6a</ref>. We first show that the agent has leveraged both aesthetic and expressiveness in producing various types of storyline layouts. To simulate the real authoring process, we create four user layouts, including incline-, stair-, and wave-layout (see <ref type="figure" target="#fig_2">Fig. 6b</ref>), using the extended interactions that reshape the overall layouts without invoking optimization models. Apparently, the user layouts are twisted and do not satisfy the aesthetic goals, but they are regarded as more expressive in terms of the diverse visual forms. We then invoke the RL model to predict actions that can modify the initially-optimized layouts <ref type="figure" target="#fig_2">(Fig. 6a)</ref> to resemble the user layouts <ref type="figure" target="#fig_2">(Fig. 6b)</ref>. The results <ref type="figure" target="#fig_2">(Fig. 6c</ref>) indicate that our RL model can successfully capture the visual features from the user layouts and produce more expressive layouts than the initially-optimized ones. Despite that the AI-generated layouts seem to have more edge crossings than the initially-optimized layouts, they still preserve a satisfactory aesthetic quality compared to the user layouts. Thus, we believe our agent achieves a better trade-off between expressiveness and aesthetics even though it increases expressiveness at the cost of some aesthetic quality.</p><p>We also conducted quantitative experiments on a desktop with a CPU (3.7GHz) to evaluate the search power and time performance of the AI agent by comparing it with a baseline method. We repeated the experiments 4 times and calculated average values to avoid the influences of CPU scheduling. Since there are no prior RL models on designing storyline visualizations, we implemented a greedy algorithm that randomly selects a group of actions and then adopts the one that can improve the reward. We compare the AI agent with the greedy algorithm by measuring their convergence rates and time when performing the same tasks. As shown in <ref type="figure" target="#fig_4">Fig. 8a</ref>, the baseline method can improve the rewards dramatically in the short term but they are trapped in the local optimums finally. While the AI agent seems to have difficulties in searching the design space in the beginning, it finally achieves better performances than the baseline method in the long term. The results indicate that our RL model has successfully learned how to "think" when designing storylines and can sacrifice short-term rewards to achieve long-term planning. Moreover, both the AI agent and the baseline method can converge to final layouts within 12 seconds (see <ref type="figure" target="#fig_4">Fig. 8b</ref>). In PlotThread, we set the default steps of the agent to 15 which ensures a satisfactory response time for users' interactions. . The AI agent is then (e) triggered to produce suggestive storylines and (f) the desired one is selected. S/He further improves the AI-generated layout using high-level interactions, namely Scaling and Bending (g). The relationships among characters are revealed using (h) Relating, and the layout is (i) embellished to enrich the narration. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">USE CASES</head><p>In this section, we illustrate the usage of PlotThread. A storyline visualization called Justice League is created to describe the authoring process of customizing the layout with the assistance of the AI agent. This use case indicates how people and the agent can work together to achieves users' design requirements. Following the same procedure, we create more use cases (see <ref type="figure">Fig. 1</ref>) to demonstrate that PlotThread can be used to design various stories and produce diverse layouts.</p><p>As a proof of concept, we simplify the story of Justice League <ref type="bibr" target="#b36">[38]</ref> and only depict events that are vital for the evolution of the narrative. The story depicts how superheroes stand together and establish Justice League to fight against Steppenwolf, which can be roughly divided into three stages. First, Batman and Wonder Woman decided to recruit team members. They recruited The Flash, Cyborg, and Aquaman to save the world from the catastrophic threat caused by Steppenwolf. The second stage begins with the fight against Steppenwolf's invasion and the rescue act for Superman. But Superman attacked the other superheroes who try to rescue him since Steppenwolf had twisted his mind. After he recovered, he decided to join Justice League. The third stage was the climax where the superheroes struggled with the fight against Steppenwolf, and finally won with the return of Superman.</p><p>As shown in <ref type="figure" target="#fig_3">Fig. 7</ref>, we illustrate how to create the storyline visualization step by step using PlotThread. We use "George" who refers to the user to describe the authoring process. George first loads the story data which is a formatted document for the storyline renderer <ref type="bibr" target="#b43">[45]</ref>, and he obtains an initial storyline. Then, he uses Shifting to change the order of characters, and separate Steppenwolf and the members of Justice League <ref type="figure" target="#fig_3">(Fig. 7a</ref>). Based on his understanding of the story, he wants to transform the layout of the first stage into an "up-step" shape, where Batman and Wonder Woman tried to increase their team by recruiting new superheroes. He uses Transforming, selects the superheroes involved, and draws an ascending step-like line to obtain the initial step layout <ref type="figure" target="#fig_3">(Fig. 7c)</ref>. Next, he moves on to transform the shape of other stages, for example, in the climax stage, he draws a parabolic curve <ref type="figure" target="#fig_3">(Fig. 7d)</ref> to illustrate how Justice League beats Steppenwolf. George thinks the appearance is not legible or aesthetically appealing enough, so he seeks for AI assistance by triggering the AI creator. After AI gives the results, he quickly switches between different layouts and finds one <ref type="figure" target="#fig_3">(Fig. 7f</ref>) which has few crossings and deviations but preserving the narrative trends specified by him.</p><p>George continues to clarify the relationship between the groups of characters in a more coarse-grained way. Using Repelling, he emphasizes the part when Superman leaves the other superheroes, and when he reunites <ref type="figure" target="#fig_3">(Fig. 7b)</ref>. He triggers the AI creator when he wants to improve the appearance and gain some inspirations about the storyline design <ref type="figure" target="#fig_3">(Fig. 7e)</ref>. After clarifying the trend of the story as well as the general narrative structure, George starts to work on detailed refinements using Bending and Scaling <ref type="figure" target="#fig_3">(Fig. 7g</ref>). For example, he emphasizes the closeness of Justice League at the end of the whole story using Scaling. After completing the layout, George uses Relating to embellish the plots and make them more expressive <ref type="figure" target="#fig_3">(Fig. 7h</ref>). For example, he uses twined lines to illustrate the intense fights. Finally, he embellishes the picture by adding icons, changing line colors and stroke weight, as well as adding text annotations <ref type="figure" target="#fig_3">(Fig. 7i</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">USER FEEDBACK</head><p>To evaluate the effectiveness and usability of PlotThread, we conducted semi-structured interviews with three experts. The first expert (EA) was an artist who graduated from a national academy of art. She evaluated the output storylines crafted by PlotThread (see <ref type="figure">Fig. 1</ref>) and compared them with the storylines generated by the optimization model <ref type="bibr" target="#b23">[25]</ref> and human artists <ref type="bibr" target="#b43">[45]</ref>. The second expert (ED) was a professional UI/UX designer who worked for an international software company. She helped to test the usability of PlotThread because she had rich experiences in using various commercial design tools (e.g., Adobe AI/PS). The third expert (EV) was a senior researcher who studied visualization and visual analytics <ref type="bibr" target="#b27">[29]</ref> for eight years. He evaluated the system development of PlotThread and discussed the potential applications for storyline visualizations. The interview includes a 30min demonstration of PlotThread and a 30-min discussion.</p><p>EA mainly evaluated the storylines generated by different agents from the aesthetic and narrative aspects. We provided three kinds of storylines: the AI-assisted storylines created by PlotThread (see <ref type="figure">Fig. 1</ref>), the extremely-optimized storylines generated by the optimization model without human involvement <ref type="bibr" target="#b23">[25]</ref>, and the hand-drawn storylines created by artists <ref type="bibr" target="#b43">[45]</ref>. She thoroughly compared the visual designs of the different storylines and surprisingly found that the extremely-optimized storylines are hardest to read although they have fewest crossings and deviations. She inferred that "viewers intend to pay attention to line groups which are hard to be distinguished in extremely-optimized storylines because they are too compact." This observation validates the effectiveness of PlotThread which intends to better balance the aesthetic goals and the narrative constraints by sacrificing some aesthetic quality to enrich the narration. On the one hand, the AI agent is inherently driven by the optimization model so that it can produce well-optimized results. On the other hand, the agent resembles the input layouts which can be flexibly customized to indicate more narrative details.</p><p>ED mainly focused on the system design, including the human-AI collaborative workflow, the design of interactions, as well as the user interface. She was impressed by the interaction and interface design and commented that "the interactions are intuitive and the interface is easy to follow," but she also pointed out that users may need some training when they first use the system. To lower the learning cost, we will further improve the system with a user-friendly built-in user guide. When asked about the experience of human-AI collaboration, she commented that "users may doubt whether the AI agent can really understand their intentions, so they may be very reluctant to seek AI for help." This concern reveals a common trust issue widely existing in "black box" models. One possible solution is to provide an animation that demonstrates the evolution of layouts and how the AI agent modifies storylines. She also suggested that it would be helpful if users do not need to prepare story scripts because "it will challenge general users who do not have story scripts." Additionally, she provided a potential application of PlotThread that "it may be promising for preschool teachers to tell stories visually using PlotThread."</p><p>EV commented on the performance of the reinforcement learning algorithm and the applicability of PlotThread. He confirmed the effectiveness and expressiveness of the storylines (see <ref type="figure">Fig. 1</ref>) created by PlotThread. He mentioned that "the diverse visual forms of the storylines can arouse viewer's emotions, which I never expect from the optimization-based results." Due to the various visual elements proposed in the design space <ref type="bibr" target="#b5">[7]</ref>, we believe that we can further improve PlotThread and expand its applications. He suggested that "it can be helpful if the AI agent can guide users when they have no clues on how to start the design of storylines." This comment involves the trade-off between AI-driven and AI-guide systems where users or agents start the design process, respectively. To balance the two sides adequately, we plan to extend our RL framework to enable the agent to generate storylines from the input stories directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">DISCUSSION</head><p>We discuss the implications and limitations of PlotThread as follows:</p><p>Implications. Our work has several important implications. First, we develop PlotThread that facilitates the easy creation of storyline visualizations. Despite that existing tools <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b43">45]</ref> have incorporated human creativity into the optimization models, they require users to have a deep understanding of the automatic generation process of storyline visualizations. Thus, non-expert users are usually limited in fully expressing their ideas and design talents when designing the layouts of storylines. Due to the assistance of the AI agent, PlotThread enables users to design storyline layouts flexibly without considering the aesthetic goals (G1 to G3). The AI agent can resemble the userspecified layouts while preserving the aesthetic quality as much as possible. Thus, we believe PlotThread can serve numerous amateur users, which reflects the idea of "visualization for the mass." Second, to the best of our knowledge, we are the first to apply reinforcement learning to the design of storyline visualizations. Despite recent studies indicate that machine learning techniques can be successfully applied to the design of data visualizations (e.g., graphs <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b44">46]</ref> and charts <ref type="bibr" target="#b31">[33]</ref>), it is still unknown whether storylines can be produced using machine learning approaches. To answer this issue, we employ reinforcement learning that formulates the design of storyline visualizations as a long-term delayed reward problem. The agent is trained to learn how designers typically "refine" initial storyline layouts to provide users possible suggestions of effective storyline layouts that follow the aesthetic goals. Our RL framework can inspire promising research frontiers in the field of visualization design. For example, researchers could first decompose a complicated design task into a set of design actions and then employ reinforcement learning to predict possible combinations of actions to construct data visualizations.</p><p>Third, we propose a mixed-initiative approach that incorporates predictive models and user feedbacks into interactive applications where users initiate and exploit the design task while computational agents explore the design space. Compared with a typical computer-assisted tool (e.g., iStoryline <ref type="bibr" target="#b43">[45]</ref>), PlotThread intends to achieve a better trade-off between human creative work and automation by providing intelligencelevel (not tool-level) assistance. Despite that the optimization-based approaches <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b42">44]</ref> have been improved significantly, we argue that it is necessary to integrate human intelligence into the design of storylines. Sitting in opposition to a perspective of pure automation, PlotThread provides a successful example where computational agents and people are seamlessly integrated to work on a shared problem, which can inspire the development of future visualization tools.</p><p>Limitations. Our work has several limitations. First, while there are various design tools to support the design of expressive storylines, PlotThread could be further improved to increase the artistry of the storyline visualizations. For instance, more diverse sketch styles could be employed to enrich the narration of storylines. Thus, we plan to develop more design tools to support the creative design of storylines. Second, even though the time efficiency of the AI agent is acceptable during the authoring process (see <ref type="figure" target="#fig_4">Fig. 8</ref>), it could be further improved to support more tightly collaborative designs. As a proof of concept, we have implemented PlotThread on a personal laptop, and we plan to improve the time performance of the AI agent via GPUs and parallel programming. Third, it is labor-intensive for users to prepare story scripts <ref type="bibr" target="#b43">[45]</ref> that are necessary input for the storyline renderer <ref type="bibr" target="#b43">[45]</ref>. To alleviate users' burden, we also plan to enable users to create storyline visualizations from scratch and investigate how to improve the collaborative design workflow progressively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">CONCLUSION</head><p>In this research, we develop PlotThread, a mixed-initiative authoring tool that seamlessly integrates computational agents and people to facilitate the easy design of storyline visualizations. The agent is designed to help users explore the design space <ref type="bibr" target="#b43">[45]</ref> efficiently by providing a set of suggestive layouts, which can also inspire lateral thinking <ref type="bibr" target="#b6">[8]</ref>. To develop such an intelligent agent, we formulate the design of storyline layouts as a reinforcement learning (RL) problem where the agent is trained to "refine" storyline layouts based on usershared interactions. Moreover, we propose a novel framework and generate a collection of well-optimized storylines to address the two major challenges, namely model architecture and model training, raised by applying RL on designing storylines. We evaluate the effectiveness of our framework using qualitative and quantitative experiments and demonstrate the usage of PlotThread through a group of use cases. As future work, we plan to improve the time efficiency of the agent by employing parallel computing and extend the design tools of PlotThread to support more creative designs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3. PlotThread is composed of a menubar for (a) loading story scripts, setting canvas, and exporting storylines; (l) a toolbar that provides a set of easy-to-use interactions (b) to (i); The red lines indicate the interactions that change original layouts (black lines) into desired layouts (blue lines). (j) buttons for activating and stopping the AI agent and (k) a panel for presenting AI-generated layouts; (m) a setting panel for changing the parameters of storylines and (n) an embellishing panel for inserting icons or images into the canvas.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Neural network architecture for the AI agent. FC refers to fullyconnected layer, and ReLU represents an activation function. Three neural networks are employed to separately predict the three high-level interactions. A greedy function is used to obtain final actions and values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 .</head><label>6</label><figDesc>Qualitative experiments: (a) the initially-optimized layouts generated by the optimization model<ref type="bibr" target="#b23">[25]</ref>. (b) the user layouts modified by the interactions shown in (a). (c) the AI-generated layouts that resemble the user layouts but with improved aesthetic quality. The intermediate layouts at the k-th step (k = 1,<ref type="bibr" target="#b3">5,</ref><ref type="bibr" target="#b13">15)</ref> are also presented to indicate how the AI agent reproduces the user layouts. The four cases are Jurassic Park, WuKong, Moon and Sixpence, Justice League (from left to right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>This case illustrates the authoring process of the storyline visualization (Justice League) using PlotThread. The designer first customizes an initial layout through (a) Shfiting, (b) Repelling, (c) and (d) Transforming (Dashed ellipses indicate the transforming regions and solid paths represent the transforming shapes)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Quantitative experiments: (a) x-axis represents the number of steps, and y-axis indicates the loss that is inverse of the cumulative rewards. The solid and dashed lines indicate the performance of the RL model and the baseline method, respectively. (b) y-axis indicates the running time of the RL model (blue) and the baseline method (Orange).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://istoryline.github.io/gallery/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The work was supported by the joint Sino-German program of NSFC (61761136020), National Key R&amp;D Program of China (2018YFB1004300), NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization (U1609217), Zhejiang Provincial Natural Science Foundation (LR18F020001) and the 100 Talents Program of Zhejiang University. This project was also partially funded by Microsoft Research Asia. Lingyun Yu is supported by XJTLU Research Development Funding RDF-19-02-11. Parts of this work were funded by German Science Foundation (DFG) as part of the project 'VAOST' (392087235).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pytorch</surname></persName>
		</author>
		<ptr target="https://pytorch.org/" />
		<imprint>
			<date type="published" when="2019-12-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Typescript</surname></persName>
		</author>
		<ptr target="https://www.typescriptlang.org/" />
		<imprint>
			<date type="published" when="2019-12-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The &quot;y&quot; of it Matters, Even for Storyline Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arendt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pirrung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Conference on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="81" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Arcade Learning Environment: An Evaluation Platform for General Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Naddaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bowling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="253" to="279" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Natural actorcritic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhatnagar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghavamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2471" to="2482" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Exploring the design space of immersive urban analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="132" to="142" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Lateral thinking: a textbook of creativity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">De</forename><surname>Bono</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Penguin UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Echarts: A declarative framework for rapid construction of web-based visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deqing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honghui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wenli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Junting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Informatics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="136" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Survey of Graph Layout Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Petit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Serna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Survey</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="356" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Fast and Simple Heuristic for Constrained Two-Level Crossing Reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Forster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Graph Drawing</title>
		<meeting>the International Conference on Graph Drawing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="206" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Principles of Mixed-Initiative User Interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Uncertainty, Action, and Interaction: In Pursuit of Mixedinitiative Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="17" to="20" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to Paint With Model-Based Deep Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8709" to="8718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reinforcement Learning: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="237" to="285" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Vizdoom: A Doom-based AI Research Platform for Visual Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kempka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wydmuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Runc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Toczek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jaśkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computational Intelligence and Games</title>
		<meeting>the IEEE Conference on Computational Intelligence and Games</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Deep Generative Model for Graph Layout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O.-H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="665" to="675" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">SketchStory: Telling More Engaging Stories with Data through Freeform Sketching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2416" to="2425" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Can computers foster human users&apos; creativity? Theory and praxis of mixed-initiative cocreativity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liapis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Yannakakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alexopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lopes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="136" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sentient World: Humanbased Procedural Cartography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liapis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Yannakakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Togelius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Evolutionary and Biologically Inspired Music and Art</title>
		<meeting>the International Conference on Evolutionary and Biologically Inspired Music and Art</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="180" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Continuous control with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards better analysis of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="100" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Steering data quality with visual analytics: The complexity challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="191" to="197" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">StoryFlow: Tracking the Evolution of Stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2436" to="2445" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1928" to="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Movie Narrative Charts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munroe</surname></persName>
		</author>
		<ptr target="https://xkcd.com/657" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Visualization Analysis and Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">What is Mixed-Initiative Interaction?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Novick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Spring Symposium on Computational Models for Mixed Initiative Interaction</title>
		<meeting>the AAAI Spring Symposium on Computational Models for Mixed Initiative Interaction</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="114" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Software evolution storylines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ogawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Software Visualization</title>
		<meeting>the International Symposium on Software Visualization</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Natural actor-critic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schaal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">7-9</biblScope>
			<biblScope unit="page" from="1180" to="1190" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Reverse-Engineering Visualizations: Recovering Visual Encodings from Chart Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Poco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Imagination-augmented agents for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Racanière</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reichert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
		<meeting>the Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5690" to="5701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Artificial Neural Network for Minimum Crossing Number Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong-Long</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okazaki</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning and Cybernetics</title>
		<meeting>the International Conference on Machine Learning and Cybernetics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="4201" to="4204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep Learning in Neural Networks: An Overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">MeetingVis: Visual Narratives to Assist in Recalling Meeting Context and Content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhamidipati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1918" to="1929" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Justice League. DC Films</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Snyder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Authoring Tools Should be Mixed-initiative Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stefnisson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICIDS Workshop on Authoring for Interactive Storytelling</title>
		<meeting>the ICIDS Workshop on Authoring for Interactive Storytelling</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Reinforcement Learning: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Policy Gradient Methods for Reinforcement Learning with Function Approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Neural Information Processing Systems</title>
		<meeting>International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Automatic Graph Drawing and Readability of Diagrams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Battista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Batini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="79" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An Efficient Framework for Generating Storyline Visualizations from Streaming Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tanahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Hsueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="730" to="742" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Design Considerations for Optimizing Storyline Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tanahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2679" to="2688" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">iStoryline: Effective Convergence to Hand-drawn Storylines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rubab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="769" to="778" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">DeepDrawing: A Deep Learning Approach to Graph Drawing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="676" to="686" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multi-task deep reinforcement learning for continuous action control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Merrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Abbass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3301" to="3307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Mixed-Initiative Cocreativity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Yannakakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liapis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alexopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on the Foundations of Digital Games</title>
		<meeting>International Conference on the Foundations of Digital Games</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A survey of visual analytics techniques for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Visual Media</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Abductive learning: towards bridging machine learning and logical reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Information Sciences</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
