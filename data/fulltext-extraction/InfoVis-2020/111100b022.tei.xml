<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantic Discriminability for Visual Communication</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><forename type="middle">B</forename><surname>Schloss</surname></persName>
							<email>kschloss@wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Psychology and Wisconsin Institute for Discovery</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Zachary Leggon, Biology and Wisconsin Institute for Discovery</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Leggon</surname></persName>
							<email>zleggon@wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Psychology and Wisconsin Institute for Discovery</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lessard</surname></persName>
							<email>l.lessard@northeastern.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Psychology and Wisconsin Institute for Discovery</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Mechanical and Industrial Engineering</orgName>
								<orgName type="institution">Northeastern University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Semantic Discriminability for Visual Communication</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">received xx xxx. 201x; accepted xx xxx. 201x.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visual Reasoning</term>
					<term>Information Visualization</term>
					<term>Visual Communication</term>
					<term>Visual Encoding</term>
					<term>Color Perception</term>
					<term>Color Cognition</term>
				</keywords>
			</textClass>
			<abstract>
				<p>How should colors be selected so the graph is as interpretable as possible? Interpretability depends more on semantic distance than perceptual distance. Semantic Distance Perceptual Distance Perceptual Distance Mango (w 2) Watermelon (w 1) Mango (w 3) Watermelon (w 1) Mango (m 1) Watermelon (w 1) Mango (m 2) Watermelon (w 1) Avg. accuracy: 50%</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In visual communication, designers produce information visualizations by encoding concepts in visual features, and observers interpret visualizations by decoding concepts from visual features <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b39">39]</ref>. Interpreting visualizations involves multiple component processes, including <ref type="bibr" target="#b0">(1)</ref> perceiving and identifying important features within a visualization, <ref type="bibr" target="#b1">(2)</ref> mapping those features to the concepts they represent, and (3) deriving</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Perceptual discriminability</head><p>Perceptual discriminability is the degree to which observers can perceive differences between different visual features (e.g., colors, sizes, shapes, or textures). Some amount of perceptual discriminability is necessary because observers cannot decode different meanings from perceptually identical features <ref type="bibr" target="#b16">[17]</ref> (e.g., they must be able to perceive the difference between two shades of blue to decode that those blues encode different concepts). Thus, visualization research has emphasized the importance of understanding perceptual discriminability <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b34">34]</ref>, including how it varies with mark size <ref type="bibr" target="#b33">[33]</ref> and shape <ref type="bibr" target="#b34">[34]</ref>. And, design guidelines have emphasized the importance of representing categorical information with colors that are well-separated in color space <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b32">32]</ref>. If perceptually discriminable features are accompanied by verbal descriptions specifying the encoded mapping (e.g., legends or labels), then observers have all the information required to decode the encoded mapping. This rationale supports using pre-made color palettes (e.g., Tableau and Colorbrewer palettes <ref type="bibr" target="#b11">[12]</ref>) that have been designed to ensure perceptual discriminability. However, the ability to decode encoded mappings depends on more than perceptual discriminability and legend reading, as explained below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Semantic discriminability</head><p>We define semantic discriminability as the degree to which observers can infer a unique mapping between visual features and concepts, based on the visual features and concepts alone (i.e., without legends or labels). For example, if observers are given an unlabeled graph containing yellow and blue colored bars and are told the graph is about the concepts banana and blueberry, they could easily infer that yellow maps to banana and blue maps to blueberry. This is because yellow and blue are semantically discriminable for the concepts banana and blueberry. Conversely, it would be more difficult to infer how orangishyellow and greenish-yellow map to the concepts banana and lemon because both colors are similarly associated with both concepts, and thus less semantically discriminable.</p><p>Semantic discriminability might sound similar to interpretability, but they are distinct constructs. Semantic discriminability concerns the ability to infer a unique mapping (irrespective of the encoded mapping), whereas interpretability concerns the ability to decode the correct mapping (specified by the encoded mapping). Building on the banana/blueberry graph example, yellow and blue would be semantically discriminable colors, regardless of the encoded mapping in the graph. Observers would infer that yellow maps to banana and blueberry maps to blue. Now, if the encoded mapping was yellow-banana/blueblueberry, the graph would be easy to interpret because the encoded mapping matched the inferred mapping. But, if the encoded mapping was blue-banana/yellow-blueberry (i.e., cross-mapped <ref type="bibr" target="#b6">[7]</ref>), the graph would be harder to interpret because the encoded mapping did not match the inferred mapping (i.e., Kosslyn's compatibility principle <ref type="bibr" target="#b16">[17]</ref>, Tversky et al.'s congruence principle <ref type="bibr" target="#b37">[37]</ref>). Observers are better at interpreting colors in visualizations when encoded mappings match inferred mappings, even when there is a clear legend <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b29">29]</ref>.</p><p>Based on the examples above, one might conclude that interpretability depends only on association strengths of encoded color-concept pairs. Lin et al. <ref type="bibr" target="#b18">[19]</ref> referred to palettes in which colors evoke the concepts they represent as semantically resonant color palettes. However, interpretability can also be achieved when not all color-concept pairs are semantically resonant <ref type="bibr" target="#b30">[30]</ref>, see Section 2.2. Rathore et al. <ref type="bibr" target="#b26">[27]</ref> referred to this more general case as semantically interpretable color palettes. For simplicity, we use the term interpretability in the present work to refer to the more general case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Perceptual vs. semantic discriminability?</head><p>From prior work, it is clear that interpretability hinges on some degree of perceptual discriminability <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b34">34]</ref> and interpretability benefits from semantic discriminability <ref type="bibr" target="#b30">[30]</ref>. However, given previous research, it is currently unknown whether increasing semantic discriminability improves interpretability, beyond that which can be explained by perceptual discriminability. Returning to our banana/blueberry/lemon examples used so far in this introduction, these examples were intended to build the intuition for semantic discriminability, but they confounded perceptual and semantic discriminability. Yellow and blue are both high in perceptual and semantic discriminability when encoding for the concepts banana and blueberry, and orangish-yellow vs. greenish-yellow are both low in perceptual and semantic discriminability when encoding for the concepts banana and lemon (assuming trichromatic color vision). Similarly, in prior work that suggested semantic discriminability improved interpretability, colors in the more semantically discriminable color palette were closer together in color space <ref type="bibr" target="#b30">[30]</ref>, see Section 2.2. So, it is unclear if this improvement was due to semantic or perceptual discriminability. Yet, semantic and perceptual discriminability can vary independently <ref type="figure">(Fig. 1)</ref>, and understanding their independent effects on interpretability is important for determining how to resolve conflicts between them when optimizing color palette design.</p><p>Likewise, it is also unknown whether increasing perceptual discriminability beyond that which is needed for semantic discriminability influences interpretability. For two colors to be semantically discriminable, they must be sufficiently perceptually discriminable to tell them apart. Otherwise, observers could not reliably infer that one color maps more than another color does to a given concept. Thus, perceptual discriminability might not capture additional variance in interpretability beyond that which is explained by semantic discriminability.</p><p>To address these questions, we tested for independent effects of perceptual and semantic discriminability on interpretability. The results will not only provide a deeper understanding about the relative contributions of perceptual and cognitive factors for visual reasoning, but will also inform optimal color palette design. Designing effective palettes for information visualization requires navigating trade-offs between several, sometimes competing, factors (e.g., perceptual discriminability, semantic discriminability, name difference, emotional connotation, and aesthetics) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b33">33]</ref>. Understanding the relative contribution of semantic and perceptual discriminability for interpretability will inform how to prioritize these factors when conflicts arise.</p><p>Contributions. Our study makes the following contributions. First, we define a metric called semantic distance for operationalizing semantic discriminability. Semantic distance depends on the relative association strengths between each color and each concept in the context of an encoding system (see Section 3.2). This is unlike perceptual distance, which only depends on the appearance of the two colors. The semantic distance between a given pair of colors may be large in the context of some concepts, but small in the context of other concepts.</p><p>Second, we present the results of two experiments that assess how perceptual distance and semantic distance influence interpretability. Evidence indicates that both factors can contribute to interpretability, but semantic distance dominates when the factors conflict. The results imply that increasing perceptual distance beyond that which is needed for semantic discriminability can improve interpretability, but when in conflict, priority should be given to maximizing semantic distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>When people interpret information visualizations, they do not simply absorb the displayed information in a bottom-up fashion. Instead, they have biases, or expectations, about how visual features map to meanings, which guide their interpretations. These biases span topics across the field of information visualization, including graphical perception <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b41">41]</ref>, visualizing uncertainty <ref type="bibr" target="#b27">[28]</ref>, and color <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b30">30]</ref>. Understanding and designing visualizations that align with these biases will help make visualizations that are easier to interpret <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b36">36]</ref>. In cases where this alignment may not be possible (i.e., multiple conflicting biases relevant to a particular visualization), an understanding of when expectations are violated can guide compensatory design decisions (e.g., extra labeling or verbal descriptions of the visualization).</p><p>Here, we focus on understanding expectations about assignments between colors and concepts for interpreting visualizations about categorical information. However, this discussion should apply to assignments between other perceptual features and concepts, as long as people have systematic associations between those features and concepts. In this section, we first describe how designers use assignment problems to produce encoded mappings between visual features and concepts. We then present evidence that observers use assignment inference to decode encoded mappings when interpreting visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Assignment problems for encoding</head><p>Assignment problems have been used to create color palettes that optimize encodings between visual features and concepts <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">30]</ref>. An assignment problem is a model for assigning items in one category (e.g., colors) to items in another category (e.g., concepts) in a manner that maximizes a total merit score <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23]</ref>. Assignment problems can be represented as bipartite graphs, as shown in <ref type="figure">Fig. 2</ref>. The square nodes are colors and the circular nodes are concepts. Edges are drawn between each color and each concept. The number on each edge represents the "merit score" of assigning that particular color to that concept, represented as x 1 ,...,x 4 . Merit scores can be calculated using different methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">30]</ref> but the goal is always the same: construct a 1-to-1 assignment between each color and a concept, such that the sum of the merit scores of assigned color-concept pairs is maximized. Assignment problems are deterministic. When there are two concepts and two colors as in <ref type="figure">Fig. 2</ref>, there are only two possible outcomes and the outcome is completely determined by the merit scores on each of the four edges. If the sum of the outer edges is greater than the sum of the inner edges (x 1 + x 4 &gt; x 2 + x 3 ), then concept A is assigned to color 1 and concept B is assigned to color 2. If the sum of the inner edges is greater (x 2 + x 3 &gt; x 1 + x 4 ), then concept A is assigned to color 2 and concept B to color 1. <ref type="figure">Fig. 2</ref> illustrates bipartite graphs with three different patterns of merit on the edges, but all three scenarios produce identical outcomes: concept A is assigned to color 1 and concept B is assigned to color 2 because the merit scores satisfy</p><formula xml:id="formula_0">A B 1 x 1 x 2 x 4 x 3 2 concepts colors A B 1 x 1 x 2 x 4 x 3 2 A B 1 x 1 x 2 x 4 x 3 2 merit A B A B A B Figure 2.</formula><formula xml:id="formula_1">x 1 + x 4 &gt; x 2 + x 3 .</formula><p>In the left and center bipartite graphs, the solution to the assignment problem ("global solution") matches the solution for each concept in isolation ("local solution", concept A is more associated with color 1 than color 2, and concept B is more associated with color 2 than color 1). However, in the rightmost bipartite graph, the local and global solutions conflict: concept B is more associated with color 1, yet it is assigned to color 2. This distinction is relevant for discussing how humans decode encoded mappings (Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Assignment inference for decoding</head><p>When people decode encoded mappings, they use a process similar to solving an assignment problem, called assignment inference <ref type="bibr" target="#b30">[30]</ref>. In assignment inference, people estimate the merit of different assignments based on association strengths between visual features and concepts, and determine the assignment that maximizes merit. However, unlike how computers solve assignment problems, human assignment inference is probabilistic rather than deterministic <ref type="bibr" target="#b30">[30]</ref>. Overall, humans can produce reliable inferences, but their responses are noisy. This noise can be attributed to uncertainty in the color-concept associations that serve as input into the assignment problem. In <ref type="bibr" target="#b30">[30]</ref>, this uncertainty was built into models that were effective at predicting human responses. <ref type="figure">Fig. 2</ref> represents the noise in color-concept associations as distributions for each color-concept pairing. For each distribution, the mean corresponds to edge thickness in the bipartite graph. The variability is assumed to be normal. Assume each time a person does assignment inference, they draw a random value from these distributions to estimate merit for each edge. When the distributions are far apart <ref type="figure">(Fig. 2 left)</ref>, random draws will consistently result in the same outcome of the assignment problem. However, when distributions overlap <ref type="figure">(Fig. 2 middle)</ref>, random draws can result in different outcomes of the assignment problem, which results in more uncertainty in assignment inference <ref type="bibr" target="#b30">[30]</ref>. This is the basis for our semantic distance metric in the present work (see Section 3.2.2).</p><p>Evidence suggests that people perform global assignment inference when interpreting the meanings of colors in information visualizations <ref type="bibr" target="#b30">[30]</ref>. In some cases, the global solution conflicts with local solutions <ref type="figure">(Fig. 2, right)</ref>. Such conflicts can result in people inferring that concepts are assigned to their most weakly associated colors, even when stronger candidate colors exist in the palette. Schloss et al. <ref type="bibr" target="#b30">[30]</ref> first demonstrated this phenomenon using a recycling task: participants were presented with images of two colored bins, along with a word describing one "target" concept. There were two possible targets, paper and trash. When trash was the target and was presented with white and purple bins, participants were faced with a scenario like in <ref type="figure">Fig. 2</ref>, right. Trash was more strongly associated with white than with purple (x 3 &gt; x 4 ), but so was paper (x 1 &gt; x 2 ), and the association between paper and white was especially strong. Participants reliably discarded trash into the purple bin, even though trash was more strongly associated with white (analogous to blue in <ref type="figure">Fig. 2, right)</ref>.</p><p>Schloss et al. <ref type="bibr" target="#b30">[30]</ref> also assessed methods for calculating merit to generate the encoded mapping, one that maximized association strength (isolated merit function) and one that prioritized semantic discriminability over association strength (balanced merit function, although the term semantic discriminability was not used in <ref type="bibr" target="#b30">[30]</ref>). Within both color palettes, responses were faster and more accurate when the target concept was more strongly associated with its correct color, but participants were more accurate for the balanced palette than the isolated palette. These results suggest interpretability increases with semantic discriminability. However, in addition to being more semantically discriminable, colors in the balanced palette were also further apart in CIELAB space (see <ref type="figure">Fig. S</ref>.1 in the Supplementary Material of the present paper). Thus, it is unclear if colors in the balanced color palette were easier to interpret because they were more semantically discriminable, more perceptually discriminable, or both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPROACH</head><p>In the present study, we assessed the independent effects of semantic discriminability and perceptual discriminability on participants' interpretations of bar graph data visualizations. The paradigm was the same as in Schloss et al. <ref type="bibr" target="#b30">[30]</ref>, but instead of interpreting colors of unlabeled trash and recycling bins, participants interpreted colors of unlabeled bars in a bar graph. On each trial, participants saw a graph containing two different colored bars, along with a target fruit concept described above the graph <ref type="figure">(Fig. 1, left)</ref>. Their task was to indicate which colored bar, left or right, corresponded to the target fruit. Within each experiment, participants judged all pairwise combinations of eight colors for two fruits (cantaloupe and strawberry in Experiment 1, mango and watermelon in Experiment 2). The data from the present experiment and analysis code are at github.com/SchlossVRL/semantic-discriminability.</p><p>We used a previous dataset on color-concept associations from Rathore et al. <ref type="bibr" target="#b26">[27]</ref> to select the colors for the present study (Section 3.1), define accuracy for the present tasks (Section 3.2.1), and quantify semantic distance (Section 3.2.2). In <ref type="bibr" target="#b26">[27]</ref>, participants rated association strengths between each of 12 fruits and each of 58 colors (UW-58 colors), uniformly sampled in CIELAB space (ΔE = 25). This distance should be at least one noticeable difference <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b34">34]</ref>. Further details on the methods of <ref type="bibr" target="#b26">[27]</ref> are in Supplementary Material of the present paper.   <ref type="table">Table S</ref>.1 for coordinates). CIELAB coordinates are shown for each color on the (A.2) a*, b* plane and the a*, L* plane (A.3), with the size of the marks corresponding to association strength with the concept named at the top of the column (same data as in A.1). Dashed ovals enclose the four colors that were the relatively strong associates with the concept at the top of the column. (B) Same as A, but for the colors and concepts in Experiment 2. Each plot has eight points, one for each color, but in some cases fewer points are visible due to occlusion on the 2D plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Selecting colors and concepts</head><p>We chose the colors and fruit concepts using the mean color-concept association data from Rathore et al. <ref type="bibr" target="#b26">[27]</ref> (see <ref type="table">Table S</ref>.6 in the Supplementary Material) and color distances in CIELAB space (ΔE). In Experiment 1, we selected eight colors and two fruits to have the following properties. Four colors varied from moderately to strongly associated with the first fruit while being weakly associated with the second fruit ( <ref type="figure" target="#fig_1">Fig. 3A.</ref>1, left). The other four colors varied from moderately to strongly associated with the second fruit while being weakly associated with the first fruit ( <ref type="figure" target="#fig_1">Fig. 3A.</ref>1, right). We generated candidate colors and fruits using an optimization routine that enforced a minimum difference in association ratings for the four colors that varied and a weak association rating for the remaining four colors. This yielded a list of candidate palettes. We excluded palettes involving fruits that had colors in their names (blueberry and orange), and this led us to selecting cantaloupe and strawberry for our first experiment. The CIELAB coordinates of these colors are plotted on the a*, b* plane in <ref type="figure" target="#fig_1">Fig. 3A.</ref>2 and on the a*, L* plane in <ref type="figure" target="#fig_1">Fig. 3A</ref>.3. The size of the marks represent the association strengths shown in 3A.1. It can be seen that there are two separate clusters for "cantaloupe colors" and "strawberry colors" (indicated by the dashed ovals). In Experiment 2, we selected fruits and colors so they had the same color-concept association properties as in Experiment 1 (compare <ref type="figure" target="#fig_1">Fig. 3B</ref>.1 to 3A.1). However, unlike Experiment 1, the colors in Experiment 2 are no longer clustered in CIELAB space <ref type="figure" target="#fig_1">(Fig. 3B.2</ref> and <ref type="figure" target="#fig_1">Fig. 3B.3)</ref>; the "watermelon colors" were split on either side of the "mango colors". These properties enabled us to independently vary semantic distance and perceptual distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Quantifying metrics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Interpretability</head><p>We operationalized interpretability as the accuracy of decoding the encoded mapping. The bar graphs in this study were unlabeled, so there was no explicit encoded mapping from the perspective of the participants (i.e., no objectively correct answer). However, we can determine an optimal encoded mapping by solving an assignment problem for each pair of colors and concepts and use the solution to define the "correct" response. The input to the assignment problem was the set of association strengths between each color-concept pair <ref type="figure" target="#fig_1">(Fig. 3</ref>). Recall these data came from different participants than those in the present study. We solved the assignment problem for each pair of colors and concepts using the method described in Section 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Semantic discriminability</head><p>We operationalized semantic discriminability using a new metric, called semantic distance (ΔS). To build the intuition for semantic distance, consider semantic discriminability in the context of assignment problems, described in Section 2.1. Given color-concept association ratings, the solution to the assignment problem yields a deterministic assignment of colors to concepts. However, we want to distinguish between robust assignments (e.g., blueberry-blue and banana-yellow, which have high semantic discriminability), and fragile assignments (e.g., lemon-greenish-yellow and banana-orangish-yellow, which have low semantic discriminability since both fruits can be either color). In a robust assignment, we can expect all people to come to the same conclusion. But in a fragile assignment, people might disagree on which assignment is correct, and the same person might even respond differently when asked the same question again. We account for variability across individuals by assuming the association ratings between colors and concepts are normally distributed with a mean equal to the mean association rating and variance that is largest when the association rating is closest to the center of the rating scale. We now define semantic distance in the case of two concepts and two colors and illustrate our definition in <ref type="figure" target="#fig_3">Fig. 4</ref> using mango and watermelon as concepts and m 4 and w 4 as colors.</p><p>Given two colors and two concepts, there are two possible assignments of colors to concepts (indicated by black edges on the two bipartite graphs in <ref type="figure" target="#fig_3">Fig. 4)</ref>. We define the semantic distance to be the absolute difference in the probabilities of each assignment being chosen by a random individual. Specifically, if x 1 , x 2 , x 3 , x 4 are the association ratings between colors and concepts (see <ref type="figure" target="#fig_3">Fig. 4</ref>), we let</p><formula xml:id="formula_2">Δx = (x 1 + x 4 ) − (x 2 + x 3 )</formula><p>. Note that if Δx &gt; 0, concept M will be assigned with color m 4 and concept W will be assigned with color w 4 . If Δx &lt; 0, the alternative assignment will be made. We assume each x i is normally distributed, with mean equal tox i , the mean association across all people for this color and concept, and standard deviation equal to</p><formula xml:id="formula_3">σ i = 1.4 •x i (1 −x i ).</formula><p>This was found to be a good fit to the experimental data <ref type="bibr" target="#b0">1</ref> . We define semantic distance as</p><formula xml:id="formula_4">ΔS = Prob(Δx &gt; 0) − Prob(Δx &lt; 0) .<label>(1)</label></formula><p>The probabilities in (1) can be computed by computing the z-score using the mean and standard deviations described above.</p><formula xml:id="formula_5">Prob(Δx &gt; 0) = Φ (x 1 +x 4 ) − (x 2 +x 3 ) σ 2 1 + σ 2 2 + σ 2 3 + σ 2 4 ,<label>(2)</label></formula><p>and Prob(Δx &lt; 0) = 1 − Prob(Δx &gt; 0), where Φ(•) is the cumulative distribution function (cdf) of the standard normal distribution. The relationship between the x i and Δx is illustrated in <ref type="figure" target="#fig_3">Figure 4</ref>. x  <ref type="figure" target="#fig_1">Fig. 3B.1</ref>. The x i are assumed to be normally distributed and combine to form Δx. When Δx &gt; 0, the assignment M-m 4 /W-w 4 is chosen and when Δx &lt; 0, the alternative assignment M-w 4 /W-m 4 is chosen. In the bipartite graphs, black/gray edges indicate the chosen/non-chosen assignment. Edge thickness indicates the mean color-concept association rating, but random draws can produce values above/below this mean, resulting in outcomes to left or right of zero. We define semantic distance ΔS as the absolute difference between these probabilities. We have 0 ≤ ΔS ≤ 1 and a larger ΔS indicates more certainty in the outcome of the assignment. <ref type="figure">Fig. 2</ref> left and center illustrate how semantic distance can vary while the assignment problem outcome remains constant. In both examples, concept A is assigned to color 1 and concept B is assigned to color 2, but semantic distance decreases between <ref type="figure">Fig. 2</ref> left and center because the merit distributions overlap more. We predict that such decreases in semantic distance will make visualizations more difficult to interpret. In <ref type="figure">Fig. 2</ref> right, the colors have a greater semantic distance than in <ref type="figure">Fig. 2</ref> center, even though color 1 is more strongly associated than color 2 with both concept A and concept B. Thus, the scenario in <ref type="figure">Fig. 2</ref> right should be more interpretable than <ref type="figure">Fig. 2</ref> center. This example shows how colors can have a large semantic distance with respect to two concepts, even though neither color is strongly evocative of a particular concept within the set. Prior work has shown such cases are easily interpretable <ref type="bibr" target="#b30">[30]</ref> (see Section 2.2). <ref type="figure" target="#fig_4">Fig. 5A</ref> shows semantic distance for all 28 pairwise combinations of 8 colors tested in Experiment 1 (see figure caption for details on how to interpret this plot). There is only one plot for both cantaloupe and strawberry because semantic distance for a given set of colors and concepts is symmetric. That is, the distance between colors c 1 and s 1 is the same, regardless of whether the target is cantaloupe or strawberry. When cantaloupe colors are paired with other cantaloupe colors (on curves labeled c 1 , c 2 , c 3 ), semantic distance increases as the difference in association strength increases (i.e., distance on the x-axis), but then levels off once reaching strawberry colors because all strawberry colors are similarly weakly associated with cantaloupe. To see the analogous pattern for strawberry colors, it is necessary to compare the heights of data points at each x-axis position. For example, looking at s 1 on the x-axis, semantic distance steadily increases for pairings with other strawberry colors as association strength difference increases (s 2 to s 4 ), and then levels off when reaching the four cantaloupe colors. <ref type="figure" target="#fig_4">Fig. 5B</ref> shows semantic distance for the colors and concepts in Experiment 2. Given that the pattern of association strengths across colors in Experiment 2 <ref type="figure" target="#fig_1">(Fig. 3B.1</ref>) was similar to Experiment 1 <ref type="figure" target="#fig_1">(Fig. 3A.1)</ref>, the pattern of semantic distances were strongly correlated between the two experiments (r(26) = .99, p &lt; .001).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distribution of</head><formula xml:id="formula_6">1 x 3 x 2 x 4 + + - x = (x 1 + x 4 ) -(x 2 + x 3 ) ( ) ( ) M W m 4 x 1 x 2 x 4 x 3 w 4 M W m 4 x 1 x 2 x 4 x 3 w 4 Prob( x &gt; 0) Prob( x &lt; 0) S = absolute difference of areas S = | Prob( x &gt; 0) -Prob( x &lt; 0) |</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Perceptual discriminability</head><p>We operationalized perceptual discriminability as perceptual distance (ΔE) in CIELAB color space, as in previous visualization research <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b34">34]</ref>. <ref type="figure" target="#fig_4">Fig. 5C</ref> shows perceptual distances in Experiment 1 and <ref type="figure" target="#fig_4">Fig. 5D</ref> shows perceptual distances in Experiment 2, plotted in the same manner as semantic distance. In Experiment 1, perceptual distance <ref type="figure" target="#fig_4">(Fig. 5C</ref>) deviated from semantic distance <ref type="figure" target="#fig_4">(Fig. 5A</ref>) but the two variables were still correlated (r(26) = .71, p &lt; .001). In Experiment 2, perceptual distance ( <ref type="figure" target="#fig_4">Fig. 5D</ref>) and semantic distance <ref type="figure" target="#fig_4">(Fig. 5B)</ref> were uncorrelated (r(26) = .02, p = .920). Perceptual distances in Experiment 1 and Experiment 2 were also uncorrelated (r(26) = .08, p = .673)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT 1</head><p>This experiment tested for independent effects of semantic and perceptual distance on interpretability, using the colors in <ref type="figure" target="#fig_1">Fig. 3A</ref>. Although semantic distance and perceptual distance were correlated, we could test for independent effects of each factor using regression analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Methods</head><p>Participants. 36 undergraduates (mean age = 18.3, 25 females, 11 males) participated for credit in Introductory Psychology. All had normal color vision (screened with <ref type="bibr" target="#b9">[10]</ref>), and gave informed consent. The UW-Madison IRB approved the protocol for this study.</p><p>Design and Displays. Participants were presented with bar graphs showing fictitious data about preferences for two different fruits <ref type="figure">(Fig. 1,  left)</ref>. Each graph had two colored bars, one for each fruit. The bars were two different colors, determined by all 28 pairwise combinations of eight colors <ref type="figure" target="#fig_1">(Fig. 3A, Table S</ref>.1 in the Supplementary Material). The bars were 50 pixels wide (2.4 cm wide) and varied in height. Each trial contained a taller and shorter bar with base heights of 150 and 100 pixels (5.1 and 3.7 cm), respectively. Bar heights were randomly, and independently, adjusted around their base height by +/-5 pixels (.2 cm) on each trial. The side of the graph containing the taller bar was left/right balanced. The x and y axes of the graph were 200 and 250 pixels long respectively. The y-axis was labeled as "Preference" (font size 14) and the x-axis and bars were unlabeled. The target fruit for  <ref type="figure" target="#fig_1">Fig. 3</ref>). The second row shows perceptual distance (ΔE), plotted in the same manner as semantic distance. The third row shows mean proportion of correct responses plotted separately for each target concept because each target was assessed independently. Error bars represent standard errors of the means using the Cousineau <ref type="bibr" target="#b4">[5]</ref> adjustment to account for overall differences at the subject level. The bottom row shows predicted response accuracy using regression equations from <ref type="table" target="#tab_1">Table 1</ref>.</p><p>a given trial was displayed as text positioned above the graph (20 pt font), centered on the x-axis. Thus, the full experiment design included 2 target concepts (cantaloupe or strawberry) × 28 color pairs × 2 positions of the colors within each pair (left or right) × 2 taller bar sides (left or right) × 3 repetitions, producing 672 trials. The displays were generated and presented using Presentation (www. neurobs.com). The monitor was a 24.1 in ASUS ProArt PA249Q monitor (1920 × 1200 resolution), viewed from about 60 cm. The background was gray (CIE Illuminant D65, x = .3127, y = .3290, Y = 10 cd/m 2 ). We used a white point of D65, luminance = 100 cd/m 2 ) to convert between CIELAB and CIE 1931 xyY coordinates. We used a Photo Research PR-655 SpectraScan spectroradiometer to characterize the monitor and verify accurate presentation of the colors. The deviance between the measured and target colors in CIE 1931 xyY coordinates was &lt; .01 for x and y, and &lt; 1 cd/m 2 for Y.</p><p>Procedure. The participants were told that they would be presented with a series of bar graphs, each showing a different person's preferences for two fruits, cantaloupe and strawberry. Within each graph, one bar would represent cantaloupe and the other bar would represent strawberry. The bars would have different colors, but would not be labeled. Above the graph, participants would see the name of one of the two fruits, cantaloupe or strawberry. Their task was to decide which bar corresponded to the fruit described above the graph and to respond by pressing the corresponding arrow key (left or right). Participants were reminded that the bars would not be labeled, and were asked to use their intuition about which bar color corresponded to the fruit described.</p><p>Participants then completed five practice trials drawn at random from all possible trials. They then completed the 672 test trials, presented in a blocked randomized design (three blocks to accommodate three repetitions). Each block included all combinations of targets, color pairs, color positions, and bar height positions, presented in a random order. Participants received a break after each set of 28 trials. Stimuli remained on the screen until participants responded, and trials were separated by a 500-ms inter-trial interval. We recorded which color was chosen and the response time (RT) to make the choice on each trial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Discussion</head><p>We first present results on accuracy, where "correct" was defined as the solution to the assignment problem for both possible targets and the two colors on a given trial (see Sections 2.1 and 3.2.1). We then present results on RTs, which can be interpreted as how difficult it was to make the decision on each trial, regardless of accuracy.</p><p>Accuracy. <ref type="figure" target="#fig_4">Fig. 5E</ref> shows mean accuracy for each color pair when the target was cantaloupe (left) or strawberry (right). To obtain these means, we first calculated the proportion of correct trials for each participant, for each target (cantaloupe or strawberry) and each pair of colors (all 28 combinations of 8 colors). This proportion included 12 data points (2 left/right positions of the colors within each pair × 2 positions of the taller bar within the bar graph × 3 repetitions). We then calculated the mean for each target and color pair across participants.</p><p>The correct color for each target and each color pair is indicated by the color positions on the x-axes of <ref type="figure" target="#fig_4">Fig. 5E</ref>. Within each color pair, the color toward the left on the x-axis was correct for cantaloupe, and the color toward the right was correct for strawberry. For example, given c 2 and c 4 , c 2 was correct for cantaloupe and c 4 was correct for strawberry.</p><p>We first highlight three key observations in <ref type="figure" target="#fig_4">Fig. 5E</ref>. First, most of the responses were well above chance. This means that participants could reliably decode our encoded mappings, even though there was no legend. Second, there is systematic variability in response accuracy across color pairs. This provides further support that human assignment inference is probabilistic, not deterministic. Recall that if a computer were solving assignment problems in our task, the outcome would be deterministic-responses would all be at 1.0 regardless of whether the assignment problem was robust or fragile (see Sections 2.1 and 3.2.2).</p><p>Third, the pattern of accuracies resembles aspects of semantic distance ( <ref type="figure" target="#fig_4">Fig. 5A</ref>) and perceptual distance <ref type="figure" target="#fig_4">(Fig. 5C</ref>). Like both predictors, accuracy tends to be greater when pairs include one cantaloupe color (c 1 -c 4 ) and one strawberry color (s 1 -c 4 ) ("between-concept pairs"), especially for cantaloupe. The predictors differ in that semantic distance increased monotonically from left to right in 5A, whereas perceptual distance is non-monotonic based on how we selected the colors. Perceptual distance is flatter among "within-concept" color pairs where colors are perceptually similar (among c 1 -c 4 and among s 1 -s 4 ), and fluctuates systematically across between-concept color pairs ( <ref type="figure" target="#fig_4">Fig 5C)</ref>. Accuracy resembles the flatness of perceptual distance for within-concept pairs where colors were most perceptually similar (especially for cantaloupe), but accuracy resembles the smoothness of semantic distance for between-concept pairs where colors were most perceptually distinct.</p><p>To test for independent effects of perceptual and semantic distance on accuracy, we used a mixed effect logistic regression (R version 4.0.2, lme4 1.1-23). The dependent measure was accuracy on each trial for each participant (1 = correct, 0 = incorrect). We included fixed effects for semantic distance and perceptual distance, and random slopes and intercepts for subjects within each fixed effect. We used z-scores of the predictors in all models to center them and put them on similar scales. As shown in <ref type="table" target="#tab_1">Table 1</ref> (Model Acc 1.1), accuracy significantly increased with increased semantic distance and perceptual distance.</p><p>Recall that both semantic and perceptual distance are symmetric, they are defined with respect to a given color pair, irrespective of the target. Thus, based on these factors alone, we would predict that the pattern of responses for both targets would be the same. However, as shown in <ref type="figure" target="#fig_4">Fig. 5E</ref>, there are systematic asymmetries. In particular, note how accuracy among pairs including the strawberry colors was greater for strawberry targets than cantaloupe targets. To fully capture this pattern of data, it is necessary to add another predictor that accounts for differences depending on the target concept.</p><p>Thus, we repeated the same model but added a new factor that could capture target-specific responses: association strength between the target and the correct color. This factor was previously shown to predict accuracy and RTs for similar data <ref type="bibr" target="#b30">[30]</ref>. As shown in <ref type="table" target="#tab_1">Table 1</ref> (model Acc 1.2), association strength significantly predicted accuracy, and the previous two factors were still significant. Therefore, accuracy increased with semantic distance, perceptual distance, and association strength between the target and the correct color. <ref type="figure" target="#fig_4">Fig. 5G</ref> shows the predicted data using weights from model Acc 1.2 in <ref type="table" target="#tab_1">Table 1</ref>. The model predictions and data for all 28 color pairs × 2 concepts are strongly correlated (r(54) = .82, p &lt; .001).</p><p>We also examined the relation between predictors in the model. Across the 28 color pairs for each of the two targets, association strength between the target and correct color was moderately correlated with semantic distance (r(54) = .43, p &lt; .001) and not significantly correlated with perceptual distance (r(54) = .21, p = .123).</p><p>Response time. without excluding trials <ref type="bibr" target="#b25">[26]</ref>. Mean RTs were negatively correlated with mean accuracy (r(54) = −.71, p &lt; .001), such that participants responded more quickly for color pairs that facilitate accuracy. We analyzed the RT data using linear-mixed effect models with the same predictors as for accuracy. The model results are in <ref type="table" target="#tab_2">Table 2</ref>. When perceptual distance and semantic distance were the only fixed effects (model RT 1.1), neither predictor explained significant variance. When association strength was added to the model, it explained significant variance, as did perceptual distance (model RT 1.2). Thus, RTs were faster when association strength was stronger and when perceptual distance was larger. <ref type="figure">Fig. 6C</ref> shows the model prediction using the weights from model RT 1.2 in <ref type="table" target="#tab_2">Table 2</ref>. Model predictions were strongly correlated with mean RTs (r(54) = .82, p &lt; .001). In summary, semantic distance and perceptual distance both independently contributed to interpretability. However, the "cantaloupe colors" and "strawberry colors" were clustered in different parts of color space, <ref type="figure" target="#fig_1">(Fig. 3A.2-3)</ref>, so conflicts between semantic and perceptual distance were only minor. In Experiment 2, we address the question of how these two factors would contribute to interpretability if they were overall decorrelated and included examples of large conflicts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT 2</head><p>This experiment tested for independent effects of semantic and perceptual distance when these two factors were uncorrelated. The pattern of association strengths was similar to Experiment 1 <ref type="figure" target="#fig_1">(Fig. 3A.1 and B.1)</ref>, so the pattern of semantic distances were also similar ( <ref type="figure" target="#fig_4">Fig. 5A and  5B</ref>). However, the relative locus of colors in CIELAB space was different. In Experiment 1, the strong associates for each concept clustered together <ref type="figure" target="#fig_1">(Fig. 3A.2-A.</ref>3), but in Experiment 2, the four "watermelon colors" were split on either side of the "mango colors" along the a* axis <ref type="figure" target="#fig_1">(Fig. 3B.2-B.3)</ref>. Thus, for watermelon, the most semantically similar colors were furthest in color distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Methods</head><p>36 undergraduates (mean age = 19.4, 18 females, 18 males) participated for credit in Introductory Psychology. All had normal color vision (screened with <ref type="bibr" target="#b9">[10]</ref>), and gave informed consent. The design, displays, and procedure were the same as Experiment 1, except we tested the colors and fruits in <ref type="figure" target="#fig_1">Fig. 3B</ref> (Table S.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and discussion</head><p>The colors and fruits in Experiment 1 and 2 differed in that their patterns of perceptual distances were uncorrelated (r(26) = .08, p = .673) but their patterns of semantic distances were almost perfectly correlated (r(26) = .99, p &lt; .001). Thus, if the patterns of data in Experiment 2 are similar to Experiment 1, they can be attributed to their similarities in semantic distance. <ref type="figure" target="#fig_4">Fig. 5F</ref> shows the mean accuracy data and <ref type="figure">Fig. 6B</ref> shows the mean RTs, calculated in the same manner as in Experiment 1. Indeed, there were significant correlations between the patterns of accuracy (r(54) = .66, p &lt; .001) and RT (r(54) = .79, p &lt; .001) between the two experiments.</p><p>Accuracy. We analyzed accuracy using the same mixed-effect logistic regression models as in Experiment 1. The first model including perceptual distance and semantic distance showed that semantic distance significantly predicted accuracy (Table 1, model Acc 2.1). The effect of perceptual distance was marginal, but it was in the opposite direction from Experiment 1. That is, accuracy tended to increase for more perceptually similar colors, probably because colors that were perceptually similar (e.g., w 1 (red) and m 2 (dark orange)) were semantically different, whereas colors that were perceptually distant were semantically similar (e.g., w 1 (red) and w 2 (green)) ( <ref type="figure">Fig. 1)</ref>.</p><p>When we added association strength between the target and correct color into the model, association strength was a significant predictor, as was semantic distance <ref type="table" target="#tab_1">(Table 1, model Acc 2.</ref>2). The effect of perceptual distance was still marginal, again in the opposite direction (more perceptually different tended to result in reduced accuracy). <ref type="figure" target="#fig_4">Fig. 5H</ref> shows the predicted accuracy based on the regression weights in model Acc 2.2. The model predictions strongly correlated with the mean accuracy data in <ref type="figure" target="#fig_1">Fig. 5F (r(54) = .83, p &lt; .001)</ref>. In this experiment, association strength between the target and correct color was again moderately correlated with semantic distance (r(54) = .42, p = .001) and not significantly correlated with perceptual distance (r(54) = −.02, p = .900).</p><p>Response time. As in Experiment 1, RT and accuracy were negatively correlated (r(54) = −.82, p &lt; .001), indicating it was easier to make decisions for color pairs that facilitated accuracy. We analyzed RTs using the same linear mixed-effect models from Experiment 1. The first model including only perceptual distance and semantic distance showed a significant effect of semantic distance and no effect of perceptual distance (Table 2, model RT 2.1). Adding association strength between the target and the correct color (model RT 2.2) resulted in significant effects of association strength and semantic distance but still not perceptual distance. <ref type="figure">Fig. 6D</ref> shows the predicted RTs based on the regression weights in model RT 2.2. The model predictions strongly correlated with the mean RTs in <ref type="figure">Fig. 6B</ref> (r(54) = .88, p &lt; .001).</p><p>In summary, semantic distance dominated interpretability when these two factors were uncorrelated overall. Perceptual distance had a marginal effect, but it was in the opposite direction from what might be expected (i.e., smaller perceptual distances tended to be more interpretable). This was because the stimulus set included cases with strong conflicts, such that large semantic distances amounted to small perceptual distances (especially for watermelon), and under such conflicts greater semantic distance resulted in greater interpretability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">GENERAL DISCUSSION AND CONCLUSION</head><p>In this study we tested whether people's ability to interpret color palettes in information visualizations depended on semantic distance, independent of perceptual distance. The results of both experiments demonstrated that increasing semantic distance improved interpretability, independent of variation in perceptual distance. In Experiment 1, we selected colors such that perceptual and semantic distance co-varied: the four colors that were most strongly associated with cantaloupe were clustered separately from the colors most strongly associated with strawberry. Under these conditions, both semantic and perceptual distance independently contributed to increased interpretability. In Experiment 2, we selected the colors in a way that decoupled perceptual and semantic distance: the four colors that were most strongly associated with mango were between the colors most strongly associated with watermelon on the a* plane of CIELAB space. Across all color pairs in Experiment 2, perceptual distance and semantic distance were uncorrelated, but there were cases in which these two factors were in direct conflict <ref type="figure">(Fig. 1)</ref>. In this experiment, accuracy and RT both improved with increased semantic distance, with no significant effects of perceptual distance. The results of this study suggest that it may be worth relaxing constraints on perceptual distance in favor of maximizing semantic distance to create interpretable color palettes.</p><p>We studied colors that were distant enough (ΔE ≥ 25) to be noticeably different <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b34">34]</ref>, but we expected that perceptual distance would play a larger role if distances were smaller. However, if colors were no longer perceptually discriminable, they would also no longer be semantically discriminable. Thus, thresholding at some degree of semantic distance may be sufficient to ensure both perceptual and semantic discriminability. Certainly, there is some lower threshold at which perceptual and semantic discriminability would be too small for interpretability, but there also may be an upper threshold at which further increasing perceptual or semantic discriminability would have no further benefit. Substantial work has investigated lower thresholds for perceptual discriminability for information visualizations <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b34">34]</ref>, but future work is needed to understand thresholds for semantic discriminability. Moreover, as in prior visualization work <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b34">34]</ref> we used ΔE as our perceptual distance metric, but future work could evaluate whether different perceptual distance metrics (e.g., CIEDE2000) are better at predicting interpretability.</p><p>As part of this study, we developed semantic distance, ΔS, as a metric to quantify semantic discriminability between pairs of colors and concepts. Semantic distance is the absolute difference in the probabilities that a random observer will make each of the two possible assignments, where the randomness is due to inherent variability in association strengths across individuals. Quantifying semantic discriminability becomes more difficult when there are more than two colors or two concepts because there are more than two possible assignments. Solving assignment problems becomes more complicated in this case, and we cannot write a simple formula as in (2) to compute assignment probabilities. <ref type="bibr" target="#b1">2</ref> Possible approaches for quantifying semantic discriminability for more than two colors and concepts could involve obtaining a distribution over possible assignments (e.g., via Monte Carlo simulation), resulting from uncertainty in color-concept association ratings and applying one of many possible metrics. For example, if we used entropy, maximum entropy would correspond to the fragile case of all assignments having equal probability. Conversely, minimum entropy would correspond to the robust case of one assignment having a very high probability and all other assignments having near-zero probability.</p><p>In this study, we used mean human color-concept association ratings to quantify association strengths. However, efficient automated approaches exist for estimating color-concept associations using images <ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b26">27]</ref> and natural language databases <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b31">31]</ref>. Different methods can be used to extract colors from images, but evidence suggests methods that leverage perceptual dimensions of color and cognitive representations of color categories are best for estimating human color-concept associations <ref type="bibr" target="#b26">[27]</ref>. Such estimates, combined with an appropriate method for quantifying variance in the sample images, could be used as input to calculate semantic distance.</p><p>The results of this study can help with designing interpretable color palettes, but interpretability is only one of the many goals in color palette design. Other priorities might include helping observers (1) locate a target in visual search <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b38">38]</ref>, (2) estimate the area of colored regions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref>, (3) refer to the colors easily by name <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b3">(4)</ref> appreciate the visualization aesthetically <ref type="bibr" target="#b7">[8]</ref>, or (5) obtain an affective impression from the overall palette <ref type="bibr" target="#b1">[2]</ref>. Different design properties are relevant for these different priorities. For example, the ability to estimate the relative area occupied by colored regions increases with perceptual distance between colors, but aesthetic preferences for those same visualizations decreases with perceptual distance <ref type="bibr" target="#b7">[8]</ref>. Extensive work is needed to understand how to navigate such trade-offs in palette design, depending on the priorities and format of a given visualization <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b33">33]</ref>. The present work provides a step in that direction by showing that maximizing perceptual distance is not necessary for creating interpretable color palettes, leaving room for maximizing the other factors that contribute to effective palette design.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>(A) Color-concept associations and CIELAB coordinates for colors tested in Experiment 1. (A.1) Mean association strength between each color with the concept labeled at the top of the column (error bars are standard errors of the means. Bar colors indicate the colors that were tested (see</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Illustration of semantic distance calculation using pairwise association ratings x i between the colors m 4 and w 4 and the concepts Mango (M) and Watermelon (W). Distributions are normal distributions fit to individual participants' color-concept association ratings, with the dashed line showing the mean corresponding to the bars in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>The left column (A,C,E,G) refers to Experiment 1 (cantaloupe and strawberry) and the right column (B,D,F,H) shows the analogous data for Experiment 2 (mango and watermelon). We will describe the left column. The top row shows semantic distances (ΔS) for all pairs of colors. Since ΔS for a pair of colors is defined in the context of both target fruits, we can represent the data in a single plot. The plot contains 28 points, one for each pair of distinct colors from the set of 8 colors. Each of the 28 points is identified with a pair of colors as follows. The color of the point itself identifies the first color, and the vertical dashed line crossing that point leads to a label on the x-axis, identifying the second color. Thus, all points connected by dashed lines share a common color, and likewise for the solid lines. The colored squares along the x-axis and associated labels also serve as a legend for the mark colors. In (A), colors c 1 to c 4 are the colors most strongly associated with cantaloupe and s 1 to s 4 are the colors most associate with strawberry (lower subscripts are more strongly associated with the fruit indicated by the letter, see also</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3 Figure 6 .</head><label>36</label><figDesc>Fig. 6Ashows mean RTs for each color pair, obtained by first calculating the median RT across all 12 trials for each target and color pair for each participant, and then calculating the mean over participants. Treating RTs this way avoids effects of outliersMean RT (sec.) Pred. RT (sec.) Mean RT (sec.) Pred. RT (sec.) The top row shows mean RTs for (A) Experiment 1 and (B) Experiment 2, plotted in the same manner as in Fig. 5. Error bars represent standard errors of the means, using the Cousineau [5] adjustment to account for overall differences at the subject level. The bottom row shows regression predictions for RTs using the model with all three predictors in Table 2 in (C) Experiment 1 and (D) Experiment 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Mixed-effect logistic regression models of accuracy in Experiment 1 (Acc 1.1, Acc 1.2) and Experiment 2 (Acc 2.1, Acc 2.2).</figDesc><table><row><cell>Model</cell><cell>Factor</cell><cell>β</cell><cell>SE</cell><cell>z</cell><cell>p</cell></row><row><cell cols="2">Acc 1.1 Intercept</cell><cell cols="2">0.89 0.14</cell><cell cols="2">6.37 &lt;.001</cell></row><row><cell></cell><cell>PercDist</cell><cell cols="2">0.22 0.06</cell><cell cols="2">3.58 &lt;.001</cell></row><row><cell></cell><cell>SemDist</cell><cell cols="2">0.34 0.07</cell><cell cols="2">4.96 &lt;.001</cell></row><row><cell cols="2">Acc 1.2 Intercept</cell><cell cols="2">0.91 0.14</cell><cell cols="2">6.38 &lt;.001</cell></row><row><cell></cell><cell>PercDist</cell><cell cols="2">0.26 0.06</cell><cell cols="2">4.11 &lt;.001</cell></row><row><cell></cell><cell>SemDist</cell><cell cols="2">0.23 0.07</cell><cell>3.05</cell><cell>.002</cell></row><row><cell></cell><cell>Assoc</cell><cell cols="2">0.23 0.05</cell><cell cols="2">4.77 &lt;.001</cell></row><row><cell cols="2">Acc 2.1 Intercept</cell><cell cols="2">0.97 0.12</cell><cell cols="2">8.36 &lt;.001</cell></row><row><cell></cell><cell cols="4">PercDist -0.06 0.03 -1.90</cell><cell>.057</cell></row><row><cell></cell><cell>SemDist</cell><cell cols="2">0.55 0.06</cell><cell cols="2">9.24 &lt;.001</cell></row><row><cell cols="2">Acc 2.2 Intercept</cell><cell cols="2">1.00 0.12</cell><cell cols="2">8.45 &lt;.001</cell></row><row><cell></cell><cell cols="4">PercDist -0.06 0.03 -1.84</cell><cell>.066</cell></row><row><cell></cell><cell>SemDist</cell><cell cols="2">0.41 0.06</cell><cell cols="2">6.86 &lt;.001</cell></row><row><cell></cell><cell>Assoc</cell><cell cols="2">0.37 0.05</cell><cell cols="2">7.95 &lt;.001</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Linear mixed-effects regression models of RT in Experiment 1 (RT 1.1, RT 1.2) and Experiment 2 (RT 2.1, RT 2.2).</figDesc><table><row><cell>Model Factor</cell><cell>β</cell><cell>SE</cell><cell>df</cell><cell>t</cell><cell>p</cell></row><row><cell>RT 1.1 Interept</cell><cell cols="2">1017.7 53.2</cell><cell cols="3">35.0 19.1 &lt;.001</cell></row><row><cell>PercDist</cell><cell cols="4">-29.3 17.1 121.4 -1.7</cell><cell>.088</cell></row><row><cell>SemDist</cell><cell cols="2">-37.2 20.6</cell><cell cols="2">39.0 -1.8</cell><cell>.078</cell></row><row><cell>RT 1.2 Interept</cell><cell cols="2">1017.7 53.2</cell><cell cols="3">35.0 19.1 &lt;.001</cell></row><row><cell>PercDist</cell><cell cols="4">-42.8 17.0 156.9 -2.5</cell><cell>.013</cell></row><row><cell>SemDist</cell><cell cols="2">1.9 19.6</cell><cell>78.6</cell><cell>0.1</cell><cell>.924</cell></row><row><cell>Assoc</cell><cell cols="2">-68.3 15.9</cell><cell cols="3">48.0 -4.3 &lt;.001</cell></row><row><cell cols="3">RT 2.1 Intercept 1121.5 62.3</cell><cell cols="3">35.0 18.0 &lt;.001</cell></row><row><cell>PercDist</cell><cell>12.1</cell><cell>8.0</cell><cell>35.0</cell><cell>1.5</cell><cell>.139</cell></row><row><cell>SemDist</cell><cell cols="2">-86.4 15.1</cell><cell cols="3">35.0 -5.7 &lt;.001</cell></row><row><cell cols="3">RT 2.2 Intercept 1121.5 62.3</cell><cell cols="3">35.0 18.0 &lt;.001</cell></row><row><cell>PercDist</cell><cell>9.0</cell><cell>7.9</cell><cell>35.0</cell><cell>1.1</cell><cell>.260</cell></row><row><cell>SemDist</cell><cell>-36.0</cell><cell>9.9</cell><cell cols="3">35.0 -3.6 &lt;.001</cell></row><row><cell>Assoc</cell><cell cols="2">-120.6 20.0</cell><cell cols="3">35.0 -6.0 &lt;.001</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Many other choices could be made here, by picking other functions that have a similar qualitative shape (i.e., zero standard deviation whenx = 0 or 1 and maximum standard deviation whenx = 0.5). We experimented with other options and found our results to be robust with respect to the choice of function.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Generally, solving a large assignment problem (many colors and concepts) cannot be reduced to solving a sequence of smaller two-color two-concept assignment problems. For example, the colors (red,yellow) and concepts (apple,banana) have a straightforward assignment, but if we add another color and concept: (red,yellow,green) and (apple,banana,strawberry), then apple switches from red to green due to the presence of strawberry.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank Ragini   </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Task-driven evaluation of aggregation in time series visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="551" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Affective color in visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2017 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1364" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Color use guidelines for mapping and visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization in Modern Cartography</title>
		<editor>A. M. MacEachren and D. R. F. Taylor</editor>
		<meeting><address><addrLine>Tarrytown</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Science Inc</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="123" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graphical perception: The visual decoding of quantitative information on graphical displays of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcgill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series A (General)</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="192" to="210" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Confidence intervals in within-subject designs: A simpler solution to loftus and masson&apos;s method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cousineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tutorials in Quantitative Methods for Psychology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="45" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Colour on temperature maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cuff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Cartographic Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="21" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Systematicity and surface similarity in the development of analogy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gentner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Toupin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="300" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Colorgorical: Creating discriminable and preferable color palettes for information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Gramazio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Schloss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="521" to="530" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The relation between visualization size, grouping, and user performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Gramazio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Schloss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1953" to="1962" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">H</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Rittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<title level="m">HRR Pseudoisochromatic Plates. Richmond Products</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">How capacity limits of attention influence information visualization effectiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Whitney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ColorBrewer.org: an online tool for selecting colour schemes for maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harrower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Brewer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Cartographic Journal</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="37" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automated color selection using semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Holmgren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 AAAI Fall Symposium Series</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Choosing effective colours for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Conference on Visualization&apos;96</title>
		<meeting>the 7th Conference on Visualization&apos;96</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page">263</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Color naming models for color selection, image editing and palette design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1007" to="1016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The cognitive science of visual-spatial displays: Implications for design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hegarty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="446" to="474" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Graph Design for the Eye and Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>OUP</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics Quarterly</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Selecting semantically-resonant colors for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="401" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What is the color of chocolate?-extracting color values of semantic expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lindner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Süsstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Colour in Graphics, Imaging, and Vision</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="page" from="355" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A large-scale multilingual color thesaurus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lindner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Süsstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Color and Imaging Conference</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ordering choropleth map symbols: The effect of background</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mcgranaghan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Cartographer</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="279" to="285" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Algorithms for the assignment and transportation problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Munkres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Industrial and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="38" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The Design of Everyday Things: Revised and Expanded Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Norman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Basic Books (AZ)</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual aesthetics and human preference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Schloss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sammartino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="77" to="107" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Methods for dealing with reaction time outliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">510</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Estimating colorconcept associations from image statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rathore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Leggon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lessard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Schloss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1226" to="1235" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T</forename><surname>Ruginski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Boone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Padilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heydari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hegarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>House</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Creem-Regehr</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Non-expert interpretations of hurricane forecast uncertainty visualizations</title>
	</analytic>
	<monogr>
		<title level="j">Spatial Cognition &amp; Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="172" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mapping color to meaning in colormap data visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Schloss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Gramazio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="810" to="819" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Color inference in visual communication: the meaning of colors in recycling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Schloss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lessard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Walmsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Foley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Research: Principles and Implications</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A linguistic approach to categorical color assignment for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="698" to="707" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Review of graph comprehension research: Implications for instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoeffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational Psychology Review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="69" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An engineering model for color difference as a function of size</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Color and Imaging Conference</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page" from="253" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Modeling color difference for visualization design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Szafir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="392" to="401" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A feature-integration theory of attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Treisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gelade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="136" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Visualizing thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="page" from="499" to="535" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Animation: can it facilitate?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Betrancourt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="247" to="262" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Five factors that guide attention in visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Visual perception and map design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Cartographic Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="64" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The curse of knowledge in visual data communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Weelden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Bars and lines: A study of graphic communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1073" to="1079" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
