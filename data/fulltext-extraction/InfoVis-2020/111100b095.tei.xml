<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Lee</surname></persName>
							<email>benjamin.lee1@monash.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Brown</surname></persName>
							<email>dave.brown@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bongshin</forename><surname>Lee</surname></persName>
							<email>bongshin@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Hurter</surname></persName>
							<email>christophe.hurter@enac.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Drucker</surname></persName>
							<email>sdrucker@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dwyer</surname></persName>
							<email>tim.dwyer@monash.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">are with Monash University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">French Civil Aviation University</orgName>
								<orgName type="institution">ENAC</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">received xx xxx. 201x; accepted xx xxx. 201x.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data visceralization</term>
					<term>virtual reality</term>
					<term>exploratory study</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Prototypes of data visceralizations in VR based on popular representations of physical measurements. (a) Scorecard of results in seconds from Olympic Men&apos;s 100 m. (b) Data visceralization equivalent to experience one-to-one scale of Olympic sprint speeds. (c) Comparison diagram of tall skyscrapers (© Saggittarius A, CC BY-SA 4.0). (d) Data visceralization equivalent to experience and compare true one-to-one scale of select skyscrapers.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Communicating information using stories that employ data visualization has been explored extensively in recent years <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49]</ref>. A fundamental part of data visualization is processing and transforming raw data, ultimately mapping this abstracted information into attributes represented in a visualization <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17]</ref>. This abstraction, while powerful and in many cases necessary, poses a limitation for data based on physical properties, where the process of measurement causes the connection between the visualization and the underlying 'meaning' of the data to be lost (i.e., what the data truly represents in the real-world). While techniques in data-driven storytelling (e.g., <ref type="bibr" target="#b51">[52]</ref>) can help establish context and resolve ambiguity in these cases, these techniques do little to help people truly understand the underlying data itself. A common approach used to help improve comprehension of these measures is by using concrete scales <ref type="bibr" target="#b12">[13]</ref>-the association of physical measurements and quantities with more familiar objects. However, this often relies on prior knowledge and requires cognitive effort to effectively envision the desired mental imagery.</p><p>To complement these approaches in data visualization and storytelling, we introduce data visceralization, which we define as a datadriven experience which evokes visceral feelings within a user to facilitate intuitive understanding of physical measurements and quantities. By visceral, we mean a "subjective sensation of being there in a scene depicted by a medium, usually virtual in nature" <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. To illustrate this <ref type="figure">Fig. 2</ref>. Our conceptual data visceralization pipeline in relation to the information visualization pipeline <ref type="bibr" target="#b10">[11]</ref>. Both run in parallel to each other, with data visceralization aimed at complementing data visualization.</p><p>concept, consider the scenarios depicted in <ref type="figure">Fig. 1</ref>(a,c). Many of us are familiar with 100 m sprint times, but understanding the 'ground truth'how fast they are actually running-is elusive. Similarly, images or diagrams showcasing tall buildings such as skyscrapers are common, but mentally envisioning what these actually look like without prior knowledge is challenging. In these scenarios, only by seeing the actual sprinter or building will achieve this truth. In a sense, seeing-or more generally, experiencing-is believing. With virtual reality (VR) technology rapidly advancing and becoming more readily available, it offers an unprecedented opportunity for achieving these visceral experiences in a manner that is both cost effective and compelling. As depicted in <ref type="figure">Fig. 1(b,d</ref>), we can now simulate what it's like to have Olympic sprinters run right past you, or the feeling of being next to one of these skyscrapers. From these experiences, a thorough understanding of these measures and quantities may be achieved, with data visualization and visceralization existing hand-in-hand to provide both quantitative (i.e., analytical reasoning) and qualitative (i.e., the ground truth) understanding of the data <ref type="figure">(Fig. 2)</ref>.</p><p>In this work, we explore this concept of data visceralization. We develop six VR prototypes as design probes based on existing data stories and visualizations specifically chosen to explore a range of different measures and phenomena. We critically reflect on these design probes, identifying key themes and factors for data visceralization such as: the appropriate types of measures and quantities; the ranges of magnitudes of physical phenomena that are suitable; and the situations where they are effective or not. We expand this reflection through sessions with external participants to gain feedback on the value and intricacies of data visceralization.We conclude by discussing multiple aspects of data visceralizations, along with future work in the area.</p><p>In summary, the main contributions of this paper are:</p><p>• The introduction of the novel concept of data visceralization, and its applications for understanding the data that underlies visualizations • A set of prototype examples to demonstrate the concept and characterize the experiences • An exploration into the factors and considerations behind data visceralization, through both a critical reflection by the authors and external feedback from participants</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>While our work focuses on virtual reality (VR), the concept of data visceralization can be applied much more broadly. There are other non-VR oriented methods of helping people understand a unit or measure such as scale models, immersive IMAX films, museum exhibits <ref type="bibr" target="#b40">[41]</ref>, or first hand experiences. In this section, we discuss data visceralization in the context of other related fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">(Immersive) Data-Driven Storytelling</head><p>Segel and Heer <ref type="bibr" target="#b48">[49]</ref> coined the term narrative visualization in 2010.</p><p>Since then, researchers have explored the design patterns of specific genres of narrative visualizations, such as Amini et al. <ref type="bibr" target="#b0">[1]</ref> with data videos and Bach et al. <ref type="bibr" target="#b1">[2]</ref> with data comics. In contrast, work by Stolper et al. <ref type="bibr" target="#b51">[52]</ref> characterized the range of recently emerging techniques used in narrative visualization as a whole. With the increased use of VR and augmented reality (AR) devices for the purposes of data visualization and analytics (known as immersive analytics <ref type="bibr" target="#b37">[38]</ref>) and for storytelling in general <ref type="bibr" target="#b9">[10]</ref>, it is feasible to begin considering how these devices can be used for immersive data-driven storytelling <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b32">33]</ref>. Recent work by Ren et al. <ref type="bibr" target="#b45">[46]</ref> has investigated the creation of immersive data stories, and work by Bastiras et al. <ref type="bibr" target="#b4">[5]</ref> of their effectiveness, but these resort to using simple 2D images in a VR environment rather than taking full advantage of the device's capabilities. A VR piece from the Wall Street Journal <ref type="bibr" target="#b29">[30]</ref> remains one of the few compelling examples of an immersive data story, using a time series of the NASDAQ's price/earnings ratio over 21 years as a roller coaster track which the reader then rides from one end to the other. The story particularly focuses on the sudden fall in the index as the dot-com bubble began to burst in 2000, having readers experience this metaphorical fall as a literal roller coaster drop in VR. In this work, we examine the use of immersive environments to achieve similar effects of transforming data into visceral experiences, but in a complementary fashion to existing data stories. That is, we focus on aiding the understanding of the underlying data itself through the use of VR, while the narrative and visualizations of the story set the context, background, and messaging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Concrete Scales and Personalization</head><p>The use of concrete scales is a popular technique used to aid in comprehending unfamiliar units and extreme magnitudes by comparison to more familiar objects. To formalize this technique, Chevalier et al. <ref type="bibr" target="#b12">[13]</ref> collected and analyzed over 300 graphic compositions found online. They derived a taxonomy of object types and measure relations, and identified common strategies such as using analogies of pairwise comparison and juxtaposing multiples of smaller objects together. They discussed the need and challenges of choosing good units, a problem which Hullman et al. <ref type="bibr" target="#b23">[24]</ref> addressed by automatically generating different re-expression units which may be more familiar to the user. Concrete scales fundamentally assists in building mental models of scale. In contrast, we use data visceralization to directly represent the measure that is being conveyed to the user, effectively skipping this process altogether.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Data Physicalization</head><p>As compared to information visualization which maps data into visual marks and variables <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17]</ref>, data physicalization explores how data can be encoded and presented in tangible, physical artifacts through its geometric and/or material properties <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>. Although users can directly experience data in a unique physicalized manner, it still fundamentally transforms and remaps abstract data into tangible experiences, often in equivalents of common visualization types <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b52">53]</ref>. While this tangibility may provide benefits for memory or engagement, the focus is on some higher level conceptual data rather than the physical property or measure itself. Data physicalization could be well suited for creating visceral experiences if attributes are represented without transformation, as any physical phenomena can theoretically be fabricated and subsequently experienced. However, this would be resource intensive and heavily dependent on advances in technology. Indeed, many museum exhibits construct one-to-one mappings of data phenomena so that people can understand the underlying data in representation, but such exhibits are expensive and also can only be experienced by visiting them. Therefore technologies such as VR are well suited for visceralization, overcoming barriers such as fabrication cost and physical space restrictions through use of virtual locomotion techniques <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Immersion and Presence in VR</head><p>VR and immersive technologies as a whole have been available for many decades, and have been extensively studied for their impact on human perception. Core to these technologies are the notions of immersion and presence, where immersion is a characteristic of the technology that enables a vivid illusion of reality to the user, and presence is the state of consciousness of being in the virtual environment <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref>. Presence is a form of visceral communication that is primal but also difficult to describe <ref type="bibr" target="#b27">[28]</ref>. This notion of presence and viscerally believing that the virtual world is real is what we aim to leverage with visceralization. VR devices have proven effective enough in doing this that they have been used in applications such as psychological treatment <ref type="bibr" target="#b53">[54]</ref>, journalism <ref type="bibr" target="#b13">[14]</ref>, and military training <ref type="bibr" target="#b33">[34]</ref>. Moreover, VR and AR has been used in scenarios where spatial representations of 3D objects are necessary, such as in 3D modeling <ref type="bibr" target="#b38">[39]</ref> and medical imaging <ref type="bibr" target="#b58">[59]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Human Perceptual Psychology and Pyschophysics</head><p>The sense of presence within VR draws on principles of Gibsonian psychology <ref type="bibr" target="#b18">[19]</ref> which ties human perception and movement to the overall comprehension of the environment. When the scene changes as result of a change in our head position, we perceive that as movement through an environment. Given the focus on the stimuli which simulate the physical measurements and quantities in data visceralization, we draw upon high level concepts from the extensive field of psychophysics <ref type="bibr" target="#b20">[21]</ref>, most notably the notion of human perceptual limits and how this may impact the ranges of stimuli used. We use this notion to systematically scope our design probes in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN PROBES INTO DATA VISCERALIZATION</head><p>To explore and better define the concept of data visceralization, we developed a set of VR prototypes using the Unity3D game engine. We critically reflect on these prototypes, with each prototype requiring 1 to 2 weeks to create, test, and critique. These design probes were conducted using an ASUS Windows Mixed Reality Headset (HC102) in an open space free of obstructions. Each prototype was adapted either from existing stories published in online journals and news articles, or from popular data-driven graphics/visualizations. We strove to test a range of different scenarios to explore data visceralizations as much as possible. In this section, we describe six of these design probes, which we refer to as examples for simplicity and abbreviate as E1 , E2 , E3 , E4 , E5 , and E6 . The first half focuses on scenarios with common types and scales of physical phenomena, not requiring any scaling or transformation to be readily perceived in VR.  <ref type="figure">(Fig. 1a)</ref>, the story shows the relative distance away from the finish line each sprinter would be when Bolt finishes, highlighting the wide margins between him and the competition. This is shown in a video rendered with 3D computer generated graphics ( <ref type="figure" target="#fig_0">Fig. 3a)</ref> and an accompanying scatterplot-like visualization. This relative distance helps to quantitatively compare how much faster Bolt is than the rest. However, neither the visualization nor video give an accurate notion of just how fast Olympic sprinters can run. While watching it live in person may provide this, most people will not have the opportunity to do so, let alone stand on the track during the event, and it is impossible to resurrect runners from the last 100 years. We based our prototype on the original story's video in a virtual environment at real-world scale <ref type="figure" target="#fig_0">(Fig. 3b</ref>). The user can play, pause, and restart the race, causing each sprinter to run down the track at their average speed. We initially used simple human-sized cubes for the sprinters <ref type="figure" target="#fig_0">(Fig. 3c</ref>), later replacing them with anatomical 3D models. We detail this notion later in Sec. 4.3. Thanks to the flexibility of VR, the race can be experienced from almost any perspective: standing at any position on the track and watching them run past, floating above the track, or even moving with the fastest/slowest sprinter ( <ref type="figure" target="#fig_0">Fig. 3d)</ref>, which demonstrates the relative speed between sprinters and provides a glimpse of what it might be like from their perspective. One clear issue early on was that by copying the original story's environment and its open, endless void, it was challenging to properly assess the speed of each sprinter. While it was still possible to make objectrelative judgments between sprinters <ref type="bibr" target="#b27">[28]</ref>, the lack of background meant there was no clear frame of reference for the virtual environment itself. We decided to add a stadium model around the track to resolve this issue, which also aided in immersion and contextual information to the experience. To further improve awareness, we also looked at adding optional annotations of exact times and speeds above each sprinter's head ( <ref type="figure" target="#fig_0">Fig. 3e</ref>), as well as experimenting with superimposing all sprinters on top of one another <ref type="figure" target="#fig_0">(Fig. 3f)</ref>. The latter was motivated by there being more than 80 lanes in the track, making it difficult to see everything at once. Note that we only re-scaled the width of the entire track for this, keeping the length of the track the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E2 -Distance: Olympic Men's Long Jump</head><p>Unlike the progressively record breaking times of the Olympic Men's 100 m into the new millennium, 1968 saw Bob Beamon get the world record for the farthest long jump at 8.9 m (29 ft 2.5 in), and still holds the Olympic record to this day-losing the world record to Mike Powell in 1991 at 8.95 m (29 ft 4.25 in). Told in a similar fashion to the Men's 100 m Sprint story with video and visualization <ref type="bibr" target="#b44">[45]</ref>, Bob Beamon's Long Olympic Shadow <ref type="bibr" target="#b43">[44]</ref> highlights not only Beamon's performance relative to his peers, but also the sheer distance that these athletes can jump to begin with: comparable to the distance of a basketball 3-point line <ref type="figure" target="#fig_1">(Fig. 4a</ref>). This comparison serves to put these distances into perspective, but what if one hasn't played basketball or even set foot on a basketball court? Of course, it is possible to use a more familiar anchor instead <ref type="bibr" target="#b23">[24]</ref>, but visualizing these distances at real-life scales would allow users to experience them for themselves. Our VR prototype shares much in common with E1 , the key difference being the use of distance rather than speed. While the user can still control the playback of the event, the focus is on the final 'freeze-frame' of each long jumper at the end of their jump <ref type="figure" target="#fig_1">(Fig. 4b</ref>).</p><p>The user can change their viewpoint to any position to get a visceral sense of the sheer distance of the long-jumpers ( <ref type="figure" target="#fig_1">Fig. 4c)</ref>, which is not possible by just watching the video. As is the case with E1 , we also superimpose all of the long-jumpers on top of one another for easier comparison. Given the precision and fine differences of the results in long jump however, the long-jumpers can instead be viewed as planted flags to more closely judge distances between each other ( <ref type="figure" target="#fig_1">Fig. 4d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E3 -Height: Comparison of Skyscrapers</head><p>When comparing physical measurements of related objects or creatures, one common visualization to use is a comparison diagram. This juxtaposes each subject as 2D images or silhouettes, with the y-axis usually showing height. One popular use of this is the comparison of skyscrapers, such as the one shown in <ref type="figure">Fig. 1c</ref>. These are great for understanding relative sizes between objects (e.g., that Mount Elbrus, Kilimanjaro, and Denali are roughly equivalent in elevation), but not the absolute size of each subject (i.e., what it feels like to be at the base of a mountain roughly 6 km or 3.7 mi tall). We decided to create a VR version of the skyscraper diagram seen in <ref type="figure">Fig. 1c</ref>. We chose skyscrapers because their size can be overwhelming to see and experience, but is still familiar to people living in cities with tall skylines. Our prototype uses 3D models of famous skyscrapers and landmarks (Statue of Liberty, Space Needle, Eiffel Tower, CN Tower, and Burj Khalifa) positioned side-by-side in a similar fashion to the original visualization. These models are scaled as accurately as possible to their real-world counterparts. As with the prior examples, it is possible to move around the environment in ways that are either not available to most people, such as viewing from below ( <ref type="figure" target="#fig_2">Fig. 5a</ref>) or from the top of each skyscraper ( <ref type="figure" target="#fig_2">Fig. 5b</ref>), or in ways that are physically impossible, such as flying around in a 'Superman'-like fashion.We also experimented with adding visual cues to aid in scale perception, such as life-sized people randomly walking at ground-level ( <ref type="figure" target="#fig_2">Fig. 5c</ref>) to simulate the feeling of 'seeing people as ants,' and casting shadows from skyscrapers to the ground ( <ref type="figure" target="#fig_2">Fig. 5d</ref>) as an artificial 'ruler.' In addition, we explored two alternative views of the scene. The first was to miniaturize the skyscrapers such that they were approximately 2 m (6 ft 7 in) in size and allowing the user to pick up and re-position them <ref type="figure" target="#fig_2">(Fig. 5e</ref>). The second was to retain their real-world scale, but position the user far away enough so that the skyscrapers still occupied a similar space in the user's field of view ( <ref type="figure" target="#fig_2">Fig. 5f</ref>). We elaborate on this difference in Sec. 4.6. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E4 -Scale: Solar System</head><p>Many graphics, visualizations, and videos exist to educate people on the enormous scale of our solar system. One such example <ref type="bibr" target="#b42">[43]</ref> ( <ref type="figure" target="#fig_3">Fig. 6a</ref>) focuses on the surprisingly large distance between the Earth and the Moon. It does so by illustrating how all of the other planets can fit between the two when at their average distance apart. This presented a challenge which we wanted to investigate: the effects of re-scaling and transformation on viscerality in VR.</p><p>In our prototype ( <ref type="figure" target="#fig_3">Fig. 6b</ref>), we chose a ratio of 1:40,000,000 (i.e., 1 m in VR = 40,000 km in space), resulting in a real-world distance of approximately 10 m between the Earth and Moon. This struck a balance between being small enough to be able to see all planets reasonably well, but large enough to still be at a reasonable size (Earth at roughly 30 cm (12 in) in diameter). As the intent is to see the other planets comfortably fitting between the Earth and Moon, the user can grab and slide these planets as a group along a single axis to align them all together. Note that for E4 , E5</p><p>and E6 , we detail these challenges in transformation in Sec. 4.6.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E5 -Discrete Quantities (of Humans): Hong Kong Protests</head><p>Protest marches on Hong Kong's streets beginning in 2019 involved over 2 million people. To help visualize the sheer scale of this event, the New York Times stitched together several birds-eye view photographs from June 16, 2019 to form a vertical composite image in a scrolling format <ref type="bibr" target="#b57">[58]</ref>  <ref type="figure" target="#fig_4">(Fig. 7a</ref>). It combines both the small size of each individual person with the seemingly never-ending photographs to accomplish this. This begs the question, however, what is it actually like to be there in person? Is it a noticeably different experience being able to walk throughout a large crowd of people as compared to looking at photos alone, and if so, can we perceive the extreme quantities on display?</p><p>Given the technical limitations of rendering upwards to a million animated 3D humanoid models in VR, we recreate only a small section of the protest using 10,000 models. The crowd and surrounding environment are at a real-world scale, and it is possible to move through the crowd to experience being surrounded by many people <ref type="figure" target="#fig_4">(Fig. 7b)</ref>. The user can also choose to fly above the crowd in a similar way to a helicopter, without any physical limitations <ref type="figure" target="#fig_4">(Fig. 7c</ref>). However, it was clearly apparent that the idle nature of the protesters detracted a lot from the experience, to the point where using static human-sized cubes in place of the models worked just as well to convey quantities ( <ref type="figure" target="#fig_4">Fig. 7d)</ref>. We suspect that much more varied models, animated movements, and lighting would go a long way to provide a more visceral experience of being at the protest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E6 -Abstract Measures: US Debt Visualized</head><p>In US Debt Visualized in $100 Bills <ref type="bibr" target="#b19">[20]</ref>, an incomprehensibly large amount of money ($20+ trillion USD in 2017) is visualized using concrete scales. Starting from single $100 bills and moving to pallets of bills worth $100 million each, the piece culminates in comparing stacks of these pallets with other large objects, such as the Statue of Liberty as seen in <ref type="figure" target="#fig_5">Fig. 8a</ref>, putting into perspective the amount of debt. However, the true scale of each stack is difficult to properly grasp from the image, let alone without having visited the Statue of Liberty or stood under a construction crane. A similar concept was already investigated in E3 , but as money is inherently conceptual, would this transformation from abstract measure to physical measure (i.e., size of $100 bills) influence viscerality? Our VR prototype closely replicates the original piece, with stacks of pallets of bills surrounding the Statue of Liberty <ref type="figure" target="#fig_5">(Fig. 8b)</ref> with an updated total of $22+ trillion USD. Each stack is comprised of 10 × 10 × 100 = 10, 000 life-sized pallets of $100 bills, piling up to approximately 114 m in height. Given both this and E3 primarily convey height, they offer similar points of view, such as from the top of a stack <ref type="figure" target="#fig_5">(Fig. 8c)</ref> or from the bottom of a stack <ref type="figure" target="#fig_5">(Fig. 8d</ref>). To try and quantify some aspects of the experience however, we add annotations of certain heights of the objects in the scene <ref type="figure" target="#fig_5">(Fig. 8d</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CRITICAL REFLECTION ON DESIGN PROBES</head><p>In this section, we go into detail of our observations and critiques of the design probes described in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Perception: Perceptual 'Sweet-spots'</head><p>It is clear from E1 and E2 that VR experiences of human-scale data fall into a perceptual sweet-spot for data visceralization. Given that these directly relate to human performance in sport, measures such as running speed and jump length can directly be experienced with VR. E3 began to highlight some of these limits however, as all skyscrapers simply appear to be tall beyond a certain height, requiring special consideration to mitigate this (Sec. 4.2). However, a given measure being within this sweet-spot did not automatically make it easy to understand every detail of the data. For example, while E2 still conveyed the sense of distance, the values were very similar to each other, making it difficult to make comparisons between athletes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Virtuality: Manipulating the Scene to Facilitate Understanding</head><p>Because we designed and implemented our prototypes using VR, the virtual world allowed us to manipulate both the virtual objects and the user's viewpoint in ways not possible in real-life in order better facilitate understanding of the chosen phenomena. One example of manipulating objects was the positioning of athletes in E1 and E2 . Perspective foreshortening can distort the relative perception of objects in the environment, meaning that comparing athletes on either end of the ≈80 m track was difficult. In the original videos <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref> the use of fixed view points, lack of stereopsis, and orthogonal perspectives avoided this issue. Conversely, the use of VR allowed us to manipulate and play with the position of the athletes, superimposing them on top of one another <ref type="figure" target="#fig_0">(Fig. 3f</ref>) to achieve a similar orthogonal view, therefore making this comparison easier. Likewise, we can manipulate the position of the user and their viewpoint to make it easier to view and understand the phenomena, as can be seen in E3 . Certain viewpoints made it difficult to accurately judge and/or make comparisons between skyscrapers, such as when standing near the base of a skyscraper and looking directly straight up, or when the skyscraper was self-occluding (e.g., the Space Needle's observation deck). However, we overcome this by allowing the user to fly and teleport around the scene, going to the top of any skyscraper they wished. Doing so reduces the distance and angle to the other skyscrapers, making it easier to see. A surprising side effect this however, was that it provided more nuanced insights in the data, such as in E1 where moving along with the fastest/slowest sprinter grants both an experience of the speed that they were moving at, but also to compare and contrast their speed directly with all the others. More broadly, this concept of manipulation to facilitate understanding is prevalent throughout our design probes, such as juxtaposing skyscrapers from different continents in E3 and moving all planets closer together in E4 . However, if the goal is strictly to viscerally understand the data in a manner as close to reality as possible, this may negatively impact that understanding as these manipulations may be deemed unrealistic and off-putting to users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Realism: The Role of Photorealism and Abstraction</head><p>In all of our examples, we needed to add relevant contextual backgrounds and visual aids, such as the stadium in E1 and E2 . The lack of contextual cues in the environment detracted from the sense of presence, and in certain cases made the data more challenging to understand. In E1 , for example, moving along with a sprinter without any background environment present removed all sense of absolute motion, whereas in E3 and E6 , not having a floor made it difficult to judge overall height. We also explicitly manipulated the level of realism of the physical phenomena in several of the examples, such as using cubes instead of humans in E1 and E5 , as well as small flags in E2 . Surprisingly, this had little impact on the visceral feeling of the data-a human-sized cube moving as fast as an Olympic sprinter still conveys the speed in a similar manner. These observations aside, it is still unclear what role realism plays. A basic level of detail of background environments may be necessary, but it does not need to be high-fidelity.</p><p>More photorealistic rendering and simulation may be more engaging and enjoyable, but conveying visceral senses of motion and distance were achievable without highly sophisticated representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Annotation: The Use of Annotations and Distractions</head><p>While our senses are very good at judging relative sizes and speeds, we are less well suited to determining absolute values-hence the need to display exact measurements. In several examples, we experimented with augmenting the direct experience with annotations to show sizes or distances. We made sure these could be turned on and off, since we were concerned that such augmentation might impact the realism and thus the direct perception of the measures. However, as in more primitive representations, we saw little detraction from the use of annotation. This was moderately surprising since, as Bertin specifies <ref type="bibr" target="#b6">[7]</ref>, reading text can capture user attention and thus reduce the perception of other stimuli, negatively impacting the visceral experience with the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Knowledge Transfer: Applying Knowledge and Experience from Visceralization into Real-Life Contexts</head><p>Data visualisations share information and insights in data. In contrast, the physical nature of visceralizations may convey a different type of understanding that is more grounded in reality. For instance, after having seen the skyscrapers in E3 , one may then be able to 'transfer' that knowledge to real-life skyscrapers in their day-to-day life, comparing this new experience with the prior VR one. Likewise, one may see the skyscrapers in VR and be reminded of previous real-life experiences. While similar in premise to VR for tourism <ref type="bibr" target="#b21">[22]</ref>, the nature of visceralizations being more closely tied to data may aid users' perception and understanding of these physical phenomena in the wild.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Data Transformation</head><p>Given that many phenomena we wish to understand fall outside of the realm of direct perceptibly, parts of E3 , E4 , E5 , and E6</p><p>helped illuminate various pitfalls that may occur when scaling large data into ranges more readily understandable by viewers, or when remapping abstract measures into perceivable concrete units. Miniaturization: Maintaining viscerality during scaling. We chose to use skyscrapers in E3 as we considered them on the cusp of being both perceivable but also somewhat too large to properly see. To this <ref type="figure">Fig. 9</ref>. Illustration of the difference in perception when viewing an object at two different scales and distances, such that the object fills the same apparent size in the field of view. Consider a given point on the object which is projected onto a position of distance δ from the edge of the field of view of angle α. When the eye is moved by a distance Δeye, this point in the scale-down object is shifted by a distance Δnear=δ near−δ and for the real-scale object Δfar= δ far-δ . Δ far is much smaller than Δ near.</p><p>end, we experimented with having: (1) a scaling transformation applied to have a miniaturized view of the skyscrapers; and (2) a distant yet visibly equivalent view of the skyscrapers, retaining absolute scales. Despite appearing the same on a traditional monitor, they had very noticeable differences in their visceral nature when in VR. The first instance produced a significant perceptual mismatch, where motion parallax (caused by the motion of our head or body) caused significant perceived motion of the scaled skyscrapers, but little perceived notion in the second instance when far away <ref type="figure">(Fig. 9)</ref>. While the latter looked to be real skyscrapers from really far away, the former looked like miniature 3D printed models which broke the illusion of being real skyscrapers. Similarly, photographers have used perceptual mismatch techniques to make real photographs look like miniature models by adjusting angle and blur to simulate a limited focal length exposure in tilt-shift photography. Extreme Scales: Experiencing phenomena significantly out of range of perception. E4 explored a scenario where visualizing the data at a one-to-one scale would be impossible through the size of the planets. As a result of the scaling, much of the experience became similar to the miniaturized skyscrapers, where they clearly looked like scale models. Because of this, it was impossible to get any direct notion of the true size of any of the planets. However, as the relative sizes between the planets and the relative distance between the Earth and Moon were preserved, it was still possible to make comparisons between the planets and the Earth-Moon gap-arguably the intention of the original piece regardless. E5 instead explored very large quantities of discrete objects, each one at a human perceptible scale (i.e. a large crowd). While the intention was to be 'lost' in the 'sea' of people, what we found was that the occlusion of nearby people made it challenging to see long distances, and in cases where this was possible, perspective foreshortening shrunk the heads of those further away. This resulted in a metaphorical 'bubble of perception', where one could only see and get a feel for the number of people within the bubble. Conversely, density was quite simple to gauge as it only relied on estimation of the immediate surroundings. For anything involving the larger crowd as a whole (i.e. tens of thousands), changing viewpoints to have a vantage point above the rest is necessary, however at certain elevations it becomes very similar to watching a news broadcast. Abstract Values: Perceiving abstract values with data visceralization. E6 explored the notion of requiring some transformation from abstract concept to concrete object, in this case mapping money of the US debt to $100 bills. While the sheer scale of the stacks of money was present in a fashion similar to E3 , there was a level of cognitive effort required to mentally translate the visceral understanding into the abstract quantity, such that it was difficult to get any sense of direct, deep understanding of money. Since there was already a transformation from quantity of dollars into stacks of bills, it is unclear whether the VR representation gave any deeper understanding of said quantity more than the original 2D illustration would. In a sense, while the visceral experience of the concrete, physicalized representation was there, there was no visceral understanding of the original quantity itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">USER FEEDBACK</head><p>To further expand our critical reflection and minimise bias, we invited external participants to try our prototypes and give feedback on the concept of data visceralization. Since it remains a novel and somewhat abstract concept, we chose not to formally measure and evaluate the effectiveness of data visceralization, instead focusing on participants' thoughts and opinions which will help us better define the concept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Process</head><p>We recruited 12 participants (4 female ) who were all university students with a range of different backgrounds (majority computer science) and experience with VR, as indicated to the right. They were not given any monetary compensation for their time. We conducted the sessions in a large open space free of obstructions using a HTC Vive Pro connected to a desktop PC with an Intel Core i7-7800X CPU (3.5 GHz, 6 cores), Nvidia GeForce GTX 1080 (8 GB) GPU, and 32 GB of RAM. We limited the scope to three of the six prototypes described in Sec. 3: E1 , E3 , and E6 , conducted in that order from simplest to most complex, however the lack of randomization may had influenced user preferences. This was done due to time constraints, but still allowed us to obtain feedback from a representative sample of measures: speed, scale, and abstract quantities. For each prototype, participants were given both the original source material and data visceralization to try (which we now refer to as desktop version and VR version respectively). For equivalency, we trimmed the desktop version to its relevant parts and mute any sound and voiceover. Each was followed by a questionnaire (with Likert scales from 1 (strongly agree) to 7 (strongly disagree)) asking for their thoughts and opinions between the two versions. Note that the goal was not to measure which version was better, but to understand their strengths, weaknesses, and characteristics. Sessions were concluded with a semi-structured interview to elicit detailed responses and opinions of data visceralization. This was loosely structured around the topics discussed in Sec. 4, but was conducted in such a manner to allow for broader discussion driven by the participants.</p><p>The questionnaire responses and de-identified transcripts are available in supplementary material. We combined interview notes and qualitative analysis on the transcripts to identify common and interesting themes. We include only the most relevant quotes below, labeled by participant. Please refer to the transcripts for additional context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Findings</head><p>We first report on high-level results and metrics, followed by insights categorized and contrasted against relevant topics that were described in Sec. 4. We then discuss themes raised by our participants which were not part of our reflection later in Sec. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">General Results</head><p>Each session lasted for an average 82.4 minutes (Mdn = 85.5, SD = 13). Overall, all participants preferred VR for E1 and E3 , but were mixed between desktop (2 preferred), VR (6), and no preference (4) for E6 . Similarly, they reported to be more immersed in the first two prototypes, particularly due to the 'unrealistic' stacks of $100 bills being off-putting. Participants generally liked the greater freedom and immersiveness of VR, but criticized the poor communication of numerical values, specifically for E6 (discussed later). Participants spent more time on average in VR than the desktop version: 3.4 times the duration for E1 , 13.2 times for E3 , and 1.8 times for E6 . Cybersickness in VR was reported by a minority of participants only when they used flying locomotion techniques, whereby they were advised to use other techniques instead (i.e., teleportation). Most participants chose to watch the desktop versions of E1 and E6 once (presented as videos) with a few watching it twice. All participants were familiar with E3 (presented as an image).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Comparison to Critical Reflection</head><p>Virtuality: Freedom of changing viewpoint provides unique insights but requires more time to do so. In Sec. 4.2 we considered how the manipulation of the virtual environment can facilitate understanding but negatively impact viscerality. While no participant specifically mentioned that this aided their understanding, three participants remarked that having these types of environments is a core part of VR as it "Allows you to do something that you otherwise would never see." <ref type="bibr">[P10]</ref>. In contrast, two other participants stated that being in these unrealistic scenarios made them feel 'out of place', such as when flying around the environment. Neither participant said that this negatively impacted their understanding of the phenomena, however one of them clarified that things still need to be "Presented in a way that hypothetically could exist." [P11], such as stacks of $100 bills technically being possible to create if one had enough resources. In terms of the user's viewpoint, many of the benefits we described were also identified by participants, particularly the ability to view the data from any angle they wished. This meant "Every angle I was at, I could take a different bit of data from it." [P9] and they could "Consume [the experience] in a way that [had] more meaning." [P7]. However, six participants commented that they had to figure out the best viewpoints by themselves, meaning that it took longer to gain the relevant information as compared to the desktop version. We discuss this notion of reader control in Sec. 6.1. Realism: Realism is not important to understand the underlying data, but is still important for engagement. In accord with Sec. 4.3, all participants agreed that more photorealistic rendering was not required to understand the underlying quantitative data, but that it made the experience more enjoyable and engaging. In terms of using abstract models (e.g., cubes instead of runners), participants agreed that the feeling and perception of the data was the same, but some remarked that it became easier to make comparisons such as "[Telling] the alignment of each racer." [P7], mitigating similar issues identified in Sec. 4.1. Many others pointed out flaws in these abstract models, such as them needing to "Keep in mind that it was an abstracted representation of running." [P7], the inability to "Distinguish different people and separate them <ref type="bibr">[as]</ref> the blocks are all the same." [P8], losing the sense of emotional attachment to the phenomena as "A block is very abstract [which] you can interpret as anything coming at you, whereas a person generates some sort of emotion." [P9], and that abstract looking models would be boring to look at in contrast to more realistic ones. Annotation: Annotations were useful to round out the experience and were not distracting. In Sec. 4.4, we raised concerns of annotations potentially being distracting. However, no participants reported any distraction or annoyance caused by them. In fact, many complained that they were either too difficult to see or didn't provide enough information. These participants thought annotations were important as without them "You would walk away with an unfinished idea... once you put the labels in, the information is more complete." [P9]. Few others thought they weren't necessary, as "VR really makes me feel the speed [and height] difference, and in that case the label doesn't really matter." [P5]. However, none argued for the complete removal of annotations, with all agreeing that they were at least nice to have. Knowledge Transfer: The ability to apply experiences from visceralizations is uncertain, but it is still valuable to have. In Sec. 4.5 we discussed the ability to transfer this deeper understanding from visceralizations into reality. When asked if they thought they could do so, participants subjectively rated an average of 5.06 for relating to previous events (Mdn = 6, SD = 1.79) and 5.14 for future events (Mdn = 5, SD = 1.42) across all three prototypes, with E6</p><p>being the lowest rated. Of note is that many participants who gave low or neutral scores clarified that they didn't have a prior ex-perience to compare against (e.g., people running past), or that the presented scenario was far too unlikely to ever see it in the future (e.g., stacks of $100 bills). That said, two participants explicitly mentioned that it triggered previous memories, such as P7 having been under the actual Eiffel Tower or P8 with a specific tower in her home country. A few were also very adamant in their ability to do so, such as "It feels I've been next to a building that's that tall, so I can compare <ref type="bibr">[it to reality]</ref>." [P2] and "That was represented really well and was really believable as compared to my [real life] experiences." [P7]. Our measures are very subjective however, as participants were asked to hypothesize if it was possible. Most gave vague responses during the interview, but agreed that this skill was valuable to have. Regardless, we see this as a valuable means of measuring the effectiveness of data visceralization in the future (Sec. 6.6). Miniaturization: Only a few participants felt the miniaturized phenomena to be unrealistic, with others not noticing or not caring.. In Sec. 4.6 we noted differences between miniature vs distant phenomena. We asked participants if they noticed any differences in either one, making sure to be as vague as possible. Only three participants stated that the distant skyscrapers felt like real structures which were "Easier to understand than having a miniature sculpture." [P9]. However this was not due to motion parallax, but due to "The representation of the hills, the elevation, and the trees [giving] me more context to the size, the scale, <ref type="bibr">[and]</ref> the place." [P7]. All other participants gave varying responses: four saying they felt the same, one saying that the distant felt unrealistic due to the gray background <ref type="figure" target="#fig_2">(Fig. 5f)</ref>, and three saying they were useful simply to get an overview of the data similar to the original desktop version <ref type="figure">(Fig. 1c)</ref>. Abstract Values: Understanding exact magnitude of abstract values is difficult, but does not have to be the goal of visceralization. In Sec. 4.6 we noted difficulties of representing abstract concepts such as money in VR, even in its physical form such as $100 bills. All participants agreed that it was difficult to understand the exact magnitude of $20+ trillion. For some, it was the abstract nature of money being difficult to comprehend. For others, it was the lack of quantitative information provided to them which caused them these issues. As both the trimmed desktop and our VR versions did not specify how much each stack of bills was worth, it meant that they "Just looked at towers and was told it was worth trillions of dollars, which is not a number I can really comprehend anyway." <ref type="bibr">[P10]</ref>. Interestingly, some participants suggested solutions, such as showing incremental stages similar to the original piece <ref type="bibr" target="#b19">[20]</ref>, or to group the $100 bills by more familiar units such as "A block of a street, or a city." [P6] in a similar vein to concrete scales <ref type="bibr" target="#b12">[13]</ref>. While we did not ask if they still thought the experience was valuable, one participant commented that "It definitely gives a good perspective... it's good to know that $20+ trillion is that much money." [P4]. We discuss the validity of perspective/appreciation being the goal of visceralizations in Sec. 6.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>In this section we discuss the most interesting and relevant themes which were raised by our participants which were not part of our critical reflection. We then discuss broader aspects of data visceralization as well as future research opportunities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Insights from Participant Feedback</head><p>Viscerality is not required for data understanding but gives the experience more meaning. When asked about feelings of viscerality, a few participants explicitly commented that it is not required for the purposes of understanding the underlying numerical measurements, as "Data and numbers are more rational, and you don't need emotions to understand rational things." <ref type="bibr">[P11]</ref>. In contrast, many others concentrated on how visceral sensations improved their qualitative understanding of the phenomena as it made the experience feel more believable, and in some cases "Added emotion to the data... it put meaning to it." <ref type="bibr">[P9]</ref>.</p><p>When asked what types of visceral sensations they felt, common responses were the feeling of something running past you, fear of heights, sense of awe/grandness, and some discomfort from flying around in the environment (particularly for E3 ). Overall, participants thought that visceral sensations improved the experience and understanding of the physical phenomena by making it feel more believable, but was otherwise not necessary for learning exact values and numbers. Data understanding and the experience go hand in hand, but numbers are not everything. We have distinguished between the qualitative and quantitative understanding of data, with participants valuing each differently. All participants preferred VR as it provides a more immersive experience and a better qualitative understanding of what the phenomena are in reality (among other benefits). In contrast, no participants argued for quantitative understanding (i.e., knowing the exact numerical values) being a fundamental takeaway of visceralization. Instead, it is there to further facilitate the qualitative understanding of the phenomena, as "The combination of both [qualitative and quantitative], they both support each other, one standing alone might be somewhat useful but together they're better." <ref type="bibr">[P10]</ref>. Three participants even posited that trying to learn the exact numerical values was pointless, as "Who will remember the values all the time, for everything, that's crazy!?" [P6]. In some ways, the focus on the qualitative aspects guided by quantitative values is the intended purpose of data visceralization, as we do not seek to replace conventional data visualization but instead complement it. In this sense, an alternate way of phrasing the purpose of data visceralization is to gain a 'better perspective' or 'appreciation' of data, as this appreciation is oftentimes missing in data visualization. This notion highly relates to a recent viewpoint by Wang et al. <ref type="bibr" target="#b55">[56]</ref>, which argues for the importance of emotion when considering the value that data visualizations provide rather than only measuring analytic and knowledge-generating value. As such, the perceived value of visceralization by our participants leans into this-that it is more about the experience and the emotions it generates rather than just the numbers. A balance needs to be struck between letting the user explore and guiding the user. As described earlier, the ability to control the viewpoint was was useful to gain more nuanced insights by having more agency to explore. However, more time is required to determine appropriate viewing angles in VR compared to the fixed angles on the desktop, and the lack of guidance may cause users to miss important information. Some participants argued for the use of predefined viewpoints tied to specific insights as a way to alleviate this, "If you have some charts aligned to that, I can click of them and say this is the view I was looking for, so this gives me more understanding [of where] I should be going." [P12]. This notion is similar to author-driven and reader-driven stories <ref type="bibr" target="#b48">[49]</ref> in determining how much guidance to provide to the user. We can reasonably say that a middle-ground would be best suited in order to retain much of the user agency that defines VR, but different considerations may be needed when used in a more storytelling context such as in immersive journalism <ref type="bibr" target="#b13">[14]</ref>. While making comparisons were common, there are opportunities to highlight individual characteristics of standalone phenomena. We noticed that participants almost always made comparisons between objects in the scene, such as comparing the speeds of different runners or the height of the Statue of Liberty against a stack of $100 bills. Three participants explicitly stated that making these comparisons was a core part of their experience, but gave mixed responses when asked if this would still be the case when only a single object/phenomena was shown. One said that it would only have the same impact "If you've had prior experience of being on heights <ref type="bibr">[</ref> ." In this circumstance, the data visceralization presents information beyond just the quantitative measures, but to include other characteristics of the chosen phenomena as well. While the hope is that visceralization can assist with understanding individual phenomena without the need for comparison, it is apparent there are alternative options for communicating more information should the opportunity present itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">One-to-One Mapping from Data to Visceralization</head><p>Based on our critical reflection (Sec. 4.6) and external feedback sessions (Sec. 5.2), it is clear that data visceralizations involving a one-to-one translation from their 'ground truth' are ideal, as they most accurately portray the underlying data. When a transformation is applied to the data, this connection to the ground truth is broken. However, it is still possible to understand comparisons between the transformed phenomena. Moreover, many participants reported that they were still able to gain an appreciation and perspective of the data-both specifically for E6 and for data visceralizations as a whole. In this sense, despite not being the original intention, data visceralization can still provide value in instances where one-to-one mappings are not possible, either by rescaling the data or using concrete scales <ref type="bibr" target="#b12">[13]</ref>. This transformation needs to be done with care, however, as its misuse may result in misleading or deceptive experiences. For example, a visceralization which subtly re-scales data to exaggerate a certain effect may be taken at face value to be true. There has been extensive discussion of data visualizations potentially being deceptive, and special care needs to likewise be taken since data visceralization is intended to give an intuitive understanding of the data that is not misleading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Visceral vs. Emotional Experiences</head><p>As reported by our participants, visceral sensations were tied to some emotional reaction, such as fear when looking down from a great height, or the feeling of awe when looking up at a large structure. For the purposes of data visceralization however, it is important to differentiate between emotions stemming from visceral sensations and those from the storytelling context. That is, visceral sensations are part of the preattentive sensory process when experiencing the presented phenomena, in contrast to strong emotional reactions that are evoked through the narrative such as sadness or anger (e.g., <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b36">37]</ref>). By treating these separately, we focus primarily on sensory fidelity and instead let the storytelling context convey any other desired emotion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Application Domains</head><p>Since effective data visceralization may restrict transformation of data, there are certain domains and experiences that are particularly well suited for visceralization. We have already identified and demonstrated two prototypes using sports visualization, and this space could be explored more extensively. Scale comparisons of other human endeavors like architecture, engineering, and design are all enhanced by having a deeper understanding of data. In particular, understanding the relative sizes of objects while browsing online services has been often suggested as a compelling use of immersive technology. Finally, there has been captivating video examples (e.g., <ref type="bibr" target="#b11">[12]</ref>) of the impact of weather events like flooding, where a one-to-one demonstration of the height of the water, or the speed of windows being blown open, could help viewers more deeply understand what happens during the event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Limitations of Data Visceralization in VR</head><p>As our presented design probes were conducted in VR, any limitations of VR directly affect the effectiveness of data visceralization. One issue in particular is that egocentric distance estimations are compressed in VR <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b46">47]</ref>, possibly resulting in perceptually misleading experiences. To combat this, the use of a virtual self-avatar has been shown to improve near distance estimation <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b39">40]</ref>. It has also been shown that the size of one's virtual body influences perceived world size <ref type="bibr" target="#b54">[55]</ref>, and the size of one's virtual hand influences perceived size of nearby objects <ref type="bibr" target="#b34">[35]</ref> which can in turn help improve size estimation <ref type="bibr" target="#b28">[29]</ref>. As visceralizations are reliant on the accurate perception of virtual objects, these techniques and others similar in the VR literature can be used. Another limitation is the trade-off between visual fidelity, dataset size (if applicable), and performance. This was notably of concern in E5 , as rendering thousands of objects with complex meshes resulted in poor performance. While we refer to general VR development guidelines to overcome these challenges (e.g., <ref type="bibr" target="#b17">[18]</ref>), we note that graphical quality may ultimately not be important for data visceralization (Sec. 5.2.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Future Work</head><p>Evaluation. While responses from our participants supported the notion that data visceralizations were engaging and impactful, their feedback was inherently subjective. We discussed several experimental measures and factors which may be considered in future studies. These include: users' capability to perceive and comprehend the qualitative 'ground-truth', time until this comprehension is reached, the transferability and generalization of learnings into the real-world, and the effects of numerous factors (e.g., transformation from data to visceralization, number and types of annotations, level of realism) on understanding. By more formally considering and measuring these in future user studies can we more thoroughly evaluate the effectiveness and appropriate use of data visceralization-particularly in comparison to similar techniques such as those in Sec. 2. Data visceralization beyond VR. Advancements in immersive technologies opens many new opportunities for data visceralization. For example, researchers have explored how non-visual senses can be stimulated to convey data, such as olfaction (e.g., <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b56">57]</ref>), gustation (e.g., <ref type="bibr" target="#b30">[31]</ref>), and haptic simulation (e.g., <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9]</ref>). AR also offers unique opportunities and challenges, as the real-world acts as an anchor for all measurements and scales. While this may improve relatability of the data as the visceralization is in the context of the user's environment, it may restrict the scope of phenomena which can be representedparticularly for large scale objects such as skyscrapers.</p><p>Combining narrative storytelling and data visceralization. As was the original intention and reaffirmed by participants, data visceralizations can fill in the 'ground truth' understanding oftentimes missing in data visualization. As such, it is important to determine how to combine the two without sacrificing the accessibility and convenience of webbased data stories. As described in Sec. 2, recent work has begun exploring the use of immersive experiences for data storytelling <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b45">46]</ref>, with some existing stories already doing so using mobile-based AR (e.g., <ref type="bibr" target="#b7">[8]</ref>). Data visceralization can both contribute to and utilize these immersive data-driven storytelling techniques in the future. Towards a general data visceralization pipeline. Development of our VR prototypes required skills in design, 3D modeling, and programming in specialized environments such as Unity3D. That said, many pre-made assets were used to hasten development, resulting in development times of around a week for each prototype (excluding reflection/evaluation). During this process, we fell into similar development patterns which we portray in <ref type="figure">Fig. 2</ref>. Sitting in parallel to the visualization pipeline <ref type="bibr" target="#b10">[11]</ref>, we pass data into the data visceralization pipeline and directly map it onto attributes of objects within the virtual environment. This simulation may use animation to encode information such as speed in E1 . After adding appropriate background imagery to contextualize the simulated phenomena, we then render these at the desired level of realism. Finally, we annotate the experience with the original quantitative data to provide perspective and context to the experience. The output is then experienced on a VR device-ideally when complementing an existing data visualization or story. While nothing is currently automated in this pipeline, the structure may help teams organize where different contributions can occur.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We introduce and define the concept of data visceralizations as a complement to data visualization and storytelling, in order to facilitate an intuitive understanding of the underlying 'ground-truth' of data. We explore the concept through the iterative design and creation of six design probes, which we critically reflect on as authors and gather external feedback and opinions from participants. Through this, we identify situations where data visceralization is effective, how transforming the data or representing abstract data may be problematic for visceral experiences, and considerations of many factors for data visceralization as a whole. We also identify future opportunities, such as formally evaluating data visceralization in a user study, and how future technologies can extend the concept. We hope that this work will spawn both future experiences for understanding data as well as deeper investigation into how to best create and more formally evaluate these experiences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Illustrative images of E1 . (a) 'Photo finish' of Olympic sprinters (adapted from [45]). (b) Overview of sprinters running down the track at real scale. (c) Same perspective but using human-sized cubes instead of humanoid models. (d) Experiencing the race from the perspective of the slowest sprinter. (e) Sprinters superimposed on top of one another. (f) Floating labels above each sprinter providing quantitative measures and values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Illustrative images of E2 . (a) Distances of long jumps compared to a 3-point line (adapted from [44]). (b) Overview of long-jumpers at the final 'freeze-frame' when landing. (c) Experiencing the jump as it happens from a close angle. (d) Long-jumpers represented as superimposed flags on the ground with labels on the furthest and closest jumps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Illustrative images of E3 . (a) Looking at the Eiffel Tower, CN Tower, and Burj Khalifa at real-life scale from below. (b) Looking at the Space Needle from the top of the Statue of Liberty. (c) Crowds randomly walk around on the ground floor. (d) Shadows cast from one building to another from a light source directed parallel to the ground. (e) Miniaturized 3D version of comparison diagram with y-axis scale. (f) Same setup but from a distant view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Illustrative images of E4 . (a) Reference scene that our prototype is based on (adapted from<ref type="bibr" target="#b42">[43]</ref>). (b) Prototype version in VR at a 1:40,000,000 scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>Illustrative images of E5 . (a) Birds-eye view of the protest (adapted from [58]). (b) Perspective from inside the crowd. (c) Perspective from above while flying in a helicopter-like fashion. (d) Crowd represented as human-sized cubes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Illustrative images of E6 . (a) Reference scene that our prototype is based off (© Oto Godfrey, Demonocracy.info, used with permission). (b) Overview of the scene with the Statue of Liberty in the center. (c) Looking down from the top of a stack. (d) Looking up from ground level and at labels of stack and Statue height.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>E1 -Speed: Olympic Men's 100 m</head><label></label><figDesc></figDesc><table><row><cell>The second</cell></row><row><cell>half investigates scenarios that required some form of transformation</cell></row><row><cell>into VR, such as scaling down extreme values and representing abstract</cell></row><row><cell>measures. While we describe, show pictures, and include video of these</cell></row><row><cell>examples, one needs to experience them in a VR setup to assess the</cell></row><row><cell>data visceralization experience. Therefore, we made these available in the supplementary material and on a public GitHub repository 1 .</cell></row><row><cell>Usain Bolt holds the world record in the Olympics Men's 100 m with</cell></row><row><cell>his performance at the 2012 London Olympic Games at a time of</cell></row><row><cell>9.63 seconds. One Race, Every Medalist Ever by the New York Times</cell></row><row><cell>[45] puts Bolt's result into perspective by comparing it with those of all</cell></row><row><cell>other Olympic medalists since 1896. While this is commonly shown</cell></row><row><cell>on a tabular layout</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>or] doing a sprint." [P9], another that they can still gain insights by "[Going] to the top or close to the base, or see the building from the bottom of it." [P6]. More interestingly, P12 suggested that "If it gives me enough options to explore, like climb the wall, climb the stairs, feel different textures... the scenario is not attached to the height scenario [any more]</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/benjaminchlee/Data-Visceralization-Prototypes</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding data videos: Looking at narrative visualization through the cinematography lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
		<idno type="DOI">10.1145/2702123.2702431</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, CHI &apos;15</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems, CHI &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1459" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Narrative Design Patterns for Data-Driven Storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stefaner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ciuccarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Koppen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-03" />
			<publisher>Taylor Francis</publisher>
			<biblScope unit="page" from="107" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m">Virtual Environments and Advanced Interface Design</title>
		<editor>W. Barfield and T. A. Furness, III</editor>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press, Inc</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Virtual environments and advanced interface design. chap. Presence and Performance Within Virtual Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Barfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeltzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sheridan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Slater</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Oxford University Press, Inc</publisher>
			<biblScope unit="page" from="473" to="513" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Combining virtual reality and narrative visualisation to persuade</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bastiras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.1109/BDVA.2017.8114623</idno>
	</analytic>
	<monogr>
		<title level="m">2017 International Symposium on Big Data Visual Analytics (BDVA)</title>
		<imprint>
			<date type="published" when="2017-11" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Grope-1: a computer display to the sense of feel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Batter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F P</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process</title>
		<imprint>
			<biblScope unit="page">71</biblScope>
			<date type="published" when="1972-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Semiology of Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bertin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>University of Wisconsin Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Augmented reality: Four of the best olympians, as you&apos;ve never seen them -the new york times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Branch</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/interactive/2018/02/05/sports/olympics/ar-augmented-reality-olympic-athletes-ul.html" />
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Project gropehaptic displays for scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">P</forename><surname>Brooks</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ouh-Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Batter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Jerome</forename><surname>Kilpatrick</surname></persName>
		</author>
		<idno type="DOI">10.1145/97880.97899</idno>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="177" to="185" />
			<date type="published" when="1990-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Storytelling for virtual reality: Methods and principles for crafting immersive narratives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bucher</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315210308</idno>
		<imprint>
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<title level="m">Readings in Information Visualization: Using Vision to Think</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Storm surge like you&apos;ve never experienced it before</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Channel</surname></persName>
		</author>
		<idno>Ac- cessed: 2020-07-23</idno>
		<ptr target="https://www.youtube.com/watch?v=q01vSb_B1o0" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using concrete scales: A practical framework for effective visual depiction of complex measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vuillemot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gali</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.210</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2426" to="2435" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Immersive journalism: Immersive virtual reality for the first-person experience of news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De La Peña</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Llobera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Giannopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pomés</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Spanlang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Sanchez-Vives</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Slater</surname></persName>
		</author>
		<idno>doi: 10. 1162/PRES a 00005</idno>
	</analytic>
	<monogr>
		<title level="j">Presence: Teleoperators and Virtual Environments</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="291" to="301" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">List of physical visualizations and related artifacts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<ptr target="http://dataphys.org/list/" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Investigating the effects of anthropomorphic fidelity of self-avatars on near field depth perception in immersive virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Hartman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Pagano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Babu</surname></persName>
		</author>
		<idno type="DOI">10.1109/VR.2018.8446539</idno>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)</title>
		<imprint>
			<date type="published" when="2018-03" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An operator interaction framework for visualization systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><surname>Huai-Hsin Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename></persName>
		</author>
		<idno>doi: 10.1109/ INFVIS.1998.729560</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Symposium on Information Visualization (Cat. No.98TB100258)</title>
		<meeting>IEEE Symposium on Information Visualization (Cat. No.98TB100258)</meeting>
		<imprint>
			<date type="published" when="1998-10" />
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Guidelines for vr performance optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Facebook</forename><surname>Technologies</surname></persName>
		</author>
		<ptr target="https://developer.oculus.com/documentation/native/pc/dg-performance-guidelines/" />
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The Ecological Approach to Visual Perception. Resources for ecological psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Us debt visualized: Stacked in $100 bills at 20+ trillion usd for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Godfrey</surname></persName>
		</author>
		<ptr target="http://demonocracy.info/infographics/usa/us_debt/us_debt.html" />
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Signal detection theory and psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Swets</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Virtual reality: Applications and implications for tourism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Guttentag</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tourman.2009.07.003</idno>
	</analytic>
	<monogr>
		<title level="j">Tourism Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="637" to="651" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The fallen of world war ii</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Halloran</surname></persName>
		</author>
		<ptr target="https://www.youtube.com/watch?v=DwKPFT-RioU" />
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving comprehension of measurements using concrete re-expression strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Speers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173574.3173608</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, CHI &apos;18</title>
		<meeting>the 2018 CHI Conference on Human Factors in Computing Systems, CHI &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Immersive Visual Data Stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordeil</surname></persName>
		</author>
		<idno>doi: 10. 1007/978-3-030-01388-2 6</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="165" to="184" />
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Evaluating the efficiency of physical visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<idno type="DOI">10.1145/2470654.2481359</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;13</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2593" to="2602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Opportunities and challenges for data physicalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kildal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornbaek</surname></persName>
		</author>
		<idno type="DOI">10.1145/2702123.2702180</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, CHI &apos;15</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems, CHI &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3227" to="3236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The VR Book: Human-Centered Design for Virtual Reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jerald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Association for Computing Machinery and Morgan &amp; Claypool</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Over my hand: Using a personalized hand in vr to improve object size estimation, body ownership, and presence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Wisniewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sandor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Hughes</surname></persName>
		</author>
		<idno type="DOI">10.1145/3267782.3267920</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Spatial User Interaction, SUI &apos;18</title>
		<meeting>the Symposium on Spatial User Interaction, SUI &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="60" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Is the nasdaq in another bubble? a virtual reality tour of the nasdaq -wsj</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Becker</surname></persName>
		</author>
		<ptr target="http://graphics.wsj.com/3d-nasdaq" />
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Tastybeats: Designing palatable representations of physical activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hjorth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">F</forename><surname>Mueller</surname></persName>
		</author>
		<idno type="DOI">10.1145/2702123.2702197</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems, CHI &apos;15</title>
		<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems, CHI &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2933" to="2942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">3D User Interfaces: Theory and Practice. Addison-Wesley usability and HCI series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Laviola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kruijff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Poupyrev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Watches to augmented reality: Devices and gadgets for data-driven storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">G</forename><surname>Veira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data-Driven Storytelling</title>
		<imprint>
			<publisher>AK Peters/CRC Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="153" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Virtual reality and its military utility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lele</surname></persName>
		</author>
		<idno>doi: 10. 1007/s12652-011-0052-4</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Ambient Intelligence and Humanized Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="26" />
			<date type="published" when="2013-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Welcome to wonderland: The influence of the size and shape of a virtual hand on the perceived size and shape of virtual objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Linkenauger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leyrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Bülthoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Mohler</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0068594</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">2013</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visual perception of egocentric distance in real and virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Loomis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knapp</surname></persName>
		</author>
		<idno type="DOI">10.1201/9781410608888.pt1</idno>
	</analytic>
	<monogr>
		<title level="m">Virtual and Adaptive Environments</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2003-06" />
			<biblScope unit="page" from="21" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Mass shootings since sandy hook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sukumar</surname></persName>
		</author>
		<ptr target="https://www.vox.com/a/mass-shootings-america-sandy-hook-gun-violence" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Itoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Stuerzlinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Immersive Analytics. Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Making vr work: Building a real-world immersive modeling application in the virtual world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yoganandan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Coffey</surname></persName>
		</author>
		<idno type="DOI">10.1145/2659766.2659780</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd ACM Symposium on Spatial User Interaction, SUI &apos;14</title>
		<meeting>the 2Nd ACM Symposium on Spatial User Interaction, SUI &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="80" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The effect of viewing a self-avatar on distance judgments in an hmd-based virtual environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Mohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Creem-Regehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Bülthoff</surname></persName>
		</author>
		<idno type="DOI">10.1162/pres.19.3.230</idno>
	</analytic>
	<monogr>
		<title level="j">Presence: Teleoperators and Virtual Environments</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="230" to="242" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Analysis of the educational potential of a science museum learning environment: Visitors&apos; experience with and understanding of an immersion exhibit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Mortensen</surname></persName>
		</author>
		<idno type="DOI">10.1080/09500691003754589</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Science Education</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="517" to="545" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Information olfactation: Harnessing scent to convey data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Patnaik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Batch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2865237</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="726" to="736" />
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Our seven fellow planets could fit end to end within our moon&apos;s orbit around us</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perplexingpotato</surname></persName>
		</author>
		<idno>Accessed: 2020-07-23</idno>
		<ptr target="https://imgur.com/Ae9hbU1" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Bob beamon&apos;s long olympic shadowinteractive graphic -nytimes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Quealy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roberts</surname></persName>
		</author>
		<ptr target="http://archive.nytimes.com/www.nytimes.com/interactive/2012/08/04/sports/olympics/bob-beamons-long-olympic-shadow.html" />
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">One race, every medalist everinteractive graphic -nytimes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Quealy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cox</surname></persName>
		</author>
		<ptr target="http://archive.nytimes.com/www.nytimes.com/interactive/2012/08/05/sports/olympics/the-100-meter-dash-one-race-every-medalist-ever.html" />
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Xrcreator: Interactive construction of immersive data-driven stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Höllerer</surname></persName>
		</author>
		<idno type="DOI">10.1145/3281505.3283400</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology, VRST &apos;18</title>
		<meeting>the 24th ACM Symposium on Virtual Reality Software and Technology, VRST &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="1" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The perception of egocentric distances in virtual environments -a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Renner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Velichkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Helmert</surname></persName>
		</author>
		<idno type="DOI">10.1145/2543581.2543590</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Data-driven Storytelling. AK Peters Visualization Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Narrative visualization: Telling stories with data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2010.179</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1139" to="1148" />
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Measuring presence: A response to the witmer and singer presence questionnaire</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Slater</surname></persName>
		</author>
		<idno type="DOI">10.1162/105474699566477</idno>
	</analytic>
	<monogr>
		<title level="j">Presence: Teleoper. Virtual Environ</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="560" to="565" />
			<date type="published" when="1999-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A framework for immersive virtual environments five: Speculations on the role of presence in virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Slater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wilbur</surname></persName>
		</author>
		<idno>doi: 10. 1162/pres.1997.6.6.603</idno>
	</analytic>
	<monogr>
		<title level="j">Presence: Teleoper. Virtual Environ</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="603" to="616" />
			<date type="published" when="1997-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Data-driven storytelling techniques: Analysis of a curated collection of visual stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Stolper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data-Driven Storytelling</title>
		<imprint>
			<publisher>AK Peters/CRC Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="85" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Investigating the use of a dynamic physical bar chart for data exploration and presentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Woodruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornbaek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alexander</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2598498</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="451" to="460" />
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Virtual reality in the psychological treatment for mental health problems: An systematic review of recent evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Valmaggia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Latif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kempton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rus-Calafell</surname></persName>
		</author>
		<idno>doi: 10. 1016/j.psychres.2016.01.015</idno>
	</analytic>
	<monogr>
		<title level="j">Psychiatry Research</title>
		<imprint>
			<biblScope unit="page">236</biblScope>
			<date type="published" when="2016-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Being barbie: The size of one&apos;s own body determines the perceived size of the world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Der Hoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guterstam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Ehrsson</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0020195</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">An emotional response to the value of visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klatzky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hurtienne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hornecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barrass</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2019.2923483</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="8" to="17" />
			<date type="published" when="2019-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Could olfactory displays improve data visualization?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Washburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCSE.2004.66</idno>
	</analytic>
	<monogr>
		<title level="j">Computing in Science and Engg</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="80" to="83" />
			<date type="published" when="2004-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">A bird&apos;s-eye view of how protesters have flooded hong kong streets -the new york times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singhvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kao</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/interactive/2019/06/20/world/asia/hong-kong-protest-size.html" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2020" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">An immersive virtual environment for dt-mri volume visualization applications: a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Demiralp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dasilva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Greenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Basser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pierpaoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Chiocca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Deisboeck</surname></persName>
		</author>
		<idno type="DOI">10.1109/VISUAL.2001.964545</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings Visualization, 2001. VIS &apos;01</title>
		<meeting>Visualization, 2001. VIS &apos;01</meeting>
		<imprint>
			<date type="published" when="2001-10" />
			<biblScope unit="page" from="437" to="584" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
