<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">What Makes a Data-GIF Understandable?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhuan</forename><surname>Shu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoyu</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junxiu</forename><surname>Tang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Bach</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingcai</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huamin</forename><surname>Qu</surname></persName>
						</author>
						<title level="a" type="main">What Makes a Data-GIF Understandable?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data-GIFs</term>
					<term>Data-driven Storytelling</term>
					<term>Evaluation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>GIFs are enjoying increasing popularity on social media as a format for data-driven storytelling with visualization; simple visual messages are embedded in short animations that usually last less than 15 seconds and are played in automatic repetition. In this paper, we ask the question, &quot;What makes a data-GIF understandable?&quot; While other storytelling formats such as data videos, infographics, or data comics are relatively well studied, we have little knowledge about the design factors and principles for &quot;data-GIFs&quot;. To close this gap, we provide results from semi-structured interviews and an online study with a total of 118 participants investigating the impact of design decisions on the understandability of data-GIFs. The study and our consequent analysis are informed by a systematic review and structured design space of 108 data-GIFs that we found online. Our results show the impact of design dimensions from our design space such as animation encoding, context preservation, or repetition on viewers understanding of the GIF&apos;s core message. The paper concludes with a list of suggestions for creating more effective Data-GIFs.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The popularity of data-driven storytelling has grown rapidly these years. Media outlets such as The New York Times [4], The Washington Post <ref type="bibr" target="#b4">[6]</ref>, FlowingData <ref type="bibr" target="#b2">[3]</ref>, and The Pudding <ref type="bibr" target="#b3">[5]</ref>, are actively crafting data stories with visualizations. A large palette of data stories result in diverse genres in narrative visualization, such as infographics, comics, slideshows, and videos <ref type="bibr" target="#b55">[57]</ref>. Each genre possesses unique characteristics and affords opportunities for various communication scenarios, e.g., integrating text and graphics, leveraging linear and non-linear sequences, as well as combining both visual and auditory stimuli.</p><p>In parallel with the advances of these established genres, we see a recent surge of attention and interests in "data-GIFs" <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">32]</ref>, an emerging format that tells data stories with visualization. Typically, GIFs are short animations, usually less than 15 seconds, played in automatic repetition, and focusing on a single core message. These small animated visualizations are saved in the form of Graphics Interchange Format (GIF), making them easily accessible online. Data-GIFs are endowed with unique properties for communicating data insights. For example, compared to data videos <ref type="bibr" target="#b5">[7]</ref>-a narrative visualization genre with longer playing time, more information, and potentially more complex narratives structures-data-GIFs are simpler with a shorter specific message and are more concise in terms of size and duration. They can be quickly loaded and automatically played and repeated, thereby supporting prompt reading and understanding. Moreover, GIFs capture viewers' attention with motion effects <ref type="bibr" target="#b10">[12]</ref>. Given the growing use and desirable properties, we argue data-GIFs are a distinct and promising genre for data-driven storytelling, worth of research and discussion.</p><p>However, the visualization research community has not yet given much consideration to data-GIFs. First, we lack an understanding of the current practices surrounding data-GIF designs. What factors should be considered when creating data-GIFs? Prior studies <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b37">39]</ref> have examined the content of animated GIFs, but their findings cannot fully contextualize data visualizations with different visual manifestations and communication goals. Given its roles for data-driven storytelling, the GIF design should involve specific considerations to craft data stories, compared to the known design principles for animated visualizations <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b62">64]</ref>. More importantly, it remains unclear what makes a data-GIF understandable to its intended audience. We have little knowledge about the performance and effectiveness of data-GIFs for communicating data stories. For example, what does a data-GIF show over time? and are animations easy to understand? Also, animation is commonly questioned to be inadequate to preserve the context and track the changes <ref type="bibr" target="#b53">[55]</ref>. How do data-GIFs present the frame sequence and facilitate the comprehension? In addition, as Munzner <ref type="bibr" target="#b49">[51]</ref> claimed "giving people the ability to pause and replay the animation is much better than only seeing it a single time straight through", the performance of data-GIFs raises questions, since they do not allow the manipulation of the playing progress but automatically repeat the animation. In this paper, we set out to address the question: "What makes a data-GIF understandable?" Our work is the first to systematically explore data-GIFs as a distinct and promising medium for data-driven storytelling. To this end, we build a collection of 108 real-world data-GIFs from a wide range of online websites such as social media, news portals, and personal blogs. We then summarize the design practices based on the curated data-GIFs, whereby extracting the design factors from intra-frame and inter-frame perspectives, i.e., visualization types and navigation progress, animation encoding, context preservation, and repetition, respectively (Sec. 3). The analysis of the design space helps us figure out specific characteristics that distinguish data-GIFs from other storytelling mediums. We conduct a qualitative study through interviews (Sec. 4), complemented by an extensive online study (Sec. 5), involving a representative subset of 20 of our collected real-world GIFs in order to reduce the study's complexity. The studies collect a variety of data including observation, think-aloud protocols, questionnaires, and subjective feedback. The results indicate that many design factors have an impact on the understandability of data-GIFs. In the end, we summarize a set of design suggestions for creating more effective data-GIFs, and discussed the limitations and future research directions. All materials including the entire GIF corpus, labeled design space, and supplementary materials for interviews and online studies can be found online: https://data-gifs.github.io. The major contributions are:</p><p>The structured design space based on a corpus of 108 data-GIFs, which summarizes current practices and extracts key design factors. Exploratory user studies that gain insights into the effect of different data-GIF designs from the standpoints of audiences. A set of design suggestions for creating more effective data-GIFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We situate our work related to research on data-driven storytelling, animated GIFs and visualization, and studies to measure understandability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Genres in Data-driven Storytelling</head><p>Narrative visualization has been widely used to communicate data insights to the public. Segel and Heer <ref type="bibr" target="#b55">[57]</ref> first identified seven genres in 2010: magazine style, annotated charts, posters, flow charts, comics, slideshows, and videos. Since then, researches appeared to inform the design of each genre (e.g., <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b9">11,</ref><ref type="bibr" target="#b48">50,</ref><ref type="bibr" target="#b54">56,</ref><ref type="bibr" target="#b59">61]</ref>), as well as the generation methods (e.g., <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b42">44,</ref><ref type="bibr" target="#b58">60,</ref><ref type="bibr" target="#b63">65]</ref>). In this work, we position data-GIFs as an emerging genre for data-driven storytelling with increasing popularity, which possesses distinct visual features and deserves discussion. For example, data-GIFs usually convey a single short message through animated visualization in automatic repetition and without sound. Regarding this, data videos consist of complex narrative structures (i.e., establisher, initial, peak, and release) with accompanying audio narration <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b20">22,</ref><ref type="bibr" target="#b57">59]</ref>, thus presenting more information and requiring a higher cost from both creators and audiences. After further investigation on the design practices, we found obvious differences of design features and strategies between data videos and data-GIFs (as shown in Sec. 3), such as animation mapping, context preservation, and repetition. On the other hand, data-GIFs with a sequence of frames can help communicate the dynamic process, compared to static single images <ref type="bibr" target="#b33">[35]</ref>. Moreover, the prevalence of smartphones promotes a design trend that displays data-GIFs on the phone and small multiples on the desktop <ref type="bibr" target="#b16">[18,</ref><ref type="bibr" target="#b17">19]</ref>. Given the differences and growing popularity, we looked into data-GIFs, providing a detailed analysis on the design space and examining their potential for data-driven storytelling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Animated GIFs and Animated Visualization</head><p>Created in 1987, animated GIFs are becoming ubiquitous online in recent years. Specifically, Bakhshi et al. <ref type="bibr" target="#b10">[12]</ref> found that animated GIFs were more engaging than other kinds of media such as pictures and videos on the social media platform, Tumblr. They also identified several significant factors that contribute to these engaging GIFs, including the animation, storytelling capabilities, and emotion expression. Furthermore, some studies <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b39">41]</ref> have trained models to predict perceived emotions of viewers for animated GIFs. Despite the engagement, Jiang et al. <ref type="bibr" target="#b37">[39]</ref> found that viewers may have diverse interpretation of animated GIFs in communication.</p><p>In this work, we examined a subset of animated GIFs, i.e., data-GIFs, which are used to convey data-driven stories and are predominantly visualization-based. Groege first elaborated the idea of data-GIFs with a small collection of examples <ref type="bibr" target="#b30">[32]</ref>. These examples present different properties from generic animated GIFs which are mainly derived from video clips or image stacking, since data-GIFs are designed to communicate data insights. However, few work follows up to study data-GIFs in depth, leaving an unclear design space. Our work thus takes the step towards this direction with a wider range of data-GIFs, and investigates the underlying stories and designs.</p><p>In practice, data-GIFs commonly incorporate animation in visualization. Despite the controversy of using animation for analysis <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b53">55]</ref>, researchers generally agree on the advantage of animation for communication <ref type="bibr" target="#b47">[49,</ref><ref type="bibr" target="#b56">58]</ref>. For example, animated representations are useful to convey transitions in statistical data graphics <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b43">45]</ref> and communicate uncertainty to the public <ref type="bibr" target="#b40">[42]</ref>. Amini et al. <ref type="bibr" target="#b6">[8]</ref> studied data clips as building blocks to compose longer data videos, and showed that incorporating animation in data clips can improve understandability. Instead, data-GIFs present another practice of using animation for storytelling, which concisely narrate a short but full story per se and automatically repeat the animation. It is different from existing animated visualization and has not yet been evaluated. Therefore, in this work, we explore the design practice of data-GIFs and examine their communication effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Empirical Research to Measure Understandability</head><p>Researches in Information Visualization put great efforts on measuring data visualization comprehension. Specifically, researchers develop a multitude of test questions for static data visualizations and tasks to assess visualization literacy in a multiphase procedure <ref type="bibr" target="#b45">[47]</ref>. Börner et al. <ref type="bibr" target="#b15">[17]</ref> collected qualitative interview feedback from the general public to analyze their comprehension with static visualization. However, these works relate to users understandability of static visualization for analysis tasks <ref type="bibr" target="#b19">[21]</ref>. Our work studies how people interpret an animated data-GIF as a communicative visualization, e.g., which design helps or hinders the understanding of the intended content.</p><p>Studies on communicative visualization assess the effects of different designs on viewers comprehension <ref type="bibr" target="#b44">[46]</ref>. For instance, Bateman et al. <ref type="bibr" target="#b11">[13]</ref> measured interpretation accuracy of embellished and nonembellished charts with a set of tests. Amini et al. <ref type="bibr" target="#b6">[8]</ref> asked questions about the content to compare the comprehensibility of animated charts and pictographs with static versions in data videos. Finally, Wang et al. <ref type="bibr" target="#b65">[67]</ref> designed comprehension questions to assess the understandability of data comics with infographics and text; quantitative and qualitative results showed data comics were generally easier to understand. Similarly, we collect qualitative descriptions to analyze the effects of various GIF designs on viewers' understandability, complemented by accuracy of comprehension questions from the online study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DATA-GIF DESIGN IN PRACTICE</head><p>To gain insights into the roles of data-GIFs in data-driven storytelling, we conduct an empirical study to collect real-world data-GIFs and analyze their design practices. Our goal is to explore the design space of data-GIFs and capture the specialities of data-GIF designs that might influence the understandability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Survey on Data-GIFs</head><p>Our survey was motivated by the small pilot corpus from Lena Groeger <ref type="bibr" target="#b30">[32]</ref>, which presented 18 data-GIF examples and classified them according to the content, e.g., showing the temporal process, distribution, different views, or little stories. By inspecting this collection, we formulated an initial understanding of data-GIF designs and considered their roles in data storytelling. Therefore, we expanded the corpus with 40 data-GIFs published by the leading media outlets on the social media platforms, news websites, and blogs, such as The New York Times, Financial Times, Flowing Data, and Google Trends. To further inform the design space, we collected another 50 data-GIFs from heterogeneous sources through Google advanced image search for GIFs with keywords including "data", "visualization", "statistics", and "graphics".</p><p>We established three selection criteria to improve the representativeness of our corpus. First, it should convey insights supported by data and contain at least one data visualization. Second, as our motivation pertains to studying data-GIFs as a distinct narrative visualization genre, we excluded GIFs for system demonstrations and animated infographics <ref type="bibr" target="#b50">[52]</ref>. These GIFs do not leverage this format for the purpose of data-driven storytelling. Third, we did not collect duplicate or templated forms of data-GIFs in the course of the survey, since the corpus aims to span a wide range of visualizations types, animation designs, and data stories in data-GIF practices.</p><p>As a result, we arrived at a corpus of 108 data-GIFs. While not necessarily fully representative, our corpus presents necessary empirical evidence to analyze the designs in current practices. The complete corpus can be found on the website along with the original sources and labeled design factors (as described in Sec. 3.3 and 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Analysis</head><p>Informed by our survey, we aimed to explore the design practices and capture designs factors that might contribute to understandability. We first computed the playback duration, which is a metadata feature (included in the file by default) of animated GIFs and proven to have a strong impact on the interpretation and engagement <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b37">39]</ref>. Overall, the average duration of the collected data-GIFs is 11.87 seconds (ranging from 1.4 seconds to 63 seconds), while 78.7% of the total data-GIFs (85/108) last less than 15 seconds (suggested as the upper limit for animated GIFs <ref type="bibr" target="#b28">[30]</ref>), as shown in <ref type="figure" target="#fig_0">Fig. 1b</ref>.</p><p>Furthermore, we conducted a qualitative analysis to study the content-based design factors of a data-GIF from two aspects:</p><p>• Intra-frame design: What visuals do data-GIFs commonly incorporate in each static frame to present content? and • Inter-frame design: How do designers articulate the connection between frames and craft animations based on the GIF format?  Subsequently, we drilled down into each aspect and captured specific design factors. The whole design space was developed through an iterative process, which started with an analysis of the 18 examples <ref type="bibr" target="#b30">[32]</ref>, improved with several rounds of discussion among the authors for the growing corpus, and finally refined with user feedback. Three of the authors went through all the collected data-GIFs and completed the coding based on the predefined scheme individually, whereby mismatches were resolved through discussions. Finally, we revised the coding according to the feedback from the user studies. We introduce our resulting five design factors (F1-F5) in the following two sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Intra-frame Design</head><p>Traditionally, GIFs are a consecutive sequence of frames played in loops.</p><p>Researches on animated GIFs commonly analyze their content with regard to each frame. For example, prior studies <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b39">41]</ref> compute the per-frame content features of animated GIFs, such as the face numbers and regions, to examine their impacts on communication and engagement. In the context of data-driven storytelling, we consider the content features for each frame from the perspectives of visualization types and narrative progress.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F1: Visualization Types</head><p>Visualizations play a primary role in data-GIFs for conveying insights with data. We first gain an overview of the visualization usage in a GIF and calculate the number of different visualizations for each data-GIF. We find that most data-GIFs (86.1%; 93) consist of exactly one type of charts, and the rest contain two types. This finding is much different from those obtained for data videos, which usually include multiple scenes with different visualizations <ref type="bibr" target="#b5">[7]</ref>. It suggests that data-GIFs tend to have lower information density than data videos because of the limitation of playback duration and communication modes.</p><p>Furthermore, we classify the visualization types based on Borkin et al.'s taxonomy <ref type="bibr" target="#b14">[16]</ref>. Visualization types are relatively limited in data-GIFs, where basic charts predominate the corpus. As shown in <ref type="figure" target="#fig_0">Fig.  1</ref>, maps (38.0%; 41) were the most commonly used by a large margin, a difference in frequency compared to static visualizations. Line <ref type="bibr">(18.5%; 20)</ref> and bar (15.7%; 17) charts follow. However, pictograms which are common in data videos <ref type="bibr" target="#b5">[7]</ref> have rarely appeared in data-GIFs (4/108). In summary, data-GIFs embrace simple and intuitive visualization designs. This might be motivated by the needs to reduce cognitive load, since GIFs could include overwhelming information but do not allow users to control the pace and pause.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F2: Narrative Progress</head><p>In addition to visualizations, some data-GIFs incorporate designs of narrative progress within each frame, which describes how viewers identify the current playback progress (similar to navigation progress in visual narrative flows <ref type="bibr" target="#b47">[49]</ref>). For example, as shown in <ref type="figure" target="#fig_2">Fig. 2a</ref>, the GIF provides a supplemental line chart which not only shows the increase of the total cases but also indicates the progress over time. Another example ( <ref type="figure" target="#fig_4">Fig. 4c</ref>) directly uses a timeline to showcase the progress. However, only a few data-GIFs (13/108) have integrated such obvious navigation progress designs, thus requiring viewers to perceive the playback progress themselves. This could be difficult especially under the scenario of automatic repetition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Inter-frame Design</head><p>This perspective captures the animated features of data-GIFs for articulating the connection between frames. Designers leverage the natural properties of the GIF format, such as the temporal context and automatic loops, to improve the elaboration of data stories. Considering the designs to describe the content relations within a repetition or between repetitions, we have identified the following three factors.    The colored line for the temperature change is growing spirally, and overlays on the previous <ref type="bibr" target="#b31">[33]</ref>. We provide the original GIFs in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F3: Animation Encoding</head><p>Frames in the data-GIF are arranged in a specific sequence to convey stories, leading to the question, "what does the data-GIF show when the GIF is playing?" We examine this by considering the information encoded by the GIF playing progress. We find that the animation can be divided into two categories, i.e., for temporal (62.0%; 67) and non-temporal meaning <ref type="bibr">(38.0%; 41)</ref>. This might be due to the wide utilization of animation for tracking changes over time <ref type="bibr" target="#b23">[25,</ref><ref type="bibr" target="#b33">35]</ref>. Therefore, most data-GIFs in our corpus are found to convey a temporal process. Referring to content relation in other narrative visualization genres <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b9">11]</ref>, we further extract three different types of animations in non-temporal data-GIFs, namely, faceting, narrative, and setup.</p><p>• Temporal (62.0%; 67) -The majority of data-GIFs communicate temporal changes of a data set. One possible explanation might be that people naturally link the temporal context with the GIF playing progress, thereby resulting in a large number of data-GIFs in this category. Specifically, some GIFs ( <ref type="figure" target="#fig_2">Fig. 2a</ref>) describe the development of data in a continuous, chronological sequence, and others ( <ref type="figure" target="#fig_3">Fig. 3a</ref>) may present data in multiple specific moments or time periods. • Faceting (26.0%; 28) -Another portion of data-GIFs are designed to show the facets of a data set in a series of frames respectively (refer to the faceting pattern in data comics <ref type="bibr" target="#b9">[11]</ref>). For example, different data items are encoded in a set of frames regarding the same attribute for comparison. <ref type="figure" target="#fig_2">Fig. 2b</ref> shows the curves of different countries for the coronavirus successively. In addition, other GIFs can present different attributes of a data item that deliver complementary views. • Narrative (8.3%; 9) -This type builds a narration during the animation <ref type="bibr" target="#b9">[11]</ref>, where it introduces problems, provides data contexts, and complements explanatory texts. Most are revealed in a step-bystep presentation, guiding viewers' attention along with the narrative through highlighting and annotating as shown in <ref type="figure" target="#fig_2">Fig. 2c</ref>. • Setup (3.7%; 4) -Data-GIFs in this portion animate the creation of a visualization. The term learns from the setup animation in data videos <ref type="bibr" target="#b6">[8]</ref>. They only build the visualization scene but do not encode data by the animation. For example, <ref type="figure" target="#fig_2">Fig. 2d</ref> shows that the bars are growing and finally presents the number of total cases in multiple countries. The process and speed do not encode information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F4: Context Preservation</head><p>While animation is commonly criticized for not allowing viewers to track the process, we find there exist designs in data-GIFs that help reveal the connection among frames and keep the reading progress contextualized. In this aspect, we summarize the techniques used in our corpus of data-GIFs to answer the question, "how can viewers track the previous data within a loop?" We describe the techniques with regard to the extents of context preservation, i.e., no context preserved (59.2%; 64), partial context preserved (16.7%; 18), and entire context preserved <ref type="bibr">(24.1%; 26)</ref>. Examining into the corpus, we further capture three different techniques in partial context preservation, namely, baseline, trails, and overview.</p><p>• No context preservation (59.2%; 64) -Most data-GIFs just play the animation straight through and do not preserve previous data, thus requiring the mental memory of viewers to follow the GIF. For example, <ref type="figure" target="#fig_2">Fig. 2b</ref> switches among different countries and only presents the current country per frame. • Baseline (3.7%; 4) -Baseline designs freeze the content in the first frame of the loop as a baseline during the animation, thereby allowing for comparison with the later frames. Typically, it can directly preserve the first frame and adjust the opacity to alleviate clutter, as shown in <ref type="figure" target="#fig_4">Fig. 4a</ref>. Others may change the representation. For example, <ref type="figure" target="#fig_3">Fig. 3a</ref> replaces the bar chart of the first year with a blue line. • Trails (9.3%; 10) -Trail designs track the data changes between consecutive frames with the GIF playing. In <ref type="figure" target="#fig_3">Fig. 3b</ref>, each point leaves a gray trail when it is moving, which indicates its previous positions and speed. Another similar design is the superimposed trail variant of Rosling's animation <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b53">55]</ref>. • Overview (3.7%; 4) -Several examples incorporate an overview in the frame sequence, which presents a summary of data. For example, in <ref type="figure" target="#fig_3">Fig. 3c</ref>, the gray points shown from the beginning foreshow the upcoming points and guide the anticipation of the viewers. • Long exposure (24.1%; 26) -This naming is borrowed from the term in photography, which retains information from previous frames. In data-GIFs, long exposure overlays data from all previous frames on the current frame with the GIF playing (i.e., entirely context preservation). As shown in <ref type="figure" target="#fig_3">Fig. 3d</ref>, the colored line is growing spirally, and the new growth overlays on the previous one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F5: Repetition</head><p>GIFs are particularly featured with automatic repetition, which can influence the reading experience of viewers <ref type="bibr" target="#b10">[12]</ref>. We consider the between-loop design and examine the problem, "what happens after the GIF is played once?" We identified three different approaches to end the loop and start a new one.   <ref type="bibr" target="#b26">[28]</ref>. We provide the original GIFs in the supplementary materials.</p><p>Specifically, some examples ( <ref type="figure" target="#fig_4">Fig. 4a</ref>) directly start a new loop once the last loop ends, while several GIFs transition from the end of the last loop to the start of the new loop, completing a seamless transition between two consecutive loops <ref type="bibr" target="#b61">[63]</ref>. • Pause (25.9%; 28) -Some data-GIFs deliberately pause a while before starting the new loop, thus forming a "freeze" of the last frame. This technique helps viewers to clearly identify each repetition. <ref type="figure" target="#fig_4">Fig.  4b</ref> shows that several frames are inserted at the end of the last loop. • Bounce (10.2%; 11) -A particular design is "bouncing", where data-GIFs play the animation once and then reverse it to the start state of the loop. It works similarly to tracing back the history. For example, <ref type="figure" target="#fig_4">Fig. 4c</ref> designs several frames with backwards animation between the end and the start of the loop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SEMI-STRUCTURED INTERVIEWS</head><p>The above analysis presents a variety of design choices in visuals and animation, leading to the question, "What makes a Data-GIF understandable to its intended audience?" Therefore, we conducted our first user study through a series of semi-structured interviews, which aimed to investigate G1) how viewers read and understood data-GIFs in the nature of automatic repetition, and G2) how each factor influences comprehension. We recorded viewers' reading experience in a thinkaloud approach and analyzed their qualitative feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Stimuli</head><p>In this study, we aimed to understand viewers' comprehension of different data-GIFs and their design decisions. To that end, we selected GIFs representing a diverse range of designs from our design space (Sec. 3). By referring to similar methodologies <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b51">53]</ref> and through several rounds of small-scale pilot studies, we decided on a subset of 20 data-GIFs (approximately 20% of the total data-GIFs in our corpus) as stimuli in our user studies (see supplementary materials. 11 of them are shown in <ref type="figure" target="#fig_2">Figures 2, 3, and 4)</ref>. The frequency of each design in our 20 sample GIFs is shown in <ref type="figure" target="#fig_5">Fig. 5</ref>. We acknowledged that in choosing representative GIFs, not all designs could be accommodated to an equal number, making the samples less a less controlled set with respect to the designs. However, the major considerations were threefold and our choice reflects a fair distribution of designs across our entire collection. First, we wanted to test real-world GIFs and the distribution of designs in practice is unbalanced and there were only several example GIFs in specific categories. Second, the construction of a data-GIF is complicated, and altering a design factor can inevitably influence others. For example, it is hard to change a faceting data-GIF to show a temporal process while preserving other factors. It is hard to untangle all the characteristics and propose fully controlled samples. Third, to our knowledge, no prior study on data-GIFs indicate which design factors are more worth studying and comparing. We consider our study as a first step towards the understanding of data-GIFs, and collect general observations and preliminary statistics. Future studies can use our design space to manually generate data-GIFs and control for individual designs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Participants and Experimental Setup</head><p>Participants. We recruited 18 participants by disseminating advertisements through emails and at online social groups. To ensure that the participants have experience in animated GIFs and have a certain level of visualization literacy, they were pre-screened through several self-reported questions in emails before finally inviting them to the interviews. As a result, we recruited 18 participants (8 males and 10 females, aged ranging from 19 to 28, mean: 23.7). They reported their frequency in reading or using animated GIFs on social media platforms (6 daily, 9 every three or four days, and 3 weekly). The familiarity with data charts was diverse (1 7), but all had a basic visualization literacy. Participants came from various backgrounds, including visualization postgraduates (4), digital media students (3), information engineering students (3), environment science students (2), software engineers (2), financial practitioners (2), UX designer (1), and government servant <ref type="bibr" target="#b0">(1)</ref>. The participants were represented as P1-P18 in the paper, respectively. They were rewarded $10 compensation for the interview, independent of their performance.</p><p>Procedure. The study included two major parts, i.e., a GIF reading and describing part, and a follow-up interview part. At first, we briefly introduced data-GIFs and provided a training session, in which we went through the procedure with one data-GIF example. Then, we asked each participant to read and describe 10 data-GIFs in total, since we intended to control the interview duration within 1 hour and keep participants active and engaged. The data-GIFs for each participant are randomly selected from the above 20 stimulus. For each GIF, we deliberately banned automatic repetition and instead asked participants whether they wanted another loop. The intention was to capture viewers' reading experience in each loop. We decided on this procedure, based on our pilot study where participants were first allowed to read GIFs freely (i.e., repeat automatically), but we found that they did not say much in the first several loops and began to talk when they had an initial idea, which was not as expected. Specifically, we first played the GIF once, then hid the GIF and asked participants to describe as much as what they had seen, e.g., visual variables and their meanings. During the description, they were encouraged to verbalize any insights they saw on the GIF, as well as their confusions and comments towards the design. After their description, we would ask whether they wanted another loop. If they said like "I want to see it one more time", we played the GIF once again and repeated the description task. Otherwise, they might reply "I cannot find anything more" or "I think I've got all the information" and move to the next GIF. After reading 10 GIFs, we asked participants about their opinions on data-GIFs, e.g., what contributes to their understanding and which roles data-GIFs play compared with other media. All the interviews were audio-recorded and lasted 50 minutes on average. The study was run on the Chrome browser at a 13-inch MacBook Pro.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Findings</head><p>We finally collected 180 responses for total 20 GIFs (9 responses for each GIF) and then decoded their description. Informed by the coding scheme for data interpretation talk <ref type="bibr" target="#b46">[48]</ref>, we coded the recordings according to a) which visual design they described, b) how they interpreted the encoding, and c) whether they correctly interpreted it. Some interpretations for visual designs were accompanied with another information, i.e., their feedback toward this design. It should be noted that we coded viewers' description with regard to each visual encoding, instead of the number of their findings or analytical results. This is because data-GIFs can present a core message with multiple additional information, and we did not require participants to find all possible insights. We considered the understandability of data-GIFs based on whether the visual encodings could be correctly understood. In addition, we corresponded their description to each repetition and counted the total times of repetition for each GIF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Goal 1: Reading Experience</head><p>To gain insights into viewers' reading experience of data-GIFs, we began with analyzing repetition times and comparing differences of viewers' descriptions between each repetition. 134 responses (74%) played the GIF more than once, with 77 responses (31%) played exactly twice. The average repetition for 20 GIFs was 2.17 times. It showed that viewers were likely to engage in the repetition (P7:"One more time. I wanted to see whether there are any other interesting things" and P3:"I would like to check my understanding"). In the follow-up interviews with those asking for another repetition, when we asked whether they would replay the content if it was a video, all of them reported no (P13: "It was troublesome especially when it was on the mobile" and P7: "Since it was automatically repeated that I cannot help but read it one more time"). P2 further explained "but if it was important information, I would replay the video. The reason may be that the information the GIF currently shows is not essential to me".</p><p>However, this behavior only existed in those easy-to-understand data-GIFs which could be interpreted by viewers within the first or second loops and formed an initial idea about the conclusion. Among those responses with more than 3 repetitions (8%), most struggled to understand the GIF and thus felt upset and bored, let alone further exploration (P8: "It was terrible. I still didn't understand even after five loops."). We also asked them about their opinions to change the GIF into a video. Their responses depended (P13: "I was not sure. Maybe I would pause to check the content, or I would even not open that." and P15: "If it was a video, I expect an accompanying audio-explanation, otherwise it was same to me."). In other words, effective data-GIFs could ignite viewers' passion to understand and explore more with additional repetitions, thereby encouraging us to explore the designs that make data-GIFs understandable.</p><p>Next, we compared the differences of viewers' description in each loop. Typically, most responses could describe the first correct interpretation at the first repetition. Viewers would shift their attention and notice details which were different from their previous focuses in subsequent repetitions. By analyzing those responses who did not fully interpret the GIF at the first loop, we found that participants might first guess the meaning of animation based on their experience, and validate their descriptions later by reading the text, but some even misunderstood ultimately. They would give a description after each loop, but added like "I will check the x-axis (or y-axis, text) next to see if it's correct." In addition, a special example was <ref type="figure" target="#fig_4">Fig. 4c</ref> where both P2 and P17 at first described it showed the relation between ages and weights even if there was no any hints indicating ages. Although they corrected their descriptions at the second repetition after reading the labels, we asked about their initial misunderstanding. Both said they had read news/stories about the relations between ages and weights before. For <ref type="figure" target="#fig_2">Fig. 2d</ref>, P4 still thought it revealed the temporal process of the increase of the cases after watching two repetitions. When telling her the true meaning, she said she thought it was similar to the bar chart racing. This also inspired us to further investigate design factors that would mislead the understanding of data-GIFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Goal 2: Insights into the Design Factors</head><p>Viewers show diverse levels of perception on data-GIFs of different animation encoding. Specifically, identifying the temporal process in data-GIFs was commonly not difficult for participants. However, it was more challenging for viewers to read a faceting data-GIF, which usually required two or three repetitions for them to extract the relationships between frames. P14 commented "The transition between frames did not help me identify the connections. I had to remember." Narrative data-GIFs were considered as step-by-step presentations. P1 enjoyed the way the GIF <ref type="figure" target="#fig_2">(Fig. 2c</ref>) "unfolds an embellished visualization in the narrative timeline." However, we found setup data-GIFs <ref type="figure" target="#fig_2">(Fig. 2d</ref>) can be ambiguous, which might be mistakenly linked to time. P4, P11, and P17 all thought it revealed a temporal process. P17 said, "Cases in Japan grew quickly at first", since she related the growing process of the bar to the increasing speed. Although P3 correctly interpreted that the GIF was to set up the visualization, she felt disappointed, "I first thought it would show the temporal process and focused on the speed. But the speed didn't show any meaning, did it?" P2, P3, and P6 all mentioned that it was "a waste of time" to play and even repeat the setup animation in GIFs. This supports Amini et al.'s suggestion <ref type="bibr" target="#b6">[8]</ref> to use setup animation with care given the delays it can introduce.</p><p>Preserving previous data helps identify subtle trends. Context preservation designs such as baseline, trails, and long exposure were basically well-received for the ease of comparison. This allowed participants to report on detailed trends with these designs. For example, in <ref type="figure" target="#fig_3">Fig. 3d</ref>, the context (temperature changes of previous years) was preserved through the growing colored line, which made it easy to identify that the temperature did not always increase with a short cooling period. P15 further complemented, "This GIF preserves previous data, so that I could easily find the evolving process." However, the preserved context could bring cognitive pressure as well, such as visual clutter and extra encoding interpretation. For example, participants felt difficulty in understanding overview design <ref type="figure" target="#fig_3">(Fig.3c)</ref> whose gray points indicated the upcoming years, thereby providing a summary of data. P1 said, "It's useless. I noticed it after I understood the GIF." P3 talked about her confusions at the first repetition, "what do the color show? the yellow, green, red, and gray points".</p><p>Viewers want the explicit start and end for a repetition. Most GIFs do not have a specific designs for repetition, which can make it difficult to differentiate the starting and ending point of a repetition. In data-GIFs, many participants did not like this seamless loop design ("I cannot find when the story starts"). In contrast, pauses at the end of the loop were appreciated. P4 said, "It gave me time to check the content of the GIF, and I could become accurately aware of a complete loop". Narrative progress also helped viewers to identify a loop. In <ref type="figure" target="#fig_2">Fig. 2a</ref>, the line chart on the top-right corner of the U.S. map shows the increase of the total cases over time. P14 said, "It works as a progress bar and seems to provide an orientation about the progress". However, for those GIFs (GIF-13 and GIF-14 in the supplementary materials) whose last frame did not subsume important information, some participants thought the pauses would not be much useful. P15 commented, "I cannot get any conclusion. The pause (at the last frame) did not provide any help to reflect on the process." Considering the GIF itself, the end frame had low information density, which only indicated a simple final state but lost the information in the progress. A possible better design was to incorporate the previous data or take-home messages in the end frame, enabling viewers to gain more information when it paused. There also existed the exception which presented the periodic change of population in the Manhattan city. The direct loops shaped an effect of "pulse" and attracted viewers. As for bounce designs, it could be hard for participants to understand. In <ref type="figure" target="#fig_4">Fig. 4c</ref>, four participants failed in identifying the correct trend after three repetitions (i.e., consider the backwards animation as part of the trend), while two participants at first misunderstood it but corrected later. Possible reasons could be that backwards animation was not clearly distinguished and without visual guidance. P15 complained, "why does the GIF need it?", while P7 thought it facilitates the comparison between the end and start.</p><p>In summary, we concluded that 1) participants understood a temporal data-GIF intuitively and might mistakenly link the setup animation with the time; 2) context preservation helped find subtle trends but might exert extra pressure such as visual clutter and context interpretation; 3) repetition should show the start and end of a loop explicitly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">ONLINE STUDY</head><p>Informed by the interviews, we find participants have varied levels of understanding to different data-GIFs, especially for several design factors. To examine the differences of different design factors on the understandability, we conduct a large scale online study with representative data-GIFs, aiming to capture specific factors that make a data-GIF understandable and inform the design of effective data-GIFs. We use the same set of data-GIFs as those utilized in the interviews for better comparison and analysis of results. The quantitative results should be carefully interpreted given the choice of our 20 GIFs (Sec. 4.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Hypotheses</head><p>Based on our preliminary user study and literature support <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b14">16,</ref><ref type="bibr" target="#b36">38]</ref>, we propose the following hypotheses:</p><p>• H-VISUALIZATION: A data-GIF containing basic visualization (e.g., map, bar, and line charts) is most understandable (F1), since viewers could comprehend the visualization easily. • H-PROGRESS: A data-GIF with the narrative progress is more understandable (F2), as it can provide an orientation within the GIF. • H-ANIMATION: A data-GIF showing the temporal process is most understandable (F3), since animation are commonly used to convey temporal changes <ref type="bibr" target="#b32">[34]</ref> and viewers intuitively will link animation to time according to our interviewers. • H-CONTEXT: A data-GIF without context preservation is least understandable (F4), as it requires viewers' mental map to remember the previous data. • H-REPETITION: A data-GIF with pause is most understandable (F5), since it differentiates the start and end of a repetition explicitly according to our interviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Participants and Experimental Setup</head><p>Participants. The experiment was hosted on the Qualtrics survey platform. We distributed the survey through multiple methods, e.g., sending emails, inviting participants on visualization-related seminars in a research institution, posting on social media and a campus BBS (Bulletin Board System). We showcased compelling data-GIFs with a brief introduction and told the duration (approximately 15 minutes) and incentives of the study. Participants took part in the study voluntarily, and successful participants were invited to a lottery for a $5 Amazon voucher. We provided the reward for the 30% participants. The distribution method and lottery-based incentives were decided to attract more self-directed subjects who participated mainly because of their interests and generate more open-ended feedback <ref type="bibr" target="#b34">[36]</ref>. In total, 100 participants (mean age: 24.4; SD: 2.77) completed our survey. Given participants' ability to read data charts, 4% indicated no knowledge, 31% with basic knowledge, 47% intermediate, and 18% expert. 51% participants reported more than six hours of daily online browsing.</p><p>Procedure. The study began with a brief description of data-GIFs, along with the experiment details and its duration (around 15 minutes for total 5 sessions). For each session, participants first saw the title of the upcoming data-GIF for 10 seconds, and then watched the GIF (randomly selected from the 20 samples) repeating three times continuously. We decided the duration and repetition times based on our experience from previous interviews. Later, we hid the GIF, and participants were directed to a questionnaire page. Questions for each GIF included: a) two 5-point Likert scores for how well they could follow the GIF before and after the questionnaire, ranging from not at all (1) to very well (5); b) two open-ended questions listing up elements which helped or hindered the understanding, respectively; and c) three multi-choice questions about content and encoding understanding, which were proposed based on the GIFs' source articles and our interview feedback, and pre-tested through pilot studies. Each question had five options, including four answer possibilities and "I don't know". The questions can be found in the supplementary materials. After finishing 5 GIFs, they were asked to fill out a short demographic form. Data collection. To avoid viewers' prior knowledge influencing the results, we asked whether they have seen any of the GIFs before the questionnaire. However, we did not want this question to influence participants' behaviors during the study. Thus, we still asked them to complete the questions, but did not consider their responses in our analysis. Finally, we had an average of 23.8 responses per GIF (SD: 3.5; total 476 responses for 20 GIFs) and the average accuracy across all questions and GIFs was 60.1%. Three types of data from the questionnaire were further analyzed: (1) accuracy from multiple-choice comprehension questions; (2) subjective scores of viewers' understandings; and (3) qualitative feedback about influencing design factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Findings: What Makes a Data-GIF Understandable?</head><p>The goal of this analysis is to find the contributing design factors and validate the hypothesis. We follow the similar statistical analysis method as Borkin et al. <ref type="bibr" target="#b14">[16]</ref> and evaluates the statistical significance of the understandability with different design factors. In our work, understanding is measured as the accuracy of multi-choice questions in the questionnaire about the GIF content. As the accuracy scores in our data are not normally distributed, we use KRUSKAL-WALLIS test for each design factor. Furthermore, we use WILCOXON TWO-SIDED test for the pair-wise comparison within each factor, and consider Bonferroni correction for multiple comparisons. We report the sample means and 95% confidence intervals in <ref type="figure" target="#fig_5">Fig. 5</ref>. <ref type="figure" target="#fig_5">Fig. 5</ref>, we observe a significant difference between the understanding of data-GIFs and chart types (p&lt;0.05). Flow diagrams <ref type="bibr" target="#b35">[37]</ref> show the highest accuracy (mean=.80), although it is not statistically significant compared to maps and bars (p&gt;0.003). After qualitatively viewing participants' responses for elements helping and hindering the understanding, most indicate that both the animation (flowing from the source to the target) and steps (showing each flow one by one) help. Possible explanations can be that animation in the flow diagram works as a visual metaphor explaining the encoding of flow diagrams, which facilitates the understanding. Meanwhile, many responses also criticize that this GIF design lacks fo-cuses. On the other hand, we see area and point charts are significantly less understandable than the others (p-value all less than 0.003). Most responses complain that the visualization types are hard to understand (e.g., "involving multiple variables or dimensions" and "cannot understand x (y)-axis"). Back to these GIFs with area ( <ref type="figure" target="#fig_4">Fig. 4a</ref>) and point charts (e.g., <ref type="figure" target="#fig_3">Fig. 3c</ref>), we find animation here does not help explain the visualization and even complicates the GIF by adding another data dimension such as time. These complex visualization types are less understandable, which we think can help accept H-VISUALIZATION. NARRATIVE PROGRESS Data-GIFs with narrative progress show a slightly higher accuracy (mean=.62) than those without it (mean=.59). However, there are no significant differences between them (p&gt;0.05), which rejects H-PROGRESS. We check the questions asking about the narrative progress ("What is the meaning of the line chart?" for <ref type="figure" target="#fig_2">Fig.2a</ref>), most responses are correct (81.8%). We also find participants frequently mention the progress bar design in the open-ended questions asking elements which assist in the understanding of those GIFs with narrative progress. But some responses criticize that the narrative progress design is "a little far from the map (the major body of the GIF)", which distracts their attention and they have to watch two changing things meanwhile. Regarding the roles of narrative progress (i.e., provide the orientation within the GIF), although it is easy to understand and improves the reading experience, viewers still get stuck in understanding other parts of the GIF which are not explained in the narrative progress. For example, in <ref type="figure" target="#fig_3">Fig. 3c</ref>, the timeline on the top only provides limited help for the understanding of the scatter plots. <ref type="figure" target="#fig_5">Fig.5</ref> shows a significant difference for animation mapping (p&lt;0.001). Setup is the least accurate with statistical significance (p-value all less than 0.008). It is consistent with the interview results that viewers are likely to misunderstand setup animation and relate the process to specific data context. However, when comparing temporal with faceting, we could not confidently say temporal is better than faceting (p=0.053), although the former has a higher mean accuracy. To examine the details, we check the scores participants rate for their understanding and find viewers might be less confident about the faceting data-GIFs than the temporal ones. Faceting has a lower score (mean=3.12) compared to temporal (mean=3.71). It corresponds to their qualitative feedback, as many complain it is "hard to compare between frames". Consequently, we think temporal and faceting are the most understandable, narrative in between, and setup the least understandable, which partially rejects H-ANIMATION. Despite no significant difference between temporal and faceting, viewers are more confident about temporal data-GIFs than faceting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VISUALIZATION TYPES As shown in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ANIMATION ENCODING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONTEXT PRESERVATION</head><p>We find there is a statistically significant effect of context preservation techniques on the understanding of data-GIFs (p&lt;0.05). However, through pairwise comparison, we cannot find a context preservation design significantly better than the others (p&gt;0.005), which also rejects H-CONTEXT. There are no obvious differences in accuracy for no context preservation, baseline, and long exposure (mean=.60, .60, .61, respectively), while overview presents the lowest mean accuracy (mean=.46). It indicates that inappropriate context design could be even worse than no context preservation, since it requires attention and efforts for viewers to notice and interpret the preserved context. However, the duration of a data-GIF could be short, thus making it hard for viewers to perceive them all at once. Especially for overview, if viewers could not notice it at first glance, it could not play the expected roles (i.e., presenting data summary), since viewers already see all the data before they realized the overview design.</p><p>REPETITION Results show a significant difference for repetition (p&lt;0.05). In <ref type="figure" target="#fig_5">Fig. 5</ref>, data-GIFs that directly loop has a higher accuracy (mean=.65) than those who pause (mean=.58, p&lt;0.008). It is much different from the interview results, and rejects H-REPETITION. To explain this, we first refer to the comprehension questions posed to participants. The questions are designed to ask the GIF content related to the repetition, instead of the specific repetition technique (i.e. , pause, loop, or bounce). It is because explicit questions to identify repetition designs do not contribute to the understanding of the GIF's core message and also influence the viewers' behaviours (i.e., participants who see it once will pay extra attention after that). Besides, although we include 10 GIFs with pauses and 7 GIFs with loop designs to alleviate the bias from other factors, the experiment is still not strictly controlled, which can potentially affect the results. When referring to the qualitative feedback from participants, many responses appreciate the pause designs can facilitate comprehension and improve the reading experience (e.g., "pauses give me time to re-think" and "it makes me feel better and comfortable"). This reminds us to think about whether loop can make viewers more focused on the GIF, thus improving comprehension. Moreover, participants' feedback varies given different last frame designs of GIFs. For example, they think highly of GIFs that pause obviously at the last frame which subsumes important information from the repetition (e.g., the end frame in <ref type="figure" target="#fig_3">Fig. 3d</ref> preserves the whole information). Thus, viewers could examine what happens from the last frame and re-think the conclusion. Otherwise, it "interrupts my reading and I lose patience when waiting", as mentioned in one response. Regarding this, we think future studies can conduct a rigorously controlled experiment in the repetition design, since repetition is an essential factor in data-GIFs. Better design solutions can be derived from such studies to decide the interval length between two loops and the GIF duration, as well as the design of the last frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>This section presents our design suggestions, followed by the discussions about limitations of our study and the roles of data-GIFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Design Suggestions</head><p>Based on our findings of the survey and two user studies, we summarize the following design suggestions for creating effective data-GIFs. Use animation to convey temporal process. Our survey shows that animation in data-GIFs is used to convey different meanings, e.g., temporal, faceting, narrative, and setup. Viewers tend to conflate frames with time, even for non-temporal GIFs, such as regarding narrative as a presentation over time. Meanwhile, despite the similar accuracy between faceting and temporal, viewers feel more confident to follow a temporal data-GIF.</p><p>Preserve context. Preserving previous data visually supports the comparison and identification of subtle trends. However, inappropriate context preservation may cause visual clutter and bring extra cognition pressure that lowers the understandability. A suggestion is to carefully consider the context preservation design regarding the data features and intention of the GIF. For example, trails in <ref type="figure" target="#fig_3">Fig. 3b</ref> tally well with the data context (i.e., bird migration), while long exposure in <ref type="figure" target="#fig_3">Fig. 3d</ref> aims to show the temperature fluctuation.</p><p>Leverage the end frame via a pause. In general, we find viewers attach importance to the end frame (e.g., they expect obvious prompts for the end of the repetition and appreciate the pause at the end). Although the online study shows that the pause may not improve the understandability, it does not indicate the uselessness of the end frame. It instead requires a careful design to make pause valuable. For example, the pause in <ref type="figure" target="#fig_4">Fig.4b allows viewers</ref> to examine the previous content. However, for <ref type="figure" target="#fig_2">Fig.2b</ref>, even if it pauses at the end frame (i.e., showing the curve of a country), it does not bring many benefits for deriving conclusions or recalling contents. An idea to leverage the end frame of a GIF is to subsume important information (e.g., previous data or take-home messages) and make it memorable. progress Incorporate narrative progress. Integrating the narrative progress design provides the preview and orientation within the GIF. Although the results do not show a significant effect on the understandability of data-GIFs, viewers express the preference of narrative progress that helps the understanding. In addition, elaborate narrative progress can also help present the climax (e.g., <ref type="figure" target="#fig_2">Fig.2a</ref> shows a sharp increase of total cases on the line chart and ignite emotions).</p><p>Structure visual content carefully. Based on our observations from interviews (Sec. 4.3), viewers' reading experience shares commonality, i.e., guess-first, details on demand. They will guess the meaning of animation at first glance and formulate an understanding of what they have seen, since animation quickly grabs their attention. Then, they will try to examine text and legends. If the initial guess confirms, they are likely to begin an active exploration; otherwise, they will struggle. Thus, a possible suggestion is to shape data-GIFs in a clear structure that supports a rapid reading and understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Study Limitations and Reflection</head><p>We see our work as a first step toward understanding and assessing (real-world) data-GIFs. The study still has several limitations.</p><p>Towards controlled studies. Our results, especially the quantitative analysis, should be carefully interpreted in the study context of our representative set of 20 GIFs. This selection is decided to reduce the study's complexity and work with real-world GIFs of diverse design factors. As mentioned in Sec. 4.1, we acknowledge that the designs across the evaluated GIFs were limited and may have few samples of a given design, which can affect the results. However, it is hard to balance and include all characteristics, especially given the large design space of data-GIFs in both visualization and animation. Our goal was to run a first informative study using real-world data-GIFs and to inform more controlled studies in future.</p><p>Impact of other design factors. In addition to the proposed design factors, other factors may also affect comprehension of data-GIFs. For example, visual complexity and the amount of information on comprehension are complicated concepts, especially in animated formats like data-GIFs which present content over time and introduce a multitude of information with the GIF playing. Another possible factor might be the duration. Our current results suggest that GIFs with relatively long duration are likely to have high accuracy (seen in the supplementary materials). However, long GIFs may bring other problems such as engagement, which requires further research. Finally, showing different GIFs with sometimes similar-but-different design decisions-e.g., the bar grow in setup animation is coincidentally similar to the bar chart race animation-may lead to misinterpretations. We acknowledge that this kind of setup animation might not be optimally designed and the results should be taken with care. However, visualization is a field full of such "false friends" <ref type="bibr" target="#b64">[66]</ref>. Other factors like text, information density, and speed of animation may also influence the understandability. The exploration on these factors is beyond the scope of this paper, but our study provides many pointers to designing more controlled studies for future works to investigate and quantify these phenomena.</p><p>Ensuring response quality. As mentioned in Sec. 5.2, the online study aims to attract self-directed participants who are interested in data-GIFs <ref type="bibr" target="#b34">[36]</ref> through multiple methods to improve the response quality. The descriptive feedback and competition time indicate that most responses are qualified. Although the crowdsourcing platform may collect more responses, it is hard to control the experiment context and quality, e.g., where participants took part in the study as well as other distracting factors <ref type="bibr" target="#b13">[15]</ref>. Especially, we cannot directly exclude responses with low accuracy, since misunderstanding responses may indicate ineffective GIF designs in our studies. We hope future work can propose more methods to ensure response quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Data-GIFs for Data-driven Storytelling</head><p>Understanding the speciality of data-GIFs. Given the growing popularity of data-GIFs, our initial research question emerges about the fundamental differences between GIFs and other data-driven storytelling mediums. From carrying out these explorations in this work, we gain preliminary insights into the particularity of data-GIFs.</p><p>First, data-GIFs are between pictures and videos. Based on our interview feedback (Sec. 4.3), the GIF format with a sequence of frames and motion effects is considered more suitable to communicate process and attract attention. Specifically, most data-GIFs are designed to show a temporal process, especially a spatial-temporal process which can be complicated in one picture. Besides, participants appreciated the data-GIFs for narrative animation as "complementing" a static visualization with step-by-step reading guidance. Context preservation techniques track changes among frames, allowing viewers to discern details and extract potential insights from the pacing. The characteristics of automatic play and repeat direct viewers' attention to GIFs <ref type="bibr" target="#b10">[12]</ref> and further examine content in multiple loops. In addition, the representation of animated GIFs is similar to videos but is shorter and lacks audio-narrated explanation and control of playing progress. These characteristics make GIFs work as a simplified version of videos, which are more accessible with a relative small file size and a single core message. Therefore, we can see data-GIFs as an intermediate format between pictures and videos, where multiple frames enriche content and the video-like animation engages and explains.</p><p>Second, data-GIFs are between exploration and explanation. From our interviews (Sec. 4.3), we observed that data-GIFs can encourage viewers to actively explore the details of GIFs in automatic repetition, even after understanding the main message. Viewers prefer GIFs that allow them to gain more information from repetitions. Meanwhile, data-GIFs are a very author-driven medium and are mostly designed to explain authors' messages. Thus, data-GIFs work for both exploration and explanation, where the animation drives the viewers to interpret and explore the GIF spontaneously and the content is self-explainable.</p><p>Despite these, a formative comparison of GIFs to other data-driven storytelling mediums is still required, which would shed light on the opportunities and limitations of GIFs for communication. Future works can investigate the design and speciality of data-GIFs deeply.</p><p>Data-GIFs as a promising medium. The natural follow-up question is whether data-GIFs can be a promising storytelling medium. As animated GIFs are widely used as visual memes in social media and possess characteristics for engagement and virality <ref type="bibr" target="#b10">[12]</ref>, we wonder how data-GIFs leverage the GIF's strengths for attracting and engaging a wide range of audiences. Although it is beyond the scope of the paper, we see our findings provide initial evidence. For example, viewers responded they would see the GIF repeating and actively explore the details while they may feel reluctant to interact with videos. This inspires the research community to further explore the usage scenarios for different storytelling mediums <ref type="bibr" target="#b18">[20]</ref>.</p><p>Opportunities for authoring data-GIFs. Another research problem is authoring data-GIFs. There are many online GIF maker tools (e.g., GIPHY <ref type="bibr" target="#b28">[30]</ref>), which create animated GIFs by trimming video clips or adding multiple photos. However, both approaches are not suitable for creating data-GIFs starting from data. The tool support for data-GIFs is still in its infancy. Recently, Google published a tool <ref type="bibr" target="#b29">[31]</ref> that supports the data-GIF creation with only three basic setup data-GIFs. We hope our corpus and design suggestions could shed light on the future authoring tool design with new and customizable templates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>Motivated by the growing popularity of data-GIFs for communicating data stories on social media, we begin by asking what makes a data-GIF understandable to its audiences. We conduct a systematic survey of 108 data-GIFs and two exploratory user studies with total 118 participants that examine the impacts of different design factors on the understanding of data-GIFs. Our results identify a set of design factors that have an impact on the understandability of data-GIFs, and also offer valuable design suggestions for creating more effective data-GIFs.</p><p>In this work, we focus on studying data-GIFs in the wild, but further research could generalize the results on larger studies with generated and controlled data-GIFs. Beyond understandability, future studies could explore other metrics of data-GIFs such as engagement and socials given the wide use and virality on social media. We hope our work could inspire further studies on using and creating data-GIFs for data-driven storytelling, and inform the future authoring tool design.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>An overview of the design space (a) and the duration distribution (b) of 108 data-GIFs in our survey.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Faceting</head><label></label><figDesc>Which Countries have Flattened the Curve for the Coronavirus?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>NarrativeFig. 2 .</head><label>2</label><figDesc>Detroit's Debt and RevenueTemporalHow the Coronavirus Spread across the U.S.?SetupThe Number of Total Cases in Multiple Countries Four data-GIFs with tailored keyframes demonstrating four animation types of data-GIFs. Text is enlarged to make the figure clear. (a) Temporal: It shows the evolvement of the coronavirus in U.S. over time<ref type="bibr" target="#b60">[62]</ref>. Shadowed callouts are added by paper authors to make the line chart clear. (b) Faceting: It presents the curves for the coronavirus of several countries one by one<ref type="bibr" target="#b61">[63]</ref>. (c) Narrative: It narrates a story by building up the visualization scene<ref type="bibr" target="#b12">[14]</ref>. (d) Setup: It animates the creation of a bar chart<ref type="bibr" target="#b52">[54]</ref>. Original GIFs are attached in the supplementary materials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Four data-GIFs with tailored keyframes demonstrating different context preservation techniques of data-GIFs. Shadowed circles in (b) and (c) are our annotations. (a) Baseline: It preserves the distribution of the first year 1971 with the blue line [27]. (b) Trails: Each point for a bird leaves the gray trails to show the migration trajectory [26]. (c) Overview: The gray points show an overview of the data, where each point indicates the value for an upcoming year [2]. (d) Long Exposure:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Three data-GIFs with tailored keyframes demonstrating three repetition techniques of data-GIFs. Some text is enlarged to make the figure clear. (a) Loop: It directly starts a new loop [29]. (b) Pause: It inserts several same frames at the end before starting the next loop [40]. (c) Bounce: It inserts several frames at the end of the loop, showing backwards animation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Results for the understandability regarding each design factor with means and 95% CIs. Frequency shows the appearance times of each design choice in 20 samples. Pair-wise comparisons with statistical significance (after Bonferroni correction) are linked with arcs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• Xinhuan Shu is with the State Key Lab of CAD&amp;CG, Zhejiang University and Hong Kong University of Science and Technology. A part of this work was done when Xinhuan Shu was a visiting student supervised by Yingcai Wu at Zhejiang University. E-mail: xinhuan.shu@connect.ust.hk. • Aoyu Wu, and Huamin Qu are with the Hong Kong University of Science and Technology. E-mail: {awuac, huamin}@cse.ust.hk. • Junxiu Tang and Yingcai Wu are with the State Key Lab of CAD&amp;CG, Zhejiang University. Yingcai Wu is the corresponding author. E-mail: {tangjunxiu, ycwu}@zju.edu.cn. • Benjamin Bach is with Edinburgh University. E-mail: bbach@inf.ed.ac.uk. Manuscript received xx xxx. 201x; accepted xx xxx. 201x. Date of Publication xx xxx. 201x; date of current version xx xxx. 201x. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org. Digital Object Identifier: xx.xxxx/TVCG.201x.xxxxxxx</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors wish to thank all the data-GIF authors and participants in our studies. The work was supported by National Key R&amp;D Program of China (2018YFB1004300), NSFC (61761136020), NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization (U1609217), Zhejiang Provincial Natural Science Foundation (LR18F020001) and the 100 Talents Program of Zhejiang University. This project was also supported in part by HKUST SSC grant F0707 and Microsoft Research Asia.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<ptr target="https://www.pinterest.com/jsvine/datagifs/" />
	</analytic>
	<monogr>
		<title level="j">Data GIFs Collections</title>
		<imprint>
			<date type="published" when="2020-04-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Fall and Rise of U.S. Income Inequality</title>
		<ptr target="https://twitter.com/galka_max/status/823778751079219201" />
		<imprint>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flowingdata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Retrieved</surname></persName>
		</author>
		<ptr target="https://flowingdata.com/" />
		<imprint>
			<date type="published" when="2020-04-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The Pudding</title>
		<ptr target="https://pudding.cool/" />
		<imprint>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<ptr target="https://www.washingtonpost.com/" />
	</analytic>
	<monogr>
		<title level="j">The Washington Post</title>
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding Data Videos: Looking at Narrative Visualization Through the Cinematography Lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
		<idno type="DOI">10.1145/2702123.2702431</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1459" to="1468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hooked on Data Videos: Assessing the Effect of Animation and Pictographs on Viewer Engagement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leboe-Mcgowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
		<idno type="DOI">10.1145/3206505.3206552</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Advanced Visual Interfaces</title>
		<meeting>the International Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Authoring Data-Driven Videos with DataClips</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Monroy-Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Irani</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2598647</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="501" to="510" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Telling Stories about Dynamic Networks with Graph Comics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kerracher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858387</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">36703682</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Design Patterns for Data Comics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farinella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray-Rust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<idno>doi: 10. 1145/3173574.3173612</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast, Cheap, and Good: Why Animated GIFs Engage Us</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bakhshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>De Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Kaye</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858532</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="575" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Useful junk? the effects of visual embellishment on comprehension and memorability of charts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bateman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Mandryk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Genest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcdine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brooks</surname></persName>
		</author>
		<idno type="DOI">10.1145/1753326.1753716</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">25732582</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Detroit&apos;s Debt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bomey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gallagher</surname></persName>
		</author>
		<ptr target="https://www.freep.com/story/news/local/michigan/detroit/2013/09/15/how-detroit-went-broke-the-answers-may-surprise-you-and/77152028/" />
		<imprint>
			<date type="published" when="2020-04-28" />
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Information Visualization Evaluation Using Crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Borgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Micallef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mcgee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.13444</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="573" to="595" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Borkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bylinskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sunkavalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.234</idno>
		<title level="m">What Makes a Visualization Memorable? IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="2306" to="2315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Investigating aspects of data visualization literacy using 20 information visualizations and 273 science museum visitors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Börner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maltese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Balliet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heimlich</surname></persName>
		</author>
		<idno type="DOI">10.1177/1473871615594652</idno>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="198" to="213" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Data viz solutions: small multiples on desktop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boyer</surname></persName>
		</author>
		<ptr target="https://twitter.com/brianboyer/status/583311823245561856" />
		<imprint>
			<date type="published" when="2015-04-28" />
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Comparative Evaluation of Animation and Small Multiples for Trend Visualization on Mobile Phones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Choe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="364" to="374" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Analyzing gaze behavior for text-embellished narrative visualizations under different task scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shidara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visinf.2020.08.001</idno>
	</analytic>
	<monogr>
		<title level="m">Visual Informatics</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Study of the Effect of Doughnut Chart Parameters on Proportion Estimation Accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Efstathiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.13325</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="300" to="312" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Examining the use of narrative constructs in data videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Zucco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visinf.2019.12.002</idno>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="22" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">GIFGIF+: Collecting Emotional Animated GIFs with Clustered Multi-task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">O</forename><surname>Rudovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACII.2017.8273647</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Affective Computing and Intelligent Interaction</title>
		<meeting>the International Conference on Affective Computing and Intelligent Interaction</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="510" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The not-so-staggering effect of staggered animated transitions on visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dragicevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franconeri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2241" to="2250" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Animations 25 Years Later: New Roles and Opportunities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chalbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurter</surname></persName>
		</author>
		<idno type="DOI">10.1145/2909132.2909255</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Working Conference on Advanced Visual Interfaces</title>
		<meeting>the International Working Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">280287</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Watch 118 Bird Species Migrate across a Map of the Western Hemisphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornell</forename><surname>Lab</surname></persName>
		</author>
		<ptr target="https://www.allaboutbirds.org/news/mesmerizing-migration-watch-118-bird-species-migrate-across-a-map-of-the-western-hemisphere/" />
		<imprint>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Shape-shifting US Income Distribution. Retrieved</title>
		<ptr target="https://twitter.com/FT/status/674759218545717252" />
	</analytic>
	<monogr>
		<title level="m">Financial Times</title>
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Americans are Growing Bigger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flowingdata</surname></persName>
		</author>
		<ptr target="https://twitter.com/flowingdata/status/742741435275874306" />
		<imprint>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The Difference between Men and Women Population by Age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flowingdata</surname></persName>
		</author>
		<ptr target="https://flowingdata.com/2018/10/17/ask-the-question-visualize-the-answer/" />
		<imprint>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Creation Best Practices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Giphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gif</surname></persName>
		</author>
		<ptr target="https://support.giphy.com/hc/en-us/articles/360019914771-GIF-Creation-Best-Practices" />
		<imprint>
			<date type="published" when="2020-04-28" />
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Google Data GIF Maker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Google</surname></persName>
		</author>
		<ptr target="https://datagifmaker.withgoogle.com/" />
		<imprint>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Data Visualization GIFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Groeger</surname></persName>
		</author>
		<ptr target="http://lenagroeger.com/datagifs/" />
		<imprint>
			<date type="published" when="2020-04-28" />
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hawkins</surname></persName>
		</author>
		<ptr target="https://twitter.com/ed_hawkins/status/729753441459945474?lang=en" />
		<title level="m">Global Temperature Change</title>
		<imprint>
			<date type="published" when="2020-04-28" />
			<biblScope unit="page" from="1850" to="2016" />
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Animated Transitions in Statistical Data Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2007.70539</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1240" to="1247" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Instructional Animation versus Static Pictures: A Meta-analysis. Learning and Instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Hoffler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Leutner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.learninstruc.2007.09.013</idno>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="722" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">You Get Who You Pay for: The Impact of Incentives on Participation Bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kocielnik</surname></persName>
		</author>
		<idno type="DOI">10.1145/2818048.2819936</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing</title>
		<meeting>the ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">823835</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Institute for Health Metrics and Evaluation. Flows of Development Assistance for Health</title>
		<ptr target="https://medicalxpress.com/news/2017-04-widely-disparate-health.html" />
		<imprint>
			<date type="published" when="2020-04-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Understanding diverse interpretations of animated gifs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Brubaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fiesler</surname></persName>
		</author>
		<idno type="DOI">10.1145/3027063.3053139</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference Extended Abstracts on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference Extended Abstracts on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1726" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The Perfect One&apos;: Understanding Communication Practices and Challenges with Animated GIFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fiesler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Brubaker</surname></persName>
		</author>
		<idno type="DOI">10.1145/3274349</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2018" />
			<publisher>CSCW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The Proliferation of Walmart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jones</surname></persName>
		</author>
		<ptr target="https://twitter.com/toddrjones/status/1167112782124179456" />
		<imprint>
			<date type="published" when="2020-04-28" />
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Predicting Viewer Perceived Emotions in Animated GIFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2647868.2656408</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="213" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Hypothetical outcome plots help untrained observers judge trends in ambiguous data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="892" to="902" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Datatoon: Drawing Dynamic Network Comics With Pen + Touch Interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pahud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300335</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Data-Driven Guides: Supporting Expressive Design for Information Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schweickart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2598620</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="491" to="500" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Designing Animated Transitions to Convey Aggregate Operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1111/cgf.13709</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Understanding visual cues in visualizations accompanied by audio narrations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-K</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Karahalios</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300280</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">113</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Vlat: Development of a visualization literacy assessment test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="551" to="560" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Decoding a Complex Visualization in a Science Museum An Empirical Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frazier</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934401</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="472" to="481" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Visual Narrative Flow: Exploring Factors Shaping Data Visualization Story Reading Experiences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mckenna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<idno>doi: 10. 1111/cgf.13195</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">377387</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Datav: Data visualization on large high-resolution displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visinf.2020.07.001</idno>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="23" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Visualization Analysis and Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Animated Infographics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<ptr target="https://jacoboneal.com/cheetah/" />
		<imprint>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Data is Personal: Attitudes and Perceptions of Data Visualization in Rural Pennsylvania</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Peck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Ayuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>El-Etr</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300474</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">People&apos;s Daily. The Number of Total Cases in Multiple Countries</title>
		<ptr target="https://wap.peopleapp.com/article/5210197/5111953" />
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Effectiveness of Animation in Trend Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2008.125</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1325" to="1332" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">What do we talk about when we talk about dashboards?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="682" to="692" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Narrative Visualization: Telling Stories with Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Segel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2010.179</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1139" to="1148" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Dancingwords: exploring animated word clouds to tell stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12650-020-00689-0</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Narrative Transitions in Data Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visuliazation Conference Short Papers</title>
		<meeting>the IEEE Visuliazation Conference Short Papers</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">PlotThread: Creating Expressive Storyline Visualizations using Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">iStoryline: Effective Convergence to Hand-drawn Storylines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rubab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="769" to="778" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<ptr target="https://twitter.com/nytimes/status/1241387140933652481" />
		<title level="m">The New York Times. How does the Coronavirus Spread across the</title>
		<meeting><address><addrLine>U.S</addrLine></address></meeting>
		<imprint>
		</imprint>
	</monogr>
	<note>Retrieved</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Which Countries have Flattened the Curve for the Coronavirus?</title>
		<ptr target="https://twitter.com/nytimes/status/1240790201414438912" />
		<imprint>
		</imprint>
	</monogr>
	<note>The New York Times</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Animation: Can it facilitate?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Btrancourt</surname></persName>
		</author>
		<idno type="DOI">10.1006/ijhc.2002.1017</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="247" to="262" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">InfoNice: Easy Creation of Information Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3173574.3173909</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Cheat sheets for data visualization techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sundin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray-Rust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Comparing Effectiveness and Engagement of Data Comics and Infographics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farinella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray-Rust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry Riche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300483</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
