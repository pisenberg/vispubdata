<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Volume Sampled Voxelization of Geometric Primitives</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidney</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">State University of New York at Stony Brook</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">State University of New York at Stony Brook</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Volume Sampled Voxelization of Geometric Primitives</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Voxelization</term>
					<term>Volume Sampling</term>
					<term>Discrete Ray Tracing</term>
					<term>Filtering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present a 30 antialiasing algorithm for voxelbased geometric models. The technique band-limits the continuous object before sampling it at the desired 3 0 raster resolution. By precomputing tables of filter values for different types and sizes of geometric objects, the algorithm is very efficient and has a complexity that is linear with the number of voxels generated. The algorithm not only creates voxel models which are free from object space aliasing, but it also incorporates the image space antialiasing information as part of the view independent voxel model. The resulting alias-free voxel models have been used to model synthetic scenes, for discrete ray tracing applications. The discrete raytraced image is superior in quality to the image generated with a conventional surface-based ray tracer, since silhouettes of objects, shadows, and rejections appear smooth (jaggy-less). In addition, the aliaslfree models are also suitable for intermixing with sampled datasets, since they can be treated uniformly as one common data representation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent progress in volume rendering technology and voxel-based graphics is apparent, not only for visualizing and analyzing sampled and computed datasets, but also for modeling synthetic scenes as in volume graphics <ref type="bibr">[14]</ref>. Modeling a geometric scene in voxel space calls for algorithms that generate from a geometric representation of the scene the set of voxels that "best" approximates the continuous model. These algorithms, called voxelization (or 3D scan conversion) algorithms, are applied to a variety of objects with lD, 2D, and 3D degrees of freedom, that is, curves, surfaces, and solids, respectively. Voxelizing a continuous model into a 3D raster requires a sampling process which determines.the value to assign to each element, or voxel, of the 3D raster. Perhaps the most straightforward method of sampling in space is by point sampling. Due to its simplicity, the point sampling approach is employed by all of the voxelization algorithms which have appeared in the literature to date <ref type="bibr">[3,</ref><ref type="bibr">[9]</ref><ref type="bibr">[10]</ref><ref type="bibr">[11]</ref>. In point sampling, we select the voxel center as the representative for each voxel, evaluate the original continuous object at this point, and assign the value of 0 or 1 to the voxel. Because of this binary classification of the voxels, the resolution of the 3D raster ultimately determines the precision of the discrete model. Imprecise modeling results in jagged surfaces known as object space aliasing <ref type="bibr">[l, 21.</ref> Aliasing in volume graphics presents greater difficulties than those of 2D raster graphics. Unlike antialiasing of 2D scanconverted graphics, where the main focus is on generating aesthetically pleasing displays, the emphasis in antialiased 3D voxelization, which is the subject of this paper, is on producing alias-free models for various volume graphics applications.</p><p>Volume graphics <ref type="bibr">[14]</ref> is concerned with the synthesis, manipulation, and rendering of volumetric objects, primarily geometric models, stored in a 3D raster of voxels. Volume graphics offers several advantages that are due to the decoupling, uniformity, and atomicity features of the approach. In volume graphics the rendering phase is viewpoint independent and insensitive to scene complexity and object complexity as demonstrated in <ref type="bibr">[19]</ref>. It supports effectively Boolean and block operations and constructive solid modeling <ref type="bibr">[13]</ref>. When 3D sampled or simulated data is available, such as that generated by medical scanners or scientific simulations, volume graphics is suitable for their representation.</p><p>However, the aliasing of the point sampled models causes many of the maladies of voxel-based graphics. For example, in discrete ray tracing <ref type="bibr">[19]</ref> and flight simulation [ 181 applications, the discrete geometric primitives are used to model the synthetic scene. During shading and secondary ray calculations, an essential requirement is the ability to accurately compute the surface normal vector. However, the lack of geometric definition of the surface in discrete voxel representation necessitates the use of discrete shading techniques which estimate the normal from a context of neighboring voxels 1201. The accuracy of discrete normal estimation depends greatly on the smoothness/jaggedness of the discrete surface. Needing accurate normals for spawning secondary rays, <ref type="bibr">Yagel et al. [191 have</ref> assumed that ray-object intersection always occurs at voxel center by pre-storing during voxelization the exact surface normal within each voxel. A more obvious effect of aliasing can be seen when detecting discrete ray-object intersection. A ray that barely misses an object in the continuous space might produce an intersection in the discrete space. Similarly, a rayobject intersection in the continuous space might not be detected in the discrete space. These two scenarios are illustrated in <ref type="figure">Figure 1</ref>.</p><p>Voxelized geometric primitives are also being utilized in conjunction with sampled d a h as in medical imaging. For example, geometrically defined objects and sampled CT datasets need to be intermixed and visualized together, such as when a scalpel is superimposed on a CT image, or radiation beams are superimposed on a scanned tumor [12, 151. A preferred solution is to convert (voxelize) the geometric object into the sampled data representation before intermixing them. The resulting composite dataset is then rendered using one of a variety of volume rendering methods. However, if the geometric primitive is voxelized using point sampling, artifacts may occur in the generated image. The reason lies in the incompatibility of merging a data of binary density (the voxelized primitive) with a data of grey scale density (the sampled CT data).</p><p>Another application employing voxelized primitives is Constructive Solid Geometry (CSG). CSG operations such as subtraction, union, and intersection between two voxelized objects are accomplished at the voxel level <ref type="bibr">[16]</ref>, thereby reducing the original problem of evaluating a CSG tree of such operations down to a Boolean operation between pairs of voxels. However, since the precision of the discrete model is determined by the 3D raster resolution, errors caused by imprecise modeling can accumulate and lead to artifacts.</p><p>The above examples present the complications inherited in the point sampled discrete models in a variety of volume graphics applications. Like pixels in 2D, voxels in 3D may in principle be made as small as desired to increase the accuracy of the discrete representation, thus reducing the aliasing. However, the improvement comes at the price of significantly increasing the memory space and scan conversion time. In this paper we devise an analytical 3D antialiasing technique for modeling continuous geometric primitives in a discrete 3D raster. The resulting discrete model is alias-free and produces high quality 2D image (superior to the image generated with conventional ray tracers) when ray traced with a discrete ray tracer. Furthermore, the antialiased discrete model not only eliminates aliasing in the object space, but it also smoothes out the image space aliasing caused by point sampling in screen space, without the need for sub-pixel supersampling or other postprocessing .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Weighted Volume Sampled Primitives</head><p>The main problem with point sampling lies in the fact that only a finite set of points are sampled, and therefore, important features presented on the boundary between the material (the object) and the empty space may be missed. This is why aliased 2D models contain jagged edges and aliased 3D models have jagged surfaces. A commonly used antialiasing method in 2D is simply to point sample the object at a high resolution before filtering (averaging) it down to the desired image resolution <ref type="bibr">[4]</ref>. However, this approach merely "hides" the aliasing by making the jagged silhouette less noticeable to the human eyes. While this method is usually adopted in 2D raster graphics, the same technique will not work in 3D, since in volume graphics the main concem is to generate "precise" models for the application, not just for viewing. Another 2D antialiasing approach follows a filtering paradigm <ref type="bibr">[17]</ref> by low pass filtering the original signal (the continuous object) before sampling. After prefiltering, point sampling is feasible. In practice, the two stages, prefiltering followed by sampling, are combined into one process which is called area sampling in 2D raster graphics [6]. <ref type="bibr">Gupta and Sproull [7]</ref> have incorporated the idea of area sampling into efficient 2D scan conversion algorithms of lines and polygons by exploiting precomputed lookup tables.</p><p>Our algorithm for generating alias-free 3D models is essentially a generalization of Gupta and Sproull's area sampling algorithm. Instead of performing 2D area prefiltering and sampling, the algorithm prefilters and samples in 3D space, and hence is termed volume sampling. Since we know in advance exactly where the samples are taken (at voxel centers), we need only to evaluate the filtered value at each sample point. Filtering is essentially an averaging process; the filtered value located at a given sample <ref type="bibr">( x , y , z )</ref> is determined by positioning the filter support centered at that sample and calculating the density contribution within the filter support:</p><formula xml:id="formula_0">density of sample (x ,y ,z ) = Jvolrune of filler support h ( r ) . f ( r , 0, $) dV (1) where 1 if point (r , 0, 4) â‚¬primitive h ( r ) = filter weight function and dV = r2 .sin$ dr d $ d 0</formula><p>The filter support we selected is a spherical volume with its radius set at three voxel units. The consequences of making the filter support radius larger or smaller will be discussed later. The filter weight function, h ( r ) , is a weight function that specifies the magnitude of importance of each point within the filter support. Since the filter support is radially symmetric with respect to the center of filter, h ( r ) can be defined as a function of distance from the filter's center along the radial axis. For the ease of implementation and its effectiveness, a Bmlett function, which has its maximum value at the center of the filter and decreases linearly to zero at a distance equal to the filter support radius, is used as our filter weight function. The use of a filter weight function gives the name weighted volume sampling to our sampling technique. Throughout the rest of this paper, the terms volume sampling and weighted volume sampling are used interchangeably.</p><p>In Equation 1 we have shown how the filtered value of each sample at voxel center is calculated. However, approximating the continuous integral using numerical methods are extremely time consuming. In our implementation, lookup tables are used to assign the filtered value of each voxel rather than compute it on the fly. For each voxel visited in the voxelization algorithm, the distance to the primitive is used as an index into a lookup table of densities. These density values in the table were precomputed using Equation 1. The pseudo code for generating a sphere primitive's lookup table is given in <ref type="figure">Figure 2</ref>.</p><p>Since a primitive is usually formed by different types of entities, a lookup table is associated with each type of entity. For example, a polygon primitive consists of faces, edges, and vertices. Hence, three lookup tables are required for the voxelization of a polygon, as illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>. Then, for a given voxel, one must first identify the entity type to which the voxel belongs; the corresponding lookup table is then used for density assignment.</p><p>Additional processing time can be significantly reduced by examining only voxels which are within or located near the continuous primitive instead of a brute force method of examining every voxel in the 3D raster. This can be accomplished easily by utilizing the existing point sampled voxelization algorithms which only visit voxels that are "relevant." Since filtered primitives are thicker than their continuous counterparts, we need to point sample a slightly larger primitive (depending on the filter support radius) to ensure that all essential voxels are visited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Benefits of Volume Sampling</head><p>In Section 1 we discussed the problems associated with 3D point sampled primitives. In this section, we  describe how these difficulties are eliminated when alias-free primitives are used instead.</p><p>Recall that jagged surfaces of point sampled primitives result in complication during ray-object intersection detection (e.g., <ref type="figure">Figure 1)</ref>. With volume sampled primitives, one might think it is impossible to detect the original surface of the primitive, since the prefiltering process smoothed out the original surface. However, by treating the filtered values in the 3D raster as samples in a scalar field and knowing the filtered density value of the primitive's surface, one can detect the original surfaces by thresholding during ray tracing. Hence, neither a false intersection nor an undetected intersection may occur.</p><p>The ray-object intersection detection algorithm is described in <ref type="figure">Figure 4</ref>. Basically, at each stepping of the ray, a trilinear interpolation is performed to evaluate the scalar value at that point, If that value is greater than the surface filter density (the threshold value), the surface must pass between the current ray position and the previous ray position. A binary search is then performed to detect the exact position of the ray-object intersection. The level of the binary search can be set according to the ray stepping increment size and the desired fidelity. The intersection detection algorithm assumes that there is only one threshold density value associated with a given object surface. This assumption, however, holds true for spheres only. For other primitives we need to normalize the entity density values, one for each type of entity (see <ref type="figure" target="#fig_2">Figure 3)</ref>, in order for the algorithm to work. By taking advantage of the fact that traversing a discrete ray is much faster than traversing a continuous parametric ray. we can step quickly through the empty space by utilizing a discrete ray, and once the ray reaches any non-transparent voxel, a more accurate continuous ray is used for intersection detection.</p><p>When an intersection point is detected, the surface normal at that particular point can be accurately estimated from the context of the neighboring samples by grey-level gradient normal estimation [8]. In our implementation, this is estimated by calculating the density central differences among the six neighboring samples taken exactly one voxel unit above, below, in front, behind, to the left of, and to the right of the exact intersection point. The reason to require that the filter radius size be at least three voxel units is to assure that the neighboring samples contain values for normal estimation. Of course, the larger the selected filter radius size, the larger is the neighborhood available for normal evaluation. But a larger filter smoothes out the sharp features of the original object (e.g., the apex of a cone, the edges and vertices of a polygon). Computing the surface normal on the fly eliminates the need to pre-store the normal during the voxelization process, thus saving memory space. More importantly, we no longer assume that the ray-object intersection always occurs at the voxel center: thus normals are more accurately computed and, for example, secondary rays are spawned in the precise direction.</p><p>In volume sampling, the fuzzy (filtered) surface has the property that the density of the surface decreases smoothly from the interior of the object to the empty space. This property of diminishing densities of the filtered surface is essentially the image space antialiasing information that is provided for the ray tracer. Normally, when a continuous object with a well defined surface is ray traced, a ray either hits or misses the object. This binary classification of the pixels results in jaggedness around the silhouette of objects, reflections, and shadows. However, with volume sampling, a ray can approximate the closeness of a miss by comparing the ratio of the current density value to the normalized surface density value while stepping along the ray. A ratio of one or greater represents a "solid hit, while a ratio between zero and one represents a "close" miss. Therefore, when determining the final color of a pixel, the closeness ratio of a rayobject miss is also considered in the final pixel intensity calculation. For example, a closeness ratio of 0.5 conmbutes only 50 percent of the object intensity to the ray. The same technique is also used to generate soft shadows by allowing partial blockage of light as rays pierce through the fuzzy silhouette of the object. Thus, the effect of image space antialiasing and soft shadow (shown in <ref type="figure" target="#fig_4">Figures 5 and 6</ref>) can be accomplished without the need for any extra postprocessing.</p><p>Volume sampled primitives also solve the problem of compatibility when merging point sampled primitives with samplWcomputed datasets, since the volume sampled primitives are sampled with the same frequency as the sampledcomputed dataset, as though the voxelized primitive is generated by a sampling device such as a CT scanner. Hence, the intermixed datasets are treated uniformly as one data representation and can be rendered using any volume rendering method. <ref type="figure">Figure   Figure 6</ref>: Volume sampled spheres casted soft shadows on a polygon. 7 shows a simulated dataset visualized together with volume sampled mirrors.</p><p>In addition, volume sampled primitives can function as matfe volumes [5] for various matting operations such as CSG operations. One example is merging multiple volumes into a single volume using union operation. Another common uses of matte volumes is to perform cut-aways. In <ref type="figure" target="#fig_6">Figure 8</ref>, a sphere matte volume is used to remove a spherical section of the CT scanned head. Since our matte volumes are fractional instead of binary, the boundaries between the material and the empty space are smooth and continuous.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Accuracy</head><p>In this section, we examine the accuracy of our ray-object intersection detection and surface normal estimation. Figures 9 and 10 are color mapped images which indicate the magnitude of errors when compared to the true geometric ray-object intersection and the true geometric surface normal, respectively.</p><p>As seen in <ref type="figure" target="#fig_7">Figure 9</ref>, the accuracy of the ray-object intersection detection degrades for rays that are around the silhouette of the primitive. The reason is because the primitive's density value changes very slowly in the direction that is perpendicular to the surface normal; hence, for a ray located near the silhouette of the primitive, it might intersect the threshold surface value at a small interval rather than a single point.</p><p>Nevertheless, the maximum error is kept under 0.2 voxel unit.</p><p>Recall that our surface normal estimation is achieved through a simple grey-level gradient method by taking the central differences. <ref type="figure" target="#fig_8">Figure 10</ref> shows that the maximum normal estimation error is under 1.5 degrees. The result can be improved by employing a more sophisticated normal estimation technique or examining a larger neighborhood. The pattern generated in the normal error image is caused by the quantization error of representing each voxel as an unsigned char rather than a float.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>Voxelization of primitives using a weighted volume sampling technique has been presented. The advantages of volume sampled models as compared to  solidifies the potential of volume graphics. We are currently working on a new surface detection algorithm which will not require the surface density values to be normalized; as a result, for a given volume sampled primitive, we will be able to treat a given volume sampled primitive as a "hard" object for modeling synthetic scene in ray tracing application, or as a "soft" object for intermixing with sampled data.</p><p>(See color plates. p.  Volume Sampled Voxelizatioiz of Geometric Primitives, S.W. Wang and A.E. Kaufman. pp. 78-84.   1 &lt;O 05 degrees, yellow represents 0 55 1 t' 1 &lt; 1 0, and red represents 1 05 1 1 &lt;1 5</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure</head><label></label><figDesc>Figure 1: A ray passing through a volume consisting of two objects. (a) The ray has a false intersection. (b) The ray has a miss intersection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>)Figure</head><label></label><figDesc>( sphere-rad, filter-rad ) { startgos = sphere center.x + sphere rad -filter rad; endgos = sphere1center.x + sphereIrad + tilterrad; for (filtergos = start: filtergos c end; filtergos += delta-x) table [filtergos] = density of sample (filtergos);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Filtering a polygon requires three density lookup tables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 4: Ray-object intersection detection algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5</head><label>5</label><figDesc>Volume sampled sphere and disk reflected onto the base of a cone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Simulated molecule reflected onto volume sampled mirrors.(See color plates, p. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Portion of the head is removed by subtracting a volume sampled sphere.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Error magnitude of ray-object intersection detection. Green represents 0.011e 14.05 voxel units, yellow represents 0.0551e kO.1, and red represents 0.1SIe k0.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Error magnitude of surface normal estimation. Green represents 0.011e k0.5 degrees, yellow represents 0.511e 1&lt;1.0, and red represents 1.0Sle k1.5. point sampled models have been discussed and demonstmted. The ability to incorporate both object space antialiasing and image space antialiasing directly into the voxel model during a preprocessing stage</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Volume sampled sphere and disk reflected onto tne base of a cone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Simulated molecule reflected onto volume sompled mirrors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 0 Figure 8</head><label>08</label><figDesc>Error magnitude of ray-object intersection detection Green represents 0 Or 1 6 7 1 &lt;O 05 voxel units yellow represents 0 055 1 t' 1 &lt;O 1 and red represents 0 isle 1432Figure6: Volume sampledspheres casted soft shadows on a polygon Portion of the head is removecl by subtracting a volume sampled spnere Figure 10 Error magnitude of surface normal estimation Green represents 0 05</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head><p>This work has been supported by the National Science Foundation under grant CCR-9205047. The images were generated using a modified version of Lisa Sobierajski's ray tracer.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">What We Need Around Here is More Aliasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Blinn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="75" to="79" />
			<date type="published" when="1989-01" />
		</imprint>
	</monogr>
	<note>IEEE Computer Graphics &amp; Applications</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scan-Conversion Algorithms for Linear and Quadratic Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Crow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<editor>Visualization, A. Kaufman,</editor>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="1981" />
			<publisher>BEE Computer Society Press</publisher>
		</imprint>
	</monogr>
	<note>A Comparison of Antialiasing Techniques</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanraham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Computer Graphics: Principles and Practice, Second Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Filtering Edges for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Sproull</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gray-Scale</forename><surname>Displays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shading 3D Images from CT Using Gray-Level Gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Hoehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bemstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging, MI</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">3D Scan-Conversion Algorithms for Voxel-Based Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shimony</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1986 Workshop on Interactive 3 0 Graphics</title>
		<meeting>the 1986 Workshop on Interactive 3 0 Graphics<address><addrLine>Chapel Hill, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986-10" />
			<biblScope unit="page" from="45" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An Algorithm for 3D Scan-Conversion of Polygons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EUROGRAPHICS&apos;87 Conference</title>
		<meeting>EUROGRAPHICS&apos;87 Conference<address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987-08" />
			<biblScope unit="page" from="197" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient Algorithms for 3D Scan-Conversion of Parametric Curves, Surfaces, and Volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="1987-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Intermixing Surface and Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="82" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Imaging in Medicine. Algorithms</title>
		<editor>Applications, K. H. Hoehne, H. Fuchs and S . M. Pizer,</editor>
		<imprint>
			<biblScope unit="page" from="217" to="227" />
			<date type="published" when="1990" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
	<note>Systems</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The voxblt Engine: A Voxel Frame Buffer Processor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Graphics Hardware Ill, A. A. M. Kuijk</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="85" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Volume Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<date type="published" when="1993-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Hybrid Ray Tracer for Rendering Polygon and Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="1990-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Geometric Modeling using Octree Encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Mehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Meagher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Garphics and Image Processing</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1990" />
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
	<note>Digital Image Warping</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Voxel-Based, Forward Projection Algorithm for Rendering Surface and Volumetric Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding Visualization &apos;92</title>
		<meeting>eeding Visualization &apos;92<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992-09" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
	<note>Discrete Ray Tracing</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Normal Estimation in 3D Discrete Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Visual Computer</title>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="page" from="340" to="348" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
