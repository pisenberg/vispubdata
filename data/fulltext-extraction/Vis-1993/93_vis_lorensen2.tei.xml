<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Enhancing Reality in the Operating Room</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lorensen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Christopher Nafis General Electric Company Corporate Research and Development Schenectady</orgName>
								<address>
									<settlement>New York</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harvey</forename><surname>Cline</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Christopher Nafis General Electric Company Corporate Research and Development Schenectady</orgName>
								<address>
									<settlement>New York</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Enhancing Reality in the Operating Room</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Three dimensional computer models of the anatomy generatedfrom volume acquisitions of computed tomography and magnetic resonance imaging are useful adjuncts to 2 0 images. This paper describes a system that merges the computer generated 3 0 models with live video to enhance the surgeon&apos;s understanding of the anatomy beneath the surface. The system can be used as a planning aid before the operation and provide additional information during an operation. The application of the system to a brain operation is described.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The surgeon stands over the patient preparing to remove a large tumor at the top of the brain. Before making any incisions, the doctor sees computer models of the underlying anatomy of the brain surface and the tumor, mixed with a live video image of the patient. The combined video and computer images permit the surgeon to plan a path to the diseased tissue. Keeping the size of the incision as small as possible may shorten the patient's recovery time. Critical functional areas such as the motor strip are readily visible on the 3D computer image and the surgeon plans the operation to avoid these regions. After making an incision through the scalp, the surgeon cuts and removes a piece of skull, revealing the surface of the brain and the top of the tumor. The patient video, enhanced by the computer models, shows the extent of the tumor's intrusion beneath the brain's surface. The combined image shows the surgeon cutting the borders of the tumor. After two hours of skilled work, the surgeon removes the golfball-sized tumor. This is an abridged description of an operation that took place at Brigham and Women's Hospital in Boston in early Spring 1993. This enhanced reality demonstration was the result of a collaboration between scientists and physicians from industry and medicine. This paper describes the methods and apparatus that were used for this operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ron Kikinis David Altobelli Langham Gleason Brigham and Women's Hospital</head><p>Surgical Planning Laboratory Boston, Massachusetts</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">3D Medical Imaging</head><p>Three-dimensional medical images provide a non-invasive visualization of internal human anatomy. These 3D images can supplant the diagnostic information in the 2D cross-sectional images provided by X-ray computed tomography (CT) and magnetic resonance imaging (MRI). The 3D images also enhance communication between the radiologist, who has special training to interpret the CT and MRI images, and the referring physician or surgeon, who are often more comfortable with 3D presentations.</p><p>In this paper, we focus on surgery applications although many of the same techniques can be applied to diagnostic radiology. Craniofacial applications have driven the development of most 3D surgical applications and our work is similarly motivated. Some work has been done on direct surgical support. The pioneering efforts at the Mayo Clinic [ 11 show the value of 3D images for stereotactic operations on deep seated pathology. Stereotaxy uses a rigid mechanical frame attached to the patient's head before imaging. The frame and its landmarks can be seen in the resulting image. Mechanical mechanisms on the frame can deliver a probe to a specific location in the anatomy. Calculation of the proper trajectory is done using the 2D or 3D images. This paper describes a procedure for surgical planning and surgical support that combines live video of the patient with the computer-generated 3D anatomy of the patient. Prior to surgery, this video mixing permits surgeons to plan access to the pathology that exists within the patient. During an operation, the surgeon can view the live video of the patient's internal anatomy mixed with the 3D computer models. The paper describes initial experiments with the system on normal volunteers and patients. The technique enhances a surgeons perception of underlying anatomy of the patient but does not currently have the accuracy to be considered for stereotactic procedures. <ref type="figure">Figure 1</ref> shows the steps necessary to create a 3D medical image, starting with data'acquisition and ending with visualization of the results. </p><formula xml:id="formula_0">I uspli Figure 1.3D Medical</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Image Processing</head><p>Improvements in signal to noise ratios can be achieved by increasing acquisition times or by post processing the ac- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="23.">Tissue Segmentation</head><p>Segmentation is the identification of regions within the 3D volume. Several approaches are possible and often combinations of these techniques are required to successfully segment the tissues in a volume. First the data is threshold4 and then each desired structure is seeded. The connectivity of the separate structures is tracked with the 3D volume and each visited voxel is marked with a tissue number. Multivariate segmentation techniques <ref type="bibr" target="#b0">[6]</ref>, use more than one set of images that have different contrast relationships. For MRI, variations in the echo times can produce simultaneous images that are perfectly registered <ref type="bibr" target="#b1">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Model Construction</head><p>Once the segmentation process identifies the tissues, surfaces of each tissue are constructed. We have developed two surface generation algorithms: marching cubes <ref type="bibr" target="#b2">[8]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Model Display</head><p>Viewing the 3D models requires a suite of display and manipulation tools. We have found the following essential features for our surgical application:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple coordinate systems:</head><p>We provide two, an object coordinate system and a world coordinate system. We maintain separate coordinate systems for each object and </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Surgical Planning</head><p>Additional features are essential for successful surgical planning <ref type="bibr">[lo]</ref>. Arbitrary cuts of the surfaces provide an electronic scalpel that can simulate the incisions to be made during surgery. Rotations of cuts about arbitrary axes help to move the cut pieces into their final locations. Interpolated slices pasted onto the cut surfaces provide a 3D context for the traditional 2D slice presentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7.">Video Registration</head><p>Once the 3D models are created, the rendered images can be combined with live video of the patient. This mixing of computer models and live video brings the surgical plan into the operating room. The schematic in <ref type="figure" target="#fig_1">figure 2</ref> shows the setup for the merging of the two video sources. The physical camera is pointed at the patient and the computer camera is aligned with the real camera by adjusting the viewing parameters. Currently, this manual registration is accomplished in a few minutes, providing there are sufficient features visible on the patient's video image. Once aligned, an operator interactively adjusts the mixing of the two video sources. The surgeon looks at a monitor that displays the mixed image. <ref type="figure">Figure 3</ref> shows example frames from an experiment on a normal volunteer. The video mixer has a variety of options that aid the registration process. <ref type="figure">Figures 3a and 3b</ref> show split windows of computer and patient images. <ref type="figure">Figure 3c</ref> shows the computer generated models of the patient's face and brain. In <ref type="figure">figure 3d</ref>, the surgeon sees the mixed image that contains his hand and pen. Watching this combined image, the surgeon draws outlines of the target and important anatomical details on the patient's head. Although in this experiment, the volunteer is wearing a bathing cap, in an actual operation the patient's head is shaved. <ref type="figure">Figure 3e</ref> uses luminance keying to substitute the computer generated image wherever the luminance exceeds a threshold value. The final surgical plan is shown in <ref type="figure">Figure 3f</ref> with the target drawn as a cross hatched circle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>The surgical planning system described above combined with off-the-shelf video equipment comprises an enhanced reality surgical support system. This section describes a recent surgical operation that used the system. The tumor was a frontal glioma. Reference [ 111 describes the diagnosis, treatment and biology of these infiltrative tumors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Acquisition</head><p>A GE Signa MRI system (GE Medical Systems, Milwaukee, WI) acquired 128 coronal slices, 256 by 256 pixels, 1.5 mm apart. A 24 cm field of view (FOV) produced .9375 mm pixels. The MRI pulse sequence was a spoiled gradient echo with 1 excitation (NEX), repetition I recovery time (TR) of 3500 ms and echo delay (TE) of 500 ms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Image Processing</head><p>The study was filtered to increase the signal to noise ratio using the algorithm (Brigham and Women's Hospital, Boston, MA) described in <ref type="bibr">[4]</ref>. <ref type="figure" target="#fig_6">Figure 4a</ref> shows a coronal slice through the center of the tumor. Coronal images are gathered perpendicular to the patient's nose. The patient's right hand side is on the left of the displayed image as is customary in medical images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Segmentation</head><p>The segmentation process identified the brain surface, cerebral spinal fluid, edema (fluid), tumor and the skin. A variation of the algorithm described in <ref type="bibr" target="#b1">[7]</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Model Construction</head><p>Dividing cubes points lists were generated for each segmented tissue. <ref type="figure">Figure 4c</ref> shows four separate objects viewed from the patient's right. The tumor is shown in green. The edema, shown in red, has been clipped part way through. The brain, in grey, has been clipped from above. A reformatted slice is painted in grey scale on a cut plane that passes midway through the tumor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">The Surgical Plan</head><p>The night before the operation, the points were displayed on a Sun Workstation (Sun Microsystems, Mountain View, CA) outfitted with a custom point rendering accelerator (GE Corporate Research and Development, Schenectady, NY). This board renders dividing cubes point lists at 10 million points per second. The video from the workstation was converted to NTSC composite video using a CVS-980 NTSC scan converter (YEM, Okada, Japan). This computer video signal was combined with the video from a VHS camera signal using a video mixer (Panasonic WJ-AVE5).</p><p>An operator manipulated the computer model of 'the face of the patient to align 'with the live video of the patient's head.</p><p>The surgeon viewed the combined signal on a TV monitor and traced the outline of the tumor to be treated on the pa-tient's shaved head. <ref type="figure" target="#fig_4">Figure 5a</ref> shows the mixed video signal. The face and brain surface are cut away along the viewing direction to expose the tumor. The doctor also sketched the location of the patient's motor strip. The strip was visible in the 3D computer model of the brain surface. By watching the combined signal on the TV monitor, the doctor moved his marking pen on the surface of the patient's head. <ref type="figure" target="#fig_4">Figure 5b</ref> shows the resulting surgical plan drawn on the patient's head.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">The Operation</head><p>The operation took place the next morning at Brigham and Women's Hospital, Boston. A cart containing a workstation, video mixer, scan converter and TVNCR was wheeled into the operating room. An ethernet connection in the operating room permitted connection to the hardware in the Surgical Planning Laboratory at the hospital. A video camera was positioned on a tripod behind and above the neuro-surgeon. Prior to draping the patient, we aligned the live patient video and computer generated surfaces. During the operation, an operator mixed the two video signals to show the relationship between the computer models and the patient. As the surgeon worked on the tumor, the mixed video signal gave the impression that the surgeon was cutting the com-    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>411</head><label></label><figDesc>quired images with noise reduction and edge sharpening filters[4].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Video Registration. one world-based camera coordinate system. A single composite matrix is built using matrix concatenation. Camera attributes include look from, look at, view up and orientation. Object Attributes: Each object has attributes that affect its appearance, orientation, scale, position and clipping. Appearance attributes include: color, visibility, backsugace shading and transparency. Three angles, azimuth, elevation and roll specify the orientation of an object. These orientations take place about an origin. . A position specifies the location of the object in the world (or camera) space. A scale factor permits stretching and shrinking about the origin. Clipping attributes include orthogonal object-space clipping and front / back clipping along the view direction. Slice acquisition attributes specify the order the slices were obtained by the scanner. These important coordinate permutations must be included to insure proper left-right relationships.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>used training points provided by the operator to produce the segmented image shown in figure 4b (Research Workstation, GE Medical Systems, Milwaukee, WI). a. Alignment Left to Right c. Computer Generated Models b. Alignment Top to Bottom d. Computer Generated + Video e. Luminance Keyed Video f. Live Video a. MRI Acquisition b. MRI Segmentation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure</head><label></label><figDesc>Figure 4. Surgical Planning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Display Prior to Operation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>(Figure 6 .</head><label>6</label><figDesc>See color plates, p. CP-46.) a. Computer Generated b. Computer Generated + Video Display During Operation puter generated models. Figure 6a shows the computer gen-[3] Hinshaw, W. S. and Lent, A. H., "An Introduction to erated images viewed from the video camera position. Fig-NMR Imaging: From the Bloch Equation to the Imagure 6b shows a mixed image of the computer images and pa-ing Equation," Proc. of the IEEE, vol. 71, no. 3, pp. 338-350, March 1983. tient video. The surgeons' hands and tools are visible in the composite image.[4] Gerig, G., Kubler, O.,Kikinis, R., and Jolesz, F. A., "Nonlinear Anisotropic Filtering of MRI Data," ZEEE Trans. on Medical Imaging, vol. 11, no. 2, pp. 221-232, 4. Future Work Several operations have been performed with the enhanced June 1992. reality system. The greatest is the registration Of [5] Cline, H. E., Dumoulin, C. L,, Lorensen, W. E., Hart, the live video with the computer generated models. Manual H. R., and Ludke, S., "3D Reconstruction of the Brain registration is quite easy if there are distinguishable features from Magnetic Resonance Images Using a Connecwithin the surgical field. But, if the patient is facedown, or tivity Algorithm,'' Magnetic Resonance Imaging, vol. the area of the operation lacks feature (like the back) the 5, no. 5, pp. 345-352, 1987. system requires more robust and automatic registration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4a :</head><label>4a</label><figDesc>Magnetic resonance image, Figure 4c: 3D models of the brain and tumor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5a :</head><label>5a</label><figDesc>Planning: Computer model and video.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6a :</head><label>6a</label><figDesc>Surgery: Computer model Figure 5b: Planning: Video of patientFigure 6b: Computer model and video CP-46</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Thresholding is the simplest segmentation approach, providing a binary classification of tissues. Each volume element (voxel) is classified as being in tissuq if its intensity lies with a range of intensities. The collection of all the voxels that lie within this range are considered part of the same tissue. Thresholding is often used to identify bone in CT because of the good contrast between bone and everything else. But in MRI, various soft tissues often overlap in intensity and other segmentation techniques are required.</figDesc><table /><note>Connectivity can be used to distinguish between two tissues that have the same contrast but are spatially separated [51.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Marching cubes generates triangles that approximate the isodensity surface of a tissue within a volume. Dividing cubes generates 3D points with surface normals that approximate the surface. Typical medical applications have high resolution and marching cubes generates large numbers of triangles. For example, in a typical 256 x</figDesc><table><row><cell>and di-</cell></row><row><cell>viding cubes [9]. 256</cell></row></table><note>x 128 MRI study of the brain, marching cubes can gen- erate over a million triangles to model the brain surface. In- teractive display rates are difficult to achieve on such large models. On the other hand, the compact point / normal list produced by dividing cubes, lends itself to fast software ren- dering and even faster custom hardware implementation. Currently, we use dividing cubes for medical applications.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multispectral Analysis of Magnetic Resonance requires some hand-editing. This lengthens the segmenta-Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Vannier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Bunerfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="page" from="221" to="224" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
	<note>Also, the tissue segmentation, although almost automatic. tion time. Finally, presentation of the mixed video could</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Three-Dimensional Segmentation of MR Images Further experiments are required to assess the benefits of of the Head Using Probability and Connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jolesz ; F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Assisted Tomography</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1037" to="1045" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
	<note>Jourthe additional complexity introduced by the display hardnul of</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Marching Cubes: A 5. Conclusions High Resolution 3D Surface Construction Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987-07" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="163" to="169" />
		</imprint>
	</monogr>
	<note>Computer graphics and image processing techniques pro-Computer Graphics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Two Algorithms for the Three plans into the operating room, providing additional in-Dimensional Construction of Tomograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>These</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Teeter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Success with our initial experi-Physics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="320" to="327" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
	<note>Medical formation for the surgeon. ments motivates us to refine the procedure</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Jolesz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorensen</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Use of Computerized Image Processing for Stereotactic Surgical System for the Removal of In-Neurosurgical Planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Kall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Goerss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Interactive</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Astrocytomas: Diagnosis, tracranial Tumors</title>
		<editor>P. McL. Black, W. c . neering</editor>
		<meeting><address><addrLine>Schoene, L. A. Lampson</addrLine></address></meeting>
		<imprint>
			<publisher>Blackwell Scien</publisher>
			<date type="published" when="1985" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="50" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ISBN 0-86542-217-6. view of Computerized Tomography with Emphasis on</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Garden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Schoene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lampson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of rhe IEEE</title>
		<meeting>of rhe IEEE<address><addrLine>Boston, MA; Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>well Scientific</publisher>
			<date type="published" when="1983-03-111" />
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>Astro-Future Developments. ISBN 0-86542-217-6. combined with live can bring the</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ludke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Crawford</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">46</biblScope>
		</imprint>
	</monogr>
	<note>See cdor plates</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
