<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Optimal Sets of Projections of High-Dimensional Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><forename type="middle">J</forename><surname>Lehmann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Theisel</surname></persName>
						</author>
						<title level="a" type="main">Optimal Sets of Projections of High-Dimensional Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2015.2467132</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multivariate Projections</term>
					<term>Star Coordinates</term>
					<term>Radial Visualization</term>
					<term>High-dimensional Data</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>To a large extent, Information Visualization deals with highdimensional datasets, i.e., data that can be described as point sets in a high-dimensional space. Finding appropriate projections into 2D (or 3D) is a standard problem in Information Visualization for which a variety of approaches have been proposed. Traditional data projection strategies often provide a complete tour through the space of all data projections, that quadratically or even exponentially grows with the dimensionality n of the data. Due to the large number of projections, such techniques tend to be exhausting for the user, even if n is rather small. Further approaches aim to reduce the number of dimensions, bearing the risk to overlook and lose important data patterns. Beyond that, no approach avoids the repetitive view on similar data patterns.</p><p>Finding good data projections is a non-trivial problem due to the following two reasons. Firstly, every projection discards information about the data while introducing distortions. Secondly, the space of all possible projections is large. To evaluate how useful a certain projection is, a variety of quality measures have been proposed. They describe the quality of a particular projection by a certain number.</p><p>In this paper, we propose a new approach to find relevant projections. Instead of evaluating the quality of a single projection, we introduce a simple measure of how much more insight is provided by a new projection if a number of other projections are already presented. Our main assumption here is that a new projection does not provide new insight if it can be obtained by a linear combination of optimal affine transformations of the already existing projections. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the concept: the two projections p 1 and p 2 of a high-dimensional point set are considered similar because p 2 can be obtained from p 1 by an affine map. Contrary, if p 1 is given, the new projection p 3 gives new insight because it cannot be obtained by an affine map from p 1 . In fact, p 3 shows that the data consists of (at least) two clusters which could not be seen in p 1 . Finally, if p 1 and p 3 are given, p 4 still gives additional information about the data because no linear combination of affine transformations of p 1 and p 3 can give p 4 .</p><p>The discarding of affine transformations for comparing projections is justified in the following observation: one of the most common research questions is to find patterns and clusters in the data. If a projection reveals e.g. two clusters, the same clusters are usually visible in an affine transformation of the projection. Moreover, if two clusters in the high-dimensional data space are projected to the same location in</p><p>• Dirk J. <ref type="bibr">Lehmann</ref>  2D (i.e. they cannot be distinguished in the projection), our approach prefers new projections that distinguish the two clusters. In detail, we make the following contributions:</p><p>• We introduce a mathematical formulation for a dissimilarity function of a new projection that encodes how much new insight the projection contributes in relation to a certain number of already present projections. Section 3 introduces the measure.</p><p>• Based on this, we apply our mathematical approach to propose a greedy approach to find a low number of projections describing the dataset completely. The main idea is to insert new projections with a maximal distance to the projections being already present. We use this to define short and complete data tours. See Section 4.</p><p>• We introduce a mathematical approach to interactively explore the data by smoothly changing the projections in such a way that either maximal new insight is gained by a small change of the projection, or that the result of the projection is kept as constant as possible while changing the projection parameters. See Section 5.</p><p>We discuss parameters of the approaches and test them on highdimensional benchmark datasets in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Related work stems from the area of multivariate projections, data tours, and quality metrics. Affine and Projective Projections: A family of multivariate embeddings have been introduced as RadViz <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b6">7]</ref> and Star Coordinates <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>. The approaches define a multivariate projection from nD data space to the 2D visualization space. They introduce additional distortion which lead to confusion during a visual search. Orthographic Projections: The multivariate Orthographic Star Coordinates <ref type="bibr" target="#b16">[17]</ref> generalize the concept of bivariate orthographic projections, such as scatterplots. They prevent distortions by maintaining a set of orthography-preserving constraints. However, the mentioned multivariate projections do not consider the data itself, even though the inherent structure of data needs to be considered for the selection of a good projection. We introduce a data-driven strategy for choosing a small set of optimal projections. Regarding this, the ProjInspector <ref type="bibr" target="#b19">[20]</ref> proposes an interactive exploration technique for a set of basic projections in order to find interesting combinations of them. Our approach does not require an interactive stage to find interesting projections. In addition, the set of projections our approach produces can be utilized as such basic projections, and thus our approach can be well combined with the ProjInspector. Distance-based Projection Techniques: The Multidimensional scaling (MDS) <ref type="bibr" target="#b26">[27]</ref> preserves distances between the data records under projection via the spectrum of a data-dependent centered distance matrix. PCA-based techniques also belong to this family of techniques. With Glimmer <ref type="bibr" target="#b12">[13]</ref>, a high-performance approach for multilevel MDS on graphic processing units is known. The large amount of distance information required to build up a projection can be reduced by partlinear multidimensional projection (PLMP) <ref type="bibr" target="#b20">[21]</ref> to a small number of pairwise distances between a number of representative data samples, which substantially increase performance of the projection process. Local affine multivariate projection (Lamp) <ref type="bibr" target="#b13">[14]</ref> provides a local data projection technique by minimizing the distances of the projected data points with the aid of (interactively) initialized seed or control points in the visualization space. Our approach does not optimize data-based distances to find a good projection. Instead, it optimizes a measure between different projections in order to discard affine transformations. In fact, it could be combined with distance-based projection techniques. Data Tours: A data tour is given by a set of (relevant) projections being a subset of the projection space, which can be investigated by the user for the purpose of visual data analysis. A time sequence of a set of projections is provided for conducting a visual data exploration. The projection pursuit <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b5">6]</ref> and the grand tour <ref type="bibr" target="#b2">[3]</ref> provide a greedy tour of (bivariate) projections, which exponentially grows with the number n of data dimensions. They allow to intuitively detect patterns of interest in the data, but they are time consuming, especially with growing n. Our concept provides a smart tour with a lower and optimal number of projections that is guaranteed to be free of redundancies, but still visits all important views of the data.</p><p>Quality Metrics: Their basic idea is to map a quality (correlation, cluster, trends) of a projection onto a real number. With this filtering tool, a set of good projections might be identified. For this, a collection of precomputed projections is rated and the worst ones are rejected. A set of metrics are available and established, such as <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b22">23]</ref>. We refer to <ref type="bibr" target="#b4">[5]</ref> for further details. Quality metrics are useful to find good projections but they have a computational overhead regarding the number of required projections. Clearly, the vast majority of precomputed projections will be rejected. We introduce an alternative concept that avoids the computational overhead of quality metrics.</p><p>In the following, we establish a dissimilarity measure for projections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A DISSIMILARITY MEASURE FOR PROJECTIONS</head><p>The n-dimensional dataset is given as m data points</p><formula xml:id="formula_0">d j = (d 1, j , ..., d n, j ) T for j = 1, ..., m, resulting in an n × m data matrix Data = (d 1 , ..., d m ).<label>(1)</label></formula><p>In this paper, we restrict ourselves to 2D Star Coordinates, i.e., linear projections that are defined by a 2 × n matrix A. Then the projection of a point d j is A • d j , and the matrix of all projected points is the 2 × m matrix A • Data. Note that A can be interpreted and visualized as the projection of the high-dimensional coordinate axes:</p><formula xml:id="formula_1">for A = (x 1 , ..., x n ), we have (x i − 0) = A • i i</formula><p>where 0 is the 2D origin and</p><formula xml:id="formula_2">i i = (0, ..., 0 i−1 , 1, 0, ..., 0 n−i )</formula><p>T is the i th coordinate axis for i = 1, ..., n.</p><p>The projection matrices A 1 , ..., A r define a number r of projections. To define the dissimilarity of a new 2×n projection matrix B to A 1 , ..., A r , we consider an affine transformation of each projection that is given by a 2 × 2 matrix Q i and a translation vector r i . We define</p><formula xml:id="formula_3">E = B • Data − 1 r r ∑ i=1 ( Q i • A i • Data + (r i , ..., r i m ) )<label>(2)</label></formula><p>and search for the Q i and r i that minimize the Frobenius norm of E. This gives the dissimilarity of B to A 1 , ..., A r : Given Data, A 1 , ..., A r and B, (3) is a quadratic minimization problem with the unknowns Q i , r i . To formulate its closed-form solution, we consider the problem in homogenous coordinates:</p><formula xml:id="formula_4">d(B, A 1 , ..., A r ) = 1 m min Q 1 ,...,Q r ,r 1 ,...,r r E 2 Fr .<label>(3)</label></formula><formula xml:id="formula_5">Data = d 1 ... d m 1 ... 1 , A =     A 1 0 . . . . . . A r 0 0...0 1     , B = B 0 0...0 1</formula><p>where Data is the homogeneous data matrix, A is a (2r + 1) × (n + 1) matrix of all known projection matrices A i , and B is the new projection matrix in homogenous coordinates. From this we compute a solution of this minimization problem as</p><formula xml:id="formula_6">D = Data • Data T (4) H = I − D• A T • A• D• A T −1 • A • Data (5)</formula><p>where I is the (n + 1) × (n + 1) unit matrix and H is an (n + 1) × m matrix with a vanishing last row. Note that A• D• A T is a symmetric quadratic (2r +1)×(2r +1) matrix, depending on r. Since r &lt; n &lt;&lt; m usually applies, the calculation of the inverse performs well and is only weakly affected by the curse of dimensionality. Further we get</p><formula xml:id="formula_7">E = B • H (6)</formula><p>where E is a 3 × m matrix with a zero third row. E is the homogenous version of (2) with optimal Q i , r i , i.e.,</p><formula xml:id="formula_8">d(B, A 1 , ..., A r ) = 1 m E 2 Fr .<label>(7)</label></formula><p>The proof of (7) is provided in Appendix 1. The behavior of d under scaling of the projection matrices is given by</p><formula xml:id="formula_9">d(β B, α 1 A 1 , ..., α r A r ) = β d(B, A 1 , ..., A r )<label>(8)</label></formula><p>for any real β and real non-zero α i . The α i have no influence because of the discarding of affine transformations, the linear behavior in β is due to the fact that d essentially adds up Euclidean distances of the projected points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GRADIENT ASCENT FOR OPTIMAL PROJECTIONS</head><p>Based on the dissimilarity measure for projections, we present an algorithm to find a finite (low) number of projections that represent the high-dimensional data best. The main idea is to find projections that have a large dissimilarity to each other. We propose a greedy algorithm: starting with a projection A 0 , we repeatedly find new projections A 1 , A 2 , ... until a new projection does not give new insight into the data. Given A 0 , ..., A i , we search for A i+1 such that it has maximal dissimilarity to A 0 , ..., A i . For this, we apply a gradient ascent of d:</p><formula xml:id="formula_10">B 0 = A i (9) B j+1 = orth( B j + λ ∇ B d(B, A 1 , ...A i ) ) and stop if B j+1 − B j 2</formula><p>Fr &lt; ρ. The convergence parameter ρ, as a numerical parameter, steers the smallest dissimilarity that has to be reached to stop the algorithm. It influences the performance of the ascent and the final number of projections. See Sec. 6.4 for details. Then A i+1 = B j+1 . The whole algorithm stops if A 0 , ..., A i are complete, i.e., for any new projection B we have d(B, A 0 , ..., A i ) = 0. In <ref type="formula">9</ref>, the function orth() computes a matrix orth(A), by applying a Gram-Schmidt orthonormalization to the row vectors of A, which guarantees an orthographic projection of the data to the visualization space <ref type="bibr" target="#b16">[17]</ref>. Due to the scaling behavior of d described in <ref type="bibr" target="#b7">(8)</ref>, it is required to restrict the length of row vectors in B j+1 to one, which is done by this orthonormalization. (6), <ref type="bibr" target="#b6">(7)</ref> give that gradient ∇ B d of d in the variables B can be computed as</p><formula xml:id="formula_11">∇ B d(B, A 1 , ..., A r ) = 2 m B • H • H T<label>(10)</label></formula><p>being a 3 × (n + 1) matrix where both the last row and the last column are zero. Our algorithm has the following parameters: the start projection A 0 , the step size λ for the gradient ascent, and the convergence parameter ρ. While choosing λ = 1, the other parameters are discussed in Section 6.4 and 6.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">INTERACTION CONCEPTS</head><p>We describe an approach for an interactive analysis of a dataset by smoothly changing the projection matrix A. This means that we consider a time-varying projection matrix A(t) where we use our dissimilarity measure to compute its path from an initial projection A(t 0 ) and some user input. For this, we propose two strategies: maximal deformation or minimal deformation of the projection. For maximal deformation, the path should consist of a sequence of projections that are maximally distant to their neighbors. In other words: for maximal deformation, the projection A(t) • Data should have maximal changes under minimal changes of A(t). Contrary, for minimal deformation, the projection A(t) • Data should have minimal changes under maximal changes of A(t). This strategy aims to provide information on which coordinate axes are dependent on each other. For both strategies, we apply an Euler integration of A(t):</p><formula xml:id="formula_12">A(t i+1 ) = A(t i ) + (t i+1 − t i )Ȧ(t i )<label>(11)</label></formula><p>where the time derivativeȦ of A is unknown. For the strategy of maximal deformation,Ȧ(t i ) is chosen to maximize d(A(t i+1 ), A(t i )) for (t i+1 −t i ) → 0. This is an eigenproblem: setting r = 1, we consider the eigenvector e n+1 corresponding to the largest eigenvalue of H • H T . Note that e n+1 forms both the first and second optimal row of the projection matrix A. Since e n+1 is an eigenvector, its length is undefined, gives us two degrees of freedom α, β for scaling e n+1 in each row of A. This gives:</p><formula xml:id="formula_13">A = (α e n+1 , β e n+1 , 0 n+1 ) T (12)</formula><p>where 0 n+1 is the (n + 1)-dimensional zero vector. Then α, β are subject of user interaction: the user can draw the 2D path of the projection of a coordinate axis x i (t) of A(t) from which we get is tangentẋ i (t).</p><p>This gives the parameters α, β byẋ i = (e n+1 ).i α β where (e n+1 ).i is the i th component of e n+1 . For the strategy of minimal deformation, we consider the thirdsmallest eigenvector e 3 of H • H T . Note that H • H T has at least two vanishing eigenvalues, reflecting the discarding of the affine transformations of the projections. Then we geṫ</p><formula xml:id="formula_14">A = (α e 3 , β e 3 , 0 3 ) T<label>(13)</label></formula><p>with a similar treatment of α, β as above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>As proof of concept, we present a set of approach-related experiments.</p><p>Our experiments run on a mobile workstation with a 2.4 GHz 64 Bit Intel CPU with 8 cores, 12 GB RAM, and WIN 7 OS in single-core and single-thread mode. We introduce the used benchmark data in Sec. 6.1, we illustrate the interaction tool in Sec. 6.2 and the optimal set of projections in Sec. 6.3, which are compared with the commonly used PCA-based approach for visual data exploration. In Sec. 6.4, we investigate the stability of the gradient ascent regarding the influence of convergence parameter ρ and, in Sec. 6.5, regarding the initial projection A 0 (cf. Sec. 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The High-Dimensional Test Datasets</head><p>Five high-dimensional test datasets are used from the UCI data base <ref type="bibr" target="#b3">[4]</ref>: Iris <ref type="bibr" target="#b8">[9]</ref>, Yeast <ref type="bibr" target="#b17">[18]</ref>, Wine <ref type="bibr" target="#b9">[10]</ref>, Wdbc <ref type="bibr" target="#b24">[25]</ref>, and Cars <ref type="bibr" target="#b3">[4]</ref>. In detail, the Fisher's Iris plants data base consist of 5 dimensions with 150 records. It gives measurements of the sepal as well as the petal length and width for three iris species. An amount of protein localization sites is given in the Yeast dataset, with 10 dimensions and 1484 records. It is usually used to develop probabilistic classifications systems in order to predict properties of proteins. The Wine data consist of 14 dimensions with 178 records. It stems from a chemical analysis of three cultivars of wine which have grown in the same Italian region. Thus, wine-specific characteristics are summarized, such as the level of alcohol, the amount of phenols, or the color intensity. The Wisconsin Diagnostic Breast Cancer aka Wdbc consists of 569 records with 32 quantitative dimensions each. It contains a set of attributes of cell nucleus measurements that are obtained from breast cancer patients. It turned out that a linear separation by a 2D classifier based on the attributes area, texture, and smoothness allows to diagnose benign and malignant cancer cells. The Cars data base contains 33 dimensions and 7755 records. A broad parameter set for different car models is provided, which encompasses attributes, such as the number of cylinders, the maximum velocity, or the power of a car.</p><p>Note that a potential a priori classification within the data is not within the focus of our approach or even required. Thus such cases are treated as usual dimensions. Furthermore, to guarantee a fair comparison between outcomes, to avoid numerical influence, and to reduce scaling effects, we linearly normalized the data within the interval [0, 1]. Since affine transformations are removed, the normalization does not negatively affect the quality of the optimal set of projections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Path-based Interaction</head><p>We illustrate the interaction concept of Sec. 5. <ref type="figure" target="#fig_2">Figure 3</ref> presents a representative coordinate axis interaction for the Wine <ref type="figure" target="#fig_2">(Figure 3 (top)</ref>) and Yeast dataset <ref type="figure" target="#fig_2">(Figure 3</ref> (bottom)): A coordinate axis is moved along a (green colored) path to yield time-varying projections A(t), shown by <ref type="figure" target="#fig_2">Figure 3 (middle)</ref>. We present the projections A(t)• Data at time-points t i , i = 1,...,4 for both the minimal deformation <ref type="figure" target="#fig_2">(Figure 3 (left)</ref>) and maximal deformation case <ref type="figure" target="#fig_2">(Figure 3 (right)</ref>). It can be seen that the maximal deformation projections are different to each other, reflecting the maximization of the dissimilarity measure during the interaction. In contrast to that, the minimal deformation projections produce similarly shaped outcomes and are similar to the initial projection. To preserve minimal or cause maximal dissimilarity between projections might lead to fluctuations of eigenvectors (cf. Sec. 5), even though the function of eigenvalues itself is smooth over the interaction. This effect is caused by data characteristics and might lead to jitter of A(t). Thus, it provides additional structural data insight. In the following, we construct optimal sets of projections of the test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Optimal Set of Projections for Test Data</head><p>The gradient ascent of Sec. 4 is applied to the test data. For this, the question of an appropriate initial projection arises: An established initial standard configuration A π of a multivariate projection is the radial layout <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b14">15]</ref>, given by</p><formula xml:id="formula_15">A π = x 0 ,...,x n−1 y 0 ,...,y n−1 with (x i , y i ) T = b• (sin(i• α), cos(i• α)) T</formula><p>and i = 0,...,n − 1 whereas α = 2•π n and b = 2/n. Following <ref type="bibr" target="#b16">[17]</ref>, a construction scheme of an orthonormalization (cf. Sec. 4) is given by using a radius b = 2/n, meaning that A π becomes an orthographic projection. It is an appropriate candidate for the initial projection A 0 of our gradient descent. Thus, our approach defines A 0 = A π as the initial projection for the gradient ascent with the convergence parameter ρ = 0.1.</p><p>The <ref type="figure" target="#fig_4">Figures 4 and 5</ref> illustrate the optimal set of projections produced by our approach (top) in comparison to the same number of best PCA-based projections (bottom), w.r.t. our benchmark datasets (cf. Sec 6.1). PCA is given by the eigenvectors e i , i = 1,...,n of the data's covariance matrix, which minimizes correlation and maximizes variance. Pairwise eigenvectors define a 2 × n projection A i j = e i/ j = (e i , e j ) T . Note that the complete number of PCA projections grows quadratically in the dimension number n, while the number of our set of optimal projections grows linear in n. For instance, the Wine dataset with n = 14 dimensions has a total number of 91 PCA-based projections (which can be found in the supplemental material), while our optimal set only requires 7 projections. However, in order to provide a fair comparison that reflects the use of PCA in practice, a subset of the largest pairwise eigenvalues is presented for each case, which has the same number of projections as our optimal set.</p><p>For our optimal sets in the figures, the annotated dissimilarity label d of a projection A i describes the dissimilarity to the subset of predecessor projections {A o ,...,A i−1 } referring to (7) as d <ref type="figure">(B, A o ,.</ref>..,A i−1 ) = d(A i ) with B = A i . Consequently, we treat the PCA projections similarly: the dissimilarity label d of a PCA projection e i/ j also describes the dissimilarity to the subset of predecessor PCA-based projections. This comparison setup facilitates an empirical comparison of the dissimilarity behavior for both techniques. Keep in mind that a larger dissimilarity means that more data insight is given with a certain projection. Finally, the dissimilarity behavior is summarized by a graph at the end of each projection sequence for each dataset and projection technique.</p><p>For our optimal sets, it can be seen that the dissimilarity rapidly decreases with growing index i, i.e., d(</p><formula xml:id="formula_16">A i ) &gt; d(A i+1 ) with i ≥ 1,...r −1.</formula><p>This appears to be plausible, since the degree of freedom to find a projection that cannot be generated as affine transformation gets small if a sufficient number of projections is available. In fact, only the first two, three or occasionally four projections of the optimal projection set show relevant data patterns. Clearly, stopping the ascent in early stages would still lead to projections showing the most important patterns. Beyond that, our experiments illustrate that the number r of projections is optimal with r ≤ n 2 . In comparison to that, each new PCA-based projection only provides little additional insight compared to the first PCA projection e 1/2 for each case: The dissimilarity values are much smaller and almost negligible compared to those of our optimal set of projections. On the other hand, relevant patterns that are shown by the PCA-based projections can also be seen in the set of optimal projections. Thus, our experiments empirically illustrate the advantages of our optimal set of projections compared to PCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Influence of Convergence Parameter</head><p>The convergence parameter ρ influences both the dissimilarity between successively selected projections during the gradient ascent and the algorithm's performance and convergence behavior. In fact, a too large value of parameter ρ would cause projections that have a small dissimilarity to each other. Thus, the parameter should be rather small in order to facilitate projections that have a large dissimilarity and thus provide new data insights. On the other hand, if ρ is chosen too small, then the algorithm's performance decreases. In order to find a good choice of the convergence parameter ρ, we investigate the algorithm's behavior for a set of small values, such as ρ = 0.1, ρ = 0.01, and ρ = 0.001 (with A 0 = A π ). <ref type="figure" target="#fig_6">Figure 6</ref> illustrates the results. Intra Set Differences: <ref type="figure" target="#fig_6">Figure 6</ref> (left) shows column-wise the intra set differences d(A i ) of the projections A i , i = 1,...,r for each value of ρ and row-wise for the test data. It can be seen that the patterns are comparable and only weakly dependent on ρ. Furthermore, the calculation time grows approximately logarithmically in ρ.</p><p>Inter Set Differences: We are interested in a comparison of the projections with the same index i but different values in ρ: Be A ρ = {A 0 ,...,A r } the set of projections w.r.t. ρ, and be A ρ (i) = A i a projection of it, then we define the inter set difference  </p><formula xml:id="formula_17">d(i, ρ k , ρ l ) = d(A ρ k (i), A ρ l (i))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Influence of Initial Projection</head><p>In this section, we investigate the influence of the initial projection A 0 . For this, we conduct the gradient ascent with noisy versions of the initial projection A 0 = A π : be R l a 2× n matrix with randomly chosen column vectors that have a p2-norm of l each, then a noisy version A π l is given by A π l = A π + R l . The larger l the noisier A π becomes. We did 100 runs of the ascent for each value l = 0.2, 0.4,...,1.2 and being started with A π l .    <ref type="figure" target="#fig_10">Figure 7</ref> illustrates the results. It can be seen that the mean inter set dissimilarity d µ (A i , l) is stable: an unstable behavior could be recognized by an exponential growth in d µ (A i , l). However, this is not what we observe. Instead, we observe a converging behavior against similar projections even though the initial projection becomes diffuse. <ref type="figure" target="#fig_11">Figure 8</ref> (a) illustrates this ability in detail for randomly chosen runs of the Wine dataset for different l: the first five projections of the optimal set can be seen each. Especially the different projections A 1 stably show the main pattern in that data, which is shaped like a rotated version of the letter 'u', independently to the start projection A 0 .</p><p>We are also interested in the behavior if the initial projection is randomly chosen, for instance by a user-based interaction. Regarding this, <ref type="figure" target="#fig_11">Figure 8</ref> (b) row-wise illustrates the first five projections of the optimal set with respect to three randomly chosen inital projections A 0 of the Wine data. Interestingly, prominent data patterns, such as the 'u' pattern in A 1 , are still visited in each case. In fact, our experiments show that relevant data patterns are found independently of the chosen start projection A 0 (please find further examples in the supplemental material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION AND LIMITATIONS</head><p>Improvements, advantages, and limitations of our approach will be discussed in this section.</p><p>Why discarding affine transformations?: In Information Visualization, depending on the application and the dataset, different goals of a visual analysis are possible. Among them there are universal goals that are relevant to all applications: the segmentation of the data points into meaningful clusters. While there is a large amount of cluster definitions for an automatic clustering, visual clustering <ref type="bibr" target="#b28">[29]</ref> has been established as an interesting alternative, i.e., an interactive process where the user manually marks the clusters in appropriate projections. This has the advantage that no prior knowledge about shape or properties of the clusters are necessary. We argue that for a visual clustering, affine transformations of the projections are of less relevance: regions that are clearly visually distinguishable remain distinguishable after an affine transformation. Please note that the human perception system is not rotationally invariant, and thus the setup for the presentation of projections influences the users' capability to recognize important structures. Nevertheless, it is paramount to have such a set of projections available that mutually bear the most structural information regarding the data, which is the focus of this work. Then, to ask for a well designed presentation in order to show the set of projections to the user is not within this paper's focus.</p><p>Relation to quality metrics: Quality metrics measure the quality of a single projection. In contrast, our approach measures the quality of a projection relative to a number of already present projections. In this sense, our approach is orthogonal to existing quality metrics. In fact, they can be used as starting point of our approach.</p><p>Dependence on the starting projection: Our approach is parametrized by a start projection A 0 (cf. Sec. 6.5). Even though the choice of this projection influences the set of optimal projections, the relevant data patterns, or variations, stably remain visible. Hence, the final result regarding a visual search is less dependent on A 0 .</p><p>Completeness of sets of projections: Given a dataset with rank(D) = n + 1, the space of all Star Coordinates under discarding of affine transformations is completely described by n b = abs( n 2 ) linear independent projections: we can find n b linear independent projections A 1 , ..., A n b with d <ref type="figure" target="#fig_0">(A j , A 1 , ..., A j−1 , A j+1 , .</ref>.., A n b ) &gt; 0 for j = 1, ..., n b , and d <ref type="figure" target="#fig_0">(B, A 1 , .</ref>.., A n b ) = 0 for any projection matrix B. The value of n/2 intended projections can be explained as follows: the space of all projections is 2n-dimensional, since a projection matrix A i consist of 2n independent entries. By discarding affine transformations, each ..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>23</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>35</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>31</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>29</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>22</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>33</head><p>... ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1272</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1308</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1052</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1480</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1319</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1493</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1248</head><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1497</head><p>...  projection matrix A i loses 4 degrees of freedom. A matrix A i with all its affine transformations forms a 4-dimensional subspace of the space of all transformation matrices. Hence, n/2 projection matrices with its affine transformations are enough to cover the transformation space.</p><p>Relation to MDS and PCA: MDS usually provides one as distance-preserving as possible projection, from nD to 2D space. Applying an affine transformation on a MDS M, such as rotation and scaling, yield an equivalent or identical MDS configuration. Following (7), two MDS configurations M i and M j are identical, i.e. they convey the same information, if d(M i , M j ) = 0, meaning they can be mapped to each other by affine transformations. In addition, PCA provides a set of partly relevant projections. It contains relevant projections but also a number of them that lead to visual noise. See an example of this behavior for the Wine dataset in the supplemental material. The ratio of relevant projections is higher with our approach, meaning that our set is less repetitive, making a user-based visual search more feasible. This is reflected by the fact that the number of projections grows quadratically in n for PCA, for our optimal set it grows linearly in n. Moreover, PCA requires Gaussian-distributed data to perform optimally, otherwise relevant data patterns might be undetectable. Our approach does not have such a requirement. Lastly, PCA performs differently if different data normalization approaches are used. Since affine transformations do not affect the result of our approach, our optimal sets behave more stably regarding data normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We provided a novel approach to measure the dissimilarity of multivariate projections disregarding affine transformations. It is based on the idea that a new projection in a tour should have a large dissimilarity to all projections that were already presented, in order to ensure the presentation of new data insights. Based on this measure, a small set of optimal projections is automatically selected by our approach. It makes a projection-based visual search more feasible for a user, since the number of projections is restricted to n/2. For the future, we are interested in the investigation of further measures that can be applied to a number of projections. For instance, to automatically detect a number of prominent projections which optimally describe the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX 1:</head><p>Proof that (4)-(7) is the solution of the minimization problem (3): Defining Q i = Q i r i 0 0 1 for i = 1, ..., r, we can write (2) in homogeneous coordinates</p><formula xml:id="formula_18">E = B • Data − 1 r r ∑ i=1 Q i • A i • Data.<label>(14)</label></formula><p>Note that E in (2) and E in <ref type="bibr" target="#b13">(14)</ref> are identical except for an additional zero row in E. Introducing the 3 × (2r + 1) matrix of all unknown affine transformation parameters</p><formula xml:id="formula_19">X = Q 1 ... Q r r 1 + ... + r r 0 0 ... 0 0 r ,<label>(15)</label></formula><p>(14) can be written as</p><formula xml:id="formula_20">E = B • Data − 1 r X • A • Data.<label>(16)</label></formula><p>Then the condition for X to minimize E 2 Fr is</p><formula xml:id="formula_21">B • Data • (A • Data) T = 1 r X • A • Data • (A • Data) T<label>(17)</label></formula><p>which can be solved to</p><formula xml:id="formula_22">X = r B • D • A T • (A • D • A T ) −1 .<label>(18)</label></formula><p>Inserting this into <ref type="bibr" target="#b15">(16)</ref> gives (6) with (4) and (5). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Four projections of a real high-dimensional benchmark dataset: p 1 and p 2 are similar; p 1 and p 3 are different; p 4 gives new information if p 1 and p 3 are known.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 Fig. 2 .</head><label>22</label><figDesc>illustrates the dissimilarity function for n = 3, m = 65, r = 1. Dissimilarity function for n = 3, m = 65, r = 1; a) n-dimensional dataset Data; b) projection by A 1 ; c) projection by B; d) best affine transformation of projection A 1 ; e) distance of B, A 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Minimal (left) and maximal (right) deformation of data patterns during identical interaction in the Wine (top) and Yeast (bottom) dataset along an interaction path (green).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>as the dissimilarity between projections with the same index in different sets that are based on different values of ρ.Figure 6(right) shows the inter set differences d(i, ρ k , ρ l ) with i = 1,...,r. The differences behave quite stable and they are just weakly dependent on the accuracy of ρ.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Optimal set of projections compared to a subset of projections of the PCA tour for the test data Iris (top) and Wine (bottom): For each successor projection, the dissimilarity d is labeled with respect to the amount of all predecessor projections of the same sequence, which is graphically summarized at the end of each sequence.Intra vs. Inter Set Differences: Be d Intra the maximal intra set difference and be d Inter the maximal inter set difference, then we get the pairs (d Intra , d Inter ) for Iris as (12.5, 0), for Wine as (45, 2.3), for Wdbc as (338, 12.5), and for Cars as (2079, 243). It follows that the observed inter set differences that are caused by a coarser accuracy of ρ are rather small and negligible compared to the dominant intra set differences. Finally our experiments shows that a convenient choice of convergence parameter is ρ = 0.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Optimal set of projections compared to a subset of projections of the PCA tour for the test data Wdbc (top) and Cars (bottom): For each successor projection, the dissimilarity d is labeled with respect to the amount of all predecessor projections of the same sequence, which is graphically summarized at the end of each sequence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Influence of the convergence parameter ρ for the parametrization ρ = 0.1, ρ = 0.01, and ρ = 0.001 on the behavior of the dissimilarity d corresponding to the resulting optimal set of projections: (left) Intra Set and (right) Inter Set Differences for the test data. Be d(A i , l) the dissimilarity to the subset of predecessor projections {A π l , A 1 ,...,A i−1 } for such a set of projections that results if the ascent starts with A π l . We define the inter set dissimilarity d(A i , l, 0) = |d(A i , l) − d(A i , 0)| of projection A i to the projections with the same index i that result by starting the ascent at A π . For a projection A i over all runs j = 1,...,100 with the same l, we stored its mean inter set dissimilarity d µ (A i , l) = 1 100 ∑ 100 j=1 d j (A i , l, 0) as well as the maximum/minimum dissimilarity d min (A i , l, 0)/ d max (A i , l, 0).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>Influence of varying the start projection A 0 on the dissimilarity corresponding to the resulting optimal set of projections, which is statistically measured by the mean inter set dissimilarity d µ and the maximum/minimum dissimilarity d min /d max for the test data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8 .</head><label>8</label><figDesc>Case study: (a) Influence of noise to the initial radial configuration and the resulting set of optimal projections for the wine data.(b) Random walk for the Wine dataset: the inital projections A 0 are randomly chosen.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, University of Magdeburg, E-mail: dirk@isg.cs.uni-magdeburg.de. • Holger Theisel, University of Magdeburg, E-mail: theisel@ovgu.de Manuscript received 31 Mar. 2015; accepted 1 Aug. 2015; date of publication xx Aug. 2015; date of current version 25 Oct. 2015. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 points</head><label>1</label><figDesc>the data characteristics.</figDesc><table><row><cell>Dataset</cell><cell>Dimensions</cell><cell>Records</cell><cell>Classes</cell></row><row><cell>Iris</cell><cell>5</cell><cell>150</cell><cell>3</cell></row><row><cell>Yeast</cell><cell>10</cell><cell>1484</cell><cell>10</cell></row><row><cell>Wine</cell><cell>14</cell><cell>178</cell><cell>3</cell></row><row><cell>Wdbc</cell><cell>32</cell><cell>569</cell><cell>2</cell></row><row><cell>Cars</cell><cell>33</cell><cell>7755</cell><cell>52</cell></row></table><note>Table 1. Characteristics of the benchmark test datasets.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improving the Visual Analysis of High-dimensional Datasets Using Quality Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Symposium on Visual Analytics Science and Technology</meeting>
		<imprint>
			<publisher>IEEE VAST</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Perception-based Visual Quality Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Magnor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Symposium on Visual Analytics Science and Technology</meeting>
		<imprint>
			<publisher>IEEE VAST</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="13" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Grand Tour: a Tool for Viewing Multidimensional Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Asimov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Scientific and Statistical Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="128" to="143" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">UCI Machine Learning Repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asuncion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2203" to="2212" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Grand Tour and Projection Pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cabreta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Statistical Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="155" to="172" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Properties of normalized radial visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Glidden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Information Visualization</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="273" to="300" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Analyzing the Role of Dimension Arrangement for Data Visualization in RadViz</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Di</forename><surname>Caro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Frias-Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frias-Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining -Volume Part II, PAKDD&apos;10</title>
		<meeting>the 14th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining -Volume Part II, PAKDD&apos;10<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The use of Multiple Measurements in Taxonomic Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Eugenics</title>
		<imprint>
			<biblScope unit="page" from="179" to="188" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">PARVUS -An Extendible Package for Data Exploration, Classification and Correlation., Institute of Pharmaceutical and Food Analysis and Technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Forina</surname></persName>
		</author>
		<imprint>
			<pubPlace>Genoa, Italy</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Projection Pursuit Algorithm for Exploratory Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="881" to="890" />
			<date type="published" when="1974-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DNA Visual and Analytic Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Conference on Visualization</title>
		<meeting>the 8th Conference on Visualization<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="437" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Glimmer: Multilevel MDS on the GPU</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Olano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="261" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Local Affine Multidimensional Projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Joia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Coimbra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Cuminato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Nonato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2563" to="2571" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Star Coordinates: A Multi-Dimensional Visualization Technique with Uniform Treatment of Dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kandogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Information Visualization Symposium</title>
		<meeting>the IEEE Information Visualization Symposium</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visualizing Multi-Dimensional Clusters, Trends, and Outliers Using Star Coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kandogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Orthographic Star Coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2615" to="2624" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Expert System for Predicting Protein Localization Sites in Gram-Negative Bacteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kanehisa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proteins: Structure, Function and Genetics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="110" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multidimensional Clusters in RadViz</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nováková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Štepánková</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th WSEAS International Conference on Simulation, Modelling and Optimization</title>
		<meeting>the 6th WSEAS International Conference on Simulation, Modelling and Optimization<address><addrLine>Stevens Point, Wisconsin, USA</addrLine></address></meeting>
		<imprint>
			<publisher>WSEAS</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="470" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Projection Inspector: Assessment and Synthesis of Multidimensional Projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pagliosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Minghim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Levkowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Nonato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="599" to="610" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Part B</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Two-Phase Mapping for Projecting Massive Data Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Nonato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1281" to="1290" />
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<title level="m">Pixnostics: Towards Measuring the Value of Visualization. Symposium On Visual Analytics Science And Technology</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Guided Sketching for Visual Search and Exploration in Large Scatter Plot Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Landesberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bremm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVA International Workshop on Visual Analytics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Selecting Good Views of High-dimensional Data using Class Consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proc. EuroVis</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="831" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nuclear Feature Extraction for Breast Tumor Diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Street</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wolberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mangasarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE International Symposium on Electronic Imaging: Science and Technology</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automated Analytical Methods to Support Visual Exploration of High-Dimensional Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="584" to="597" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multidimensional Scaling: I. Theory and Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Torgerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="401" to="419" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grossman</surname></persName>
		</author>
		<title level="m">Graph-Theoretic Scagnostics. IEEE Symposium on Information Visualization</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="157" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Visual Clustering in Parallel Coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="1047" to="1054" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
