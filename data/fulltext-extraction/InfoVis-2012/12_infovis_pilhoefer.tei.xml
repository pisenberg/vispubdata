<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Comparing Clusterings Using Bertin&apos;s Idea</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pilhöfer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gribov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antony</forename><surname>Unwin</surname></persName>
						</author>
						<title level="a" type="main">Comparing Clusterings Using Bertin&apos;s Idea</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Order optimization</term>
					<term>fluctuation diagrams</term>
					<term>classification</term>
					<term>seriation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Classifying a set of objects into clusters can be done in numerous ways, producing different results. They can be visually compared using contingency tables [27], mosaicplots [13], fluctuation diagrams [15], tableplots [20] , (modified) parallel coordinates plots [28], Parallel Sets plots [18] or circos diagrams [19]. Unfortunately the interpretability of all these graphical displays decreases rapidly with the numbers of categories and clusterings. In his famous book A Semiology of Graphics [5] Bertin writes &quot;the discovery of an ordered concept appears as the ultimate point in logical simplification since it permits reducing to a single instant the assimilation of series which previously required many instants of study&quot;. Or in more everyday language, if you use good orderings you can see results immediately that with other orderings might take a lot of effort. This is also related to the idea of effect ordering [12], that data should be organised to reflect the effect you want to observe. This paper presents an efficient algorithm based on Bertin&apos;s idea and concepts related to Kendall&apos;s τ [17], which finds informative joint orders for two or more nominal classification variables. We also show how these orderings improve the various displays and how groups of corresponding categories can be detected using a top-down partitioning algorithm. Different clusterings based on data on the environmental performance of cars sold in Germany are used for illustration. All presented methods are available in the R package extracat which is used to compute the optimized orderings for the example dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Categorical data analysis involves analysing the frequencies of occurrence of the different possible combinations of variable values rather than analysing the individual values themselves. Combinations with high frequencies are evidence of associations between variables. Graphical displays can be helpful in revealing these associations, but they have to be informatively designed. Choosing category orderings is important. In his famous book A Semiology of Graphics <ref type="bibr" target="#b4">[5]</ref> Bertin writes "the discovery of an ordered concept appears as the ultimate point in logical simplification since it permits reducing to a singe instant the assimilation of series which previously required many instants of study". Or in more everyday language, if you use good orderings you can see results immediately that with other orderings might take a lot of effort.</p><p>The aim of this paper is to find informative joint orders for two or more nominal variables. This is related to the idea of effect ordering <ref type="bibr" target="#b11">[12]</ref>, that data should be organised to reflect the effect you want to observe. To be a little bit more concrete we regard an ordering to be good if it makes the identification of structural information and particularly of separable groups (clusters) easier and brings similar categories together.</p><p>To accomplish this a criterion based on concepts introduced by Bertin and Kendall <ref type="bibr" target="#b16">[17]</ref> is defined and efficient algorithms which optimise it are presented. An even more efficient variation of the algorithm which takes tree structures from hierarchical clusterings into account is also presented. The paper considers the optimisation of several different kinds of displays: contingency tables, mosaicplots <ref type="bibr" target="#b12">[13]</ref>, fluctuation diagrams <ref type="bibr" target="#b14">[15]</ref>, modified parallel coordinates plots (cpcp) <ref type="bibr" target="#b27">[28]</ref>, and circos diagrams <ref type="bibr" target="#b18">[19]</ref>. All these displays have in common that their interpretability decreases rapidly with the number of categories included.</p><p>An important application where comparing categorical variables arises is cluster analysis. Different clustering methods can sometimes lead to very different results. It is valuable to be able to compare clustering results and to assess the agreements (and disagreements) between them. The clusterings used in this paper are based on data from the German Automobile club, the ADAC <ref type="bibr" target="#b0">[1]</ref>, which publishes information on the environmental performance of cars sold in Germany. The dataset includes 1320 cars, rated by their CO 2 and pollutants emissions and will be referred to as the ecotest dataset. Five variables (horsepower, engine size, fuel consumption, CO 2 rating, pollutants rating) were chosen and standardised, and the cars were clustered using several well-known clustering algorithms including hierarchical clustering, model-based clustering and k-means clustering. The article is structured as follows: First we present an overview of existing work in this direction. We concentrate on three related approaches which are available in R. In Section 3 we describe and motivate the Bertin Classification Criterion as well as its scaled version, the Bertin Classification Index (BCI), which can be used as a measure of association between two or more variables. In Section 3.2 we descibe a weighted version of BCI and Section 3.3 deals with the dependence of the optimization algorithms on the initial category orders. The generalisation of the BCI to more than two dimensions is described in Section 3.4. We present the efficient algorithms which we used for the optimisations along with some information on their complexity in Section 4. These algorithms are even more efficient when used on hierarchical clustering data (see Section 4.2). Finally we mention a few details on the implementation of the techniques in the statistical software R <ref type="bibr" target="#b28">[29]</ref> in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Improving visualizations via rearrangements of the displayed objects is not a new idea and several approaches already exist. Bertin <ref type="bibr" target="#b4">[5]</ref> was among the first to propose reorderings of categories for the optimization of graphical displays.</p><p>One approach which directly addresses Bertin's idea for contingency tables was developed by Niermann <ref type="bibr" target="#b25">[26]</ref> who optimized the conciseness of a matrix using a stress measure which counts for each observation how many other observations are in its so-called Moore-Neighborhood meaning the eight directly neighboring matrix entries. The stress measure is defined as</p><formula xml:id="formula_0">SM 1 (X) = r ∑ i=1 c ∑ j=1 min(r,i+1) ∑ l=max(1,i−1) (X i j − X lm ) 2 + r ∑ i=1 c ∑ j=1 min(c, j+1) ∑ m=max(1, j−1) (X i j − X lm ) 2</formula><p>and Niermann proposed an evolutionary algorithm for its minimization. Using only the (at most) four direct neighbors to each entry is referred to as the Neumann Neighborhood and the resulting stress measure is</p><formula xml:id="formula_1">SM 2 (X) = r ∑ i=1 c ∑ j=1 min(r,i+1) ∑ l=max(1,i−1) min(c, j+1) ∑ m=max(1, j−1) (X i j − X lm ) 2</formula><p>The minimization of this second stress measure is almost equivalent to the maximization of the measure of effectiveness (ME) <ref type="bibr" target="#b24">[25]</ref>. ME is the number of directly neighboring pairs of observations, i.e. the sum over all matrix entries times the sum of the entries in their Neumann Neighborhood. It is defined as</p><formula xml:id="formula_2">ME(X) = 1 2 n ∑ i=1 m ∑ j=1 X i j • (X i−1, j + X i, j−1 + X i+1, j + X i, j+1 ) = 1 2 n ∑ i=1 m ∑ j=1 X i j • (X i−1, j + X i+1, j ) + 1 2 n ∑ i=1 m ∑ j=1 X i j • (X i, j−1 + X i, j+1 )</formula><p>for a matrix X = (X i j ) ∈ N nxm and X i0 = X 0 j := 0. The stress measure based on the Neumann neighborhood can be rewritten as follows:</p><formula xml:id="formula_3">SM 2 (X) = 8 r ∑ i=1 c ∑ j=1 X i j − 4 • ME(X) −2 r ∑ i=1 (X i1 + X ic ) − 2 c ∑ j=1 X 1 j + X r j</formula><p>Since the first term of the equation is a constant we can see from the last two terms that in comparison to ME the stress measure SM 2 additionally favors (large) entries at the border of the matrix and since it is hard to see a reason for doing so ME will be used as a basis for further development in Section 3. A similar equation holds for Niermann's stress measure SM 1 and an extension of ME to Moore neighborhoods.</p><p>The measure of effectiveness as well as the Moore Stress and the Neumann Stress are related to the criterion we propose, but are less general criteria and do not produce diagonalized results. Although the Neumann Stress and ME address a less complex problem (the category orders for all variables are independent) the computation of our proposed criterion has the same order of complexity.</p><p>Apart from these criteria which are more directly related to the criterion we propose there are several other measures for the agreement between two clusterings that have been developed. Among the most important ones is the Mirkin metric D m which is equivalent to the Ben-Hur metric <ref type="bibr" target="#b3">[4]</ref>:</p><formula xml:id="formula_4">D m (C 1 ,C 2 ) = 2N disagree (C 1 ,C 2 )</formula><p>where N disagree (C 1 ,C 2 ) is the number of pairs of data points which share one category in one variable and different categories in the other. This metric counts the number of discordant pairs and can be scaled to [0, 1] by division by the number of all pairs.</p><p>Like most metrics for clustering comparisons, the Mirkin metric does not directly depend on the number of clusters and can be computed efficiently. Unfortunately the resulting values poorly reflect structural information and complex associations between the clusters as the following example shows: There are four 4x4 contingency tables of 20 data points in <ref type="figure" target="#fig_0">Figure 1</ref> for all of which the unscaled Ben-Hur metric has the value 48, although there are very different patterns of association between the classifications. While the two tables to the left both show 3 clusters in the data, the top right table suggests 2 clusters and the bottom right one shows only one cluster and no particular relationship between the classifications at all.</p><p>Two other criteria are the Rand index <ref type="bibr" target="#b29">[30]</ref>, which counts the number of concordant pairs, and the Van Dong metric <ref type="bibr" target="#b30">[31]</ref>. The optimisation of the measure of effectiveness is implemented in the R package seriation <ref type="bibr" target="#b13">[14]</ref> as one of only two methods for multi-way data (several sets of objects). The package concentrates on the optimization of "two-way one-mode" data (one set of objects represented by a two-dimensional dissimilarity matrix) and also offers visualization techniques like heatmaps <ref type="bibr" target="#b36">[37]</ref> and bertinplots <ref type="bibr" target="#b9">[10]</ref>.</p><p>Two algorithms are offered for the maximization of ME: the original approach which uses the Bond-Energy-Algorithm (BEA) <ref type="bibr" target="#b24">[25]</ref> and an alternative approach based on the Traveling-Salesman-Problem (BEA-TSP) <ref type="bibr" target="#b20">[21]</ref>.</p><p>For an overview of several other seriation techniques which are also implemented in the package see for instance Chen et.al. <ref type="bibr" target="#b5">[6]</ref> and <ref type="bibr" target="#b6">[7]</ref> who use sorting for data matrix visualization. The optimisation of matrix representations via seriation techniques is also related to Bertin's ideas and often uses anti-Robinson Matrix conditions <ref type="bibr" target="#b1">[2]</ref>. Some approaches use singular value decompositions (SVD) of matrices to reorder the objects: Friendly <ref type="bibr" target="#b10">[11]</ref> described the ordering of correlation matrices using the first two principal components and an algorithm using only the first principal component is the second approach for multi-way data offered in the R package.</p><p>Mäkinen et al. <ref type="bibr" target="#b22">[23]</ref> propose the so-called barycenter heuristic for the reordering of the categories in data matrices. This approach is very similar to the iterative reordering of the rows by their weighted mean column indices and the columns by their weighted mean row indices which is called the 2D-sort in Mäkinen et al. <ref type="bibr" target="#b23">[24]</ref>. The barycenter heuristic was first used by Sugiyama <ref type="bibr" target="#b33">[34]</ref> for the rearrangement of nodes in hierarchical system structures which can be expressed by a series of connectivity matrices. In their work they also propose the Penalty Minimization (PM) method which is an iterative procedure based on graph theoretic concepts. Bastert et al. <ref type="bibr" target="#b2">[3]</ref> describe several reordering procedures which minimize the number of crossing lines in digraphs. Most of these approaches work with binary data such as adjacency matrices in graphs. The algorithms mostly work on binary data or graphs, which can also be represented by binary adjacency or connectivity matrices. Categorical data can also be transformed to a binary representation by defining a binary variable for each category. Regarding cpcp plots (see <ref type="figure" target="#fig_11">Figure 7</ref>) or similar graphics as graphs with one node per variable and observation makes the application of the algorithms possible but at a very high computational cost. Other approaches such as the barycenter heuristic or the 2D sort are not easily generalised to more than two dimensions and also lack a clear optimisation criterion which can be used to judge the quality of the results.</p><p>Two additional related approaches are worth mentioning: To overcome problems with clusterings and visual perception in heatmaps the Matchmaker technique was described by Lex et al. <ref type="bibr" target="#b21">[22]</ref>. It uses dummy variables and a visualisation which is very similar to cpcp plots. It also provides heatmaps, queries, interactive highlighting <ref type="bibr" target="#b34">[35]</ref> and other interesting options. The concepts of Eulerian Tours and Hamiltonian Paths are utilized by methods proposed by Hurley and Oldford <ref type="bibr" target="#b15">[16]</ref> for the reordering of variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CRITERIA AND VISUALIZATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Bertin's classification index and related approaches</head><p>One of the best ways to visualise two-way categorical data is to use fluctuation diagrams <ref type="bibr" target="#b14">[15]</ref>. In a fluctuation diagram each entry of a contingency table is represented by a rectangle of size proportional to the corresponding number of observations, i.e. each side of the rectangle is proportional to the square root of the number of observations. With this graphic it is easy to identify groups of matching categories when the underlying matrix has been sorted properly as <ref type="figure">Figure</ref> 2 demonstrates: the graphic shows two fluctuation diagrams of the same confusion matrix of k-means and model-based clusterings of the ecotest dataset. The first matrix uses the default category orderings and the second one is optimised. The red rectangles in the optimised display indicate groups which could be identified visually although they were actually computed using a procedure we present in Section 4.3. There exist some other graphics for the visualization of tabular data which are very similar to fluctuation diagrams such as tableplots <ref type="bibr" target="#b19">[20]</ref>, bertinplots <ref type="bibr" target="#b9">[10]</ref> or multiple barcharts <ref type="bibr" target="#b14">[15]</ref>. Of all these fluctuation diagrams meet our purpose best, since we do not look at expected values, residuals or negative values as it is the case for tableplots and also we do not assume a directed causality between the variables which is the case where multiple barcharts or bertinplots would be preferrable. A very common alternative for the definition of fluctuation diagrams is to adjust the rectangles in the bottom left corner of their corresponding cells instead of using the center. For three reasons we prefer our definition: firstly rectangles placed to the bottom left corners may sometimes give the impression of an association which tends to this direction even when there isn't one. Secondly, it is a much harder task to identify the correct row and column of a rectangle in the plot especially when the number of rows and columns increases. The last point is that it is the area of the rectangles we are interested in and not their side lengths. Positioning all the rectangles centrally makes this comparison more intuitive and prevents the user from comparing the side lengths.</p><p>We will also refer to line-based plots meaning all plots that can be regarded as (systems of) bipartite graphs such as parallel coordinates plots. From this class we will particularly present examples using cpcp plots <ref type="bibr" target="#b27">[28]</ref> and circos diagrams <ref type="bibr" target="#b18">[19]</ref>.</p><p>With a 1:1 correspondence between the classifications, an n×n data table can be displayed in a diagonal form and one variable is completely redundant. A much more general idea which also works for non-quadratic data tables is to look for perfect correspondences between single rows and one or more columns (1:c correspondence) or vice versa (r:1 correpondence). To cater for this we consider so-called pseudo-diagonals defined as follows:</p><p>A matrix with row classifications R = {R 1 , .., R n } and column clas-</p><formula xml:id="formula_5">sifications C = {C 1 , ..,C m } is in pseudo diagonal form, if there exists a partition of the data D into r ≤ min(n, m) disjoint clusters K 1 , ..., K r with K i ∈ {C 1 , ...,C m , R 1 , ..., R n } such that D = ⊎{K 1 = {C 1 , ...,C k1 }, K 2 = {C k1+1 , ...,C k2 }, ..., K r = {C kr−1 , ...,C m }} = ⊎{K 1 = {R 1 , ..., R t1 }, K 2 = {R t1+1 , ..., R t2 }, ..., K r = {R tr−1 , ..., R m }}.</formula><p>. A cluster K i can therefore possibly contain either more than one row or more than one column of the data matrix. Hence every row classification is either fully contained in exactly one column classification (1:c correspondence) or is itself the union of one or more column classifications. <ref type="figure" target="#fig_2">Figure 3</ref> illustrates this definition: the marked blocks indicate three clusters</p><formula xml:id="formula_6">K 1 = {R 1 , {C 1 ,C 2 }}, K 2 = {C 3 , {R 2 , R 3 }} and K 3 = {R 4 , {C 4 ,C 5 }}.</formula><p>In practice, even with a high level of agreement, the classifications may overlap as is the case for the data points marked with a * in <ref type="figure" target="#fig_2">Figure 3</ref>. An n × m data table which has a perfect pseudodiagonal representation with no such overlaps can be represented by a single variable with at most min(n, m) groups. Our goal is to reorder the matrix rows and columns to get as close as possible to a pseudo-diagonal form and the orientation of pairs of entries in the matrix can be used to assess its closeness to a pseudodiagonal. Two matrix entries A i j and A i ′ j ′ are not part of the pseudodiagonal form if (i − i ′ )( j − j ′ ) ≤ 0. Equality indicates that the two entries share the same row or column.</p><p>For the pair of entries A i j and A i ′ j ′ the product A i j • A i ′ j ′ is the number of pairs of data points with one point in each of the combinations. This product should be small when the entries are not part of the diagonal form and large if they are. An approximately pseudo-diagonal form can be found by maximizing</p><formula xml:id="formula_7">K(A) = ∑ i ji ′ j ′ A i j A i ′ j ′ sign((i − i ′ )( j − j ′ )) = B(A) − B ′ (A) with B ′ (A) = ∑ i&gt;i ′ , j&lt; j ′ A i j A i ′ j ′ and<label>(1)</label></formula><formula xml:id="formula_8">B(A) = ∑ i&gt;i ′ , j&gt; j ′ A i j A i ′ j ′</formula><p>being the nonconforming and conforming pairs respectively. This optimisation is equivalent to minimising B ′ (A) or maximising B(A) since the number of all products of pairs of entries G(A) can be broken up into</p><formula xml:id="formula_9">G(A) = N(N − 1) − ∑ i j A 2 i j = B(A) + B ′ (A) + X(A) +Y (A)</formula><p>where</p><formula xml:id="formula_10">X(A) = ∑ i=i ′ , j = j ′ A i j A i ′ j ′ and Y (A) = ∑ i =i ′ , j= j ′ A i j A i ′ j ′</formula><p>are the pairs that share a row or a column respectively and both are invariant with respect to row or column permutations. N denotes the total number of observations. The criterion B ′ (A) is from now on referred to as the Bertin Classification Criterion (BCC) since it is a direct realization of Bertin's ideas. The complexity order for the computation of this criterion for a given matrix A ∈ N n×m turns out to be O(mn). For details refer to Section 4.</p><p>The original data matrix A is defined by a categorical row variable and a categorical column variable. Replacing their original values by the row and column indices yields two ordinal variablesṼ andW . For these variables a correlation coefficient called Kendall's τ <ref type="bibr" target="#b16">[17]</ref> can be computed. For two (continuous) variables v and w it is defined as Since B(A) + B ′ (A) is invariant over all permutations of rows and columns the denominator remains constant and the optimisation of τ(A) is equivalent to the optimisation of B(A). In contrast to τ, B ′ (A) has a more intuitive and direct interpretation referring to (permutationdependent) deviations from a pseudo-diagonal form and we will use it.</p><formula xml:id="formula_11">τ(v, w) = C(v, w) − D(v, w) C(v, w) + D(v, w) + I 1 (v, w) • C(v, w) + D(v, w) + I 2 (v, w) where C(v, w), D(v, w), I 1 (v, w) and I 1 (v, w) are computed from all pairs of observations z i j := ((v i , w i ), (v j , w j )): C(v, w) = |{z i j |(v i &gt; v j ∧ w i &gt; w j ) ∨ (v i &lt; v j ∧ w i &lt; w j )}| D(v, w) = |{z i j |(v i &gt; v j ∧ w i &lt; w j ) ∨ (v i &lt; v j ∧ w i &gt; w j )}| I 1 (v, w) = |{z i j |(v i = v j ∧ w i = w j )}| I 2 (v, w) = |{z i j |(v i = v j ∧ w i = w j )}|</formula><p>Among all matrices with the same marginal distributions (i.e. row and column sums) as a matrix A, the worst optimal value for B(A) is reached for the independence matrix which is defined by N • p x ⊗ p y where N is the total number of observations, p x and p y are the row sums and column sums divided by N and ⊗ is the outer product. This worst optimal value is</p><formula xml:id="formula_12">B I (A) = (B(A) + B ′ (A) + X(A)) • (B(A) + B ′ (A) +Y (A)) N 2</formula><p>Hence it is possible to compute a scaled version of B(A), which we call the Bertin Classification Index (BCI), that can be used to judge the strength of association between the classifications:</p><formula xml:id="formula_13">BCI(A) = B ′ (A) B I (A) ∈ [0, 1]<label>(2)</label></formula><p>The Bertin Classification Index can also be used to compare the strength of association between different pairs of variables where 1 represents perfect independence and 0 occurs when the matrix has a pseudo-diagonal form. It is also possible to compute it for ordinal variables as a measure of dependence rather than for constructing a new category order. In comparison to other methods, such as linearby-linear association models (see for instance <ref type="bibr" target="#b32">[33]</ref>), non-linear dependencies can also be detected this way. and eighth column (No. 6). These cutting points have been marked in the graphic with red rectangles. One approach on how such rectangles can be derived by analytical methods is described in Section 4.3. The BCI for this matrix has a value of 0.1944. It should be noted that the clusters marked in the graphic do not form a pseudo-diagonal, but can be transformed into such by combining adjacent rows and columns. The BCI is well suited for finding such block-diagonal structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Weighted Bertin Classification Criterion</head><p>In Section 4 it will be shown that the BCC and its scaled version, the BCI, can be computed efficiently and the examples illustrate that the optimisations yield results which can be easily interpreted. The similarity between Kendall's τ and BCC partly depends on the observation that X(A) and Y (A) are invariant with respect to changes in the row and column orders. X(A) and Y (A) being constant means that the value related to any 2x2 submatrix (taking any pairs of columns and rows) is independent of the rest of the matrix and in particular does not depend on the number of rows or columns in between. Usually it would be much preferable when large entries that share the same row or column would also be placed next to each other. Also one might argue that the penalties for contradictions to the pseudo-diagonal form should be larger when the corresponding observations are far from each other. To reach this a weighted version the Bertin Classification Criterion is now presented. The Weighted Bertin Classification Criterion (WBCC) is defined as</p><formula xml:id="formula_14">W BCC(A) = ∑ i≥i ′ , j≥ j ′ w(i, i ′ , j, j ′ ) • A i j A i ′ j ′ with w(i, i ′ , j, j ′ )</formula><p>being the weights, which ideally should be chosen to have the properties of a metric. The Euclidean metric In this paper the Hamming distance will be used for two reasons: first it is a metric which suits the categorical nature of the data and second it can be partitioned into x and y components which makes an efficient computation possible. Additionally, it is possible to scale W BCC by dividing it by the "worst case" under independence in the same way as the unweighted classification criterion in equation 3.1. The difference is that for the weighted criterion the orders of the rows and columns also matter under independence, since they depend on the ranks of the row and column weights respectively. The optimal order of the rows with ranks r i where n i+ &lt; n j+ ∀ j &gt; i is and similarly for the column orders. The worst possible value under independence results when the ranks are in decreasing order, i.e. n i+ &gt; n j+ ∀ j &gt; i. The scaled version of WBCC using the Hamming distance will be referred to as the Weighted Bertin Classification Index (WBCI).</p><formula xml:id="formula_15">w(i, i ′ , j, j ′ ) = (i − i ′ ) 2 + ( j − j ′ ) 2 or the so-called Hamming dis- tance w(i, i ′ , j, j ′ ) = |i − i ′ | + | j − j ′ |</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dependence on initial category orders</head><p>Criterion evaluation and the optimisation algorithms are computationally cheap but depend on the initial order of the categories. A simple idea to get round this is to start from many randomly chosen initial orders and to choose the best outcome. <ref type="figure" target="#fig_6">Figure 4</ref> shows the best result for 1000 trials with BCI (top) and the WBCI (bottom). The BCI values for the two matrices are 0.1820 (top) and 0.2261 (bottom) and the WBCI values are 0.1987 and 0.1899 respectively. Again rectangles for three possible correspondence groups have been added to both graphics and the memberships of the groups are the same in both solutions. In fact these memberships are the same as for the single optimisation in <ref type="figure" target="#fig_1">Figure 2</ref> but the structure within the groups looks better especially within the first block which now also looks diagonalized. A histogram of the BCI values from the 1000 trials is shown in <ref type="figure" target="#fig_8">Figure 5</ref>: although there are some less optimal solutions with values up to 0.5327 the distribution has a positive skew which means that even a relatively small number of repetitions will usually lead to good if not optimal results. For this example the computation of all 1000 repetitions took about 2 seconds on an iMac with a 2.8GHz Core i7 and 8GB DDR2-1066 RAM. For very large matrices presorting the categories with a simple technique such as using weighted row and column mean indices may be beneficial.</p><p>For line-based graphics such as parallel coordinates plots for categorical data (cpcp) <ref type="bibr" target="#b27">[28]</ref>, parallel sets <ref type="bibr" target="#b17">[18]</ref>, table representations in circos <ref type="bibr" target="#b18">[19]</ref> or hammock plots <ref type="bibr" target="#b31">[32]</ref> BCC is in fact the number of crossing lines which is often seen as a main factor for judging the level of visual perception, for instance in parallel coordinates plots <ref type="bibr" target="#b8">[9]</ref>. To see this suppose there are two observations a and b with values (x a , y a ) and (x b , y b ) in variables X and Y . Now for any given values (x a , y a ) the line for observation b will cross the line for observation a if either x a &lt; x b ∧ y a &gt; y b or x a &gt; x b ∧ y a &lt; y b , which exactly meets the summation indices in the BCC formula <ref type="bibr" target="#b0">(1)</ref>. Note that here the number of crossing lines refers to (poly-) lines for each observation even if in some graphics many such lines are combined to ribbons. <ref type="figure" target="#fig_10">Figure 6</ref> shows circos diagrams of the original matrix from Figure 2 (first) and the optimised version from <ref type="figure" target="#fig_6">Figure 4 (first)</ref>. In addition to the new category orders the groups which are marked in the fluctuation diagram are used to arrange the rows and columns. The red cutting lines show these clusters. The first and unsorted graphic mainly shows the largest entries and is beyond that relatively hard to interpret. The sorted version also gives useful information about similarities and corresponding groups of rows and columns and is generally much easier to read: for instance one of the main violations of the group structure is the combination of the 9th k-means cluster (km9) and the fourth model-based cluster (mc4). Within the largest group the colors pink and green (km1 and km5) mainly correspond to the 8th and 9th modelbased clusters (mc8 and mc9) whereas the blue and the brown group (km9 and km2) form the majority of cases in the 11th model-based cluster (mc11).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The multivariate Bertin Classification Criterion</head><p>For more than two dimensions we present two ways of generalising the Bertin Classification Criterion and the related concept of a pseudodiagonal: a multivariate pseudo-diagonal element is defined by at least one category in one dimension and exactly one category in all others. All pairs of observations in different pseudo-diagonal groups are then fully concordant in all dimensions. Hence a direct approach to try and achieve a form of the data array which is closest to this definition is to maximize the number of fully concordant pairs. Analogous to equation  the number of observation pairs that differ in all variables (i.e. they have no ties).</p><p>A second way of generalising to more than two dimensions is to demand concordance in at least two dimensions and to permit equality in all others. This second version of the criterion is better suited when there are more than two clusters in the data which are not necessarily defined on the same subset of variables. This version of B(A) will be denoted by B * (A) and is defined as</p><formula xml:id="formula_16">B * (A) = ∑ s 1 ≥s 1 ,....,s k ≥s k :|{i:s i &gt;s i }|≥2 A s 1 ,...,s k As 1 ,...,s k</formula><p>For the definition of B ′ * (A) we again use the form B ′ * (A) = N 2 −B * (A) where this time N 2 is the total number of observation pairs which differ in at least two dimensions.</p><p>As for the two-dimensional case it is again possible to scale B ′ (A) </p><formula xml:id="formula_17">N I 1 = N 2 k ∏ s=1 ∑ i = j p s i p s j and N I 2 = N 2 k ∏ s=1 ∑ i = j (2p s i p s j + (p s i ) 2 + (p s j ) 2 )</formula><p>respectively. The scaled versions of the criteria will be referred to as the Multivariate Bertin Classification Indices MBCI and MBCI * :</p><formula xml:id="formula_18">MBCI(A) = N 1 − B(A) (2 k−1 − 1)N I 1 MBCI * (A) = N 2 − B * (A) N I 2 − N 2 ∏ k s=1 ∑ i, j p s i p s j</formula><p>Both indices are between 0 and 1 after optimisation of the corresponding criterion where again 0 indicates full concordance and 1 indicates independence. Note that for the optimisation it is sufficient to maximize B(A) and B * (A). <ref type="figure" target="#fig_11">Figure 7</ref> shows a cpcp plot <ref type="bibr" target="#b27">[28]</ref> comparing clusterings produced by four different methods: k-means, model based, hierarchical complete and hierarchical based on Ward. A cpcp plot is in fact a standard parallel coordinates plot where each observation is represented by one polyline. The coordinates of the observations on each axis are derived as follows: Each category is represented by equidistant points in an interval of length proportional to the relative observed frequency of the category. The observations are then assigned to the interval coordinates according to their ranking with respect to the other variables. The line segments of similar observations are parallel and appear as a thick joint line segment.</p><p>The first graphic uses the original category orders and the second one is optimised with respect to MBCI. The sorted visualisation is clearly easier to interpret and you can see that except for some cases in the complete-linkage hierarchical clustering the (k-means) clusters 9, 2, 3, 5 and 1 are quite separated from the rest. Cluster 10 in the kmeans solution is mainly divided into two clusters in both the modelbased clustering and the hierarchical clustering by Ward's method, but the partition of the observations is very different for the two methods. In general it is easier to detect combinations which do not match a pseudo-diagonal form since such cases are represented by lines which cross many other lines. The "parallelization" which results from the sorting also reduces overplotting which was also studied in <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">COMPLEXITY, ALGORITHMS AND COMPUTATION TIMES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Optimization algorithms for the Bertin Classification Criterion</head><p>This section deals with the complexity order of the computation of the Bertin Classification Criterion and the optimisation algorithms. For reasons of simplicity we use the two-way data case (i.e. data matrices) to illustrate the algorithms and concepts in this section. The results for multi-way data are analogous. The computation of the Bertin Classification Criterion as it is defined in Section 3 can be performed very efficiently using a reformulation based on cumulative sums:</p><formula xml:id="formula_19">B(A) = n ∑ i=2 i−1 ∑ i ′ =1 m−1 ∑ j=1 m ∑ j ′ = j+1 A i j A i ′ j ′ = n ∑ i=2 m−1 ∑ j=1 A i j m ∑ j ′ = j+1 i−1 ∑ i ′ =1 A i ′ j ′</formula><p>These cumulative sums which occur inside the brackets are illustrated in <ref type="figure" target="#fig_12">Figure 8</ref>, where the orange marker shows the deviations from the pseudo-diagonal form relative to the entry X i j .</p><p>The complexity of computing the classification criterion with this procedure is O(mn) with an exact number of 4(m − 1)(n − 1) − 1 = 4mn − 4m − 4n + 3 operations and hence it can be easily computed even for very large data matrices. For k-way data with s i , i = 1..k denoting the number of categories in variable k the complexity is of order O(s 1 • ... • s k ). With a similar trick based on cumulative sums the Hamming-weighted BCC can also be computed in O(mn). The initial BCC value is always bounded above by the BCC under independence</p><formula xml:id="formula_20">m 2 1 m 2 n 2 1 n 2 N 2 = (m−1)(n−1) 4mn N 2 ≤ N 2 /4</formula><p>. since for any case with a higher value one can simply reverse the row or column order. The total number of steps of a greedy algorithm which requires an improvement in each step is hence bounded above by min(N 2 /4, m!n!) because the underlying data is of integer type. This is also the case for the very efficient greedy algorithm we propose next but of course the required number of steps is in fact much lower than this upper boundary. The algorithm uses the simple operations move row/column i to position j. In each step there are (m − 1) 2 or (n − 1) 2 such operations possible leading to an order of complexity O(m 3 n) or O(mn 3 ) per step.</p><p>Fortunately the form of the criterion can again be utilised to further significantly lessen the complexity of the algorithm: The operation move row/column i to position j with w.l.o.g. i &lt; j can be rewritten as for k = i+1 to j do exchange rows/columns k and k-1 which is illustrated in <ref type="figure" target="#fig_13">Figure 9</ref>. Let X k denote a column or row of X and {X i , X j } be the submatrix of columns or rows i and j. The matrix ∆ = (δ ) i j with entries</p><formula xml:id="formula_21">δ i j = M({X j , X i }) − M({X i , X j })</formula><p>contains the changes in value of the criterion which are caused by putting column or row i behind column or row j assuming they are next to each other (i.e. disregarding any columns or rows between them). The change matrix for the columns is henceforth referred to as ∆ C and that of the rows as ∆ R respectively. Note that ∆ C remains constant over all permutations of columns for any fixed row order and ∆ R remains constant over all permutations of rows for any fixed column order.</p><p>The operation move row/column i to position j changes the value of the criterion by the sum of the pairwise change values δ C k,k+1 or δ R k,k+1 , k = i + 1... j, respectively. Computing the pairwise values of change for all pairs of columns (or rows) needs m 2 (6n − 5) operations. For a single step this leads to a complexity of order O(m 2 n + m 2 ) which is already better than O(m 3 n) and since ∆ C and ∆ R are constant over all column order changes and row order changes respectively it is possible to perform further operations of the same type each at a cost of only (m − 1) 2 sum operations on ∆ C or (n − 1) 2 sum operations on ∆ R . This suggests the following iterative procedure:</p><p>Algorithm Step <ref type="bibr" target="#b0">[1]</ref> of this alternative algorithm looks for the best among (n − 1) 2 row and (m − 1) 2 column operations and thus has a complexity order of O(n 2 + m 2 ).</p><p>Step <ref type="bibr" target="#b1">[2]</ref> updates either m 2 or n 2 δ − values. Therefore after a column operation it is sufficient to compute n sums within each row and analogously n sums within the columns after a row operation. Denoting these sums by d u we have </p><formula xml:id="formula_22">d u =          ∑ j k=i+1 A</formula><formula xml:id="formula_23">= δ R s,t ± (A is d t − A it d s ) or δ C s,t = δ C s,t ± (A is d t − A it d s )</formula><p>where the sign again depends on whether i &gt; j or j &gt; i. In summary each of the O(n 2 +m 2 ) possible operations makes O(m 2 +mn) or O(n 2 + mn) update operations necessary and hence the computational effort for each step is only O(n 2 + m 2 ) because 2mn ≤ m 2 + n 2 .</p><p>Which of the algorithms performs better strongly depends on the data matrix A. On the one hand the alternative algorithm makes larger steps towards the optimum which results in fewer operations in total and also avoids the recomputation of the delta matrices. On the other hand the first algorithm usually doesn't switch between optimising rows and columns too often and each single operation is very cheap. For multi-way data the first algorithm is usually more efficient since the updating process in the second algorithm becomes more costly with a larger number of dimensions.</p><p>To roughly indicate how fast the algorithm really works we computed the average computation time for the optimization of 400 × 400 matrices each consisting of twenty 20 × 20 blocks. The row and column orders were chosen at random. The average computation time for these matrices was 7.033 seconds on a Macbook Pro with a core i7 CPU with 2.66 GHz and 8GB DDR3-1066 RAM. Adding noise to the matrix increased the computation time to 8.538 seconds on average. In this case the noise was not completely at random: to create as many problems as possible the matrix (in a random order) was mixed with half of the matrix in another random order (rounded up). For 200 × 200 and 100 × 100 matrices with the same structure the average times were 1.583 seconds and 0.179 seconds respectively. The computation times for smaller matrices such as the one used as an example in this paper are of course even smaller. This brief performance study is not meant to yield general results for the algorithms but rather to give an impression of how quickly the algorithms work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hierarchical structures</head><p>An important application for the reordering procedures described in this paper is the comparison and interpretation of different clusterings. Among them, there is an entire class which produces neither ordinal nor nominal classifications: hierarchical clusterings produce a tree where (groups of) columns or rows which join at some point are kept next to each other. The nodes of the dendrogram, i.e. the points at which two groups join, can be regarded as the angles of a mobile and it is possible to turn these angles but not to separate the two corresponding branches from one another. Although this structural constraint reduces the freedom of choice in the orderings it brings several advantages with it: Firstly, it is possible to move more than one column or row at a time and the numbers of possible row and column operations are only n − 1 or m − 1 respectively. Secondly, each operation which turns an angle exchanges the positions of two neighbouring groups and hence it is possible to compute change values δ d for each node d in the dendrogram. This is illustrated in <ref type="figure" target="#fig_0">Figure 10</ref> where blocks B1 and B2 are exchanged while the rest of the matrix as well as the inner structures of B1 and B2 remain untouched. All operations with a positive value δ d can be performed right away without computing any further sums. <ref type="figure" target="#fig_0">Figure 11</ref> shows the confusion matrix of a hierarchical clustering using complete linkage and another using "Ward" for the ecotest dataset. The categories in the matrix on the left side are ordered by their appearance in the dendrogram from left to right, top to bottom. Although their order is thus not completely at random the optimised matrix at the bottom clearly gives a better impression of the similarities between the two clusterings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Identifying clusters and pseudo-diagonals</head><p>In Sections 3 and 3.4 we have shown how the optimisation of the Bertin Classification Criterion can improve graphical displays of the data. The interpretation of the results is much easier and groups of corresponding categories can be visually identified as the red rectangles in <ref type="figure" target="#fig_1">Figure 2</ref> and 4 illustrate. However it is also possible to utilize the optimised form of the array in order to compute such clusters.</p><p>In this section we present a very efficient top-down partitioning algorithm based on Kendall's τ which directly takes advantage of the optimality with respect to BCC. It also works well for other diagonallike representations.</p><p>The algorithm iteratively seeks to find suitable divisions of pairwise disjunct clusters S z defined by connected sets of rows {R z 1 , ..., R z u } and connected sets of columns {C z 1 , ...,C z v }. Starting with one cluster according to the full sets of rows and columns the algorithm hierarchically divides all available clusters S z into two new subclusters S z</p><formula xml:id="formula_24">1 = {{R z 1 , ..., R z r * }, {C z 1 , ...,C z c * })} and S z 2 = {{R z r * +1 , ..., R z u }, {C z c * +1 , ...,C z v })} defined by the optimal cut- points {r * , c * } = argmax rc g(Ã) wherẽ A = ∑ R 1 ≤i≤R r ,C 1 ≤ j≤C c A i j ∑ R 1 ≤i≤R r ,C c &lt; j≤C v A i j ∑ R r &lt;i≤R u ,C 1 ≤ j≤C c A i j ∑ R r &lt;i≤R u ,C c &lt; j≤C v A i j</formula><p>as long as the cluster S z has at least two columns and two rows (i.e. u, v &gt; 1) and g(Ã) exceeds a prespecified value g 0 . For the choice of the function g(.) there is Kendall's τ but also other possibilties such as Cohen's κ <ref type="bibr" target="#b7">[8]</ref> which often leads to similar results. A logical choice for the minimum criterion value is g 0 = τ 0 = τ(A). The smaller τ 0 is, the more clusters will be found. Choosing τ 0 = −1 results in a pseudo-diagonal with the maximum number of clusters. <ref type="figure" target="#fig_0">Figure 12</ref> illustrates the splitting process using the matrix from  <ref type="figure" target="#fig_6">Figure 4</ref> and looks best due to the structure within the rectangles. The interpretation of this result is that there are three main groups in the data which are found by both clustering algorithms. Within these <ref type="figure" target="#fig_0">Fig. 11</ref>. Two hierarchical clusterings (complete, ward) with twelve clusters for the ecotest dataset. The categories for the first matrix are ordered by their appearance in the dendrograms, those of the second matrix are optimised. <ref type="figure" target="#fig_0">Fig. 12</ref>. The matrix from <ref type="figure" target="#fig_6">Figure 4</ref> with marked clusters according to different values of τ 0 ∈ {0.76 (orange), 0.6 (solid red), 0.4 (dashed red), −1.0 (dotted red)}. groups the classifications are still related but agree less. Also the threecluster-solution covers about 90% of the data. The clusters C1, C2 and C3 (top left to bottom right) in the example are strongly related to other variables in the ecotest dataset: <ref type="figure" target="#fig_0">Figure 13</ref> shows the three clusters and the remaining unclassified cases as a barchart and a generalized spineplot conditioned on the variables car class and engine type from the ecotest dataset. The car classes range from very small cars (I) to large executive cars (VII). The graphic shows that the third cluster (blue) covers most of the petrol-engine cars and some gas-powered cars in the lower car classes I to IV. The second cluster (green) contains most of the larger cars in classes V to VII except for some dieseleninge cars which belong to the first cluster (red). All in all these results indicate that the groups have some data-related meaning and it might for instance be useful to include the car class and engine type in the clustering process for this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SOFTWARE: THE R PACKAGE EXTRACAT</head><p>The R package extracat provides an open source access to the methods and algorithms described in this article. The central reordering functionality is provided via the function optile which uses the algorithms described in Section 4 and section 4.2. It accepts several different data types and also offers additional reordering procedures based on singular value decompositions. The fluctuation diagrams in this article were generated via the function fluctile. cfluctile computes clusters for matrices accoring to the procedure described in Section 4.3 and adds the rectangles to the plot. Dendrograms can be added using tfluctile. The function cpcp provides interactive parallel coordinates plots for categorical data (cpcp) based on the iplots package <ref type="bibr" target="#b35">[36]</ref>. The generalized spineplot in <ref type="figure" target="#fig_0">Figure 13</ref> is one variation of RMB-plots (relative multiple barcharts) which are available via the function rmb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND OUTLOOK</head><p>Many graphics displays can be substantially improved by reordering. In this article we have presented effective procedures for reordering nominal categorical data such as arise when different clusterings for a dataset are compared. For this the Bertin Classification Criterion (BCC) was defined and two efficient optimisation algorithms were presented. We have also shown how tree structures such as arise in hierarchical clusterings can be taken into account. A weighted version of the Bertin Classification Criterion (WBCC) has been developed for twoway data and the scaled versions of the criteria , the Bertin Classification Index (BCI) and the Weighted Bertin Classification Index (WBCI) were introduced for measuring the degree of association between the classification variables. In the final part the "diagonalized" structure of data matrices was utilized by a top-down partitioning algorithm with which clusters of corresponding row and column categories can be identified. The real data application illustrates that our Bertin-based methods lead to faster comprehension and better interpretation of the graphics displays. Future work will involve generalising the partitioning algorithm to more than two dimensions and visualising the results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Illustration of four different (theoretical) 4x4 clustering results of 20 data points. All four tables have the same value of the Ben-Hur metric.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>A confusion matrix of k-means and model-based clusterings of the ecotest dataset displayed with a fluctuation diagram. The first matrix uses the default category orderings, the second one is optimised. The area of the rectangles is proportional to the matrix entries and thus blank cells represent 0-counts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Illustration of a pseudo-diagonal form.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>such that C and D are the numbers of concordant and discordant pairs, while I 1 and I 2 are the numbers of pairs agreeing on one dimension. For the index variablesṼ andW this leads to the following form of τ defined on B(A), X(A) and Y (A): τ(A) = B(A) − B ′ (A) B(A) + B ′ (A) + X(A) • B(A) + B ′ (A) +Y (A) τ(A) is a non-parametric rank correlation coefficient and takes values in the interval [−1, 1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2</head><label>2</label><figDesc>shows the confusion matrix (cross-tabulation) of a k-means clustering and a model-based clustering of the ecotest dataset before (top) and after optimisation (bottom). The increase in interpretability is clear: The last two rows (No. 11, 10) and columns (No. 4, 5) form the most obvious cluster but also the first pair of rows (No. 1, 5) correspond to the first three or four columns (No. 8, 9, 10, 1). Since also the fourth and fifth column (No. 1, 11) and the fifth row (No. 9) are related to this cluster it might be reasonable to handle rows one to five and columns one to five as one cluster with an interesting structure. A second global cutting point is possible after the ninth row (No. 7)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>are obvious candidates for the choice of weighting function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>A confusion matrix of a k-means clustering and a model-based clustering for the ecotest dataset. The matrices on the top and on the bottom are each the best of 1000 optimisations with different initial category orders. The first is optimised by means of BCI and the second one by means of the WBCI.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>r 1 ,</head><label>1</label><figDesc>r 3 , ..., r m , r m−1 , ..., r 4 , r 2 f or m = 2k + 1 r 1 , r 3 , ..., r m−1 , r m , ..., r 4 , r 2 f or m = 2k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 .</head><label>5</label><figDesc>A histogram of the BCI values of 1000 trials with random initial orders. The positive skew indicates that even a small number of repetitions is usually sufficient to achieve a good if not optimal result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>1 we define B(A) = ∑ s 1 &gt;s 1 ,....,s k &gt;s k A s 1 ,...,s k As 1 ,...,s k . and for the multivariate version of the observation pairs B ′ (A) which are not fully concordant we use B ′ (A) = N 1 − B(A) where N 1 denotes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 6 .</head><label>6</label><figDesc>circos plots of the original matrix from Figure 2(first) and the optimised version from Figure 4(first). In addition to the new category orders the groups which are marked in the fluctuation diagram are used to arrange the rows and columns. The red cutting lines mark these groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 7 .</head><label>7</label><figDesc>Two cpcp plots of a k-means clustering, a model-based clustering and two hierarchical clusterings for the ecotest dataset. For the first graphic the original category orders have been used, whereas for the second one the orders have been been optimised sequentially.and B ′ * (A) after optimisation using the independence case as a basis. In the independence case N 1 and N 2 are</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 8 .</head><label>8</label><figDesc>Illustration of the cumulative sum procedure used for the computation of BCC which leads to overall complexity of O(nm).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 9 .</head><label>9</label><figDesc>Illustration of the procedure in which a row or column is moved one position at a time. The sums of the corresponding change values are the required change values for the whole operation of moving row or column i to position j.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>ku after row i went to position j &gt; i, ∑ i−1 k= j A ku after row i went to position j &lt; i ∑ j k=i+1 A uk after column i went to position j &gt; i ∑ i−1 k= j A uk after column i went to position j &lt; i Then the updated matrix entries δ R s,t or δ C s,t are δ R s,t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 10 .</head><label>10</label><figDesc>Illustration of turning the branches B1 and B2 of a tree around their common node.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Figure 4(top) for Kendall's τ with τ 0 ∈ {0.76, 0.6, 0.4, −1.0}. The outcomes for the different values are colored solid orange, solid red, dashed red and dotted red and lead to 3, 6, 8 and 10 clusters respectively. Choosing τ 0 = τ(A) ≈ 0.76 (orange) is the solution used in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 13 .</head><label>13</label><figDesc>The three clusters which are marked with rectangles inFigure 4(top) andFigure 12(orange) are shown in a barchart (left). The generalized spineplot of car class vs. engine type shows that the clusters are strongly related to combinations of these variables.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adac</forename><surname>The</surname></persName>
		</author>
		<ptr target="http://www.adac.de/infotestrat/tests/eco-test/default.aspx" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A method for chronologically ordering archaeological deposits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bar-Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Demaine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gifford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Antiquity</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="293" to="301" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Layered drawings of digraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bastert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Matuszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Drawing Graphs</title>
		<editor>M. Kaufmann and D. Wagner</editor>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">2025</biblScope>
			<biblScope unit="page" from="87" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A stability based method for discovering structure in clustered data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ben-Hur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="6" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Graphics and Graphic Information Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bertin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<publisher>Walter de Gruyter</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generalized association plots: Information visualization via iteratively generated correlation matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="7" to="29" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Matrix visualization and information mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings in Computational Statistics</title>
		<meeting>in Computational Statistics<address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Physika Verlag</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="85" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pargnostics: screen-space metrics for parallel coordinates. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1017" to="1026" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A tribute to J. Bertins graphical data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>De Falguerolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sawitzki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SoftStat 97</title>
		<meeting>the SoftStat 97</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Corrgrams: Exploratory displays for correlation matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Friendly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="316" to="324" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effect ordering for data displays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Friendly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics and data Analysis</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="509" to="539" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mosaics for contingency tabless</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hartigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kleiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Symposium on the Interface</title>
		<meeting>the 13th Symposium on the Interface</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Getting things in order: An introduction to the r package seriation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hashler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buchta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring categorical data: Interactive mosaic plots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Metrika</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="26" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pairwise display of high-dimensional information via eulerian tours and hamiltonian decompositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Oldford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="861" to="886" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Seriation from abundance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematics in the Archaeological and Historical Sciences</title>
		<imprint>
			<date type="published" when="1971" />
			<biblScope unit="page" from="214" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ziemkiewicz</surname></persName>
		</author>
		<ptr target="http://eagereyes.org/parallel-sets" />
		<title level="m">Parallel sets v2.1: Categorical data visualization</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Circos: an information aesthetic for comparative genomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krzywinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1639" to="1645" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tableplot: A new tool for assessing precise predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Friendly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">217</biblScope>
			<biblScope unit="page" from="38" to="48" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Clustering a data array and the traveling salesman problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lenstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="413" to="414" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Comparative analysis of multidimensional, quantitative data. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Partl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kashofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1027" to="1035" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reordering the reorderable matrix as an algorithmic problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mäkinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Siirtola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory and Application of Diagrams</title>
		<editor>M. Anderson, P. Cheng, and V. Haarslev</editor>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">1889</biblScope>
			<biblScope unit="page" from="453" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mäkinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Siirtola</surname></persName>
		</author>
		<title level="m">The barycenter heuristic and the reorderable matrix. Informatica</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="357" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Problem decomposition and data reorganization by a clustering technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="993" to="1009" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimizing the ordering of tables with evolutionary computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Niermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">On the Theory of Contingency and Its Relation to Association and Normal Correlation. Drapers&apos; company research memoirs: Biometric series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pearson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1904" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">New approaches in visualization of categorical data: R-package extracat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pilhöfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Unwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Development Core</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Team</surname></persName>
		</author>
		<idno>3-900051-07-0</idno>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Objective criteria for the evaluation of clustering methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Performance criteria for graph clustering and markov cluster experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Rand</surname></persName>
		</author>
		<idno>INS-R0012 Centrum voor Wiskunde en Informatica</idno>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Visualizing categorical data arising in the health sciences using hammock plots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schonlau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>RAND Corporation</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Analysing Categorical Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Simonoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Methods for visual understanding of hierarchical system structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tagama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Toda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="125" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Interactive Graphics for Data Analysis: Principles and Examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Theus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Urbanek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Chapman &amp; Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">iPlots -high interaction graphics for r</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Theus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the DSC 2003 Conference</title>
		<meeting>the DSC 2003 Conference</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The history of the cluster heat map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Friendly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="184" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
