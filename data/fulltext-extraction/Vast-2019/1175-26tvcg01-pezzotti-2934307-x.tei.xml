<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2019.2934307</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>High Dimensional Data</term>
					<term>Dimensionality Reduction</term>
					<term>Progressive Visual Analytics</term>
					<term>Approximate Computation</term>
					<term>GPGPU</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In recent years the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm has become one of the most used and insightful techniques for exploratory data analysis of high-dimensional data. It reveals clusters of high-dimensional data points at different scales while only requiring minimal tuning of its parameters. However, the computational complexity of the algorithm limits its application to relatively small datasets. To address this problem, several evolutions of t-SNE have been developed in recent years, mainly focusing on the scalability of the similarity computations between data points. However, these contributions are insufficient to achieve interactive rates when visualizing the evolution of the t-SNE embedding for large datasets. In this work, we present a novel approach to the minimization of the t-SNE objective function that heavily relies on graphics hardware and has linear computational complexity. Our technique decreases the computational cost of running t-SNE on datasets by orders of magnitude and retains or improves on the accuracy of past approximated techniques. We propose to approximate the repulsive forces between data points by splatting kernel textures for each data point. This approximation allows us to reformulate the t-SNE minimization problem as a series of tensor operations that can be efficiently executed on the graphics card. An efficient implementation of our technique is integrated and available for use in the widely used Google TensorFlow.js, and an open-source C++ library.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GPGPU Linear Complexity t-SNE Optimization</head><p>Nicola Pezzotti*, Julian Thijssen*, Alexander Mordvintsev, Thomas Höllt, Baldur van Lew, Boudewijn P.F. Lelieveldt, Elmar Eisemann and Anna Vilanova <ref type="figure">Fig. 1</ref>: Evolution of the t-SNE embedding for the MNIST dataset. The optimization is performed in only a few seconds while running in a web browser and providing progressive updates. Previous implementations require tens of minutes to run in multithreaded C++ programs. CUDA implementations exists, but require NVIDIA GPUs and do not run in the browser. The example can be run at the following link https://nicola17.github.io/tfjs-tsne-demo/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>¨ ¨ ¨</head><p>Understanding how data points are arranged in a high-dimensional space plays a crucial role in exploratory data analysis <ref type="bibr" target="#b38">[39]</ref>. In recent years, non-linear dimensionality reduction techniques became powerful tools for mining knowledge from data, such as for the discovery of clusters. In the field of data visualization, these techniques are used for reducing the dimensionality to two or three dimensions in order to make visualization possible. Specifically, the algorithms preserve certain characteristics of the data, such as the local neighborhoods. This is effective due to the fact that most of the real-world data satisfy the "manifold hypothesis", i.e., they lie on low-dimensional manifolds embedded in high-dimensional space.</p><p>The t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm <ref type="bibr" target="#b41">[42]</ref> has become one of the state-of-the-art non-linear dimensionality reduction methods for visual analysis of high-dimensional data. It has been successfully applied to different domains, such as life sciences <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b24">25]</ref>, the comprehension of machine-learning models and to human-driven supervision <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33]</ref>. The t-SNE algorithm can be separated in two computation modules; first it computes the similarities of the high-dimensional points as a joint probability distribution and, second, it minimizes the Kullback-Leibler (KL) divergence <ref type="bibr" target="#b20">[21]</ref>, which measures the similarity between the data distribution in the high-dimensional space and the low-dimensional space.</p><p>The gradient of the KL divergence can be interpreted as a summation of attractive and repulsive forces between points, which makes the minimization process very similar to an N-body simulation <ref type="bibr" target="#b0">[1]</ref>. The memory and computational complexity of the algorithm is O N <ref type="bibr" target="#b1">2</ref> , where N is the number of data points. Interactive computation times are essential in an interactive visual exploration solution, and in consequence much research effort has been spent on improving its computational and memory complexity.</p><p>While many works focused on improvement of the similarity computation <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b40">41]</ref>, only limited effort has been spent on improving the minimization algorithm employed for the creation of the embedding <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b40">41]</ref>. Barnes-Hut-SNE (BH-SNE) was proposed by van der Maaten <ref type="bibr" target="#b40">[41]</ref>. It makes use of the Barnes-Hut algorithm for N-body simulations <ref type="bibr" target="#b2">[3]</ref> to approximate the repulsive forces between the data points. Repulsive forces change during minimization, since they depend on the data points position in the low-dimensional embedding space. Despite the improvements the computational costs remain high for large amounts of data points.</p><p>In this work, we focus on the minimization of the objective function, i.e., the KL-divergence, for the creation of the embedding. We observe that the heavy tail of the Student's t-distribution used by t-SNE makes the application of an N-body simulation not particularly effective. We propose a paradigm shift from point-to-point computation to a fieldbased computation of the embedding by reformulating the gradient of the objective function as a function of scalar and vector fields combined with tensor operations.</p><p>Our technique has linear computational and memory complexity, O (N), and is suitable for implementation in a GPGPU fashion, providing considerably better computation times compared to the current state of the art. It also allows us to implement a version for the browser and desktop that minimizes the objective function for standard datasets in a matter of seconds, potentially enabling the development of more advanced web-based analytics solutions.</p><p>The contribution of our work is twofold:</p><p>A linear complexity minimization of the t-SNE objective function. Specifically, we</p><p>approximate the repulsive forces between data points with a GPGPU approach relying on texture splatting adopt a tensor-based computation of the objective function's gradient.</p><p>An efficient implementation of our approach is released as part of Google's TensorFlow.js library and as part of the C++ HDI library. Our implementation is not only several orders of magnitude faster than the Barnes-Hut-SNE, but we demonstrate that it minimizes the objective function more effectively in addition to having better high-dimensional neighbor preservation.</p><p>The rest of the paper is structured as follows. In the next section, we provide a theoretical primer on the t-SNE algorithm that is needed to understand the related work (Section 3) and our contributions (Section 4). In Section 5, we provide details regarding our implementations. Finally, in Section 6, we compare our technique to BH-SNE, t-SNE-CUDA and the original t-SNE. We show the performance and accuracy improvements over these techniques using publicly available high-dimensional datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">T-SNE</head><p>In this section, we provide an introduction to the t-SNE <ref type="bibr" target="#b41">[42]</ref> algorithm, which is essential to understand the related work and our contribution. The t-SNE algorithm interprets the overall distances between data points in the high-dimensional space as a symmetric joint probability distribution P that encodes their similarities. Likewise a joint probability distribution Q is computed that describes the similarity in the low-dimensional space. The goal is to achieve a representation, referred to as an embedding, in which Q faithfully represents P. This means that the embedding preserves the local neighborhoods of the high-dimensional data points. At the same time, the low-dimensional embedding only has two or three dimensions, which can easily be visualized.</p><p>This objective is achieved by optimizing the positions of the points in the low-dimensional embedding to minimize the cost function C given by the Kullback-Leibler, KL, divergence between the joint-probability distributions P and Q. Intuitively, points in the embeddings are moved in an iterative fashion, such that the embedding similarities encoded by Q become more closely matched to the similarities in the highdimensional space encoded by P.</p><p>In more detail, given two data points x i and x j in a high-dimensional dataset X = {x 1 ...x N }, the probability p i j models the similarity of these points in high-dimensional space. q i j models the similarity in the low-dimensional embedding of the corresponding points y i and y j . The cost function C is formulated as follows:</p><formula xml:id="formula_0">C(P, Q) = KL(P||Q) = N ∑ i=1 N ∑ j=1, j =i p i j ln p i j q i j ,<label>(1)</label></formula><p>where KL measure the mismatch between Q and P. Similarities between two points x i and x j in the high-dimensional space are represented by p i j . More specifically, for each point x i , a Gaussian kernel is centered on the point and used to compute the probability that the other point is a neighbor. The variance σ i of the kernel is defined according to the local density in the high-dimensional space, and p i j is computed as follows:</p><formula xml:id="formula_1">p i j = p i| j + p j|i 2N ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">p j|i = exp(−(||x i − x j || 2 )/(2σ 2 i )) ∑ N k =i exp(−(||x i − x k || 2 )/(2σ 2 i ))<label>(3)</label></formula><p>p j|i can be seen as a relative measure of similarity for the point x i and all the points x j in its local neighborhood. The effective number of neighbors considered for each data point is derived by the perplexity value μ, which is a user-defined parameter. Consequently, the value of σ i is chosen such that for a fixed perplexity μ and for each i it satisfies:</p><formula xml:id="formula_3">μ = 2 − ∑ N j p j|i log 2 p j|i (4)</formula><p>A Student's t-Distribution with one degree of freedom is used to compute the joint probability distribution in the low-dimensional embedding Q, where the positions of the data points should be optimized. Q plays a similar role for the points in the low-dimensional space, as P does for the high-dimensional space. It encodes the similarities given the neighborhood information. In the embedding space the dispersion of the distribution (i.e., the Student's t-Distribution) is constant. Given two low-dimensional points y i and y j , the probability q i j is given by:</p><formula xml:id="formula_4">q i j = (1 + ||y i − y j || 2 )Z −1 (5) with Z = N ∑ k=1 N ∑ l =k (1 + ||y k − y l || 2 ) −1<label>(6)</label></formula><p>The goal of a t-SNE optimization is to move randomly initialized points y i in the embedding, such that the distribution Q is as close as possible to the distribution P. Intuitively, when Q matches P, the neighborhoods in the low-dimensional space match the high-dimensional counterparts. This result is obtained by minimizing a cost function C which is defined as the Kullback-Leibler divergence between P and Q. The gradient of C has an analytical solution and indicates the change in position of the points y i . It is given by:</p><formula xml:id="formula_5">δC δ y i = 4(F attr i − F rep i ) (7) = 4(Z N ∑ j =i p i j q i j (y i − y j ) − N ∑ j =i q 2 i j Z(y i − y j ))<label>(8)</label></formula><p>The optimization is based on gradient descent. For each iteration, the gradient is used to update the position of the data points in the embedding. The gradient descent can be seen as an N-body simulation <ref type="bibr" target="#b0">[1]</ref>, where each data point exerts an attractive and a repulsive force (F attr i and F rep i ) on all other points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>We now present the work that has been done to improve the computation of t-SNE embeddings in terms of quality and scalability. Van der Maaten proposed the Barnes-Hut-SNE (BH-SNE) <ref type="bibr" target="#b40">[41]</ref>, which reduces the complexity of the algorithm to O(N log(N)) for both the similarity computations and the objective function minimization. More specifically, in the BH-SNE approach the similarity computations are seen as a k-nearest neighborhood graph computation problem, which is obtained using a Vantage-Point Tree <ref type="bibr" target="#b44">[45]</ref>. The minimization of the objective function is then seen as an N-body simulation, which is solved by applying the Barnes-Hut algorithm <ref type="bibr" target="#b2">[3]</ref>.</p><p>In our previous work <ref type="bibr" target="#b33">[34]</ref>, we observed that the computation of the k-nearest neighborhood graph for high-dimensional spaces using the Vantage-Point Tree is affected by the curse of dimensionality, limiting the efficiency of the computation. To overcome this limitation, we proposed the Approximated-tSNE (A-tSNE) algorithm <ref type="bibr" target="#b33">[34]</ref>, where approximated k-nearest neighborhood graphs are computed using a forest of randomized KD-trees <ref type="bibr" target="#b28">[29]</ref>. Moreover, A-tSNE adopts the novel Progressive Visual Analytics paradigm <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b35">36]</ref>, allowing the user to observe the evolution of the embedding during the minimization of the objective function. This solution enables a user-driven early termination of the algorithm. t-SNE-CUDA <ref type="bibr" target="#b6">[7]</ref> is a CUDA implementation of the Approximated-tSNE algorithm. For computing the high-dimensional neighborhood, it uses the GPU library FAISS <ref type="bibr" target="#b15">[16]</ref>. A tree structure based on the BH-SNE is implemented in CUDA to compute the repulsive forces. While the technique allows for a fast computation of the embedding, the application is limited to NVIDIA hardware, greatly limiting its application. Furthermore, like BH-SNE, the resulting embedding remains an approximation of the t-SNE embedding.</p><p>A similar observation on the benefit of using approximated computations was later made by Tang et al. that led to the development of the LargeVis technique <ref type="bibr" target="#b37">[38]</ref>. LargeVis uses random projection trees <ref type="bibr" target="#b8">[9]</ref> followed by a kNN-descent procedure <ref type="bibr" target="#b9">[10]</ref> for the computation of the similarities and a different objective function that is minimized using a Stochastic Gradient Descent approach <ref type="bibr" target="#b17">[18]</ref>. Despite the improvements, both the A-tSNE and LargeVis tools still suffer from long computation times during the optimization that hinder interaction for large data sets. Better performance is achieved by the UMAP algorithm <ref type="bibr" target="#b26">[27]</ref>, which provides a different formulation of the dimensionality-reduction problem as a cross-entropy minimization between topological representations. Computationally, UMAP follows LargeVis very closely and adopts a kNN-descent procedure <ref type="bibr" target="#b9">[10]</ref> and stochastic gradient-descent minimization of the objective function.</p><p>A different approach is taken in the Hierarchical Stochastic Neighbor Embedding algorithm (HSNE) <ref type="bibr" target="#b31">[32]</ref>. HSNE efficiently builds a hierarchical representation of the manifolds and embeds only a subset of the initial data that represents an overview of the available manifolds. The user can "drill-in" the hierarchy by requesting more detailed embeddings that reveal smaller clusters of data points. While HSNE allows scalability of the analysis to large data sets by the generation and user-guided exploration of multiple embeddings, it does not address the acceleration of the computation of single embeddings.</p><p>The techniques presented so far do not take advantage of the dimensionality of the target domain. As a matter of fact, t-SNE is mostly used for data visualization in two-dimensional scatterplots, while the techniques introduced in this section so far are general and can be used in target domains of any dimensionality. Based on this observation, Kim et al. introduced the PixelSNE technique <ref type="bibr" target="#b18">[19]</ref>, where the points are not embedded in a continuous 2D space, but rather in a discretized space corresponding to the pixels used to display the scatterplot. The optimization is performed using an N-body simulation approach, which is similar to the one employed by BH-SNE. In order to compute embeddings that faithfully preserve high-dimensional neighborhoods, a large number of pixels must be used, often much larger than the display's resolution. In addition, it hampers the scalability of the technique, requiring many hours to compute embeddings containing more than a million points.</p><p>In our work, we take advantage of the two-dimensional domain in which the embedding resides and we propose an efficient way to minimize the t-SNE objective function. Contrary to PixelSNE, we only discretize the two-dimensional space for the computation of the repulsive forces presented in Equation 8. We developed a linear-complexity approach implemented using GPGPU as a desktop and client-side browser application. This is an improvement over t-SNE-CUDA, which can only be run on NVIDIA GPUs. Even though their computation of the embedding is faster, our technique produces embeddings that match more closely to the high-dimensional space. Compared to BH-SNE and PixelSNE, our technique computes embeddings with more than a million points in just a few minutes instead of several hours, while providing better preservation of high-dimensional similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LINEAR COMPLEXITY T-SNE MINIMIZATION</head><p>In this section, we present our approach to minimizing the t-SNE objective function as presented in Equation 1. The main idea consists in rewriting the gradient presented in Equation 7 such that it relies on a scalar field S and a vector field V in the 2D embedding domain. These fields can be computed in linear time on the GPU and queried in constant time. Therefore, the complexity of the algorithm is reduced from quadratic to linear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Field-based computation of the gradient</head><p>The gradient of the objective function has the same form as in regular t-SNE:</p><formula xml:id="formula_6">δC δ y i = 4(F attr i −F rep i ),<label>(9)</label></formula><p>with attractive and repulsive forces acting on every point x i ∈ X. We denote the forces with a ∧ to distinguish them from their original counterparts. We rewrite the equation of the gradient in the form of a scalar field S and a vector field V :</p><formula xml:id="formula_7">S (p) = N ∑ i 1 + ||y i − p|| 2 −1 , S : R 2 ⇒ R (10) V (p) = N ∑ i 1 + ||y i − p|| 2 −2 (y i − p), V : R 2 ⇒ R 2<label>(11)</label></formula><p>Intuitively, S represents the density of the points in the embedding space, according to the Student's t-distribution, and it is used to compute the normalization of the joint probability distribution Q. An example of the field S is shown in <ref type="figure" target="#fig_0">Figure 2b</ref>. The vector field V represents the directional repulsive force applied to the entire embedding space. An example of V is presented in <ref type="figure" target="#fig_0">Figures 2c and d</ref>, where the horizontal and vertical gradient components are visualized separately. If a point in the embedding resides in the red area of <ref type="figure" target="#fig_0">Figure 2c</ref>, it will be pushed a certain amount to the right in the current iteration of the gradient descent, while a point in the blue area will be pushed to the left. Similarly for the vertical component, see <ref type="figure" target="#fig_0">Figure 2d</ref>, a point will be pushed either up, for red areas, or down for blue ones. We describe the construction of S and V in Section 4.2. For now, we assume these fields are given, and we present how the gradient of the objective function is derived from S and V .</p><p>For the attractive forces, we adopt the restricted neighborhood contribution as presented in the Barnes-Hut-SNE technique <ref type="bibr" target="#b40">[41]</ref>. The rationale of this approach is that, by imposing a fixed perplexity on the Gaussian kernel, only a limited number of neighbors effectively apply an attractive force on any given point (see Equations 3 and 4). Therefore we limit the number of contributing points to some multiple of the chosen perplexity. This approach reduces the computational and memory complexity of the computation of the attractive forces to O(N), since the size of the neighborhood k is several orders of magnitude lower than N, k N.</p><formula xml:id="formula_8">F attr i =Ẑ ∑ l∈kNN(i) p il q il (y i − y l )<label>(12)</label></formula><p>The computation of the normalization factor Z, as it is presented in Equation 6, has computational complexity O N 2 . In our approach, we computeẐ by consulting the scalar field S in constant time, giving us a complexity of O (N).Ẑ</p><formula xml:id="formula_9">= N ∑ l=1 (S (y l ) − 1)<label>(13)</label></formula><p>Note that the formulation of Z andẐ is identical but, since S is computed in linear time, computingẐ also has linear complexity.Ẑ does not depend on the point y i for which we are computing the gradient. Therefore,Ẑ needs to be computed just once, cached, and then used at each iteration of the gradient descent for all points.</p><p>The repulsive force assumes the following form</p><formula xml:id="formula_10">F rep i = V (y i )/Ẑ,<label>(14)</label></formula><p>where the value of the vector field V in the location identified by the coordinates y i is normalized byẐ. Similar toẐ,F rep has an equivalent formulation as F rep but with computational and memory complexity equal to O(N). So far, we assumed that S and V are computed in linear time and queried in constant time. In the next section, we present how the rasterization pipeline is used to compute an approximation of the S and V fields. In Section 5, two ways to implement the proposed approach are given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Computation of supporting fields</head><p>Our approach to the computation of the fields resembles an approach used for Kernel Density Estimation <ref type="bibr" target="#b34">[35]</ref>, which has applications in visualization <ref type="bibr" target="#b21">[22]</ref> and non-parametric clustering <ref type="bibr" target="#b12">[13]</ref>. In this setting, given a number of points, the goal is to estimate a two-dimensional probability density function. This is achieved by superimposing a Gaussian kernel, whose σ has to be estimated, over every data point. Summing the contributions of all points in a given location or pixel in the embedding gives us the probability density function in a given location.</p><p>In KDE methods, the 2D kernel density is estimated efficiently on the GPU because of the quasi-limited support of the kernels, i.e., having values almost equal to zero if they are sufficiently far away from the origin. A good approximation of the density function is then achieved by drawing a quad at the location of each sample, which contains a precomputed texture or evaluates the kernel for each covered pixel <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b21">22]</ref>. By using additive blending, i.e., by summing the values in every pixel, the resulting output approximates the desired density function.</p><p>In our context, we want to compute S and V as shown in equations 10 and 11. These equations can also be seen as a summation of kernels S and V as defined in the following equations:</p><formula xml:id="formula_11">S (p) = N ∑ i S(y i − p), S(d) = 1 + ||d|| 2 −1 (15) V (p) = N ∑ i V (y i − p), V (d) = 1 + ||d|| 2 −2 (d)<label>(16)</label></formula><p>The presented kernels S and V are stored in a texture and are presented in <ref type="figure" target="#fig_1">Figure 3</ref>. The kernels have a limited function support, making it indeed very similar to the Kernel Density Estimation case discussed before. As the fields S and V are a summation of the aforementioned kernels, we can compute an approximation of the fields by additively rendering these per-point kernel textures at the locations of each of the points in the embedding.</p><p>The resulting 3-channel texture, an example of which is presented in <ref type="figure" target="#fig_0">Figures 2b-d</ref>, represents the scalar field S and the vector field V . Fetching the value of S and V for a point y i then corresponds to Contrary to the Kernel Density Estimation case, where the size of the quads changes according to the σ chosen for the Gaussian kernel, our functions must have a fixed support in the embedding space. This is dictated by the fact that we are optimizing Equation 1, a change of the quad size corresponds to a change in the low-dimensional distribution characterizing the points. Therefore, the resolution of the texture influences the quality of the approximation but not the overall shape of the fields. To achieve linear complexity, we define the resolution of the aggregate field texture according to the size of the embedding. The number of pixels that are covered by the textures presented in <ref type="figure" target="#fig_1">Figure 3</ref> is kept constant. This is achieved by changing the size of the target texture in the embedding space. A ratio ρ between the diameter of the embedding and the texture resolution is fixed. Hence, every data point updates the value of a constant number of pixels in the target texture equal to ρ 2 . This solution leads to O(Nρ 2 ) complexity for the computation of the fields, and we empirically found ρ = 0.5 to be a good compromise between the fidelity of the resulting fields and the computation time required. Since ρ <ref type="bibr" target="#b1">2</ref> N, the resulting computational complexity is O(N). Note that, by being adaptive to the texture size, no parameter tuning is required. A potential limitation is the maximum embedding size as defined by the OpenGL standard. In practice, this does not pose a limit since the embeddings size does.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IMPLEMENTATIONS</head><p>In this section we explain how the ideas presented in the previous section are implemented both for the browser as part of TensorFlow.js and for the desktop as part of the open source High-Dimensional Inspector (HDI) library <ref type="bibr" target="#b30">[31]</ref>. Two different approaches are presented: one that makes use of the rasterization pipeline, and one that uses compute shaders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Rasterization Approach</head><p>In this section, we present an implementation that heavily makes use of the rasterization pipeline of modern GPUs. Rasterization is the task of converting a series of geometric primitives, most commonly triangles, into a series of pixels that form a raster image. Contrary to the common application of rasterization in computer graphics, i.e., rendering of geometric scenes, here we associate each pixel with an atomic computation used for minimizing the t-SNE loss function. These are the computation of the attractive forces given the similarity distribution P (Section 5.1.1), the computation of the fields used for computing the repulsive forces (Section 5.1.2) and subsequently the updating of the embedding (Section 5.1.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Attractive Forces</head><p>Computation of the attractive forces, shown in the upper portion of <ref type="figure" target="#fig_2">Figure 4</ref>, is performed by measuring the sum of the contribution of every neighboring point in the high-dimensional space. The neighborhoods are encoded in the joint probability distribution P which is stored in a sparse matrix. P can be computed ahead of time, for example using an approximated k-nearest-neighborhood algorithm <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b28">29]</ref> or by the HSNE technique <ref type="bibr" target="#b31">[32]</ref>. We use existing techniques here, and do not provide any contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Repulsive Forces</head><p>We achieve linear complexity for the computation of the repulsive forces by making use of the rasterization pipeline innate in graphics cards. For the browser implementation we make use of the WebGL API and for the desktop implementation we use standard OpenGL.</p><p>In order to form the field textures we start with a randomly initialized t-SNE embedding. Centered on each of the points in the embedding, a quad is rendered. We apply a texture to the quad whose R color channel contains S(p) from Equation 15 and whose G and B color channels contain V (p) in each dimension from Equation 16. By enabling additive blending these splatted textures will add up to an approximation of the S and V fields. The approximated fields are stored in another floating-point RGB texture whose resolution is proportional to the size of the embedding space. The ratio between the two is defined by the parameter ρ introduced in Section 4.2. The degree of approximation is controlled by the resolution of the aggregate field texture and the resolution of the kernel texture.</p><p>To query the field values for a specific point in the embedding, we sample the field value at the point's position using bilinear texture interpolation. This operation is natively supported in the GPU and very efficient. The normalization factorẐ is obtained by summing all the elements in the tensor with the interpolated values of S . This summation is performed as a reduction operation on the graphics card. Note thatẐ is computed once and cached, hence Equation 14 is computed by simply dividing the interpolated field value by the cachedẐ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Updating the points</head><p>The remaining computational steps are computed as tensor, i.e., matrix, operations as defined in toolkits like TensorFlow.js.F rep is obtained by dividing the interpolated values of V byẐ, and the gradient of the objective function is obtained by adding the attractive forcesF attr . The gradient is then applied to the embedding modifying the position of the points according to the gradient. <ref type="figure" target="#fig_2">Figure 4</ref> shows an overview of our approach. Green squares represent textures containing the computed fields or the similarity matrix P, while blue rectangles represent tensors. Operations are represented by circles. More specifically, red circles are custom operations that are implemented specifically for our technique. Orange circles are tensor operations that are commonly available in TensorFlow.js or in the HDI library.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Compute Shader Approach</head><p>Implementations of our approach are available for both the web and desktop. These implementations are broadly applicable due to their limited feature requirements. However, as the computation of the algorithm is essentially reduced to a series of tensor operations, it lends itself very well to execution using one of the GPGPU APIs available. In the rasterization approach, many splats might overlap with each other. In particular, when the function support of the t-distribution is increased for more accurate embeddings, this simultaneously results in more overlapping splats. With additive blending enabled, this results in a high degree of overdraw, which can be quite costly. For this reason we have developed another implementation of the previously described algorithm. Instead of splatting textures to obtain the fields, here, we calculate the fields in a compute shader in the following manner.</p><p>For each pixel in the output field we calculate the influence of perpoint kernels on this pixel. If the point lies further away from the current pixel in embedding space than the given function support, the point is ignored. The complexity of this operation is O (N Px) where Px represents the number of pixels used for the output field. In practice, our solution behaves very linearly, since the maximum number of pixels affected is much lower than the number of points in reasonably sized data sets. This means, that the function support can be unbounded with negligible loss of performance, thereby resulting in even more accurate embeddings. This can also be done in the rasterization approach, however, it would result in extreme overdraw and have a significant impact on performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>In order to assess the efficacy of the proposed technique we evaluate the computational costs and quality of the embedding using three metrics. First, we record the execution time of the minimization process over 1000 iterations. Secondly, we evaluate the quality of the resulting embedding by using the reached Kullback-Leibler divergence. Kullback-Leibler is the objective function of the t-SNE algorithm. This metric shows how well the objective function is optimized by the different techniques. We also compute the Nearest-Neighbor Preservation (NNP) metric as described by Venna et al. <ref type="bibr" target="#b43">[44]</ref> and implemented by Ingram and Munzner <ref type="bibr" target="#b14">[15]</ref>. It measures how well small neighborhoods in the high-dimensional space are preserved during the dimensionality reduction. The main benefit of such a metric is its independence from the objective function optimized by the t-SNE algorithm. In order to measure the NNP accurately it is important that the gradient descent has fully converged. We chose 1000 iterations for the MNIST and ImageNet datasets and 5000 iterations for the WikiWord and Word2Vec datasets to guarantee full convergence for the different data sizes.</p><p>We compare the results of our technique (i.e., GPGPU-SNE) with the results obtained from the Barnes-Hut-SNE <ref type="bibr" target="#b2">[3]</ref> and the t-SNE algorithm without computational improvements <ref type="bibr" target="#b41">[42]</ref>. Both implementations are written in C++, support multi-threaded computations and are openly available in the High-Dimensional-Inspector (HDI) library <ref type="bibr" target="#b30">[31]</ref>. For Barnes-Hut-SNE, we provide results for two different values of its θ parameter. This parameter controls the trade-off between speed and accuracy of the algorithm. A value of θ = 0.5 sacrifices accuracy slightly for the benefit of a significant performance boost, and is often chosen as the default value. A value of θ = 0.1 prioritizes generating embeddings closer to those produced by original t-SNE, but at considerable execution time cost. Moreover, we provide a comparison with the t-SNE-CUDA algorithm <ref type="bibr" target="#b6">[7]</ref> for a value of θ = 0.0 and 0.5.</p><p>We expect that our implementation outperforms BH-SNE in time as well as quality of the embeddings. Our approach is fundamentally a different method of acceleration compared to t-SNE-CUDA. Our method does not rely on the CUDA API and can therefore be used to create embedding in a web-browser. Concerning performance, we expect t-SNE-CUDA to be similar or better concerning the computational costs, but lower in quality since it is an acceleration based on the approximation of BH-SNE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>We have chosen five commonly used datasets to illustrate the applicability of our technique to both small and large amounts of highdimensional data. First, we use the MNIST dataset. It consists of 60k labeled grayscale images of handwritten digits (compare <ref type="figure" target="#fig_0">Figure 2a)</ref>. Each image is represented as a 784 dimensional vector, corresponding to the gray values of the pixels in the image. The MNIST data is often used to validate non-linear dimensionality reduction techniques. As a matter of fact, it clearly contains 10 different manifolds, one for each digit. Moreover, the manifolds are non-linear, hence linear dimensionality-reduction techniques such as PCA are not able to reconstruct the manifolds. The WikiWord and GoogleNews datasets contain words, which are associated with a vector representation. These vector representations are algorithmically generated by processing large text corpora, often through a deep neural network <ref type="bibr" target="#b23">[24]</ref> and by requiring that words that occur in similar contexts share a similar representation. The shapes associated with each word present interesting characteristics for latent semantic analysis <ref type="bibr" target="#b22">[23]</ref>. As an example, it is shown that simple summation and subtraction of the vectors representing the words King − Man +Woman, as produced by the GloVe model <ref type="bibr" target="#b29">[30]</ref>, is very similar to the vector representation associated with the word Queen. Non-linear dimensionality reduction is often used in systems for the analysis of such word representations <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26]</ref>.</p><p>Finally, we present two different datasets obtained by collecting the activations of different layers in a deep neural network (DNN) <ref type="bibr" target="#b23">[24]</ref> on the validation set of the ImageNet dataset [20] 1 . The resulting embeddings shed a light on the internal computations performed by the deep neural network, the Google Inception <ref type="bibr" target="#b36">[37]</ref> in this case. Images, or image patches, that are close in the embedding are considered similar by the DNN <ref type="bibr" target="#b32">[33]</ref>. Recently, an increasing number of web-based tools, like the Activation Atlas <ref type="bibr" target="#b5">[6]</ref> or Tensorboard, have been proposed to <ref type="bibr" target="#b0">1</ref> The datasets can be created for an arbritary activation layer using the following Colab Notebook: https://colab.research.google.com/github/ tensorflow/lucid/blob/master/notebooks/activation-atlas/ activation-atlas-simple.ipynb better understand and improve DNNs through dimensionality reduction techniques such as t-SNE or UMAP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>In <ref type="figure">Figure 6</ref>, we show the results of the experiments for the chosen datasets. All experiments are conducted on an Intel Core i7-4820K Processor, with 4 physical cores (8 threads) @ 3.70 Ghz. The machine has 16GB of DDR3 RAM, and an NVIDIA GeForce GTX Titan GPU with 2688 CUDA cores @ 837 Mhz and 6GB of GDDR5 memory. All experiments run fit in the main memory available and have no interaction with disk during the optimization process.</p><p>To better highlight the behaviour of the algorithms with increasing dataset sizes, we run the algorithm on a random subset of the data with a growing number of data points for each of the experiments. The first row of charts in <ref type="figure">Figure 6</ref> shows the execution time of the various algorithms plotted against the number of data points in the subsampled dataset. Note that a logarithmic scale is used for both the vertical and horizontal axes.</p><p>Our technique significantly cuts back on execution time compared to Barnes-Hut-SNE and t-SNE. For the MNIST dataset, t-SNE takes two days to complete the iterations. BH-SNE with θ = 0.1 takes one hour and with θ = 0.5 takes around 8 minutes. While our technique computes the embedding in just 16 seconds. This is a reduction on the cost of the gradient descent in the range of orders of magnitude. For the other datasets it becomes infeasible to run the first two algorithms as they would take many days to execute. It is possible to run BH-SNE θ = 0.5 on the WikiWord dataset, but the computation takes more than an hour, while our technique computes the embedding in a mere 35 seconds. t-SNE-CUDA outperforms our technique by a factor in the range of x2 to x5. This can be explained by the highly-optimized code enabled by the CUDA implementation.</p><p>The second row examines the KL-divergence of the final embeddings from their original high-dimensional counterparts. And the last row shows the Nearest Neighborhood Preservation of all the embeddings, presented as a precision/recall plot.</p><p>In comparison to other optimization methods our technique produces a better, i.e., lower KL-divergence at data sets of non-trivial size. A likely explanation for this is that as the datasets get larger, the domain of the embedding expands but this expansion is not linear in the number of points. Therefore, the embedding will get progressively more dense, which is unfavourable for the Barnes-Hut approximation, which is also used by the t-SNE-CUDA. Approximations of the forces applied by distant points will become coarser as more of them are lumped together. Consequently this lowers the accuracy of the algorithm. This results in embeddings where the objective function cannot be effectively minimized, hence resulting in lower nearest-neighbor preservation. This observation is confirmed by the results presented in the third row. A similar observation can be made for the t-SNE-CUDA algorithm. Here, even higher KL-divergence can be observed for lower numbers of data points in the embedding. Speed is traded in favour of quality in producing the final embedding.</p><p>In the last row of <ref type="figure">Figure 6</ref>, we present the nearest-neighbor preservation for the different data sets. For each point, we examine a neighborhood of k points in the high and low-dimensional space. For every value from k = 1 to k = 30 we compute the true positive T , defined as the points that belong to both neighborhoods. From this, we compute precision as T /k, while recall is defined as T /30. The values of precision and recall for each value of k form a precision/recall curve for every point. The precision/recall curve for the entire embedding is obtained by averaging the curves of every point in the dataset. Since t-SNE and BH-SNE with θ = 0.1 take days to compute on these datasets, it becomes infeasible to calculate the metric for all datasets. We provide it for the MNIST dataset to give an indication of the relationship between the techniques. In addition, for the 3-million data point Word2Vec dataset calculating the metric would take more than a week. Therefore, we compute it on a 350k subset of the dataset, which also allows the curve for Barnes-Hut-SNE to be presented. We see that our technique has a significant advantage over the Barnes-Hut-SNE and t-SNE-CUDA algorithm, as it presents a high Precision/Recall curve GPGPU-SNE BH-SNE θ = 0.1 BH-SNE θ = 0.5 t-SNE-CUDA θ = 0.0 t-SNE-CUDA θ = 0.5 <ref type="figure">Fig. 6</ref>: Results of the experiments on the MNIST, WikiWord and Word2Vec datasets for the t-SNE, Barnes-Hut-SNE, t-SNE-CUDA and our approach. The first row shows the evolution of the execution time with increasingly bigger subsets of the dataset. The second row shows how well the objective function is fulfilled, while the third row shows the Nearest-Neighborhood Preservation (NPP). Our technique is up to two orders of magnitude faster than Barnes-Hut-SNE and provides higher quality embeddings compared to Barnes-Hut-based techniques.</p><p>in all measured datasets. <ref type="figure">Figure 7</ref> shows the results on the ImageNet datasets for our technique, BH-SNE with theta = 0.5 and t-SNE-CUDA with theta = 0.0 and 0.5. The results confirm the previous analysis, showing that our technique beats the BH-SNE by almost two orders of magnitude. t-SNE-CUDA is faster by a factor of approximately x3 on the full dataset, requiring less than 4 seconds while our approach computes the embeddings in 11 seconds. Our solution, however, shows lower KL-divergence and better precision and recall than both BH-SNE and t-SNE-CUDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this work, we presented a novel approach for the optimization of the objective function of t-SNE that scales to large datasets. We provided a reformulation of the gradient equations of the objective function that includes a scalar and a vector field. These fields represent the point density and the directional repulsive forces in the embedding space. Our approach relies on modern graphics hardware to efficiently compute these fields, obtaining linear complexity in the number of points compared to the quadratic complexity of the non-accelarated t-SNE.</p><p>In our experiments, we observe that our implementation outperforms the Barnes-Hut-SNE algorithm by several orders of magnitude. Besides the faster optimization, our technique is better at minimizing the objective function than all other acceleration methods, i.e., having a lower Kullback-Leibler divergence, and provides better Nearest-Neighbor Preservation. t-SNE-CUDA outperforms our method in computational times, but produces lower quality embeddings, and relies on NVIDIA GPUs, which limits its applicability. We provide two implementations of our technique. The first one is available in the High-Dimensional Inspector library. The library, which can be found at the following link https://github.com/Nicola17/ High-Dimensional-Inspector, is a C++ library used by several visual-analytics applications such as Cytosplore <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b42">43]</ref>. The second implementation is released as part of TensorFlow.js and can be found on GitHub at the following address: https://github.com/ tensorflow/tfjs-tsne.</p><p>As future work, we want to explore how our implementation can be integrated in Progressive Visual Analytics systems <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b39">40]</ref>, such as tools for the analysis of Deep Neural Networks. For example, the Embedding Projector 2 , TensorBoard 3 and DeepEyes <ref type="bibr" target="#b32">[33]</ref>. A limitation of the presented technique is that a graphics card is required in order to run the algorithm, which potentially restricts its applicability. In addition, our technique shares the intrinsic problems of t-SNE, such as a limited ability to reveal global relationships in the data. Therefore, we are interested in extending our approach to other techniques that better address this problem, such as UMAP <ref type="bibr" target="#b26">[27]</ref> and HSNE <ref type="bibr" target="#b31">[32]</ref>. To conclude, we believe that our technique is an enabler for more interactive highdimensional data analysis, in particular thanks to the possibility of optimizing embeddings directly in the browser.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Fields used in our approach. (a) The MNIST dataset contains images of handwritten digits and is embedded in a 2-dimensional space. The minimization of the objective function is computed in linear time by making use of a scalar field S (b) and a 2-dimensional vector field V , where (c-d) show the horizontal and vertical components respectively. The fields are computed on the GPU by drawing properly designed mathematical kernels using the additive blending function of the rendering pipeline. The rest of the minimization is treated as a series of tensor computations that are computed on the GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Functions drawn over each embedding point to approximate the scalar field S and the 2-dimensional vector field V .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Computational workflow of our approach. On the lower side of the chart, the computation of the repulsive forces is presented. The fields texture is generated by the additive texture splatting presented in Section 5.1.2. The values of S and V are obtained through texture interpolation and are used to compute the repulsive forces. The attractive forces are computed in a custom shader that takes as input the similarities P and the embedding. The gradient of the objective function is then computed using both forces and is used to update the embedding. extracting the interpolated value at the point's position in the field textures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Embeddings of the MNIST, ImageNet Mixed3a, ImageNet Head0, WikiWord and Word2Vec datasets generated by our technique.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>5 Fig. 7 :</head><label>57</label><figDesc>θ = 0.5 t-SNE-CUDA θ = 0.0 t-SNE-CUDA θ = 0.Results of the experiments on the ImageNet datasets for Barnes-Hut-SNE, t-SNE-CUDA and our approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Manuscript received 31 Mar. 2019; accepted 1 Aug. 2019. Date of publication 16 Aug. 2019; date of current version 20 Oct. 2019. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org, and reference the Digital Object Identifier below. Digital Object Identifier no. 10.1109/TVCG.2019.2934307</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Datasets used for the evaluation.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Number of points Number of dimensions</cell></row><row><cell>MNIST-60000</cell><cell>60000</cell><cell>768</cell></row><row><cell>WikiWord</cell><cell>350000</cell><cell>300</cell></row><row><cell>GoogleNews</cell><cell>3000000</cell><cell>300</cell></row><row><cell>ImageNet Mixed3a</cell><cell>100000</cell><cell>256</cell></row><row><cell>ImageNet Head0</cell><cell>100000</cell><cell>128</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 26, NO. 1, JANUARY 2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://projector.tensorflow.org 3 https://www.tensorflow.org/programmers guide/summaries and tensorboard</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors wish to thank the Google AI team PAIR for supporting the development of the TensorFlow.js implementation. This work received funding through the STW Project 12720, VAnPIRe.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Aarseth</surname></persName>
		</author>
		<title level="m">Gravitational N-Body Simulations</title>
		<imprint>
			<publisher>Cambridge Books Online</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pe&apos;er. viSNE enables visualization of high dimensional single-cell data and reveals phenotypic heterogeneity of leukemia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">D</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Tadmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Simonds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Bendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Shenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Krishnaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Nolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature biotechnology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="545" to="552" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A hierarchical o (n log n) force-calculation algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page">446</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Highdimensional analysis of the murine myeloid cell system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Becher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schlitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Sumatoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W W</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ruedl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Riccardi-Castagnoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Poidinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature immunology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1181" to="1189" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">3d dynamic grouping for guided stylization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bezerra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Decoret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thollot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NPAR 2008: Proceedings of the 6th International Symposium on Non-photorealistic Animation and Rendering</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="89" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Activation atlas. Distill</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<idno>doi: 10.23915/ distill.00015</idno>
		<ptr target="https://distill.pub/2019/activation-atlas" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Canny. t-sne-cuda: Gpuaccelerated t-sne and its applications to modern data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="330" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Evaluating semantic relations in neural word embeddings with biomedical and general domain knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC medical informatics and decision making</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Random projection trees and low dimensional manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fortieth annual ACM symposium on Theory of computing</title>
		<meeting>the fortieth annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="537" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient k-nearest neighbor graph construction for generic similarity measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Moses</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World wide web</title>
		<meeting>the 20th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="577" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Progressive analytics: A computation paradigm for exploratory data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Primet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.05162</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual analytics in deep learning: An interrogative survey for the next frontiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Hohman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pienta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cytosplore: Interactive immune cell phenotyping for large single-cell datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Höllt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Van Unen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Koning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cyteguide: Visual guidance for hierarchical single-cell analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Höllt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Van Unen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Koning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dimensionality reduction for documents with nearest neighbor queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="page" from="557" to="569" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08734</idno>
		<title level="m">Billion-scale similarity search with gpus</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A cti v is: Visual exploration of industry-scale deep neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H P</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="97" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Stochastic estimation of the maximum of a regression function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kiefer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wolfowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="page" from="462" to="466" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Pixelsne: Visualizing fast with just enough precision via pixel-aligned stochastic neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02568</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>F. Pereira, C. Burges, L. Bottou, and K. Weinberger</editor>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Information theory and statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Courier Corporation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interactive visualization of streaming data with kernel density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">D</forename><surname>Lampe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization Symposium (PacificVis), 2011 IEEE Pacific</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="171" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An introduction to latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Foltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Discourse processes</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="259" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mass cytometry reveals innate lymphoid cell differentiation pathways in the human fetal intestine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Van Unen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Höllt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Bergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Chuva De Sousa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Medicine</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visual exploration of semantic relationships in neural word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Thiagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Livnat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="553" to="562" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Umap: Uniform manifold approximation and projection for dimension reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03426</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scalable nearest neighbor algorithms for high dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Muja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2227" to="2240" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">High dimensional inspector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hierarchical stochastic neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Höllt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deepeyes: Progressive visual analytics for designing deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Höllt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="108" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Approximated and user steerable tsne for progressive visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hollt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>PP</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Remarks on some nonparametric estimates of a density function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="page" from="832" to="837" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Progressive visual analytics: Userdriven visual exploration of in-progress analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stolper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1653" to="1662" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visualizing large-scale and highdimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="287" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The future of data analysis. The Annals of Mathematical Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<biblScope unit="page" from="1" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Binnig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Palpanas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rusu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.08032</idno>
		<title level="m">Progressive data science: Potential and challenges</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Accelerating t-sne using tree-based algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3221" to="3245" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Interactive visual analysis of mass cytometry data by hierarchical stochastic neighbor embedding reveals rare cell types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Van Unen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hollt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J T</forename><surname>Reinders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Koning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P F</forename><surname>Lelieveldt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Information retrieval perspective to nonlinear dimensionality reduction for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Venna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peltonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nybo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Aidos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kaski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="451" to="490" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Data structures and algorithms for nearest neighbor search in general metric spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Yianilos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth annual ACM-SIAM Symposium on Discrete algorithms</title>
		<meeting>the fourth annual ACM-SIAM Symposium on Discrete algorithms</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="311" to="321" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
