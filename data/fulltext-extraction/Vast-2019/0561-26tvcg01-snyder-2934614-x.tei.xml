<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Learning for Identifying Relevant Tweets to Support Real-time Situational Awareness</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Snyder</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Car wreck on Taylor Loop! Social Media Post Irrelevant Relevant Relevance Classifier Interface Automated Label Verify Label</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Shan</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Car wreck on Taylor Loop! Social Media Post Irrelevant Relevant Relevance Classifier Interface Automated Label Verify Label</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morteza</forename><surname>Karimzadeh</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Car wreck on Taylor Loop! Social Media Post Irrelevant Relevant Relevance Classifier Interface Automated Label Verify Label</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Car wreck on Taylor Loop! Social Media Post Irrelevant Relevant Relevance Classifier Interface Automated Label Verify Label</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">David</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Car wreck on Taylor Loop! Social Media Post Irrelevant Relevant Relevance Classifier Interface Automated Label Verify Label</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Interactive Learning for Identifying Relevant Tweets to Support Real-time Situational Awareness</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2019.2934614</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Interactive machine learning</term>
					<term>human-computer interaction</term>
					<term>social media analytics</term>
					<term>emergency/disaster management</term>
					<term>situational awareness</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Our interactive learning framework allows users to train text relevance classifiers in real-time to improve situational awareness. In this example, a real-time tweet regarding a car accident is incorrectly classified as &quot;Irrelevant&quot;. Through the SMART 2.0 interface, the user can view its label and correct it to &quot;Relevant&quot;, thereby retraining and improving the classifier for incoming streaming data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Social media data has been used extensively in a variety of applications and research endeavors due to its ability to provide useful information on the public's opinions and behavior. Analysts in various domains are increasingly using social media to gain rapid situational awareness. For instance, first responders are leveraging Twitter data to obtain actionable information for crisis response and prevention (see <ref type="bibr" target="#b28">[29]</ref> for an extensive list of literature on this subject). However, the vast amounts of unstructured text make the identification of relevant information nontrivial, limiting situational awareness. This issue is further compounded by changes in topics of interest (to end users) over time, since the computational models built to determine relevant information for one event or one user group may not apply to other events or other user groups due to variations in diction, word structure, or user expectations.</p><p>Several classification approaches have been developed to identify relevant and irrelevant social media information, such as clustering <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, keyword matching <ref type="bibr" target="#b45">[45]</ref>, and term-vector similarity <ref type="bibr" target="#b11">[12]</ref>. However, Luke S. Snyder, Yi-Shan Lin, Dan Goldwasser, and David S. Ebert are with Purdue University. Email: {snyde238, lin670, dgoldwas, ebertd}@purdue.edu Morteza Karimzadeh is with the University of Colorado Boulder (formerly at Purdue University). Email: karimzadeh@colorado.edu to the best of our knowledge, no existing work in this area includes interactive learning with real-time data, focusing instead on improving the machine learning algorithms themselves <ref type="bibr">[5, 16, 23, 31-33, 38, 45, 46, 54]</ref> or interactively training on archived datasets <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18]</ref>. Continuing on our example of first responders, a pre-trained classifier may not fulfill first responders' varying needs, since one first responder may be interested in monitoring road closures, and another one might be interested in identifying disinformation and misinformation on social media in order to take counter-action. Ultimately, first responders' definition of relevancy will depend on the situation at hand, which can vary over time. Interactively training classifiers through iterative user labeling can alleviate this problem.</p><p>In this paper, we present a novel interactive framework in which the user iteratively (re)labels the relevancy of streaming social media data to adaptively train the underlying model to match their needs for improved situational awareness. We compare three different types of neural networks in terms of classification performance and computational efficiency for real-time learning. Furthermore, we optimize and computationally evaluate the selected models by simulating the real-time user feedback on several crisis-related datasets. Our results show that our interactive model outperforms state-of-the-art machine learning-based classification models.</p><p>To incorporate our evaluated models into a working application, we extend an existing visual analytics system tailored for situational awareness called the Social Media Analytics and Reporting Toolkit (SMART) <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b53">53]</ref>, which has been successfully used by many first responder groups in the United States. SMART allows users to interactively explore trending topics on social media through integrated topic modeling and spatial, temporal, and textual visualizations. We call the newly extended system SMART 2.0, which incorporates our interactive learning framework to address the needs raised by the aforementioned first responder users and reduce noise in the incoming stream of data.</p><p>Finally, we present domain-expert feedback on the usefulness of our approach as experienced by multiple first responders who used SMART 2.0 for crisis-related use cases. In addition, we include two usage scenarios of the system to illustrate its application to real-life situations. Overall, the major contributions of this paper are as follows:</p><p>1. We present a novel interactive learning framework for classification of streaming text data.</p><p>2. We compare three different types of neural networks in terms of performance and computational efficiency, and tune the models for learning at interactive rates. We further computationally evaluate the selected model on several disaster-related datasets.</p><p>3. We integrate our models in SMART 2.0, a visual analytics application for situational awareness, and present user feedback obtained from domain experts using the system for crisis events.</p><p>In the remainder of the paper, we discuss related work in section 2, the design of the framework and model in section 3, SMART 2.0 in section 4, evaluation of our framework in section 5, discussion and future work in section 6, and concluding remarks in section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Short Text Classification</head><p>Researchers have presented many techniques to classify text documents into categories such as sentiment or topics <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b49">49]</ref>. However, classifying short text, e.g. social media posts, is more challenging due to the lack of contextual information and loose adherence to standard grammar. To tackle the brevity of short text, auxiliary resources such as external corpora <ref type="bibr" target="#b9">[10]</ref> or knowledge bases <ref type="bibr" target="#b19">[20]</ref>, or methods such as term frequency-inverse document frequency (TF-IDF) <ref type="bibr" target="#b15">[16]</ref>, have been proposed for improving classification.</p><p>Representing words as n-dimensional vectors (i.e. word embedding) has become increasingly prevalent, since vectors can be used as inputs to machine learning models for finding semantic similarities <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b50">50]</ref>. In particular, Google's Word2Vec <ref type="bibr" target="#b29">[30]</ref> has been employed extensively in classification tasks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref> due to its impressive ability in capturing linguistic regularities and semantics. For instance, words frequently used together are likely to be closer in the Word2vec vector space than words that are not, and vector operations reveal meaningful semantics (e.g., the vector "King" − "Man" + "Woman" is close to the vector "Queen" <ref type="bibr" target="#b29">[30]</ref>). Since pre-trained Word2vec models encode embeddings learned from larger web corpora, they have been increasingly used in short text classification tasks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">44]</ref>.</p><p>Neural networks have generated state-of-the-art results in recent years for text classification problems <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b43">43]</ref> and have also been used with Word2Vec <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">44]</ref>. Neural networks are well-suited for online learning processes in which training data is supplied iteratively since they can learn adaptively from new data <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>. Nguyen et al. <ref type="bibr" target="#b32">[33]</ref> presented a convolutional neural network with Word2Vec that outperformed non-neural classifiers, and Nguyen et al. <ref type="bibr" target="#b31">[32]</ref> proposed a new online learning classification algorithm for deep neural networks utilizing the log-loss and gradient of sequential training batches. Their methods were evaluated with disaster-related datasets. However, these methods were not adapted to user-guided learning in which time constraints are essential and the provided batches may be small. In particular, the online learning method designed by Nguyen et al. <ref type="bibr" target="#b31">[32]</ref> was evaluated with batch sizes of 200. In our work, we assume the user needs to train with flexibly interactive amounts of data (10-20 samples) to view immediate predictive improvements for situational awareness.</p><p>Classification for situational awareness. Utilizing real-time social media data for situational awareness (and crisis prevention in particular) is a heavily researched topic <ref type="bibr">[16, 23, 31-33, 38, 45, 54]</ref>. However, identifying situationally-relevant information is nontrivial due to the high noise-to-signal ratio. Karimi et al. <ref type="bibr" target="#b22">[23]</ref> found that classification methods, such as Support Vector Machine and multinomial Naïve Bayes, can identify disaster-related tweets, although generic features such as hashtag count and tweet length are preferable so that the model does not learn relevancy only for a specific disaster. Researchers have used clustering <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b46">46]</ref> or enhanced keyword matching <ref type="bibr" target="#b45">[45]</ref> to detect relevant crisis and event information, and provided human-annotated Twitter corpora that can be used to train word embedding models <ref type="bibr" target="#b20">[21]</ref>.</p><p>Nazer et al. <ref type="bibr" target="#b30">[31]</ref> developed a system to detect requests for help by utilizing both tweet context (e.g., geotag) and content (e.g., URLs). Rudra et al. <ref type="bibr" target="#b37">[38]</ref> designed a novel classification-summarization framework to classify disaster-related tweets, and then summarize the tweets by exploiting linguistic properties typical of disaster tweets (e.g., combinations of situational and non-situational information). Zoppi et al. <ref type="bibr" target="#b54">[54]</ref> provided a relevance labeling strategy for crisis management that computed data relevance as a function of the data's integrity (e.g., are the geo-coordinates incorrect?), statistical properties (e.g., can we select a subset of the data that are geographically close?), and clustering (e.g., what groups are present in the data?). Toriumi et al. <ref type="bibr" target="#b46">[46]</ref> clustered tweets based on their retweet count in real-time to extract important topics and classify tweets accordingly.</p><p>The methods discussed so far, however, lack user interactivity. In particular, these classification methods are inflexible to user-dependent needs that change over time as new situations and events occur. As such, their practical use for real-time situational awareness is limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Analytics and Interactive Learning for Situational Awareness</head><p>Researchers have presented a number of visual analytics (VA) solutions for situational awareness. Diakopoulos et al. <ref type="bibr" target="#b11">[12]</ref> developed Vox Civitas, a VA application for journalistic analysis and user-guided filtering using social media content. Vox Civitas filters out unrelated data by automatically computing time-dependent term-vector similarities. Twit-Info <ref type="bibr" target="#b27">[28]</ref> aggregates streamed Twitter data and automatically discovers events from activity peaks in real-time. The authors assign relevance to a tweet by counting its number of event-related keywords. Pezanowski et al. <ref type="bibr" target="#b35">[36]</ref> designed the geovisual analytics system SensePlace3 to provide situational awareness by leveraging geographical information and place-time-theme indexing with string-based queries for exploring datasets. SensePlace3 primarily relies on TF-IDF for tweet retrieval in response to user queries. However, these tools do not employ machine learning for relevance classification and do not integrate user feedback to improve their underlying models or algorithms. Visual analytics has also been increasingly used to improve various machine learning processes, such as feature selection <ref type="bibr" target="#b12">[13]</ref>, attribute weighting <ref type="bibr" target="#b48">[48]</ref>, and labeling <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b17">18]</ref>, and even understanding the models themselves <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b42">42]</ref>. Sacha et al. <ref type="bibr" target="#b39">[40]</ref> proposed a framework to discuss the various forms of human interaction with machine learning models in visual analytics systems and theorized that VA tools could increase knowledge and usability of machine learning components. Endert et al. <ref type="bibr" target="#b14">[15]</ref> designed a system that classifies archived documents through user-guided semantic interactions (e.g., moving a document to another group) that improve the underlying model. Our work is based on the same idea in that we intend to improve model performance through user feedback, but with real-time social media data.</p><p>Heimerl et al. <ref type="bibr" target="#b17">[18]</ref> analyzed three separate methods for user-guided classification of a set of archived text documents: the basic method, which does not employ sophisticated visuals; the visual method, which visually represents the labeled and unlabeled documents for user exploration; and the user-driven method, which provides the user with full control over the labeling process. The first two methods employ active learning, in which the model selects a data sample to be labeled by the user that most effectively helps it distinguish relevant from irrelevant data. This contrasts with the user deciding which instances they wish to label. The authors did not find any statistically significant differences in terms of F 1 score between the methods in their user study. Bosch et al. <ref type="bibr" target="#b8">[9]</ref> developed ScatterBlogs2, a VA application that provides userguided learning of filter classifiers on historical social media messages to support situational awareness. These two works are perhaps the most similar to ours, yet differ in two fundamental ways. First, they do not provide interactive learning in real-time, which strains the user, as they are required to visit historical data for additional training. Second, they do not employ neural networks, which are better suited for online learning environments, such as social media streaming, in which training data is supplied sequentially over time <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>. It is important to note that Bosch et al. <ref type="bibr" target="#b8">[9]</ref> allow the user to adjust a filter's focus (i.e., how precise the classification is) in real-time if it misses relevant data or does not sufficiently filter out irrelevant data. However, this could indicate that the model has not properly learned the distinction between relevant and irrelevant data. Since training can only be completed with historical posts, the user is unable to update the model immediately with the streamed data, limiting situational awareness. Our approach not only solves this issue by allowing the user to immediately train the model for improvement, but also provides the user with the ability to create classifiers on-the-fly to accommodate their real-time needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">INTERACTIVE LEARNING FRAMEWORK</head><p>Our framework for interactively learning relevant social media posts in real-time consists of two primary components. The first is a formalized set of design goals necessary to effectively facilitate situational awareness in real-time through user interactivity. The second is a detailed underlying model that is adapted to user-guided training with real-time streaming data. In section 4, we discuss our implementation of the framework that realizes the design goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Design Goals</head><p>The framework's design goals were iteratively defined through discussions with domain experts such as first responders who frequently use visual analytic social media applications for real-time situational awareness. In general, these experts found it necessary for the interactive framework to incorporate user feedback in a timely manner, as well as account for time and situation-dependent user needs. With their feedback, the following specific design goals were established: DG1 Filter and view relevant data: Filtering data by relevancy removes noisy data, allowing the user to more quickly find data that may require immediate attention or contain important information. The ability to view the relevant data itself is equally important for determining the urgency and content of relevant data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DG2 Correct incorrect classifications:</head><p>Since classifiers may provide incorrect results, especially during the early stages of training, it is necessary for the user to be able to correct the label in realtime. This both improves the model's performance and lowers the likelihood that incoming streamed data will be incorrectly classified and missed.</p><p>DG3 Create new classifiers in real-time: The needs of the user can change dramatically over time and vary across users themselves.</p><p>As an example, one user may wish to train a classifier to find data related to a specific hurricane event to expedite identification of people in desperate need of assistance. However, another user may wish to find data related to safety in general, not just a hurricane. As such, they should each be able to create and train their own classifiers in real-time specific to their needs at the time.</p><p>DG4 Minimize model training time: Although it is important to design a high-performing model, time constraints are equally important. Specifically, when the model is trained by user feedback, the user should not have to wait for several minutes for the model to be retrained and relabel data. Previously streamed data labels may update with retraining, allowing the user to potentially find important information that they had not seen before. As such, it is necessary to provide these updated results as quickly as possible for real-time situational awareness. <ref type="figure" target="#fig_1">Fig. 2</ref> shows the three primary components of our framework's workflow applied to streaming tweets (however, the framework can be generalized to other kinds of text). First, as tweets are streamed in real-time, they are vectorized using a word embedding model. Second, the vectorized tweets are provided as inputs to the neural network classifier (discussed in next section), which outputs a set of probabilities from the activation function of the tweet's predicted relevancy and assigns an unverified relevance label. Third, the labeled tweet is relayed to the user through the user interface. If the user identifies tweets with incorrect labels, they can correct the label for the system to retrain and improve the model for relevance predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Workflow</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interactive Model Details</head><p>In the following subsections, we elaborate on the underlying representations and models used to support our interactive learning framework. We design, optimize, and evaluate our approach with the key assumption that classifiers are trained (from scratch) in real-time using user-provided labels for streaming text. We simulate this process by adding training examples in small batches of 10 and evaluating against testing data, as explained below. All simulations were completed on a server with 128 GB RAM, 32 TB of disk storage, and 2 Intel(R) Xeon(R) E5-2640 v4 CPUs at 2.40GHz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Model Candidates</head><p>Selecting the underlying model for our framework was a key task, as it must be efficiently trainable with a continual stream of user-labeled data (DG4). As discussed in Section 2, neural networks are a natural choice for online learning scenarios in which training data is supplied sequentially over time <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>. In addition, neural networks have generated impressive results with Word2Vec <ref type="bibr" target="#b29">[30]</ref> embeddings <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">44]</ref>. Therefore, we employ a neural network as our classifier to determine text relevance based on real-time training examples provided by the user. To convert the text into vector inputs (of our neural network), we use word embeddings generated by Google's Word2Vec skip-gram model <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">30]</ref>, which contains 3 million 300-dimensional word vectors pre-trained (and therefore, capturing word embeddings) on a subset of the Google News dataset with approximately 1 billion words.</p><p>In selecting the specific neural network model type, we experimented with the well-known Convolutional Neural Network (CNN) <ref type="bibr" target="#b24">[25]</ref>, Long-Short Term Memory (LSTM) Neural Network <ref type="bibr" target="#b18">[19]</ref>, and Recurrent Neural Network (RNN) <ref type="bibr" target="#b13">[14]</ref> since they have performed well in various text classification tasks <ref type="bibr" target="#b51">[51]</ref>. Hybrid architectures, such as recurrent convolutional neural networks <ref type="bibr" target="#b23">[24]</ref>, have also been proposed in recent years, but have not been made available in well-supported libraries. Therefore, we did not consider them in this paper, since our goal was to also support a well-tested SMART 2.0 system for end users.</p><p>Our CNN model contains the traditional convolutional and maxpooling layers before activation <ref type="bibr" target="#b51">[51]</ref>. Specifically, we apply a 1dimensional convolutional layer, 1-dimensional max-pooling layer, flatten the output, and then activate it with softmax and a dense layer. The filter and kernel sizes of the convolutional layer are optimized during the hyperparameter stage (explained in Section 3.3.4). We use Hochreiter's LSTM <ref type="bibr" target="#b18">[19]</ref> and the traditional RNN <ref type="bibr" target="#b13">[14]</ref> architectures as provided by Keras <ref type="bibr" target="#b1">[2]</ref>. The LSTM and RNN hidden layer each contain 300 hidden neurons and use softmax activation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Design</head><p>As mentioned before, to enable the use of neural networks for classifying text, we convert the unstructured text (of the tweets) into vectors ready for consumption by the neural network. When using Word2Vec vectors as features for classification, a common approach is to convert each word in the sentence to its vector, average the word vectors in the sentence, and then use the resulting feature vector for model training <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b43">43]</ref>. However, averaging the vectors results in the loss of syntactic information, which can negatively impact classification results <ref type="bibr" target="#b26">[27]</ref>. As an example, the two sentences "Only Mary will attend the ceremony." and "Mary will only attend the ceremony." would generate identical averaged sentence vectors since they contain the same set of words, but they differ in meaning. Therefore, to capture both semantic and syntactic information, we represent a sentence as a matrix where each row i is a 300-dimensional Word2Vec vector corresponding to word i in the original sentence.</p><p>The input to the neural network consists of the matrix representing the sentence (as described above) and the output consists of the classification labels for the input sentence <ref type="figure" target="#fig_1">(Fig. 2)</ref>. Specifically, we allow a tweet to be (1) Relevant, (2) Not Relevant, or (3) Can't Decide. The label with the highest probability from the activation function corresponds to the final label given to it. The "Can't Decide" label indicates that the tweet may or may not be relevant depending on the context. This is useful if the user finds a social media post such as "Remembering when Hurricane Irma destroyed my home..." that may not directly relate to the current event, but may be semantically relevant, and the user does not want to mark such cases as "Not Relevant". This gives the user more flexibility to accommodate their needs since the definition of relevancy will depend on both the user and the situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Corpus for Model Selection and Optimization</head><p>To experiment with different neural network model types and optimize the selected model, we used a disaster-related corpus annotated on the crowd-sourcing platform, <ref type="figure">Figure Eight</ref>  <ref type="bibr" target="#b0">[1]</ref>. The dataset contains 10,876 tweets related to different types of disaster events, such as hurricanes and automobile accidents. The data was collected using keywords such as "ablaze" or "quarantine", and therefore, covers a wide variety of disaster-related topics. Our main motivation for using this open dataset is its size (as well as topical relevance), enabling the optimization of hyperparameters and comparison of various models. In the corpus, each tweet is manually labeled by Figure Eight's workers as "Relevant", "Not Relevant", or "Can't Decide", and the distribution of labels is unbalanced. Specifically, there are 4,673 "Relevant" instances, 6,187 "Not Relevant" instances, and 16 "Can't Decide" instances. This dataset has been used in other tweet classification research projects <ref type="bibr" target="#b45">[45]</ref>. However, the researchers of that study remove the tweets with the "Can't Decide" label to improve training data quality. As explained in the previous section, we find the "Can't Decide" option useful for users to apply to cases with insufficient context for relevance determination. We randomly shuffle the data and divide the dataset into 80% training, 10% validation, and 10% testing sets.</p><p>It is important to note that we only use the <ref type="figure">Figure Eight</ref> dataset to optimize the hyperparameters and provide an initial evaluation of the model by simulating the provision of labels in real-time by the user. Since each tweet in the dataset contains true labels that were manually assigned by humans, it allows us to evaluate the model performance by comparing the model's predictions to the true labels after each training iteration. Our proposed approach as well as its integration within the SMART 2.0 system, however, allows for the creation of the models from scratch (with no prior training) (DG3), leveraging real-time labels provided by users on streaming data for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Optimization</head><p>In order to experiment with the different neural network model types, we ran several training simulations with random combinations of hyperparameters (i.e., random grid search) to see which model converged to the best F 1 score. The F 1 score is a metric widely used to evaluate the quality and performance of machine learning models and neural networks <ref type="bibr" target="#b40">[41]</ref>. It is computed as the harmonic mean of precision (the proportion of true positive predictions compared to the total number of positive predictions) and recall (the proportion of true positive predictions compared to the overall number of positive instances) :</p><formula xml:id="formula_0">F 1 = 2×precision×recall</formula><p>precision+recall . The F 1 score provides a balanced measure, combining these two performance aspects. It is therefore more informative compared to other metrics such as accuracy, especially when the training and testing sets are imbalanced <ref type="bibr" target="#b10">[11]</ref>, as in our case.</p><p>A central part of our approach to the training, validation, and verification of learning models is simulating the interactivity of visual analytics for real-time data, i.e. for use cases in which training data does not exist prior to user interaction. We assume the user (re)labels the incoming stream of data and therefore iteratively trains a model, which consequently meets their real-time needs. To replicate this process, we computationally evaluate the model's performance (as if it is successively trained by user-labeled data) by iteratively training the model with 10 new samples from the training dataset. We average the F 1 score obtained from each of these iterations and use the resulting number to measure the model's performance. In addition, we introduce a new variable, window size, for our training iterations. Specifically, due to the considerably small amount of training data provided by the user, we found that an appropriately small number of epochs (one forward and one backward pass over the training data in the model) was necessary to reduce performance degradation from initial overfitting. However, we also found that increasing the number of epochs could lead to higher F 1 scores as more data was provided. Thus, we use a sliding window of 110 samples that includes the (successively provided) new training data (10 samples) as well as the most recently used training data (100 samples) to both account for small amounts of training samples and increase the number of total training epochs for a given sample.</p><p>We use the validation data to optimize the hyperparameters for each of the CNN, LSTM, and RNN models. Specifically, after each training iteration with 10 new samples, we evaluate the neural network's F 1 score on the validation set to view its simulated performance as if it was trained by gradual user labeling. After identifying the optimal hyperparameters for each of the CNN, LSTM, and RNN models, we evaluate their performance on the testing set. <ref type="table">Table 1</ref> demonstrates the results from our validation stage. Specifically, it lists the average F 1 score obtained during each training simulation along with the total CPU time required to complete the simulation (accumulated with each training and evaluation iteration). Although in many applications, F 1 score alone is sufficient to evaluate machine learning models, it is not for ours. To see why, note that the LSTM model yields an F 1 score of 0.75, the highest of any hyperparameter combination. However, the LSTM model (with the highest F 1 score) takes approximately 4,242 seconds to complete training, whereas the CNN model (with the highest F 1 score) only takes 504 seconds. Thus, the LSTM model takes roughly eight times longer to simulate than the CNN model, but does not improve its F 1 score by a significant amount (LSTM: 0.75 vs. CNN: 0.74). In the context of interactive learning, we wish to balance the training/CPU time and performance such that the model both performs well and retrains in a short amount of time for rapid improvement (DG4). Therefore, it is necessary to consider both the CPU time and average F 1 score. With these optimization standards in mind, we chose the hyperparameters that yielded the highest F 1 scores for each model since the other hyperparameter combinations generated lower F 1 scores and higher or comparable CPU times. The selected combinations correspond to rows 1, 4, and 7 in <ref type="table">Table 1</ref> with the average F 1 scores in bold.</p><p>The testing process is identical to the validation process: after the model is trained with 10 new samples, its performance is measured by computing the average F 1 score on the testing set (using the optimized hyperparameters from the validation stage). Our results are summarized in <ref type="table" target="#tab_0">Table 2</ref>. We found that the LSTM model yielded the highest F 1 score of 0.75. The CNN and RNN models achieved a 0.73 and 0.70 F 1 score, respectively. Based on these results and the previously discussed optimization standards, we selected the optimized CNN model for our classifier. In particular, the CNN simulation not only yielded a competitive average F 1 score of 0.73, but also achieved this score 6 to 8 times more quickly than the LSTM or RNN <ref type="figure" target="#fig_2">(Fig. 3)</ref>, which is <ref type="table">Table 1</ref>. Average precision, recall, F 1 score, and CPU time for the top three performing hyperparameter combinations on each of the CNN, LSTM, and RNN models. Bold numbers correspond to the highest F 1 scores and lowest CPU times for each of the three model types. We report the recall, precision, and F 1 score to four decimal places (when necessary) to distinguish the average F 1 scores.  <ref type="figure">row 1)</ref>. This model performance may be due to the initial lack of sufficient training data and difficulty in classifying certain tweets. For instance, after examining the testing dataset, we found that many misclassified tweets were extremely short (e.g., the tweet "screams internally" was misclassified as "Relevant") or contained complex disaster-related diction (e.g., the tweet "emergency dispatchers in boone county in the hot seat" was misclassified as "Relevant"). However, as we demonstrate in the next section, our model still outperforms state-of-the-art learning models on tweet datasets.</p><p>It is worth noting that we do not save the trained model from the validation or testing stages for evaluation in the next stage (or for use with SMART 2.0). We only save the optimized hyperparameters. This is because we assume that users start training a new model (for any event or topic they choose) by labeling the incoming stream of tweets.</p><p>In this section, we optimized the model on a sufficiently large dataset that contained tweets related to several kinds of disasters. In the next section, we evaluate the model on datasets containing tweets on specific events, which is representative of cases for situational awareness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5">Evaluation</head><p>To further demonstrate the optimized CNN model's performance, we computationally evaluated it on wildfire, bombing, and train crash datasets from CrisisLexT26 <ref type="bibr" target="#b33">[34]</ref>, each of which contain approximately 1,000 tweets collected during 2012 and 2013 from 26 major crisis situations labeled by relevance. We apply a similar process to evaluate our optimized CNN model on these datasets as we did with the <ref type="figure">Figure  Eight [1]</ref> dataset. Specifically, we split the data into 50% training and 50% testing sets (to replicate the experimental setting of To et al. <ref type="bibr" target="#b45">[45]</ref>, against which we will compare our results), train the model by supplying 10 tweets from the training set at a time (to simulate user labeling of streaming data), evaluate the resulting model on the entire testing set, and then average the F 1 scores for each evaluation.</p><p>We summarize our results in <ref type="table" target="#tab_1">Table 3</ref> and graph the model's performance for retraining with 10 new incoming tweets in <ref type="figure">Fig. 4</ref>, 5, and 6. In addition, we report the average CPU times to train the model during a single iteration (10 tweets) with each dataset in <ref type="table" target="#tab_1">Table 3</ref>. Since the datasets vary slightly in size, we only compute the averages from the first 45 iterations since the smallest dataset (Boston Bombings) required 45 iterations to complete the simulation. We found that per-iteration training was fast and approximately 0.5 seconds with each dataset, which meets our timing demands (DG4).</p><p>We obtained 0.71, 0.64, and 0.88 F 1 scores for the Colorado wildfires, Boston bombings, and NY train crash datasets, respectively. Interestingly, the variance of the F 1 scores over the datasets is significant. The textual data in the Boston bombings dataset, which yielded the lowest average F 1 score, was not as easy to separate into the different relevance categories by the model compared with the other two datasets. However, the F 1 score does eventually converge towards a higher value similar to the other datasets, indicating the potential presence of outliers during the first few training iterations. In addition, we found that the simulations converged to the average F 1 scores after training with approximately 190-230 tweets, depending on the dataset, meaning that users need to label 190-230 tweets to achieve the reported F 1 scores. However, the CrisisLexT26 datasets also correspond to specific events, such as wildfires. As such, we surmise that interactively training the model on specific, well-defined events will reduce the amount of training data needed to achieve satisfactory results than with generic constraints on relevance (e.g., a classifier about safety in general).</p><p>Finally, we compare our results with the learning-based algorithm employed by To et al. <ref type="bibr" target="#b45">[45]</ref>, who also evaluated their model's performance with CrisisLexT26 datasets. In particular, their learning-based approach used Word2Vec, TF-IDF, latent semantic indexing, and logis- tic regression for classifying data as relevant or irrelevant. The authors of that study split the dataset into two equal parts: one for training and one for testing. They trained the model once (as opposed to our iterative approach) and evaluated on the testing set. Their algorithm was able to yield high precision scores between 0.85-0.95, compared to our scores of 0.64-0.86. However, their recall scores were approximately 0.22-0.45, considerably lower than our recall scores of 0.65-0.90. Therefore, our approach outperforms the learning-based model presented by <ref type="bibr" target="#b45">[45]</ref>, in terms of the overall F 1 score: our interactive approach achieves F 1 scores of 0.64-0.88 (depending on the dataset) compared to 0.45-0.64 by <ref type="bibr" target="#b45">[45]</ref>. The authors also presented a matching-based approach that achieved a much higher F 1 score of 0.54-0.92, which is comparable to ours. However, they generate the set of hashtags to be used for matching by scanning all of the tweets in the dataset. Since we assume the data is streamed in real-time, and therefore, not available altogether, we use an iterative learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SMART 2.0 4.1 SMART</head><p>The Social Media Analytics and Reporting Toolkit (SMART) <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b53">53]</ref> is a visual analytics application designed to support real-time situational awareness for first responders, journalists, government officials, and special interest groups. SMART obtains real-time publicly available geo-tagged data from the Twitter streaming API. The user is able to explore the trending and abnormal topics on various integrated visualizations, including spatial topic model visualization and temporal views. The tweet time chart and theme river visuals convey the temporal distributions of topics if the user wishes to determine how the content of streamed social data has changed over time. SMART uses string matching-based classifiers to visualize relevant data. Specifically, the user can either (a) select pre-defined filters, such as Safety or Weather <ref type="figure" target="#fig_3">(Fig. 7(c)</ref>), each using a series of related keywords for inclusion and exclusion of tweets in the subsequent topicmodeling ( <ref type="figure" target="#fig_3">Fig. 7(f)</ref>) and (geo)visualizations <ref type="figure" target="#fig_3">(Fig. 7(b)</ref>), or (b) create their own filters by supplying keywords, and intersect or union multiple filters according to their needs. However, keyword-based matching is insufficient for finding relevant information as it fails to accurately capture semantic relevance and therefore effectively filter out noisy data. As an example, if the user were to apply the Safety classifier, it would be possible for the tweets "My house is on fire!" and "I was just fired from my job." to pass through the filter since they both include the keyword fire. However, the latter is unrelated to the intended semantic context of Safety and thus dilutes the filter's quality.</p><p>To address this problem, we integrate our interactive learning framework (the focus of this paper) in the existing SMART application <ref type="bibr" target="#b52">[52,</ref><ref type="bibr" target="#b53">53]</ref> and seek domain expert feedback on the use of these models. We call the resulting extended application SMART 2.0. SMART 2.0 allows users to define string matching-based keyword filters (similar to SMART), but adds the ability for users to then iteratively refine and train the newly integrated models by labeling the filtered data as semantically relevant or not. In addition, the SMART 2.0 interface includes interactive visuals to facilitate user exploration, filtering, and refinement of relevant data <ref type="figure" target="#fig_3">(Fig. 7)</ref>.</p><p>As with the model simulations in Section 3.3, SMART 2.0's underlying models are trained with successive batches of 10 user-labeled tweets. In cases where model predictions conflict with user labels, user labels override the model's since they represent the ground truth. In addition, users should not need to manually relabel the same data multiple times. Although conflicts might indicate that the model is not sufficiently trained, the model trains with the same data during several successive iterations (as discussed in Section 3.3.4), so conflicts might be resolved after future iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SMART 2.0 Interface</head><p>The extensions to SMART 2.0's user interface, compared with SMART, concern the new interactive visuals that allow users to iteratively train machine learning models, utilize model predictions for rapid relevancy identification, and understand a model's reliability. The SMART 2.0 interface ( <ref type="figure" target="#fig_3">Fig. 7)</ref> extends the interactive features of SMART for relevance identification in three primary ways:</p><p>1. Extending the tweet table (containing a tweet's creation date and text) by including the predicted relevance label, relevance label probabilities, label modification, model training performance, and relevance filtering.</p><p>2. Extending the interactive map containing the geo-tagged tweets whose relevancy can be individually inspected or modified.</p><p>3. Altering the content of existing SMART views (e.g., topic models and spatial topic lenses) using either all data or only relevant data (as identified by the model and corrected by the user).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Table</head><p>The SMART 2.0 table <ref type="figure" target="#fig_3">(Fig. 7(g</ref>)-(j)) is extended from SMART in that it not only provides a tweet's creation date and text, but also provides the predicted relevance label <ref type="figure" target="#fig_3">(Fig. 7(i)</ref>) and the probabilities of a tweet belonging to any of the relevance classes ( <ref type="figure" target="#fig_3">Fig. 7(j)</ref>) (DG1).</p><p>In particular, the relevance of a tweet can be "Relevant", "Not Relevant", or "Can't Decide". The "Relevant" label is colored blue, the "Not Relevant" label red, and the "Can't Decide" label gray to visually The message table aggregates the tweets for efficient exploration with (g) the model's estimated classification performance (F 1 score), (h) a drop down box to filter data by their relevance labels, (i) color-coded relevance labels that can be changed by clicking on the label itself, and (j) associated relevance probabilities. Tweet map symbols are colored orange and purple to distinguish Twitter data from Instagram-linked tweets, respectively, since the latter contains potentially useful images for situational awareness.</p><p>separate tweets with different relevance. SMART's preexisting blue color scheme motivated us to use the blue, red, and gray diverging coloring for relevancy in order to maintain visual appeal and harmony.</p><p>Users can directly click on relevance labels to correct the classifier's prediction (DG2). For instance, if a tweet is incorrectly marked "Relevant", clicking the label will change it to "Not Relevant" or "Can't Decide", depending on the label the user wishes to assign. Further, a drop down box is included at the top of the relevance label column <ref type="figure" target="#fig_3">(Fig. 7(h)</ref>), which provides the option to filter out data that does not have a specified relevancy (DG1). For example, by selecting "Relevant" from the drop down box, the table will remove tweets with labels "Not Relevant" and "Can't Decide" from all views and visualizations in SMART, including geovisualizations and temporal views.</p><p>The table also displays the degree (or confidence) of a tweet's relevancy. In specific, the probabilities of a tweet being "Relevant", "Not Relevant", or "Can't Decide" are represented as a horizontal segmented bar graph and sized proportional to their respective percentages <ref type="figure" target="#fig_3">(Fig. 7(j)</ref>). In addition, the user can sort tweets based on relevancy probability in ascending or descending order.</p><p>We provide the relevance probabilities and associated sorting actions as a supplementary relevance filtering mechanism (DG1). In particular, it is possible for tweets to be classified as "Relevant" by the model, for example, but with low confidence. The probability filtering allows the user to specifically view high-confidence relevant data and therefore further reduce potentially noisy data.</p><p>The table provides a performance bar that encodes the estimated performance (F 1 score) of the underlying learning model <ref type="figure" target="#fig_3">(Fig. 7(g)</ref>), as well as the number of user-labeled tweets, to inform the user of the model reliability. Since labeled testing data is not available to evaluate the model for real-time training (because we assume the user may train on any type of event data and has their own specifications for relevancy), the model's performance can only be estimated. Based on our evaluations in Section 3.3.5 with datasets typical of situational awareness scenarios <ref type="table" target="#tab_1">(Table 3)</ref>, the Colorado wildfires dataset generated the F 1 score (0.71) closest to the average of the three datasets (0.74). Therefore, we use the Colorado wildfires dataset's logarithmic trendline y = 0.09 log e (x) + 0.22 <ref type="figure">(Fig. 4</ref>) to approximate the model's F 1 score as a function of the number of user-labeled tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Map</head><p>The SMART 2.0 map is extended from SMART in that it includes a tweet's relevance label (which can be modified) in addition to its text and creation date ( <ref type="figure" target="#fig_3">Fig. 7(d)(e)</ref>). Through the Tweet Tooltip, the user can directly click on tweet symbols on the map to view their text and associated relevancy (DG1). In addition, the user can correct the classified relevance label (DG2) by clicking on the label itself. Map inspection can allow the user to view and investigate potential geographical relevancy trends. For example, during crisis events, relevant tweets might be closely grouped on the map, so it may be more beneficial for the user to view predicted relevance from the map itself.</p><p>The interactions between the table and map are synchronized. If the user relabels data on the map, the associated new label will also be updated in the table, and vice versa. In addition, selecting a relevancy filter from the drop down box in the table filters the tweets on the map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Integration with Existing Visualizations</head><p>Many of SMART's original visualizations, such as the topic-model views, spatial topic lenses, and temporal views help users make sense of spatiotemporal text data. Therefore, we integrated all of these views in SMART 2.0 with the relevance extensions.</p><p>Users have the option to view only relevant or all the data (including irrelevant tweets) in various visualizations in case the interactive classifiers are not yet trained to desirable accuracies since, as we show in Section 3.3.5, classifiers typically require around 200 user-labeled tweets to achieve F 1 scores of 0.70-0.80. If they choose to view only relevant tweets, any relevance filtering action also updates the data used by other visuals. For example, the topic-modeling view <ref type="figure" target="#fig_3">(Fig. 7(f)</ref>) extracts the top 10 topics from the tweets and displays the most frequently used words for each topic. If the user filters out irrelevant tweets, the topic-modeling view will only be applied to the remaining relevant tweets. It is important to note that the majority of visualizations in SMART 2.0 require a minimum number of tweets in order to render. When filtered relevant data is scarce, visualizations do not populate, in which case users can individually inspect tweets. For instance, the topic-modeling view requires at least 10 tweets to extract topics.</p><p>Overall, SMART 2.0's suite of visualization tools can be used in combination with relevance interactions to further understand trends and important spatiotemporal characteristics of relevant data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">USER EXPERIENCE</head><p>In this section, we provide usage scenarios and feedback from domain experts that demonstrate our framework's effectiveness and usability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Usage Scenario 1</head><p>Alice is an emergency dispatcher interested in identifying people in need for help or hazardous locations during a hurricane. She uses SMART 2.0 to find any related social media posts near the affected area. She adds a new filter Hurricane and provides an appropriate set of filter keywords such as "hurricane", "help", "blocked", and "trapped".</p><p>After applying the Hurricane filter, she explores the filtered tweets in the table and finds a tweet labeled "Relevant" that says "Does anyone know how to get help setting up my TV?". Since the tweet is unrelated to a hurricane, she relabels it as "Not Relevant". After further browsing the table, she finds a tweet that says "The road near Taylor Loop is blocked from a broken tree.", but it is labeled as "Not Relevant". Since the tweet contains actionable information, she relabels it as "Relevant". After labeling several more tweets for model training and noticing that the model predicts correctly, she decides to only view "Relevant" tweets and sort them by most relevant. She promptly identifies a tweet posted only a few minutes ago marked as highly relevant. It reads "Car just crashed into tree blocking road near Taylor Loop!". Alice immediately notifies first responders of the location to provide assistance.</p><p>By using SMART 2.0, Alice is able to identify important, relevant data more quickly through interactively training the model to remove noise and then filtering by relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Usage Scenario 2</head><p>To demonstrate the generalizability of our framework to other domains, we applied our interactive framework in real-time during the Purdue vs. Virginia 2019 March Madness game in the Kentucky area. We assumed the role of a journalist who wanted to follow public discourse on the game by identifying the relevant tweets. We first constructed a Sports filter, which included keywords such as "Purdue", "game", "score", and "#MarchMadness". We then interacted with the streaming data by iteratively labeling the relevancy of tweets (from scratch) and found that the system correctly classified incoming data after roughly 80 training samples <ref type="figure" target="#fig_4">(Fig. 8)</ref>. We noticed that the time intervals between successive trainings increased, indicating that it was more difficult to find incorrectly labeled data towards the end and that the model gradually learned from user feedback. In particular, the interval between the first and second training iterations was 2 minutes, whereas the interval between the final two was 4 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Domain Expert Feedback</head><p>We piloted SMART 2.0 with two groups of first responders, each containing two individuals, who frequently use SMART during events for situational awareness in their operations. Both groups participated in separate 1-hour long sessions via conference call in which they iteratively trained a classifier from scratch and applied relevance filtering and visualizations to assess the implemented framework. They received a tutorial of SMART 2.0 30 minutes beforehand and were provided with web access to the system to complete the session. For both groups, we simulated the real-time use of SMART 2.0 by feeding in a stream of historical data on events (previously collected). For the first group, the system presented unlabeled tweets from the Las Vegas shooting on October 1, 2017 in the Las Vegas area. For the second group, we used unlabeled tweets from the October 2017 Northern California wildfires. We used historical event datasets to ensure the existence of sufficient training relevant samples for a situational awareness scenario.</p><p>The domain experts in the first group applied the Safety, Damage, and Security filters during the iterative training process, resulting in 317 tweets. They trained on the same underlying model for all three filters, as they considered them semantically related. In total, after relabeling approximately 200 tweets, they indicated that they could trust the model to predict accurately and were pleased that the tweets they had not seen before from the Security filter were labeled correctly. Their definition for relevancy was tweets containing actionable information. For instance, they marked tweets containing information about road closures, blood drive locations, or death counts as relevant. They labeled data with general comments regarding the shooting, such as "I hope everyone is safe now...terrible shooting...", as irrelevant since they did not provide actionable information. Interestingly, they also marked tweets that would influence public opinion (and therefore may cause action) such as those from bots or trolls as relevant since they still contained actionable information.</p><p>The domain experts from the second group followed a similar process in which they applied the Safety, Damage, and Security filters, resulting in 445 tweets, and trained a learning model for relevance. They found that after training on roughly 67 tweets, the model satisfactorily predicted relevancy. As with the first group, these domain experts labeled tweets as relevant if they contained actionable information.</p><p>The domain experts from both groups found SMART 2.0 to be easy to use and effective in identifying important data. For instance, they discovered relevant, actionable information after training the model: specific blood drive locations to aid shooting victims. Notably, the users mentioned that they felt less the need to relabel data as they progressed since the system provided more correct labels. They were pleased that they had the option to view only relevant data, but could see all of the data regardless of relevancy to avoid potentially missing important misclassified data, and that the model was responsive to user training. In addition, they found the relevance percentage bars to be helpful in determining the tweets that were potentially the most relevant.</p><p>One concern the domain experts had was that SMART 2.0 does not indicate the number of tweets that are predicted as relevant. They felt this extension could help them infer the occurrence of events or potential crises. For example, the number of relevant tweets for the Safety classifier would likely increase significantly during a widespread disaster. We plan to introduce this feature in the next development cycle. However, we have added a visualization of estimated model performance in SMART 2.0 ( <ref type="figure" target="#fig_3">Fig. 7(g)</ref>) to help users ascertain the reliability of a model's relevancy predictions.</p><p>Overall, the feedback from the domain experts was positive and helpful, indicating the system's practicality and usefulness in facilitating real-time situational awareness. In addition, they have asked to use SMART 2.0 in their emergency operations center.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION AND FUTURE WORK</head><p>Our interactive learning framework and SMART 2.0 integration were developed with the user in mind, influencing all of our design, computational evaluation, and implementation choices. Our user-centered model and SMART 2.0 application contribute to both the machine learning and visual analytics communities. We bridge the two fields by demonstrating how models can be interactively trained and evaluated while keeping the user in mind, and used to facilitate situational awareness for real-life, practical use. SMART 2.0 currently only collects English tweets, although supporting non-English languages (one at a time) with our current design (e.g., Spanish only) is straightforward since Word2Vec embeddings can be independently trained on a corpus in the target language <ref type="bibr" target="#b6">[7]</ref>. Extending our system to support multilingual tweets would be a powerful asset, especially for multilingual users, in amplifying situational awareness by leveraging relevancy of tweets issued in different languages. However, the multilingual model performance evaluation and testing is an open area for research. In addition, determining the specifics of how a single relevance classifier might be trained with multilingual tweets requires careful attention. For instance, training iterations with Spanish tweets should also affect the relevancy of semantically-related English tweets. Since similar words in different languages likely have different vector representations (embeddings), multilingual mappings must be learned or training must be performed differently, such as with parallel corpora <ref type="bibr" target="#b6">[7]</ref>. Multilingual support also requires changes in SMART 2.0's language-dependent visualizations, such as the topic-modeling view <ref type="figure" target="#fig_3">(Fig. 7(f)</ref>). Translation to a unified language or extracting topics separately for each language are two potential solutions.</p><p>The scalability of our framework is a natural concern, especially since SMART and many deployed real-time visual analytics applications contain multiple users who require responsive interfaces while monitoring crisis events. We deliberately designed the framework architecture with scalability in mind. As mentioned in Section 3.3.4, we selected the model and optimal hyperparameters based on training/CPU time in an effort to maximize the model's computational speed. Further, SMART 2.0 filters and views at most 800-900 tweets at a time, although user-specified filtering (typical in situational awareness scenarios) reduces the data to only a few hundred tweets, as demonstrated in Section 5.3. It takes only 2-3 seconds to calculate and retrieve their relevance labels over the network from the server where the model resides, and per-iteration training is fast, as established in Section 3.3.5.</p><p>Training a model during a particular event, such as a disaster, can be straightforward due to potentially larger amounts of relevant data. However, social media data during periods without major events are likely to contain very few, if any, relevant tweets. As such, if the user only trains the model on irrelevant data, it will poorly predict relevant data since it has only be taught what is irrelevant. Although the user can improve the model through training during a real-life disaster, they are required to know when and where the disaster occurs to begin training. This can be problematic if the user wishes to rely on relevancy predictions to detect hazardous situations.</p><p>To accommodate time periods in which relevant data is scarce, we plan to introduce an interactive feature in which users can provide example tweets or external resources for specific relevance labels. For instance, if the user would like to train a Hurricane classifier before a hurricane event, they could provide a relevant text such as "I'm stranded by this hurricane. Please help!". The model could then detect relevant tweets once the hurricane begins as opposed to requiring user training during the event. In addition, we plan to provide the user with the option to visit specific historical data to train existing classifiers, as done by Bosch et al. <ref type="bibr" target="#b8">[9]</ref>.</p><p>Our interactive learning performed well on target datasets (i.e., wildfire, bombing, and crash) as explained in Section 3.3.5. Specifically, it required the users to label approximately 200 tweets to achieve acceptable F 1 scores. However, tweets are short, and therefore, more research is required to investigate the suitability of our approach for "general" classifiers, such as ones that learn to classify relevant data to "safety". As safety can be affected by many events or situations, the model may need additional training that is typical of a targeted dataset.</p><p>Finally, although we rigorously optimize and evaluate our machine learning model, the hyperparameter combinations were only tuned with the <ref type="figure">Figure Eight dataset</ref>  <ref type="bibr" target="#b0">[1]</ref>. Since optimal hyperparameters can depend on the dataset itself, it is possible our model may not be optimally tuned for different datasets, even though that optimization may be negligible from a user standpoint. We did use other datasets in our model evaluation to show the satisfactory resulting performance (Section 3.3.5). Given that the Figure Eight dataset classifies generic events as relevant or irrelevant, as opposed to specific events, we expect that our model performs well on many different event types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We presented a novel interactive framework in which users iteratively (re)train neural network models with streaming text data in real-time to improve the process of finding relevant information. We optimized and evaluated a machine learning model with various datasets related to situational awareness and adapted the model to learn at interactive rates. According to evaluation results, our model outperforms state-ofthe-art learning models used in similar classification tasks. Finally, we integrated our framework with the SMART application and extended it to SMART 2.0, allowing users to interactively explore, identify, and refine tweet relevancy to support real-time situational awareness. Our discussions with multiple first responders who use SMART 2.0 indicated positive feedback and user experience. In particular, their assessments demonstrated that our interactive framework significantly improved the time-consuming process of finding crucial information during real-time events.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Manuscript received 31</head><label>31</label><figDesc>Mar. 2019; accepted 1 Aug. 2019. Date of publication 16 Aug. 2019; date of current version 20 Oct. 2019. For information on obtaining reprints of this article, please send e-mail to: reprints@ieee.org, and reference the Digital Object Identifier below. Digital Object Identifier no. 10.1109/TVCG.2019.2934614</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>High-level workflow of our framework with three main components: tweet vectorization, tweet classification, and user feedback.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>The total CPU time required for each model to complete the testing simulation. The CNN model is noticeably faster than both the LSTM and RNN models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>SMART 2.0 overview: (a) The control panel provides several filters, visualizations, and views. (b) The content lens visualization provides the most frequently used words within a selected area. (c) The tweet classifier visualization provides keyword-based filters to help reduce noisy data. (d)(e) Clicking a tweet on the map with the tweet tooltip visualization displays the tweet's time, message, and relevance label. (f) The topic-modeling view, based on Latent Dirichlet Allocation, extracts trending topics and the most frequently used words associated with each topic among tweets with specified relevancy. (g)-(j)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 8 .</head><label>8</label><figDesc>Tweets with correctly predicted relevancy from the Purdue vs. Virginia 2019 March Madness game after the user (re)labels 80 tweets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>Model Learning Batch Epochs Dropout Recurrent Filter Kernel Optimizer Average Average Average Testing results with the optimal hyperparameter combinations for the CNN, LSTM, and RNN models. The bold numbers correspond to the highest F 1 score and lowest CPU time among the three models.</figDesc><table><row><cell>CPU</cell></row></table><note>significant in terms of responding to user feedback in a timely manner. The optimized CNN model yielded 0.74 and 0.73 average precision and recall scores respectively (Table 2,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Average precision, recall, and F 1 score for three Cri-sisLexT26<ref type="bibr" target="#b33">[34]</ref> datasets.</figDesc><table><row><cell>Category</cell><cell>Average</cell><cell cols="3">Average Average Average CPU</cell></row><row><cell></cell><cell>Precision</cell><cell>Recall</cell><cell>F 1 score</cell><cell>Time (sec)</cell></row><row><cell>Colorado wildfires</cell><cell>0.72</cell><cell>0.71</cell><cell>0.71</cell><cell>0.49</cell></row><row><cell>Boston bombings</cell><cell>0.64</cell><cell>0.65</cell><cell>0.64</cell><cell>0.50</cell></row><row><cell>NY train crash</cell><cell>0.86</cell><cell>0.90</cell><cell>0.88</cell><cell>0.49</cell></row><row><cell cols="5">Fig. 4. Optimized CNN F 1 score per training iteration of 10 tweets with the</cell></row><row><cell cols="5">Colorado wildfires dataset (Table 3). The F 1 scores are logarithmically</cell></row><row><cell cols="5">fitted and intersect with the average F 1 score (0.7134) at 228 tweets.</cell></row></table><note>Fig. 5. Optimized CNN F 1 score per training iteration of 10 tweets with the Boston bombings dataset (Table 3). The F 1 scores are logarithmically fitted and intersect with the average F 1 score (0.6410) at 184 tweets. Fig. 6. Optimized CNN F 1 score per training iteration of 10 tweets with the NY train crash dataset (Table 3). The F 1 scores are logarithmically fitted and intersect with the average F 1 score (0.8792) at 191 tweets.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGEMENTS</head><p>This material is based upon work funded by the U. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.figure-eight.com/data-for-everyone/" />
		<title level="m">Disasters on social media</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keras</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Word2vec</surname></persName>
		</author>
		<ptr target="https://code.google.com/archive/p/word2vec" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">UofL at SemEval-2016 task 4: Multi domain word2vec for twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Abdelwahab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elmaghraby</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/s16-1024</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="164" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tweedr: Mining twitter to inform disaster response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ashktorab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International ISCRAM Conference</title>
		<meeting>the 11th International ISCRAM Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="354" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Beyond trending topics: Realworld event identification on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Weblogs and Social Media</title>
		<meeting>the 5th International Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="438" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">MultiVec: a multilingual and multilevel representation learning toolkit for NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bérard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Servan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pietquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Besacier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 10th edition of the Language Resources and Evaluation Conference (LREC)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparing visual-interactive labeling with active learning: An experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeppelzauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fellner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<idno type="DOI">10.1109/tvcg.2017.2744818</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="298" to="308" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scatterblogs2: Real-time monitoring of microblog messages through user-guided filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Puttmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Worner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<idno>doi: 10. 1109/tvcg.2013.186</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2022" to="2031" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Short text classification improved by learning multi-granularity topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1776" to="1781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Calibrating probability with undersampling for unbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pozzolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Caelen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bontempi</surname></persName>
		</author>
		<idno type="DOI">10.1109/ssci.2015.33</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium Series on Computational Intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Diamonds in the rough: Social media visual analytics for journalistic inquiry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kivran-Swaine</surname></persName>
		</author>
		<idno type="DOI">10.1109/vast.2010.5652922</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="115" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Visualization and interactive feature selection for unsupervised data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Dy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<idno type="DOI">10.1145/347090.347168</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="360" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
		<idno type="DOI">10.1016/0364-0213(90)90002-e</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantic interaction for visual text analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<idno type="DOI">10.1145/2207676.2207741</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;12</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="473" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Class specific TF-IDF boosting for shorttext classification: Application to short-texts generated during disasters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Desarkar</surname></persName>
		</author>
		<idno type="DOI">10.1145/3184558.3191621</idno>
	</analytic>
	<monogr>
		<title level="m">Companion of the The Web Conference 2018 (WWW &apos;18)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1629" to="1637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Twitter sentiment classification using distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">1</biblScope>
			<pubPlace>Stanford</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">CS224N Project Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visual classifier training for text document retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<idno type="DOI">10.1109/tvcg.2012.277</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2839" to="2848" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploiting internal and external semantics for the clustering of short texts using world knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<idno type="DOI">10.1145/1645953.1646071</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM &apos;09</title>
		<meeting>the 18th ACM Conference on Information and Knowledge Management, CIKM &apos;09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="919" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Twitter as a lifeline: Human-annotated twitter corpora for NLP of crisis-related messages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the 10th International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ActiVis: Visual exploration of industry-scale deep neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chau</surname></persName>
		</author>
		<idno>doi: 10.1109/ tvcg.2017.2744718</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="97" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Classifying microblogs for disasters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Paris</surname></persName>
		</author>
		<idno type="DOI">10.1145/2537734.2537737</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Australasian Document Computing Symposium, ADCS &apos;13</title>
		<meeting>the 18th Australasian Document Computing Symposium, ADCS &apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 29th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2267" to="2273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<idno type="DOI">10.1109/5.726791</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Support vector machines and word2vec for text classification with semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lilleberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/icci-cc.2015.7259377</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE 14th International Conference on Cognitive Informatics &amp; Cognitive Computing (ICCICC)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="136" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Two/too simple adaptations of word2vec for syntax problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Trancoso</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/n15-1142</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1299" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">TwitInfo: aggregating and visualizing microblogs for event exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Badar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1145/1978942.1978975</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;11</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;11</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Twitter as a tool for the management and analysis of emergency situations: A systematic literature review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Martínez-Rojas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D C</forename><surname>Pardo-Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Rubio-Romero</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijinfomgt.2018.07.008</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Information Management</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="196" to="208" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Finding requests in social media for disaster relief</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Nazer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/asonam.2016.7752432</idno>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1410" to="1413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Applications of online deep learning for crisis response using social media information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.01030</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A A</forename><surname>Mannai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03902</idno>
		<title level="m">Rapid classification of crisis-related data on social networks using convolutional neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">What to expect when the unexpected happens: Social media communications across crises</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vieweg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<idno>doi: 10. 1145/2675133.2675242</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing, CSCW &apos;15</title>
		<meeting>the 18th ACM Conference on Computer Supported Cooperative Work &amp; Social Computing, CSCW &apos;15</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="994" to="1009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A machine learning approach to twitter user classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International AAAI Conference on Weblogs and Social Media (ICWSM)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">SensePlace3: A geovisual framework to analyze place-time-attribute information in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pezanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Maceachren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Savelyev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="DOI">10.1080/15230406.2017.1370391</idno>
	</analytic>
	<monogr>
		<title level="j">Cartography and Geographic Information Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="420" to="437" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning to classify short and sparse text &amp; web with hidden topics from large-scale data collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Horiguchi</surname></persName>
		</author>
		<idno type="DOI">10.1145/1367497.1367510</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on World Wide Web</title>
		<meeting>the 17th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Extracting situational information from microblogs during disaster events: a classificationsummarization approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<idno type="DOI">10.1145/2806416.2806485</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="583" to="592" />
		</imprint>
	</monogr>
	<note>23-of CIKM &apos;15</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">VIS4ML: An ontology for visual analytics assisted machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno>doi: 10.1109/ tvcg.2018.2864838</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="385" to="395" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Human-centered machine learning through interactive visualization: Review and open challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th European Symposium on Artificial Neural Networks (ESANN)</title>
		<meeting>the 24th European Symposium on Artificial Neural Networks (ESANN)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="641" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Beyond accuracy, F-score and ROC: A family of discriminant measures for performance evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sokolova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Szpakowicz</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<idno>doi: 10. 1007/11941439</idno>
		<title level="m">Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>AI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">114</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">EnsembleMatrix: interactive visualization to support machine learning with multiple classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1145/1518701.1518895</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;09</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1283" to="1292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d15-1167</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning sentimentspecific word embedding for twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/p14-1146</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1555" to="1565" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics (ACL)</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On identifying disaster-related tweets: Matching-based or learning-based?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>To</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<idno type="DOI">10.1109/bigmm.2017.82</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE 3rd International Conference on Multimedia Big Data (BigMM)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Real-time tweet classification in disaster situation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Toriumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baba</surname></persName>
		</author>
		<idno type="DOI">10.1145/2872518.2889365</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference Companion on World Wide Web</title>
		<meeting>the 25th International Conference Companion on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="117" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">News classification from social media using twitter-based doc2vec model and automatic query expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Tran</surname></persName>
		</author>
		<idno type="DOI">10.1145/3155133.3155206</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Symposium on information and communication technology</title>
		<meeting>the 8th International Symposium on information and communication technology</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page" from="460" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Podium: Ranking data using mixed-initiative visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kalidindi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<idno type="DOI">10.1109/tvcg.2017.2745078</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="288" to="297" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hoffmann</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli.08-012-r1-06-90</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="433" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Hetzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Posse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Whiting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Havre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">O</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.1109/infvis.2004.37</idno>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization</title>
		<meeting>the IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>SPIRE InfoVis 2004 contest entry</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01923</idno>
		<title level="m">Comparative study of CNN and RNN for natural language processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Real-time identification and monitoring of abnormal events based on microblog and emergency call data using SMART</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Breunig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sheeley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/vast.2014.7042582</idno>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="393" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">SMART: Social media analytics and reporting toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Surakitbanharn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Labelling relevant events to support the crisis management operator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zoppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ceccarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lo Piccolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lollini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Giunta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Morreale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bondavalli</surname></persName>
		</author>
		<idno type="DOI">10.1002/smr.1874</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Software: Evolution and Process</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
