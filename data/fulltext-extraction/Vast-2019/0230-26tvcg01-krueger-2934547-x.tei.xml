<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Krueger</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanna</forename><surname>Beyer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Won-Dong</forename><surname>Jang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">K</forename><surname>Sorger</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
						</author>
						<title level="a" type="main">Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2019.2934547</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Clustering</term>
					<term>Classification</term>
					<term>Visual Analysis</term>
					<term>Multiplex Tissue Imaging</term>
					<term>Digital Pathology</term>
					<term>Cancer Systems Biology</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Multiple coordinated views in Facetto for interactive and hierarchical phenotype analysis of 36-channel image data (image resolution: 31, 616 × 22, 272 pixels; raw image size: 49.8 GB). (a) Phenotype tree resulting from hierarchical data filtering and cell calling. (b) Multi-channel visualization of high-resolution CyCIF image data showing the current clustering and classification results. (c) Ridgeplot of high-dimensional feature data to steer visual analysis and data filtering. (d) UMAP projection of the sampled feature space of cells, colored by cluster ID. (e) Scatterplots showing feature value correlations. (f) Table view of all cells and their features. Abstract-Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 10 9 or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A great number of diseases, including virtually all cases of human cancer, are diagnosed by histological analysis of tissue samples, most commonly by anatomic pathologists. These samples are acquired by biopsy or surgical resection and subsequently fixed, sectioned and stained prior to examination by bright-field microscopy. Histology plays a bigger role in the diagnosis and treatment of cancer than DNA There is rapidly growing interest in bio-medicine in the use of image recognition algorithms, particularly those based on deep learning, to improve the quality and reduce the cost of diagnosis <ref type="bibr" target="#b28">[29]</ref>. This is particularly true in the case of digital histology, which is being transformed by the introduction of multiplexed imaging methods that can provide precise molecular information on cells and their constituents. For example, the Cyclic Immunofluorescence (CyCIF) approach used in this work <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>, generates up to 60-plex (60 channel) images of tumors and tissues at sub-cellular resolution. In such an image, each channel is acquired by staining a tissue section with antibodies that detect specific protein antigens. This makes it possible to measure the levels and locations of individual proteins and their modified forms. Information on protein levels and localization are diagnostic of cell type (i.e., cancer, immune or supporting stroma) and state (i.e., dividing, quiescent or dying). Multiplexed tissue imaging promises to combine the proven power of histology with the molecular detail hitherto provided by genomics, which currently lacks spatial resolution, in determining whether a tumor is aggressive or benign and whether it is responding to therapeutic drugs. Analyzing the data generated by multiplexed tissue imaging is the primary challenge facing widespread adoption of the method. CyCIF datasets can contain 60 or more image channels, each 30k×30k pixels in size, with up to 10 6 or more cells of dozens of different types. Much of the knowledge needed to interpret such images is exclusively in the brains of anatomic pathologists, who are extraordinarily skilled at identifying the hallmarks of disease by eye. These factors make data analysis very challenging. It requires joint analysis of images and image-derived data and means to tap the deep knowledge of pathologists. Few software tools currently exist to assist in this task, and they rarely support a combined visual and computational analysis.</p><p>In this paper, we describe Facetto, a new software tool for interactive phenotypic analysis of large and high-dimensional image data. The overall goal of Facetto is to provide an environment in which human experts can efficiently interact with images and image-derived data and train algorithms to perform most routine image processing tasks. This will allow a much wider range of individuals to interpret multiplex images and free pathologists to review the most salient findings to advance cancer research and improve differential diagnosis. Facetto was developed using an iterative user-centered design process with pathologists, oncologists, and computational biologists as collaborators. Facetto supports any type of high-dimensional image data including those compatible with the Bioformats Standard <ref type="bibr" target="#b7">[8]</ref> and the wide variety of emerging tissue imaging methods <ref type="bibr" target="#b8">[9]</ref>, but this paper concentrates on multi-channel fluorescent images in the OME-TIFF format <ref type="bibr" target="#b1">[2]</ref> acquired by CyCIF. The software integrates expectation maximization (EM) clustering and a convolutional neural network (CNN) into an interactive image exploration interface. In a typical iterative analysis process, users leverage clustering to discover and isolate new cell types and then feed the results of clustering to train classifiers which are then used to assign labels to new image data. The visual exploration of the data is supported by several different rendering modes within an image viewer and by multiple linked feature space visualizations (see <ref type="figure">Fig. 1</ref>).</p><p>The current work makes three primary contributions. First, it applies unsupervised and supervised learning in a novel way to the task of identifying cell types and subtypes. Second, it uses a set-based data-tree visualization to hierarchically subdivide (facet) large image and feature datasets into smaller subsets and to annotate the cellular phenotypes they represent. Finally, it discusses system design and implementation based on expert feedback. Two real-world use-cases demonstrate the applicability of our approach to cutting-edge cancer research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Cellular Screening and Phenotype Analysis: A wide variety of biomedical visual analysis (VA) tools have been developed for analyzing images of cells grown in culture. CellProfiler <ref type="bibr" target="#b13">[14]</ref> is a widely-used open-source tool for cell-based screening that can segment and quantify cells grown in multi-well dishes using preconfigured pipelines. Related open-source and commercial tools include, Phaedra <ref type="bibr" target="#b52">[53]</ref>, HCSanalyzer <ref type="bibr" target="#b49">[50]</ref>, ScreenIt <ref type="bibr" target="#b21">[22]</ref>, Cytosplore <ref type="bibr" target="#b32">[33]</ref>, PerkElmer's High Content Profiler <ref type="bibr" target="#b23">[24]</ref>, and Genedata Screener <ref type="bibr" target="#b26">[27]</ref>. Few of these tools are applicable to tissue imaging where image size is typically very large, the number of different cell types is substantial, and cells are crowded closely together in a complex environment. Tissue images require a richer interactive and EDA framework in which experts can bring in domain knowledge to steer automated algorithms and evaluate results. The existing tool closest in performance to Facetto is HistoCat <ref type="bibr" target="#b59">[60]</ref>, a Matlab-based toolbox with a visual front-end for analyzing tissue images acquired using imaging mass spectrometry. The developers of HistoCat are part of our team and were involved in the Facetto evaluation. Facetto extends concepts developed in HistoCat by providing a web-based interface, by integrating machine learning (ML) into the data analysis workflow and by adding multiple forms of data faceting. Multi-modal Analysis of Image and Feature Data: Several VA tools explicitly focus on image data and feature data in combination. Bannach et al. <ref type="bibr" target="#b5">[6]</ref> use image data to extract radiometric features from radiology data that can be used for grouping patients into cohorts. Corvlò et al. <ref type="bibr" target="#b17">[18]</ref> extract features from medical image data for digital pathology, but the tool is not configured to support multi-channel images. Other multi-modal analysis approaches include tumor tissue analysis <ref type="bibr" target="#b56">[57]</ref>, medical perfusion data <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b48">49]</ref> and time-varying volumes <ref type="bibr" target="#b25">[26]</ref>. However, none of these tools are designed to work with large, high-resolution multi-channel tissues images and they do not support spatial selection and interactive ML-based analysis. Facetto also has new tools for faceting data and for visual guidance (via phenotypic trees) in the form of orienting, as defined by Ceneda et al. <ref type="bibr" target="#b14">[15]</ref>. Interactive Clustering and Classification: Clustering, an unsupervised ML technique, enables the discovery of new patterns in data, based on a defined distance function and cluster strategy <ref type="bibr" target="#b36">[37]</ref>. Supervised classification techniques learn dependencies from examples and apply the knowledge to categorize new data <ref type="bibr" target="#b22">[23]</ref>. Both approaches have been combined with interactive interfaces to select input subsets <ref type="bibr" target="#b45">[46]</ref>, actively steer algorithms <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b33">34]</ref>, understand model internals <ref type="bibr" target="#b62">[63]</ref> and input-output relations <ref type="bibr" target="#b65">[66]</ref>, and to explore, compare <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref> and refine results <ref type="bibr" target="#b16">[17]</ref>. Users are frequently involved in these processes to add domain knowledge and make final decisions for critical applications.</p><p>A less explored aspect of ML is combining unsupervised and supervised learning methods, that are "[...] two complementary concepts embedded at the very heart of visual analytics" <ref type="bibr" target="#b63">[64]</ref>. Combining them can be especially advantageous when little or no ground truth is known and there is a repetitive need to classify new data similarly. An example of a simple combined approach is classifying new instances according to nearest cluster centers (nearest neighbors) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b30">31]</ref>. A more advanced combined application involves radial basis function (RBF) networks in which cluster centroids determine the centers of input or middle-layer neurons <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b34">35]</ref>. Other approaches <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b47">48]</ref> leverage clustering for selecting representative subsets in active learning, taking into account natural breaks in the data distribution. Thom et al. <ref type="bibr" target="#b9">[10]</ref> provide both clustering to find spatio-temporal patterns and topic-based classification in a VA setup but it applies them in isolation. With Facetto we go one step further by iteratively and interactively combining clustering and classification to support reasoning <ref type="bibr" target="#b69">[70]</ref> (Section 6.4). Hierarchical Data Faceting and Provenance: A variety of methods exist to visually capture data provenance and track consecutive filtering actions during a data manipulation and analysis process. Many of these approaches follow a filter-flow metaphor <ref type="bibr" target="#b68">[69]</ref>. Prominent analysis tools include KNIME <ref type="bibr" target="#b6">[7]</ref> and Orange <ref type="bibr" target="#b20">[21]</ref>. SOMFlow <ref type="bibr" target="#b58">[59]</ref> can iteratively facet and refine clusters, with the history of previous decisions visualized in a flow graph. Alternatively, DataMeadow <ref type="bibr" target="#b24">[25]</ref> subdivides (facets) datasets into nodes, each representing a data subset whose instances and features can be visually encoded within the node. VisTrails <ref type="bibr" target="#b11">[12]</ref> provides visualizations to create and edit dataflows and support provenance management. Following the provenance types defined by Ragan et al. <ref type="bibr" target="#b55">[56]</ref>, Facetto supports recall and action recovery, enabling data subsetting and facetting and also storing the cognitive outcome and information derived from the analysis process. Scatterblogs <ref type="bibr" target="#b9">[10]</ref> also supports data subsetting, using classifiers, for social media analysis. However, unlike Facetto, it does not enable learning from subsets asnd application of the knowledge so gained to create new sets in the hierarchy. Large-scale Image Viewing: Many medical and biological visualization systems focus on the display of 2D imaging data. Deep Cell Zoom <ref type="bibr" target="#b2">[3]</ref> and the Cancer Digital Slide Archive <ref type="bibr" target="#b12">[13]</ref> support online browsing of curated biological datasets. However, both tools are pure image viewers and do not enable interactive manipulation of viewing parameters other than zooming and panning. To make image viewing and rendering scalable to large data, multi-resolution techniques such as image pyramids <ref type="bibr" target="#b29">[30]</ref> must be employed. Facetto is based on OpenSeadragon <ref type="bibr" target="#b50">[51]</ref>, a scalable web-based framework for viewing multi-resolution images. We additionally support high-precision (32-bit) segmentation masks, multi-channel rendering, and multiple rendering modes (Section 5.2). Multi-channel rendering is conceptually similar to multi-volume rendering <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b66">67]</ref>, in which multiple volumes are blended together to form a final output image, for example, using one dataset for defining opacity and another dataset for defining the output RGB color <ref type="bibr" target="#b43">[44]</ref>. Facetto supports similar rendering modes, by blending multiple channels or using a single channel (e.g., a segmentation mask) to define the rendering mode for the other channels.  <ref type="figure" target="#fig_1">Figure 2</ref> shows an overview of the CyCIF imaging process. Acquisition. Multiplex tissue imaging uses tissue samples recovery from patients for diagnosis (biopsies) or during surgery (resections). Following sectioning (typically into 5 micron thick slices) samples vary in size from a few square mm to several square cm. Almost all approaches to multiplex tissue imaging use antibodies against specific proteins to identify cells types, visualize structures within these cells, and measure the levels of specific proteins involved in regulation of cell state (the targets of such antibodies are often referred to as "markers"). In the specific case of CyCIF, chemically fixed tissue samples are stained with a mixture of antibodies each of which is chemically linked to a different fluorescent molecule (a fluorophore). Tissue samples with bound antibodies are then imaged using a high-resolution optical microscope, resulting in 16-bit four-channel images that show precisely where each antibody has bound, and thus, the locations and levels of proteins of interest. Finally, fluorophores are chemically inactivated (bleached) and another round of incubation with fluorescently-labelled antibodies is performed (often called "staining") followed again by imaging. This process is repeated multiple times (see <ref type="figure" target="#fig_1">Fig. 2</ref>, step 1), leading to 60 or more images of the same tissue. Processing. High resolution optical microscopes have limited fields of view. Thus, larger samples are acquired as a series of image tiles, which are then stitched together to form a complete image (see <ref type="figure" target="#fig_1">Fig. 2</ref>, step 2). Different fluorescence channels are registered to each other using software such as the open-source tool ASHLAR <ref type="bibr" target="#b4">[5]</ref>. This yields precisely aligned images, 30,000 pixels in each dimension, that are then segmented to identify individual cells (see <ref type="figure" target="#fig_1">Fig. 2, step 3)</ref>. Segmentation is a challenging task, currently performed using a random forest classifier <ref type="bibr" target="#b61">[62]</ref>, but is subject to continuous improvement. Segmentation information is stored in 32-bit masks that define the cell ID for each pixel in a multi-channel image stack. Next, per-cell mean intensities, area, shape, and neighborhood features are extracted for 10 <ref type="bibr" target="#b5">6</ref> or more individual cells per specimen (see <ref type="figure" target="#fig_1">Fig. 2</ref>, step 4). The resulting multichannel images, segmentation, and high-dimensional feature data are then ready for interactive analysis in Facetto (see <ref type="figure" target="#fig_1">Fig. 2</ref>, step 5). Terminology and Data Characteristics. For the remainder of this paper, we assume that a CyCIF dataset contains (1) a multi-channel tissue image, (2) a segmentation mask, and (3) a feature table of image-based features in csv format. Each image (or channel) in the multi-channel image stack represents data from a different antibody stain. The segmentation mask spatially locates individual cells in each tissue specimen and assigns cell IDs. Each row in the csv file (i.e., instance) is identified by its cell ID and also contains the extracted feature values for that cell. Features represent either expression levels (i.e., average intensity for specific cell in a specific channel), subcellular morphological features, or spatial features involving multiple cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MULTIPLEX TISSUE IMAGING WORKFLOW</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GOAL AND TASK ANALYSIS</head><p>To better understand the goals and tasks associated with the analysis of multiplex tissue (CyCIF) data, we conducted in-depth, semi-structured interviews with ten domain experts. All of them are affiliated with the Harvard Laboratory of Systems Pharmacology. Two experts are oncologists (hereinafter referred to as O1, O2), two are pathologists (P1, P2), and six are cell and computational biologists (CB1-6). Additionally, we participated in weekly group meetings over several months during the development of Facetto and the acquisition of initial datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">User Roles and Goals</head><p>Oncologists are physicians who diagnose and treat cancer and have direct contact with the patients they treat. The oncologists involved in this project are also research scientists active in understanding the molecular basis of diseases such as melanoma, breast, and lung cancer. Their primary clinical goal is to identify optimal treatment regimens for individual patients; their primary research goal is understanding the molecular basis of drug response and resistance.</p><p>Pathologists are physicians who analyze tissues and biological samples to diagnose disease. Anatomic pathologists primarily use microscopes in their work and have unique expertise in understanding the complex features of histological preparations that are diagnostic of specific diseases. The pathologists involved in the project are also research scientists and, within the CyCIF team, have a special role in guiding and checking work performed by other investigators and by computer algorithms. Their primary clinical goals are distinguishing diseases from each other (differential diagnosis) and working closely with oncologists on treatment strategies; their primary research goal is understanding the role played by tumor cell type and state and the tumor microenvironment in disease processes and response to therapy. Cell and Computational Biologists combine biomedical knowledge with skills in technical subjects, ranging from mathematics and physics to computer science. Within this project they are responsible for developing the CyCIF methods, for collecting primary data and for processing this data to create stitched images, segmentation masks and sets of derived features (Section 3). They develop analysis scripts and apply a variety of computational methods to image and numerical data. The cell and computational biologists involved in this project are trained in interpreting the morphologies of cells, but they do not have the pathologists' deep knowledge of tissue structure and disease.</p><p>The three user roles are dependent on each other, as cell and computational biologists are typically guided in their interpretation of tissue data by physicians and physicians are dependent on biologists for wet and dry method development, data transformation, and analysis. Facetto is designed to support close collaboration and interaction among pathologists, oncologists, and cell and computational biologists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tasks and Challenges</head><p>From interviews with experts, we derived a series of tasks that need to be performed on images to meet the overall goals of understanding cancer biology and diagnosis of disease in individual patients. Along with these tasks, we identified gaps and challenges that currently hinder the analysis of tissue imaging data. T1: Cell Type Discovery and Calling. The task most frequently mentioned by all experts is identifying and analyzing specific types and states of cells based on the intensity and pattern of staining with specific antibodies (O1, O2, P1, P2, CB1-6). Challenges: Challenges lie in processing, displaying, and faceting the large and high-dimensional data, as well as in mutual support of manual and automated analysis. A lack of adequate tools makes this task very time-consuming at present. T2: Overview-Detail Exploration of Multi-Channel Image Data. A crucial task for oncologists and pathologists is rapid navigation and visualization of multi-channel images (O1, O2, P1, P2). Pathologists are accustomed to moving slides back and forth physically on a microscope stage and switching between high and low power views. They rely on a seamless visual experience to make a diagnosis. Challenges: Image analysis must not only support seamless pan and zoom, but also switching between groups of channels. Current tools do not scale beyond 4-5 channels and lack on-demand rendering, blending of channels, and means to emphasize (and recall) regions or individual cells of interest. T3: Data Filtering and (Sub-)Structuring. Another task frequently performed by pathologists is gating, which refers to manual filtering of selected image channels based on the channel's intensity value range (often visualized as a frequency-intensity plot), or specific spatial features or regions of interest (P2, O2, CB2). Challenges: Analysis steps such as gating are often applied in an iterative manner in which the data is hierarchically faceted into subsets. These subsets can then be further analyzed, used in benchmarks, or exported for presentation or reuse with other samples. Thus, tracking the evolution and provenance of gates and gated data is important. T4: Proofreading and Analyzing Results in Spatial Context. Many algorithms operate on features computed from images following segmentation; these include mean intensity value per cell and channel. Feature extraction and segmentation from tissues, in which cells of different sizes and shapes are crowded together, are challenging tasks for which software tools are still being developed. As a result, it is essential that the results of feature extraction are checked and corrected prior to downstream data processing (CB1, CB3). This requires effective means to link feature and image space (P1, O1). Challenges: Currently, such linking is only supported by HistoCat <ref type="bibr" target="#b59">[60]</ref>, and generally requires domain experts to continuously switch between tools (CB2). T5: Deriving Profiles for (Sub)regions and Classes. Once a type/region is detected, it is important to identify, annotate, and extract a profile of typical marker distributions within an area of interest (O2, P2). The profile includes statistical measures and distributions of cell features and can be used to present the outcome of an analysis session, diagnosis, or as a starting point for further analysis. Challenges: The variables used to construct profiles, and the ways in which these variables are displayed, are not standardized and can only be developed by human-machine interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VISUAL EXPLORATION OF CYCIF DATA</head><p>We used the tasks of Section 4 to guide the design and implementation of Facetto, playing the translator role put forth in the design study methodology by Sedlmair et al. <ref type="bibr" target="#b60">[61]</ref>. <ref type="figure">Figure 1</ref> gives an overview of Facetto's interface. Using the image viewer, users can explore spatial features (T2), hierarchically facet the data into subsets (T3), and look at profiles of cell phenotypes and spatial regions (T5). Classification and clustering can be triggered in different views to support the hierarchical discovery of cell types (T1). To proofread and analyze results (T4), we have implemented features such as image tool-tips and an interactive sortable table for cell features. The table view gives details on individual cells and supports manual manipulation of cell feature data. A key design goal is preventing feature overload and effectively guiding users through specific, repetitive tasks. The Facetto image viewer is therefore surrounded by tools that can be activated and deactivated as needed. We now present and justify these design and implementation decisions in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data Faceting and Hierarchical Analysis</head><p>Cell type discovery and labeling (T1) is an iterative process. Experts usually start with a region of interest (ROI) at high resolution (so that individuals cells are visible) that represents a subset of the complete multi-channel image stack and then define spatial and image features to create data subsets of interest (T3). The results obtained on this ROI are then applied to the entire specimen. We support multiple iterations of this process with hierarchical data faceting. Users can build up a hierarchy of different data subsets, and we automatically display this ongoing analysis in a hierarchical phenotype tree view. This allows users to track their progress, and to maintain an overview of their data faceting and analysis steps they have performed (T5) (i.e., allowing users to look up results from past analysis steps to recover or re-execute them with a different image or in a different setting). <ref type="figure" target="#fig_3">Figure 3</ref> shows the visual representation of our faceting approach, a so-called phenotype tree, an interactive n-tree visualization. At the  beginning of an analysis session, the tree holds a single root node representing the entire dataset. From region and feature-based selections, users are able to create new subsets and store them as child nodes in the tree. We have integrated algorithms (Section 6) that make it possible to further divide the active data subset into classes and clusters, which can again be stored as new nodes in the tree. In contrast to many automatic data lineage systems, we allow domain experts to manually decide which subsets are meaningful and to add them to the phenotype tree. We provide a context menu that makes it possible to activate a node's subset (i) for use as the current data (sub)set across all views in Facetto (ii) to delete a subset/node, and (iii) to create new nodes, e.g., from selections or classification results. To improve semantic understanding and recall, users can name, color, and annotate each selection. Facetto can also derive visual profiles (T5) for each discovered (sub)region and class. <ref type="figure" target="#fig_3">Figure 3</ref> shows an entire phenotype tree (left) and an exemplary snippet (right) with an active node (denoted by the presence of a halo) containing active selections (orange fill line showing the number of cells in the selection). It descends from a spatial selection and is the parent to a clustering result with three detected subgroups, representing different immune cell types. All views in Facetto support this faceting approach by being able to display either the entire dataset, the active subset, or the current selections a user is working with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Image Exploration</head><p>Facetto's image viewer allows users to navigate and explore large multichannel image data (T2) using a scalable multi-resolution visualization approach. We store segmentation masks at the same resolution as the image data but in a 32-bit integer format to support the large number of cells in each image. A resection specimen imaged in 60 channels with its associated segmentation masks represents 60 GB of data.</p><p>To support interactive image exploration we employ a multiresolution rendering approach. In a pre-processing step, an image pyramid is computed for each channel by repeatedly down-filtering the original data. We use bicubic downsampling to maintain smooth gradients in the lower resolution images. We also create an image pyramid of the cell segmentation mask.   IDs at lower image resolutions, we perform downsampling by nearest neighbor filtering. To ensure fast data loading times, each resolution level in the image pyramid is further split into smaller image tiles of a fixed resolution (e.g., 130×130 pixels) and stored on disk. <ref type="figure">Figure 4</ref> shows our different image pyramids and rendering options.</p><p>Multi-Resolution Image Viewer. Our image viewer is based on OpenSeaDragon <ref type="bibr" target="#b50">[51]</ref>, an open-source, web-based image viewer library. To support the visualization of CyCIF data, we added support for image tile caching, segmentation masks, multi-channel rendering, and advanced selection and filtering capabilities. During rendering, the image viewer determines the required tiles for the current viewport, zoom level, and active image channels. If the tiles are not in the cache (i.e., they have not been loaded yet, or have been purged), the tiles are requested, loaded, and transferred to the viewer. Tiles are rendered asynchronously, which ensures that the application remains responsive even if very large datasets are being loaded in the background or if the network connection is slow. The visualization is updated automatically whenever a new tile has been loaded. We also support interactive transfer functions (i.e., color look-up tables) to allow users to adjust the visual representation of the displayed image data. This is likely to become increasingly important as color mapping of histological data is subject to government regulation <ref type="bibr" target="#b51">[52]</ref>. <ref type="figure" target="#fig_5">Figure 5</ref> shows a single-channel image <ref type="figure" target="#fig_4">(Fig. 5a</ref>) as well as different zoom levels in a multi-channel rendering ( <ref type="figure" target="#fig_5">Fig. 5b-d</ref>) of a CyCIF dataset with 376,286 cells.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Channel Rendering.</head><p>To analyze the image data (T3, T4), we visually encode features of interest and subsets of the data. To make spatial distributions and correlations among multiple channels preattentively visible, we allow the user to blend the data from different channels into a single image (see <ref type="figure" target="#fig_5">Fig. 5b-d)</ref>. Users select the appropriate channels for their current tasks based on domain knowledge. For multi-channel rendering, we first retrieve pixel intensities for each (x,y) position in the selected image channels and then apply linear color and opacity transfer functions to the individual channels. We blend the contributions of the individual channels to get the final RGBA (i.e., color plus alpha) output for that pixel. Facetto supports different blend modes of the individual channels, such as alpha compositing, addition, or multiplication <ref type="bibr" target="#b54">[55]</ref>. When mapping up to three concurrent channels (default colors are red, green, and blue) Facetto can guarantee nonoverlapping colors. However, after feedback from domain scientists, we added support for up to five concurrent channels, which allows users to look at additional channels that have no spatial overlap. For each channel, users can set and modify a linear color and opacity transfer function by specifying the respective intensity range (i.e., lower and upper bound) as well as the colors of the transfer function.</p><p>A caveat of multi-channel rendering is that mixing different colors at pixel level makes detailed interpretation of the resulting pixel color difficult, as RGB colors are not distinct perceptual channels <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b64">65]</ref>. However, after speaking to our experts we found that this multi-channel color mapping is state-of-the-art in cell-based image analysis, and our domain scientists expect, and heavily use, this feature in visualization tools. Furthermore, domain experts most commonly combine channels that have almost no spatial overlap (e.g., two antibodies that stain different types of cells or non-overlapping structures). Usually, three of the five possible mixed channels are well separated visually, and five channels are still informative if spatial overlap is limited. To assist in evaluating overlap, users can quickly toggle the visibility of individual channels. <ref type="figure" target="#fig_5">Figure 5b-d</ref> shows a multi-channel visualization of channels pS6 (a ribosomal protein whose phosphorylation state is a measure of cell signaling), HES1 (a transcription factor) and DNA. Cell-based Rendering. The tasks of interactive exploration and filtering (T2, T3) also require support for dynamic selection of cells and their visual display in image space. This requires a means to convey that cells in a ROI are part of a currently selected subset. To support the visual selection and highlighting of individual cells, we use the segmentation mask (Section 3) to determine the cell ID associated with each pixel. Next, we dynamically adjust the render mode based on the current pixel's cell ID. Facetto supports different render modes, depending on whether the user is currently focusing on the entire dataset, a subset (i.e., a node in the hierarchical phenotype tree), or a user selection (i.e., based either on manual selection or a clustering/classification result). Facetto can then display individual cells in their original grayscale intensity, apply a color and opacity transfer function (see <ref type="figure" target="#fig_5">Fig. 5d, bottom)</ref>, or show color overlays for cluster/class membership (see <ref type="figure" target="#fig_5">Fig. 5d, top)</ref>. Focus and Context. To reveal contextual feature information for an individual cell or for a selection, users can click on a cell in the image viewer and show a visual profile card in which data statistics are summarized (T5). The card shows a boxplot of the feature space, the phenotype labels, and a short summary that includes any previous user annotation, making it possible for information to be acquired sequentially over a number of sessions involving multiple users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Feature Space Exploration</head><p>The image viewer makes it possible to blend different image channels to reveal spatial structures and patterns, but analyzing the multivariate dependencies in the data remains difficult. During the image preprocessing step we extract features for each segmented cell (Section 3) such as mean intensity for each cell in each channel, cell area, shape, and neighborhood features. To enable in-depth analysis of these fea- tures (T3, T4, T5), we provide a set of visualizations that display the feature values and value ranges for an active selection of cells. We also represent cell similarity and distributions for subsets and selections in feature space. Finally, we provide means to investigate and manipulate individual cell values in an interactive tabular display. Exploring Feature Distributions. For the exploration of each channel's distribution, we integrated a ridgeplot (see <ref type="figure" target="#fig_6">Fig. 6</ref>) that comprises multiple area charts alongside relevant information about the variable being examined (T5). Each chart represents a feature's value distribution (a ridge). Typically, the distribution of features that are derived from a channel's intensity values is skewed, having a few distinct peaks and some outliers. We, therefore, apply square root scaling to make dense regions in the intensity distribution more visible and reduce visual peaks. Each ridge is equipped with range sliders, allowing to filter the underlying data with visual feedback at the level of the distribution (T3). The selection range is used directly for specifying the color transfer function applied in the image viewer. To allow the exploration of feature distributions for subsets of the image or individually selected cells, we overlay the parallel x-axes in the ridgeplot with vertical polylines (see <ref type="figure" target="#fig_6">Fig. 6</ref>, orange paths), encoding each cell's features as a connected path, similar to parallel coordinate plots <ref type="bibr" target="#b35">[36]</ref>. To reduce clutter, we decrease opacity as the number of selected cells grows, an approach that provides an indication of the correlations and distribution ranges of a selection, while focusing less on individual cells. Alternatively, a single polyline can be used to represent the mean values of a cluster. Exploring Individual Cell Features. Experts can sort, inspect, select, and manipulate individual values for each feature of a cell using the interactive visual tabular display (see <ref type="figure">Fig. 1f</ref>). The main goal of the tabular view is a) detailed analysis and direct manipulation of individual cells, and b) allowing users access to the original data table. We encode the extracted intensity values in the tabular view as numbers, as well as by using small multiples of bars. The tabular view is also color encoded, with each color indicating a distinct phenotypic class. All views in Facetto are connected via brushing and linking so that users can analyze a selection from different perspectives. In this way, users can mark (and edit) individual cells with certain features in the tabular view and inspect spatial context in the image view or vice versa (T4). Dimensionality Reduction of High-Dimensional Features. We visualize higher-order similarities and differences between data subsets (T5) using dimensionality reduction techniques and subsequent display in a 2D scatterplot. We use UMAP (uniform manifold approximation and projection for dimension reduction) <ref type="bibr" target="#b44">[45]</ref>, a recently developed machine learning technique, to display features of the current data subset (see <ref type="figure" target="#fig_7">Fig. 7b</ref>). This algorithm is similar to the popular t-SNE projection <ref type="bibr" target="#b42">[43]</ref> but preserves more of the global structure and has superior run time performance <ref type="bibr" target="#b67">[68]</ref>. We have found that UMAP works particularly well on multiplex-immunofluorescence data from tissue sections <ref type="bibr" target="#b67">[68]</ref>. Users can also switch to displaying the first two components of a PCA (principal component analysis); this is faster to compute for very large datasets. The data is visualized in gray, and active selections are shown in orange or are visually encoded by their phenotype (class/cluster) color. The projection reveals how well certain cell groupings cluster or separate from each other. Our domain experts are very familiar with dimensionality reduction techniques. Hence, this is a valuable means to discover and review phenotypes and to discover novel cell sub-populations with similar staining patterns. We support filtering of cell groupings in our projection views by polygon selection, similar to the image-based selection mechanisms (Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SEMI-AUTOMATIC PHENOTYPE ANALYSIS</head><p>We developed a novel semi-automatic approach to cell state analysis for CyCIF data. It supports data faceting (T3) with unsupervised and supervised machine learning methods that are tightly integrated into Facetto's visual interface. This allows domain experts to steer, review, and manipulate the outcome of those automatic methods (T4). Specifically, we leverage clustering as a means to discover novel cell subtypes (T1) and acquire new knowledge, and classification as a means to propagate the learned cell types/states across CyCIF images (T1). We close the loop by allowing users to set the output of one method as the input to the other method in an interactive manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Unsupervised and Supervised Learning Loop</head><p>Both clustering (unsupervised) and classification (supervised) facet data into subsets by assigning labels to cells. These labels denote categories or classes and are completely independent of the cell IDs used by the image segmentation mask (Section 3). When there are many unknown aspects of an image and dataset (e.g., a different patient, a new type of cancer, or new immuno-fluorescence antibodies), a bottom-up analysis strategy <ref type="bibr" target="#b53">[54]</ref> is often considered the best approach. Clustering is then a helpful means to identify similar cell types and states and to segregate them from each other. After carefully reviewing and adjusting the clusters for a smaller subset, a user can then apply the optimal faceting strategy to other cell subsets. This is accomplished by using the labeled data to train a CNN model and subsequently apply it to new data. Having a dataset classified and faceted into broad categories (e.g., cancer, immune, and stromal cells), users may want to further subdivide the data to arrive at more fine-grained subtypes. This may include subdividing all immune cells into their different myeloid and lymphoid subclasses by examining antibody staining of cell lineage markers (e.g., CD3 for T cells, B220 for B cells, etc.). Clustering in Facetto runs on feature data, while classification runs on the original image data. This makes the classification step more expensive, but has the advantage of incorporating data from full high-resolution images.</p><p>To limit cognitive load in the approach outlined above, Facetto allows users to track and review machine learning results and decisions and quickly access subsets of the data on which to train and apply ML methods by means of hierarchical faceting and the phenotype tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Expectation Maximization Clustering</head><p>To assist exploratory discovery of cell types, Facetto includes EM clustering <ref type="bibr" target="#b19">[20]</ref>, a partitioning method that iteratively computes maximum likelihood estimates using a Gaussian mixture model. The method assumes that the data is sampled from an underlying statistical population that can be expressed by an analytic distribution. Each iteration consists of an expectation step E and a maximization step M. E estimates the distribution of the underlying population from an available sample, given a certain fixed model. M finds means and variances of Gaussian mixture components that maximize expected log-likelihood of the observed data and hidden variables. These steps are alternated until the log-likelihood changes fall below a given threshold. EM clustering has several advantages over other clustering approaches, such as k-means and DBSCAN: It can find clusters of different size, density, and shape. However, Facetto also allows easy integration of other methods. <ref type="figure" target="#fig_8">Figure 8b</ref> depicts our clustering pipeline with each cell represented by features. A user first defines the input instances (cells) and features to be considered. We normalize the selected features using a log 10 transform and percentile normalization, which are standard in singlecell image analysis. In percentile normalization, we transform [0.1%, 99.9%] values to [0, 1], and truncate outliers. We then apply EM clustering with k clusters, where k is selected by the user. The results can then be reviewed and manipulated. Users can apply domain knowledge to re-label certain cells or to further split clusters into smaller subsets (subtypes). To judge cluster quality, users can inspect cluster separation in high-dimensional space using UMAP (see <ref type="figure" target="#fig_7">Fig. 7b</ref>) and investigate silhouette coefficients across multiple clustering runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Classification via Convolutional Neural Network</head><p>To classify cells based on pre-defined types as well as those discovered through clustering, we have integrated a deep-learning convolutional neural network (CNN) into Facetto. <ref type="figure" target="#fig_8">Figure 8c</ref> illustrates our cell classification pipeline. The inputs are a multi-channel input image and a segmentation mask of cell IDs. The network yields probability maps for each cell type as an output. We convert the probability maps into classification labels for each cell by applying a softmax function and aggregating cell-type probabilities for each segmented cell. Network architecture. Our CNN consists of an encoder and a decoder with skip connections <ref type="bibr" target="#b57">[58]</ref> to exploit low-level and high-level features. The encoder has 8 convolution layers with 3×3 filters and 3 pooling layers, decreasing spatial resolutions to increase receptive fields. We built the decoder using 9 convolution layers, 9 filters, and 3 deconvolution layers. The deconvolution layers restore the original spatial resolution that had been decreased by the pooling layers. Training. We train the network by accepting images of cells and their ground truth cell type labels as annotated by experts, such as 'cancer,' 'immune,' and 'stroma.' This ground truth can be derived from manual labeling or from the result of a previous EM clustering run. Due to computational complexity, we divide the entire image into tiles and load only the tiles with ground truth data to train the network. We minimize a softmax cross entropy between predictions and their ground-truths using the Adam optimizer <ref type="bibr" target="#b37">[38]</ref>. Parameters in the network are randomly initialized and the learning rate is set to 0.001. To judge the quality and trustworthiness of the trained classifier we display the prediction accuracy and precision and recall in a confusion matrix. Application. Once trained, users can apply the classifier to selected data subsets. As in the training step, a user defines a set of cells to be classified. We then compute which tiles need to be loaded (i.e., all tiles that contain any of the selected cells), using a quad-tree acceleration structure. We then classify each cell in the loaded tiles. Subsequently, the results are filtered to match only the requested labels to be displayed. Users can visually inspect results and manually sort out or relabel questionable cell classifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Expert in the Loop</head><p>Facetto is an "expert in the loop" system designed to exploit the domain knowledge of pathologists and cell biologists while automating routine tasks and supporting quantitative analysis that is not possible by eye alone. In Facetto, experts configure automated approaches (e.g., by selecting input instances and features) and directly analyze results. Algorithms can be triggered by active selection through the visual interface. When the result is available, the interface updates to show results and also provide contextual scales and information on accuracy. By default, each new cluster or class is assigned a name (label) and a distinct color from a categorical color scale. This color can be used to display cluster membership of cells in the image viewer. Alternatively, users can toggle the render mode to multi-channel rendering of the original image channels. Users can move back and forth between an image viewer providing information on the spatial distribution of the cell types (classes/clusters) and various feature-based visualizations revealing the distribution of image-derived information in high-dimensional space. For example, if UMAP indicates that clusters 1 and 2 are well separated, while cluster 3 is more connected to cluster 1, users can rerun the clustering with a different number k of clusters. Brushing and linking allows users to drill down to individual instances, and to review and relabel selected values and assigned classes in the image and table view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">IMPLEMENTATION</head><p>Facetto is a web-based client-server system. The back-end is implemented with Flask, a python microframework for web development. The stateless back-end provides a restful interface, making it possible to retrieve image and feature data, and steer analytics. Facetto's components are based on a modular design, where new computational methods can be plugged in, and called by defining new restful endpoints. Clustering, classification and UMAP computation are implemented in Tensorflow <ref type="bibr" target="#b0">[1]</ref>. Clustering, training, and classification of 10 3 cells takes 0.05, 25, and 20 seconds respectively. We intend to further optimize training time to enable a more interactive experience. Facetto's frontend runs in the web browser and is based on Javascript, HTML, CSS and D3.js. The image viewer extends OpenSeaDragon (see Section 5.2) for client-side dynamic rendering in the browser. Scalable scatterplots are implemented in hardware-accelerated HTML canvas views.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EVALUATION</head><p>We present two case studies that demonstrate how Facetto can accelerate and improve the analysis of multiplex tissue images. Both evaluations were carried out in a small meeting room with Facetto displayed on a wall monitor. We collected think-aloud feedback and logged user analysis steps and actions. We also collected regular feedback on the tool's usability from a computational biologist using Facetto for her research. In the case studies described below, we followed the visual analytics evaluation protocol developed by Arias-Hernandez et al. <ref type="bibr" target="#b3">[4]</ref>.: while the domain experts guided and steered the analysis, we operated the user interface. This approach allowed us to evaluate the capabilities and limitations of our approach on cutting edge research tasks and questions rather than simply collect feedback on details of the interface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Use Case 1 -Exploratory Data Analysis (EDA)</head><p>In Proofreading. The team started the analysis by looking at the segmented cells in the image viewer. We activated the channel corresponding to nuclear DNA and then added other channels. Our users had not previously been able to interactively explore segmentation masks aligned with image data. Using Facetto, users were able to identify immediately some segmentation errors involving incorrect cell merging and splitting (T4). Using the tabular data view, they sorted the cells based on their size, used brushing to select the largest cells, and then inspected these cells in the image viewer. These "large" cells were commonly ones in which the segmentation algorithm had failed to separate individual cells that were in close contact. Users then utilized clustering (based on cell size) to analyze different types of segmentation problems (i.e., boundary errors vs. overlapping nuclei). Using Facetto, it was simple to exclude these cells from subsequent analysis. Phenotype Analysis. Next, our users explored simple cell phenotypes within the lung specimens. To spot tumor and immune cells (T1), they leveraged Facetto's multi-channel rendering. Users first looked at the distribution of nuclei (bright structures in the DAPI channel), and a single tumor marker (Keratin). Next, they added the channel for a protein that marks proliferating cells (Ki-67) and for a stromal cell marker (aSMA). By toggling channels on and off, it was possible to confirm the expected patterns of co-staining and marker exclusion. Next, one expert identified an area with a high concentration of immune cells lying at the border of the tumor (T2). By activating different channels related to immune cell markers (CD4, CD8a, FOXP3), users were able to visually assess the spatial distribution of two functionally distinct types of immune cells (Cytotoxic T-cells and Regulatory T cells). The ratio of these cell types is widely thought to play a role in the susceptibility of different cancers to the latest generation of immuno-oncology drugs, and is therefore important to estimate reliably. Our users then selected a spatial region in the heart of the tumor with the polygon tool and turned to clustering. They asked us to run clustering on markers for tumor cells (Keratin), immune cells (CD45), and cell size, to distinguish tumor and non-tumor cells (T3, T4). We clustered the tumor subset further based on Ki67 staining and iteratively increased the cluster number to k = 5. After confirming in the image viewer that these five clusters corresponded to different types of proliferating tumor cells (as judged by toggling color-coded cluster overlays), we labeled corresponding nodes in the phenotype tree and then studied the nodes in more detail (T5). By looking at the UMAP, users confirmed a clear separation among clusters. Feedback. Users were excited about Facetto's proof-reading and analysis capabilities and found the interface more intuitive and responsive than any existing tool. They stated that the interaction between image viewer and feature analysis was essential for identifying meaningful combinations of overlapping cells. The pathologists were more skeptical than other users about automated classification and its applicability to infer cancer subtypes, but considered it a useful way to examine large datasets. The ability to interactively review classification results is likely to be important for these users. Users relied heavily on Facetto's multi-channel rendering and observed that the flexible transfer functions involving use of a histogram to set upper and lower bounds in the rendered image helped a lot (CB3). The color overlay of cluster results was also perceived as intuitive, since Facetto uses visually distinct colors for transfer functions and clustering. To reduce clutter in ridgeplots, users wanted to toggle between a detailed view (one vertical polyline per cell) and an overview (one polyline per cluster).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Use Case 2 -Ovarian Cancer Phenotype Analysis</head><p>In a second use case we analyzed images of ovarian cancers over a span of two hours, guided by a gynecologist/oncologist (O2), and a medical informatician with six years of experience in cancer research (CB4). The goal was to explore ovarian cancer-specific spatial patterns. Dataset. Our users examined two datasets involving 40-channel images of serous ovarian cancer resections. The first dataset (D1) contained 5,273 successfully segmented cells and was 5, 666 × 9, 306 pixels in size (4.1 GB). The second dataset (D2) contained 358,380 segmented cells and was 22, 703 × 14, 841 pixels in size (26.4 GB). Proofreading. After visual exploration of dataset D1 at different zoom levels in the image viewer (T2), we marked a specific spatial region from which to retrieve feature details in the tabular view. To the experts' surprise, when we highlighted the resulting cell IDs from the ROI query in the image view, the cell IDs did not align with the selected region (see <ref type="figure" target="#fig_12">Fig. 10</ref>). Upon closer inspection, we identified an error in the extracted feature data (T4). Evidently some cell IDs were dropped during preprocessing; this arose because virtually all of the software tools used for tissue imaging are in active development. Spotting an error like this is crucial; when the extracted cell features do not match the cell IDs in the segmentation mask, subsequent analyses are incorrect. CB4 stated that without Facetto, they might not have discovered the error. Our users then switched to dataset D2 with no preprocessing errors. Phenotype Analysis. The users explored the image view and chose channels that would highlight cell nuclei (DNA) and a marker of proliferation (Ki67) that is high in rapidly dividing cancer and immune cells. Our collaborators discovered areas of the tumor with different numbers of proliferating cells (T2, T3). To analyze a specific region of the sample in greater detail, users selected a ROI using the polygon selection tool, and then stored the resulting set of cells as a node in the phenotype tree (see <ref type="figure" target="#fig_10">Fig. 9b, 9f</ref>). To distinguish between cancer and non-cancer cells, they applied integrated EM clustering on DNA and Ki67, with k set to two clusters (T1). Facetto displays the clustering results visually as colored overlays on the cells in the image viewer (see <ref type="figure" target="#fig_10">Fig. 9c</ref>). Hiding the cluster overlays allowed experts to fine-tune the color transfer functions for individual channels (T3). User O2 further refined the clustering by adding E-Cadherin, a marker responsive to tumor cells. Subsequently, CB4 stated that the clusters look a lot more accurate than those identified by other approaches (see <ref type="figure" target="#fig_10">Fig. 9g</ref>) and she verified that the UMAP displayed expected features.</p><p>Next, our users attempted to identify different cell sub-phenotypes by analyzing staining patterns in different image channels (T1, T3). We started a new phenotype tree, extracted dividing cells into a cluster, and then created further subsets from that cluster node using the hierarchical faceting view. Our experts clustered on DNA, PAX8, CD4, CD3, CD8a, CD163, PD1, IBA1, CK7, CD11b, E-Cadherin, and Vimentin. By looking at CD3 in combination with the colored cluster overlays, users were able to identify putative false positives in the CD3 staining as well as T-cells of particular interest (see <ref type="figure" target="#fig_10">Fig. 9d, 9h</ref>). They then added textual labels to the clusters in the phenotype tree. Next, they wanted to use the cell clusters they had discovered as the basis for further analysis of the rest of the image. This included classification, exporting findings, and performing a more in-depth statistical analysis (T5).</p><p>To showcase Facetto's proofreading and classification capabilities, we introduced the experts to the editing mode in the tabular data view as a means to validate individual cell-cluster memberships. We also demonstrated how cells can be manually reassigned to a different cluster (T4). This data can then be used to feed the updated cluster and phenotype labels as ground truth data into a classifier (Section 6.4). Our experts found this especially promising, considering the large number of samples they currently need to label and proofread manually. Feedback. O2 and CB4 were excited about the integration of visualization and ML. They stated that this integration sped up the workflow significantly. It allowed them to identify different cell types, and to fine-tune clustering by adjusting the ROI and selected image features. Importantly, they could also directly check for segmentation errors and mapping issues between image and extracted feature data, which would be hard to detect otherwise. A key advantage of Facetto over other tools for these applications is that it is possible to concurrently review both, original image data and the results of image analysis. Users found the phenotype tree view to be a particularly useful means for exploring identified subsets and hierarchically analyzing data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Lessons Learned and Limitations</head><p>Tool complexity. One general drawback of VA tools used for multidimensional image data is their inherent visual complexity. Our collaborators repeatedly requested more functionality, even if that came at a higher cognitive load. We accommodated this by allowing users to toggle between visualizations involving different levels of complexity. For example, color encoding in the image view is usually based on transfer functions for selected channels, but can also be used to show cluster/class membership using visually distinct colors. Other examples of variable complexity included toggling the vertical polylines in the ridge view from showing one line per cell to one line per cluster. Accommodating different users. Facetto supports users with different medical and technical backgrounds. The Facettto UI launches into a common ground view comprising the image viewer and channel selection in the ridgeplot. Additional tools, such as clustering or hierarchical phenotype analysis, are arranged around the image viewer, and can be used depending on the user's background and analysis goals. All of our current users are highly involved in research, but in a production environment Facetto could support multiple roles, such as histotechnician and physician, each with access to different functionality. Building trust. Trustworthiness is an important aspect to data visualization. Our collaborators always want access to the original data. Facetto supports this in the tabular view and in the image viewer. Furthermore, we allow scientists to examine results of 'black-box' ML algorithms, crucial for building trust. One current limitation of Facetto in this regard is that our phenotype tree does not support fuzzy sets to represent partial memberships to classes (e.g., 80% probability of cancer). Additional trust could be built with visual guidance pointing users to interesting channels. In practice, however, current users often know which channels to examine, based on prior knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSION AND FUTURE WORK</head><p>We describe a newly developed visual analytics tool, Facetto, that combines unsupervised and supervised learning for hierarchical phenotypic analysis of multi-channel tissue images. Facetto addresses an acute need for software that complements manual analysis of histological data, which is the norm in a clinical setting, with automated analysis.</p><p>Facetto as an open-source tool allows others to add algorithms and interfaces as needed. With Facetto, we hope to substantially improve our ability to interpret complex tissue images in both research and translational settings, thereby advancing our understanding of disease and of new and existing therapies. In the longer term we expect tools like Facetto to be applied in a clinical setting as a means to improve patient diagnosis and enable personalized therapy.</p><p>User testing suggests that Facetto is already superior to many existing image analysis tools. In the future, we intend to add features that allow users to evaluate and improve other aspects of the tissue imaging workflow, including verification and correction of segmentation results with active learning. Ultimately, Facetto is expected to support ML methods that transcend the limitations of conventional segmentation methods. We also intend to add new means for creating and applying classifiers and for leveraging GPUs to parallelize computation for capturing user feedback in real-time.</p><p>Of particular importance in tissue imaging is exploiting the ability of anatomic pathologists to identify image features that have scientific and diagnostic significance. By interactively linking numerical and spatial features derived from images, machine learning and image visualization, Facetto provides a "human-in-the-loop" approach to accelerating and improving image exploration and analysis. With Facetto, we aim to let physicians, oncologists and cell and computational biologists benefit from each other's expertise: physicians can leverage computers to cope with data overload and computational biologists can identify and test algorithms for automating repetitive tasks. Ultimately, we expect that the vast majority of work in analyzing multiplexed image data will be automated, allowing scientists to focus on interpretation and innovation. A critical aspect of this transformation will be making the results of ML interpretable to users and also subject to user-guided improvement. This type of interactivity is at the heart of the Facetto approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>analysis. Despite this, contemporary digital technologies have not yet had much impact on anatomic pathology.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>The CyCIF imaging workflow. Steps 1-4: Acquisition and Preprocessing. Tissue sections are stained with antibodies chemically linked to a fluorophore; typically 3-5 antibodies are combined. The sections are imaged and fluorophores are then chemically inactivated (bleached) making it possible to perform another round of staining and imaging. Multiple cycles allow collecting images with 60 or more different "channels," each of which represents the staining pattern from a single antibody. Images are collected in successive tiles, which are then stitched together. Cells are segmented, and features such as total intensity per cell are extracted. The resulting data are analyzed interactively in Facetto (step 5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Phenotype tree hierarchy.(b) Active node with active selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>The phenotype data flow tree supports the analyst in the phenotype analysis workflow. Users make selections (e.g., by filtering, clustering, or classification) in an initial dataset (i.e., root). Selections can be stored as subsets and applied in a hierarchical manner, leading to a tree structure that maintains analytical provenance. Each node has a label, color, and displays the number of contained cells as a fill line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>( a )</head><label>a</label><figDesc>Single channel rendering. (b) Rendering of three different channels. (c) Zoom-in on the selected area. (d) Full zoom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Image viewer render modes. (a) shows single channel rendering, while (b-d) show different zoom levels of a 49.8 GB dataset. The rendering shows three channels (proteins pS6, HES1 and DNA) with a selection on a metabolically active area. (d) Top: Selected nuclei are highlighted in orange. Bottom: 3-channel rendering without nuclei highlights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>The ridgeplot (middle and right) shows intensity distributions for each of the 44 image channels, arranged on parallel x-axes. Feature values for the currently selected cells are visualized using vertical polyline overlays (in orange). Users can interactively filter individual channels, select channels for display in the image viewer (left), and adjust transfer functions used for rendering (bottom left and right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>(a) Image viewer showing a region with colored cell nuclei from clustering, overlaid onto the DNA channel. (b) UMAP projection scatterplot of an active subset with color-coded clusters. The clustering separates cancer regions (red) from immune cells (blue). (c) Small-multiple scatterplots show correlations of active rendering channels (here DNA, the tumor marker S100, and immune cell marker CD45).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>(a) Facetto allows users to employ clustering and classification in an iterative (loop) setting where users can use the result of one to steer the other, and vice versa. (b) EM Clustering: User-selected data is normalized, clustered, and finally visualized. (c) Classification: Multichannel images of labeled cells are used as input to train a CNN. For selected cells, respective image tiles are inputs for the classification. Classified cells are extracted and directly visualized in the image viewer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>(a) Ovarian cancer tissue. (b) Spatial ROI (orange), KI67 (green). (c) Tumor (red) in image and UMAP. (d) False-pos. immune cells (purple). (e) Whole dataset. (f) ROI subset. (g) 2 Clusters from subset. (h) 3 Clusters from t-cell cluster.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Ovarian cancer phenotype analysis (use case 2). Left to right: Experts start with a high-level view of the data (a, e), extract a ROI (b, f), cluster cells in the region into cancer and immune subpopulations (c, g), and subsequently subdivide one of the clusters into subtypes (d, h).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>this use case, two pathologists (P1, P2) and one cell and computational biologist (CB3) used Facetto to analyze samples of lung tumor over a span of ninety minutes. The main goal of our experts was to freely explore the data and thereby gain novel insight into the tumor biology by leveraging linked image and feature representations. The users were also interested in evaluating the accuracy of cell segmentation. Dataset: We analyzed a dataset of lung tissue, containing a stack of 44 images (channels), a nuclei segmentation mask, and a table with extracted mean intensity values per cell for each channel. Each channel had a dimension of 14, 448 × 11, 101 pixels, resulting in 13.6 GB raw channel data, and contained 110,500 successfully segmented cells.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Mismatched cell IDs in dataset D1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The visualization supports interactive and seamless zooming and panning, on-demand rendering of multi-channel information, manual selection of cells, and highlighting of classification and clustering results as well as faceting operations. The image viewer also provides details on demand when hovering over individual cells. Image Data. Each image tile in CyCIF is a 16 bit grayscale image, typically comprising 4 × 10 6 pixels (the dimensions of a scientific grade CMOS camera). Each channel is recorded in a separate grayscale image that is registered to other channels and pseudocolored for visualization. Segmentation assigns an ID (cell ID) to each cell in the stitched image.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>To prevent incorrect interpolation of cell ... ...Fig. 4. Multi-resolution image rendering. Left: The input to our rendering pipeline is a stack of high-resolution images (one image per CyCIF channel) and a segmentation mask containing a cell ID per pixel. Middle: We pre-compute multi-resolution image pyramids for all input data. Right: During rendering, we blend channels and choose between different rendering modes based on a pixel's cell ID, e.g., for highlighting a selected set of IDs.</figDesc><table><row><cell>cell IDs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>cell IDs }</cell></row><row><cell>high-resolution</cell><cell>multi-resolution</cell><cell>cell IDs</cell><cell>viewport</cell><cell>} multi-channel</cell></row><row><cell>channel images</cell><cell>image pyramids</cell><cell>image pyramid</cell><cell></cell><cell>blending</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank Rumana Rashid, Shannon Coy, Sandro Santagata, Anniina Farkkila, and Julia Casado for their valuable input and feedback. We thank Benjamin Izar, Jia-Ren Lin and Yu-An Chen for data and advice on the manuscript, and Denis Schapiro, Clarence Yapp, Jeremy Muhlich for image stitching and segmentation. This work is supported by the Ludwig Center at Harvard Medical School, by NCI Grant U54-CA225088, by King Abdullah University of Science and Technology (KAUST) and the KAUST Office of Sponsored Research (OSR) award OSR-2015-CCF-2533-0.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)</title>
		<meeting><address><addrLine>Savannah, GA</addrLine></address></meeting>
		<imprint>
			<publisher>USENIX Association</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">OMERO: flexible, model-driven data management for experimental biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Burel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Linkert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Loynton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarkowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Loranger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Avondo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lagerstedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lianas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hands</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Kleywegt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zanetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Swedlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">245</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<ptr target="https://www.allencell.org/deep-cell-zoom.html" />
	</analytic>
	<monogr>
		<title level="j">Allen Cell Explorer</title>
		<imprint/>
	</monogr>
	<note>Last visited: 2019-07-31</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pair Analytics: Capturing Reasoning Processes in Collaborative Visual Analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arias-Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Kaastra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">44th Hawaii Int. Conference on System Sciences</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<idno>Last visited: 2019-07- 31</idno>
		<ptr target="https://github.com/labsyspharm/ashlar" />
		<title level="m">ASHLAR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visual Analytics for Radiomics: Combining Medical Imaging with Patient Data for Clinical Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bannach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohlhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Scheckenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wesarg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Workshop on Visual Analytics in Healthcare (VAHC)</title>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="page" from="84" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">KNIME-the Konstanz information miner: version 2.0 and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Berthold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cebron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kötter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Meinl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wiswedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="31" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">BIO FORMATS -the solution for reading proprietary microscopy image data and metadata</title>
		<ptr target="https://www.openmicroscopy.org/bio-formats" />
		<imprint/>
	</monogr>
	<note>Last visited: 2019-07-31</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multiplexed Epitope-Based Tissue Imaging for Discovery and Healthcare Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bodenmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cell systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="225" to="238" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scatterblogs2: Real-time Monitoring of Microblog Messages Through User-Guided Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Püttmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wörner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2022" to="2031" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Data Intermixing and Multi-volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sakas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="359" to="368" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">VisTrails: Visualization Meets Data Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD Int. Conference on Management of Data</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="745" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<idno>Last visited: 2019-07-31</idno>
		<ptr target="http://cancer.digitalslidearchive.net/" />
		<title level="m">Cancer digital slide archive</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">CellProfiler: image analysis software for identifying and quantifying cell phenotypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Friman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Guertin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Lindquist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Golland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Sabatini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome biology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">100</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Characterizing Guidance in Visual Analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ceneda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gschwandtner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miksch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tominski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="111" to="120" />
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recursive Hybrid Algorithm for Non-Linear System Identification Using Radial Basis Function Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Billings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Journal of Control</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1051" to="1070" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">iVisClassifier: An Interactive Visual Analytics System for Classification based on Supervised Dimension Reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kihm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE Symposium on Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">PathoVA: A visual analytics tool for pathology diagnosis and reporting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Corv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Van Driel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Westenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Workshop on Visual Analytics in Healthcare (VAHC)</title>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="page" from="77" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical Sampling for Active Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th Int. Conference on Machine Learning</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="208" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Maximum Likelihood from Incomplete Data via the EM Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Orange: Data Mining Toolbox in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Curk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Erjavec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Č</forename><surname>Gorup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hočevar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Milutinovič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Možina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Polajnar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Toplak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Starič</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2349" to="2353" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Screenit: Visual Analysis of Cellular Screens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dinkla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Genest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reiling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Borowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="591" to="600" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Pattern Classification. John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Elmer</surname></persName>
		</author>
		<ptr target="http://www.cambridgesoft" />
		<title level="m">High Content Profiler</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tsigas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="33" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visualization and Exploration of Time-varying Medical Image Data Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Celler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics Interface 2007, GI &apos;07</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="281" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genedata</forename><surname>Screener</surname></persName>
		</author>
		<idno>Last visited: 2019-07-31</idno>
		<ptr target="http://www.genedata.com/products/screener" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Visual Analytics Approach to Diagnosis of Breast DCE-MRI Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Glaßer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Preim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Tönnies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="611" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Development and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Coram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Widner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Madams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cuadros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Webster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pyramid Methods in Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ogden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RCA Eng</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The WEKA Data Mining Software: An Update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visual Classifier Training for Text Document Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2839" to="2848" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cytosplore: Interactive Immune Cell Phenotyping for Large Single-Cell Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Höllt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pezzotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Van Unen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Koning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lelieveldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="171" to="180" />
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Scatter/Gather Clustering: Flexibly Incorporating User Feedback to Steer Clustering Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K R</forename><surname>Ojili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ramakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2829" to="2838" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">An Efficient Method to Construct a Radial Basis Function Neural Network Classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-Y</forename><surname>Bang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1495" to="1503" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The plane with parallel coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Inselberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="69" to="91" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<title level="m">Data Clustering: 50 Years Beyond K-Means. Pattern Recognition Letters</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="651" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cyclic Immunofluorescence (CycIF), A Highly Multiplexed Method for Single-cell Imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fallahi-Sichani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y.</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Sorger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Protocols in Chemical Biology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="251" to="264" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Highly multiplexed immunofluorescence imaging of human tissues and tumors using t-CyCIF and conventional optical microscopes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Izar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Santagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Sorger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>Elife, 7</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Integrating Predictive Analytics and Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">XCluSim: A visual analytics tool for interactively comparing multiple clustering results of bioinformatics data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Visualizing Data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Visualizing Inner Structures in Multimodal Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Manssour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Furuie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Olabarriaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M D S</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIBGRAPI 02</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Umap: Uniform Manifold Approximation and Projection for Dimension Reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Melville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03426</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A Partition-Based Framework for Building and Validating Regression Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mühlbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1962" to="1971" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Visualization Analysis and Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>AK Peters/CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Active Learning Using Pre-Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st Int. Conference on Machine Learning</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">79</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Interactive Visual Analysis of Perfusion Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oeltze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Doleisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Muigg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1392" to="1399" />
			<date type="published" when="2007-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">HCS-Analyzer: Open source software for high-content screening data correction and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ogier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dorval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1945" to="1946" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Openseadragon</surname></persName>
		</author>
		<idno>Last visited: 2019- 07-31</idno>
		<ptr target="https://github.com/openseadragon" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Technical Performance Assessment of Digital Pathology Whole Slide Imaging Devices</title>
		<ptr target="https://www.fda.gov/regulatory-information/search-fda-guidance-documents/technical-performance-assessment-digital-pathology-whole-slide-imaging-devices" />
		<imprint/>
	</monogr>
	<note>Last visited: 2019-07-31</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phaedra</forename></persName>
		</author>
		<idno>Last visited: 2019-07-31</idno>
		<ptr target="http://www.phaedra.io" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The Sensemaking Process and Leverage Points for Analyst Technology as Identified Through Cognitive Task Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Intelligence Analysis</title>
		<meeting><address><addrLine>McLean, VA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Compositing Digital Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;84</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="253" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Ragan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Visual Analytics for the Exploration of Tumor Tissue Characterization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raidou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">A</forename><surname>Van Der Heide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghobadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Kallehauge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Breeuwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional Networks for Biomedical Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conference on Medical Image Computing and Computer-assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="130" />
			<date type="published" when="2018-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">histoCAT: analysis of cell phenotypes and interactions in multiplex image cytometry data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Raghuraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Zanotelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Giesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Catena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Varga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bodenmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">873</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Design Study Methodology: Reflections from the Trenches and the Stacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2431" to="2440" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Ilastik: Interactive Learning and Segmentation Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Straehle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Koethe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Symposium on Biomedical Imaging: From nano to macro</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="230" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="667" to="676" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Visual Analytics of Social Media for Situation Awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>University of Stuttgart</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Visual Thinking for Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">What-If</forename><surname>Tool</surname></persName>
		</author>
		<idno>visited: 2019-07-31</idno>
		<ptr target="https://pair-code.github.io/what-if-tool" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Last</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Interactive Multi-volume Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Int. Conference on Computational Science</title>
		<imprint>
			<biblScope unit="volume">VI</biblScope>
			<biblScope unit="page" from="102" to="110" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Comparison Between UMAP and t-SNE for Multiplex-Immunofluorescence Derived Single-Cell Data from Tissue Sections. bioRxiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chevrier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Loh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">549659</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A Graphical Filter/Flow Model for Boolean Queries: An Implementation and Experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="327" to="339" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Abduction? Deduction? Induction? Is There a Logic of Exploratory Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of American Educational Research Association</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
