<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2019.2934631</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>(1) Poisoning instance #40 has the largest impact on the recall value, which is <ref type="bibr" target="#b1">(2)</ref> also depicted in the model overview. (3) There is heavy overlap among instances in the two classes as well the poisoning instances. (4) Instance #40 has been successfully attacked causing a number of innocent instances to have their labels flipped. <ref type="bibr" target="#b4">(5)</ref> The flipped instances are very close to the decision boundary. (6) On the feature of words "will" and "email", the variances of poisoning instances are large. (7) A sub-optimal target (instance #80) has less impact on the recall value, but the cost of insertions is 40% lower than that of instance #40.</p><p>Abstract-Machine learning models are currently being deployed in a variety of real-world applications where model predictions are used to make decisions about healthcare, bank loans, and numerous other critical tasks. As the deployment of artificial intelligence technologies becomes ubiquitous, it is unsurprising that adversaries have begun developing methods to manipulate machine learning models to their advantage. While the visual analytics community has developed methods for opening the black box of machine learning models, little work has focused on helping the user understand their model vulnerabilities in the context of adversarial attacks. In this paper, we present a visual analytics framework for explaining and exploring model vulnerabilities to adversarial attacks. Our framework employs a multi-faceted visualization scheme designed to support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We demonstrate our framework through two case studies on binary classifiers and illustrate model vulnerabilities with respect to varying attack strategies.</p><p>Index Terms-Adversarial machine learning, data poisoning, visual analytics</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In the era of Big Data, Artificial Intelligence and Machine Learning have made immense strides in developing models and classifiers for { } real-world phenomena. To date, applications of these models are found in cancer diagnosis tools <ref type="bibr" target="#b18">[19]</ref>, self-driving cars <ref type="bibr" target="#b40">[41]</ref>, biometrics <ref type="bibr" target="#b57">[58]</ref>, and numerous other areas. Many of these models were developed under assumptions of static environments, where new data instances are assumed to be from a statistical distribution similar to that of the training and test data. Unfortunately, the real-world application of these models introduces a dynamic environment which is home to malicious individuals who may wish to exploit these underlying assumptions in the machine-learning models. Consider e-mail spam filtering as an example. To date, a variety of machine learning methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13]</ref> have been developed to protect e-mail inboxes from unwanted messages. These methods build models to classify e-mail as spam or not-spam. However, adversaries still want their spam messages to reach your inbox, and these adversaries try to build input data (i.e., spam e-mails) that will fool the model into classifying their spam as safe. This can be done by misspelling words that might cause the machine learning classifier to flag a mail as spam or by inserting words and phrases that might cause the classifier to believe the message is safe. Other adversarial attacks have explored methods to fake bio-metric data to gain access to personal accounts <ref type="bibr" target="#b7">[8]</ref> and to cause computer vision algorithms to misclassify stop signs <ref type="bibr" target="#b14">[15]</ref>. Such exploits can have devastating effects, and researchers are finding that applications of machine learning in realworld environments are increasingly vulnerable to adversarial attacks. As such, it is imperative that model designers and end-users be able to diagnose security risks in their machine learning models. Recently, researchers have begun identifying design issues and research challenges for defending against adversarial machine learning, such as data de-noising, robust modeling, and defensive validation schemes <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b61">62]</ref>, citing the need to identify potential vulnerabilities and explore attack strategies to identify threats and impacts. These challenges lend themselves well to a visual analytics paradigm, where training datasets and models can be dynamically explored against the backdrop of adversarial attacks. In this paper, we present a visual analytics framework ( <ref type="figure" target="#fig_0">Figure 1</ref>) designed to explain model vulnerabilities with respect to adversarial attack algorithms. Our framework uses modularized components to allow users to swap out various attack algorithms. A multi-faceted visualization scheme summarizes the attack results from the perspective of the machine learning model and its corresponding training dataset, and coordinated views are designed to help users quickly identify model vulnerabilities and explore potential attack vectors. For an in-depth analysis of specific data instances affected by the attack, a locality-based visualization is designed to reveal neighborhood structure changes due to an adversarial attack. To demonstrate our framework, we explore model vulnerabilities to data poisoning attacks. Our contributions include:</p><p>A visual analytics framework that supports the examination, creation, and exploration of adversarial machine learning attacks;</p><p>A visual representation of model vulnerability that reveals the impact of adversarial attacks in terms of model performance, instance attributes, feature distributions, and local structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work focuses on explaining model vulnerabilities in relation to adversarial attacks. In this section, we review recent work on explainable artificial intelligence and adversarial machine learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Explainable Artificial Intelligence -XAI</head><p>Due to the dramatic success of machine learning, artificial intelligence applications have been deployed into a variety of real-world systems. However, the uptake of these systems has been hampered by the inherent black-box nature of these machine learning models <ref type="bibr" target="#b28">[29]</ref>. Users want to know why models perform a certain way, why models make specific decisions, and why models succeed or fail in specific instances <ref type="bibr" target="#b17">[18]</ref>. The visual analytics community has tackled this problem by developing methods to open the black-box of machine learning models <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref>. The goal is to improve the explainability of models, allow for more user feedback, and increase the user's trust in a model. To date, a variety of visual analytics methods have been developed to support model explainability and performance diagnosis.</p><p>Model Explainability: Under the black-box metaphor of machine learning, several model-independent approaches have been developed in the visual analytics community. EnsembleMatrix <ref type="bibr" target="#b58">[59]</ref> supports the visual adjustment of preferences among a set of base classifiers. Since the base classifiers share the same output protocol (confusion matrices), the approach does not rely on knowledge of specific model types. In EnsembleMatrix, the users are provided a visual summary of the model outputs to help generate insights into the classification results. The RuleMatrix system <ref type="bibr" target="#b44">[45]</ref> also focuses on the input-output behavior of a classifier through the use of classification rules, where a matrix basedvisualization is used to explain classification criterion. Similarly, model input-output behaviors were utilized in Prospector <ref type="bibr" target="#b28">[29]</ref>, where the relations between feature values and predictions are revealed by using partial dependence diagnostics.</p><p>While those approaches focused on utilizing model inputs and outputs, other visual analytics work focuses on "opening the black box," utilizing the internal mechanisms of specific models to help explain model outputs. Work by Muhlbacher et al. <ref type="bibr" target="#b46">[47]</ref> summarizes a set of guidelines for integrating visualization into machine learning algorithms through a formalized description and comparison. For automated iterative algorithms, which are widely used in model optimization, Muhlbacher et al. recommended exposing APIs so that visualization developers can access the internal iterations for a tighter integration of the user in the decision loop. In terms of decision tree-based models, BaobabView <ref type="bibr" target="#b60">[61]</ref> proposes a natural visual representation of decision tree structures where decision criterion are visualized in the tree nodes. BOOSTVis <ref type="bibr" target="#b35">[36]</ref> and iForest <ref type="bibr" target="#b69">[70]</ref> also focus on explaining tree ensemble models through the use of multiple coordinated views to help explain and explore decision paths. Similarly, recent visual analytics work on deep learning <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b62">[63]</ref><ref type="bibr" target="#b63">[64]</ref><ref type="bibr" target="#b64">[65]</ref><ref type="bibr" target="#b67">68]</ref> tackles the issue of the low interpretability of neural network structures and supports revealing the internal logic of the training and prediction processes.</p><p>Model Performance Diagnosis: It is also critical for users to understand statistical performance metrics of models, such as accuracy and recall. These metrics are widely-used in the machine learning community to evaluate prediction results; however, these metrics provide only a single measure, obfuscating details about critical instances, failures, and model features <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b68">69]</ref>. To better explain performance diagnostics, a variety of visual analytics approaches have been developed. Alsallakh et al. <ref type="bibr" target="#b0">[1]</ref> present a tool for diagnosing probabilistic classifiers through a novel visual design called Confusion Wheel, which is used as a replacement for traditional confusion matrices. For multi-class classification models, Squares <ref type="bibr" target="#b49">[50]</ref> establishes a connection between statistical performance metrics and instance-level analysis with a stacked view. Zhang et al. <ref type="bibr" target="#b68">[69]</ref> propose Manifold, a model-agnostic framework that does not rely on specific model types; instead, Manifold analyzes the input and output of a model through an iterative analysis process of inspection, explanation, and refinement. Manifold supports a finegrained analysis of "symptom" instances where predictions are not agreed upon by different models. Other work has focused on profiling and debugging deep neural networks, such as LSTMs <ref type="bibr" target="#b55">[56]</ref>, sequenceto-sequence models <ref type="bibr" target="#b54">[55]</ref>, and data-flow graphs <ref type="bibr" target="#b64">[65]</ref>.</p><p>While these works focus on linking performance metrics to inputoutput instances, other methods have been developed for feature-level analysis to enable users to explore the relations between features and model outputs. For example, the INFUSE system <ref type="bibr" target="#b27">[28]</ref> supports the interactive ranking of features based on feature selection algorithms and cross-validation performances. Later work by Krause et al. <ref type="bibr" target="#b26">[27]</ref> also proposed a performance diagnosis workflow where the instance-level diagnosis leverages measures of "local feature relevance" to guide the visual inspection of root causes that trigger misclassification.</p><p>As such, the visual analytics community has focused on explainability with respect to model input-outputs, hidden layers, underlying "black-box" mechanisms, and performance metrics; however, there is still a need to explain model vulnerabilities. To this end, Liu et al. <ref type="bibr" target="#b32">[33]</ref> present AEVis, a visual analytics tool for deep learning models, which visualizes data-paths along the hidden layers in order to interpret the prediction process of adversarial examples. However, the approach is tightly coupled with generating adversarial examples for deep neural networks, which is not extensible to other attack forms and model types. Our work builds upon previous visual analytics explainability work, adopting coordinated multiple views that support various types of models and attack strategies. What is unique in our work is the integration of attack strategies into the visual analytics pipeline, which allows us to highlight model vulnerabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Adversarial Machine Learning</head><p>Since our goal is to support the exploration of model vulnerabilities, it is critical to identify common attack strategies and model weaknesses. The four main features of an adversary (or attacker) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b61">62]</ref> are the adversary's Goal, Knowledge, Capability, and Strategy, <ref type="figure">Figure 2</ref> (Left). Goal: In adversarial machine learning, an attacker's goal can be separated into two major categories: targeted attacks and reliability attacks. In a targeted attack, the attacker seeks to insert specific malicious instances or regions in the input feature space and prevent these insertions from being detected <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b50">51]</ref>. In a reliability attack, the goal of the attacker is to maximize the overall prediction error of the model and make the model unusable for making predictions <ref type="bibr" target="#b52">[53]</ref>. Knowledge: The information that can be accessed by an attacker plays a significant role in how an attacker will design and deploy attack operations. The more knowledge an attacker has about a model (victim), the more precise an attack can be. In a black-box model, the attacker will have imprecise (or even no) knowledge about the machine learning model, while in a white-box setting, the attacker will have most (if not all) of the information about the model, including the model type, hyper-parameters, input features, and training dataset <ref type="bibr" target="#b9">[10]</ref>. Capability: The capability of the attacker refers to when and what the attacker can do to influence the training and testing process to achieve the attack's goal. Where the attack takes place (i.e., the stage of the modeling process -training, testing) limits the capability of the attacker. For example, poisoning attacks <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b65">66]</ref> take place during the training-stage, and the attacker attempts to manipulate the training dataset. Typical operations in data poisoning attacks include adding noise instances and flipping labels of existing instances. An evasion attack <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21]</ref> takes place during the testing stage. Such an attack is intended to manipulate unlabeled data in order to avoid detection in the testing stage without touching the training process. In all of these cases, the attacker is constrained by how much they can manipulate either the training or test data without being detected or whether the training and test data are even vulnerable to such attacks. Strategy: Given the attacker's goal, knowledge, and capabilities, all that remains is for the attacker to design an attack strategy. An optimal attack strategy can be described as maximizing the attack effectiveness while minimizing the cost of data manipulation or other constraints <ref type="bibr" target="#b42">[43]</ref>. Currently, numerous adversarial machine learning attacks are being developed, with evasion and poisoning strategies receiving the most attention <ref type="bibr" target="#b59">[60]</ref>. In evasion attacks, a common strategy is to add noise to test data instances. Goodfellow et al. <ref type="bibr" target="#b20">[21]</ref> proposed a method to add "imperceptible" noise to an image, which can drastically confuse a trained deep neural network resulting in unwanted predictions. For poisoning attacks, the strategies are usually formalized as bi-level optimization problems, such as gradient ascending <ref type="bibr" target="#b8">[9]</ref> and machine teaching <ref type="bibr" target="#b42">[43]</ref>. Common among these attacks is the goal of manipulating the trained model, and it is critical for users to understand where and how their models may be vulnerable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGN OVERVIEW</head><p>Given the key features of an adversary, we have designed a visual analytics framework that uses existing adversarial attack algorithms as mechanisms for exploring and explaining model vulnerabilities. Our framework is designed to be robust to general adversarial machine learning attacks. However, in order to demonstrate our proposed visual analytics framework, we focus our discussion on targeted data poisoning attacks <ref type="bibr" target="#b9">[10]</ref>. Data poisoning is an adversarial attack that tries to manipulate the training dataset in order to control the prediction behavior of a trained model such that the model will label malicious examples into a desired classes (e.g., labeling spam e-mails as safe). <ref type="figure">Figure 2</ref> (Right) maps the specific goal, knowledge, capabilities, and strategies of a poisoning attack to the generalized adversarial attack.</p><p>For the purposes of demonstrating our framework, we assume that the attack takes place in a white-box setting, i.e., the attacker has full knowledge of the training process. Although the scenario seems partial to attackers, it is not unusual for attackers to gain perfect-or near-perfect-knowledge of a model by adopting multi-channel attacks through reverse engineering or intrusion attacks on the model training servers <ref type="bibr" target="#b6">[7]</ref>. Furthermore, in the paradigm of proactive defense, it is meaningful to use the worst case attack to explore the upper bounds of model vulnerability <ref type="bibr" target="#b9">[10]</ref>. In terms of poisoning operations on the training dataset, we focus on causative attacks <ref type="bibr" target="#b3">[4]</ref>, where attackers are only allowed to insert specially-crafted data instances. This kind of insertion widely exists in real-world systems, which need to periodically collect new training data, examples include recommender systems and email spam filters <ref type="bibr" target="#b52">[53]</ref>. In such attacks, there is a limit to the number of poisoned instances that can be inserted in each attack iteration, i.e., a budget for an attack. An optimal attack attempts to reach its goal by using the smallest number of insertions within the given budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Analytical Tasks</head><p>After reviewing various literature on poisoning attacks <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b61">62]</ref>, we extracted common high-level tasks for analyzing poisoning attack strategies. These tasks were refined through discussions with our co-author, a domain-expert in adversarial machine learning.</p><p>T1 Summarize the attack space. A prerequisite for many of the algorithms is to set target instances to be attacked in the training dataset. In our framework, analysts need to be able to identify attack vectors and vulnerabilities of the victim model in order to specify target instances.</p><p>T2 Summarize the attack results. By following the well-known visual information seeking mantra <ref type="bibr" target="#b51">[52]</ref>, the system should provide a summary of the attack results after an attack is executed. In data poisoning, typical questions that the attackers might ask include:</p><p>T2.1 How many poisoning data instances are inserted? What is their distribution? Has the attack goal been achieved yet?</p><p>T2.2 What is the performance of the model before and after the attack and is there a significant difference? How many instances in the training dataset are misclassified by the poisoned model? T3 Diagnose the impact of data poisoning. In this phase, the user explores the prediction results and analyzes the details of the poisoned model. Inspired by the recent work in interpretable machine learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b68">69]</ref>, we explore the influence of insertion focusing on: attribute changes for individual instances; and drifts of data distributions on features due to poisoning. We consider both instance-level and featurelevel diagnoses when investigating the impact of poisoning data. The following questions are explored in this phase:</p><p>T3.1 At the instance-level, is the original prediction different from the victim model prediction? How close is the data instance to the decision boundary? How do the neighboring instances affect the class label? Is there any poisoned data in the data-instance's top-k nearest neighbors?</p><p>T3.2 At the feature-level, what is the impact of data poisoning on the feature distributions?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Design Requirements</head><p>From the task requirements, we iteratively refined a set of framework design requirements to identify how visual analytics can be used to best to support attack analysis and explanation. We have mapped different analytic tasks to each design requirement.</p><p>Visualizing the Attack Space -D1. The framework should allow users to upload their victim model and explore vulnerabilities. By examining statistical measures of attack costs and potential impact, the users should be able to find weak points in the victim model depending on the application scenario, and finally identify desired target instances for in-depth analysis in the next step (T1). Local Impacts -D2.4, depict the relationships between target data instances and their nearest neighbors (T3.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualizing Attack Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VISUAL ANALYTICS FRAMEWORK</head><p>Based on the user tasks and design requirements, we have developed a visual analytics framework ( <ref type="figure">Figure 3</ref>) for identifying vulnerabilities to adversarial machine learning. The framework supports three main activities: vulnerability analysis, analyzing the attack space, and analyzing attack results. Each activity is supported by a unique set of multiple coordinated views, and the user can freely switch between interfaces and views. All views share the same color mapping in order to establish a consistent visual design. Negative and positive classes are represented by red and blue, respectively, and the dark red and blue colors are used for indicating the labels of poisoning data instances. All actions in our framework are predicated on the user loading their training data and model. While our framework is designed to be modular to an array of attack algorithms, different performance and vulnerability measures are unique to specific attack algorithms. Thus, for discussion and demonstration, we instantiate our framework on data poisoning attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data-Poisoning Attack Algorithms</head><p>We focus on the binary classification task described in <ref type="figure">Figure 4</ref> (a) where the training data instances are denoted as x ∈ X , X ⊆ R n×d with class labels of y ∈ {−1, +1} (we refer to the −1 labels as negative and the +1 labels as positive). A classification model θ is trained on the victim training dataset, which creates a victim model. For a target data instance xt and the corresponding predicted label yt = θ(xt), the attacker's goal is to flip the prediction yt into the desired class −yt by inserting m poisoning instances</p><formula xml:id="formula_0">P = {p i |p i ∈ R d , i ∈ [1, m]}.</formula><p>We use B to represent the budget, which limits the upper bound of m, i.e., an attacker is only allowed to insert at most B poisoned instances. To maximize the impact of data poisoning on the classifier, the attack algorithms craft poisoned instances in the desired class, yp i = −yt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Attack Strategies</head><p>Various attack algorithms have been developed to create an optimal set of P with |P| ≤ B. To demonstrate how attacks can be explored in our proposed framework, we implement two different attack algorithms (Binary-Search and StingRay) described in <ref type="figure">Figure 4</ref> (b).</p><p>Binary-Search Attack 1 . The Binary-Search Attack <ref type="bibr" target="#b11">[12]</ref> assumes that the target instance xt can be considered as an outlier with respect to the <ref type="bibr" target="#b0">1</ref> For simplicity, we refer to the Burkard and Lagesse algorithm <ref type="bibr" target="#b11">[12]</ref> as "Binary-Search Attack" even though it is not named by the original authors.  <ref type="table">Table View</ref> Model Overview <ref type="figure">Fig. 3</ref>. A visual analytics framework for explaining model vulnerabilities to adversarial machine learning attacks. The framework consists of: vulnerability analysis, attack space analysis, and attack result analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attack Result Analysis</head><p>training data in the opposite class {xi|yi = −yt}. The classification model acts as an outlier detector and separates this target from the opposite class −yt. For crafting poisoning instances in a Binary-Search attack, the goal is to establish connections between the target and the desired class −yt that mitigate the outlyingness of the target. As illustrated in <ref type="figure">Figure 4</ref>, for each iteration, the Binary-Search Attack utilizes the midpoint x mid between xt and its nearest neighbor xnn in the opposite class, −yt, as a poisoning candidate. If this midpoint is in the desired class, it is considered to be a valid poisoning instance. This instance is appended to the original training dataset, and the model is re-trained (θ1 in Step 3 - <ref type="figure">Figure 4</ref>). In this way, the poisoned instances are iteratively generated, and the classification boundary is gradually pushed towards the target until the target label is flipped. Sometimes the midpoint may be outside of the desired class. Under this circumstance, a reset of the procedure is required by using the midpoint between x mid and xnn as the new candidate.</p><p>StingRay Attack. The StingRay attack <ref type="bibr" target="#b56">[57]</ref> inserts new copies of existing data instances by perturbing less-informative features. The StingRay attack shares the same assumptions and pipeline as the Binary-Search attack. The main difference between the attacks is how poisoning instances are generated (Step 2, <ref type="figure">Figure 4</ref>). In StingRay, a base instance, xnn, near the target, xt, in the desired class is selected, and a copy of the base instance is created as a poisoned candidate. By using some feature importance measures, a subset of features are selected for value perturbation on the poisoned candidate. After randomly perturbing the feature values, the poisoned instance closest to the target is inserted into the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Attack Results</head><p>Both attacks insert poisoned data instances into the victim training dataset resulting in the poisoned training dataset. The model trained on this poisoned dataset is called the poisoned model, and we can explore a variety of performance metrics to help explain the results of an attack (e.g., prediction accuracy, recall). For data instance level analysis (D2.2), we derive two metrics that can characterize the impact of data poisoning on the model predictions.</p><p>Decision Boundary Distance (DBD) <ref type="bibr" target="#b21">[22]</ref>: In a classifier, the decision boundary distance is defined as the shortest distance from a data in- The Nearest Neighbor x nn</p><p>Step 2: Insert a poisoning instance</p><p>x nn</p><p>x t</p><p>x nn</p><p>x t</p><p>x nn</p><p>x t Step 1: Find the nearest neighbor</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Binary-Search</head><p>Step 3: Retrain the model stance to the decision boundary. Under the assumption of outlyingness in the Binary-Search or StingRay attack, DBD is an indication of the difficulty of building connections between a target instance and its opposite class. However, it is difficult (and sometimes infeasible) to derive exact values of DBD from the corresponding classifiers, especially in non-linear models. We employ a sample-based, modelindependent method to estimate the DBDs for the training data as illustrated in <ref type="figure">Figure 5</ref>. First, with a unit ball centered at the data instance, we uniformly sample a set of unit direction vectors from the ball. For each vector, we perturb the original instance along the vector iteratively with a fixed step length, predict the class label with the classifier, and stop if the prediction is flipped. We use the number of perturbation steps as the distance to the decision boundary. We use the product of step length and the minimum steps among all the directions as an estimation of the DBD for each data instance.</p><p>Minimum Cost for a Successful Attack (MCSA): To help users understand the cost of an attack with respect to the budget, we calculate the minimum number of insertions needed to attack a data instance. For each data instance, the MCSA is the number of poisoning instances that must be inserted for a successful attack under an unlimited budget. The MCSA value is dependent on the attack algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Visualizing the Attack Space</head><p>The data table view <ref type="figure" target="#fig_0">(Figure 1 (B)</ref>) acts as an entry point to the attack process. After loading a model, all the training data instances are listed in the table to provide an initial static check of vulnerabilities (T1, D1). Each row represents a data instance in the training dataset, and columns describe attributes and vulnerability measures which includes the DBD and MCSA for both the Binary-Search and StingRay attack algorithms, as well as the original and the predicted labels. Inspired by Jagielski et al. <ref type="bibr" target="#b22">[23]</ref> and Steinhardt et al. <ref type="bibr" target="#b52">[53]</ref>, we use colored bars for MCSA to highlight different vulnerability levels based on the poisoning rates, which is defined as the percentage of poison instances in the entire training dataset. Poisoning rates of lower than 5% are considered to be high risk, since only a small amount of poisoned instances can cause label flipping in these data instances, and poisoning rates of 20% are likely infeasible (high risk of being caught). We define three levels for the poisoning rates: 1) high risk (red) -lower than 5%; 2) intermediate risk (yellow) -5% to 20%, and; 3) low risk (green) -more than 20% . The rows in the table can be sorted by assigning a column as the sorting key. The user can click on one of the checkboxes to browse details on the data ID, class label, and feature values, <ref type="figure" target="#fig_0">Figure 1 (B)</ref>. In addition, the clicking operation will trigger a dialog to choose between the two attack algorithms, and the interface for the corresponding attack result will be opened in a new tab page below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Visualizing the Attack Results</head><p>After selecting a target instance and an attack algorithm, the user can perform an in-depth analysis of the corresponding attack results. To visualize the results of the attack, we use four views: model overview, instance view, feature view, and kNN graph view.</p><p>Model Overview: The model overview provides a summary of the poisoned model as well as a comparison between the original (victim) and poisoned model (T2, D2.1). The model overview <ref type="figure" target="#fig_0">(Figure 1 (C)</ref>) provides a brief summary of the names of the victim and the poisoned models, the ID of the target data instance, and the class of the poisoned instances. A radar chart is used to describe the performance of the two models. The four elements commonly used in confusion matrices (true negative (TN), false negative (FN), true positive (TP), and false positive (FP)) are mapped to the four axes on the left side of the radar chart, and accuracy, recall, F1 and ROC-AUC scores are mapped to the right side. When hovering on the lines, the tooltip shows the detailed values on the axes. The two lines in the radar chart can be disabled or enabled by clicking on the legends.</p><p>Instance View: The instance view illustrates changes in the training datasets and supports the comparative analysis of predictions made by the victim and poisoned models from the perspective of individual data instances (T3.1, D2.2). The instance view is comprised of two sub-views, a projection view and an instance attribute view, which visualize data instances under the "overview + detail" scheme. Projection View: The projection view <ref type="figure" target="#fig_0">(Figure 1 (D)</ref>) provides a global picture of the data distribution, clusters, and relationships between the original and poisoned instances. We apply the t-SNE projection method <ref type="bibr" target="#b39">[40]</ref> to the poisoned training dataset. The projection coordinates are then visualized in a scatterplot. We share the colors used in the Model Overview, where red is for label predictions in the negative class and blue for the positive class. To support comparisons between the victim and poisoned model, we apply the corresponding poisoning color to the border of poisoned instances and stripe patterns to the data instances whose class prediction changed after the attack. Instance Attribute View: The instance attribute view <ref type="figure" target="#fig_0">(Figure 1 (E)</ref>  <ref type="figure">Fig. 6</ref>. Design of the virtual decision boundaries in the instance attribute view. The central vertical line acts as the virtual decision boundary. Two circles representing the prediction results of the victim and the poisoned models are placed beside the line. In this example, the data instance far away from the decision boundary was classified as positive with a relatively high probability. However, in the poisoned model, the instance crosses the boundary, causing the label to flip.</p><p>an individual data instance including classification probabilities and DBDs from the victim and poisoned model. To conduct a comparison between the attributes of the victim and poisoned models, we embed an illustration of attribute changes into the rows using a virtual decision boundary, <ref type="figure">Figure 6</ref>. Here, the vertical central line acts as a virtual decision boundary and separates the region into two half panes indicating the negative and positive class regions. Two glyphs, representing the predictions of the victim and the poisoned models, are placed in the corresponding half panes based on the predicted class labels. The horizontal distances from the center dots to the central line are proportional to their DBDs. To show the direction of change, we link an arrow from the victim circle to the poisoned circle. Additionally, the classification probabilities are mapped to the length of the lines in the glyph. A set of options are provided in the top right corner of the view for filtering out irrelevant instances based on their types.</p><p>Feature View: The feature view is designed to reflect the relationship between class features and prediction outputs to help users understand the effects of data poisoning (T3.2, D2.3). In <ref type="figure" target="#fig_0">Figure 1 (F)</ref>, each row in the list represents an individual feature. The feature value distribution is visualized as grouped colored bars that correspond to positive, negative, and poisoning data. To facilitate searching for informative features, the rows can be ranked by a feature importance measure on both the victim and the poisoned models. In our framework, we utilize the feature weights exported from classifiers as the measure, e.g., weight vectors for linear classifiers and Gini importance for tree-based models. In the list, the importance values and their rankings from the two models, as well as the difference, are shown in the last three columns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local Impact View:</head><p>In order to understand model vulnerabilities, users need to audit the relationship between poisoned instances and targets to gain insights into the impact of an attack (T3.1, D2.4). We have designed a local impact view, <ref type="figure" target="#fig_0">Figure 1 (G)</ref>, to assist users in investigating the neighborhood structures of the critical data instances.</p><p>For characterizing the neighborhood structures of data instances, we utilize the k-nearest-neighbor graph (kNN graph), <ref type="figure" target="#fig_6">Figure 7</ref> (a), to represent the closeness of neighborhoods, which can reveal the potential impact on the nearby decision boundary. A poisoned instance that is closer to a target may have more impact on the predicted class of the target. Such a representation naturally corresponds to the underlying logic of the attack algorithms, which try to influence the neighborhood structures of target instances. Our view is designed to help the user focus on the most influential instances in an attack. To reduce the analytical burden, we condense the scale of the kNN graph to contain only three types of instances as well as their k-nearest neighbors:</p><p>1. The target instance, which is the instance being attacked; 2. The poisoning instances, and; 3. The "innocent" instances, whose labels are flipped after an attack, which is a side-effect of poisoning. For the target and innocent instances, we extract their kNNs before the attack, i.e., the top-k nearest non-poisoned neighbors. This allows the user to compare the two sets of kNNs to reveal changes in the local structures after inserting poisoned instances.</p><p>The design of the local impact view is based on a node-link diagram of the extracted kNN graph where the data instances are represented as nodes. The coordinates of the nodes are computed with the forcedirected layout method on the corresponding graph structure. We use three different node glyphs to encode the data instances depending on the instance type (target, poisoned, innocent), <ref type="figure" target="#fig_6">Figure 7 (b)</ref>.</p><p>For the target and innocent instances, we utilize a nested design consisting of three layers: a circle, an inner ring, and an outer ring. The circle is filled with a blue or red color representing the predicted label. A striped texture is applied to the filled color if the label predicted by the poisoned model is different from the victim one, indicating that label flipping has occurred for this data instance. Additionally, the classification probability from the poisoned model is mapped to the radius of the circle. The inner ring uses two colored segments to show the distribution of the two classes in the k-nearest non-poisoning neighbors. The outer ring is divided into three segments that correspond to the negative and positive classes and poisoning instances in the kNN.</p><p>For poisoned instances, we use circles that are filled with the corresponding poisoning color. To depict the total impact on its neighborhoods, we map the sum of the impact values due to poisoned instances to the lightness of the filled color. As in the encoding of the target instances, the radius of the poisoned instance circles represent the classification probability. All other data instances are drawn as small dots colored by their corresponding prediction labels.</p><p>The edges in the local impact view correspond to measures of relative impacts, which are represented by directed curved edges. Inspired by the classic leave-one-out cross validation method, the relative impact is a quantitative measure of how the existence of a data instance (poisoned or not) influences the prediction result of another instance with respect to the classification probability. Algorithm 1 is used to calculate the impact of a neighbor xnn on a data instance x. First, we train a new model with the same parameter settings as the poisoned model; however, xnn is excluded. Then, we compute the classification probability of x with this new model. Finally, the relative impact value is calculated as the absolute difference between the new probability and the previous one. To indicate the source of the impact, we color an edge using the same color as the impacting data instance. The color gradient maps to the direction of impact and curve thickness maps to the impact value. Additionally, since the kNN graph may not be a fully-connected graph,  we employ dashed curves to link the nodes with the minimum distances between two connected components in the kNN graph. </p><formula xml:id="formula_1">, I(xnn, x) 1 θ ← Classifier(X \ {xnn}) 2 p x ← Probability of θ(x) 3 I(xnn, x) ← |p x − px|</formula><p>The local impact view supports various interactions on the kNN graph. Clicking on a node glyph in the local impact view will highlight the connected edges and nodes and fade out other irrelevant elements. A tooltip will be displayed as well to show the change of neighboring instances before and after the attack. The highlighting effects of data instances are also linked between the projection view and the local impact view. Triggering a highlighting effect in one view will be synchronized in the other one.</p><p>One limitation in the proposed design is the potential for visual clutter once the size of the graph becomes considerably large. In order to provide a clear entry point and support detail-on-demand analysis, we support various filters and alternative representations to the visual elements. By default, the edges are replaced by gray lines, which only indicates the linking relationships between nodes. Users can enable the colored curves mentioned above to examine the impacts with a list of switches, <ref type="figure" target="#fig_0">Figure 1 (G.1)</ref>. Unnecessary types of nodes can also be disabled with the filtering options, <ref type="figure" target="#fig_0">Figure 1 (G.2)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CASE STUDY AND EXPERT INTERVIEW</head><p>In this section, we present two case studies to demonstrate how our framework can support the analysis of data poisoning attacks from the perspective of models, data instances, features, and local structures. We also summarize feedback from four domain experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Targeted Attack on Hand-written Digits</head><p>Digit recognizers are widely-used in real applications including autograders, automatic mail sorting, and bank deposits. In such a system, an attacker may wish to introduce reliability issues that can result in mis-delivered mail, or create targeted attacks that cause checks to be mis-read during electronic deposit. For this case study, we employ a toy example in which a model is used to classify hand-written digits. This case study serves as a mechanism for demonstrating system features.</p><p>For this classifier, we utilize the MNIST dataset <ref type="bibr" target="#b30">[31]</ref>, which contains 60,000 images of ten hand-written digits at a 28×28 pixel resolution (784 dimensions in total). We trained a Logistic Regression classifier, implemented in Python Scikit-Learn library <ref type="bibr" target="#b47">[48]</ref>, using 200 randomly sampled images from the numbers 6 and 8, respectively. The value of k for extracting kNN graphs in the local impact view is set to 7.</p><p>Initial Vulnerability Check (T1): After the training dataset and model are loaded into the system, vulnerability measures are automatically calculated based on all possible attacks from the Binary-Search and StingRay Attack, and results are displayed in the data table view <ref type="figure" target="#fig_0">(Figure 8 (1)</ref>). By ranking the two columns of MCSAs for each attack algorithm, the user finds that the red bar colors indicate that many of the data instances are at high risk of a low cost poisoning attack. From the table, the user can also observe that the accuracy and recall values are not highly influenced by an attack, suggesting that a targeted attack on a single instance will not influence prediction performances. To some extent, this may disguise the behavior of a targeted attack by not alerting the model owners with a significant performance reduction.</p><p>Visual Analysis of Attack Results (T2, T3): Next, the user wants to explore a potential worst case attack scenario. Here, they select the instance with the largest MCSA among all the data instances (instance #152, 3.5% in poisoning rate) <ref type="figure">(Figure 8</ref> (2)) under the StingRay attack. As illustrated in <ref type="figure">Figure 8</ref> (3), first the user performs a general check of the model performance (T2.2). In the model overview, the two lines on four performance metrics in the radar chart overlap, indicating little to no model performance impact after a poisoning attack. Next, the user explores the distribution of the poisoning instances (T2.1, T3.1).</p><p>In the projection results, <ref type="figure">Figure 8 (4)</ref>, the poisoning instances span the border region of two clusters and flip the prediction of the target instance. However, there are no other innocent instances influenced by the poison insertions. The user can further inspect the impact of at attack on instance #152 by examining the local impact view, <ref type="figure">Figure 8</ref> (5). Here, the user can observe that in a poisoning attack on instance #152, the neighborhood of #152 must be heavily poisoned, and these poison insertions establish a connection between the target instance #152 and two other blue instances, leading to label flipping. In this case, the user can identify that the sparsity of the data distribution in the feature space may be contributing to the vulnerability of instance #152. Finally, the user explores the detailed prediction result of instance #152 by navigating to the instance attribute view <ref type="figure">(Figure 8 (6)</ref>). Here, the user observes that the label has flipped from Number 8 (red) to Number 6 (blue); however, the poisoning results in a very short DBD and a low classification probability for instance #152.</p><p>Lessons Learned and Possible Defense: From the analysis, our domain expert identified several issues in the victim model and dataset. First, even if instance #152 is successfully poisoned, the instance is fairly near the decision boundary of the poisoned model, which can be identified by the low value of DBD and the low classification probability. If any further data manipulations occur in the poisoned dataset, the prediction of the target instance may flip back, i.e., #152 is sensitive to future manipulations and the poisoning may be unstable. For the attackers, additional protection methods that mitigate the sensitivity of previous target instances can be adopted by continuously attacking neighboring instances, further pushing the decision boundary away from the target, or improving attacking algorithms to insert duplicated poisons near the target. Our domain expert was also interested in the pattern of a clear connection from the two blue instances to instance #152 in the local impact view. He noted that it may be due to data sparsity, where no other instances are along the connection path established by the poisoning instances, resulting in #152 having a high vulnerability to poisoning insertions. For defenders who want to alleviate the sparsity issue and improve the security of the victim model, possible solutions could be to add more validated labeled samples into the original training dataset and adopt feature extraction or dimension reduction methods to reduce the number of the original features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Reliability Attack on Spam Filters</head><p>For spammers, one of their main goals is to maximize the number of spam emails that reach the customers' inbox. Some models, such as the Naive Bayes spam filter, are extremely vulnerable to data poisoning attacks, as known spammers can exploit the fact that the e-mails they send will be treated as ground truth and used as part of classifier training.</p><p>Since known spammers will have their mail integrated into the modeling process, they can craft poisoned data instances and try to corrupt the reliability of the filter. These specially-crafted emails can mislead the behavior of the updated spam filter once they are selected in the set of new samples. In this case study, we demonstrate how our framework could be used to explore the vulnerabilities of a spam filter.</p><p>We utilize the Spambase dataset <ref type="bibr" target="#b16">[17]</ref> that contains emails tagged as non-spam and spam collected from daily business and personal communications. All emails are tokenized and transformed into 57dimensional vectors containing statistical measures of word frequencies and lengths of sentences. For demonstration purposes, we sub-sampled the dataset into 400 emails, keeping the proportion of non-spam and spam emails (non-spam:spam = 1.538:1) in the original dataset, resulting in 243 non-spam instances and 157 spam ones. A Logistic Regression classifier is trained on the sub-sampled dataset. The value of k for the kNN graphs is again set to 7.</p><p>Initial Vulnerability Check (T1): Using the Logistic Regression Classifier as our spam-filter model, we can explore vulnerabilities in the training data. For spam filters, the recall score (True-Positives / True-Positives + False-Negatives) is critical as it represents the proportion of detected spam emails in all the "true" spams. For a spam filter, a lower recall score indicates that fewer true spam emails are detected by the classifier. We want to understand what instances in our training dataset may be the most exploitable. Here, the user can sort the training data instances by the change in recall score after an attack <ref type="figure" target="#fig_0">(Figure 1</ref> (1)). After ranking the two columns of recall in ascending order for each attack algorithm, we found that the Binary-Search attack, when performed on instance #40, could result in a 0.09 reduction in the recall score at the cost of inserting 51 poisoned instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual Analysis of Attack Results (T2, T3):</head><p>To further understand what an attack on instance # 40 may look like, the user can click on the row of instance #40 and choose "Binary-Search Attack" for a detailed attack visualization. In the model overview, <ref type="figure" target="#fig_0">Figure 1</ref> (2), we see that the false negative value representing the undetected spams increased from 16 to 30 (nearly doubling the amount of spam e-mails that would have gotten through the filter), while the number of detected spams decreased from 141 to 127. This result indicates that the performance of correctly labeling spam emails in the poisoned model is worse than the victim model (T2.2).</p><p>We can further examine the effects of this attack by doing an instancelevel inspection using the projection view (T3.1). As depicted in <ref type="figure" target="#fig_0">Figure 1 (3)</ref>, the two classes of points, as well as the poisoned instances, show a heavy overlap. This indicates that there is an increased possibility of flipping innocent instances coupled with a decrease in prediction performance. In the local impact view <ref type="figure" target="#fig_0">(Figure 1 (4)</ref>), it can be observed that the poisoning instances are also strongly connected to each other in their nearest neighbor graph (T2.1). Additionally, there are five poisoning instances with a darker color than the others. As the lightness of poisoning nodes reflects their output relative impact, these five neighbors of the target instance contributes more to the prediction results than other poisons. For target instance #40, the outer ring consists only of the poisoning color, indicating that it must be completely surrounded by poisoning instances in order for the attack to be successful. Additionally, in a successful attack, there would be more than 20 innocent instances whose label are flipped from spam to non-spam, which is the main cause of the decreased recall value. After examining the details of these instances in <ref type="figure" target="#fig_0">Figure 1 (5)</ref>, we found that most of their DBDs in the victim model are relatively small, i.e., they are close to the previous decision boundary. As such, their prediction can be influenced by even a small perturbation of the decision boundary. Finally, we conducted a feature-level analysis by browsing the feature view (T3.2, <ref type="figure" target="#fig_0">Figure 1 (6)</ref>). We find that for distributions of poisoning instances along each feature, the variances are quite large on some words including "will" and "email". This suggests that there are large gaps between the non-spam emails and instance #40 on these words in terms of word frequencies, which could be exploited by attackers when designing the contents of the poisoned emails. Lessons Learned and Possible Defense: From our analysis, our domain expert was able to identify several key issues. First, from the distribution of impact values and classification probabilities among the poisoning instances, an interesting finding was that the poisoning instances close to the target are more uncertain (i.e., of low classification probability values) and essential to flipping its label. Our domain expert mentioned that further optimization may be performed by removing poisoning instances far away from the target because their impact and classification uncertainty could be too low to influence the model training. Second, even though an attack on instance #40 has the maximum influence on the recall value, there is a large (but not unfathomable) cost associated with inserting 51 poisoning instances (poisoning rate = 12.75%). Given the large attack cost, our domain expert was interested in exploring alternative attacks with similar impacts and lower costs, such as instance #80 <ref type="figure" target="#fig_0">(Figure 1 (7)</ref>). A poisoning attack on #80 can result in a reduction of 0.07 on the recall at almost half the cost of #40 (29 insertions, poisoning rate = 7.25%). The key takeaway that our analyst had was that there are multiple viable attack vectors that could greatly impact the reliability of the spam filter. Given that there are several critical vulnerable targets, the attackers could perform continuous lowcost manipulations to reduce the reliability of the spam filter. This sort of approach is typically referred to as a "boiling-frog attack <ref type="bibr" target="#b61">[62]</ref>". Here, our domain expert noted that the training-sample selection process may need to be monitored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Expert Interview</head><p>To further assess our framework, we conducted a group interview with our collaborator (E0) and three additional domain experts in adversarial machine learning (denoted as E1, E2, and E3). For the interview, we first introduced the background and goals of our visual analytics framework, followed by an illustration of the functions supported by each view. Then, we presented a tutorial of the analytical flow with the two case studies described in Section 5.1 and 5.2. Finally, the experts were allowed to freely explore the two datasets (MNIST and Spambase) in our system. The interview lasted approximately 1.5 hours.</p><p>At the end of the interview session, we collected free-form responses to the following questions:</p><p>1. Does the system fulfill the analytical tasks proposed in our work? 2. Does our analytical pipeline match your daily workflow?</p><p>3. What are the differences between our visual analytics system and conventional machine learning workflows?</p><p>4. Is the core information well-represented in the views?</p><p>5. Are there any views that are confusing, or that you feel could have a better design?</p><p>6. What results can you find with our system that would be difficult to discover with non-visualization tools?</p><p>Framework: The overall workflow of our framework received positive feedback with the experts noting that the system was practical and understandable. E3 appreciated the two-stage (attack space analysis and attack result analysis) design in the interface, and he conducted a combination of "general checks + detailed analysis". E2 noted that "the stage of attack space analysis gives our domain users a clear sense about the risk of individual samples, so we can start thinking about further actions to make the original learning models more robust and secure,". E1 mentioned that the framework could be easily adapted into their daily workflow and improve the efficiency of diagnosing new poisoning attack algorithms. E1 also suggested that it will be more flexible if we can support hot-swapping of attack algorithms to facilitate the diagnosis process.</p><p>Visualization: All the experts agreed that the combination of different visualization views can benefit multi-faceted analysis and provide many aspects for scrutinizing the influence of poisoning attacks. E2 was impressed by the instance attribute view and felt that the glyphs were more intuitive than looking at data tables since the changes of distances to the decision boundary can be directly perceived. E3 mentioned that the local impact view provides essential information on how the neighboring structures are being influenced. The two-ring design of the target and innocent instances provides a clear comparison of two groups of nearest neighbors before and after an attack. E3 further added that the node-link diagram and the visual encoding of impacts are effective for tracing the cause of label flipping and the valuable poisoning instances. "With the depiction of impacts, maybe we could find how to optimize our attack algorithms by further reducing the number of insertions, since some of the low-impact poisoning instances may be removed or aggregated."</p><p>Limitations: One issue found by our collaborator, E0, was the training time that was necessary for using our framework. E0 commented that during the first hour of the interview, we were often required to repeat the visual encoding and functions in the views. However, once the domain experts became familiar with the system after free exploration for some time, they found that the design is useful for gaining insights from attacks. We acknowledge that there could be a long learning curve for domain experts who are novice users in comprehensive visual analytics systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION AND CONCLUSIONS</head><p>In this work, we propose a visual analytics framework for exploring vulnerabilities and adversarial attacks to machine learning models. By focusing on targeted data poisoning attacks, our framework enables users to examine potential weak points in the training dataset and explore the impacts of poisoning attacks on model performance. Task and design requirements for supporting the analysis of adversarial machine learning attacks were identified through collaboration with domain experts. System usability was assessed by multiple domain experts and case studies were developed by our collaborating domain scientist. Target users of our framework are data scientists who utilize machine learning models in mission-critical domains. In contrast to traditional reactive defense strategies that respond when attacks are detected, our framework serves as a mechanism for iterative proactive defense. The users can simulate poisoning operations and explore attack vectors that have never been seen in the historical records. This can enable domain scientists to design more reliable machine learning models and data processing pipelines. An implementation of our framework is provided in Github 2 .</p><p>Target Users: The target users of our framework are data scientists and security experts who wish to explore model vulnerabilities. Data 2 https://github.com/VADERASU/visual-analytics-adversarial-attacks scientists can use the proposed framework to perform extensive checks on their model training processes in order to enrich the quality of training datasets. Similarly, security experts can benefit from using our framework by actively adopting new attack strategies for the purpose of penetration testing following the paradigm of "security-by-design" in proactive defense <ref type="bibr" target="#b9">[10]</ref>.</p><p>Limitations: One major concern in our design is scalability. We have identified issues with both the attack algorithms and visual design.</p><p>Attack Algorithms: The computational efficiency of an attack algorithm has a significant influence on the cost of pre-computing vulnerability measures. In order to explore vulnerabilities in data poisoning, every data instance must undergo an attack. In the two case studies, it takes about 15 minutes to compute the MCSA values for the 400 training data instances. In large-scale datasets, this may make the pre-computation infeasible. Sampling methods could be used to reduce the analysis space, and weighted sampling can be adopted to increase the number of samples in the potentially vulnerable regions in the feature space. An upper limit on attack costs could also be used so that a poisoning attack would simply be marked as "failure" if the upper bound is reached. Furthermore, progressive visual analysis <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b53">54]</ref> can be employed in the sampling process, allowing users to conduct a coarse-grained analysis of the samples and then increase sample rates on targeted regions.</p><p>Visual Design: In our visual design, circles may overlap when the number of training data instances is over one thousand. To mitigate visual clutter in the projection result, we have employed semantic zooming in the projection view to support interactive exploration in multiple levels. In the future, various abstraction techniques for scatterplots such as Splatterplots <ref type="bibr" target="#b41">[42]</ref>, down-sampling <ref type="bibr" target="#b13">[14]</ref>, and glyphbased summarization <ref type="bibr" target="#b31">[32]</ref> can be integrated to reduce the number of points displayed in the canvas. Interactive filtering can also be adopted to remove the points in less important regions, e.g., far away from the target instance. A similar issue also exists in the local impact view where the current implementation supports up to 100 nodes shown as graph structures. The readability of large graph visualizations is still an open topic in the community. One way to scale our design would be to build hierarchical aggregation structures on the nodes by clustering the corresponding instances with specific criteria <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b66">67]</ref>.</p><p>Future Work: In this work, we use the data poisoning attack as the main scenario to guide the visual design and interactions in the visual analytics framework. Based on the successful application in poisoning attacks, we plan to adapt our framework for other typical adversarial settings and attack strategies, such as label-flipping attacks <ref type="bibr" target="#b52">[53]</ref> where the labels of training data instances can be manipulated, and evasion attacks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21]</ref> that focus on the testing stage. Another issue of our work is that the framework currently does not support the integration of known defense strategies. In practice, attack and defense strategies often co-exist and must be simultaneously considered in assessing vulnerabilities. Future iterations of this framework will incorporate defense methods as a post-processing stage to evaluate the vulnerability and effectiveness of attacks under countermeasures. In addition, since currently our work only considers classification models for generalpurpose tasks, another extension would be to specialize our framework to support domain-specific analyses, such as image recognition, biological analysis, and network intrusion detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>ExplainingFig. 1 .</head><label>1</label><figDesc>Vulnerabilities to Adversarial Machine Learning through Visual Analytics Yuxin Ma, Tiankai Xie, Jundong Li, Ross Maciejewski, Senior Member, IEEE Reliability attack on spam filters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>-D2. To analyze the results of an attack, the framework should support overview and details-on-demand: Model Overview -D2.1, summarize prediction performance for the victim model as well as the poisoned model (T2.2); Data Instances -D2.2, present the labels of the original and poisoned data instances (T2.1, T3.1); Data Features -D2.3, visualize the statistical distributions of data along each feature (T3.2);</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Goal: prevent x t from being classified as +1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>y</head><label></label><figDesc>mid y nn Set x mid as the midpoint between x nn and x mid , and go back to Step 1Loop until poisoned (x t ) = -1, or return "failed" if upper bound B is reached.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>An illustration of data poisoning attacks using the Binary-Search and Stingray algorithms. (a) In a binary classification problem, the goal of a data-poisoning attack is to prevent the target instance, xt, from being classified as its original class. (b) The Binary-Search and StingRay attacks consist of three main steps: 1) select the nearest neighbor to the target instance, 2) find a proper poisoning candidate, and 3) retrain the model with the poisoned training data. The procedure repeats until the predicted class label of xt is flipped, or the budget is reached. Estimating the decision boundary distance. (Left) Six directional vectors are sampled from the unit ball. (Right) For each direction, the original instance is perturbed one step at a time until it is in the opposite class. In this example, the direction highlighted by the red rectangle is the minimum perturbed step (3 steps) among all the directions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>The class distribution of kNNs in the victim model Outer Ring: The class distribution of kNNs in the poisoned model Color: The predicted label Texture: Whether the predicted label is flipped from the victim model Size: The source node of the impact Gradient: Direction of the impact Thickness: Impact value Visual design of the local impact view. (a) The process of building kNN graph structures. (b) The visual encodings for nodes and edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>3 Fig. 8 .</head><label>38</label><figDesc>A targeted attack on hand-written digits.<ref type="bibr" target="#b0">(1)</ref> In the data table view, we identify the target instance #152 (2) as a potential vulnerability.(3)In the model overview, we observe no significant change of the prediction performance after an attack on #152 occurs. (4) In the projection view, the two classes of instances are clearly separated into two clusters. The poisoning instances (dark blue circles) penetrate class Number 8 and reach the neighboring region of instance #152.<ref type="bibr" target="#b4">(5)</ref> The attack can also be explored in the local impact view where poisoning nodes and the target show strong neighboring connections. (6) The detailed prediction results for instance #152 are further inspected in the instance attribute view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Algorithm 1 :</head><label>1</label><figDesc>Computing the impact of xnn on x Data: training dataset X ; two instances x ∈ X , xnn ∈ X ; previous classification probability of x, px Result: The impact value of xnn on x</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>1 Data Table View Model Overview 2 3 Projection View 4 Local Impact View</head><label></label><figDesc></figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the U.S.Department of Homeland Security under Grant Award 2017-ST-061-QA0001. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of the U.S. Department of Homeland Security.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visual methods for analyzing probabilistic classification data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alsallakh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Miksch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1703" to="1712" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeltracker: Redesigning performance analysis tools for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amershi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Human Factors in Computing Systems</title>
		<meeting>the ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="337" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A review and characterization of progressive visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Angelini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Santucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informatics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The security of machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Barreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Tygar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010-11" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="121" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Surveying the complementary role of automatic data analysis and visualization in knowledge discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lalanne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery Integrating Automated Analysis with Interactive Exploration</title>
		<meeting>the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery Integrating Automated Analysis with Interactive Exploration</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="12" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evasion attacks against machine learning at test time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Corona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maiorca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Šrndić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laskov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Giacinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<meeting>the European Conference on Machine Learning and Knowledge Discovery in Databases</meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="387" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Security evaluation of pattern classifiers under attack</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fumera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="984" to="996" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adversarial biometric recognition: A review on biometric system security from the adversarial machine-learning perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fumera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Russu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Didaci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="31" to="41" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Poisoning attacks against support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laskov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1467" to="1474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Wild patterns: Ten years after the rise of adversarial machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Roli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="317" to="331" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A survey of learning-based techniques of email spam filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blanzieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bryl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="92" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Analysis of causative attacks against svms learning from data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burkard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lagesse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd ACM on International Workshop on Security And Privacy Analytics</title>
		<meeting>the 3rd ACM on International Workshop on Security And Privacy Analytics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="31" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A survey of emerging approaches to spam filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visual abstraction and exploration of multi-class scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346594</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1683" to="1692" />
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Shapeshifter: Robust physical adversarial attack on faster R-CNN object detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cornelius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H P</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<meeting>the Joint European Conference on Machine Learning and Knowledge Discovery in Databases</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="52" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adversarial classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sanghai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">UCI machine learning repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Graff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The state of the art in integrating machine learning into visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Nabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dermatologist-level classification of skin cancer with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kuprel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Novoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Swetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">542</biblScope>
			<biblScope unit="issue">7639</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Manynets: An interface for multiple network analysis and visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Golbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Decision boundary analysis of adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Manipulating machine learning: Poisoning attacks and countermeasures for regression learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagielski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Biggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Nita-Rotaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Security and Privacy</title>
		<meeting>the IEEE Symposium on Security and Privacy</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="19" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Activis: Visual exploration of industry-scale deep neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="97" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gan lab: Understanding complex deep generative models using interactive visual experimentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kahng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H P</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="310" to="320" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Graphprism: Compact visualization of network structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kairam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Working Conference on Advanced Visual Interfaces</title>
		<meeting>the International Working Conference on Advanced Visual Interfaces</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="498" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A workflow for visual diagnostics of binary classifiers using instance-level explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Swartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aphinyanaphongs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Conference on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="162" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">INFUSE: Interactive feature selection for predictive modeling of high dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1614" to="1623" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Interacting with predictions: Visual inspection of black-box machine learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5686" to="5697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Retainvis: Visual analytics with interpretable and interactive recurrent neural networks on electronic medical records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="299" to="309" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cluster-based visual abstraction for multivariate scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2754480</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2531" to="2545" />
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Analyzing the Noise Robustness of Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Conference on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Analyzing the training processes of deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Towards better analysis of machine learning models: A visual analytics perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Informatics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="56" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visual diagnosis of tree boosting methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="163" to="173" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Trojaning attack on neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual Network and Distributed System Security Symposium. The Internet Society</title>
		<meeting>the 25th Annual Network and Distributed System Security Symposium. The Internet Society</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Recent progress and trends in predictive visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Computer Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="192" to="207" />
			<date type="published" when="2017-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The state-of-the-art in predictive visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="539" to="562" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Driving style recognition for intelligent vehicle control and advanced driver assistance: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="666" to="676" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Splatterplots: Overcoming overdraw in scatter plots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mayorga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.65</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1526" to="1538" />
			<date type="published" when="2013-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Using machine teaching to identify optimal training-set attacks on machine learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 29th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2871" to="2877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Understanding hidden memories of recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Conference on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">RuleMatrix: Visualizing and understanding classifiers with rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="342" to="352" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Systematic poisoning attacks on and defenses for machine learning in healthcare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mozaffari-Kermani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sur-Kolay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Jha</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2014.2344095</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1893" to="1905" />
			<date type="published" when="2015-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Opening the black box: Strategies for increased user involvement in existing algorithm implementations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Muhlbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gratzl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1643" to="1652" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Scikitlearn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Visualizing the hidden activity of artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fadel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Falcao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Telea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Squares: Supporting interactive performance analysis for multiclass classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amershi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Poison frogs! Targeted clean-label poisoning attacks on neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shafahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Najibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Suciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dumitras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6106" to="6116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The eyes have it: a task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<idno type="DOI">10.1109/VL.1996.545307</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Visual Languages</title>
		<meeting>IEEE Symposium on Visual Languages</meeting>
		<imprint>
			<date type="published" when="1996-09" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Certified defenses for data poisoning attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3520" to="3532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Progressive visual analytics: Userdriven visual exploration of in-progress analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Stolper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1653" to="1662" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Seq2seq-Vis: A visual debugging tool for sequence-to-sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="353" to="363" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">LSTMVis: A tool for visual analysis of hidden state dynamics in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="667" to="676" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">When does machine learning fail? Generalized transferability for evasion and poisoning attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Suciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Marginean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dumitras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the USENIX Security Symposium</title>
		<meeting>the USENIX Security Symposium</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1299" to="1316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep learning for biometrics: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Woodard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">EnsembleMatrix: Interactive visualization to support machine learning with multiple classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Human factors in Computing Systems</title>
		<meeting>the International Conference on Human factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">1283</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Adversarial machine learning: A literature review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tabrizi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Machine Learning and Data Mining in Pattern Recognition</title>
		<editor>P. Perner</editor>
		<meeting>the Machine Learning and Data Mining in Pattern Recognition</meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="324" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">BaobabView: Interactive construction and analysis of decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Den Elzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Conference on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Vorobeychik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kantarcioglu</surname></persName>
		</author>
		<title level="m">Adversarial Machine Learning. Synthesis Lectures on Artificial Intelligence and Machine Learning</title>
		<imprint>
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">DQNViz: A visual analytics approach to understand deep q-networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="288" to="298" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">GANViz: A visual analytics approach to understand the adversarial game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1905" to="1917" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Visualizing dataflow graphs of deep learning models in TensorFlow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wexler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Adversarial label flips attack on support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Artificial Intelligence</title>
		<meeting>the European Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="870" to="875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Graph Thumbnails: Identifying and comparing multiple graphs at a glance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Yoghourdjian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wybrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Understanding neural networks through deep visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep Learning Workshop, Proceedings of the International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Manifold: A modelagnostic framework for interpretation and diagnosis of machine learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="364" to="373" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">iForest: Interpreting random forests via visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="407" to="416" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
