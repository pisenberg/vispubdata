<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Do What I Mean, Not What I Say! Design Considerations for Supporting Intent and Context in Analytical Conversation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Tory</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tableau Software Palo Alto</orgName>
								<address>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidya</forename><surname>Setlur</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tableau Software Palo Alto</orgName>
								<address>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Do What I Mean, Not What I Say! Design Considerations for Supporting Intent and Context in Analytical Conversation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Human-centered computing-Visualization-Empirical studies in visualization; Human-centered computing-Interaction paradigms-Natural language interfaces</keywords>
			</textClass>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>(a) initial utterance (b) implicit intent to retain context (c) implicit intent asking for a correlation <ref type="figure" target="#fig_14">Figure 1</ref>: Example 'analytical conversation' from our study showing how intent could drive visualization responses for a dataset of Titanic passengers. Following an initial utterance (a), an anaphoric reference conveys an implicit intent to retain context (b). Attributes Children Aboard? and Survived? are retained, while Sex and Age are added in a way that preserves the previous chart structure. In (c), 'correlation' suggests an implicit intent for a new visualization such as a heat map to depict relationships between attributes %survived, Age, and Fare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Natural language can be a useful modality for creating and interacting with visualizations but users often have unrealistic expectations about the intelligence of natural language systems. The gulf between user expectations and system capabilities may lead to a disappointing user experience. So -if we want to engineer a natural language system, what are the requirements around system intelligence? This work takes a retrospective look at how we answered this question in the design of Ask Data, a natural language interaction feature for Tableau. We examine two factors contributing to perceived system intelligence: the system's ability to understand the analytic intent behind an input utterance and the ability to interpret an utterance contextually (i.e. taking into account the current visualization state and recent actions). Our aim was to understand the ways in which a system would need to support these two aspects of intelligence to enable a positive user experience. We first describe a pre-design Wizard of Oz study that offered insight into this question and narrowed the space of designs under consideration. We then reflect on the impact of this study on system development, examining how design implications from the study played out in practice. Our work contributes insights for the design of natural language interaction in visual analytics as well as a reflection on the value of pre-design empirical studies in the development of visual analytic systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural language (NL) interfaces for visualization <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b44">43,</ref><ref type="bibr" target="#b45">44,</ref><ref type="bibr" target="#b50">49,</ref><ref type="bibr" target="#b52">51]</ref> can enable effective and engaging interactions with data and * e-mail: mtory@tableau.com † e-mail: vsetlur@tableau.com may lower the barriers to entry for less-skilled individuals. Designing NL systems for visual analytics is challenging because people often overestimate the system intelligence <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b44">43]</ref>, leading to unrealistic expectations and disappointment when those expectations are not met. This challenge is not limited to visual analytic systems; it is an established trend for all emerging technologies <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b36">35,</ref><ref type="bibr" target="#b47">46]</ref>. When engineering such systems, it is nearly impossible to meet the high bar of expectations around their intended behavior, given resource constraints and technology limitations <ref type="bibr" target="#b36">[35,</ref><ref type="bibr" target="#b47">46,</ref><ref type="bibr" target="#b53">52]</ref>. So then -what are the requirements that an analytical conversation system needs to meet, in order to deliver a delightful user experience? We take a retrospective look at how we answered this question in the design of Ask Data <ref type="bibr" target="#b1">[2]</ref>, a recently developed NL capability for Tableau, shown in <ref type="figure" target="#fig_0">Figure 2</ref>. Our previous work on Eviza <ref type="bibr" target="#b44">[43]</ref> and Evizeon <ref type="bibr" target="#b26">[27]</ref> revealed that people often underspecify details in their NL queries, expecting the system to both fill in the gaps and interpret queries in the context of the current visualization state. Thus, when we began developing Ask Data, we knew that two aspects of perceived system intelligence would be its ability to understand analytic intent (i.e., what a user is trying to achieve) and its relation to context (i.e., the current visualization state). An open question though, was the extent to which the IEEE VAST 2019 20-25 October, Vancouver, BC, Canada 978-1-7281-2018-8/19/$31.00 ©2019 IEEE system would need to understand these aspects of communication to support a positive experience. We were also unclear what visual analytic intents people had in mind and how they would express them. Given the underspecificity of these utterances, what would the system need to infer? A 'smart' system might exhibit forms of computational intelligence to better understand the user's needs and personalize or guide the interaction <ref type="bibr" target="#b43">[42]</ref>. <ref type="figure" target="#fig_14">Figure 1</ref> illustrates how an analytical conversation system might respond to a series of NL utterances. For a useful transition from (a) to (b), the system needs to infer that utterance (b) represents an intent to retain the existing chart layout but add information. To create a useful visualization in response to utterance (c), the system needs to infer that there is a new line of inquiry and that 'correlation' implies a desire to see the relationship between variables. <ref type="figure" target="#fig_14">Figure 1</ref> represents an ideal interaction that could be difficult to fully realize in a first-generation system, particularly when deployed at scale where it must work with any data source. Could we get away with something simpler and then improve it over time, without severely compromising the experience? At the extreme end, would it be terrible if all the system could do was recognize attributes and values in the input utterance and then use a visual encoding recommender like ShowMe <ref type="bibr" target="#b38">[37]</ref> to generate a chart, ignoring all context information and any additional expressions of intent?</p><p>To elicit requirements around intent and context for the yet-tobe-built Ask Data system, we ran a Wizard of Oz study. The results were deeply influential, ultimately effecting decisions around design principles, system requirements, evaluation criteria, and implementation phasing. We first describe our study and its results. We then reflect on the study's impact on development, examining how design implications from the study played out in practice. Our work contributes insights for the design of NL interaction in visual analytics, a reflection on the value of pre-design empirical studies, and a glimpse into the user experience challenges involved in technology transfer and productization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Literature on intent can be classified into: Intent for search in information retrieval systems and Intent for analytical tasks in visual analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Intent for search in information retrieval systems</head><p>Most research on understanding intent centers on information search, where it is an important aspect of improving precision and recall. Harrison and Dourish recognize the need for determining users' context to better support their activities through appropriate behavior and relevant actions <ref type="bibr" target="#b14">[15]</ref>. Broder introduced a taxonomy of search intent with three categories of queries: navigational, informational and transactional <ref type="bibr" target="#b6">[7]</ref>. This led to approaches mapping query intent to algorithmically classified search result categories <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b41">40,</ref><ref type="bibr" target="#b54">53]</ref>. Hu et al. deduced intent from user behavior of URL clicks <ref type="bibr" target="#b27">[28]</ref>. Baeza-Yates et al.'s approach suggested related queries based on query log data and clustering. Query recommendation and refinement are concepts that help further hone user intent, i.e., transforming an initial query into a more relevant one capable of satisfying the user's information need <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b32">32]</ref>. Often, information needs evolve. Research has explored interactive intent modeling and reinforcement learning, where search intents are estimated and visualized for interaction <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b42">41]</ref>. However, the paradigm of intent deduction from search cannot be directly translated to visual analytical workflows, as their goals and the results tend to be different <ref type="bibr" target="#b46">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Intent for analytical tasks in visual analytics</head><p>Numerous systems recommend or automatically create visualizations, based on theoretical foundations such as the data state model <ref type="bibr" target="#b10">[11]</ref> and the visualization reference model <ref type="bibr" target="#b7">[8]</ref>. Data property based systems (e.g., APT <ref type="bibr" target="#b37">[36]</ref> and ShowMe <ref type="bibr" target="#b38">[37]</ref>) rely on data characteristics to choose a visual representation. Systems such as Voyager <ref type="bibr" target="#b57">[56]</ref> recommend views to reveal data features based on statistical properties, whereas task based systems (e.g., <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16]</ref>) rely on formal definitions of the user's task. Most recently, Draco <ref type="bibr" target="#b39">[38]</ref> combined many of these ideas in a constraint-based programming framework.</p><p>Few visualization systems have attempted to infer a user's analytical intent. Gotz and Wen <ref type="bibr" target="#b22">[23]</ref> used click interactions as implicit signals of intent. Steichen et al. <ref type="bibr" target="#b51">[50]</ref> and Gingerich et al. <ref type="bibr" target="#b20">[21]</ref> demonstrated that low-level visualization tasks could be inferred from eye gaze patterns. These results were demonstrated with a small number of pre-defined tasks on known visualizations; a generalization suitable in automated presentation systems does not yet exist. However, the basis for such systems are task models, data-, quality-or interestingness measures.</p><p>Recurrent neural networks have been used in conversation-style chatbots <ref type="bibr" target="#b48">[47]</ref>. Systems for NL interaction for exploring data <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b44">43,</ref><ref type="bibr" target="#b50">49,</ref><ref type="bibr" target="#b52">51]</ref> depend on understanding user intent and can infer intent since NL utterances may hint at a user's goals. Cook et al. guide the user using a mixed initiative approach <ref type="bibr" target="#b11">[12]</ref>. However, most systems infer very limited aspects of intent, typically relying on explicitly named data attributes, values, and chart types. Conversational interpretation in Nicky <ref type="bibr" target="#b30">[30]</ref> was supported by a domain-specific ontology, which tends not to generalize outside a particular domain. Evizeon <ref type="bibr" target="#b26">[27]</ref> and Orko <ref type="bibr" target="#b50">[49]</ref> supported follow-on utterances through simplistic models of intent <ref type="bibr" target="#b23">[24]</ref>, but only for filters. Recent research <ref type="bibr" target="#b49">[48]</ref> encouraged researchers to study NL utterances to understand user needs. We build on this progress by elucidating ways in which conversational analytics systems may understand and respond to intent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Study Method</head><p>Prior to an expensive software development process, we needed to understand the importance of intent and context in analytical conversations, to define the minimum viable product and plan future improvements. We therefore conducted a Wizard of Oz study, with the goal to gather qualitative data on user expectations related to intent and context behavior. Many other studies followed, but we focus on this one as it was particularly influential. We first document the study and its findings; we then reflect on how the findings impacted development.</p><p>We iteratively refined our task, data set, and wizard behavior rules through a pilot study with 10 participants, which also provided wizard practice. We discarded data sets where the data was not easily understood or participants could not consistently achieve meaningful insight within 25 minutes, leading us to the Titanic dataset. We also refined wizard behavior rules to keep users in the flow of analysis as much as possible within each condition (judged qualitatively based on actions users took to correct 'system' behavior as well as users' expressed frustration).</p><p>We use the term utterance to refer to a participant's typed input to the system (used by the wizard) and aloud to refer to a vocalization in conversation with the experimenter (used in our subsequent analysis).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Conditions</head><p>We compared 4 conditions, in which 'system' behavior varied across axes of context and intent (see <ref type="table" target="#tab_0">Table 1</ref>). B (baseline) examined whether a simple system that chooses visual encodings based primarily on data attributes (via ShowMe <ref type="bibr" target="#b38">[37]</ref>) could be sufficient. The other conditions allowed us to explore the added value of understanding intent and remembering context, plus user expectations surrounding those concepts. A wizard controlled chart creation in all conditions. We chose a between-subjects design to avoid learning and fatigue effects. Intent: In the no-intent conditions (B, C), the wizard followed prescribed rules. Initially, we planned B to simply use ShowMe plus filters. Pilots demonstrated that this was frustrating, so we added the additional B rules in <ref type="table" target="#tab_0">Table 1</ref>. The visual encoding was always the ShowMe default except for explicit requests. In intent conditions (I, CI), the wizard made smarter choices based on their understanding of the user's analytical intent and used their semantic knowledge of the data (e.g. upper class = class 1).</p><p>Context: In no-context conditions (B, I), every utterance was treated independently; the wizard cleared the view between visualizations. Context conditions could adapt the existing visualization state (C by pre-defined rules, CI by wizard judgment). C context retention rules were adapted and refined over a series of pilots, as we found it difficult to define prescriptive rules for transitioning the context of attributes without unexpected behavior. Ultimately, unless there was an anaphoric reference or explicit instructions in the input, we retained both dimensions (independent variables) and filters, but replaced numeric measures (dependent variables) when a new one was specified.</p><p>Context and intent understanding are not strictly independent. CI involved wizard judgment of two types of intent: analytic intent as in I, plus context intent of what the user wants to retain from the prior step. Experiencing the wizard role helped us break intent into these two components and understand the need for systems to interpret both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Participants</head><p>We recruited 41 volunteers (18 female, 21 male, 1 male/female pair who walked in together): 26 via an information desk at the Tableau Conference and 15 by email within our organization. All were fluent in English. Participants spanned several industries (retail, education, finance, travel, etc.) and all had analytics experience with spreadsheets and Tableau. They were each randomly assigned to one of 4 conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Task and Data</head><p>We employed an open-ended task with no correct answer. Participants examined the Titanic dataset (1309 records, 10 fields) and attempted to answer the question "Which characteristics made it more likely that a passenger survived?" Participants were instructed to phrase their input naturally, as if they were interacting with a search engine that only knew about the Titanic dataset. They were given a reference page containing data fields and example values. We used only one dataset because the wizard needed to be very familiar with the data. None of our participants reported familiarity with the data set itself, though they were familiar with the Titanic disaster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Apparatus and Setting</head><p>We used a custom version of Tableau <ref type="bibr">Desktop 10.5 [3]</ref> shown in <ref type="figure" target="#fig_1">Figure 3</ref> (top). Custom additions were a text input box for the user to type NL input and a red text field for feedback. Input utterances were copied to the feedback field, which could be edited by the wizard (e.g. for error messages). Participants interacted with Tableau only in presentation mode, which showed only the visualization, a descriptive caption, filter controls, and legends. The wizard used the full Tableau Desktop interface to produce visualizations.</p><p>Three experimenters (including the authors) played the wizard role. All were regular users of Tableau, with a minimum of 1.5 years experience with the tool. Wizards intensively discussed and documented behavior rules during pilots to ensure consistency.</p><p>Each session started with a blank screen, mirroring the experience of authoring a visualization from scratch in tools like Tableau Desktop. Subsequent questions were asked with the previous visualization still in view. Filter widgets were always shown for any applied filter. Participants could interact with visualizations through tooltips, filter controls, and by selecting items in a legend to highlight the related subset; these automatic actions did not require wizard intervention.</p><p>Figure 3 (bottom) shows the physical setup. Participants interacted with content on a 20" monitor using a mouse and keyboard. A wizard used a MacBook Pro laptop to create visualizations and had a 20" monitor to duplicate the user's screen. Whenever the wizard was manipulating a visualization, the user's screen displayed, "Processing, please wait. . . ". The wizard switched the monitor between the visualization display and the processing message by toggling between extended and mirrored display modes. Due to constraints of the conference setting, the wizard had to be in the same room as the participant; however, the physical setup obscured the participant's view of the wizard's actions. We screen recorded the participant's view plus audio. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Procedure</head><p>Sessions lasted approximately 25 minutes (2-5 minutes of introduction, 15-20 minutes of actual task, 3-5 minutes of wrap-up) and participants created an average of 9 visualizations. An experimenter led the session and employed a question-asking protocol to elicit qualitative information (alouds) from the user for subsequent data analysis. The wizard was introduced as "technical support"; their role was revealed during wrap-up. Input to the system was typed, not spoken, and wizards were trained to respond only to the text utterances. After typing their input, participants saw the processing screen and the wizard created the visualization (or provided a pre-defined error message if the input did not match 'understandability' criteria). Wizard response time was typically 30 − 60s. During this time, the experimenter asked the participant what they expected the system to do. The experimenter subsequently prompted them for feedback on the system behavior. Some participants guessed that the system was being operated by a human, but played along; we did not notice a difference in their behavior compared to participants who did not know. The wrapup interview asked participants to reflect on unexpected system behavior and possible improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Post-Study Analysis</head><p>We created detailed notes for each session, including exact text utterances, timestamps, visualization screenshots, mouse actions such as filtering and sorting, and participants' alouds (i.e., their comments about expectations and feedback). Subsequent analysis was conducted on this video catalog, which is available as supplemental material.</p><p>We conducted a qualitative, multi-pass, open coding analysis based on grounded theory <ref type="bibr" target="#b4">[5]</ref>. We focused on user and system behaviors around intent, context, and their relationships. Input utterance / visualization response pairs were the unit of our analysis. Each pass investigated a new concept and refined the coding of previous passes. To mitigate impact of varying wizard behavior (both intentional variation across conditions and occasional unintentional variation within conditions), we explicitly chose to analyze the user's expectations of the response to their input in relation to the actual visualization generated (i.e., rather than the expected visualization based on the wizard rules). Experimental condition was also considered as a contextual factor that was likely to impact user expectations.</p><p>To understand user intent in relation to visualizations, we categorized unexpected system behaviors based on participants' alouds and actions they took to prevent or recover from system errors. We also examined visualization design elements (beyond the basic condition B behavior) that users reported were helpful. To understand context, we used alouds to categorize user intent around transitions, such as whether the user intended to adjust the visualization, elaborate on it, or start over. We compared this expectation against the visualization response to identify instances where context was unexpectedly lost or retained.</p><p>Open coding tags were organized through axial coding. At this stage, we realized that our initial groupings corresponded to steps in the visualization reference model <ref type="bibr" target="#b7">[8]</ref> and we identified relationships between categories. The axial coding step resulted in our conversational transitions model (next section). Later structured coding passes were done to gather quantitative information and to completely describe expected vs. actual visualization transitions using our model. We note that our focus was on qualitative understanding of system requirements rather than quantitative comparison of conditions. We collected frequency data for our observations (as a rough indicator of prevalence); however, we did not employ statistical hypothesis testing and would not expect these numbers to be representative of real system use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Study Findings</head><p>We first introduce the conversational transitions model that emerged from our analysis and helped us to organize and interpret our findings.</p><p>We then describe what we learned about how VA systems might handle context information and user expressions of intent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Conversational Transitions Model</head><p>Our conversational transitions model ( <ref type="figure" target="#fig_2">Figure 4</ref>) describes how to transition a visualization state during an analytical conversation. The model is inspired by conversational centering <ref type="bibr" target="#b23">[24]</ref>, commonly used for identifying structure in human communication. Conversational centering describes how the context of a conversation adjusts over time to maintain coherence, through transitional states that retain, shift, continue, or reset discourse elements (in this case, visualization components). A key insight during our analysis was that users' intent around transitions (how they expected the visualization to change) may apply to any or all aspects of a visualization state, not just filters as in Evizeon <ref type="bibr" target="#b26">[27]</ref> and Orko <ref type="bibr" target="#b50">[49]</ref>. Applying transitions to filters alone is insufficient for a conversational system that creates new visualizations in response to user input, especially one that updates a single visualization at each step. We adopted our state definition from the visualization reference model <ref type="bibr" target="#b7">[8]</ref>, wherein the visualization state is comprised of the data attributes in play, transformations (e.g. calculations to create derived attributes), filters, and the visual encoding of attributes.</p><p>After interpreting a visualization (the thinking human in <ref type="figure" target="#fig_2">Figure 4</ref>), a user may continue their analytical conversation by formulating a new question. This analytical intent will ultimately drive a user's transitional goals (how they wish to transform the existing visualization to answer the new question), which in turn drive user actions. We identified the following transitional goals: elaborate (add new data to the visualization), adjust / pivot (adapt aspects of the visualization), start new (create an altogether new visualization), retry (re-attempt a previous step that failed), and undo (return to the prior state).</p><p>This model was derived through the coding analysis. Topical organization of unexpected behaviors revealed categories related to attributes, transformations, filters, and visual encodings. An unexpected encoding might show a bar chart when the user expected a crosstab. Attributes could be unexpectedly dropped or retained from the prior step or the system could include a different attribute than the user intended in cases of ambiguity. Unexpected filtering often occurred when users asked for 'survivors', where they sometimes wanted both Survived? = 'yes' and 'no,' but other times wanted only 'yes.' Unexpected behavior around transformations included instances where the system showed raw counts instead of an expected survival rate percentage. Organization into these categories also revealed a 1:1 correspondence between system actions and unexpected behaviors: smart system actions prevented unexpected behavior and / or supported error recovery, whereas naïve system actions led to problems. One smart system action (in I and CI) was to interpret 'survival' as the calculation %survived.</p><p>Initially, we wondered whether a simple system based on ShowMe <ref type="bibr" target="#b38">[37]</ref> could be sufficient for analytical conversation, given a list of attributes extracted from the utterance. Our transitions model made it clear that the answer was no, and helped us articulate why. ShowMe automatically creates a visual encoding for selected attributes. However, it does not infer missing attributes or intended transformations, does not address filtering, and does not consider what visual encoding a user might intend. Apart from the point case of adding a single attribute to a view, it also does not ensure visual encoding coherence between states. A more intelligent system would infer a user's transitional goals based on their actions and then update the visualization components accordingly. It would also be able to interpret and respond to user intent around each component of a visualization state (i.e., attributes, transformations, filters, and visual encodings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Impact of Failing to Understand Intent and Context</head><p>What goes wrong when the system fails to correctly understand intent or context? Here we summarize people's reactions to system behavior to examine the impact of these components of intelligence. We focus first on unexpected system responses, as these were often problematic or undesirable. We use the notation [Participant.Condition] to contextualize quotes with the condition the participant experienced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Unexpected System Behavior</head><p>In relation to our model <ref type="figure" target="#fig_2">(Figure 4)</ref>, unexpected system behaviors ( <ref type="figure" target="#fig_3">Figure 5</ref>) mapped to the four visualization state components or an incorrect transition. Most often they related to visual encodings (62 cases) or transformations (44 cases, of which 28 were calculations). For attributes, unexpected behaviors involved an unexpected schema (e.g. misunderstanding the parents &amp; children aboard? {yes, no} attribute) or a failure to infer an un-named attribute (e.g. expecting that the system would also include NumberOfRecords even when the user asked for a % calculation). Transformation errors included binning (failure to bin or unexpected binning), aggregation at an unexpected level of detail (or lack thereof), or misunderstood intent around calculations. For instance, with the question, "Did younger women survive better than older women?" [P21.I] expected the system to choose a threshold value and group ages above and below the threshold. Instead the wizard showed all 5-year age bins.</p><p>Filter problems were typically failures to include or exclude data values. Observing a chart of %survived, [P12.C] input, "show this by count instead of percent," expecting to see only a count of survivors. Instead the wizard substituted NumberOfRecords for %survived, producing a total count. Participants also sometimes expected a filter widget to be available even when they had not asked to filter.</p><p>Unexpected visual encodings occurred most often when ShowMe chose a poor chart type for the task or when the participant simply expected a different chart type. For instance, while looking at a scatterplot, [P17.CI] requested, "split by class," expecting the system to create small multiples rather than add color encoding.</p><p>Unexpected behavior around transitions meant that either desired context from the prior state was lost, or undesired context was retained, in any visualization state component (attributes, transformations, filters, or encodings). When [P22.C] asked, "What class were people in?" while looking at a bar chart showing counts of survived vs. not, he expected class to be added as an additional variable rather than replacing the Survived? attribute. We also observed poor continuity in visual encodings. <ref type="figure" target="#fig_4">Figure 6</ref> shows an example where ShowMe substantially shifted the visual encoding when adding two new attributes. Unexpected visualization states were not always problematic. In 14 instances, unexpected behavior was actually more helpful: 5 times for encodings, 3 times for binning, 3 times for a retained attribute, once for a retained filter, and 2 times for a failure to exclude data values. <ref type="figure" target="#fig_14">Figure 1c</ref> is a real example from [P21.I], who expected a scatterplot. After examining the chart he remarked several times on its value, "This is a very interesting chart...This is actually telling the story of what happened. You can see that people who paid the most, and were in the middle age bucket, they survived the most as well...This is the most useful chart that it showed, out of everything." <ref type="figure" target="#fig_5">Figure 7</ref> compares total unexpected system behaviors per condition. Unsurprisingly, the 'intelligent' CI condition had the fewest unexpected behaviors, validating the usefulness of both intent and context understanding. Examining the other 3 conditions, though, was helpful to derive minimum system requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Comparison of Conditions</head><p>B, I, and C had similar unexpected behavior totals, but the distribution differed. B had the most unexpected visual encodings, suggesting that ShowMe's rules were insufficient. C (context without intent) had the most transition problems. Even in pilot studies, we found it difficult to prescribe accurate transition rules. I's attribute errors were mostly failures to infer an unnamed attribute (8/13 cases) and its transformation errors were mostly unexpected calculations (13/19 cases). Qualitatively, we observed the most frustration with C, as users could not predict what the system would choose to retain from the prior step. In contrast, B and I's behaviors were at least predictable. Participants learned to repeat and adjust their prior utterances to adapt the view, a strategy that was slightly annoying but effective. Unexpected visual encodings tended to have less impact on analysis than unexpected attributes, transformations, and filters -it is better to present the correct information non-optimally than to present the wrong information. Additional indicators of system failure are retry, repair, and explicit reset ("start over") actions, summarized in <ref type="figure" target="#fig_6">Figure 8</ref>. Retries involved rephrasing the prior utterance after it failed to achieve the desired result. Repair actions were explicit corrections (e.g., selecting and excluding an unexpected value, or removing an unexpected attribute as in, "take out fare bin" [P40.C]). Frequent resets suggest that participants lack confidence in the system's ability to transition between states. [P22.C] resorted to this (annoying) strategy when he lost confidence in the system's ability to detect an implicit reset. Most interesting here is the weak performance of C (context without intent).</p><p>Comparing the conditions revealed two key insights that later informed our system design: (1) Avoid trying to understand context without understanding intent (i.e. the poor performance of C) and (2) B was surprisingly okay since its behavior was predictable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Responding to Intent and Context in VA Systems</head><p>Conversational analytics systems need to extract user intent from the utterance and then choose how to respond. The supplemental material documents keywords and cues that may help with extracting intent from NL. Here we focus on the latter problem: once we understand intent, how can we produce the most useful visualization?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Supporting Explicit and Implicit Intent</head><p>Wizard choices were often better than ShowMe's default because the wizard could understand a user's analytical intent (whereas ShowMe relies only on field types). Here, we explore how a system like ShowMe might be extended, given intent as an additional input. Prioritize explicit intent requests: Explicit intent requests clearly state user expectations, and therefore should take priority. For example, "color by sex" indicates color encoding, "show only female" indicates a filter, and the utterance in <ref type="figure" target="#fig_7">Figure 9</ref>(c) specifies a scatter plot. Visual encoding heuristics for implicit intents: Implicit intents do not directly specify encodings, but visualization best practices can define encoding heuristics. We observed that actions and targets from Munzner's why framework <ref type="bibr" target="#b40">[39]</ref> could be identified from utterances and used to model intent. The following examples illustrate how actions and targets can be translated to suitable visualizations by linking them to Few's <ref type="bibr" target="#b17">[18]</ref> best practices for data visualization:</p><p>• Numeric analysis: <ref type="figure" target="#fig_7">Figures 9(a)</ref> and 10 identify a distribution target suited to a histogram. In contrast, a correlation target can be revealed in a scatterplot (if the variables are continuous) or highlight table (if discrete), as in <ref type="figure" target="#fig_14">Figure 1</ref>(c). • Categorical data analysis: For an overview of many attributes, as in "Show survival by class, sex, ChildrenAboard? and SpouseAboard?" use the compact heatmap representation. In contrast, <ref type="figure" target="#fig_8">Figure 10</ref> implies a comparison of target attribute survived?: side-by-side views are appropriate for such comparison tasks. A comparator attribute can be redundantly encoded with color if cardinality is low. Alternatively, if the target is an extreme as in "Class with the highest survival rate," the target item should be sorted to the top and highlighted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Transitions: Prioritize Intent Over Encoding Coherence</head><p>A key insight of our model <ref type="figure" target="#fig_2">(Figure 4</ref>) was that transition states of continuing, retaining, and shifting need to be applied to all visualization state components (attributes, transformations, filtering, and encoding) to maintain conversational coherence. Maintaining coherence in the visual encoding is important, as abrupt changes to the visual representation can be jarring and easily misinterpreted. <ref type="figure" target="#fig_10">Figure 11</ref> shows an example where the naïve use of ShowMe in B resulted in a misunderstood change. However, analytical intent may conflict with the goal to maintain visual encoding coherence. Examining instances from the study convinced us that analytical intent should take priority when it is known. Sometimes it is worth the cognitive cost of interpreting a new encoding to gain a better visualization for one's task. For example, in <ref type="figure" target="#fig_14">Figure 1</ref>, the second utterance can be handled by simply adding a new column and color encoding to the existing view; however, supporting the correlation target in the third utterance requires a substantial encoding change. The poor performance of C (context without intent) underlines the importance of this prioritization and the need to accurately infer user intent in a system that supports follow-on utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Anticipate User Needs with Proactive Design</head><p>We observed that some wizard design choices were proactive, failsafe and supported flexibility. These design choices enabled users to easily correct misunderstandings or adapt the visualization to answer more questions. Key fail-safe and proactive design choices were:</p><p>• Display filter controls and interactive legends: Filter controls enable users to recover data that was incorrectly filtered or restore it later for comparison. Interactive legends similarly enable highlighting and filtering. • Show data in context: Instead of filtering to a named value,</p><p>show the target value in comparison to alternatives. E.g. the answer to "how many people survived?" is more interesting in comparison to the number who did not survive. • Adjust row/column nesting order: Changing the default attribute order to create a hierarchy suited to the question. E.g. "Compare survival by sex for each class" implies a different nesting order than "Compare survival by class for each sex." • Redundant color encoding: Redundantly encoding an important variable, typically the focus of a comparison. E.g. in the nesting examples above, redundantly encode sex in the first case and class in the second. <ref type="figure" target="#fig_8">Figure 10</ref> shows another example.</p><p>• Encoding based on semantics: Using similar encodings and placement for semantically related attributes enhances interpretability (e.g., parent/child and sibling/spouse).    Anticipating user needs in these ways was nearly always met with praise. Participants expressed excitement and were impressed with how well the system could answer their questions. For example, [P41.I] commented, "This is better than I expected, because I thought I was just going to get a filter to yes...but I got no as well, so now I have more of the context, which is good." Similarly, [P34.C] appreciated filter widgets, "Even though I only asked for males, it has options."</p><p>Proactive behavior is an established concept in intelligent user interfaces, explored in domains such as information systems (e.g. <ref type="bibr" target="#b5">[6]</ref>), task management (e.g. <ref type="bibr" target="#b58">[57]</ref>), and mobile interaction (e.g. <ref type="bibr" target="#b56">[55]</ref>). However, proactivity has been only minimally investigated for analytics and visualization, despite a recent call for more proactive behavior in visualization tools <ref type="bibr" target="#b49">[48]</ref>. Guo et al. explored proactive suggestions for data wrangling, with mixed feedback from users <ref type="bibr" target="#b24">[25]</ref> and various visual analytics systems have explored recommendations (e.g., <ref type="bibr" target="#b39">[38,</ref><ref type="bibr" target="#b57">56]</ref>), but none of these systems integrated an explicit understanding of user intent. It is clear from our results that proactive behavior is a worthwhile future direction to explore for analytical conversation.</p><p>We are working towards implementing proactive behavior. Ask Data includes filter controls and legends, visually encodes filtered attributes in a bar chart, and offers limited support for calculation transformations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Study Takeaways for Ask Data Implementation</head><p>This section examines how results of the Wizard of Oz study influenced Ask Data, drawing on example utterances from the study as well as subsequent observations of the system in use. We reflect on how our experience developing Ask Data, and studies of the system in use, confirmed or contradicted what we learned in our pre-design study. Participants in the study got into a flow of analysis, employing related utterances in series to investigate a problem. This behavior prompted our most important design principle for Ask Data: no dead ends. We also observed that when participants were in the flow of analysis, their alouds focused on the data; when their flow got disrupted by undesirable system responses, they focused on system design. This led to the design principle the interface disappears; it's all about my data. These design guidelines also served as evaluation criteria, helping us understand what to look for in subsequent usability studies.</p><p>Based on these design guidelines, the main technical takeaways for designing the system behavior were:</p><p>• Handle underspecified utterances and make smart system inferences to keep users in the flow of analysis. • Maintain context to facilitate a conversation with the system based on previous utterances and the current visualization state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Inferencing to Handle Underspecificity</head><p>Nearly all utterances in the study were underspecified. Visual encodings and data attributes were frequently incomplete, left out, or specified indirectly as an analytical goal (e.g. "sales over time" with a time attribute left out). This motivated us to develop heuristics and inferencing logic to provide defaults for missing inputs <ref type="bibr" target="#b45">[44]</ref>. Ask Data infers data attributes and encodings for partial analytical expressions to help satisfy the intent in input utterances. Our inferencing logic includes inferring a descending sort order when users ask for "products with highest sales" to show the highest value on top. We also support visualization responses requested by users, with sensible inferencing to map an abstract concept such as 'location' to an appropriate geo attribute or inferring a scatterplot when a user types "show me the correlation." In addition to supporting vague and underspecified analytical intents, Ask Data also supports flow by providing suitable alternatives, in case the system does not support the direct request. For example, in Tableau, one can only create a histogram with a measure, and not a dimension. So, if Age is a numerical dimension, and a user types "age as a histogram," Tableau would not return a visualization response. However, the underlying intent is probably to view the number of records per numerical quantity, especially if the user has created a binned form (Age (bin)). Ask Data can infer the binned field and display Age (bin) as a a bar chart, seen in <ref type="figure" target="#fig_1">Figure 13</ref>. Similarly, based on user feedback, we improved analytical intent for the phrase "How many" to infer 'distinct count' for countable entities such as dimensions, but the default aggregation such as 'sum' or 'average' for quantitative measures. <ref type="figure" target="#fig_2">Figure 14</ref>: Top: Mapping the intent of "how many" to distinct count for a countable dimension room types. Bottom: The default aggregation average for a measure Beds is inferred for "how many".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Managing Context in Conversational Flow</head><p>Context in a "smart" system is its ability to take into account the information, circumstances and factors surrounding the interaction with a user <ref type="bibr" target="#b55">[54]</ref>. Specifically with an NL system such as Ask Data, realizing the pragmatic meaning of such an analytical conversation is a matter of matching up the linguistic elements of the utterances with the schematic entities of the context. These entities could be people, places, or objects that are considered relevant to the interaction <ref type="bibr" target="#b12">[13]</ref>.</p><p>A surprising and encouraging finding from the study was that B, arguably the least intelligent condition, was not so bad in terms of the user experience. C (context) was clearly worse due to its unpredictability. To us, this meant that the implementation of Ask Data could be broken into phases -develop a basic system first, iteratively improve its understanding of intent, and then add support for contextual understanding. We adopted an incremental approach to implementing contextual understanding based on the classification of context in ordered degrees of complexity, stemming from linguistic literature <ref type="bibr" target="#b35">[34]</ref>.</p><p>Situational Context: Situational context refers to the environment and information where the interaction occurs <ref type="bibr" target="#b31">[31]</ref>. With respect to analytical conversation, that environment is the underlying data source being explored. To provide situational context in the analytical workflow, we surfaced an explicit interface, the data pane, that displays information about the attributes in the data source and their data properties. Icons are used to distinguish the various data types (e.g., geo, date time, numeric and text). Hovering over each attribute provides additional semantic information such as synonyms and top values in the data domain based on cardinality (refer to <ref type="figure" target="#fig_3">Figure 15)</ref>.</p><p>Context through Intentional Interaction: The study also revealed how we could retain the character of conversational inter- action (principle of no dead ends), with only limited contextual understanding of follow-on utterances. A key annoyance with the no-context conditions was repeating partial utterances (e.g. "survival by sex" followed by "survival by sex and age" to add one attribute). In Ask Data we resolved this problem through a refinement user interface (UI). Clicking on any interpreted phrase opens a graphical UI where users can change their query, similar to how study participants used filter widgets to make adjustments. Users could also elaborate by typing a new scoped query that would add on to the current interpretation. The top row in <ref type="figure" target="#fig_4">Figure 16</ref> shows these various intentional interactions. Using a combination of on-boarding documentation for Ask Data and visual treatments to indicate that phrases in the UI textbox were editable, users were encouraged to adopt a mixed initiative approach for repair and refinement.</p><p>Linguistic Context: Linguistic context, or cohesion, refers to the relationship amongst tokens in the NL utterances, and how they relate to their predecessors and successors in a discourse <ref type="bibr" target="#b25">[26]</ref>. We leverage Ask Data's underlying query language Arklang to determine how linguistic context from the previous utterance informs interpretation of a new utterance. ArkLang provides a set of all syntactically valid and semantically meaningful analytical expressions that can be obtained from the semantic model describing the underlying data source, a context-free grammar, along with a fixed set of semantic constraints <ref type="bibr" target="#b45">[44]</ref>.</p><p>Linguistic context is determined by a set of Add, Remove and Replace operations as implemented in Algorithm 1 and shown in <ref type="figure" target="#fig_4">Figure 16</ref> (bottom row). For example, if τ = "distinct count of Beds by Neighborhood," and β is the filter expression "Beds at least 2," Ask Data will update τ with β, applying a filter to the visualization in context. A Replace intent "by Description instead of Neighborhood," will replace the group expression "by Neighborhood" with the group expression "by Description," where α = "by Neighborhood," and β = "by Description." If β is the Remove intent for "at least," with α = "Beds at least 2" in play, the update U function will remove the filter on the current visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Impact on work in progress</head><p>Some insights from the study are not yet in the product (at the time of writing) but are influencing work in progress. These include comparison intents (as in <ref type="figure" target="#fig_8">Figure 10</ref>), additional semantics to inform inferencing, and visual encoding coherence to address jarring changes such as <ref type="figure" target="#fig_10">Figure 11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">What We Missed</head><p>The study presented here naturally missed some insights and identified others that turned out to be less important. One observation Algorithm 1: Handling linguistic context in Ask Data Input: natural language utterance β Output: VizQL Let U = (τ, α, β) be the update function that determines the linguistic context to perform Add, Remove and Replace operations to the current contextual set of analytical expressions τ in the system. α is an analytical expression that is part of τ. β is the current utterance in the discourse. Add determines intent for adding β to τ. Remove determines intent for removing α from τ. Replace determines intent for replacing α with β in τ. was that breaks in analytical flow could be detected via overlap of concepts in subsequent utterances (see supplemental material). This turned out to be irrelevant because we designed the interface to retain prior inputs until a user explicitly removed them. Additionally, while the study identified a need for smart inferencing, details of what to infer (and when) required substantial follow-up. The study also did not offer insight into user learning or skill development.</p><p>Because the Titanic data set had only one measure (Num-berOfRecords), we also saw little diversity in calculations or numerical targets like outliers. Even within the limited context of the Titanic data set (where most transformations were % calculations), the ways in which people expressed intent around calculations were varied and complex. We later repeated the Wizard of Oz approach in a follow-on study specifically focused on understanding calculation intents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Limitations and Future Work</head><p>Our study design has several limitations that restrict the generalizations we can draw from our results. Most notably, we chose to sacrifice some internal validity by running the study in a noisy conference setting with the wizard in the same room as the participant; we made this choice for external validity since it enabled access to our target user population. However, wizards may have been influenced by overhearing the conversation and participants may have been influenced by the wizard presence. Additionally, wizard judgment played a large role in the 'system responses' and was not strictly controlled, making system responses less machine-like and subject to human bias and interpretation. We mitigated some of these effects by having the wizard follow strict rules in the no intent conditions and training them to respond only to text utterances. We also analyzed what users said they expected in relation to their input, regardless of the actual system response, focusing on what system behavior they intended with their utterance.</p><p>Absence of autocompletion and delayed response time reduced realism, as expected in this type of study. At the same time, the system delay enabled us to ask people about their expectations, generating rich qualitative data. The study also used only one data source that was somewhat simplistic. Later investigations for Ask Data elaborated on this work by exploring more complex data sources and utterances.</p><p>Future work might investigate changes in interaction patterns over the longer-term course of an analysis session, intents around learning system capabilities, and handling query over-specification (e.g. suggesting reduced constraints when no results are returned). We would also like to explore voice and multi-modal interaction.</p><p>Adding "at least 2 beds"</p><p>Replacing Neighborhood with Description</p><p>Removing "with Beds at least 2" <ref type="figure" target="#fig_4">Figure 16</ref>: A user interacting with the New Orleans AirBnB <ref type="bibr" target="#b0">[1]</ref> data source in Ask Data. Top row: First version of Ask Data supporting intentional interaction to explicitly add, replace and remove utterances as scoped queries. Bottom row: Newer version of Ask Data that additionally supports natural language utterances to add, replace and remove interpreted phrases using linguistic context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Studying Smart Systems</head><p>Studying analytical conversation systems is notoriously difficult. Any structured (i.e., quantitatively measurable) task is nearly impossible to articulate without biasing users' NL input. Such tasks are also poor representatives of real world use. When we evaluated Eviza <ref type="bibr" target="#b44">[43]</ref>, we noticed substantial behavior differences on structured tasks compared to open-ended analysis. Yet without structured tasks, it is difficult to define concrete indicators of success. Observing that when users are in the flow of analysis, they focus on the data, not the interface, was a key insight. We looked for this throughout future studies of Ask Data. The Wizard of Oz study enabled us to test ideas and make key decisions early. Despite the study's limitations, the results were impactful, reducing uncertainty around requirements and design choices, undoubtedly reducing costly development time. We repeatedly found ourselves referring back to examples from this pre-design study to answer small questions that arose throughout development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a pre-design empirical study that informed design considerations for Ask Data, a deployed analytical conversation system. Results of the study gave us a systematic way to think about intent and context understanding in analytical conversations, suggested approaches to interpret and respond to intent, and revealed how varying levels of system understanding might effect the user experience. Findings influenced our design principles and prompted us to develop inferencing to handle underspecification and strategies to manage user expectations around context. Overall, the study narrowed the space of design options under consideration, reducing uncertainty around timing and feasibility. We hope that others may find value in our insights around the design of intelligent visual analytics systems, the value of pre-design studies, and the challenges of productizing research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Ask Data's response to "gold medals of each gender over time."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Environment and hardware setup used in the study (bottom) and participant's view of the software (top).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Conversational transitions model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Total unexpected behaviors (gray: vis state, blue: transitions).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>(Top) Response to, "people by parents or children" [P23.C]. (Bottom) Response to follow-up utterance, "count of survival by age (bin) and parents or children." ShowMe substantially changed the view, moving the row attribute to color and changing the bar orientation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Unexpected behaviors by condition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Total reset, retry, and repair actions across all participants.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>•Figure 9 :</head><label>9</label><figDesc>Visually encode filtered attributes: Including a filtered attribute as an encoded variable supported follow-up actions. By adjusting the filter control, participants could obtain a useful comparison visualization, as illustrated inFigure 12.• Add bonus info: Anticipate future needs by adding more information than requested. E.g. [P4.CI] asked how many children were under age 10, and the system responded with an age histogram showing frequency of all age groups. • Apply transformations: Binning quantitative variables (binned versions of age and fare were easier to interpret) or creating useful calculations (e.g. percentages). (a) "Distribution of survivors by fare?" (b) "split this data by survived status" (c) "scatter plot of survival status by age and fare" (d) "add a trend line" A snippet of analytical conversation in [P17.CI]'s session. "Distribution" in (a) is an implicit intent for a histogram. "split this" in (b) indicates a transition to small multiples. In (c), the full sentence and new attributes suggest a new line of inquiry and "scatter plot" is an explicit encoding request.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Response to, "What is the age distribution of those who survived and didn't survive?" [P11.I] The distribution target and implied comparison action suggest two histograms. The target attribute survived? is redundantly encoded using position and color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>(</head><label></label><figDesc>a) "percent survived for each age bin" (b) "percent who survived for each age bin, plus the number who survived"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Transition with poor visual coherence, from [P38.B]'s session. Age moves from the y axis to color, which the participant fails to notice.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>(Top) Response to, "How many passengers in class 1 survived?" [P5.B] (Bottom) Because Class is also a row attribute, adjusting the filter control creates a comparative visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 :</head><label>13</label><figDesc>Ask Data's response to "age as a histogram." Because Age is a numerical dimension as opposed to a measure, the system infers the binned form of the field and displays a bar chart to provide a reasonable alternative to the user's request.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 15 :</head><label>15</label><figDesc>An explicit contextual data pane that provides situational context regarding the types of attributes and their properties to help a user type valid analytical expressions in Ask Data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>1</head><label>1</label><figDesc>Perform an Add(β) operation if β τ. 2 Perform a Remove(β) operation if β = α. 3 Perform a Replace(α, β) operation where we apply Remove(α) and Add(β). 4 Apply U if U = (τ, α, β) satisfies Arklang constraints.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Study conditions (Cx = context memory). C, I, and CI conditions add functionality beyond the Baseline condition. A more detailed version of this table is available in supplementary material.</figDesc><table><row><cell></cell><cell>No Intent</cell><cell>Understand Intent</cell></row><row><cell></cell><cell>B (Baseline) ShowMe default encoding.</cell><cell>I (Intent)</cell></row><row><cell>No Cx</cell><cell>Add NumberOfRecords if no measure given. Fuzzy string match. On explicit request: filters, chart types, calcs, sorting, binning.</cell><cell>Understood synonyms &amp; semantics. Custom visual encodings. Automatic binning, calcs, sorting.</cell></row><row><cell></cell><cell>C (Context) Prescriptive content retention rules:</cell><cell>CI (Context &amp; Intent)</cell></row><row><cell>Cx</cell><cell>Retain all on explicit request or anaphoric reference. Reset all on 'reset'. Otherwise: Retain filters, dimensions. Replace measures.</cell><cell>I plus context memory. Wizard judgment of what to retain and when to reset.</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Jeff Ericson and Naomi Bancroft for the custom software, Anthony Chen for study assistance, and Marti Hearst for feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Airbnb</surname></persName>
		</author>
		<ptr target="https://www.airbnb.com" />
		<imprint>
			<biblScope unit="page" from="2019" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tableau's Ask</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Data</surname></persName>
		</author>
		<ptr target="https://www.tableau.com/products/new-features/ask-data" />
		<imprint>
			<biblScope unit="page" from="2019" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tableau</forename><surname>Desktop</surname></persName>
		</author>
		<ptr target="https://www.tableau.com/products/desktop" />
		<imprint>
			<date type="published" when="2019-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Query Recommendation Using Query Logs in Search Engines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hurtado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mendoza</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-540-30192-9_58</idno>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="588" to="596" />
			<pubPlace>Berlin Heidelberg; Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Basics of grounded theory analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Barney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Emergence vs Forcing. Sociology press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving proactive information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Billsus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Hilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maynes-Aminzade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf Intelligent User Interfaces</title>
		<meeting>Conf Intelligent User Interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A taxonomy of web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<idno type="DOI">10.1145/792550.792552</idno>
	</analytic>
	<monogr>
		<title level="j">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3" to="10" />
			<date type="published" when="2002-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Readings in information visualization: using vision to think</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Task-analytic approach to the automated design of graphic presentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Casner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="151" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bringing order to the web: Automatically categorizing search results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<idno type="DOI">10.1145/332040.332418</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCHI Conf. Human Factors in Computing Systems, CHI &apos;00</title>
		<meeting>SIGCHI Conf. Human Factors in Computing Systems, CHI &apos;00<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A taxonomy of visualization techniques using the data state reference model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symp. Information Visualization, INFOVIS &apos;00</title>
		<meeting>IEEE Symp. Information Visualization, INFOVIS &apos;00<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page">69</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Mixed initiative visual analytics using task-driven recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">O</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Israel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wolverton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Burtner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2015.7347625</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Understanding and using context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Dey</surname></persName>
		</author>
		<idno type="DOI">10.1007/s007790170019</idno>
	</analytic>
	<monogr>
		<title level="j">Personal Ubiquitous Comput</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="7" />
			<date type="published" when="2001-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Analyza: Exploring data with conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dhamdhere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Mccurley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nahmias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Intelligent User Interfaces</title>
		<meeting>Conf. Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="493" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">What we talk about when we talk about context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dourish</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00779-003-0253-8</idno>
	</analytic>
	<monogr>
		<title level="j">Personal Ubiquitous Comput</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="30" />
			<date type="published" when="2004-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Intentions in the coordinated generation of graphics and text from tabular data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fasciano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="310" to="339" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Iris: A conversational agent for complex tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mendelsohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05015</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Show me the numbers: Designing tables and graphs to enlighten</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Few</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Analytics Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Datatone: Managing ambiguity in natural language interfaces for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Karahalios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Symp. User Interface Software Technology</title>
		<meeting>ACM Symp. User Interface Software Technology<address><addrLine>UIST; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">5 trends emerge in the gartner hype cycle for emerging technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gartner</surname></persName>
		</author>
		<ptr target="https://www.gartner.com/smarterwithgartner/5-trends-emerge-in-gartner-hype-cycle-for-emerging\-technologies" />
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2019" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Constructing models of user and task characteristics from eye gaze data for user-adaptive information highlighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gingerich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Conati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1728" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Directing exploratory search: Reinforcement learning from user interactions with keywords</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Glowacka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ruotsalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Konuyshkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Athukorala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kaski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jacucci</surname></persName>
		</author>
		<idno type="DOI">10.1145/2449396.2449413</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Intelligent User Interfaces, IUI &apos;13</title>
		<meeting>Conf. Intelligent User Interfaces, IUI &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Behavior-driven visualization recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Intelligent User Interfaces</title>
		<meeting>Conf. Intelligent User Interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Attention, intentions, and the structure of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Sidner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="175" to="204" />
			<date type="published" when="1986-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Proactive wrangling: mixed-initiative end-user programming of data transformation scripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kandel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Symp. User interface software and technology</title>
		<meeting>Symp. User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Halliday</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cohesion in English. English Language Series</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Applying pragmatics principles for interaction with visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dykeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="309" to="318" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mining query subtopics from search log data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGIR Conf. Research and Development in Information Retrieval, SIGIR &apos;12</title>
		<meeting>ACM SIGIR Conf. Research and Development in Information Retrieval, SIGIR &apos;12</meeting>
		<imprint>
			<biblScope unit="page" from="305" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/2348283.2348327</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ACM</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Determining the informational, navigational, and transactional intent of web queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Spink</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2007.07.015</idno>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1251" to="1266" />
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Nicky: Toward a virtual assistant for test and measurement instrument recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pollock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 11th Intl. Conf. Semantic Computing (ICSC)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="196" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Embedded menus: Selecting items in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Koved</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scneiderman</surname></persName>
		</author>
		<idno type="DOI">10.1145/5684.5687</idno>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="312" to="318" />
			<date type="published" when="1986-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mining anchor text for query refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kraft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zien</surname></persName>
		</author>
		<idno>doi: 10. 1145/988672.988763</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on World Wide Web, WWW &apos;04</title>
		<meeting>the 13th International Conference on World Wide Web, WWW &apos;04<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="666" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic identification of user goals in web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. World Wide Web, WWW &apos;05</title>
		<meeting>Conf. World Wide Web, WWW &apos;05</meeting>
		<imprint>
			<biblScope unit="page" from="391" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/1060745.1060804</idno>
		<imprint>
			<date type="published" when="2005" />
			<publisher>ACM</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The role of context in discourse analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lichao</surname></persName>
		</author>
		<idno type="DOI">10.4304/jltr.1.6</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Teaching and Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="876" to="879" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Alexa vs. siri vs. cortana vs. google assistant: a comparison of speech-based natural user interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quesada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Guerrero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. Applied Human Factors and Ergonomics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="241" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automating the design of graphical presentations of relational information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="110" to="141" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Show me: Automatic presentation for visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Formalizing visualization design knowledge as constraints: Actionable and extensible models in draco</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Visualization analysis and design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Inferring query intent from reformulations and clicks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Szummer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<idno>doi: 10.1145/ 1772690.1772859</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. World Wide Web, WWW &apos;10</title>
		<meeting>Conf. World Wide Web, WWW &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1171" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Directing exploratory search with interactive intent modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ruotsalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peltonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eugster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Glowacka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Konyushkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Athukorala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kosunen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reijonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Myllymäki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jacucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kaski</surname></persName>
		</author>
		<idno>doi: 10.1145/ 2505515.2505644</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Conf. Information &amp; Knowledge Management, CIKM &apos;13</title>
		<meeting>ACM Conf. Information &amp; Knowledge Management, CIKM &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1759" to="1764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Artificial Intelligence: A Modern Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Prentice Hall Press</publisher>
			<pubPlace>Upper Saddle River, NJ, USA</pubPlace>
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Eviza: A natural language interface for visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Battersby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gossweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proce. ACM Symp. on User Interface Software and Technology, UIST 2016</title>
		<meeting>e. ACM Symp. on User Interface Software and Technology, UIST 2016<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="365" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Inferencing underspecified natural language utterances in visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Setlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Djalali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Intelligent User Interfaces</title>
		<meeting>Conf. Intelligent User Interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Sorting out searching: A user-interface framework for text searches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="95" to="98" />
			<date type="published" when="1998-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">A siries of unfortunate events: Users&apos; emotional responses during the first month of siri use</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Smith</forename><surname>Auld</surname></persName>
		</author>
		<ptr target="https://blinkux.com/assets/Blink_Siri_White_Paper.pdf" />
		<imprint>
			<biblScope unit="page" from="2019" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A neural network approach to contextsensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/N15-1020</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Natural language interfaces for data analysis with visualization: Considering what has and could be asked</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EuroVis</title>
		<meeting>EuroVis</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="55" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Orko: Facilitating multimodal interaction for visual exploration and analysis of networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="511" to="521" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">User-adaptive information visualization: using eye gaze data to infer visualization tasks and user cognitive abilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steichen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Conati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Intelligent User Interfaces</title>
		<meeting>Conf. Intelligent User Interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="317" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Articulate: A semi-automated model for translating natural language queries into meaningful visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Symp. Smart Graphics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="184" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Bigbluebot: teaching strategies for successful human-agent interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Weisz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">N</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lange</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. on Intelligent User Interfaces</title>
		<meeting>Conf. on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Clustering user queries of a search engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1145/371920.371974</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. World Wide Web, WWW &apos;01</title>
		<meeting>Conf. World Wide Web, WWW &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="162" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">On the limitations of linguistics applied</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Widdowson</surname></persName>
		</author>
		<idno type="DOI">10.1093/applin/21.1.3</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="25" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A model for proactivity in mobile, context-aware recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Woerndl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gallego-Vico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM Conf. Recommender systems</title>
		<meeting>ACM Conf. Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="273" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Voyager: Exploratory analysis via faceted browsing of visualization recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="649" to="658" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The design of a proactive personal agent for task management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yorke-Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saadati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Morley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intl. J. Artificial Intelligence Tools</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page">1250004</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
