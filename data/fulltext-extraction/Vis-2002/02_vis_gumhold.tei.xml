<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Maximum Entropy Light Source Placement</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Gumhold</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">WSI/GRIS</orgName>
								<orgName type="institution">University of Tübingen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Maximum Entropy Light Source Placement</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.8 [Computer Graphics]: Miscellaneous-Lighting Design</term>
					<term>G.1.6 [Numerical Analysis]: Optimization-Global Optimization</term>
					<term>Lighting Design, Visualization, Illumination, Maximum Entropy, Optimization, User Study</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Finding the &quot;best&quot; viewing parameters for a scene is quite difficult but a very important problem. Fully automatic procedures seem to be impossible as the notion of &quot;best&quot; strongly depends on the human judgment as well as on the application. In this paper a solution to the sub-problem of placing light sources for given camera parameters is proposed. A light position is defined to be optimal, when the resulting illumination reveals more about the scene as the illuminations from all other light positions, i.e. the light position maximizes the information that is added to the image through the illumination. With the help of an experiment with several subjects we could adapt the information measure to the actually perceived information content. We present fast global optimization procedures and solutions for two and more light sources.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Lighting design approaches are seldom used in scientific visualization. Especially, in the exploration stage the scientist does not know much about the data set that he is looking at. With lighting design tools based on the inverse paradigm the user has to specify objectives and constraints that the illumination should satisfy. These are not applicable, as they require that the user can express his wishes. Instead most visualization tools provide a standard illumination or let the user interactively explore different lighting parameters. The latter forces the user to explore the data set as well as the lighting parameters what unnecessarily elongates the exploration process.</p><p>In this paper we present a tool to automatically design the illumination especially tweaked for the visualization process. The basic idea is to maximize the information introduced by the illumination. Information maximization is a common goal in scientific visualization and the most effective visualization techniques follow this idea. For example in vector field visualization the line integral convolution method proofed to be remarkably efficient. The technique initializes the image with a random noise texture, which has maximum information content. In the second phase the random texture is averaged along stream-lines. This can be interpreted as the annihilation of the information that conceals the vector field. The information portraying the vector field is maximized. Another example is the design of color or material palettes by the use of histogram methods. Here a scientific quantity of interest is monotonically mapped onto a visual attribute such that over the complete data set the probability of each possible value for the visual attribute is equally likely. The histogram approaches maximizes the information content of the visual attribute.</p><p>Section 3 describes how to place light sources in a way that maximizes the illumination information. A conservative global maximization procedure is presented as well as a fast modification that finds the global maximum in most cases. <ref type="figure">Figure 3</ref> shows examples of maximum information illuminations. They are not as helpful as expected. The first drawback is that a lot of information is found on flat surfaces, which typically do not compose the most important parts of the scene. The second drawback is that highlights are exaggerated, what perturbs more than it helps. In order to resolve the drawback we designed an experiment as described in section 4, in which several potential or already trained users of visualization tools had to adjust the light source positions until they could perceive the scene from a fixed view point as well as possible. Section 5 describes how we used the experimental results to modify the definition of illumination information to the perceptual illumination information. Section 6 details the placement of several light sources before we conclude in section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Maximum entropy solutions are widely spread in all types of sciences <ref type="bibr" target="#b1">[2]</ref>. For view-point selection maximum entropy solutions have been investigates in computer vision <ref type="bibr" target="#b0">[1]</ref> and more recently in computer graphics <ref type="bibr" target="#b13">[14]</ref>.</p><p>For the more general problem of choosing viewing parameters and light source parameters different approaches exist in the literature. In the interactive evolutionary approach <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b4">5]</ref> the user is himself the optimality criterion and has to judge suggestions proposed by an evolutionary process until optimal parameters are found. The second type of approaches <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b2">3]</ref> define the viewing parameters by solving inverse problems, i.e. the user somehow specifies how the scene should look like by defining some locations of highlights or shadows and the computer tries to find viewing parameters matching the imagination of the user. Marks et al. <ref type="bibr" target="#b8">[9]</ref> use a perceptual based difference measure for images in order to generate a gallery of maximally perceptually different images by variation of the viewing parameters. The user selects the viewing parameters by the selection of one of the images from the gallery. The lighting design tool of Shacked and Lischinski <ref type="bibr" target="#b11">[12]</ref> optimizes the lighting parameters according to a perceptual based quality metric. They define six quality terms, for which the user has to specify weights. No user experiments have been performed to justify their quality metric.</p><p>To accelerate the illumination calculations we used similar techniques as described in <ref type="bibr" target="#b10">[11]</ref>. As a result our implementation does not support shadow computations. The more sophisticated relighting engine as proposed by Gershbein and Hanrahan <ref type="bibr" target="#b3">[4]</ref> could be used to support shadows. for given lighting parameters and describe how to compute it. The most costly part of the computation is the lighting of the scene. In the second subsection we detail how to accelerate multiple illumination computations for a fixed view-point. The last subsections work out two optimization strategies that look for light positions of directional light sources that maximize the illumination information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Illumination Information and Entropy</head><p>From Shannon's source coding theorem we know that the information content of a series of n random variables is equal to n times the entropy of the series. Suppose the random variables can assume the finite set of values {v1, . . . , vm} and that in the given series the probability of a variable to have the value vi is pi. Then the entropy of the series is defined as</p><formula xml:id="formula_0">H = m i=1 pi log 2 1 pi .<label>(1)</label></formula><p>The series of n symbols can be encoded with n • H bits for example with an adaptive arithmetic coder <ref type="bibr" target="#b15">[16]</ref>. Let us now define the illumination entropy in accordance with our needs. In scientific visualization one of the most often exploited visual attributes is color. For illuminated datasets only the hue and saturation components of the color can be effectively used as they are influenced less by the illumination as the brightness. In order to not misrepresent the color attribute in the final image all light sources should be white and, therefore, there is no degree of freedom for the lighting design in the choice of light source color. The illumination entropy is based only on brightness information, which is sufficient as the information content of the hue and saturation components are not influenced by the lighting design. We used the Y tristimulus value of the CIE 1931 standardized color model and converted it from RGB via the standard default color space sRGB (Y = 0.21262</p><formula xml:id="formula_1">• R + 0.71514 • G + 0.07215 • B).</formula><p>For a given illumination of the scene the Y values of all covered pixels are interpreted as random variable series. The typically supported set {0, . . . , 255} of different brightness values is too large for our purposes. More appropriate is the number of distinguishable brightness values, which is between 20 and 50. The actual choice is not important and influences the illumination design only negligibly. We chose to use m = 30 different bins bi of Y values, i.e. if normalized to [0, 1] a value Y falls into bin bi with index i = m • (Y + <ref type="bibr" target="#b0">1</ref> 2 ) . For a given illumination of a scene view with n covered pixels the probabilities pi are computed from the counts ci of Y values falling into bin bi by pi = c i n . The illumination entropy is finally computed via equation 1.</p><p>One inherent difficulty with the illumination entropy is that it is not even continuous no matter what illumination model we use. This can be easily seen by defining the characteristic functions 1i : [0, 1] → {0, 1} for each bin, which are one inside the bin and zero outside. With the characteristic bin functions, the counts compute to ci = j 1i(Yj), where j runs over all n covered pixels. Thus even if the brithness values Yj depend continuously on the illumination parameters, the counts, the probabilities and, therefore, the illumination entropy function are discontinuous because of the characteristic functions. <ref type="figure" target="#fig_0">Figure 1 b)</ref> shows the illumination entropy of the scene in a) for different positions of a white directional light source drawn over a sphere with the entropy values as radial offsets and additionally color coded. In c) only the largest thirty percent of the entropy values were used for radial displacement, which was raised to the power of thirty in order to emphasize the discontinuous characteristic of the entropy function. We can see that on a large scale corresponding to some degrees the entropy is smooth and only on a very fine scale corresponding to fractional degrees it is rough. The amplitude of the roughness itself is only in the order of fractional per mills.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Fast Lighting</head><p>In order to optimize the light position a lot of lighting computations have to be performed for the same view-point. The standard approach is to use the graphics hardware and render the scene again and again with different lighting parameters. This has the advantage that all illumination features of nowadays graphics accelerators are available. But the big disadvantage is that the lighting calculations are of scene complexity. For the visualization of iso-surfaces of volumetric data scenes with a complexity of up to a million of triangles arise. Even new graphics accelerators allow only four frames per second if the triangles are not organized into strips and no more than six fps if they are. Reading out the frame buffer costs additional time.</p><p>As the scene and the view point do not change when the lighting parameters are varied, for each rendering of the scene the same pixels are covered and lighted with the same surface properties. The lighting calculation can be easily done in software with a complexity of the number of covered pixels when for each covered pixel the surface properties are known. Our acceleration technique uses the Phong-Blinn illumination model. In the following we derive the necessary parameters and formula to relight the same scene with different light source positions.</p><p>We assume that all calculations are performed in a global coordinate system originating in the pinhole of the camera. The color components Cα, α ∈ {R, G, B} of each covered pixel are computed from the surface normaln, the light location l and the viewing vector v pointing from the surface location in the pixel to the pinhole</p><formula xml:id="formula_2">Cα = Aα • aα + Dα • dα• &lt;n,û &gt;+ +Sα • sα• &lt;n,ĥ &gt; E + u = l + v h =û +v,<label>(2)</label></formula><p>where "&lt; ., . &gt;+" denotes the scalar product of two vectors, if it is greater than zero, and zero otherwise and ". " denotes the direction of a vector. The parameters Aα, Dα and Sα are the material properties of the surface specifying the corresponding ambient, diffuse and specular color components, whereas E defines the surface shininess. The light source l has corresponding ambient, diffuse and specular color components aα, dα and sα, which we assume to be defined by the user. For each covered image pixels j the software lighting algorithm needs to know the surface propertiesnj, vj, Aα,j, Dα,j, Sα,j and Ej. As the entropy only depends on the brightness values, the material properties can be reduced to the brightness components AY,j, DY,j, SY,j. To collect the surface properties the basic rendering algorithms have to support four rendering modes: standard mode, normal mode, brightness mode and parameter mode. The standard mode supports the standard approach of rendering with the graphics accelerator. The normal mode provides the lighting design tool with the surface normals. OpenGl lighting is turned off and the surface normals are rendered as colors. A normal vectorn is coded via the RGB color</p><formula xml:id="formula_3">C = (R, G, B) ∈ [0, 1] 3 C = 1 2 n + (1, 1, 1) T .</formula><p>The surface normals are automatically interpolated over the triangles by the graphics accelerator providing approximated Phong shading. When the lighting design tool reconstructs the surface normals from the colors obtained via glReadPixels, the normal vectors need to be normalized after the back transformation. background color of ( 1 2 , 1 2 , <ref type="bibr" target="#b0">1</ref> 2 ) was used to mark invalid pixels with normals of length zero. An uniform eight bit quantization of the normal components hardly influences the lighting calculations.</p><p>The viewing directionv of the viewing vector v is completely defined by the pixel coordinates, when the modelview matrix and the camera parameters are given. The length of v can be computed from the depth value of the pixel, which can also be obtained with glReadPixels. To ensure a maximal resolution of the depth value, the clipping planes need to be chosen as tight as possible to the scene limits.</p><p>The brightness mode renders the surface parameters AY,j, DY,j and SY,j quantized to eight bit again without any OpenGl lighting. Finally, the parameter mode renders E and any further parameters as for example the importance which is introduced in section 5. After rendering the scene three times in normal, brightness and parameter mode, the lighting design tool has collected for each covered pixel the necessary lighting parameters. It can now light the image with different light source placements in time proportional to the number of valid pixels. This allowed for an image resolution of 400 times 300 and 50 thousand covered pixels forty scene lightings per second.</p><p>In order to accelerate the lighting computations further we reduced the number of covered pixels by grouping together neighboring pixels. We built an image hierarchy in a recursive fashion. Groups of four pixels were combined to one pixel of double side lengths. Let the original image, i.e. the base level of the image hierarchy, be the zero-th level. A larger pixel on the first image hierarchy level is called parent pixel and its children the sub-pixels. The surface properties of the parent pixel are averaged from its children. As some of the sub-pixels can be invalid, each parent pixel obtains an additional field: the count cj of valid pixels on the finest level. From the first image hierarchy level we can construct the second level by again combining four pixels of level one. The surface properties of the sub-pixels are again averaged and the counts are summed, such that the coarsest level consists of one pixel with its count equal to the number of valid pixels. Building the image hierarchy consumes about <ref type="bibr" target="#b3">4</ref> 3 of the time spent for one lighting calculation. With the image hierarchy all computations can be performed in different resolutions. <ref type="figure" target="#fig_0">Figure 1 d</ref>) visualizes the third image hierarchy level of the scene in a). Stepping one level deeper in the image hierarchy reduces the time complexity for lighting by a factor of four but also introduces more and more error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Global Maximization</head><p>Even if the entropy function is not continuous on a fine scale, for the resolution, at which we want to find light positions, it makes sense to at least assume that the entropy function is Lipschitz continuous, i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∀l1,l2 ∈ S</head><formula xml:id="formula_4">2 : l 1 −l2 ≤ δ =⇒ H(l1) − H(l2) ≤ δ • L (3)</formula><p>with a Lipschitz-constant L, that will be estimated from the entropy function as described below. If we choosel1,l2 ∈ S 2 such that l 1 −l2 = δ, equation 3 tells us, that the absolute value of the gradient of the entropy is limited by L. Let us exploit the Lipschitzcontinuity to avoid unnecessary lighting computations during the search for the maximum entropy.</p><p>We propose the following adaptive search algorithm, that estimates L and determines the maximum entropy value up to a user defined perceptual error . We implemented the approach for the placement of one directional light. It can be generalized to a light in general position as well.</p><p>1. Evaluate the entropy function on a coarse sampling over S <ref type="bibr" target="#b1">2</ref> and form a triangular mesh. 6. Split all marked triangles into four, evaluate the entropy function on the newly introduced vertices and go back to step 2.</p><p>For step 1 the spherical domain was sampled on the vertices of an octahedron. Another choice would be the icosahedron. In step 2 the minimum and maximum values Hmin and Hmax of the entropy are determined in order to decide, when a triangle has to be subdivided in step 4 and when to terminate in step 5.</p><p>To estimate the Lipschitz constant L of the entropy function in step 3 we computed the Lipschitz constant Lapp of the current piecewise linear approximation and multiplied it with a safety factor k safety . A value of 2 for the safety factor worked well for the views we investigated. Lapp is equal to the maximum norm of the entropy gradient over the whole domain. As the entropy gradient is constant on each triangle of the approximation, we simply computed the gradient over each triangle and determined the maximum norm resulting in Lapp.</p><p>Step 4 is the crux of the algorithm. It determines for each triangle t = (p0, p1, p2) the maximum entropy value Ht, that an arbitrary L-Lipschitz continuous function h can reach on the triangle t. The only constraint on h is that h(p0), h(p1) and h(p2) must be equal to the measured entropy values H0, H1 and H2. Let hwc be the worst case function over t, that grows with the maximum gradient L on all rays originating in one of the triangle vertices pi. In <ref type="figure" target="#fig_1">Figure 2 a</ref>  </p><p>The quartic nature of these equations avoids an explicit solution. A steepest descent solver was used instead, that starts in the triangle center. Whenever pmax left the triangle during optimization, it was placed on the edge (pi, pj), through which it left the triangle, by plugging pmax = (1 − τ )pi + τ pj into equation 4 and solving for τ . Compared to the time spent for lighting computations, the time consumed by the iterative solver was negligible, i.e. less than a percent of the total computation time. <ref type="figure" target="#fig_0">Figures 1 b)</ref> and c) show the triangular subdivision of the unit sphere resulting from the adaptive entropy maximization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Fast Maximization Method</head><p>Even with the adaptive global maximization method several thousands of lighting calculations are necessary. If we use for example level three of the image hierarchy the maximum could be found in less than a second, but its location is slightly off the location found on the original image resolution. In this section we combine the speed of the low-resolution maximization with the accuracy of the original resolution. In order to receive a coarse sampling of the entropy function we perform the global maximization procedure to a coarse level of the image hierarchy. Level three proved to be valuable for this purpose. As the maximum found with the coarse image hierarchy level is displaced from the original maximum we limited the spatial resolution by restricting the subdivision process to a maximum number of three iterations. From the coarse sampling we used the local maxima as seed points for an iterative maximization procedure.</p><p>A simple steepest ascent method with adaptive step size λ was used. In order to compute the entropy gradient ∇H(l) we sampled the entropy function in tangential x and y direction at a distance of from the current location. Because of the roughness of the entropy function, λ and have to be chosen carefully. We used an initial λ corresponding to half the edge length of the spatial resolution of the coarse sampling. For each seed we performed the following local maximization algorithm:  <ref type="figure">Figure 3</ref> shows two bad examples of maximum entropy illuminations, where huge highlights are placed on flat surfaces. This disturbs more than it is helpful. To learn more about the question of how to design the illumination in order to allow the spectator to optimally perceive the three dimensional shape of the surface we designed the following experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE USER EXPERIMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Design</head><p>The experiment was kept as simple as possible. The five test scenes in figure 7 a) with fixed view points were presented to fifteen subjects, some of them skilled in visualization, some of them not. The lighting was restricted to one directional light source that could be adjusted either with two sliders or by mouse tracking. The subjects were asked to adjust the light such that they could perceive the three dimensional shape of the scene best. Every subject started with the same initial light position and was requested to first investigate the different illuminations before accepting a light. No color was used in the scenes and the background was set to red in order to avoid that the subject concentrates on the visibility of the silhouette. The subjects easily familiarized with the test environment. The adjustment of the lights in the five scenes took from three minutes to fifteen minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Figure 7 c) shows the illuminations selected in the user experiments averaged over all subjects, where we averaged the brightness values and not the light positions. In b) the entropy function together with the selected light directions is shown. Again the thirty highest percent of the entropy value are displaced after taken to the power of ten. The large variation in the adjusted positions can be led back by additional questioning onto two factors. Firstly, the subjects could not definitely select the best light position from several good ones.</p><p>And secondly, the subjects had different preferences. In the interrogation of the subjects we could find out two common preferences. The highlights need to be chosen carefully at areas with high curvature and should not be too large in extent. And secondly, the scene should not contain dark parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PERCEPTUAL ILLUMINATION ENTROPY</head><p>In this section we want to incorporate the perceptual preferences found in the experiments. For this we refine the illumination entropy definition in two ways. First we change the bins used for classification of the brightness values in order to put penalties on dark and very bright illuminations. In a second step we put more emphasis onto high curvature regions. The extensions will offer three parameters to adjust the perceptual entropy definition. Finally, we select the parameters by fitting the model to the results from the user experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Perceptual Binning</head><p>To prevent the lighting design tool from producing dark regions or too bright regions, we cannot just neglect the contributions to the entropy from probabilities p with small and large indices i, because then for different illuminations a different number of counts are considered, such that the resulting entropies cannot be compared anymore. Instead we chose larger intervals for the bins of low and high brightness values than for bins corresponding to moderate brightness values. 2 ) . The function f is called the (brightness) preference function. <ref type="figure" target="#fig_3">Figure 4</ref> shows an example of a preference function and illustrates how it stretches the bin intervals.</p><p>In order to independently discriminate dark and bright regions, we defined an array of curves dependent on two parameters one for dark discrimination: ω0 ∈ [0, 1] and one for bright discrimination: ω1 ∈ [0, 1], where small weights ω correspond to high discrimination and a value of one to no discrimination. We started with a polynomial of degree three, defined as</p><formula xml:id="formula_6">f0 = −(2 + 3ω0 + ω1) • Y 3 + (3 − 2ω0 − ω1) • Y 2 + ω0 • Y. (5)</formula><p>The preference function in <ref type="figure" target="#fig_3">figure 4</ref> shows f0 for maximum discriminations ω0 = ω1 = 0. No discrimination (ω0 = ω1 = 1) yields the identity function. The amount of discrimination potential of f0 is not enough. To increase the potential without destroying the monotonicity we applied f0 five times resulting in the brightness preference function fperc(ω0, ω1) = f0(f0(f0(f0(f0(Y ))))) for our perceptual model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Curvature Importance</head><p>The second aspect the subjects took into consideration was the surface curvature. In regions with high surface curvature there should be more information than in flat regions. This can be modeled with the concept of importance, which can also be used to emphasis the information content of other important features.</p><p>If we multiply the entropy by the total number n of covered pixels we receive the total information of the illumination. As n • pi is the number of brightness values Yj falling into bin bi, each brightness value Yj contributes log 2</p><formula xml:id="formula_7">1 p i(Y j )</formula><p>bits to the information. In order to weight the information contributed by the brightness value Yj of a covered image pixel j with the importance ιj we define the importance weighted illumination information I as</p><formula xml:id="formula_8">I = n j=1 ιj • log 2 1 p i(Y j ) .<label>(6)</label></formula><p>The per pixel importance parameter can seamlessly be worked into the presented fast lighting approach by adding an importance accumulator, whenever a counter was used to count grouped pixels. In addition to count the pixels, the importance accumulator adds up the importance values of the grouped pixels. Given a view of a scene, we have to specify for each covered pixel j an importance value ιj based on the surface curvature. As we already collected for each covered pixel the surface normals, we can exploit them to estimate the surface curvature. For this we compute for each pixel the length of the normal gradient in radiant from normals of adjacent pixels. This angular measurement is not only high in regions of high curvature, but also at internal silhouettes and sharp creases, what are important features as well. In a second step we sort all pixels by the radiant values and assign the importance based on the position k(j) ∈ {1, . . . , n} in the radiant order</p><formula xml:id="formula_9">ιj = k(j) n ωκ .<label>(7)</label></formula><p>The curvature exponent ωκ is the third parameter in the perceptual entropy model. A value of zero will weight all pixels equally and with increasing exponent the importance of the information on high curvature regions is increased. <ref type="figure" target="#fig_4">Figure 7 d</ref>) illustrates the importance of the covered pixels for the five test scenes with ωκ = 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Fitting the Model</head><p>It is left to adjust the parameters ω0, ω1 and ωκ to the results of the experiment. As the subjects preferred significantly different light source positions, we could not deduce an optimal light source position from the experiment that could be compared to the perceptual entropy based optimal light source position. Instead we interpreted all light source positions from the user experiment as good but not optimal. Thus for a given scene the perceptual entropy function Iω 0 ,ω 1 ,ωκ (l) mapping the light source position l to the perceptual illumination entropy resamples the user experiment if it reproduces high entropy values Iω 0 ,ω 1 ,ωκ (li=1...n) for all selected light source positions {l l , . . . , ln}, where high should be measured relative to the maximum achievable entropy. These considerations lead to the following measure M for the wellness of the fit between a perceptual entropy function and the user experiment.</p><formula xml:id="formula_10">M (ω0, ω1, ωκ) = i=1 n Iω 0 ,ω 1 ,ωκ (li) max l∈S 2 Iω 0 ,ω 1 ,ωκ (l) 2</formula><p>The ω's where derived for each scene as the parameters that maximize M . To do this in reasonable time we first sampled M on a coarse grid over the ω's. We chose the grid as the described steepest ascent procedure. The last three columns of table 1 show the resulting ω-values. All five scenes yielded similar values justifying the presented approach. There is one outlier: the ω1 value discriminating the highlights is smaller in the case of the crocodile. This is probably due to the fact that the bumpy surface of the crocodile always produces a lot of highlights. The averaged ω's were ω0 = 0.94, ω1 = 0.075 and ωκ = 4.2. <ref type="figure" target="#fig_4">Figure 7 b</ref>) shows the perceptual entropy functions for these ω-values together with the light locations adjusted by the subjects. In e) the optimal illuminations are shown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">MULTIPLE LIGHT SOURCES</head><p>In most cases a single light source does not result in a satisfactory illumination. Therefore, we have to generalize our approach to an arbitrary number of light sources. We followed two approaches. For the case of two directional light sources we considered the enlarged search space and again globally optimized the entropy function with a trade-off parameter between information maximization and light source independence. As every further directional light source will introduce two more free parameters what makes the optimization procedure more and more difficult, we also implemented a procedure that adds a further light to a given illumination maximizing the perceptual entropy of the combined illumination. This allows for fast placement of an arbitrary number of light sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Independence vs. Maximum Information</head><p>The independence of two illuminations can be expressed with conditional entropies. Suppose two illuminations Y1,j and Y2,j of n covered pixels are given. The combined illumination Yj with both light sources turned on computes to Y12,j = min(1, Y1,j + Y2,j), from which the perceptual illumination entropy I(Y1, Y2) := I(Y12,j) can be computed. Let us define the conditional probabilities p i 2 |i 1 (Y1, Y2) that a brightness value Y2,j of a pixel j falls into bin bi 2 under the condition that Y1,j of the same pixel already fell into bin bi 1 and the probabilities pi 1 ,i 2 (Y1, Y2) that the brightness values (Y1,j, Y2,j) fall into the bins i1 and i2. Then the conditional entropy computes to</p><formula xml:id="formula_11">H(Y2|Y1) = m i 1 =1,i 2 =1 pi 1 ,i 2 log 2 1 p i 2 |i 1 .</formula><p>n • H(Y2|Y1) measures the information added by illumination Y2 under the precondition that the scene is lighted with Y1. With the same method as in the case of the unconditioned entropy, we can compute the importance weighted conditional probabilities via</p><formula xml:id="formula_12">I(Y2|Y1) = n j 1 =1,j 2 =1 ιj 1 • ιj 2 • log 2 1 p i(Y 2,j )|i(Y 1,j )</formula><p>.</p><p>An optimal placement of two light sources should maximize on the one hand I(Y1, Y2) and the total conditional information I(Y2|Y1) + I(Y1|Y2) and on the other hand it should ensure that each light source adds a similar amount of information to the illumination, i.e. the difference I(Y2|Y1) − I(Y1|Y2) should be minimal. This leads to the following definition of an optimality measure for two light sources</p><formula xml:id="formula_13">Mτ (Y1, Y2) = (1 − τ ) • I(Y1, Y2) + (8) τ • (I(Y2|Y1) + I(Y1|Y2)− |I(Y2|Y1) + I(Y1|Y2)|) .<label>(9)</label></formula><p>The parameter τ ∈ [0, 1] allows to trade off between maximum τ = 0 τ = 0.25 τ = 0.75 τ = 1 <ref type="figure">Figure 5</ref>: illumination of a skull with a yellow and a blue light sources and different independence parameters τ entropy (τ = 0) and independence of the light sources (τ = 1). <ref type="figure">Figure 5</ref> shows illuminations of a skull with different values of τ for the placement of a yellow and a blue light source. The smaller τ the higher is the information content but also the higher is the overlap of the illuminations, such that for τ = 0 the blue light source cannot be distinguished. For τ = 1 the illuminations are maximally independent, which can be easily seen from the good perception of the blue and yellow regions on the skull. We used the same optimization strategies as in the case of single light source placement and used the same sampling over S 2 for both light source. On each subdivision with light positions L = {l1, . . . ,l k } the optimality measure Mτ (l1,l2) is computed for all pairs (l1,l2) ∈ L 2 . To avoid multiple lighting computations, the illuminations were cached. The k 2 optimality measures are combined by maximization to the function M over S 2</p><formula xml:id="formula_14">Mτ (l1) = max l 2 ∈L Mτ (l1,l2),</formula><p>which is used for further adaptive subdivision of the sampling function. As the computational complexity is already in the order of k 2 in the number k of sample locations, this approach is not suitable for generalization to more than two light sources. Instead we designed the following incremental approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">More Than Two Light Sources</head><p>Given a set of light sources, the addition of a further light source is quite simple. For this we lighted the scene with the known light sources and store the resulting illumination in a color image. Then we optimize the position of a further light source with the techniques described in section 3. For each tested light location we combine the buffered illumination with the illumination of the new light source into a second color image, from which we extract the brightness values and compute the perceptual entropy. first light source second light source third light source fourth light source <ref type="figure">Figure 6</ref>: incremental adding up to four white light sources</p><p>If additionally the intensities of the different light sources are optimized, even higher maximum entropy values can be reached. When we compute the perceptual entropy for a given light position of the further light source, we first lighten the scene with the new light source. In the combination step we vary the intensity of the new light source between zero and one as well as the intensity of the combined illumination of all previous light sources and select the weights that achieve the maximum entropy. For the case of only white light sources the process of adding new lights soon converges in the sense that the entropy is not increased anymore. For colored light sources the process converges slower as the brightness range of colors significantly darker than white is smaller and the entropy maximum cannot be reached as fast. <ref type="figure">Figure 6</ref> shows the incremental addition of up to four white light sources. In the final image the intensities of the lights sources were 0.46, 0.35, 0.46 and 0.5. The bottom row of <ref type="figure" target="#fig_4">figure 7</ref> shows the test scenes lighted with differently colored light sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We started off with an intuitive motivation of how to place light sources by maximizing the illumination information. A safe and a fast global optimization procedure were designed that work well with entropy functions. We also proposed a fast and hierarchical method for the lighting calculations. From user experiments we learned how to quantify the perceived information content. For this we adapted the binning needed for entropy computations and we introduced an importance weighting based on surface curvature measured in the image. The resulting perceptual entropy function reproduced the results of the experiment.</p><p>Furthermore, we generalized the approach to more than one light source with the notion of independence applicable for two light sources and the incremental addition of a light source for an arbitrary number of light sources.</p><p>In future work we want to investigate light sources in general positions. For this the same optimization strategies can be exploited. Basically, we have to implement a tetrahedral grid that allows for adaptive subdivision. A further very important point for future work is the incorporation of shadows as can be done with the relighting engine described by <ref type="bibr">Gershbein</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>a) example scene b) entropy function of directional light c) view from camera location illustrated in b) with the upper 20 percent of the entropy values taken to the power of 30 d) simulation of level three of hierarchical illumination</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>a) finding the maximum reachable entropy value over a triangle, b) steepest ascent of seed (black) from coarse approximation to local maxima (bright magenta), green/cyan lines are the additional samples for gradient estimation and the grey arrow shows global maximum some of these rays are drawn in dashed style. hwc is the point wise minimum of the three functions h wc,i∈{0,1,2}= Hi + p − pi •L.The circles around the triangle vertices inFigure 2a) illustrate isolines of the functions hwc,i. The maximum of hwc is found at the point pmax, where all hwc,i have the same value. In the special case, where all Hi are the same, this point is the intersection of the three bisectors between pairs of the triangle vertices. In the general case pmax is the solution to the following two equations hwc,0(pmax) = hwc,1(pmax) = hwc,2(pmax).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 . 2 5. set λ = λ 2 , 2 Figure 2 bFigure 3 :</head><label>122223</label><figDesc>given seed location l with H(l) and initial λ 2. construct tangential direction x and y and set = λ2 3. sample H(l + • x), H(l + • y) and estimate ∇H(l) 4. step to l = l + λ •∇H(l), if H(l ) &gt; H(l) set l = l and goto if λ &gt; 0.5 degrees goto ) shows an example of the adaptive steepest ascent method. The light directions corresponding to the selected seed locations are the black lines. With decreasing λ the brightness of the lines increase to magenta. The green and cyan lines show the additional samples needed for gradient estimation. The grey arrow shows the maximum found with the global optimization procedure and it points nearly exactly to the same location as the brightest magenta line. a) b) Two examples of maximum entropy light source placement, that exaggerate highlights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>a) example of a brightness preference function, b) brightness bins α) identity, β) f0 and γ) from model fit The simplest way to change the bin intervals is to define a strictly monotonic function f : [0, 1] → [0, 1] with f (0) = 0, f (1) = 1 and f (Y1) &gt; f(Y2) ⇐ Y1 &gt; Y2. The bin intervals are defined equal sized in the range of f . The bin index of a brightness value Y computes to i = m • (f (Y ) + 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7</head><label>7</label><figDesc>: a) the five test scenes, b) fitted perceptual entropy function and selected light source directions, c) average of brightness values over the adjusted illuminations, d) curvature importance, e) optimal illumination maximizing perceptual entropy, f) scenes illuminated with multiple colored light sources</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Results for the test scenes: number of covered pixels n, optimization time for global optimization t glb in seconds, number of illuminations # glb , for fast approximate optimization time tapp and number of coarse level illuminations plus number of high resolution illuminations and the number of seed, finally the fitted ω's.</figDesc><table><row><cell cols="3">(ω0, ω1, ωκ) ∈ {0,</cell><cell>1 5</cell><cell>,</cell><cell>2 5</cell><cell>,</cell><cell>3 5</cell><cell>,</cell><cell>4 5</cell><cell>, 1} 2 × {0, 1, 2, 4, 8}.</cell></row><row><cell cols="10">In a second phase we applied a similar local optimization method</cell></row><row><cell></cell><cell>gabor</cell><cell cols="4">engine</cell><cell></cell><cell></cell><cell cols="2">lobster crocodile galleon</cell></row><row><cell>n</cell><cell>77874</cell><cell cols="4">47003</cell><cell></cell><cell></cell><cell cols="2">94755</cell><cell>53762</cell><cell>92990</cell></row><row><cell>t glb</cell><cell>241</cell><cell cols="3">505</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>138</cell><cell>164</cell><cell>117</cell></row><row><cell># glb</cell><cell>3666</cell><cell cols="4">6290</cell><cell></cell><cell></cell><cell></cell><cell>3416</cell><cell>3582</cell><cell>1522</cell></row><row><cell>tapp</cell><cell>14.2</cell><cell cols="3">10.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5.2</cell><cell>4.5</cell><cell>9</cell></row><row><cell cols="10">#app 149+154 137+123 145+127 162+66 129+106</cell></row><row><cell>seeds</cell><cell>7</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell>3</cell><cell>4</cell></row><row><cell>ω0</cell><cell>0.96</cell><cell cols="3">0.94</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.94</cell><cell>0.95</cell><cell>0.93</cell></row><row><cell>ω1</cell><cell>0.085</cell><cell cols="4">0.084</cell><cell></cell><cell></cell><cell cols="2">0.082</cell><cell>0.057</cell><cell>0.068</cell></row><row><cell>ωκ</cell><cell>4.7</cell><cell cols="3">4.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3.9</cell><cell>4.0</cell><cell>4.0</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Viewpoint selection by navigation through entropy maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ferrie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th IEEE International Conference on Computer Vision (ICCV-99)</title>
		<meeting>the 7th IEEE International Conference on Computer Vision (ICCV-99)<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="248" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Maximum entropy solutions to scientific problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Bevenesee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Lighting design: A goal based approach using optimisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio Cardoso</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">Augusto</forename><surname>Sousa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Nunes</forename><surname>Ferreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rendering Techniques &apos;99, Eurographics</title>
		<editor>Dani Lischinski and Greg Ward Larson</editor>
		<meeting><address><addrLine>Wien New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="317" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A fast relighting engine for interactive cinematic lighting design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Gershbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pat</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Computer Graphics Conference 2000 (SIGGRAPH-00)</title>
		<editor>Sheila Hoffmeyer</editor>
		<meeting>the Computer Graphics Conference 2000 (SIGGRAPH-00)<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACMPress</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="353" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The applications of evolutionary and biological processes to computer art and animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Joblove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Latham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Todd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="page" from="389" to="390" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Radioptimization -goal based rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">K</forename><surname>Kawai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">S</forename><surname>Painter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Proceedings, Annual Conference Series</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="147" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A prototype system for design automation via the browsing paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Kochhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface &apos;90</title>
		<meeting>Graphics Interface &apos;90</meeting>
		<imprint>
			<date type="published" when="1990-05" />
			<biblScope unit="page" from="156" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hierarchical spacetime control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
		<idno>0-89791-667-0</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Proceedings, Annual Conference Series</title>
		<editor>Andrew Glassner</editor>
		<meeting><address><addrLine>Orlando, Florida</addrLine></address></meeting>
		<imprint>
			<publisher>ACM SIGGRAPH, ACM Press</publisher>
			<date type="published" when="1994-07-29" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
	<note>Proceedings of SIGGRAPH &apos;94</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Design galleries: A general approach to setting parameters for computer graphics and animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andalman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Beardsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hodgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mirtich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ruml</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ryall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shieber</surname></persName>
		</author>
		<idno>0-89791-896-7</idno>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 97 Conference Proceedings, Annual Conference Series</title>
		<editor>Turner Whitted</editor>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="1997-08" />
			<biblScope unit="page" from="389" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Painting with light</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Schoeneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Dorsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Smits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Arvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Proceedings, Annual Conference Series</title>
		<editor>James T. Kajiya</editor>
		<imprint>
			<publisher>ACM SIGGRAPH, ACM Press</publisher>
			<date type="published" when="1993-08" />
			<biblScope unit="page" from="143" to="146" />
		</imprint>
	</monogr>
	<note>SIGGRAPH 93 Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Parameterized ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><forename type="middle">H</forename><surname>Sequin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliot</forename><forename type="middle">K</forename><surname>Smyrl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;89 Proceedings)</title>
		<editor>Jeffrey Lane</editor>
		<imprint>
			<date type="published" when="1989-07" />
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic lighting design using a perceptual quality metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram</forename><surname>Shacked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<idno>1067-7055</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Artificial evolution for computer graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Sims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH &apos;91 Proceedings</title>
		<imprint>
			<date type="published" when="1991-07" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="319" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Viewpoint selection using viewpoint entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pere-Pau</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miquel</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateu</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Heidrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procedings of Vision, Modeling, and Visualization &apos;01, Annual Conference Series</title>
		<editor>Thomas Ertl</editor>
		<meeting>edings of Vision, Modeling, and Visualization &apos;01, Annual Conference Series</meeting>
		<imprint>
			<publisher>Addison Wesley</publisher>
			<date type="published" when="2001-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spacetime constraints</title>
		<imprint>
			<date type="published" when="1988-08" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Arithmetic coding for data compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">G</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cleary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="520" to="540" />
			<date type="published" when="1987-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
