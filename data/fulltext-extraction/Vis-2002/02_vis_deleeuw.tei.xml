<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BM3D: Motion Estimation in Time Dependent Volume Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wim</forename><surname>De Leeuw</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Van Liere</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Center for Mathematics and Computer Science</orgName>
								<orgName type="institution">CWI</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Information Systems</orgName>
								<address>
									<postBox>P.O. Box 94097</postBox>
									<postCode>1090 GB</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BM3D: Motion Estimation in Time Dependent Volume Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation; I.3.6 [Computer Graphics]: Methodology and Techniques feature tracking</term>
					<term>vector fields</term>
					<term>volume visualization</term>
					<term>biomedical imaging</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper describes BM3D: a method for the analysis of motion in time dependent volume data. From a sequence of volume data sets a sequence of vector data sets representing the movement of the data is computed. A block matching technique is used for the reconstruction of data movement. The derived vector field can be used for the visualization of time dependent volume data. The method is illustrated in two applications.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Visualization and analysis of time dependent volume data is of key importance for understanding of many scientific problems such as confocal microscopy and material transport simulations, e.g. fluid mixing, convection and combustion. An important aspect in all problems is movement or transport of data. However, in the volume data itself no explicit information about movement is available. Animated volume rendering techniques are not sufficient for understanding complex movement patterns in the data.</p><p>We present BM3D: a general method for motion estimation in time dependent volume data. Our objective is to estimate a velocity for all positions in a volume. We assume that motion can be reconstructed from data patterns in the neighborhood around these positions. BM3D can be applied to any time dependent volume data. It is useful in volumes where complex movements occur, such as reorganization or mixing, and where no knowledge about movement is available from other sources.</p><p>The output of BM3D is a time dependent vector field. Standard vector field visualization techniques can be used to visualize the vector field. Stream lines or texture techniques can be used to show velocity at a particular moment. Particle paths can be used to show movement paths of objects of interest. In addition, the resulting vector field can serve as a basis for data analysis. The tracking of a feature in the original volume data is reduced to the computation of a particle path in the generated vector field. Also, material flux through an arbitrary surface can be easily determined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The derivation of a vector field from two dimensional image data was introduced as optical flow by Gibson <ref type="bibr" target="#b0">[1]</ref>. Optical flow is the distribution of apparent velocities of movement of brightness patterns in an image. It gives information about the spatial arrangement of the objects in the image and the rate of change of this arrangement. The computation of an optical flow field from digital image sequences was addressed by Berthold et al. <ref type="bibr" target="#b1">[2]</ref> and Nagel <ref type="bibr" target="#b2">[3]</ref>. These algorithms use intensity gradients in the spatial and temporal domain in combination with additional constraints to obtain the velocity. One choice for additional constraints is the minimization of the velocity gradients to ensure the smoothness of the velocity field. However, other application dependent criteria can be used as constraints.</p><p>The problem of the derivation of a vector field from two subsequent data sets can also be treated as a non rigid registration problem. The vector field can be easily calculated from the displacement field. Much work has been done in this area to match two volume data sets, for example matching scans of two different patients brains using elastic deformation <ref type="bibr" target="#b3">[4]</ref>. An overview of non rigid registration can be found in Dawant <ref type="bibr" target="#b4">[5]</ref>.</p><p>Another application area is video processing. For example, in MPEG encoding motion is estimated using prediction vectors <ref type="bibr" target="#b5">[6]</ref>. The primary goals in video processing are compression and processing tasks such as de-interlacing and frame rate interpolation.</p><p>A popular technique for implementing video transmission is the block-matching (BM) algorithm <ref type="bibr" target="#b6">[7]</ref>. The underlying idea of the BM-algorithm is that each image frame is divided into a fixed number of square blocks of pixels. For each block, a search is made in a reference frame for a matching block. The search is for the 'best' matching block. Best can be defined as minimizing either mean square differences or mean absolute difference of pixels in the matching blocks (see figure 1). Typical block sizes are in the order of 16x16 pixels, and the maximum displacement might be 64 pixels from a block's original position. Several search strategies are possible, ranging from exhaustive search to various sampling mechanisms, <ref type="bibr" target="#b7">[8]</ref>. <ref type="figure">Figure 1</ref>: Block matching algorithm: movement is computed by determining the best match using a block of pixels. From left to right: data at time step t, data at time step t + 1, best matching blocks (stippled boxs) and displacement vectors (arrows) for two blocks in the data.</p><formula xml:id="formula_0">¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ ¡ ¢ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¡ £ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¡ ¤ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¡ ¥ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ ¡ ¦ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ § ¡ §¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡¨ ¡ ¡ ¡ ¡ ¡ ¡ ¡ © ¡ © ¡ © ¡ © ¡ © ¡ © ¡ © © ¡ © ¡ © ¡ © ¡ © ¡ © ¡ © © ¡ © ¡ © ¡ © ¡ © ¡ © ¡ © © ¡ © ¡ © ¡ © ¡ © ¡ © ¡ © © ¡ © ¡ © ¡ © ¡ © ¡ © ¡ © © ¡ © ¡ © ¡ © ¡ © ¡ © ¡ © © ¡ © ¡ © ¡ © ¡ © ¡ © ¡ © ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡ ¡</formula><p>A well known visualization method for gaining insight into time dependent data is feature tracking, <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. These algorithms consider feature tracking as a two step process. First, in the detection phase, features extracted from each time step in the data. Features are described by feature attributes. Then, in the tracking phase, the correspondence of features in successive time steps is used for the IEEE Visualization 2002 Oct. 27 -Nov. 1, 2002, Boston, MA, USA 0-7803-7498-3/02/$17.00 © 2002 IEEE determination of tracks. Correspondence between features is determined by thresholds on the feature attributes. Often the notion of evolutionary events, such as split, merge, birth and death events are used to describe the evolution of features. Additional correspondence criteria may be formulated in case of evolutionary events.</p><p>The contribution of this work is that we use 3D block matching to reconstruct the motion vector field from volume data and that we use the vector field to enhance the visualization of time dependent volume data.</p><p>Compared to feature tracking, the BM3D generated vector field does not rely on the definition of a feature and feature correspondences. Instead, motion vectors are computed by matching blocks of data. A matching operator is used to compute correspondences in the raw data. Feature tracking is useful in cases where domain knowledge is available. In contrast, for BM3D no a priory knowledge about the data is needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BM3D METHOD</head><p>The objective is to compute a motion vector v at a position x for a particular time step T . This is achieved by comparing a data block at position x at time step T with a number of displaced data blocks in the vicinity of x at time step T + 1. The motion vector v will be chosen to be the displacement vector of the 'best matching' data block.</p><p>Stated more formally, the objective is to find a the motion vector v which displaces the data at position x at time T to a position x + d at time T + 1. The displacement d is then the sought motion vector. A minimization procedure is used to compute the displacement d.</p><p>We first define as being a data block matching operator :</p><formula xml:id="formula_1">R 3 × R 3 → R.</formula><p>The block matching operator is a metric which is used to compare two data blocks based on voxel values in the block.. Two blocks are defined to be match if results in a low value and are defined not to match if returns a high value. We denote as:</p><formula xml:id="formula_2">BT ( x) BT +1( y)<label>(1)</label></formula><p>in which BT ( x) is a data block in the data set at time T centered around position x, BT +1( y) is a data block in the data set at time T + 1 centered around position y. Both blocks have the same size. Finding the displacement d is realized by computing the minimum of the set of block matches in the vicinity of x; i.e. the displacement d for the smallest element of the set</p><formula xml:id="formula_3">{BT ( x) BT +1( x + d) | d ∈ SW } (2)</formula><p>in which the displacement vectors d are chosen from a search window SW position in the vicinity of x. This process is repeated for all positions x in the volume to construct a vector field for one time step. To construct a time dependent vector field, the process is repeated for all time steps.</p><p>We illustrate the method in 2D (see figure 2). A data block B around position x is matched with 4 data blocks displaced at different positions at time T + 1. Each block is highlighted with a unique color. For clarity, only four blocks are drawn; however, all blocks in the search window will be tested. The result of the matching operator is shown in the lower part of the figure. In this example we choose matching operator to be the sum of the absolute differences the voxel values in the block. The right most block has the minimum value.</p><p>The pseudo C-code for the block matching algorithm is as follows:</p><formula xml:id="formula_4">void BM3D (timestep T) { ∀ voxel x ∈ dataset (T)) { ∀ d ∈ SEARCH WINDOW and GRANULARITY { value = BT (x) BT +1(x + d)) if (value &lt; minval) { minval = value; dmin = d; } } motion vector v = dmin; } }</formula><p>The BM3D algorithm sweeps over all voxels x and applies the block matching operator to blocks positioned at x with blocks positioned a x + d in which d is chosen from a search window. The method of choosing the displacement vector d from a search window depends on the search strategy and its granularity.</p><p>A number of parameters occur in the algorithm. Here, the influence of parameters on the algorithm and the result is discussed:</p><p>• matching operator</p><p>The matching operator usually found in 2D block matching algorithms is the sum of the absolute pixel differences the data blocks.</p><p>In the current BM3D implementation, the absolute voxel difference scaled with a Gaussian weighting function centered at the point of interest is used; i.e.</p><formula xml:id="formula_5">block |BT ( x) − BT +1( x + d)|e −C| δ| (3)</formula><p>Where δ is the distance from the point of interest. The motivation is that, in contrast to the 2D algorithms used for video compression where the motion of the whole block is of importance, BM3D is interested in the motion at the point of interest. The data variation close to the point of interest is more important than variations further away. Therefore, a Gaussian weighting function centered at the position of interest is used to scale the voxel differences.</p><p>• size of the matching block.</p><p>The block matching operator compares all voxel values of a data block around the point of interest with voxels of a data block around a displaced point. The larger the size of the block, the larger the region used to determine the motion.</p><p>The block size has an optimum which depends on the characteristics of the data. One one hand, matching single voxels will allow the same or almost the same voxel value to be matched. On the other hand, if the block size is too large the average movement of a region is calculated instead of the movement at a particular position. The optimum block size will be the one that is just big enough to avoid false matches. In our implementation, the scale factor (C in equation 3) used in the matching operator is proportional to the block size.</p><p>• search window</p><p>The search window is the area which is searched for the displacement vector. The size of the search window should be at least as large as the largest data displacement between two time steps. For example, if data represents fast moving media a large search window must be chosen. • displacement vector granularity Until now, we have assumed that the size of the displacement vector is a multiple of voxels in the volume. However, data movement is not restricted to complete voxels only. By using tri-linear interpolation, data blocks can be compared at subvoxel resolution. Hence, the block matching operator can be computed for arbitrary sized displacement vectors.</p><p>Granularity is a metric that is used to restrict the number of displacement vectors in the search window. It defines the potential displacement of a vector with respect to the size of a voxel. For example, a granularity of 1.0 relates to displacement vector measured in entire voxels. A granularity of 0.5 relates to displacements at half the size of a voxel. <ref type="figure" target="#fig_1">Figure 3</ref> illustrates the notion of displacement vector granularity. In the left image, the displacement vector granularity is equal to the size of a voxel. In the right image, the granularity is equal to half the size of a voxel. Hence, the displacement vector granularity is 0.5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Search strategies</head><p>The performance of the BM3D algorithm depends on the number of block matches that are performed. For each voxel the best matching block is determined in the next time step. A complete search through the data set would require a number of block matches roughly equal to the number of voxels in the data. This would be very time consuming. The number of matches required is decreased by introducing a search window positioned around the point for which the velocity is calculated. The matching is only performed for blocks in the search window.</p><p>The current BM3D implementation uses two different search strategies to determine the displacement vector in the search window. The first strategy is a straightforward exhaustive search. All the blocks in the search window are matched to the block around the point of interest.</p><p>The second strategy, referred to as hill climbing, uses a two level steepest ascent method to guide the search along a path to the best block match. Instead of the exhaustive search of all the displacement vectors in the search window, only the 26 blocks adjacent to the current position are examined. The block with the minimum block matching value found is taken as the new current position. The process is repeated until no lower value is found among adjacent blocks. The first pass of the steepest ascent uses displacement vector granularity of 1.0. This is followed by a second pass in which the displacement vector granularity is set to the desired sub pixel granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Test Results</head><p>Artificial data sets were generated to study the accuracy and performance of BM3D. The movement of the data in these data sets simulate the movement of a paramterized Gaussian function G; i.e. a blob with an initial position, velocity and diffusion rate. The parameters of the Gaussian are: initial position p 0 , initial size σ0, velocity v, intensity I, and diffusion rate D. Diffusion was used because it is an often occurring phenomenon in volume data. Diffusion is approximated by decreasing the maximum intensity in combination with an increasing blob size such that the integral over all intensity values remain constant. The following equation was used for the Gaussian function :</p><formula xml:id="formula_6">G(x) = I σ0 σ0 + Dt 3 e − |p 0 +vt−x| σ 0 +Dt 2<label>(4)</label></formula><p>Each generated test data set has a resolution of 64x64x64. 32 time steps were computed. A number of tests with varying input data and parameter settings were performed to gain insight in the accuracy and performance of the algorithm. <ref type="figure" target="#fig_2">Figure 4</ref> shows two vector plots of a 2D slice of the BM3D generated vector fields. In the left image, the initial parameters of G(x) were set to v = &lt; 1.8, 1.0, 0.0 &gt; and D = 0.0. In this case, the Gaussian moves at a uniform speed in the direction of the initial velocity. In the right image the initial parameters of G(x) were set to v = &lt; 0.0, 0.0, 0.0 &gt; and D = 0.05. In this case, the motion is completely determined by the change of shape of the Gaussian. The radius increases over time based on diffusion rate.</p><p>In the case that the diffusion rate is equal to 0, the input velocity can be compared to the BM3D computed velocity in the vector field. The error is taken to be the average length of the difference between the input velocity and BM3D vector at every voxel;</p><formula xml:id="formula_7">1 N N i=1 | v(i) −v(i) | (5)</formula><p>in which v(i) is the input velocity at voxel i,v(i) is the BM3D computed speed at voxel i and N is the number of calculated velocity samples. <ref type="table">Table 1</ref> tabulates the error for three different block sizes, two search strategies and three displacement vector granularities, for the test data set in which v = &lt; 1.8, 1.0, 0.0 &gt; and D = 0.0. From the data it can be seen that decreasing the displacement vector granularity also decreases the average error. Also, increasing the block matching size decrease the average error. Finally, the error caused by using hill climbing search is negligible compared to the error made by the exhaustive search strategy. <ref type="table" target="#tab_1">Table 2</ref> shows the performance of the BM3D method for three different block sizes and two search strategies. The performance is measured as the time spent (in milliseconds) to compute the motion of the data at each voxel. The total time of BM3D can be computed by multiplying this value with the number of voxels and the number of time steps. The table shows that for both strategies the time needed is linear over the number of voxels in the matching block. In addition, using the hill climbing search strategy is approximately a factor 100 faster than the exhaustive search strategy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPLICATIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Convection</head><p>A time dependent data set of convection flow -the circulatory motion that occurs in a fluid at a nonuniform temperature owing to the variation of its density and the action of gravity -in the earth's crust was obtained from a numerical simulation 1 done by Dr. Jörg Schmalzl, Institute of Geophysics, Münster University. The data set consists of 30 time steps at a resolution of 128x128x64.  BM3D was applied to the convection data set. The hill climbing search strategy with a matching block size of 5x5x5 and a displacement vector granularity of 0.05 was used. Equation 3 was used for the block matching operator. A wide palette of vector visualization techniques have been implemented to visualize the BM3D generated vector field. <ref type="figure" target="#fig_5">Figure 6</ref> illustrates three techniques. A slice of the vector field is taken at Z = 32 at time T = 0. Red, blue and gray regions are drawn on a plane to represent the magnitude of the motion perpendicular to the plane. Red denotes upward flow, blue denotes downward flow, gray is used if there is no flow perpendicular to the plane.</p><p>An arrow plot (drawn as small yellow arrows) is drawn from a data slice taken at X = 16 at time T = 0. Arrows represent the flow magnitude and direction at each voxel in the slice.</p><p>Particle paths are shown as red/white segmented tubes taken at a number seed points (shown as small blue spheres). Small arrows are drawn at end point of particle path to indicate direction. Each segment of the particle corresponds with two time steps in the data. Seed points are chosen on a grid-like pattern on the cutting plane. Particle paths represent the motion of the seed point throughout the time steps. Note that the lengths of the particle paths and the path segments vary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Chromatin decondensation</head><p>We have used BM3D to analyze the movement of chromatin during formation of the cell nucleus of a newly formed daughter cell. Chromatin was visualized in living cells and movement was followed using 3D confocal microscopy. Densely packed areas of chromatin are used to analyse the movement of the entire chromatin. The densely packed areas are represented as high intensity levels in the data.</p><p>The data set consisted of a series of 134 3D data sets. Each time step consists of a stack of 64 optical sections of 256 × 256 pixels. Due to physical characteristics of a confocal microscope the optical resolution along the z-axis is four times less than in the x-y plane. The 3D images are corrected for this by scaling in the z-direction during rendering. <ref type="figure" target="#fig_6">Figure 7</ref> show six volume renderings of the data set. Densely packed areas of chromatin are represented as high intensity values in the data.</p><p>BM3D was applied to the decondensation data set. The hill climbing search strategy, a block matching size of 5x5x5, a displacement vector granularity of 0.05, and equation 3 were used as parameters. <ref type="figure">Figure 8</ref> shows how the original data can be combined with the BM3D generated vector field 2 . Volume renderings of the original data are combined with particle paths. Seed points are chosen by using a feature detector to find points of high intensities at time T = 0. These points were used as the seed points for the particle paths. The complex movement of chromatin can be studied by following particle paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>BM3D is a technique used to generate a time dependent vector field that represents the movement of data in time dependent volume data sets. Insight into these movements can be obtained by applying standard vector field visualization techniques to the vector field.</p><p>Various parameters are used to drive BM3D. For a simple artificial data set we have shown that the errors made by BM3D depend on the value of the displacement vector granularity, block matching size, and search strategy. In real data, however, parameter settings t=40 t=135 <ref type="figure">Figure 8</ref>: Combining volume data with particle paths.</p><p>depend on the characteristics of the data:</p><p>• The size of the matching block should be chosen to reflect the variation of velocity changes in the data. In data with large velocity fluctuations over space, a small block size should be chosen. In data in which the velocity is more uniform, larger blocks can be applied.</p><p>• The size of the search window should be chosen to reflect the maximum velocity occurring in the data; i.e. the maximum displacement of the data remains within the search window.</p><p>• The granularity of the displacement vector is a trade-off between performance and the error. A fine granularity results in a more accurate reconstruction, but will require more computation.</p><p>• The matching operator should take special properties of the data into account. Equation 3 implements a weighted sum of absolute differences of the voxels in the data blocks. In cases in which mass conservation holds, the total mass of the compared blocks can be used as a metric.</p><p>• As shown in section 3 the additional error due to using hill climbing search is negligible for uniform data. However, for data sets with high frequencies, the hill climbing algorithm might iterate to a local minimum. In such data sets an exhaustive search may lead to better results.</p><p>Since there usually is no a priori knowledge about the characteristics of the data which influence the parameter settings, test runs are usually required. Several approaches can be utilized to gain insight in to quality of the vector field: First, visual comparison of animations of the original data with paths generated from the vector data. Second, an analysis of the matching errors. High error values indicate problems in matching. The lower the value the better the match. Third, using known properties of the data to validate the field. For example, if some data the total flux through some surface is known, this value can be compared to the flux calculated from the generated vector field.</p><p>The BM3D generated vector field need not only be used for the visualization of data movement. The vector field can also be used for data analysis. In particular, we give examples of how the vector field can be used for feature tracking and the modeling of physical phenomena.</p><p>In <ref type="bibr" target="#b10">[11]</ref>, we have presented an interactive feature tracking system and its use for the analysis of chromatin decondensation. In this method, features are described as points in a multidimensional attribute space and distances between points are used as a measure for feature correspondence. Tracks are constructed by linking corresponding features. We have also applied BM3D to the same data set and compared the results with our feature tracking method (see Section 4.2 for a description of the data). <ref type="figure">Figure 9</ref> shows 8 green tracks (obtained from our feature tracking method) combined with 8 red particle paths calculated from the vector field generated by BM3D applied the volume data. At time T = 50, 8 features (local maximum intensity values in the data) belonging to the longest found tracks were selected. The positions of the selected features were used as seed points for particle paths traced forward and backward in time using the vector data. A volume rendering of the chromatin data at time T = 50 is superimposed over the paths.</p><p>It would be expected that the computed points in the feature tracks and particle paths would be roughly the same. Although they obviously are not, figure 9 shows that the shape and direction of the tracks and paths are very similar 3 . There are three possible explanations for these differences. First, the feature tracks are not all the same length. Some tracks terminate because a corresponding feature could not be found in a following time-step. Second, incorrect correspondences in the feature matching algorithm might result in incorrect feature tracks. Finally, small errors in the velocity field may accumulate due to integration, resulting in particle path diverging from the feature tracks.</p><p>It can be argued that BM3D has a number of advantages over the feature tracking algorithm. First, BM3D does not rely on the definition of a feature. Instead, movement is computed using the underlying data. Second, by placing a seed point and computing a particle path, movement can be examined at arbitrary positions in the data. In contrast, feature tracks are only available at positions where a feature is detected.</p><p>On the other hand, feature tracking provides an explicit representation of properties in the data which are of interest to the user. In addition, BM3D results in a large increase of stored data whereas feature tracking is very useful to compress large volumetric data sets.</p><p>The vector field generated by BM3D can also be used for modeling physical phenomena. In the case of the decondensation data set, densely packed areas of chromatin are represented as high in- <ref type="figure">Figure 9</ref>: Feature tracks (green) and particle paths (red). tensity levels in the data. However, from the vector field we also have velocity information and can easily compute acceleration and forces. This information can be used to model various aspects of the decondensation process. For example, it may be possible to determine the individual chromosomes in the chromatin this way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We have presented BM3D, a method to estimate motion in time dependent volume data. The motion is reconstructed by matching local patterns in volume data. The output of BM3D is a time dependent vector field. Vector field visualization techniques can be applied to the vector field.</p><p>BM3D can be applied to any time dependent volume data. It is useful in volumes where complex movements occur, such as reorganization or mixing, and where no knowledge about the movement is available from other sources.</p><p>Future work will include further improvements to the velocity estimation by enhancing the matching process. In addition to block matching, more elaborate methods for 2D motion estimation have been proposed such as triangle motion compensation, and control grid interpolation. Such techniques should be applied to volume data as well. Also, the derived velocity information could be applied to volume data compression, in the same way as in image sequence compression.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>BM3D illustrated in 2D : a block B positioned at x at time T is matched with 4 data blocks displaced at different positions at time T + 1. The result of the matching operator for each displaced block is shown in the lower part of the figure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Displacement vector granularity : The granularity in the left image is 1.0. The granularity in the right image is 0.5. Dots show positions of blocks, arrows show some possible displacements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Vector plots of one time step from the moving Gaussian test data sets. Image on the left represents the Gaussian with initial translation speed and a diffusion rate of 0.0. Image on the right represents the Gaussian with initial speed of 0 and a diffusion rate of 0.05.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 5shows four volume renderings of the data set. Regions of high temperature move upwards from the bottom to the top, while regions of low temperature move downwards from the top to bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Four time steps of the convection data set. Volume rendering is used to show the scalar field.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Particle paths, arrow plots, and vector magnitude are used to depict various aspects of the vector field.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Six volume renderings show movement of compact chromatin domains as concentration variations over time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance (in milliseconds per voxel) with varying three block matching sizes and two search strategies.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The data was kindly provided by Klaus Engel, University of Stuttgart</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">See also the supplementary mpeg-animation on DVD.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">See also the supplementary mpeg animation on DVD.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The Perception of the Visual World</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1950" />
			<publisher>Riverside Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Determining optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Berthold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">G</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="185" to="203" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the estimation of optical flow: Relations between different approaches and some new results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Hellmut</forename><surname>Nagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="299" to="324" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finite element approach to warping of brain images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Haynor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bajcsy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging 1994: Image Processing</title>
		<editor>M.H. Loew</editor>
		<meeting><address><addrLine>Bellingham</addrLine></address></meeting>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Non-rigid registration of medical images: Prupose and methods, a short survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Benoit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dawant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE International Symposium on Biomedical Imaging</title>
		<meeting>IEEE International Symposium on Biomedical Imaging</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="465" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A computational framework and an algorithm for the measurement of visual motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Anandan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="283" to="312" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Tekalp</surname></persName>
		</author>
		<title level="m">Digital Video Processing</title>
		<meeting><address><addrLine>Upper Saddle River, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Architectures for hierarchical and other block matching algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions for Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="477" to="489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Visualizing features and tracking their evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samtaney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zabusky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="20" to="27" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attribute-based feature tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Reinders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Spoelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Visualization &apos;99</title>
		<editor>E. Gröller, H. Löffelmann, and W. Ribarsky</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Chromatin decondensation: a case study of tracking features in confocal data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>De Leeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Liere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<editor>Kenneth Joy, Amitabh Varshney, and Thomas Ertl</editor>
		<meeting>IEEE Visualization<address><addrLine>Los Alamitos (CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="441" to="444" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
