<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visibility-Guided Simplification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computing</orgName>
								<orgName type="institution" key="instit1">GVU Center</orgName>
								<orgName type="institution" key="instit2">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Turk</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computing</orgName>
								<orgName type="institution" key="instit1">GVU Center</orgName>
								<orgName type="institution" key="instit2">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Visibility-Guided Simplification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visualization</term>
					<term>Visibility</term>
					<term>Mesh Simplification</term>
					<term>Rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>For some graphics applications, object interiors and hard-to-see regions contribute little to the final images and need not be processed. In this paper, we define a view-independent visibility measure on mesh surfaces based on the visibility function between the surfaces and a surrounding sphere of cameras. We demonstrate the usefulness of this measure with a visibility-guided simplification algorithm. Mesh simplification reduces the polygon counts of 3D models and speeds up the rendering process. Many mesh simplification algorithms are based on sequences of edge collapses that minimize geometric and attribute errors. By combining the surface visibility measure with a geometric error measure, we obtain simplified models with improvement proportional to the amount of low visibility regions in the original models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Visibility is important and has been well-studied in computer graphics. In general, visibility refers to determining which surfaces are unoccluded from certain camera positions in an environment.</p><p>In this paper, we are primarily interested in describing how some surface points are difficult to see due to object self-occlusions. For instance, the interiors of an object are invisible from any outside viewpoint. Some exterior regions are more difficult to see than others. To describe this view-independent property, we define a surface visibility measure which depends on the visibility function between the surface and a surrounding sphere of cameras (camera space). To calculate the surface-camera visibility function, we render the object from a dense set of camera poses in the camera space. For a point on the surface, the visibility measure is the percentage of the camera space from which this point is visible, and the camera space is weighted by the dot product between the point's surface normal and the viewing directions. We use this measure to help mesh simplification.</p><p>Mesh simplification algorithms reduce the polygon count of a model while maintain its overall shape and appearance. This is important for reducing the model storage cost and subsequent processing time. Many mesh simplification algorithms are based on a sequence of edge collapses. At each step, one edge is collapsed into a vertex, reducing the polygon count by two. The sequence of the edge collapse operations is designed to minimize geometric and appearance errors. In our study, we observe that many CAD models and medical imaging data sets contain large interiors and concavities, which contribute little to the final images from any outside viewpoint when being rendered as opaque objects. In these regions, our visibility-guided algorithm allows greater geometric and attributes errors. e-mail: {zhange,turk}@cc.gatech.edu</p><p>The remainder of the paper is organized as follows. In Section 2 we review existing methods for visibility calculation and mesh simplification algorithms. We present the definition of our surface visibility measure in Section 3 and then describe how we calculate this measure in Section 4. In Section 5 we present our visibilityguided simplification algorithm, which combines the surface visibility measure with a well-know geometric measure, the quadric measure. Section 6 provides a summary and discuss some future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p>In this section, we review previous work in visibility and mesh simplification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visibility</head><p>Visibility issues appear in many aspects of graphics. Here, we review some areas that are related to our work.</p><p>Visible Surface Determination Problem: The Visible Surface Determination Problem (VSD), also called the Hidden Surface Removal Problem, is the task of deciding which parts of the opaque objects in a scene are visible from a given viewpoint. In their 1974 survey <ref type="bibr" target="#b21">[22]</ref>, Sutherland et al classify existing VSD algorithms into those that perform calculations in object-space, those that perform calculations in image-space, and those that work partly in both, list-priority. They further point out these algorithms differ in how they perform sorting and what local coherence information is used to reduce the recalculation cost. The local coherence information used may include: face coherence <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b23">24]</ref>, scan line coherence and edge coherence <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b24">25]</ref>, depth coherence <ref type="bibr" target="#b23">[24]</ref>, etc. Catmull develops the depth-buffer or z-buffer image-precision algorithm which uses depth coherence <ref type="bibr" target="#b2">[3]</ref>. Myers later incorporates the depth-buffer algorithm with the scan-line algorithm <ref type="bibr" target="#b15">[16]</ref>. Fuchs et al use BSP tree to establish scene visibility <ref type="bibr" target="#b6">[7]</ref>. Appel <ref type="bibr" target="#b0">[1]</ref>, Weiler and Atherton <ref type="bibr" target="#b26">[27]</ref>, and Whitted <ref type="bibr" target="#b27">[28]</ref> develop ray tracing algorithm which transforms the VSD into ray-object intersection tests.</p><p>Aspect Graph: The visibility of a static scene often remains constant if viewpoints are restricted to be inside a limited region. This has led Koenderink and Van Doorn to propose the aspect graph to record where visibility changes occur <ref type="bibr" target="#b12">[13]</ref>. In this graph, each node represents a general view as seen from a region of viewpoint space. Two neighboring nodes are linked by an edge to represent a visual event (visibility change) when the viewpoint moves from one region to another. Algorithms have been developed for computing the aspect graph for 3D convex objects using orthographic views <ref type="bibr" target="#b17">[18]</ref> and perspective views <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref>. Gigus et al propose algorithms for computing the aspect graph for 3D polyhedra under orthographic views <ref type="bibr" target="#b8">[9]</ref>. Unfortunately, computing aspect graphes is expensive. For general polyhedra with n supporting planes, the complexity of computing the aspect graph using orthographic views is O(n 6 ). One often uses sampling techniques to generate approximations <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b9">10]</ref>. However, the sampling rate is difficult to set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Mesh Simplification</head><p>Mesh simplification, too, is a well-studied problem in computer graphics. Since the literature in this area is extensive, we review  Head-on views are in lighter greens and side views are in darker greens. For instance, point p is visible from both c1 and c2, but occluded from c3. Furthermore, c1 has a better viewing angle for the surface near p than that c2 does. only a few of the most relevant methods. Hoppe proposes the framework of the progressive mesh <ref type="bibr" target="#b10">[11]</ref> representation to address the issues of progressive transmission, selective refinement and geomorphing. Under this scheme, the polygon count is reduced by a sequence of edge collapses. All edges are put on a priority queue, which is sorted by some error measure. At each step, the edge with the least error is collapsed into a single vertex, therefore removing two polygons. The location of the new vertex and the choice of the error measure are the keys to determining the quality of the simplified models.</p><p>Ronfard and Rossignac <ref type="bibr" target="#b18">[19]</ref> measure the geometric errors by using the maximum distance of the new vertex location to the supporting planes of the original edge's 1-neighborhood. Garland and Heckbert use similar geometry information, namely, the quadric measure <ref type="bibr" target="#b7">[8]</ref> as their error measure. In this measure, determining the location of the new vertex is internally linked to the error measure, defined as the squared sum of the distances of the new vertex location to the supporting planes that contain at least one triangle incident to the edge. The quadric measure is a geometry-based error. Hoppe later extends this to handle attributes such as colors and texture coordinates <ref type="bibr" target="#b11">[12]</ref>. The original quadric measure does not use visibility information.</p><p>Lindstrom and Turk define a different type of error measure, namely, the image-driven measure <ref type="bibr" target="#b14">[15]</ref>. Instead of measuring the geometric deviation caused by the edge collapse operations, they measure the image deviation, that is, the visual differences between the model before and after a certain edge collapse. By creating images of both the original and partially simplified models from a number of different camera poses (such as the center of the faces of an icosahedron) the method determines the order of the edges based on the visual difference that these edges contribute. This measure indirectly takes into account which portions of an object are visible, and it greatly reduces the number of polygons used to represent interior details. However, the processing time required for calculating the image deviation is substantially more than that for the geometric deviation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VISIBILITY MEASURE DEFINITION</head><p>Due to scene occlusions, a point p is not always visible from a camera pose c. <ref type="figure" target="#fig_1">Figure 1</ref> illustrates this object-camera visibility function. In the left image, an object M consisting of line segments is observed from inward-looking orthographic cameras on a surrounding circle S with infinite radius. The center of S coincides with the center of the bounding box of M . Note, to draw both M and S in the same image, their relative size are distorted. The cameras are drawn as small line segments pointing toward the center of the circle. p is a point on M . c1, c2 and c3 are camera poses on the circle. p is visible from both c1 and c2, and invisible from c3 due to self-occlusion. c1 has a head-on view of the region near p while c2 views the same region at a poor angle.</p><p>The right image in <ref type="figure" target="#fig_1">Figure 1</ref> is a visualization of F (p, c), which we call the visibility diagram of M . The x-axis represents points on the perimeter of the shape, as traversed counter-clockwise. The y-axis represents camera poses on the surrounding circle, also traversed counter-clockwise. In the visibility diagram, the color at point (p, c) encodes the visibility between point p on the object M and camera pose c. Green means they are mutually visible, and white means they are mutually occluded. The intensity of greenness is proportional to the dot product between N (p) and R(c), the surface normal at p and the viewing direction of c, respectively. Lighter green indicates better views. The overall visibility of p from outside views is defined as:</p><formula xml:id="formula_0">V (p) = S F (p, c) (R (c) • N (p)) dc S (R (c) • N (p)) dc (3.1) V (p)</formula><p>measures the percentage of camera space that can "see" p, giving more weight to views at better angles. The portion of S over which we integrate is actually a half-sphere, based on the surface normal at p. V (p) is between 0 and 1. For example, any point on a convex object achieves the maximum value. Using the terms from radiosity <ref type="bibr" target="#b4">[5]</ref> and under the assumption that there is no scattering or energy loss during light transport,</p><formula xml:id="formula_1">F (p, c) (R (c) • N (p))</formula><p>is the form factor between an infinitesimal surface around p and an infinitesimal surface around c, i.e., the fraction of light which leaves c that reaches p. Therefore, V (p) measures the fraction of light which leave a sphere infinitely away from the object that can directly reach p. Furthermore, V (p) is related to the measure used by Nooruddin and Turk <ref type="bibr" target="#b16">[17]</ref> for surface interior/exterior classification and visualization. For their applications, their measure is a binary measure and all camera views are weighted equally. <ref type="figure" target="#fig_2">Figure 2</ref> shows the measure V (p) for some of our test models. The color coding is as follows: 0-1/3 (interpolating between white and red), 1/3-2/3 (interpolating between red and yellow), 2/3-1 (interpolating between yellow and green). The overall visibility of mesh M is defined as:</p><formula xml:id="formula_2">V (M ) = M V (p) dp M dp (3.2)</formula><p>This measure is 1 for convex objects. <ref type="table" target="#tab_1">Table 1</ref> shows the overall surface visibility of some test models. The Stanford Bunny model has a large convex body with the ears and other parts that are attached. This model has a high overall visibility. The Motor and Blade models contain large numbers of interior polygons, resulting in a low overall visibility. To obtain uniformly spaced camera poses, we construct a tessellation of the camera space S by subdividing the faces of an octahedron three times and placing sample cameras at every vertex of the resulting mesh. We assume a camera pose v sees a triangle t if and only if at least part of t is visible from v. We now adapt all our definitions in Section 3 as follows. F (t, v) is defined as 0 if t is entirely invisible from v, and 1 otherwise. N (t) is the normal of t, and R(v) is the viewing direction of v. We assume the tessellation of the camera space is even. Thus, area(v) is the same for all v.</p><formula xml:id="formula_3">V (t) = v∈S F (t, v) * (R (v) • N (t)) * area(v) v∈S (R (v) • N (t)) * area(v) (4.3)</formula><p>Here, we make the assumption that the visibility between a triangle t and a view triangle v is constant across both t and v. In general this is not true. However, when triangles in both M and S are small enough, the error introduced in the above formula becomes negligible. From each viewpoint v, we render the mesh object with a color-encoding of the polygon ID using graphics hardware. Then we record F (t, v) = 1 if at least one pixel has color t in the color buffer. This approach has two problems that need attention: triangles that are too large, and triangles that are too small or sliver-shaped. Large triangles increase the error since F (t, v) is far away from being constant. Small triangles result in aliasing, or so-called popping effect. When being viewed from rather poor angles, depending on how the scan-conversion is done in the rendering system, the presence of pixels for a particular triangle in the image is not consistent.</p><p>To handle triangles that are too large, we subdivide them such that the length of the longest edge of each triangle after subdivision is limited by a threshold l. l is calculated based on the aspect ratio and worst viewing angle (we use 75 degrees, where the dot product   between the surface normal and light rays is 0.25). To perform the subdivision, we add vertices to the middle of any edge that is longer than l. For each triangle, based on the number of the new vertices added to its edges, we divide it into sub-triangles. This process is repeated until all mesh edges are shorter than l.</p><p>While mesh subdivision removes large triangles, it maintains or even creates small and sliver triangles, which are subject to sampling problems. This affects the accuracy of F (t, v) more for the side views than then the head-on views. Since V (t) is defined to favor the head-on views, it is less sensitive to the sampling problems. Nonetheless, we alleviate t he situation by storing a depth buffer along with the color buffer for each camera pose. To determine F (t, v) for a small triangle t, we compare the depths of its vertices to the depths of their respective neighbor pixels. Even without pixels in the color buffer indicating t is visible, our algorithm considers it visible if the depth at any of its vertices is within a tolerance to the depth of a neighbor pixel. With this method, we are able to use a relatively low resolution (480 × 480) during the rendering process.</p><p>The accuracy of our algorithm depends on the sampling pattern in the camera space. In general, more cameras means more accurate results. On the other hand, more cameras means longer calculation time. <ref type="figure" target="#fig_3">Figure 3</ref> shows the relation between the visibility errors with respect to the number of cameras used for the Motor and Happy Buddha models. Here, we subdivide an octahedron up to 5 times to generate 6 camera sampling patterns, namely, 6, 18, 66, 258, 1026 and 4098 cameras evenly spaced on a sphere. Assuming the visibil-ity is accurate using 4098 cameras, we obtain the visibility errors for the other sampling patterns by calculating the area-weighted average of the visibility difference. As one can see, the visibility errors quickly converge, and we find that 258 cameras seem to be a good comprise between time and accuracy for all test models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VISIBILITY-GUIDED SIMPLIFICATION 5.1 Algorithm</head><p>We observe that many applications do not require processing invisible and low visibility concavity regions. We can be less concerned with the geometry errors at those parts of the surface. To put this into practice, we combine our surface visibility measure with a well-known geometric error measure called the quadric measure <ref type="bibr" target="#b7">[8]</ref>, which is defined for each edge in the mesh object. Let e be the next edge to collapse into a point v, represented in homogeneous coordinates as (x 0 , y 0 , z 0 , 1) T . Let T be all the triangles in M that are adjacent to at least one vertex of e, i.e., T is the union of the 1-ring neighborhoods of both vertices of edge e, allowing the triangles in both neighborhoods to be counted twice. Each triangle t has a plane equation</p><formula xml:id="formula_4">A t x + B t y + C t z + D t = 0 (5.4)</formula><p>The quadric measure is then defined as</p><formula xml:id="formula_5">E q (e) = t∈T (distance (v, t)) 2 (5.5)</formula><p>i.e.,</p><p>Eq (e) =</p><formula xml:id="formula_6">t∈T (Atx0 + Bty0 + Ctz0 + Dt) 2 = v T Qv (5.6)</formula><p>where</p><formula xml:id="formula_7">Q = t∈T    A 2 t AtBt AtCt AtDt A t B t B 2 t B t C t B t D t A t C t B t C t C 2 t C t D t AtDt BtDt CtDt D 2 t    (5.7)</formula><p>To combine our visibility measure with the quadric measure we note that the quadric measure is the sum of the squared distance from a point to many planes. If edge e is adjacent to some triangles with low visibility, then the distance from v to this plane makes less visual impact than the distances from v to high visibility triangles if the geometric errors are the same. Our visibility-guided error measure is defined as</p><formula xml:id="formula_8">E v (e) = t∈T (distance (v, t) V (t)) 2 (5.8) E v<label>(</label></formula><p>e) guides which edges are collapsed, that is, this measure is used to order the priority queue. Recall the meaning of V (t) as the weighted sum of dot products between a triangle's normal with incoming ray directions, our visibility-guided error measure for one triangle is the weighted average projected distance from all viewing directions. This means edges with higher geometric errors can be chosen for removal if they situate in extremely low visibility regions, such as interiors and creases. We use the original quadric matrix to select the best new vertex location for the collapsed edge as described in <ref type="bibr" target="#b7">[8]</ref>. For computational purpose, our measure is written as Ev (e) = v T Qvv (5.9)</p><p>where</p><formula xml:id="formula_9">Q v = t∈T       A 2 t AtBt AtCt AtDt AtBt B 2 t BtCt BtDt A t C t B t C t C 2 t C t D t A t D t B t D t C t D t D 2 t    V 2 (t)    (5.10)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>To compare the quality of the two simplification methods, we select the following image-based root-mean-squared (RMS) error, based on the method of Lindstrom and Turk <ref type="bibr" target="#b14">[15]</ref>. For the original model M 0 and the simplified model M i , we render both models from the twenty vertices of a surrounding dodecahedron using flat shading. The RMS "image" error between the images is calculated as:</p><formula xml:id="formula_10">RM S (M i , M 0 ) = 20 n=1 D n i (5.11)</formula><p>Here, D n i is the squared sum of pixel-wise intensity difference between the n-th image of Mi and M0. Essentially we are evaluating how similar the original and simplified models appear when rendered.</p><p>For each of the six test model, we select seven target polygon counts, and apply both the quadric-based (QB) method <ref type="bibr" target="#b7">[8]</ref> and our visibility-guided (VG) method. <ref type="figure" target="#fig_4">Figure 4</ref> shows the comparisons between the image errors and the geometric errors obtained using the Metro program <ref type="bibr" target="#b3">[4]</ref> for the simplified models of the same polygon counts. Results obtained for the QB method are painted using blue lines, and those for the VG method are painted using red lines. The image errors are painted using regular lines with diamonds, and the geometric errors are painted using wider lines. This figure shows that the VG method in general generates smaller image errors but incurs greater geometric errors than the QB method. The greater geometric errors occur in low visibility regions. <ref type="figure">Figure 5</ref> shows the visual comparisons for the Motor model, a car engine model with 140,113 polygons (middle). This model has a large number of invisible polygons with high curvatures occluded by its main exterior feature, a box. The exterior also contains several mechanical parts. For the simplified models (QB on the left, and VG on the right) with the same polygon count of 15,000, the VG method has 51.77% less image error as the QB method. In fact, the image error for the VG method of polygon count 12,000 is about equal to that for the QB method of 27,000 polygons <ref type="figure" target="#fig_4">(Figure 4)</ref>. This is not surprising since the quadric errors for the original Motor model's interior edges are higher than that of most exterior features. When the regions with low quadric errors have been simplified, the QB method starts simplifying the exterior features. The VG method simplifies the interior regions despite their relatively high quadric errors.</p><p>Also shown in <ref type="figure">Figure 6</ref> is the Blade model created from CT data of an actual turbine blade (middle: original model with 1,688,933 polygons, left: QB method, and right: VG method, both with 15,000 polygons). It also contains a large number of interior polygons. Again, the VG method performs better than the QB method. Note the difference at the letters on the base (bottom row) and the features along both sides of the blade (both rows).</p><p>Medical imaging data sets often contain large interiors and concavities. The Skull model, created from 124 CT scan slices, is shown in <ref type="figure">Figure 7</ref> (middle: the original model with 1,169,608 polygons, left: QB method, and right: VG method, both with 10,000 polygons). To remove the contour lines that are artifacts of the reconstruction algorithm, we performed Taubin's smoothing method <ref type="bibr" target="#b22">[23]</ref> before simplification. This model does not have many invisible polygons, but it has a large number of polygons with low   <ref type="table">Table 2</ref>: This table shows the comparison between six test models, with their polygon counts, visibility measure, image error, and the calculation time the visibility measure as well as processing time for simplification. The timing measurements were taken on a SGI Octane with a 195 MHz CPU.</p><p>visibility. The VG method maintains better triangulations than the QB method around the regions of the teeth and their roots, as well as the forehead.</p><p>To understand the range of applicability of our method, we tested our method against models that has a relatively small amount of low visibility regions. The Buddha model and the Dragon model (not shown), created using range scan and surface reconstruction, belong to this category. As shown in <ref type="figure" target="#fig_4">Figure 4</ref>, the visibility-guided method consistently perform better although the improvement is less than that of other models. <ref type="figure">Figure 8</ref> shows the visual comparisons for the Buddha model (bottom middle: original model with 1,087,416 polygons, bottom left: QB method, and bottom right: VG method, both with 20,000 polygons). The main difference is mainly around the face. Note the features in this regions are better maintained using our VG method than using the QB method.</p><p>From the analysis above, it appears that the amount of improvement is related to the overall visibility measure of the surface, see <ref type="table">Table 2</ref>. The last column lists the average of the percentage differences in the image errors incurred using VG method than using the QB method for the seven levels. The table also lists the processing time for each test model, including the time to calculate the visibility measure, and the time to perform visibility-guided simplification. Note that the time required for the QB method and the VG method differ very little (&lt; 1%). Therefore, if a model's visibility measure has been pre-computed, the visibility-guided simplification does not require more time than that is needed by other edge-collapse mesh simplification algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>In this paper, we defined a view-independent visibility measure to classify mesh surface regions based on how easy they are to see from the outside. This visibility measure depends on the visibility function between the mesh surface and a surrounding sphere of cameras. We combined our visibility measure with the quadric measure to perform mesh simplification. The visibility-guided method produces improvements (measured according to image differences) that are related to the amount of low-visibility regions in the mesh.</p><p>As a possible next step, we would like to find algorithms to calculate the visibility function more accurately. One possibility is to allow the visibility function to have values between 0 and 1 as a probability for views at poor angles or insufficient resolutions. Also, we would like to perform out-of-core visibility calculations for large models such as those obtained through the digital Michelangelo project <ref type="bibr" target="#b13">[14]</ref>.</p><p>We are also exploring other applications for our visibility measure, including shape matching and texture mapping.</p><p>The visibility function and the visibility measure describe the self-occlusion properties of mesh objects. Therefore, it is possible that the distribution of the visibility measure can be used in shape matching and feature recognition.</p><p>In texture mapping, the surface of an object is often divided into patches. Every patch is independently unfolded onto a plane before all the patches are packed into the texture map. Since mesh interiors do not contribute the final images for opaque objects, we do not need to assign space for them. Also, regions with low visibility measure will be viewed from poor angles, allowing us to be less concerned about their stretch during the texture unfolding process. <ref type="figure">Figure 5</ref>: Visual comparisons between the original Motor model (Middle, 140,113 polygons), and the simplified versions using the quadriconly method (Left, 15,000 polygons) and the visibility-guided method (Right, 15,000 polygons). All images are rendered using flat shading. Compare the overall shape of the trunk and mechanical parts. <ref type="figure">Figure 6</ref>: Visual comparisons between the original Blade model (Middle, 1,688,933 polygons), and the simplified versions using the quadriconly method (Left, 15,000 polygons) and the visibility-guided method (Right, 15,000 polygons). All images are rendered using flat shading. Compare features such as the letters on the base (bottom row), the column of rectangular vents along the right edge, and the small holes along the left edge (both rows). <ref type="figure">Figure 7</ref>: Visual comparisons between the original Skull model (Middle, 1,169,608 polygons), and the simplified versions using both the quadric-only method (Left, 10,000 polygons) and the visibility-guided method (Right, 10,000 polygons). All images are rendered using flat shading. Compare features such as the teeth and forehead. <ref type="figure">Figure 8</ref>: Visual comparisons between the original Buddha model (Bottom Middle, 1,087,416 polygons), and the simplified versions using the quadric-only method (Bottom Left, 20,000 polygons) and the visibility-guided method (Bottom Right, 20,000 polygons). All images are rendered using flat shading. The top row images use the red channel to encode image differences between the bottom row images. Note that the top left image (difference between the bottom center image and the bottom left image) has more areas of red than the top right image (difference between the bottom center image and the bottom right image).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>IEEE</head><label></label><figDesc>Visualization 2002 Oct. 27 -Nov. 1, 2002, Boston, MA, USA 0-7803-7498-3/02/$17.00 © 2002 IEEE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>An object (left) and its visibility diagram F (p, c) (right). In the visibility diagram, white indicates surface point p and camera pose c are mutually occluded. Green indicates they are mutually visible. The intensity of greenness is related to the dot product between the surface normal at p and the viewing direction of c.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>This image illustrates the visibility measures for some test models: the Utah Teapot, a foot bone model, Happy Buddha, Dragon, and a CAD model of three interlocking tori.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>This diagram shows the tradeoff between the visibility errors and the number of cameras (calculation time) for the Motor and the Buddha models. The visibility is calculated with 6, 18, 66, 258, 1026 cameras, and is compared to the visibility calculated with 4096 cameras. The X-axis represents the number of cameras used for visibility calculation, and the Y-axis represents the visibility error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Image error (diamond) and geometric error (wider line) comparisons between the quadric simplification method (blue) and our visibility-guided method (red) at 7 levels in the progressive meshes. The X-axis represents the numbers of polygons for each level. The left Y-axis represents represents the image error and the right Y-axis represents the geometric error. Motor, Skull, Blade and Locomotive models show significant improvement due to the large percentage of interiors. Buddha and Dragon models show small but noticeable improvement due to the large percentage of low visibility regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">Motor (140000 polygons)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Buddha (1087123 polygons)</cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.15</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0 0</cell><cell>200</cell><cell>400</cell><cell>600</cell><cell>800</cell><cell>1000</cell></row></table><note>This table shows the surface visibility measure for several models along with the processing time. The timing measurements were taken on a SGI Octane of 195 MHz CPU.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">VISIBILITY MEASURE CALCULATIONCalculating the exact mesh visibility function for large models is computationally prohibitive. Nooruddin and Turk<ref type="bibr" target="#b16">[17]</ref> have used a sampling approach in both the object space M and the camera space S for interior/exterior classification. Here, we use a similar approach. First, we subdivide the mesh surface until all triangles are small. Next, we choose a finite number of camera positions that are evenly distributed in the camera space. Finally, we render M from each of these camera positions with the help of graphics hardware to quickly compute a table of visibility between the camera positions and the surface triangles. This table is a discrete version of the visibility diagram(Figure 1).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGEMENTS</head><p>We would like to thank the following people and groups for the 3D models they provided: Will Schroeder, Ken Martin, Bill Lorensen, Bruce Teeter, Terry Yoo, Mark Levoy and the Stanford Graphics Group. Also, we would like to thank Michael Garland for the QSlim code. Finally, we thank the anonymous reviewers for their excellent suggestions.</p><p>This work is funded by NSF grant ACI 0083836.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Some Techniques for Shading Machine Renderings of Solids , SJCC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Appel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A procedure for Generation of Three-Dimensional Half-toned Computer Graphics Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Bouknight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm, ACM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="1969-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A Subdivision Algorithm for Computer Display of Curved Surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Catmull</surname></persName>
		</author>
		<idno>UTEC-CSc-74-133</idno>
		<imprint>
			<date type="published" when="1974" />
			<pubPlace>Salt Lake City, UT</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of Utah</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D Thesis, Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Metro: measuring error on simplified surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cignoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rocchini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Scopigno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="174" />
			<date type="published" when="1998-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Hemi-Cube: A Radiosity Solution for Complex Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Proceedings</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Property spheres: a new representation for 3-D object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Computer Vision: Representation and Control</title>
		<meeting>the Workshop on Computer Vision: Representation and Control<address><addrLine>Annapolis, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1984-05-02" />
			<biblScope unit="page" from="192" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On Visible Surface Generation by A Priori Tree Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">M</forename><surname>Kedem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naylor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="124" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Surface Simplification using Quadric Error Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Heckbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference Series (SIGGRAPH 97)</title>
		<imprint>
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computing the aspect graph for the line drawings of polyhedral objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gigus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malik</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pat. Matching &amp; Mach. Intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1990-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The 3-D profile method for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kanade</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings, CVPR &apos;85 (IEEE Computer Society Conference on Computer Vision and Pattern Recognition)</title>
		<meeting>CVPR &apos;85 (IEEE Computer Society Conference on Computer Vision and Pattern Recognition)<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985-06" />
			<biblScope unit="page" from="458" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Progressive Meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 1996 Proceedings)</title>
		<imprint>
			<biblScope unit="page" from="99" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">New quadric metric for simplifying meshes with appearance attributes, IEEE Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-10" />
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The singularities of the visual mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Vandoorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioCyber</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pulli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruskinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ginzton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ginsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fulk</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<title level="m">The Digital Michelangelo Project: 3D Scanning of Large Statues , SIGGRAPH Proceedings</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="131" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image-Driven Simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lindstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Turk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="204" to="241" />
			<date type="published" when="2000-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">An Efficient Visible Surface Program, Report to National Science Foundation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Myers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975-07" />
			<pubPlace>Columbus, OH</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Graphics Research Group, Ohio State University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Interior/Exterior Classification of Polygonal Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Nooruddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Turk</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization 2000 Conference</title>
		<meeting><address><addrLine>Salt Lake City, Utah</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-08-13" />
			<biblScope unit="page" from="415" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An algorithm for constructing the aspect graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Plantinga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dyer</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th Annual Symposium on Foundations of Computer Science</title>
		<meeting><address><addrLine>Los Angeles, Ca., USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986-10" />
			<biblScope unit="page" from="123" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Full-range approximations of triangulated polyhedra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ronfard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rossignac</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurographics96</title>
		<meeting>Eurographics96</meeting>
		<imprint>
			<date type="published" when="1996-08" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">67</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Study for Applying Computer Generated Images to Visual Simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Schumacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gilliland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sharp</surname></persName>
		</author>
		<idno>AFHRL-TR-69-14</idno>
		<imprint>
			<date type="published" when="1969-09" />
		</imprint>
		<respStmt>
			<orgName>US Air Force Human Resources Laboratory</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Direct construction of the perspective projection aspect graph of convex polyhedra, Computer Vision, Graphics and Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stewman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bowyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990-07" />
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="20" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A characterization of ten hidden-surface algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">E</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Sproull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Schumacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Survey</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="1974-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A signal Processing Approach to Fail Surface Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 1995 Proceedings</title>
		<imprint>
			<date type="published" when="1995-08" />
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A Hidden-Surface Algorithm for Computer-Generated Halftone Pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Warnock</surname></persName>
		</author>
		<idno>TR 4-15</idno>
		<imprint>
			<date type="published" when="1969-06" />
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of Utah</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A Real-Time Visible Surface Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Watkins</surname></persName>
		</author>
		<idno>UTECH-CSC-70-101</idno>
		<imprint>
			<date type="published" when="1970-06" />
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of Utah</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Calculating the principle views of polyhedron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Watts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth International Conference on Pattern Recognition</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988-11" />
			<biblScope unit="page" from="316" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Hidden Surface Removal Using Polygon Area Sorting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atherton</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="214" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An Improved Illumination Model for Shaded Display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Whitted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACAM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="343" to="349" />
			<date type="published" when="1980-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
