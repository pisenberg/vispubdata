<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A New Object-Order Ray-Casting Algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mora</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut de Recherche en Informatique de Toulouse (IRIT)</orgName>
								<orgName type="institution">Université Paul Sabatier</orgName>
								<address>
									<postCode>31062</postCode>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Pierre</forename><surname>Jessel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut de Recherche en Informatique de Toulouse (IRIT)</orgName>
								<orgName type="institution">Université Paul Sabatier</orgName>
								<address>
									<postCode>31062</postCode>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">René</forename><surname>Caubet</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut de Recherche en Informatique de Toulouse (IRIT)</orgName>
								<orgName type="institution">Université Paul Sabatier</orgName>
								<address>
									<postCode>31062</postCode>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A New Object-Order Ray-Casting Algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation</term>
					<term>I.3.7 [Computer Graphics]: Three-Dimensional graphics and realism</term>
					<term>Raytracing</term>
					<term>Visible line/surface algorithms Volume Rendering</term>
					<term>Scientific Visualization</term>
					<term>Medical Imaging</term>
					<term>Ray Tracing</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Many direct volume rendering algorithms have been proposed during the last decade to render 256 3 voxels interactively. However a lot of limitations are inherent to all of them, like lowquality images, a small viewport size or a fixed classification. In contrast, interactive high quality algorithms are still a challenge nowadays. We introduce here an efficient and accurate technique called object-order ray-casting that can achieve up to 10 fps on current workstations. Like usual ray-casting, colors and opacities are evenly sampled along the ray, but now within a new objectorder algorithm. Thus, it allows to combine the main advantages of both worlds in term of speed and quality. We also describe an efficient hidden volume removal technique to compensate for the loss of early ray termination.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Volume visualization has been widely studied over the last decade due to the expansion of scientific devices producing such data. Many algorithms have been developed, and some of them are regrouped under the category of direct volume rendering <ref type="bibr">(DVR)</ref> methods in which the whole original dataset is used for the rendering without any intermediate representation of the volume. In DVR algorithms, the interaction between rays traced from the viewpoint and the volume is studied, which allows high quality images and a great freedom of action. Several models of interaction are widely used nowadays, like the maximum intensity projection (MIP) model that returns the maximum value encountered along the ray, or the accumulation model that integrates the signal. Here, we will only focus on optical models <ref type="bibr" target="#b11">[10,</ref><ref type="bibr" target="#b17">16]</ref> that are common to many volume rendering applications, even if our algorithm can be easily extended to other models. The Kajiya's optical model in its low albedo form is given by:</p><formula xml:id="formula_0">( ) ( ) ( ) ∫ ∫         − × × = l s ds dt t s s C I 0 0 exp τ τ λ λ (1)</formula><p>Where I λ is the amount of light of wavelength λ along the ray reaching the viewpoint. The contribution of the ray at the location s is given by C λ (s) weighted by the extinction coefficient τ(s) and by the percentage of occlusion that depends on the opacity between the viewpoint and s. However this integral cannot be evaluated as it is, and a Riemann sum is often used to approximate it. This way, rays are usually evenly sampled with a distance ∆s, and the accumulated color (C i ) and opacity (α i ) are estimated with the recursive process given below (front-to-back order):</p><formula xml:id="formula_1">C i+1 = C i + (1-α i ) α s C s<label>(2)</label></formula><p>α i+1 = α i + (1-α i ) α s It is obvious that the accuracy of the integral estimation directly depends on the distance ∆s and on the evaluation of the values α s and C s . A large sampling distance can accelerate the rendering times, but on the other hand it provides low quality images.</p><p>Furthermore the sampled values α s and C s have to be estimated from the discrete volume data with a reconstruction filter. Thus the choice of the reconstruction filter is crucial and nowadays only the trilinear filter and the Gaussian filter, usually considered as reasonable quality filters, can perform direct volume rendering in acceptable times, even if studies <ref type="bibr" target="#b16">[15]</ref> have shown that a better quality can be obtained with more complex filters. Then a good volume rendering application should provide the best compromise between quality and speed.</p><p>In this paper we will intend to give such a trade-off by using an efficient approach to compute ray-casting. Usually, trilinear interpolation is made easier with this algorithm, but the pixel-bypixel approach (also called image-order) drastically slows down the rendering process, even if the hidden regions of the volume are not processed. On the opposite, the projection approaches (also called object-order) are well-suited for skipping empty regions, but the usually associated filters are either low-quality filters or too complex to be interactive, and hidden volume removal is not very efficient. Our approach combines the advantages of both approaches to produce interactive high-quality volume rendering.</p><p>First, in section 2, we will look at today's mostly used techniques and we will try to explain the strengths and {mora, jessel}@irit.fr weaknesses of each approach. Then, in section 3, we will describe the new object-order ray-casting algorithm. Finally, we will show in section 4 that efficient hidden volume removal is possible with it before giving our results in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PREVIOUS WORK</head><p>Four main software algorithms have emerged in the last decade <ref type="bibr" target="#b19">[18]</ref> and are widely used: the Shear-Warp method and the Hardware-assisted 3D texture mapping techniques that are speed oriented, and the quality oriented ray-casting and splatting algorithms.</p><p>Shear-Warp <ref type="bibr" target="#b13">[12]</ref> is currently considered as the fastest software algorithm. It offers many optimizations probably allowing unbeatable rendering times. This object-order method considers the volume as a stack of 2D slices parallel to the face of the volume the most perpendicular to the view axis. Slices are accumulated on an intermediate image that undergoes an ultimate resampling step to produce the final image. The intermediate image is aligned with the slices and has the same pixel density, allowing both the volume and the image to be run in an efficient memory order, and to perform fast projection (i.e. one voxel is projected on one pixel). To improve quality, a bilinear interpolation is made for every projection with constant coefficients within a slice. Finally an efficient pre-classified runlength encoding of the volume allows skipping quickly empty regions.</p><p>However, regarding quality, this algorithm has many drawbacks. First, the sampling rate on the z-axis is between 1 and 1.73 according to the viewpoint, which is definitely not enough for the observation of thin volume structures. The pre-classification partially blurs the intermediate image, which is increased by the final resampling step. Finally, artifacts occur when the viewing angle is close to 45 o due to the bilinear interpolation. Thus, the global quality provided by the original implementation turns out to be poor.</p><p>A solution to these drawbacks is to use trilinear interpolation, post-classification and supersampling, as implemented in the VolumePro board <ref type="bibr" target="#b27">[26]</ref>. This PCI board can render 500 million interpolated samples per second with a brute-force Shear-Warp algorithm (parallel projection), which is sufficient to render 256 3 volumes at 30 frames per second. Supersampling can be computed on hardware in the z-direction and on software in the x and y directions by rendering several images at different offsets. However supersampling divides the frame rate by the number of samples per voxel, and then if the sampling rate along the 3 axes is doubled to produce high quality images, the frame rate can decrease to under 4 frames per second. Furthermore, applying these improvements on the original algorithm should also reduce greatly its performances. Thus, real time high quality volume rendering should not be really possible yet by using a shear-warp algorithm.</p><p>Another popular way to perform interactive volume rendering is to use 3D texture mapping hardware <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">2,</ref><ref type="bibr" target="#b5">4,</ref><ref type="bibr" target="#b18">17,</ref><ref type="bibr" target="#b30">29]</ref> by extracting and compositing 2D planes parallel to the image plane, but until recently the proposed approaches had several limitations, like binary classification or diffuse shading only. Engel and al. <ref type="bibr" target="#b4">[3]</ref> have used the NVidia's OpenGL extension available with the new Geforce3 graphics hardware to circumvent these drawbacks. Although real-time rendering rates are possible on small volumes (&lt;128 3 ) with the current available implementation, it does not exceed 2 frames per second for 256 3 volumes due to the high memory bandwidth needed. Furthermore the large distance (∆s=1) between the extracted slices can miss small details or produce artifacts in spite of the very interesting pre-integrated classification used. Thus the main advantage of this approach is to provide constant and at least interactive perspective renderings with a reasonable quality, even if the flexibility of the 3D texturebased methods is still low.</p><p>Like the 3D texture-based algorithms, splatting has also come to maturity over the years since the first release proposed by Westover <ref type="bibr" target="#b32">[31]</ref>. A Gaussian filter is usually associated with this method, but its use requires several refinements within the algorithm. In the latest versions proposed by Mueller et al. <ref type="bibr" target="#b24">[23,</ref><ref type="bibr" target="#b25">24]</ref>, slices are extracted parallel to the image plane and combined with a sheet buffer in a front-to-back order. Post-classification and post-shading can also be done to improve the image quality. The main drawback is that this algorithm is rather slow and even an optimized release <ref type="bibr" target="#b9">[8]</ref> needs several seconds to render an isosurface. However, the global quality that can be obtained with this filter is different from, but not really superior to, the one obtained with a trilinear filter <ref type="bibr" target="#b19">[18]</ref>. While this latter produces more aliasing, the Gaussian filter is a low-pass filter blurring small details within the volume. Thus it seems that splatting with a gaussian kernel is not interesting if compared with trilinear interpolation because the larger kernel size limits its efficiency.</p><p>Ray-casting is another way to produce good quality images because trilinear interpolation can easily be implemented, although other filters can also be used <ref type="bibr" target="#b22">[21]</ref>. Another great advantage is the incoherency between the rays that reduces greatly the staircase artifacts visible in algorithms extracting 2D planes, like with 3D texture-based DVR. Last but not least, early ray termination avoids the hidden regions to be treated. However, this algorithm is naturally slow because it is a pixel-by-pixel approach. Every time the ray steps forward within the volume, eight samples have to be loaded before performing trilinear interpolation. This creates cache misses because the samples cannot be stored in memory order. Furthermore, other rays rerunning the same cell may not take advantage of the preloaded data in the cache because the cache lines are often replaced by other data. On the contrary, the object-order methods access the voxels a limited number of times and produce traffic on the frame buffer, which is preferable because the image caching is generally better and easier than the volume caching. The second drawback is the difficulty to skip empty regions of the volume, especially when interactive classification is needed.</p><p>Several acceleration techniques have been proposed to reduce rendering times. Yagel and Kaufman <ref type="bibr" target="#b35">[34]</ref> proposed the use of the same template ray to accelerate volume traversal. Sobierajski and Avila <ref type="bibr" target="#b38">[37]</ref> proposed a two-step method. First, boundary cells are projected on the image plane using graphics hardware to identify more precisely the relevant parts of the rays. Then, a standard raycasting is used. Interactive renderings are possible <ref type="bibr" target="#b29">[28]</ref> for 256 <ref type="bibr" target="#b4">3</ref> volumes with 256 2 rays. However as this method did not allow efficient interactive classification, Westermann and Sevenich <ref type="bibr" target="#b31">[30]</ref> used 3D textures instead of boundary cells to estimate the start of the ray traversal. Although those methods are efficient for isosurface renderings, they do not address the problem of the vertex loading and then are not efficient in other cases. Thus, Knittel <ref type="bibr" target="#b12">[11]</ref> proposed the interleaving of voxel addresses, like many hardware implementations do, and deep optimizations to improve cache hits. Tile-casting was also used to take advantage of the ray coherency in space. Nonetheless, the acceleration data structure used for empty space skipping has to be recomputed to get optimal rendering times when the classification is changed, which limits the interactivity. Interactive rendering rates are possible on a small perspectives image (256 2 ) with a bi-PIII clocked at 500 MHz.</p><p>Thus, the current image-order ray-casting implementations have several gaps limiting the rendering times. The new object-order ray-casting we are looking at here tries to take advantage of both the quality produced by trilinear interpolation and the efficiency of the object-order methods (optimized volume run and easy space leaping). Thus, it is suitable for high-quality interactive volume rendering. We also propose a hidden volume removal algorithm to compensate for the loss of the early ray termination optimization inherent to image-order algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">OBJECT-ORDER RAY-CASTING</head><p>The reconstruction filter employed in object-order algorithms is closely related to the projection technique used <ref type="bibr" target="#b33">[32]</ref>. Until recently, it was limited to the projection of Gaussian kernels with the splatting algorithm, to the projection of one cell on one pixel with the shear-warp algorithm, or to the projection of the cell faces with polygons <ref type="bibr" target="#b37">[36]</ref>, which has serious drawbacks. Recent advanced methods <ref type="bibr" target="#b20">[19,</ref><ref type="bibr" target="#b23">22]</ref> have shown that the projection of a parallelepipedic shape can be efficiently performed when using an orthogonal projection. Therefore, it makes object-order raycasting possible.</p><p>For every cell that has to be rendered (i.e. not transparent and not hidden), the pipeline is as follows: first, the values and gradients of the 8 vertexes are loaded. Then, for every ray intersecting the cell, colors and opacities are sampled along it before updating the equivalent pixel. The next sections describe the main parts of this pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Efficient Ray-Cell Intersection</head><p>When using orthogonal visualization, every cell projection on the image plane is given by the same template hexagon modulo a translation. The projection of the center of the cell is just able to inform us about this translation vector. Therefore, a square made of four neighboring pixels is subdivided and a list of relative coordinates corresponding to the projection of the cell is associated with each subdivision (Pixel index in <ref type="figure" target="#fig_1">fig. 2a</ref>). The rasterized pixels are simply given by the addition of the pixel indexes of the subdivision containing the projected center of the cell with the global coordinate of the square where the center is projected. Here, all the lists are precomputed every time the viewpoint change and the use of a linear indexing improves the efficiency. However, some erroneous pixels can be projected because the same list is used with all the cells so that the centers are projected within the same subdivision. Fortunately the probability is low and can be corrected by testing line equations. See <ref type="bibr" target="#b20">[19]</ref> for a complete description about this implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evenly Spaced Sampling</head><p>The previous section has shown how to determine the rays going through a cell with precision. Now, the sequential process (2) estimating the line integral (1) must be performed for each ray in a front-to-back order to ensure the right evaluation. Thus, the intermediate luminance and density values needed in (2) are stored as 16 bits unsigned integers for every pixel. However, two main difficulties arise from this technique. First, the sampling coordinates within the cell needed for trilinear interpolation have to be computed quickly. Second, sampling points should be evenly spaced to evaluate precisely the Riemann sum. In order to make them possible, the algorithm uses both a set of preprocessed rays and a four-bits depth-sampling indicator aliased to the four lower bits of the pixel opacity.</p><p>The set of preprocessed rays ( <ref type="figure" target="#fig_1">fig. 2b</ref>) is used to find out the ray entry point within the cell. Each element stores the 3 entry coordinates (x, y, z) as 16 bits unsigned integers representing values in the range [0..1], plus an additional ray length used for evenly spaced sampling. Thus, a ray number pointing to the best representative preprocessed ray is assigned to every pixel of the projection lists (ray index <ref type="figure" target="#fig_1">in fig 2a)</ref>. Here, directly storing a preprocessed ray with every pixel would be less efficient because it would increase the table size. The set of rays is reconstructed  The depth-sampling indicator is now used to ensure a regular sampling of the ray between two consecutive cells. It determinates how many unit translation vectors (UTVs) must be added to the entry point to obtain the first sampling location. The next sampling locations of the ray within the cell are given by adding a constant translation vector depending on the sampling rate. The UTV is parallel to the viewing direction and it is defined as <ref type="bibr" target="#b17">16</ref> 1 of the longest vector crossing the cell, which means that its coordinate on the major projection axis is also equal to <ref type="bibr" target="#b17">16</ref> 1 . The maximum number of UTVs that can be added to the entry point before going out of the cell gives the length parameter of the preprocessed rays. Thus, the basic algorithm to compute a ray/cell interaction is as follows:  <ref type="bibr" target="#b17">16]</ref>. We point out the fact that while cells are correctly traversed by rays, the sampling positions (and thus, the trilinear weights) are approximated with our technique ( <ref type="figure">fig. 4</ref>). This is due to the limited set of preprocessed rays, to the limited number of projection lists and to the four-bits only depth indicator. Accuracy can be improved by increasing the size of tables and the number of bits in the depth indicator. However it also increases cache misses and reduces randomizing, which is not necessarily good because it trades noise for aliasing ( <ref type="figure" target="#fig_2">fig. 3b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interleaving Depth Indicators</head><p>While usual methods (Shear-Warp, 3D Textures and Splatting) sample the volume at the same depth locations, ray-casting can benefit from the incoherency between the rays to improve rendering by using a shifted sampling ( <ref type="figure">fig. 5b</ref>). Theußl et al. have shown <ref type="bibr" target="#b28">[27]</ref> that this way to sample the volume provides a better accuracy than the usual rectilinear sampling. In our algorithm, half of the depth indicators are initialized to zero and the others to half of the sampling rate such that every pixel has a different initialization than its four nearest neighborhoods. The use of randomized patterns is also conceivable. <ref type="figure" target="#fig_2">Figure 3</ref> shows the resulting improvement. While staircase effects are visible when sampling at constant depths ( <ref type="figure" target="#fig_2">fig. 3b and 3c</ref>), even with high sampling rates, interleaving depth indicators ( <ref type="figure" target="#fig_2">fig. 3d</ref>) clearly reduces this aliasing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">OPTIMIZATIONS</head><p>Some improvements in the previous algorithm are implemented to obtain a really efficient approach. Here is a method on how to  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Skipping Transparent Regions</head><p>Because the classification process can eliminate a great part of the volume <ref type="bibr" target="#b13">[12]</ref>, skipping transparent regions is a major improvement in software volume rendering. However, a user-friendly application should always allow changing the classification interactively. In this way, a min-max octree structure is used in addition to the usual volume representation. The leaf nodes store the minimum/maximum values of the 8 vertexes of the corresponding cell while the other nodes bring up the values of their 8 sons.</p><p>Here, octrees have several advantages. First, using a trilinear reconstruction kernel makes traversing the octree in a front-toback visibility order possible, which is not feasible in usual splatting methods without artifacts. Second, the octree can be run in an efficient memory order (with cache hits), whatever the viewpoint is. Third, two cells run consecutively are projected close to one another most of the time, which improves image caching. Fourth, it allows changing the classification interactively <ref type="bibr" target="#b13">[12]</ref>. Finally, hidden nodes can be skipped with the new algorithm presented in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hidden Volume Removal</head><p>In contrast with usual computer graphics applications where efficient occlusion culling methods have been widely studied <ref type="bibr" target="#b7">[6,</ref><ref type="bibr" target="#b8">7,</ref><ref type="bibr" target="#b36">35]</ref>, elimination of hidden volumes must be deeply improved in object-order DVR. A scan-line method was used in <ref type="bibr" target="#b13">[12]</ref>, but the efficiency of such a method seems limited. Mueller et al. <ref type="bibr" target="#b26">[25]</ref> have proposed an occlusion test for splatting avoiding the projection process, but this test performed on every voxel remains. A more interesting approach is given by Lee and Ihm <ref type="bibr" target="#b10">[9]</ref> where a min-max octree is used in association with either a range tree or a quadtree. Nonetheless, while the visibility test is not efficient with the former, the node visibility is approximated with the latter, providing artifacts. In fact the main problem of this approach comes from the use of trees that do not allow efficient neighbor finding. Instead, our new algorithm is based on hierarchical occlusion maps (HOMs) <ref type="bibr" target="#b36">[35]</ref>, which is by far superior for skipping the hidden nodes of the octree. This section only describes the two main lines of this algorithm: how HOMs are updated and how to perform the visibility test.</p><p>HOMs are images where the pixels store an integer value in the range [0..16] and are initialized to 0. The first occlusion map size is equal to quarter of that of the image and the last occlusion map of the hierarchy only represents one pixel. The updating process begins on the first HOM (i.e. the finest map) every time a pixel of the image plane becomes opaque. In this case the pixel of the HOM including the opaque pixel and its 3 nearest pixels in the map are incremented ( <ref type="figure">fig. 6a)</ref>. When an HOM pixel reaches its maximum value (i.e. incremented 16 times), updating starts again recursively at the superior level. Thus, the complexity of this process is equal to m 2 .Log 2 (m) only, where m is the image width. However, an opacity test must also be added for every treated ray.</p><p>The visibility process consists in determining the hidden nodes during the rendering. Because the projection of a node is also represented by a hexagon, an HOM level is now associated with every octree level. This HOM level is equal to the finest level such that a HOM pixel can include the entire projection of the octree node ( <ref type="figure">fig. 6b)</ref>. Thus, the visibility test is performed for each node by looking if the pixel of the corresponding occlusion map where the center of the node projects is equal to 16. This value means that an extended square around the pixel made of 16 quarter of pixel ( <ref type="figure">fig. 6b)</ref> is opaque. <ref type="figure" target="#fig_4">Figure 7</ref> shows an example of an octree run with efficient hidden volume removal. In this example, most of the encountered leaf nodes are located near the visible surface, though some of them are surprisingly far beyond because the recursive run of the volume allows efficient but non-optimal hidden volume removal. Another observation is the rareness of big block skipping. This is mainly due to the low accuracy given by the corresponding occlusion maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Other Optimizations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Fast Projection</head><p>The projection of the center of the octree nodes is a key element in our application because it is used in the visibility process ( § 4.2) and for determining the rays intersecting the cell ( § 3.1). Here, the use of an orthogonal projection allows the projected center of a node to be computed from the projected center of the parent node by a simple 2D translation. In this way, eight constant 2D translation vectors are preprocessed for every level of the octree. 32 bits integer arithmetic is also used to quickly determine the subdivisions and the pixels affected by the projection and to quickly update recursively occlusion maps. Finally, the depth component used for fast depth cueing is computed in the same way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Classification and Shading</head><p>Classification and shading are computed on every sampled point along the ray from the volume samples and the gradient by using a trilinear interpolation. Usually, classification and shading are performed either before the interpolation step (preclassification and preshading) or after (postclassification and postshading). The first technique is fast while the latter gives better results. However, in the case of preclassification and preshading it is strongly recommended to use opacity weighted color interpolation <ref type="bibr" target="#b14">[13,</ref><ref type="bibr" target="#b34">33]</ref>. Our approach is a hybrid method using postclassification but only preshading, in order to not degrade speed. Here the volume gradient is precomputed like many algorithms do <ref type="bibr" target="#b12">[11,</ref><ref type="bibr" target="#b13">12,</ref><ref type="bibr" target="#b20">19]</ref>, and a number indexing a set of quantized space directions is associated with every voxel. Shading is applied on every quantized direction before every rendering and the resulting preshaded reflectance map is used during the rendering to shade the 8 vertexes before the color interpolation at the sampling location.</p><p>Mueller et al. <ref type="bibr" target="#b25">[24]</ref> have shown an example of preshading and postclassification with bad artifacts. We want to point out that no artifact is visible with our application and we think that the given interpretation of this phenomenon is probably erroneous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Optimized Trilinear Reconstruction</head><p>MMX, SSE or 3DNow! SIMD processor extensions have been used to improve memory copying and trilinear interpolation. Color and opacity have been computed on 16 bits unsigned integers. However, code running on MMX only processors does not allow the line equation tests to take place (cf. 3.1) and then minor artifacts can occur on the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Volume Interleaving</head><p>To reduce cache misses, the volume is decomposed in small blocks containing 32 <ref type="bibr" target="#b4">3</ref> samples <ref type="bibr" target="#b12">[11]</ref> where the bits of the coordinates are interleaved as follows:</p><formula xml:id="formula_2">(X n…0 , Y n…0 , Z n…0 ) ⇒ Z n…5 Y n…5 X n…5 Z 4 Y 4 X 4 …Z 0 Y 0 X 0</formula><p>A 32-entry table and binary operators are used to interleave the five lower bits and to generate the new memory address.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RESULTS</head><p>Here, we are looking at the first results of this new algorithm. The entire program except trilinear interpolation and memory copying (SIMD instructions) is written in C++. In contrast with many other DVR methods using small window sizes, here, all rendering are made on 512 2 pixel images not to degrade image quality. The number of quantized space directions used for shading is equal to 8192. Pixel subdivisions ( <ref type="figure" target="#fig_1">fig.2a</ref>) and precomputed rays ( <ref type="figure" target="#fig_1">fig. 2b</ref>) are both fixed to 16 <ref type="bibr" target="#b2">2</ref> , allowing up to 4x zoom without visible noise. The sampling_rate variable determining the distance between two consecutive interpolations is initialized such as ∆s=0.5, which allows between two and four samplings along a ray within a cell. Thus, these settings make high quality possible. Finally, due to the high efficiency of our algorithm when visualizing isosurfaces, the current implementation can also superimpose two rendering passes stemming from different transfer functions.</p><p>Benchmarks have been performed on two platforms allowing 3DNow! instructions: a low-end platform based on an AMD Duron 600 MHz (64/64 KB L1/L2 data cache) with 320 MB (SDRAM 100 MHz) and a more recent AMD Athlon 1.4 GHz (64/256 KB L1/L2 data cache) with 512 MB (DDR SDRAM 266 MHz). Four datasets have been used: the usual head, brain and engine from UNC Chapel Hill plus a highly compact angiography dataset (courtesy of Philips Research Labs). An additional PIII platform has also be used for a comparison with the Ultravis system.</p><p>The main results are summarized in table 1. All the measurements are averaged with 24 renderings. We observe a minimal/maximal divergence of less than 30% about rendering times. Octree processing and volume preshading take approximately 20 seconds, but are computed only once per volume. The fourth column indicates the number of cells (in thousands) within the volume that are neither transparent nor removed by the hidden volume test, even if all the rays going through them can be already opaque. The next column gives the ratio of occluded cells. The sixth column is about the number of octree nodes that are run. The values within parentheses are measured without hidden volume removal, which is disabled to rate its efficiency. The seventh column indicates the number of sampled points along the rays and the last two columns give the rendering times. The results show that interactive high-quality volume rendering is possible on current high-end platforms when visualizing isosurfaces. Better still, rendering remains interactive even with highly complex transfer functions that include a great part of the volume in the rendering process (f). No other algorithm running on a standard workstation is able to produce such a frame rate with this level of detail today. While methods based on 3D texture hardware currently do not exceed 2 fps on 256 3 volumes with a limited accuracy, previously mentioned ray-casting techniques are really slower. Only a Shear-Warp implementation should be able nowadays to deliver a superior frame rate, but once again with an important loss of quality that clearly limits its use. We have compared the efficiency of our algorithm with the Ultravis system <ref type="bibr" target="#b12">[11]</ref>, which is one of the most advanced ray-casting platforms. The same parameters have been used with both methods, but the Ultravis system, which generates 256 2 pixel images only, uses post-shading and can handle perspective renderings. This latter is the main drawback of our algorithm, but it is only required in some specific applications and many professional systems do not implement it <ref type="bibr" target="#b27">[26]</ref>. The results clearly show the superiority of our approach, and like many other ray-casting algorithms, Ultravis performs badly on datasets with much empty space (cf. bonsai and aneurism datasets). Rendering times are only equals for the engine dataset where early ray termination is very important, showing us that HVR is also an efficient alternative to the lack of early ray termination in object-order volume rendering. Last but not least, we have noticed that our algorithm produces a much better image quality, partially due to the low image resolution of Ultravis.</p><p>By studying table 1 in great details, we have come to many interesting conclusions. First, we can clearly see that hidden volume removal eliminates a large fraction of the cells and octree nodes within the opacity range when visualizing isosurfaces. Here, the predominant parts of the rendering are the octree run and the voxel loading, while trilinear interpolation becomes predominant in the case of semi-transparent transfer functions. An important fact is that the efficiency of HVR is very superior to the method proposed by Lee and Ihm <ref type="bibr" target="#b10">[9]</ref> where the ratio of occluded splats for similar renderings (b) and (g) is respectively only 25% and 67%. Actually, this ratio can also be considered as a good HVR speed-up estimation because our algorithm delivers an approximately constant cell throughput (between 1.4 and 2.1 millions cells per second). Thus, hidden volume removal is a very aggressive optimization here, but the recursive run of the octree does not optimize it (as seen previously). A better approach in future works might be a plane-by-plane volume run, allowing a better efficiency in occlusion tests. However, the non-leaf nodes will be run several times. Another observation is that the rendering times seem to scale well with the processor clock frequency, even if the two configurations are quite different (memory clock, L2 cache size).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>A volume rendering application must be carefully designed and should always provide user-friendliness and accuracy. Hardware implemented techniques, although they are fast and sometimes not expensive, have limited on-board memory and are not flexible. On the other hand software algorithms can handle a wide variety of problems but suffer from a lack of performances. Our method offers a new way to perform ray-casting on rectilinear grids, achieving almost real-time volume rendering when visualizing isosurfaces and at least, interactive renderings in general. These achievements are mainly due to the efficient object-order raycasting approach that we have introduced and to its optimizations like hidden volume removal. But in contrast with the rare software techniques able to produce such a frame rate, our algorithm reaches the high-level of details that scientific visualization requires. Indeed, its features such as randomized high sampling rate with trilinear interpolation, large image size (512 2 pixels), and interactive post-classification are facilitating devices.</p><p>We have found two drawbacks to our method. First, it is the use of preshading that slightly degrades the quality and finally, the lack of perspective projection. This latter is needed in stereo viewing applications or in virtual reality for example, but it is not required most of the time for scientific visualization where parallel projection is often preferred. In the future, we should look for a way to implement an efficient post-shading version of this algorithm in order to prevent the frame rate from decreasing too much. We are also planning to improve the rendering engine and to use multi-processor based PCs.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Two-pass volume rendering of a 256 3 bonsai dataset, visualized at approximately 3 frames per second. IEEE Visualization 2002 Oct. 27 -Nov. 1, 2002, Boston, MA, USA 0-7803-7498-3/02/$17.00 © 2002 IEEE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Lists needed for efficient ray-cell intersections and ray sampling. every time the viewpoint changes by sampling the square surrounding the template hexagon (fig. 2b image space)and computing the ray parameters at each sampling location.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Different renderings with ∆s = 1 (b), ∆s = 0.5 (c) and ∆s = 0.5 plus interleaving of the depth indicators (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :Figure 4 :</head><label>54</label><figDesc>Usual rectilinear sampling (a) and shifted sampling (b) Normal Ray-casting Object-order Ray-casting Sampled Points Randomized ray sampling in Object-order ray-casting skip transparent and hidden regions. Some other optimizations are also mentioned.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>(a) Rendering example. The blue line gives the cutting plane. (b) Segmented cross section plus octree traversal. Here the non-leaf nodes crossing the blue area are removed by the occlusion test. (c) HOMs after the rendering (Level 0 [256 2 ] =&gt; Level 5 [8 2 ]). (a) (b) Figure 6: Examples of an occlusion map used during the updating process (a) and the visibility test (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Different renderings used for the benchmarks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Measurements for different renderings.</figDesc><table><row><cell>Volume</cell><cell>Size</cell><cell>Rendering Mode</cell><cell>Cells</cell><cell>Occluded Cells</cell><cell>Octree Nodes</cell><cell>Sampled Points</cell><cell>Tbird 1.4 GHz</cell><cell>Duron 600 MHz</cell></row><row><cell>UNC Head (a)</cell><cell>256x 256x225</cell><cell>Single</cell><cell cols="3">343K (4093K)* 91.70% 907K (4711K)*</cell><cell>645K</cell><cell>6.2 f ps</cell><cell>2.6 f ps</cell></row><row><cell>UNC Head (b)</cell><cell>256x 256x225</cell><cell>Single</cell><cell cols="3">268K (1255K)* 79.70% 694K (1475K)*</cell><cell>453K</cell><cell>7.7 f ps</cell><cell>3.4 f ps</cell></row><row><cell>UNC Head (c )</cell><cell>256x 256x225</cell><cell>Double</cell><cell>617K (5120K)*</cell><cell>88%</cell><cell>1570K (6300K)*</cell><cell>1077K</cell><cell>3.1 f ps</cell><cell>1.4 f ps</cell></row><row><cell cols="2">UNC Engine (d) 256x 256x110</cell><cell>Single</cell><cell cols="3">236K (1453K)* 83.80% 621K (1686K)*</cell><cell>356K</cell><cell>9.1f ps</cell><cell>4.5 f ps</cell></row><row><cell cols="2">UNC Engine (e) 256x 256x110</cell><cell>Double</cell><cell cols="3">371K (1175K)* 68.50% 759K (1570K)*</cell><cell>564K</cell><cell>5.6 f ps</cell><cell>2.7 f ps</cell></row><row><cell cols="2">UNC Engine (f ) 256x 256x110</cell><cell>Single</cell><cell>1544K (2150)*</cell><cell cols="2">28,2% 1822K (2750K)*</cell><cell>6747K</cell><cell>1.4 f ps</cell><cell>0.55 f ps</cell></row><row><cell>UNC Brain (g)</cell><cell>256x 256x167</cell><cell>Single</cell><cell cols="3">226K (2434K)* 90.80% 593K (2808K)*</cell><cell>654K</cell><cell>7.7 f ps</cell><cell>3.2 f ps</cell></row><row><cell>A neurism (h)</cell><cell>256x256x256</cell><cell>Single</cell><cell>71K (104K)*</cell><cell cols="2">31.80% 113K (190K)*</cell><cell>223K</cell><cell>20 f ps</cell><cell>10 f ps</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">* Without Hidden V olume Removal</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparisons with the Ultravis system (PIII 600MHz, 512 MB)</figDesc><table><row><cell>Volum e</cell><cell>Ultravis</cell><cell>OO RC</cell></row><row><cell>UNC Head (a)</cell><cell>0.8 f ps</cell><cell>2.4 f ps</cell></row><row><cell>UNC Engine (d)</cell><cell>3.5 f ps</cell><cell>3.5 f ps</cell></row><row><cell>UNC Brain (g)</cell><cell>1.0 f ps</cell><cell>3.2 f ps</cell></row><row><cell>A neurism (h)</cell><cell>0.45 f ps</cell><cell>6.75 f ps</cell></row><row><cell>Bonsai (f ig. 1)</cell><cell>0.5 f ps</cell><cell>2.1 f ps</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Accelerated volume rendering and tomographic reconstruction using texture mapping hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foran</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Siggraph symposium on</title>
		<imprint>
			<biblScope unit="page" from="91" to="97" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Highquality volume rendering using texture mapping hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dachille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kreeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bitter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m">Siggraph/Eurographics workshop on graphic hardware</title>
		<imprint>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">High Quality pre-integrated volume rendering using hardware-accelerated pixel shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc Eurographics/Siggraph workshop on graphic hardware</title>
		<meeting>Eurographics/Siggraph workshop on graphic hardware</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Direct volume rendering via 3D texture mapping hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Volume Rendering Symposium</title>
		<meeting>Volume Rendering Symposium</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Wavelength dependant reflectance functions. Siggraph&apos;94 proc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
		<title level="m">Hierarchical Z-Buffer Visibility. SIGGRAPH&apos;93 Proc</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="231" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Greene</surname></persName>
		</author>
		<title level="m">Hierarchical polygon tiling with coverage masks. SIGGRAPH&apos;96 Proc</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast splats: optimized splatting on rectilinear grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shareef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization&apos;00 proceedings</title>
		<imprint>
			<date type="published" when="2000-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On enhancing the speed of splatting using both object-and-image space coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ihm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graphical models and image processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="263" to="282" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ray tracing volume densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kajiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Von Herzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH&apos;</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="165" to="174" />
			<date type="published" when="1984-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Ultravis System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Knittel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM SIGGRAPH</title>
		<imprint>
			<biblScope unit="page" from="71" to="78" />
			<date type="published" when="2000-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast volume rendering using a shearwarp factorization of the viewing transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH&apos;94</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comp. Graph. &amp; App</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient raytracing of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="261" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An evaluation of reconstruction filters for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Marschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Lobb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of visualization&apos;94</title>
		<meeting>visualization&apos;94</meeting>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="100" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optical model for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="108" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Enabling classification and shading for 3D texture mapping based volume rendering using OpenGl and extensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meißner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Straßer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization&apos;99</title>
		<meeting>Visualization&apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="207" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A practical comparison of popular volume rendering algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meißner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-10" />
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Accelerating volume rendering with quantized voxels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Jessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caubet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM SIGGRAPH</title>
		<imprint>
			<biblScope unit="page" from="63" to="70" />
			<date type="published" when="2000-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Jessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caubet</surname></persName>
		</author>
		<title level="m">Visualization of isosurfaces with parametric cubes. Eurographics&apos;01 Proc</title>
		<imprint>
			<date type="published" when="2001-09" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluation and Design of Filters Using a Taylor Series Expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="184" to="199" />
			<date type="published" when="1997-06" />
		</imprint>
	</monogr>
	<note>ITVCG</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Interactive high quality maximum intensity projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Groller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics&apos;00</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Eliminating popping artifacts in sheet buffer-based splatting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization&apos;98</title>
		<meeting>Visualization&apos;98</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="239" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Splatting without the blur</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization&apos;99</title>
		<meeting>Visualization&apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="363" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Highquality splatting on rectilinear grids with efficient culling of occluded voxels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shareef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crawfis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Splatting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="116" to="134" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The volumepro real-time ray-casting system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hardenbergh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH&apos;99</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optimal Regular Volume Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Theußl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2001-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">High performance presenceaccelerated ray casting. proc. Visualization&apos;99</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bryson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="363" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<title level="m">Efficiently using graphics hardware in volume rendering applications. SIGGRAPH&apos;98</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="169" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Accelerated volume ray-casting using texture mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sevenich</surname></persName>
		</author>
		<idno>proc. 2001</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Interactive volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Chapel Hill Workshop on volume visualization</title>
		<meeting>the Chapel Hill Workshop on volume visualization</meeting>
		<imprint>
			<date type="published" when="1989-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Footprint evaluation for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH&apos;90 Proc</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="367" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Opacity-weighted color interpolation for volume sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wittenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Symposium on</title>
		<imprint>
			<biblScope unit="volume">Visualization</biblScope>
			<biblScope unit="page" from="135" to="142" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Template-based volume viewing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics&apos;92</title>
		<meeting>Eurographics&apos;92</meeting>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="153" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Hoff</surname></persName>
		</author>
		<title level="m">Visibility culling using hierarchical occlusion Maps. SIGGRAPH&apos;98 Proc</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="77" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A coherent projection approach for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH&apos;91 Proc</title>
		<imprint>
			<biblScope unit="page" from="275" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A Hardware Acceleration Method for Volume Ray Tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierarjski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Avila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>IEEE Visualization</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
