<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BLIC : Bi-Level Isosurface Compression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Taubin</surname></persName>
							<email>taubin@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="department">IBM T.J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 704</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ibm</forename><forename type="middle">T J</forename><surname>Watson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">IBM T.J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 704</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Research</forename><surname>Center</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">IBM T.J. Watson Research Center</orgName>
								<address>
									<postBox>P.O. Box 704</postBox>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BLIC : Bi-Level Isosurface Compression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Compressed Cuberille isosurfaces as rendered by our simple Java decoder. A: spine set</term>
					<term>91×512×512 voxels</term>
					<term>level 1500</term>
					<term>381</term>
					<term>278 faces</term>
					<term>381</term>
					<term>667 vertices</term>
					<term>compressed to 0.6182 bits per face. B: UNC CThead data set</term>
					<term>113×256×256 voxels</term>
					<term>level 600</term>
					<term>294</term>
					<term>524 faces</term>
					<term>294</term>
					<term>018 vertices</term>
					<term>compressed to 0.7437 bits per face. C: UNC CThead data set</term>
					<term>level 1160</term>
					<term>312</term>
					<term>488 faces</term>
					<term>312</term>
					<term>287 vertices</term>
					<term>compressed to 0.8081 bits per face CR Categories: I.3.5 [Computer Graphics]: Computational Geometry and Object Modelling-surface</term>
					<term>solid</term>
					<term>and object representations 3D Geometry Compression</term>
					<term>Algorithms</term>
					<term>Graphics</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In this paper we introduce a new and simple algorithm to compress isosurface data. This is the data extracted by isosurface algorithms from scalar functions defined on volume grids, and used to generate polygon meshes or alternative representations. In this algorithm the mesh connectivity and a substantial proportion of the geometric information are encoded to a fraction of a bit per Marching Cubes vertex with a context based arithmetic coder closely related to the JBIG binary image compression standard. The remaining optional geometric information that specifies the location of each Marching Cubes vertex more precisely along its supporting intersecting grid edge, is efficiently encoded in scan-order with the same mechanism. Vertex normals can optionally be computed as normalized gradient vectors by the encoder and included in the bitstream after quantization and entropy encoding, or computed by the decoder in a postprocessing smoothing step. These choices are determined by trade-offs associated with an in-core vs. out-of-core decoder structure. The main features of our algorithm are its extreme simplicity and high compression rates</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Isosurface extraction algorithms construct polygon mesh approximations to level sets of scalar functions specified at the vertices of a 3D regular grid. The most popular isosurface algorithms <ref type="bibr" target="#b8">[9]</ref> are Cuberille <ref type="bibr" target="#b0">[1]</ref> and Marching Cubes <ref type="bibr" target="#b13">[14]</ref>. In this paper we refer to the polygon meshes produced by these and related algorithms as isosurface meshes. Despite the widespread use of these meshes in scientific visualization and medical applications, and their very large size, special purpose algorithms to compress them for efficient storage and fast download have not been proposed until very recently <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37]</ref>. We compare our new algorithm with these recent approaches in section 8, after the relevant concepts are introduced.</p><p>Polygon Mesh Coding A number of general purpose polygon mesh compression algorithms have been proposed in recent years. Deering <ref type="bibr" target="#b2">[3]</ref> developed a mesh compression scheme for hardware acceleration. Taubin and Rossignac <ref type="bibr" target="#b29">[30]</ref>, Touma and Gotsman <ref type="bibr" target="#b30">[31]</ref>, Rossignac <ref type="bibr" target="#b20">[21]</ref>, Gumhold and Strasser <ref type="bibr" target="#b4">[5]</ref>, and others, introduced methods to encode the connectivity of triangle meshes with no loss of information. King et. al. <ref type="bibr" target="#b11">[12]</ref> developed a method to compress quadrilateral meshes. Methods to encode the connectivity of polygon meshes were introduced by Isenburg and Snoeyink <ref type="bibr" target="#b5">[6]</ref>, Konrod and Gotsman <ref type="bibr" target="#b12">[13]</ref>, and Khodakovsky et.al. <ref type="bibr" target="#b9">[10]</ref>. These algorithms focus on compressing the connectivity information very efficiently, and are all based on a traversal of the primal or dual graph of the mesh. Some of them compress connectivity of very regular meshes to a small fraction of a bit per vertex, and all to 2-4 bits per vertex in the worst case. When the geometry information (vertex coordinates, and optionally normals, colors, and texture coordinates) is also taken into account, the cost per vertex increases considerably. For example, adding only vertex coordinates quantized to 10 bits per vertex lifts the cost to typically 8-16 bits per vertex. In addition, all of these approaches are incompatible with the out-of-core nature of isosurface extraction algorithms that visit the voxels in scan order.</p><p>Resampling and Subdivision Khodakovsky et.al. <ref type="bibr" target="#b10">[11]</ref> follow a different approach to compress large connected and uniformly sampled meshes of low topological complexity, based on resampling, subdivision and wavelets. They obtain up to one order of magnitude better compression rates than with the connectivity preserving schemes, by approximating the mesh geometry with a subdivision mesh, and compressing this mesh instead. Wood et.al. <ref type="bibr" target="#b34">[35]</ref> introduced a method based on surface wave propagation to extract isosurfaces from distance volumes that produces semi-regular multi-resolution meshes. These meshes can be compressed with Khodakovsky's wavelet-based scheme.</p><p>Compressed Isosurfaces Isosurface algorithms take as input very large volume data files, and produce polygon meshes with very large number of vertices and faces. For remote visualization, we can transmit either the volume data and run the isosurface algorithm in the client, or compute the isosurface in the server and transmit the resulting polygon mesh. In both cases the transmission time constitutes a major bottleneck because of the file sizes involved, even using general purpose mesh compression schemes in the second case. And this is true without even considering the computational resources of the client.</p><p>We follow a third approach based on an observation made by Saupe and Kuska <ref type="bibr" target="#b23">[24]</ref>. The only information from the volume data the isosurface algorithm uses to construct the polygon mesh is: which grid edges cross the desired level set, and where these intersection points are located within the edges. As a result the isosurface algorithm can be decomposed into two processes: the server or encoder process, which scans the volume data, determines intersecting edges, and computes locations of intersection points; and the client or decoder process, which reconstructs the polygon mesh from the data transmitted by the server process. Our contribution is a very simple scheme to efficiently encode these data. In addition, we consider the tradeoffs associated with optionally computing normal vectors (used mainly for shading) in the server or the client.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ISOSURFACE ALGORITHMS</head><p>An isosurface algorithm constructs a polygon mesh approximation of a level set of a scalar function defined in a finite 3D volume. The function f (p) is usually specified by its values fα = f (pα) on a regular grid of three dimensional points</p><formula xml:id="formula_0">G = {pα : α = (α0, α1, α2) ∈ [[n0]]×[[n1]]×[[n2]]} , where [[nj]] = {0, .</formula><p>. . , nj − 1}, and by a method to interpolate in between these values. The surface is usually represented as a polygon mesh, and is specified by its isovalue f0. Furthermore, the interpolation scheme is assumed to be linear along the edges of the grid, so that the isosurface cuts each edge in no more than one point. If pα and p β are grid points connected by an edge, and fα &gt; f0 &gt; f β , the location of the point p αβ where the isosurface intersects the edge is</p><formula xml:id="formula_1">p αβ = fα − f0 fα − f β p β + f β − f0 f β − fα pα .<label>(1)</label></formula><p>Marching Cubes One of the most popular isosurface extraction algorithm is Marching Cubes <ref type="bibr" target="#b13">[14]</ref>. In this algorithm the points defined by the intersection of the isosurface with the edges of the grid are the vertices of the polygon mesh. These vertices are connected forming polygon faces according to the following procedure. Each set of eight neighboring grid points define a small cube called a cell</p><formula xml:id="formula_2">C α = {p α+β : β ∈ {0, 1} 3 }.</formula><p>Since the function value associated with each of the eight corners of a cell may be either above or below the isovalue (isovalues equal to grid function values are called singular and should be avoided), there are 2 8 = 256 possible configurations. A polygonization of the vertices within each cell for each one of these configurations is stored in a static look-up table. When symmetries are taken into account, the size of the table can be reduced quite significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topological Inconsistencies</head><p>Since some of the cases admit multiple polygonizations, care should be taken during the construction of the table to avoid the generation of polygon meshes with topological inconsistencies <ref type="bibr" target="#b31">[32]</ref>. One such approach is based on estimating the value at the cell center using tri-linear interpolation within each cell. In the continuum, the surface defined by a level set of a smooth function without singularities is an orientable manifold without boundary which separates space into two disconnected sets, the inside where the function is negative, and the outside where the function is positive (or vice-versa). For most applications it is desirable that the isosurface algorithm generates a mesh with the same characteristics. This property is guaranteed when the mesh is the boundary of a regular solid (without self intersections).</p><p>Cuberille <ref type="bibr">Kalvin [8]</ref> proposed one way to resolve this inconsistency problem by observing that the polygon mesh generated by Marching Cubes is the dual mesh of the quadrilateral mesh generated by the Cuberille algorithm <ref type="bibr" target="#b0">[1]</ref>. Each vertex of the grid where the scalar function is specified (the primal grid) is the centroid of a dual grid cell, or voxel. Every edge of the primal grid intersects the common face of the two voxels corresponding to the ends of the edge. The mesh generated by the Cuberille algorithm is the regularized (converted to manifold) boundary surface of the solid defined by the set of voxels corresponding to grid vertices with scalar value above the isovalue. Without regularization, in general this mesh is highly singular (non-manifold). The conversion to manifold requires duplication of vertices and edges, so that in the resulting mesh every edge has exactly two incident faces. Which vertices to duplicate and how to connect the faces can be determined by virtually shrinking the solid, moving the faces in the direction of the inside. The multiplicity of each dual grid vertex in the regularized mesh only depends on the local connectivity of the eight incident voxels. Again, the regularization can be done by table look-up while the volume data is being scanned, with a table of size 2 8 = 256.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple Reconstruction Schemes</head><p>What is important is to note that the Cuberille algorithm can construct the isosurface mesh from the same information as the Marching Cubes algorithm. The edge intersections in the primal mesh specify the location of the face centroids of the Cuberille mesh. The location of the cuberille vertices can then be computed by local averaging, or by using more accurate schemes <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27]</ref>. In addition, the client can apply a number of subsequent smoothing algorithms to improve the mesh appearance <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28]</ref>. The situation is similar for normals. If computed in the server as the gradient of the scalar function at the edge intersection points <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b18">19]</ref>, and included in the compressed data, the Marching Cubes decoder will treat them as vertex normals, and the Cuberille decoder as face normals. If the normals are not included in the compressed data, then it is up to the client to decide how to estimate them from the vertex coordinates and the connectivity information.  The implication of these observations is that there is considerable freedom in the implementation of the decoder, making absolutely no changes to the encoder or the compressed bitstream. It is not even necessary for the decoder to produce a polygon mesh as output. For visualization purposes, and in particular if normals are included in the compressed data, a point-based approach <ref type="bibr" target="#b21">[22]</ref> could be very effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ENCODER</head><p>The encoder algorithm scans the volume data, determines which grid edges intersect the isosurface, computes the location of the intersection points along the corresponding edges, optionally generates normal vectors for these points as scalar function gradient estimates, and entropy encodes all of this data after quantization. In this section we describe what data is encoded, and the order of the encoded data elements in the bitstream. <ref type="figure" target="#fig_1">Figure 2</ref> is a high level pseudo-code description of the encoder algorithm. In the next section we describe the methods we use to entropy encode these data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Occupancy Image</head><p>Since whether an edge intersects the isosurface or not depends on the values of the scalar function at the edge ends, we encode the occupancy image. This is a 3D binary image defined by one bit per grid vertex bα = 1 if fα &lt; f0 0 otherwise specifying whether the scalar function attains a value above or below the isovalue on that vertex. We also define bα = 0 if αj &lt; 0 or αj ≥ nj for some j ∈ {0, 1, 2}. This ensures that the isosurface generated is closed (water-tight). We encode these bits in scan order. Since there are more edges than vertices, encoding one bit per edge would be wasteful, and may lead to inconsistencies.</p><p>Intersection Points The location of the intersection points and the optional normals are associated with the intersecting edges, which can be determined from the occupancy image. Except for boundary vertices, each grid vertex has six incident edges {pα, p α+β } : β = ± δj , with δ 0 = (100), δ1 = (010), and δ2 = (001). To simplify the description, we add the missing edges as virtual edges to the boundary vertices, but we do not include them in the compressed data. Of these six incident edges, three connect the vertex with preceding vertices, and the other three with subsequent vertices in the scan order. Regarding the edges as oriented according to the vertex scan order, each edge has a beginning and end vertex. We order the edges, first by the scan order of the end vertex, and then by the direction of the displacement (0,1,2)</p><formula xml:id="formula_3">eα,j = {pα, p α−δ j } : j = 0, 1, 2 .</formula><p>The position of the intersection point pα,j along the edge eα,j is determined by equation 1. This data has to be encoded in the compressed data only if the occupancy image has different values at the ends of the edge, i.e., if b α−δ j = bα. We specify the location of the intersection point along the edge with a number between zero and one 0 ≤ tα,j ≤ 1 such that</p><formula xml:id="formula_4">pα,j = (1 − tα,j) p α−δ j + tα,j pα .</formula><p>Normal Vectors Since the gradient vector of a function is normal to its level sets, normals used for shading can optionally be computed during the volume traversal as finite difference approximations to the gradient vectors normalized to unit length <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Order of Transmission</head><p>The encoder and decoder must have a hard-coded convention for the order of transmission of all these data. Since the occupancy image is encoded in scan order, after decoding each bit the decoder has all the information necessary to determine which of the three edges ending at the corresponding vertex are intersecting or not. We encode the optional data (positions and normals) corresponding to these edges in edge order, right after the occupancy bit corresponding to the end vertex. With this data organization, in case of loss of data due to interrupted transmission, a partial reconstruction using all the transmitted data can be obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ENTROPY ENCODING</head><p>Entropy encoding is the problem of how to represent with a minimum number of bits a sequence of independent symbols X = (x1, . . . , xN ) that belong to a finite alphabet Σ = {σ1, . . . , σn} <ref type="bibr" target="#b22">[23]</ref>. Symbols that appear more often in the sequence should be represented with fewer bits than those that appear more infrequently. The absolute lower bound for the total number of bits necessary to represent the sequence X with no loss of information is given by the entropy <ref type="bibr" target="#b22">[23]</ref>. In practice the arithmetic coder <ref type="bibr" target="#b33">[34]</ref> asymptotically achieves the entropy. Arithmetic coding is used as the basis of many image and data compression schemes and applications <ref type="bibr" target="#b14">[15]</ref>, very good public domain software implementations <ref type="bibr" target="#b32">[33]</ref>, and even hardware implementations <ref type="bibr" target="#b24">[25]</ref> are available.</p><p>To deal with the lack of stationary distribution of symbols in the sequence, adaptive models are used. In arithmetic coding with an adaptive model the encoder updates the alphabet probabilities after encoding each symbol. Since encoder and decoder must use the same model to encode and decode each symbol, the model update procedure must be based on data previously encoded, and agreed upon information. Among these data are the initial probabilities, which may be hard-coded or included in the compressed data. A common practice is to start with uniform probabilities and keep track of the relative symbol frequencies as probability estimates.</p><p>For binary data, where the alphabet is composed of two symbols Σ = {0, 1}, keeping track of global symbol frequencies is usually not good enough as a model update procedure, and a context-based procedure is used. This is a state machine model with separate sets  of probability estimates associated with each state or context. The update procedure determines the context from previously encoded data (such as values of previously encoded neighboring pixels in an image), and after the symbol is encoded with the probabilities associated with a context, the set of probabilities corresponding to that context is updated, but not the other. Context-based arithmetic coding is a very efficient adaptive compression scheme. It is used in the JBIG lossless image compression standard, and is the main reason for the high efficiency of our isosurface compression scheme.</p><p>JBIG JBIG is short for Joint Bi-level Image experts Group. This is both the name of a standards committee, and of a particular scheme for the lossless compression of binary images <ref type="bibr" target="#b6">[7]</ref>. It can also be used for coding gray scale and color images with limited numbers of bits per pixel. JBIG is one of the best available schemes for lossless image compression.</p><p>The JBIG algorithm is based on context based arithmetic coding. For each pixel in an image a context is derived from a specific fixed pattern of surrounding pixels preceding the current pixel in the scan order. The standard defines several such neighborhoods. The 10 pixels included in two of these neighborhoods are illustrated in figure 3. These binary pixels values are used to construct a 10-bit context number, used to index into a list of context probability estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoding the Occupancy Image</head><p>We can look at the occupancy image as a stack of binary images, one for each value of α0 = 0, . . . , n0 −1. One possibility is to use JBIG to encode these binary images independently of each other. The results are good, but the high correlation normally existing among spatially close voxels in neighboring layers is not taken into account. Instead, we use values from neighboring voxels not only in the current layer, but also in the previous layer, to build the context used to encode each voxel value. This simple idea allows us to increase the encoding efficiency quite significantly. In average we reduce the size of the compressed data by 50% compared to compressing the layers individually. There is a trade-off to be made in deciding how to build the context from neighboring voxels. Using more voxels increases the number of contexts, and so, the amount of memory needed to maintain the probability estimates, but can potentially lead to more efficient encoding. We have found that the simplest possible neighborhood performs very well. Of all the voxels that share a vertex, edge, or face with a given voxel, we use seven that precede it in the scan order to build a seven bit context cα by concatenating the bits of these voxels in scan order. We use this context to encode the voxel bit bα. The configuration is illustrated in <ref type="figure" target="#fig_3">figure 4</ref>. If we denote c α|j the j-th bit of cα from least to most significant, we have</p><formula xml:id="formula_5">             c α|0 = b α−(001) c α|1 = b α−(010) c α|2 = b α−(011) c α|3 = b α−(100) c α|4 = b α−(101) c α|5 = b α−(110) c α|6 = b α−(111)</formula><p>Encoding the Intersection Points The second piece of information that needs to be encoded is the position of each intersection point pα,j, i.e., the number 0 ≤ tα,j ≤ 1. This number is uniformly quantized to B bits, and the quantized value, which corresponds to an integer number between 0 and 2 B − 1, is entropy encoded with no further loss. The decoder reconstructs the quantized valuetα,j as the centroid of the segment defined by the corresponding integer. For example, if B = 0, which is sufficient in many cases, the reconstructed value istα,j = 0.5 independent of α and δj. In this case, no intersection point data is actually included in the compressed data, and all the geometry information is derived from the occupancy image. If B = 1, i.e., one bit is encoded per intersection point, there are two possible reconstructed values: 0.25 and 0.75. In general, if the B-bits integer to be encoded is h, the reconstructed value ist</p><formula xml:id="formula_6">α,j = h + 0.5 2 B .</formula><p>We look at each bitplane of these encoded integers as a new 3D binary image of the same dimensions as the occupancy image. By encoder-decoder convention we set the values corresponding to non-intersecting edges to zero, and we encode these 3B threedimensional binary images (one each for j = 0, 1, 2 and each bitplane) with the same context-based method as we encode the occupancy image, except that we maintain separate context probabilities for each bitplane and each axis. The only difference is that none of the zero values agreed upon by the encoder and decoder are included in the bitstream. The encoder just skips them, and the decoder can set the corresponding bits to zero because it can determine which are these bits from the occupancy image bits. Both the encoder and the decoder have to reconstruct these bits, though, because they are needed to build the contexts used to encode and decode the corresponding bits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoding Normal Vectors</head><p>The last piece of information to be encoded is the normal vectors at the intersection points. These vectors were optionally computed during the volume traversal as finite difference approximations to the gradient vectors, and normalized to unit length.</p><p>In the MPEG-4 standard <ref type="bibr" target="#b16">[17]</ref> polygon mesh normals are quantized to 3 + 2S bits as follows. The first 3 bits determine the octant the normal vector belongs to. Each of these octants corresponds to a triangular face of a regular octahedron with vertices on the coordinate axes. Each of these triangular faces is recursively quadrisected (Loop subdivided) S times. The centroids of the 2 2S resulting triangles define vectors, which after normalization to unit length, define the quantized values. The angle distribution of quantized normals is not uniform here, but the lack of uniformity is not severe. On the positive side, the scheme does not require evaluation of transcendental functions. We quantize the normals with a variation of this method to B = 2S bits. As in the case of intersection points, if B = 0 nothing is encoded, and the quantized normals are defined by the edges containing the intersection points. Otherwise, the first two bits determine the octant, and the remaining bits the level of triangle subdivision. We only need two bits to determine the octant because each normal cannot deviate by more than 90 • from the quantized value corresponding to zero bits. Alternatively, the quantization scheme proposed by <ref type="bibr">Deering [3]</ref> can be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DECODER</head><p>The decoder algorithm can be decomposed into two parts. The first part is a loop similar in structure to the encoder algorithm shown in figure 2. In this loop the occupancy image is decoded in scan order, and the optional values of intersection points and normals are reconstructed, if present in the compressed data. The second part of the algorithm, which is performed simultaneously within the loop, is the reconstruction of the data structure used for subsequent processing. This could be the polygon mesh produced by Marching Cubes, the quadrilateral mesh produced by Cuberille, or just a set of oriented points organized in a hierarchical data structure used by Qsplat <ref type="bibr" target="#b21">[22]</ref>. As we mentioned before, we have considerable freedom in the implementation of this second part. Our current implementation is based on the Cuberille method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IN-CORE vs. OUT-OF-CORE</head><p>The main decision in the design of the decoder is determined by whether the reconstructed mesh can be kept in memory (in-core) or not (out-of-core). The highest compression rates are obtained with an in-core implementation, where intersection points and normal vectors are quantized to zero bits. In this case the encoder is simplified because the computation of intersection points and estimation of normal vectors is avoided. Instead, to improve the appearance of the reconstructed cuberille mesh, smoothing schemes are used to displace the ver- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">IMPLEMENTATION</head><p>We have implemented one encoder in C++, and two decoders; one in C++, and the other in Java. The C++ encoder and decoder are command line applications. For the arithmetic coder, we used the public domain software implementation by Wheeler <ref type="bibr" target="#b32">[33]</ref>, with minor modifications. The encoder reads a header file and a binary data file, and produces a compressed data file. The compressed data file includes information such as number of samples along each axis, as well as a linear transformation to scale, rotate, and translate the reconstructed mesh to user coordinates. This is important for example when processing medical data (CT and MRI) in which the sampling rate along one axis is different from the others. The C++ decoder reads the compressed data, constructs a Cuberille mesh incore, optionally applies smoothing operators to vertex coordinates and normals, and saves the result as a VRML file. The Java decoder implements the same algorithms, but instead of saving the result as a file, it is integrated with a simple 3D rendering engine which allows the user to navigate around the reconstructed mesh and change the orientation of the light source. All the isosurfaces shown in the paper have been generated with this decoder. More advanced rendering techniques produce much better images. <ref type="figure" target="#fig_4">Figure  5</ref> shows screen-dumps of the application. In addition, we implemented a simple Java user interface to visualize volume data, and to choose appropriate thresholds. <ref type="figure" target="#fig_5">Figure 6</ref> shows a screen dump of this application, which also works as a front-end for the command line encoder.</p><p>In our current in-core decoder implementation, the encoding of intersection points is supported, but normal vectors are estimated by smoothing the normals to the faces of the cuberille. We look at these normals as a vector field defined on the dual graph of the Cuberille mesh. We iteratively transfer normals from the dual to the primal graph, and then back from the primal to the dual. We compute a primal vector field (defined on the graph of the Cuberille mesh) from the dual vector field as follows. faces, and then we normalize the value to unit length. This simple procedure produces satisfactory results. More complex procedures can be used as well <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28]</ref>. For medical applications, where guarantees of conservation of geometric or differential properties are often required, the smoothing process can be constrained so that each mesh vertex stays within a voxel center at the initial Cuberille vertex position. However, in our current implementation these constraints are not taken into account. The reconstructed intersection points are the locations of the vertices of the Marching Cubes mesh (without triangulation of faces). Since the connectivity of the Cuberille mesh that our algorithm constructs is dual of Marching Cubes, we determine the location of its vertices as the centroids of the Marching Cubes faces. That is, in our implementation each Cuberille vertex position is computed as the average of the face centroids of incident faces. As a more complex alternative we can determine the location of the vertices by dual mesh resampling <ref type="bibr" target="#b26">[27]</ref>. It is important to implement an algorithm that produces meshes without topological inconsistencies to prevent artifacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RESULTS</head><p>In this section we present some preliminary results. We have experimented extracting and compressing isosurfaces corresponding to different isolevels on the same volume data set, on different volume data sets, and on volume data sets generated by down-sampling. <ref type="figure" target="#fig_6">Figure 7</ref> shows renderings of some Cuberille isosurface meshes produced by our Java decoder. The tables in figures 8 and 9 show numerical results for some of these data sets.</p><p>For the data sets we used in our experiments, a quantization level  B of zero bits, coupled with smoothing of vertex positions and normals as a decoder postprocessing step, produced excellent results, with a typical bitrate of less than one bit per face. The bitrate increases somehow when the data is noisy, and the ratio of isosurface faces to voxels increases. Roughly speaking, if the intersection points are uniformly quantized to B bits, we observe compression bitrates of about 0.60 − 0.95 bits per face for B = 0, 1.20 − 1.80 bits per face for B = 1, and 2.10−2.90 bits per face for B = 3. An these results seem to be fairly independent of the grid dimensions. Remember that this is without including normals in the compressed data, which are computed by smoothing. Note that the best compression bitrates are obtained for B = 0, which corresponds to the very efficient encoding of the occupancy image, and every increase of one bit in the quantization parameter B results in roughly one bit increase in the compression bitrate. In our experience, this high entropy in the quantized intersection points is due to the lack of predictors. For example, in <ref type="bibr" target="#b28">[29]</ref> a smoothing operator is used as a predictor to efficiently encode vertex displacements from a coarse mesh to a refined mesh. We could do the same here to predict each bitplane of the quantized intersection points, and then encode the correction bits which hopefully will have lower entropy. We intend to explore this issue in the near future. <ref type="figure">Figure 10</ref> shows the same isosurface at different quantization levels, and the table in <ref type="figure">figure 11</ref> shows the sizes and compression rates for these meshes. The last column of this table shows our distortion measurements. We compare the position of the vertices of a reference and a distorted mesh, both with the same connectivity. As the reference mesh we take what we would obtain without quantization. The distorted mesh corresponds to finite values of B. In both cases we apply the same smoothing step before making the measurements. As distortion measure we consider the ratio of average vertex displacement divided by average edge length in : Compression results as a function of quantization parameter B, corresponding to the volume data set CThead meshes isolevel 600 (CThead-600-0, CThead-600-2, and CThead-600-4 shown in <ref type="figure">figure 10)</ref>, and isolevel 1160. The mesh of level 600 has 294524 faces, and the mesh of level 1160 has 312488 faces. The last two columns can be used to plot rate-distortion curves.</p><formula xml:id="formula_7">B = 0 B = 2 B = 4</formula><p>the reference mesh. This is not the most common way of measuring distortion. The Metro tool <ref type="bibr" target="#b1">[2]</ref>, which measures the Haussdorf distance between two meshes, has become a de-facto standard, but incompatible file formats and time constraints have prevented us from reporting results based on this tool. We plan to perform more exhaustive rate-distortion testing in the near future. The polygon-mesh coder introduced by Khodakovsky et.al. <ref type="bibr" target="#b9">[10]</ref> is considered as one of the best general polygon mesh connectivity coders. For comparison purposes, we show in figure 12 the results obtained compressing the connectivity information of the meshes of figures 8, 9, and 11 with this coder. Note that no geometry information is included in the bitrates because the current implementation does not compress the geometry data. With our in-core implementation we could not reconstruct the full resolution visible man isosurface due to lack of memory.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">RELATED WORK</head><p>Despite their widespread use, only during the last year researchers started to address the problem of compressing isosurfaces. Saupe and Kuska <ref type="bibr" target="#b23">[24]</ref> presented an algorithm to compress isosurfaces closely related to ours. They extract and encode the occupancy image and intersection points. Normals are computed from the reconstructed Marching Cubes polygon mesh. The occupancy image is encoded with an octree-based scheme to deal more efficiently with large homogeneous regions of empty space. The intersection points are encoded with a multi-symbol context-based arithmetic coder. They compare the compression rates of their method with a number of existing schemes. They report results on isosurfaces corresponding to five different isovalues, extracted from a CT scan with a grid of size 250×192×168, and used B = 4 to quantize intersection point to obtain a global vertex quantization of 12 bits per coordinate. They do this to be able to compare with irregular mesh compression schemes. They report compression rates between 11.56 and 11.77 bits per polygon. We do not have access to the same data, and in our experience B = 0 is almost always good enough for this kind of data, if a postprocessing smoothing step is added in the decoder. Look at the example shown in <ref type="figure">figure  10</ref>. But for B = 4 and similar medical data, such as figure1 B and C, we obtain compression rates of 4.42 and 4.64. This is about 2.5 times better. But again, with B = 2, B = 1, and sometimes even B = 0, plus smoothing of vertices and normals, the results are almost indistinguishable. They also report results corresponding to four isosurface extracted from smooth analytic functions evaluated on grid vertices. The grid size is 192×192×192. The compression rates here range from 9.68 to 10.69 bits per polygon. Still more than twice what our simpler scheme produces.</p><p>Zhang et.al. <ref type="bibr" target="#b37">[38]</ref> have a short discussion about isosurface compression with the larger context of massively parallel isosurface rendering. They propose a scheme similar in nature to ours, where the occupancy image and intersection points are encoded, but very superficial details are provided given the limited space. They propose to entropy encode the occupancy image using run-length encoding or arithmetic coding, but they do not seem to take advantage of correlation between consecutive layers. They report total byte size of compressed files for five different data sets, but it is difficult to compare due to lack of details about the meshe sizes.</p><p>Mroz and Hauser <ref type="bibr" target="#b17">[18]</ref> encode the occupancy image using a more complex scheme based on chain coding, where the voxels that contain isosurface intersections are linked in long chains and represented as a sequence of symbols, each one specifying in which direction to go to visit the next cell. This is potentially more efficient, because the number of symbols to be encoded is proportional to the number of vertices or faces of the reconstructed mesh, as opposed to the number of voxels in our case. This representation also rules out an out-of core implementation, because typically chains traverse the volume in random fashion. On the positive side, this data can be rendered directly from the compressed data, i.e., decoded on-the-fly. This representation is ideal for a decoder based on oriented particles or volume rendering, in which case one additional normal per cell must be encoded in a separate channel. This method is also significantly less efficient than ours, even if normals are not included in the compressed data. They report typical rates between 2.0 and 2.5 bits per chained voxel. Since they do not include additional information to specify the location of the voxel more precisely, these results are 3 − 4 time worse than our scheme without normals and B = 0 bits of quantization for intersection points.</p><p>Yang and Wu <ref type="bibr" target="#b36">[37]</ref> describe a rather complex method to compress triangle meshes generated by the Marching Cubes algorithm. Each mesh vertex is represented by the index of the containing cube, the index of the supporting edge, and the position of the vertex along the supporting edge (our tα,j). The decoder interconnects these vertices forming triangles using the occupancy image, as in the original Marching Cubes paper <ref type="bibr" target="#b13">[14]</ref>. But the occupancy image is not encoded in the bitstream. Instead, it is reconstructed from the cube and edge indices in the encoding of mesh vertices by a complex procedure that in fact determines the connected components of the grid graph after removing the edges where mesh vertices are supported. Normal vectors are not compressed. Compression bitrates are several times worse than with our scheme. And it is not possible to do an out-of-core implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">CONCLUSIONS</head><p>In this paper we introduced a simple algorithm to compress isosurface data based on the overall structure of the JBIG binary image compression standard, and exploiting the correlation between consecutive layers of the volume scalar data to increase the compression rates quite significantly. The algorithm can be implemented in out-of-core or in-core fashion. The highest compression is achieved in the in-core version with smoothing of vertex positions and normal vectors. Despite its simplicity, this algorithm beats all the other methods proposed so far to deal with the same problem by a factor of at least 2−3, and more typically 10, and existing general purpose mesh compression algorithms by higher factors.</p><p>As for future work, we envision several areas to improve compression efficiency. We plan to concentrate on reducing the compression bitrates of intersection points and normals by using better prediction schemes, and simultaneously compressing multiple isosurfaces corresponding to different isolevels on the same volume data. This can be used for example in medical data to simultaneously show different tissues rendered as semi-transparent surfaces. We believe that even further compression gains can be achieved when several levels are compressed jointly by exploiting the relations between the order of the isolevels.</p><p>Finally, the main limitation of our method is its computational complexity, because although the length of the compressed bitstream is proportional to the number of faces in the output mesh, the time complexity of the decoder algorithm is proportional to the number of voxels in the grid. To remove this obstacle we plan to investigate ways to combine the ideas presented in this paper with the alternative approaches described above based on hierarchical space partition data structures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>IEEE</head><label></label><figDesc>Visualization 2002 Oct. 27 -Nov. 1, 2002, Boston, MA, USA 0-7803-7498-3/02/$17.00 © 2002 IEEE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>High level description of encoder algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The three and two line templates used in JBIG to determine the arithmetic coding context. The red pixel is about to be encoded. The orange pixels define a 10 bit context. The pixels surrounded by green edges have already been encoded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>The seven bit template used to determine the context to encode each bit of the occupancy image. The red pixel is about to be encoded. The orange pixels define the 7 bit context. The pixels surrounded by green edges have already been encoded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Decoder implemented in Java and integrated with a simple interactive viewer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Interactive isosurface selection and volume data visualizer.tices and normals from their reconstructed positions aligned with the grid<ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>For each vertex of the Cuberille mesh we average the values associated with incident Some isosurface meshes used in our experiments, as rendered by our simple Java decoder. A: data set generated by evaluation of smooth analytic function on grid vertices. B: Stanford bunny CT data set. C: numerical simulation of electrostatic potential of iron molecule. D: section 6 of Visible man fresh CT data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Compression results for the Visible Man fresh CT data set, section 6, isolevel 600. The grid of size 160 × 512 × 512 is the original data set. The other two were generated by downsampling within each layer. Number of faces are 1855144, 566630, and 176758, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>Connectivity-only compression results (no geometry) for the polygon meshes of figures 8, 9, and 11, with the polygonmesh coder of Khodakovsky et.al.<ref type="bibr" target="#b9">[10]</ref>.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">ACKNOWLEDGEMENTS</head><p>Thanks to Andrei Khodakovsky et.al. for providing an executable version of their polygon mesh connectivity coder <ref type="bibr" target="#b9">[10]</ref> for comparison purposes. Thanks to Alan Kalvin for useful discussions about isosurface algorithms. Thanks to Alan Kalvin, Chris Morris, Stanford University, and UNC for providing access to volume data sets.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Surface shading in the cuberille environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Udupa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="33" to="42" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metro: measuring error on simplified surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cignoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rocchini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Scopigno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="174" />
			<date type="published" when="1998-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Geometric compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph&apos;95 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1995-08" />
			<biblScope unit="page" from="13" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Constrained elastic surface nets: generating smooth surfaces from binary segmented data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computation and Computer Assisted Interventions, Conference Proceedings</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="888" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Real time compression of triangle mesh connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Strasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph&apos;98 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Face fixer: Compressing polygon meshes with properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoeyink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph&apos;2000 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000-07" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Information technology -Coded representation of picture and audio information -Progressive bi-level image compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Itu-T T</surname></persName>
		</author>
		<ptr target="http://www.itu.int" />
		<imprint>
			<date type="published" when="1993-03" />
			<biblScope unit="volume">82</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Segmentation and Surface-Based Modeling of Objects in Three-Dimensional Biomedical Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Kalvin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991-03" />
			<pubPlace>New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>New York University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A survey of algorithms for constructing surfaces from 3d volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Kalvin</surname></persName>
		</author>
		<idno>RC 17600</idno>
		<imprint>
			<date type="published" when="1992-01" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>IBM Research Division</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Near-optimal connectivity encoding of 2-manifold polygon meshes. Geometric Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khodakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Alliez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Desbrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schröder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Special Issue on Processing of Large Polygonal Meshes (to appear</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Progressive geometry compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khodakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sweldens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph&apos;2000 Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000-07" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Connectivity compression for irregular quadrilateral meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Szymczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
		<idno>GIT-GVU-99-36</idno>
	</analytic>
	<monogr>
		<title level="j">Georgia Tech GVU</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient coding of non-triangular meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Konrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gotsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Pacific Graphics</title>
		<meeting>Pacific Graphics<address><addrLine>Hong-Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Marching cubes: a high resolution 3d surface construction algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computer Graphics (Siggraph Conference Proceedings)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="163" to="196" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A JBIG-ABIC compression engine for digital document processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Marks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A comparison of normal estimation schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization&apos;97, Conference Proceedings</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m">ISO/IEC 14496-1 Information technology -Coding of audio-visual objects</title>
		<imprint>
			<date type="published" when="1999-03" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Visual / PDAM1 (MPEG-4 v.2)</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Space-Efficient Boundary Representation of Volumetric Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Eurographics-IEEE TCVG Symposium on Visualization (VisSym01)</title>
		<meeting>the Joint Eurographics-IEEE TCVG Symposium on Visualization (VisSym01)<address><addrLine>Ascona, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gradient estimation in volume data using 4d linear regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Csébfalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>König</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics 2000, Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rapid high quality compression of volume data for visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Saupe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Edgebreaker: Connectivity compression for triangular meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="61" />
			<date type="published" when="1999-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Qsplat: A multiresolution point rendering system for large meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph&apos;2000, Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Data Compression -The Complete Reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salomon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="page" from="0" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Compression of isosurfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Saupe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Kuska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Vision, Modelling and Visualization</title>
		<meeting>IEEE Vision, Modelling and Visualization<address><addrLine>Stuttgart, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Qx-coder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Slattery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A signal processing approach to fair surface design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph&apos;95 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1995-08" />
			<biblScope unit="page" from="351" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dual mesh resampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Graphics</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Linear Anisotropic Mesh Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<idno>RC-22213</idno>
		<imprint>
			<date type="published" when="2001-10" />
		</imprint>
		<respStmt>
			<orgName>IBM Research</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Progressive forest split compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guéziec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lazarus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph&apos;98 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1998-07" />
			<biblScope unit="page" from="123" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Geometry Compression through Topological Surgery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rossignac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="84" to="115" />
			<date type="published" when="1998-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Triangle mesh compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Touma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gotsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics Interface Conference Proceedings</title>
		<meeting><address><addrLine>Vancouver</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Topological considerations in isosurface generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="337" to="375" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Arithmetic coding package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wheeler</surname></persName>
		</author>
		<ptr target="http://www.cipr.rpi.edu/wheeler/ac" />
		<imprint>
			<date type="published" when="1996-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Arithmetic coding for data compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cleary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1987-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semi-regular mesh extraction from volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">J</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Desbrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schr"oder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Breen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Proceedings</title>
		<imprint>
			<date type="published" when="2000-10" />
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
	<note>IEEE Visualization</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Normal estimation in 3d discrete space. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="278" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Compressing isosurfaces generated with marching cubes. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="54" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Scalable Isosurface Visualization of Massive Datasets on COTS-Cluster</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Blanke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Parallel Visualization and Graphics</title>
		<meeting>IEEE Symposium on Parallel Visualization and Graphics<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
