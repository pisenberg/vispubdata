<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PEARL: An Interactive Visual Analytic Tool for Understanding Personal Emotion Style Derived from Social Media</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Gou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Zhou</surname></persName>
						</author>
						<title level="a" type="main">PEARL: An Interactive Visual Analytic Tool for Understanding Personal Emotion Style Derived from Social Media</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Personal emotion analytics</term>
					<term>affective and mood modeling</term>
					<term>social media text</term>
					<term>Twitter</term>
					<term>information visualization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. A person&apos;s emotional profile on a timeline visualized by PEARL derived from his tweets, of which volumes are shown as the blue background. Various emotional variables are encoded by (a) an emotion band, including (b) its center position on y-axis representing the valence, its overall brightness indicating the arousal, (c) orientations of white arrows on it showing the dominance, and (d) colors referring to different types of emotions or moods as seen from the legend. Thus, from the emotion band visual representation, we can observe that this person has an overall positive, calm, and neutrally dominant emotional outlook, and is primarily in the moods of anticipation, joy, and trust. In addition, he has had just a few emotional ups and downs (low volatility) except during July. Finally, he is emotionally resilient since he managed to quickly bounce back from (e) his negative emotional states.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A person's emotions, such as anger, joy, and grief, often significantly impact his or her behavior and performance in the real world <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b9">10]</ref>. Thus, understanding a person's emotions and the patterns of these emotions provides great value for both individuals and businesses alike. For example, individuals can use such understanding for selfreflection and self-enhancement <ref type="bibr" target="#b20">[21]</ref>, while businesses can use it to provide more personalized services, such as recommending suitable wellness programs based on a person's emotional patterns <ref type="bibr" target="#b9">[10]</ref>.</p><p>However, capturing and understanding people's emotions let alone the patterns of their emotions is not trivial. So far there have been many efforts in the space, which roughly fall into two broad categories. One is to use physical sensors or devices to monitor and capture</p><p>• Jian Zhao is with University of Toronto. E-mail: jianzhao@dgp.toronto.edu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Liang Gou, Fei Wang, and Michelle Zhou are with IBM Research</head><p>Almaden. E-mails:{lgou,wangfe,mzhou}@us.ibm.com.</p><p>one's emotional states from the collected data and then extract certain emotional patterns from the detected states <ref type="bibr" target="#b20">[21]</ref>. This line of work however has its limitations due to the hardware requirement, including the accuracy of the sensors and the burden on users to wear the devices. More recently, researchers have started applying text analytics to one's digital footprints (e.g., online reviews and social media text) to detect one's emotions <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b5">6]</ref>. However, most of existing work focuses on identifying distinct emotional states at individual time points instead of capturing one's emotional style that characterizes and summarizes the patterns of emotions over time.</p><p>Consider the role of a customer representative, Alison, who works at the social media contact center of an airline and interacts with many customers on Twitter daily, including those who are angry and agitated by their flight experience. It would be very helpful for Alison to know how to best interact with her customers, if she has a tool that can help her understand each customer's overall emotional style inferred from the customer's public tweets, especially with the following information:</p><p>• What kind of mood is this person normally in? Is it overall positive or negative? excited or calm? emotionally aggressive or submissive?</p><p>• How often or how easily does he get upset?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>203</head><p>IEEE Symposium on Visual Analytics Science and Technology 2014 November 9-14, Paris, France 978-1-4799-6227-3/14/$31.00 ©2014 IEEE</p><p>• How quickly can he recover from negative emotions?</p><p>• What usually triggers the person's emotional changes?</p><p>To help Alison answer the above questions, we are developing PEARL (Personal Emotion Analysis, Reasoning, and Learning), a timeline-based visual emotion analysis tool that allows a user to interactively analyze and explore a person's emotional patterns over time from one's social media text (e.g., tweets). In this paper, we describe three unique aspects of PEARL.</p><p>First, we present PEARL's analytic engine that performs multi-dimensional emotion analysis on social media text. The engine automatically derives a person's basic emotions that are emotional episodes revealed by the text at individual time points. It then aggregates and summarizes the derived basic emotions to infer the corresponding moods that are longer-lasting emotional feelings over a time period. To characterize one's emotional style, for each inferred emotions or moods, PEARL computes the associated discrete affective categories (e.g., joy or anger), and three continuous quantitative dimensions (i.e., valence, arousal, and dominance).</p><p>Second, we describe the design and development of the visualization component of PEARL, which transforms the complex, multidimensional emotion analysis results into a comprehensible, timelinebased visual emotional profile. As shown in <ref type="figure">Figure 1</ref>, a user can interact with such a visual summary to easily discover a person's emotional style from three perspectives:</p><p>• emotional outlook that captures the primary emotions or moods by their valence, arousal, and dominance values;</p><p>• emotional volatility that indicates the frequency and degree of emotional changes over time;</p><p>• emotional resilience that shows the period of time taken to recover from adversity.</p><p>Third, due to the noise in social media text and the imperfections in emotion analytics, PEARL also supports a rich set of interactions that help users further examine and validate emotion analysis results from multiple perspectives. As a result, not only can users discover one's emotional style at a high level, but they can also examine the details of emotional states ( <ref type="figure" target="#fig_2">Figure 3c</ref>) and their triggers ( <ref type="figure" target="#fig_2">Figure 3i</ref>). Furthermore, users can drill down to the original social media text ( <ref type="figure" target="#fig_2">Figure 3d</ref>) to browse the evidence used to infer the emotions or moods, and validate the performance of our analytics.</p><p>In summary, compared to existing visual text analytic systems including those supporting sentiment or emotion analysis <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b11">12]</ref>, our work offers three unique contributions:</p><p>1. Multi-dimensional emotion analysis that analyzes noisy social media text to automatically extract emotional episodes at various time points and infer longer-lasting moods by aggregating the individual episodes and summarizing their changes over time;</p><p>2. Effective visualization that creates a visual emotional profile and helps users to digest complex, multi-dimensional emotion analysis results and discover one's emotional style;</p><p>3. Rich interactions that allow users to interactively examine and validate emotion analysis results from multiple perspectives to aid the interpretation of the results and compensate for the imperfections in current analytics.</p><p>To evaluate PEARL, we designed and conducted a series of studies. First, we collected ground truth by asking users to label emotions expressed by their own tweets over one month period. We used this data to verify PEARL's emotion analysis models and design subsequent studies. Next, we conducted two studies including an interview study for assessing PEARL's effectiveness in user self-reflection, and a survey on Mechanical Turk for evaluating the usefulness of our system in analyzing others' emotional profiles. The results of our studies demonstrated the effectiveness of PEARL in support of users' real-world emotion analysis tasks by producing adequate emotion analysis results and facilitating visual exploration of the generated visual emotional profiles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our work is related to several areas of research, including emotional psychology and computational modeling of human emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Emotional Psychology</head><p>Our work on understanding one's emotions and emotional style builds on a vast amount of research in Emotional Psychology and Affective Science. Our work is built on two main emotional models: categorical and dimensional. Categorical models describe emotions as discrete categories. Specifically, our work uses the four pairs of primary emotions suggested by Plutchik (i.e., anger-fear, anticipation-surprise, joy-sadness, and trust-disgust) <ref type="bibr" target="#b28">[29]</ref>. On the other hand, dimensional models characterize emotions by a common set of dimensions. In particular, we adopt the PAD model developed by Mehrabian et al.</p><p>-pleasure (also known as valence), arousal and dominance, which uses three dimensions to represent human emotions <ref type="bibr" target="#b21">[22]</ref>. Emotions can also be described by their temporal properties. For example, emotional episodes exist for a brief moment which is often with intense feelings directed to someone or something, i.e., usually elicited by particular triggers; whereas moods are prolonged feelings that tend to be less intense than emotions and that often (though not always) lack a contextual stimulus <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref>. Moreover, researchers have also observed different emotional styles, such as outlook and resilience <ref type="bibr" target="#b9">[10]</ref>.</p><p>Our current work combines both categorical and dimensional models to characterize emotions. Moreover, we capture the temporal properties of emotions to distinguish various emotional constructs, including emotional episodes, moods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref>, and emotional styles <ref type="bibr" target="#b9">[10]</ref>. While we build on existing theories in Emotional Psychology, we greatly extend such work by creating computational approaches that automatically infer the emotions from a person's social media text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sentiment and Emotion Analysis from Text</head><p>Our work is related to various efforts in sentiment and emotion analysis from text. For example, Liu provided a comprehensive review of sentiment analysis <ref type="bibr" target="#b17">[18]</ref>. Similar to this line of work, we derive various emotional feelings from text, including their polarity and intensity. However, unlike sentiment analysis, which often focuses on understanding the aggregated feelings expressed by a crowd, we focus on investigating an individual's feelings over time, which poses different challenges as described later.</p><p>In addition to sentiment analysis, there are efforts on inferring emotions from text including social media. For example, Bollen et al. derived the daily moods exhibited by the public on Twitter <ref type="bibr" target="#b2">[3]</ref>, and Munmun et al. extracted 200 moods from social media text <ref type="bibr" target="#b26">[27]</ref>. While these works study distinct emotional states voiced by the public, we focus on modeling an individual's emotional style over time. More importantly, PEARL combines emotion analytics and interactive visualization to help users perform multi-dimensional emotion analysis that none of previous works has addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sentiment and Emotion Visualization</head><p>Complementing sentiment and emotion analysis efforts in the field of text analytics, researchers have developed visualizations that allow users to visually explore these text analysis results. For example, Opinion Space is created to display people's opinions including sentiment expressed on a particular subject <ref type="bibr" target="#b13">[14]</ref>. A set of visual metaphors is designed to represent sentiment extracted from online hotel reviews <ref type="bibr" target="#b33">[34]</ref>. TwitInfo supports a timeline-based interactive exploration of events derived from tweets, together with the associated text sentiment <ref type="bibr" target="#b19">[20]</ref>. A spatial-temporal visualization is proposed to display varied people's moods across the United States throughout a day <ref type="bibr" target="#b23">[24]</ref>. Along the similar line, WeFeelFine collects people's emotions by continuously extracting sentences like "I feel" or "I'm  feeling" from blogs and social networking websites and allows users to browse and search for the extracted information <ref type="bibr" target="#b15">[16]</ref>.</p><p>These works, however, do not address finer-grained emotion modeling of individuals as we do. In particular, we model one's emotions from multiple perspectives, covering emotional categories, valence, arousal, and dominance. More importantly, PEARL reveals one's emotional style observed from temporal patterns of emotions, which few works have touched upon.</p><p>Besides visualizing emotions inferred from text, there are efforts on visually summarizing emotions derived from other channels. For example, EventEscape encodes valences and mood types derived from multimedia documents (e.g., images and video stills) <ref type="bibr" target="#b0">[1]</ref>. Affec-tAura visualizes a person's emotions detected by a set of physical sensors <ref type="bibr" target="#b20">[21]</ref>. Emotion Scents displays and allows users to interact with a user's emotional states recorded by a electroencephalography (EEG) headset <ref type="bibr" target="#b7">[8]</ref>.</p><p>However, the above systems only provide basic visual representations for encoding limited numbers of emotional variables, lacking a thorough analysis and visualizations of personal emotions from multiple perspectives. Moreover, differing from them, ours focuses on extracting an individual's emotional style from only text and creating a rich and interactive visual emotional profile that users can explore and validate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PEARL SYSTEM OVERVIEW</head><p>PEARL is designed to help a user analyze a person's emotional style from his/her text footprints. PEARL visually summarizes the inferred emotions and captures their changes over time. <ref type="figure" target="#fig_1">Figure 2</ref> provides an overview of the PEARL system architecture. The system consists of three main components: text pre-processor, emotion analysis engine, and visualizer. The input to the system is a collection of text, such as emails, blog posts, and tweets, authored by an individual. In this paper, we focus on the use of an individual's tweets to derive his or her emotional profile.</p><p>Given a Twitter ID, PEARL collects all the tweets of that person. The text pre-processor then uses a set of standard text processing routines, including tokenization and stemming, to "clean" each raw tweet to extract a set of keywords and associated meta-data, such as tweet time stamp. The output is then sent to the basic emotion analysis component to derive the basic emotions revealed by individual tweets at specific time points. These basic emotions are aggregated and summarized by the mood analysis component to infer the moods over a time period. The derived moods are characterized by both the discrete Plutchik emotion model <ref type="bibr" target="#b28">[29]</ref> and the continuous VAD dimensions <ref type="bibr" target="#b21">[22]</ref>. Given the complex and abstract results produced by the analysis engine, the visualizer transforms them into a timeline-based visual emotional profile. Users can then interact with the generated visualization to perform exploratory analysis.</p><p>PEARL is a web-based system. The server side, including its analysis engine and visualizer, is implemented in Java, while its client side is built with D3 JavaScript toolkit <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MULTI-DIMENSIONAL EMOTION ANALYTICS</head><p>To infer an individual's emotional style from his tweets, PEARL performs emotion analysis in two main steps: basic emotion analysis and mood analysis. Basic emotion analysis derives emotional episodes (i.e., momentary feelings directed toward someone or something) revealed by a person's tweets at individual time points. Mood analysis aggregates those episodes to infer moods (i.e., composite longerlasting emotional states) over different time intervals.</p><p>Since each emotional episode or mood is computed from one or more tweets, PEARL provides these tweets as low-level data evidence to help users interpret and validate emotion analysis results. Moreover, PEARL summarizes the content of these tweets to display possible emotional triggers, allowing users to understand what might have evoked the emotions or changes of moods <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multi-Dimensional Emotion Model Definition</head><p>Before describing our two-step emotion analysis, we first define the multi-dimensional emotion model that we use to guide the analysis.</p><p>To capture one's emotional style, we have adopted two well-known emotion models in psychology. More specifically, we used Plutchik's discrete categorical model <ref type="bibr" target="#b28">[29]</ref> to classify emotional states into eight primary emotions (including four pairs: anger-fear, anticipationsurprise, joy-sadness, and trust-disgust). We also characterize all the detected emotions or moods by the continuous dimensional model <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">31]</ref> with three measurements (VAD): valence (degree of positiveness), arousal (degree of excitement), and dominance (degree of aggressiveness). With the above emotion variables, we further model three basic emotional styles <ref type="bibr" target="#b9">[10]</ref>: outlook (overall positiveness), volatility (sensitivity to context), and resilience (ability to recover).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Basic Emotion Analysis</head><p>In this step, we first use a lexicon-based approach to detect affective expressions (i.e., emotional words) in each tweet, and then derive basic emotions from these expressions. Each inferred basic emotion is characterized by the above two emotion models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Affective Expression Detection</head><p>Although sentence level emotion detection is perhaps more effective <ref type="bibr" target="#b6">[7]</ref>, we employ a lexicon-based approach to detect affective expressions in tweets for two reasons. First, this approach is more extensible in handling text input in various forms across different domains. Second, tweets are special forms of text that often contain short, broken, and incomplete sentences. To derive a word's emotional category and VAD scores, we combine two most widely-used dictionaries for emotion detection: the NRC lexicon <ref type="bibr" target="#b25">[26]</ref> based on Plutchik's model and the ANEW lexicon <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b32">33]</ref> based on the VAD model. However, many of the words in ANEW are not labeled with emotion categories, and vice versa. To obtain the missing VAD scores or emotion categories of a word, we use the WordNet database <ref type="bibr" target="#b22">[23]</ref> to find its synonyms and check if the synonyms appear in the other lexicon. If so, we assign the corresponding labels and average VAD scores to the word. Otherwise, we remove it from the lexicon. With the integrated lexicon, PEARL identifies a set of emotional words in a tweet, each of which is associated with one or more emotional categories and three VAD scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Basic Emotion Estimation</head><p>To estimate a basic emotion from a tweet, we first use a vector P : (c 1 , c 2 , . . . , c 8 ) T to capture the emotion categories by the Plutchik's model. The quantity c i is computed from Ni/N, where N i denotes the number of emotional words in category c i based on the lexicon and N denotes the total number of emotional words in this tweet. Since c i is estimated by the amount of evidence (numbers of relevant emotional words) used by a person, it can be interpreted as the intensity of this specific emotion. Similarly, we use a vector VAD :</p><formula xml:id="formula_0">(v i , a i , d i )</formula><p>to capture the dimensional model related to each category c i by averaging the VAD scores of all the associated emotional words. As a result, a basic emotion E basic (t) of a tweet at a timestamp t is represented by one 8-dimensional vector P and a 8-by-4 matrix VAD:</p><formula xml:id="formula_1">[P t ,VAD t ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Mood Analysis</head><p>While a basic emotion captures the emotional states at a specific time stamp, moods represent a person's longer-lasting emotional feelings. We are interested in understanding people's moods, since they often have larger impact on one's behavior in the real world <ref type="bibr" target="#b29">[30]</ref>. We use the above detected basic emotions to identify meaningful emotional segments for deriving moods. To better understand what might have elicited different types of emotions in a particular mood, we also extract emotional triggers and provide data evidence based on the relevant tweets</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Clustering-Based Mood Detection</head><p>Moods are prolonged emotional feelings with no obvious stimulus <ref type="bibr" target="#b14">[15]</ref>, which indicates the coherency of time, emotions, and expressions. Therefore, based on the basic emotions derived above and raw tweet content, we identify meaningful segments of tweets expressing a mood. Each tweet segment should satisfy three criteria: 1) emotional proximity-they reveal similar emotions, 2) semantic proximity-they are on a similar topic evoking the emotions, and 3) temporal proximity-they are posted in a short time period. Note that if we simply cluster the tweets by only their emotional proximity, we may end up with segments containing diverse semantic content and spreading across entire the timeline, which is difficult to understand. The tweet clustering task is very similar to the temporal topic segmentation described in <ref type="bibr" target="#b27">[28]</ref>, therefore we adopt their constrained co-clustering approach to segment the tweets with the above three criteria.</p><p>To infer a mood from a tweet segment identified above, we first group all the emotional words into the eight Plutchik emotional categories (where some may be empty), and then merge clusters whose sizes are below a threshold to their closest ones in the VAD space to extract major representative emotional categories. Similar to computing E basic (t) previously, a mood M over an time interval T can be characterized by the Plutchik vector P and its corresponding VAD vectors with the clusters of emotional words:</p><formula xml:id="formula_2">M(T ) : [P m ,VAD m ] T ,</formula><p>which is also a 8-by-4 matrix. Additionally, each row of the mood matrix represents an emotion component of the mood</p><formula xml:id="formula_3">E comp (i, M(T )) : [c i , v i , a i , d i ] T</formula><p>, where i denotes one of the eight emotional categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Emotional Triggers Summarization</head><p>To better understand what might have elicited different types of emotions in a particular mood, we also extract emotional triggers and provide data evidence based on the relevant tweets.</p><p>We summarize the tweets content contained within an emotional segment to approximate the cause or trigger related to a mood, and provide the data evidence for users to understand the inferred mood. Currently we compute the tf-idf scores of all words in the tweets, where we treat each mood segment as a "document" to calculate the inverse document frequency for words to highlight the words unique to the mood. We choose the tf-idf model over the more sophisticated topic modeling (e.g., LDA) for its speed, especially for supporting real-time emotion analysis where the text content is updated frequently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">INTERACTIVE VISUALIZATION OF EMOTIONAL STYLES</head><p>After our analytic engine produces emotion analysis results, the visualization component then transforms the complex, multi-dimensional results into a comprehensible visual emotional profile that allows users to easily discover one's emotional styles. Before presenting the visual metaphors and interactions supported by PEARL, we first introduce our design goals and define the data input to our visualization engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Design Goals</head><p>Since PEARL is designed to support visual analysis of emotional profiles from social media, its visualization must serve this purpose by satisfying the following three main goals.</p><p>DG1 Summarizing personal emotions at multiple levels and from multiple perspectives. As described earlier, a person's emotion is complex and often characterized by multiple constructs (e.g., emotional categories vs. VAD space) <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b28">29]</ref>, at multiple levels (e.g., basic emotions vs. moods). Thus, the visual interface must portray the derived emotion variables at multiple levels and summarize their relationships from various perspectives.</p><p>DG2 Revealing emotional patterns over time. Our goal is to understand an individual's emotional style as it can be used to predict or influence the person's longer-term behavior in real life <ref type="bibr" target="#b9">[10]</ref>. Therefore, the visualization must capture temporal variations of emotions over time to unveil the person's emotional patterns, such as critical emotional transitions or irregularities, which would aid users in discovering the emotional styles.</p><p>DG3 Providing data evidence for analytical reasoning. Due to the complexity and imperfections in analytic algorithms, it is desirable to present the key evidence used to infer various emotions, which would help users to interpret and validate the analysis results as well as facilitate their analytical reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multi-Dimensional Emotion Data</head><p>The data input to PEARL's visualization engine includes two main parts: the original text (tweets) used for emotion analysis and the output produced by the analytic engine. Specifically, the output contains a series of inferred moods {. . . ,</p><formula xml:id="formula_4">M(T i ), . . . } represented by the mood matrices [P m ,VAD m ] T i . Each mood further consists of a set of emotion components E comp ( j, M(T i )) : [c j , v j , a j , d j ] T i .</formula><p>Additionally, each mood is associated with a set of tweets, and each tweet is associated with a number of detected emotional words. Currently, we do not visually display basic emotions derived from individual tweets, since they are too low level and hinder users from discovering higher level emotional patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">PEARL Interface</head><p>As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, PEARL provides users with the following main interface components: (a) an overview of one's emotional profile, (b) a detail emotion timeline view, (c) a mood word view, and (d) a raw tweets view. The overview and detail view are coupled through interactions with a time window (e). Hovering over a visual element brings up tooltips for a user to drill down into details (h, i) . Moreover, PEARL offers an action menu (f) and an interactive legend (g) for additional means to inspect the emotional profile, such as emotional category filtering and critical point highlighting (j).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Visual Metaphors</head><p>Following the design goals, our visualizations not only must depict the inferred moods and emotions (DG1), but also capture their variations over time (DG2). We have developed two novel visual representations to summarize the emotion analysis results: emotion bands encoding moods and summarizing their changes over time, and emotion bubbles revealing emotion components associated with a mood <ref type="figure" target="#fig_3">(Figure 4</ref>). Emotion Band.</p><p>As <ref type="figure" target="#fig_3">Figure 4a</ref> shows, an emotion band encodes the VAD measurements from the derived moods along the horizontal time axis. Specifically, a mean VAD vector,</p><formula xml:id="formula_5">[v t , a t , d t ],</formula><p>is computed from the mood matrix M(T ) by averaging its VAD m components. The y-axis represents the valence score v t from 0 to 1, indicating negative to positive emotions, which determines the vertical center of the band. The brightness of a band encodes the arousal scale a t , where a darker shade implies a lower arousal level. The dominance dimension d t is represented by the orientation of a "white arrow" displayed at the temporal center of a mood (i.e., the middle of time interval T ), where the arrow pointing downward implies a more submissive emotion. Moreover, an emotion band consists of many sub-bands, each of which encodes an emotion category P m in different hues based on the color scheme used in Plutchik's emotional wheel <ref type="bibr" target="#b28">[29]</ref>. The intensity levels of emotional categories, denoted by the components of P m , are normalized and mapped to the widths of sub-bands at a specific time point, where the total width of sub-bands, the width of an emotion band, is a constant.</p><p>To reveal the temporal variations of emotions (DG2), out of Bertin's seven visual variables <ref type="bibr" target="#b1">[2]</ref>, we select those that can be easily interpolated for representing continuous changes (e.g., position, brightness, and size) along a timeline. We use these continuous visual variables to encode the most examined emotion elements (e.g., valence, arousal, and emotion intensity), while using discrete visual variables to encode the less used emotion elements, such as dominance <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>Emotion Bubble.</p><p>To provide users with detailed information, PEARL uses emotion bubbles to encode the emotion components of a mood. A consistent visual language as described above is applied to encode the emotion variables in emotion bubbles. Specifically, each bubble indicates an emotion component of the mood, E comp ( j, M(T i )), where the hue and size of the bubble represent the emotional category itself and its intensity level c j , respectively. Similarly, the brightness of the bubble and the arrow orientation represent the arousal a j and dominance d j of that emotion component. Overall, the bubbles representing all emotion components of a mood are laid out inside a circular area by a circle packing algorithm <ref type="bibr" target="#b31">[32]</ref>. The circle is placed at the temporal midpoint of a mood segment.</p><p>Splitting Emotion Bands and Bubbles.</p><p>Since the above emotion band and emotion bubble represent a mood often consisting of many emotion components, which are implied by the sub-bands and individual bubbles, these visualizations can be further split to represent individual emotion components in a similar way <ref type="figure" target="#fig_3">(Figure 4b</ref>). This allows a user to observe temporal variations of each emotion component at a lower level. Specifically, the vertical center position of each sub-band is determined by the valence score of the corresponding emotion v j . Similar to the visual encodings used in an emotion bubble, the band brightness represents the arousal score a j and the orientation of the white arrow denotes the dominance value d j .</p><p>In summary, the visual metaphors described above allow users to obtain an overall visual emotional profile and specific details at various levels (DG1). From the visualization, users can also easily discover emotional patterns over time (DG2). For example, a user can identify the primary emotional categories from the dominant band colors and heights (emotional outlook), and observe emotional changes over time from the bands' curvature and size fluctuations (emotional volatility or resilience). Using the split bands or emotion bubbles, the users can trace the patterns of a particular type of emotion (e.g., sadness).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Visual Interactions</head><p>To help users explore, interpret, and validate the emotion analysis results, PEARL also supports several types of visual interactions.</p><p>Highlighting and Filtering.</p><p>Our goal is to understand one's emotional style including discovering interesting emotional phenomena (DG1). PEARL thus interactively suggests and highlights interesting features in a visual emotional profile. A user can press the action buttons ("E", "O", and "R" respectively) to observe extreme emotions, emotional outlook, and resilience <ref type="figure" target="#fig_2">(Figure 3f,j)</ref>. Moreover, a user can use the interactive legend ( <ref type="figure" target="#fig_2">Figure 3g</ref>) to filter out certain types of detected emotions <ref type="figure" target="#fig_3">(Figure 4b)</ref>.</p><p>Details on Demand. Like any other interaction visualization systems that deal with complex data, PEARL allows users to drill down into the details of emotion analysis results from multiple perspectives (DG1). For example, a user can view a mood, drill down on the emotion components of the mood, as well as unfold each individual emotion component.</p><p>Furthermore, most of the detailed information shown on demand links the visual elements back to the original data, such as relevant tweets and emotional words. This not only helps users explain how the emotion analysis results are derived, but also allows human validation of such results to compensate for the imperfections in analytic algorithms (DG3). For example, hovering over a tweet segment brings up a tag-cloud summarization of these tweets, indicating potential emotional triggers <ref type="figure" target="#fig_2">(Figure 3i</ref>). Hovering over a mood on the emotion bands will bring up emotion bubbles to display the emotion components <ref type="figure" target="#fig_2">(Figure 3h</ref>). By clicking on any of the bubbles, the mood word view <ref type="figure" target="#fig_2">(Figure 3c</ref>) will pop up to show a scatterplot of all the emotional words used to infer the mood. Similar to the circumplex model <ref type="bibr" target="#b30">[31]</ref>, these words are laid out as small circles in the 2D valence-arousal space, where the circle radius represents the dominance and the filling colors indicate the associated emotional category. Meanwhile the raw tweets view <ref type="figure" target="#fig_2">(Figure 3d</ref>) can be brought up to show all the original text used for deriving the emotions, where the emotional words are highlighted.</p><p>Coordinated Multi-View Analysis.</p><p>Since our emotion analysis results are quite complex, PEARL allows users to interact with multiple views in a coordinated way to comprehend the data. In particular, dynamic brushing and linking techniques are used to associate the information presented in multiple views. For example, hovering over a particular circle (word) in the mood word view automatically scrolls the tweet view to show the tweets containing the emotional word. On the other hand, hovering over a tweet in the tweet view highlights all the emotional words of that tweet in the mood word view. In the meantime, a pink circle indicating the posting time of the tweet also shows up in the timeline-based emotional profile. Similarly, if the mouse is over the emotion bubbles of a selected mood, the unrelated emotional words in the mood word view fade and related tweets are highlighted <ref type="figure" target="#fig_3">(Figure 4c,d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EVALUATION</head><p>To demonstrate the effectiveness and usefulness of PEARL, we designed and conducted a series of studies. We first asked users to perform manual emotion analysis and label their own tweets to gather ground truth for quantitatively evaluating the performance of PEARL's analytical engine. Based on the collected ground truth, we carried out two user studies on the use of PEARL for self-reflection and third-party emotion analysis, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Ground-Truth Gathering Study</head><p>We performed a one-month study to collect ground truth data-a person's true emotions occurred in the real world, which could help us verify the accuracy of PEARL's emotion analysis engine and design the subsequent studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Participants and Data</head><p>Through an email campaign within a large IT company, we recruited 10 participants with Twitter presence (2 females and 8 males, aged 35-54), with varied backgrounds, including Marketing, Sales, and Software Development. All were relatively active on Twitter, posting at least one tweet per day on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Method</head><p>At the beginning of the study, we provided all the participants with the background knowledge of the two emotional models used in PEARL <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b28">29]</ref>. We then asked each participant to attend a tweet-labeling session on every Friday for four consecutive weeks.</p><p>In each labeling session, the participants were given their own tweets posted during the past week. They were instructed to use our customized online survey tool to label each tweet with the following information: valence, arousal, and dominance level, each on a 9-point scale (-4 for most negative, 0 for neutral, and 4 for most positive), a commonly used affective rating <ref type="bibr" target="#b4">[5]</ref>, and the emotional category from the Plutchik's eight primary emotions. If the participants did not think a tweet was associated with any emotions, they could choose the label "None". We also asked participants to indicate mood segments during which they had expressed longer-lasting distinct feelings and tag the segment with the VAD rating and emotional category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Results and Analyses</head><p>From the study, we collected a total of 308 labeled tweets belonging to 60 mood segments, which were also used to measure the user task performance in our subsequent studies. Previous work has already demonstrated the effectiveness of using the ANEW and NRC lexicons to identify people's emotions from texts at the word and sentence levels <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b6">7]</ref>. We thus further aggregated the labeled tweets by their mood segments since one of the main focuses of PEARL is to detect moods that are longer-lasting and mixed with different emotions. We compared the ground truth data with PEARL's analysis results by two aspects: VAD scores and emotional categories.</p><p>VAD Score Comparison.</p><p>To rid of the noise and inconsistency in human labeling, we first applied a method used in <ref type="bibr" target="#b20">[21]</ref> to discretized the VAD values into 3 levels-negative, neutral and positive-by setting two thresholds (0.33 and 0.67). By this measure, the Cohen's Kappa coefficients of agreements between the ground truth and PEARL's output were: valence 0.71, arousal 0.78, and dominance 0.72 ( <ref type="figure" target="#fig_4">Figure 5)</ref>. Although we were aware that our discretization may be too coarse and more carefully chosen thresholds (e.g., by data distribution) may be needed, our results are still very encouraging since this level of agreement is often considered acceptable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotional Category Comparison.</head><p>To compare the user-labeled and PEARL-derived moods by their emotional categories, we performed Cohen's Kappa tests over the two, indicating an average coefficient of 0.68. <ref type="figure" target="#fig_4">Figure 5</ref> shows the result for each mood, where the "anger" mood was estimated most accurately with 0.81. Since our participants did not explicitly label their emotional intensity in the study, we computed the intensity by dividing the count of labels obtained for each emotional category by the total number of labels obtained in one mood segment. Similar to the analysis of VAD scores above, we discretized the emotional intensity into three levels, producing the average Cohen's Kappa coefficient 0.73 for all emotional categories, which is also equally promising ( <ref type="figure" target="#fig_4">Figure 5)</ref>.</p><p>It is worth noting that PEARL achieved the level of analysis accuracy similar to those achieved by using multi-source and multi-modal input to estimate fewer emotional variables <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b16">17]</ref>. This is especially encouraging since PEARL uses only the tweets to derive richer emotional information. Also, for the purpose of PEARL's applications, we do not need the emotion analysis engine to be perfectly accurate, because its visualization allows users to incorporate their own knowledge into the analytical process to compensate for imperfects in analytic algorithms (DG3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Participatory Interview Study</head><p>One of the key applications of PEARL is to support self-reflection of emotions. The goal of this study was to evaluate how well a user could use PEARL to analyze emotions and emotional style derived from one's own tweets. We also wanted to assess if the overall visualization design satisfied the goals described earlier (Section 5.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Participants and Data</head><p>In this study, we selected 6 participants (1 female and 5 males, aged 31-42) from the 10 people who participated in our ground-truth gathering study described above by balancing several factors, such as their levels of Twitter activity and genders. The participants contributed their tweets posted in the last two years, where each data set had more than 600 tweets (the most one had over 4000 tweets).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Method</head><p>We invited each participant to an one-hour participatory interview. At the beginning of the study, we gave participants a tutorial of PEARL, introducing its key functions and interface. Participants were then asked to use PEARL to explore the emotion analysis results of their own tweets falling in several selected time segments (about 8.5 segments per person) in allotted time. We observed their interactions with PEARL and offered help on using and understanding the system when necessary. Next we interviewed the participants with a set of questions about their findings, including their identification of mood segments and emotional patterns, and collected their feedback about the system. Their interactions with PEARL were tracked via a screen capture software and all the conversations were also recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.3">Results and Analyses</head><p>Overall, all the participants enjoyed the experience of analyzing their own emotions using PEARL. The six participants explored a total of 51 segments and agreed that the emotion analysis results of 42 segments matched with their own assessment. They also thought that PEARL adequately captured their true emotional style revealed by their tweets. The participants appreciated PEARL's visualization and interaction capabilities, and indicated that the system was useful, efficient, and intuitive in reconstructing stories, recalling past activities and events, and refreshing their memories.</p><p>Since the analytic engine of PEARL produced rather complex multi-dimensional emotion analysis outputs, the visual summary of these results helped our participants to understand their own emotional style from multiple perspectives (DG1). For example, the curvature of emotion bands helped the participants to assess their own emotional volatility in terms of valence: "I would think I am quite stable. This matches what I am, although I can see some zig-zag here and there, b a <ref type="figure">Fig. 6</ref>. One participant was experiencing an emotional resilience stage between two extreme emotions (marked with "R" and "E" by PEARL respectively), which was a recovery from a mountain hiking accident.</p><p>and some disgust emotion here. But in general, I would say I have a pretty smooth [emotion] band. " (P4).</p><p>Participants also indicated that the visualizations were intuitive and they could easily locate the important emotional changes by looking at the overall shape and brightness of the bands over different time periods. For example, several mentioned that following the "little ants" (the circled white arrows encoding dominance value) and the general trends of emotion bands could give them a much better idea on how their moods have changed over time.</p><p>Second, one of our main goals is to aid users in understanding one's emotional style revealed from the temporal variation of emotions (DG2). The rich visual encodings of moods as emotion bands and bubbles helped the participants to easily discover their own emotional outlook and other emotional patterns. For example, P2 commented: "looking at the color of green all over, it is trust dominating my emotion over the time. Third, due to the complexity and imperfections in emotion analysis, PEARL visualization allowed the participants to interactively validate the analysis results and compensate for the imperfections (DG3). Specifically, by coordinating the tweets view and emotional words view, our participants could easily identify emotional words in the tweets, which helped them verify the correctness of the inferred moods. For example, P5 mentioned that the system correctly detected the "joy" and "anticipation" for her baby's birthday celebration with emotional words such as "birthday", "happy", and "baby". Moreover, the participants liked the tag cloud tooltips that summarized the mood triggers from the relevant tweets: "Looking at this [tweets tag clouds], quite a lot of words related to my work here, such as 'leaders', 'socialcustcare' [Social Customer Care], etc. Useful context information. I would say my trust emotion is kinda related to my workspace." (P2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Mechanical Turk Study</head><p>In addition to supporting self emotion analysis, PEARL's second main use scenario is to allow a user to analyze and assess the emotional style of others. Such function can benefit many lines of businesses tremendously, ranging from health-care to financial services. We thus designed and conducted another study to evaluate PEARL's effectiveness in support of this use case. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Participants</head><p>We recruited 50 turkers on Amazon Mechanical Turk in our surveybased study. We obtained 44 valid survey results (25 males, 13 females, and 6 with unknown genders) by removing dubious submissions (e.g., completed within 5 minutes).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Method</head><p>During the Mechanical Turk study survey, we asked the participants to analyze the emotions and emotional style of a selected person from the 10 participants in our ground-truth gathering study, whose labeled data partially matched with what PEARL inferred. The rationale was that we wanted to make tasks as realistic as possible, including handling analytic imperfections of a system. Each turker was instructed to use PEARL to complete a set of emotion analysis tasks. Before starting the tasks, turkers were required to read an instruction manual and watch a video tutorial to get familiar with the visualizations and interactions of PEARL as well as understand the basic psychological concepts of emotions. They were first asked to answer three testing questions about the basic features of PEARL before they could continue the real study. This step helped us filter out the participants who were not paying attention.</p><p>Our survey contained 10 basic non-trivial emotion analysis tasks, each to be completed by answering a set of multiple choice questions. These questions were specifically designed to test whether a participant could use PEARL to discover another person's emotional patterns and style, including interpreting visual cues and finding evidence to back up their discoveries. Sample survey questions included: "Which time period was this person emotionally most submissive?", "During which time period did this person have the most number of emotional changes?", "What is the primary mood of this person from May 2013 to July 2013?", and "Which of the evidence listed below is related to the mood detected from June 2013 to July 2013?". At the end of the survey, turkers were also asked to rate different aspects of PEARL on an 1-7 Likert scale (from least favorable to most favorable).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3">Results and Analyses</head><p>The average survey completion time for the 44 valid results was 21.6 minutes (SD=7.64). On average, the turkers correctly performed 7.14 out of 10 (SD=1.42) analytical tasks, resulting in an overall accuracy rate 71.4%. <ref type="figure" target="#fig_6">Figure 7</ref> shows the correction rates of all tasks classified in 4 categories. The results were also very good on interpreting PEARL visual encodings (average accuracy 77.3%) and locating data evidence (average accuracy 78.4%). In contrast, the tasks of identifying "emotional patterns" and "emotional style" were harder for turkers since they performed less well for T4 (68% accruracy) on assessing the person's emotional volatility, and T8 (65% accuracy) on emotional resilience. Our hypothesis was that these concepts are more abstract and harder for an untrained audience to grasp.</p><p>As for their subjective ratings on the system, PEARL received the average rating of 5.64 out 7 for all questions, which was very encouraging. Overall, the turkers were satisfied with the system and thought that PEARL was useful and effective in analyzing one's emotional patterns along time (Q1, Q2 and Q3). Also, the turkers were able to use PEARL to understand the psychological models of emotions (Q4). The results of Q5 (average rating 5.68 out of 7) indicated that PEARL was effective for even complicated emotion analysis tasks. Although appreciated by the participants, PEARL's capabilities of displaying the underline data evidence (Q6) were rated lower than other aspects. One reason might be that the tasks designed for this study may have not exposed the full value of these functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>In this section, we discuss the limitations of our system revealed from the user studies and future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Limitations</head><p>Our current system has several limitations, mainly in its analytics and the data used to derive the emotions.</p><p>Lexicon-based Approach.</p><p>As described in Section 4, PEARL uses a lexicon-based approach to identify emotional cues (unigrams) and derive basic emotions. While such approach is very portable and fast, it ignores many important linguistic features when inferring emotions, e.g., handling negations (e.g., "I'm not happy"). In addition, the emotion lexicons that PEARL uses were developed based on human-labeled emotional words in a limited context, while different words in different contexts may express completely different emotions. For example, the word "sick" in general evokes a negative emotion, while on social media it may signal completely the opposite as in "Frigging great song. Sick band too." Given these limitations of a lexicon-based approach, PEARL unavoidably limits its emotion analysis accuracy.</p><p>Data Source. PEARL currently uses only a person's social media text to infer his/her emotions. It does not take into account any other information, such as the person's social network structure. As our users pointed out, such information may help improve emotion analysis (e.g., the same emotional feeling tends to spread across one's social network) especially when an individual's linguistic evidence is inadequate to infer one's emotions confidently.</p><p>Scalability.</p><p>Currently, PEARL assumes that it can process a person's all social media text at once. This may not be realistic if a person has a very large set of linguistic footprints (e.g., hundreds of thousands of tweets or other types of text). To handle such cases, PEARL needs to be improved to support incremental analysis of text input to handle large, changing data set with reasonable response time.</p><p>Reliability. Although our study results indicated that PEARL can achieve adequate accuracies compared to the ground truth gathered from selfreflection tasks, emotion or mood is still a fuzzy and often difficult concept for users to grasp. To better assess the reliability of PEARL analytic engine, we need to evaluate our work with a significant larger number of users, including collecting ground truth from a more general and broader population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Future Extensions</head><p>There are several interesting directions to extend and improve the current version of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improvements in Analysis Engine.</head><p>To overcome the limitations of our lexicon-based approach, we are exploring other approaches to improve the overall performance of emotion analysis. For example, we are experimenting with n-grams and the use of a person's social network to achieve better emotion analysis results. Moreover, we wish to infer complex emotions in addition to the eight primary emotions in Plutchik's model <ref type="bibr" target="#b28">[29]</ref>.</p><p>Emotion Analysis of Groups.</p><p>Currently PEARL supports only visual analysis of individuals' but not a group's emotions. For example, one of our study participants mentioned: "I am wondering if I can group a bunch of influencers to see the aggregated emotions, because their influence could be important to determine the emotion status of the overall network". However, supporting emotion analysis of a group is non-trivial as PEARL needs to aggregate the already complex, multi-dimensional emotion analysis results of individuals in a sensible way and visualize the aggregated results.</p><p>Real-Time Analysis. A person's emotions often fluctuate during human-human interactions, such as during contact center calls. The ability to support real-time emotion monitoring and analysis from text will definitely facilitate such interactions. For example, such ability will help guide an online chat session between a customer representative and a customer. PEARL thus must be able to infer a person's emotions incrementally based on the person's text input and visually explains the results. Such real-time emotion analysis can also be integrated with speech transcription technologies to support real-time conversation analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We have presented an interactive visual analytic tool, called PEARL, which aids users in multi-dimensional emotion analysis from text. Specifically, PEARL automatically analyzes a person's tweets and infers the person's emotional episodes at discrete time points, moods over extended time periods, and temporal patterns of these emotions and moods. It then visually summarizes the complex, multidimensional emotion analysis results to create a timeline-based visual emotional profile of the person. In addition, PEARL allows users to interact with the created visual emotional profile to further investigate the person's emotions from multiple perspectives (e.g., observing emotional outlook and volatility, and discovering extreme emotions). To help users validate the emotion analysis results and compensate for imperfections in the analytics, PEARL also allows users to interactively examine linguistic evidence used to derive the person's emotions, moods, and triggers that invoke such emotions.</p><p>To demonstrate the value of PEARL, we have designed and conducted a series of studies. First, our ground-truth gathering study verified the adequacy of PEARL's emotion analytics, as the participants' self-assessed emotions matched well with those derived by PEARL. We then designed and conducted two user studies, evaluating the effectiveness of PEARL in support of self-reflection and third-party emotion analysis through a participatory interview study with 6 users and an online survey study with 50 workers from Amazon Mechanical Turk, respectively. The results of both studies were very encouraging as they showed the effectiveness of PEARL in support of users' real-world emotion analysis tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Overview of the PEARL system architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>The PEARL user interface consists of several interactively coordinated views: (a) emotional profile overview, (b) emotional profile detail view, (c) mood word view, and (d) raw tweets view. The overview and detail views are coupled with direct manipulations of (e) a time window. A toolbar on top contains a search box, (f) an action menu, for (j) highlighting important data points, and (g) an interactive legend, for data filtering. PEARL also provides (i) informative tooltips on many of the visualization elements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>PEARL visualizes personal emotions using the metaphors of bands and bubbles: (a) aggregated view, and (b) split view with the green "fear" emotion filtered out. When a user hovers over an emotion bubble of the selected mood, such as "joy" in (b), brushing and linking techniques are applied to (c) the mood word view and (d) the raw tweets view to indicate related visual elements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Cohen's Kappa test results of agreements between the ground truth and PEARL's output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>[After hovering over different individual bands], I would say, anger is the least [part of my emotion], just a little red." Also, participants found PEARL can help them assess how emotionally resilient they are. For example, P6 commented: "[After pushing on the 'resilience' button,] I saw a highlighted segment [on the timeline]. Hmm, this is an interesting example. You see here I broke my foot during mountain hiking, and was taken down with an emergency chopper. It [PEARL] captured my mood down here and went up here quickly. You see the tweets, 'recovery in progress!'. It does make sense to show how I recovered from setbacks." (Figure 6).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Average accuracy of Mechanical Turk survey results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The system is useful as it helps me detect one's emotional patterns over time.5.84 1.13 Q2. The system is usable as I can finish the above analytical tasks easily. 5.32 1.39 Q3. The system is intuitive in its visual representations and interactions. 5.81 0.98 Q4. I can better understand the abstract concepts of emotions with the interface. 5.75 1.19 Q5. I can easily tell a person's emotional styles by exploring the data. 5.68 1.08 Q6. The functions of showing relevant tweets and emotional words are helpful for me to understand the derived emotional states. 5.41 1.27 Questionnaire results of the Mechanical Turk study</figDesc><table><row><cell>Question</cell><cell>Mean SD</cell></row><row><cell>Q1.</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We would like to thank all the users who participated in our studies, especially ones who contributed and annotated their tweets. We also wish to thank Rorik Henrikson from University of Toronto for narrating the accompanying video of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Eventscapes: visualizing events over time with emotive facets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM international conference on Multimedia, MM &apos;11</title>
		<meeting>the 19th ACM international conference on Multimedia, MM &apos;11</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1477" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Semiology of Graphics: Diagrams, Networks, Maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bertin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>University of Wisconsin Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling public mood and emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l AAAI Conference on Weblogs and Social Media, ICSWSM&apos;11</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="450" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">D3: Data-driven documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Affective norms for english words (anew) instruction manual and affective ratings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lang</surname></persName>
		</author>
		<idno>c-1</idno>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>The Center for Research in Psychophysiology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Statistical affect detection in collaborative chat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuksenok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Torkildson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Anicello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zukowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Aragon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on Computer supported cooperative work, CSCW &apos;13</title>
		<meeting>the 2013 conference on Computer supported cooperative work, CSCW &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="317" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Emotions in text: Dimensional and categorical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Mac</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="527" to="543" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Emotion scents: a method of representing user emotions on gui widgets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cernea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kerren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE: Visualization and Data Analysis</title>
		<meeting>SPIE: Visualization and Data Analysis</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">8654</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Textflow: Towards better understanding of evolving topics in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2412" to="2421" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The Emotional Life of Your Brain: How Its Unique Patterns Affect the Way You Think, Feel, and Live-and How You Can Change Them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Begley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Hudson Street Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A visual backchannel for large-scale events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gruen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1129" to="1138" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Leadline: Interactive visual analysis of text data through event identification and exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Skau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Visual Analytics Science and Technology, VAST&apos;12</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="93" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<title level="m">Emotions Revealed. Holt Paperbacks</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Opinion space: a scalable tool for browsing online comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Faridani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bitton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ryokai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;10</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1175" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Moods, emotion episodes and emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Frijda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Emotions</title>
		<editor>M. Lewis and J. M. Haviland</editor>
		<imprint>
			<publisher>Guilford Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="381" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">We feel fine and searching the emotional web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Kamvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM international conference on Web search and data mining, WSDM &apos;11</title>
		<meeting>the fourth ACM international conference on Web search and data mining, WSDM &apos;11</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="117" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multimodal affect recognition in learning environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual ACM International Conference on Multimedia, MULTIMEDIA &apos;05</title>
		<meeting>the 13th Annual ACM International Conference on Multimedia, MULTIMEDIA &apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="677" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Sentiment Analysis and Opinion Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The role of affect in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Loewenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lerner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of affective science</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Twitinfo: aggregating and visualizing microblogs for event exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Badar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Madden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;11</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;11</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Affectaura: an intelligent system for emotional memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcduff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roseway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Czerwinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;12</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="849" to="858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Basic Dimensions for a General Psychological Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mehrabian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Oelgeschlager,Gunn &amp; Hain Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Wordnet: A lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Pulse of the nation: U.s. mood throughout the day inferred from twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mislove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Onnela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rosenquist</surname></persName>
		</author>
		<ptr target="http://www.ccs.neu.edu/home/amislove/twittermood/" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Portable features for classifying emotional text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohammad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Emotions evoked by common words and phrases: using mechanical turk to create an emotion lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, CAAGET &apos;10</title>
		<meeting>the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, CAAGET &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="26" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Not all moods are created equal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Munmun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l AAAI Conference on Weblogs and Social Media, ICSWSM&apos;12</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Optimizing temporal topic segmentation for intelligent text visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 International Conference on Intelligent User Interfaces, IUI &apos;13</title>
		<meeting>the 2013 International Conference on Intelligent User Interfaces, IUI &apos;13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="339" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The nature of emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Plutchik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Scientist</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">344</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Core affect and the psychological construction of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="172" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A circumplex model of affect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1161" to="1178" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visualization of large hierarchical data by circle packing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;06</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="517" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Norms of valence, arousal, and dominance for 13,915 english lemmas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Warriner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kuperman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brysbaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Opinionseer: Interactive visualization of hotel customer feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1109" to="1118" />
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
