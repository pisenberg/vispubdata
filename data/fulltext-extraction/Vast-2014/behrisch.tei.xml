<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Michael</forename><surname>Behrisch</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Korkmaz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Shao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Tobias</forename><surname>Schreck</surname></persName>
						</author>
						<title level="a" type="main">Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>View Space Exploration Framework</term>
					<term>Interesting View Problem</term>
					<term>Relevance Feedback</term>
					<term>User Preference Model</term>
				</keywords>
			</textClass>
			<abstract>
				<p>The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user&apos;s preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user-and context-dependent visual exploration systems.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Our current data-agnostic society is driven by the prevalent perception that most data contains valuable information, which can be retrieved in a later information retrieval process. To this end, all kinds of data are stored and analyzed. The business consultancy McKinsey even forecasts that the "data scientist" will become one of the most important jobs in the US in the coming decade <ref type="bibr" target="#b23">[24]</ref>. While the collected data may be rich in information, it is still highly challenging identifying appropriate views on the data sets. As an example, an n-dimensional numeric data set allows to render (n × (n − 1)/2) distinctive views only by using a projection onto two distinctive dimension axis. This spans a large exploration space in which interesting views need to be identified. To make matters worse, the most valuable data views exists in relation with the users' current tasks, intentions, and current context.</p><p>A range of approaches to deal with the interesting view problem were developed over the years. For example, Focus+Context systems <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b2">3]</ref> lead the users in an overview to areas of interest and let them explore these areas with drill-down mechanisms. Focus+Context systems are an established and approved method, but often tend to be expert systems restricted to specific data set characteristics and/or user interactions. These systems potentially introduce misleading abstractions, which ultimately can lead to wrong exploration paths. Semantic zoom interfaces <ref type="bibr" target="#b4">[5]</ref> help also to deal with this problem. Here, the user explores the data set at varying levels of abstraction/detail, starting with a highly aggregated version of the underlying data. The more the user "zooms" into the data, the more details become assessable. Al-</p><p>• Michael Behrisch is with the Universität Konstanz, Germany. E-mail: michael.behrisch@uni-konstanz.de. • Fatih Korkmaz is with the Universität Konstanz, Germany. E-mail:</p><p>fatih.korkmaz@uni-konstanz.de. • Lin Shao is with the Universität Konstanz, Germany. E-mail:</p><p>lin.shao@uni-konstanz.de. • Tobias Schreck is with the Universität Konstanz, Germany. E-mail:</p><p>tobias.schreck@uni-konstanz.de.</p><p>ternatively, cluster-based navigation systems partition the exploration space into a range of distinctive clusters that are represented by a small amount of prototypes. Choosing the prototypes relates directly to the interesting views problem. A further well-understood, yet simple, approach to tackle the interesting views problem is to focus on faceted search algorithms that operate on the available meta data. This requires a manual annotation and insertion of meta data, which is often prone to errors or missing values. Directly related to the interesting views problem is that a query formulation <ref type="bibr" target="#b22">[23]</ref> on complex data sets is difficult. This is primarily due to the fact that the collected data sets are multivariate and highdimensional in nature. To tackle this problem, novel querying mechanisms, such as query-by-example or sketch-based interfaces were developed. Here, the systems rely on the assumption that users have a priori an initial understanding of the interesting patterns under investigation. This explicit definition of interest is time consuming, particularly if interest rules need to be updated during the exploration process.</p><p>In this paper we present a novel approach to the interesting view problem, which focuses on the interplay between the user and an automatic decision-support system. In an iterative work flow the user assesses whether a set of presented views are of interest or not. These views can be arbitrary, but suitable, visualizations for the highdimensional data exploration task at hand. A classification system learns from the previous user decisions, while notifying the user in case of potentially wrong decision paths and major decision path divergence. The general idea is inspired by multimedia retrieval approaches, where the user's explicit relevance feedback on retrieval results is used to recommend additional previously unseen results <ref type="bibr" target="#b22">[23]</ref>. In contrast to the major work in this field, the presented relevance feedback mechanism is incorporated into a feedback loop, which adapts to the earlier user decisions.</p><p>Our approach relies on the basic assumption that for most and even complex data visualizations a comprehensive set of feature vector descriptors can be found, either in the data-, in the image space or in a combination of the latter, that can be mapped to its analytic benefit.</p><p>The outlined approach has to be seen as a framework for an interactive relevance feedback driven data exploration process. One of the benefits of the framework is that a great variety of design alternatives can be applied without changing the fundamental approach. We are showing one reference implementation of the framework by using <ref type="figure">Fig. 1</ref>. The user interacts in the View Space Explorer by choosing relevant or irrelevant examples (4) from a small sample set. An incremental decision tree visualization (5) and a feature tube visualization (6) help to assess the exploration convergence. Specific decision support intervention points can be enabled/disabled in <ref type="bibr" target="#b2">(3)</ref>. Additional decision support notifications are shown in <ref type="bibr" target="#b7">(8)</ref>.</p><p>an incremental decision-tree classification to guide the user in a large scatter plot exploration space. However, it has to be mentioned that we are not restricting ourselves to scatter plot visualizations, but allow any type of visualization technique as long as a descriptive feature vector space can be found.</p><p>The remainder of the paper is structured as follows. In Section 2 we discuss related work. In Section 3 we introduce the general idea of the interactive relevance feedback driven data exploration framework. The following Section 4 describes our instantiation of the exploration framework and discusses the design decisions and alternatives. Section 5 details on the implementation of the decision support system and its implications, while Section 6 shows the visual interface for the view space exploration. Next, in Section 7 we present the results of two case studies on real-life data. In Section 8 we discuss limitations and possible extensions. Finally, Section 9 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work relates to interactive and automatic approaches for view selection, relevance-driven information retrieval, and systems which capture user feedback to guide the analysis process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Interest-Driven Data Filtering for Visual Analysis</head><p>Methods for visual data analysis need to handle increasingly large data sets. As the data size grows, so does the space of data views, which are possible, given large data spaces and view parameters. Then, analysts run risk of overlooking interesting views if relying only on interactive navigation. To this end, intelligent methods for compressing and filtering data for potential patterns of interest has recently become a research focus. Overview-based approaches aim to generate effective layouts over many candidate data portions, to efficiently spot patterns of interest. Examples include the Value-and-Relation display <ref type="bibr" target="#b35">[36]</ref>, which lays out pixel-oriented views based on their data similarity. Another example is <ref type="bibr" target="#b32">[33]</ref>, where many time series are shown by small glyphs which are layed out based on data similarity.</p><p>Besides overview approaches, automatic filtering of views for potential structures of interest has been proposed. For scatter plots, the Scagnostics approach <ref type="bibr" target="#b33">[34]</ref> automatically analyzes structures in scatter plots, which can be used to rank and filter. Recently, a clusteringbased overview approach was presented in the ScagExplorer <ref type="bibr" target="#b7">[8]</ref>. In case class information is given, scatter plots can be filtered for dis-criminative views by class consistency measures <ref type="bibr" target="#b28">[29]</ref>. Also, projection pursuit approaches, such as initially presented by Friedman and Tukey <ref type="bibr" target="#b12">[13]</ref>, try to identify interesting 2D subspaces in highdimensional data (mostly depicted by scatter plot views). Further heuristic interestingness filters for Scatter-and Parallel Coordinate plots have been discussed in <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b8">9]</ref> and may narrow down the potentially large search space for high-dimensional data. In <ref type="bibr" target="#b31">[32]</ref>, an explorative overview of subspaces contained in high-dimensional data based on mutual differences and clustering quality properties was introduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relevance-Driven and Image-Based Retrieval</head><p>In Information Retrieval, similar to Information Visualization, users search for relevant information, but often without being able to precisely specify the pattern they are looking for. In context of document retrieval, relevance feedback <ref type="bibr" target="#b1">[2]</ref> allows to incrementally refine the user query. Based on a set of example documents, users assign a degree of relevance on them, based on the context of their information need. This assignment information in turn is used to iterate the search, e.g., by query term expansion or by weighting of query terms, based on the subset of relevant documents. This mechanism abstracts from the specific query formulation by the user, but may implicitly capture the user information need. Relevance feedback methods have also been intensively applied in content-based image retrieval <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30]</ref> and shown to improve the retrieval performance.</p><p>Many image retrieval systems so far rely on low-level image features, such as color histograms, edge histograms, or texture measures <ref type="bibr" target="#b9">[10]</ref>, which are heuristically combined to form distance functions. Relevance feedback methods for image retrieval may operate on these low-level feature representations in various ways. One option is to construct a new query vector by averaging the feature vectors of all image examples marked by the user as relevant. Another option is to train a classifier (e.g., SVM or Decision Tree <ref type="bibr" target="#b13">[14]</ref>) from the set of relevance information provided by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relevance-Driven Analytics and Distinction of our Work</head><p>According to our observation, the majority of Visual Analytics approaches which incorporate interest-driven data filtering rely either on a) fixed heuristics for fully automatic filtering, or b) on fully interactive filter specification by users. However, fixed heuristics may not necessarily map to a given users' information need, which may depend on data and context. Moreover, fully interactive search may not be feasible due to large search spaces. Surprisingly few works provide user-adaptive data filtering heuristics. In <ref type="bibr" target="#b21">[22]</ref>, intelligent visual analytics queries are proposed. The user marks a section within a given visualization as interesting; the system then computes certain distribution measures given in the data section, and automatically retrieves similar data segments from a larger database. The assumption is that the additionally retrieved data will add to the user information need. In <ref type="bibr" target="#b15">[16]</ref>, user data navigation is supported by a Bayes classification approach. The method learns to distinguish between interesting and uninteresting data sections while users pan and zoom an information landscape. The classifier is then utilized to suggest navigation paths of interest to a given user.</p><p>Two further recent works exploit user interaction to improve the analysis process. In <ref type="bibr" target="#b3">[4]</ref>, users interact by with the marks in a 2D projection of high-dimensional data, to express their notion of data correspondences. This input is used to adapt the data similarity function and re-project the data. Along similar lines, the approach in <ref type="bibr" target="#b11">[12]</ref> allows users to interact with the positioning of documents in a 2D document landscape collection, to express document-level relationships. The system then learns and highlights the document terms which are most descriptive of the expressed document relationships.</p><p>In our approach, we apply ideas of relevance feedback-driven image retrieval to the problem of exploring large view spaces. Based on user examples, a decision tree is trained to identify additional interesting views based on Scagnostics features. We instantiate the approach for scatter plots described with Scagnostics features. Our approach is novel in that we a) introduce the concept of relevance feedback to scatter plot exploration, and b) that we make explicit the gained knowledge by a decision tree, which is used to guide and monitor the user exploration process. In that, our approach is related to <ref type="bibr" target="#b15">[16]</ref> where a Bayes classifier is used to navigate a 2D information landscape. Our approach differs from <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12]</ref> in that the latter works consider user feedback in one single 2D view of the data, which is continuously updated. We here aim at retrieving sets of relevant 2D views in an iterative process. Furthermore, we do not update a data similarity function but use a Decision Tree classifier to capture user feedback and expressed interestingness relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Framework for Feedback-Driven View Exploration</head><p>The basic idea of a feedback-driven view exploration approach is to put users into a steering position to determine what they want. <ref type="figure">Fig-ure</ref> 2 outlines the main work flow in the semi-automated exploration process. In a normal sequence of actions the user chooses a data set under investigation and decides for a meaningful visualization to assess the underlying data. The framework uses an appropriate feature descriptor from the data-and/or the image space to represent the data. The resulting feature vectors are the basis for the visualizations. In case of a feature descriptor operating on the data space characteristics, such as the data distribution or compressibility, will be represented. An example would be to measure the convexity of a scatter plot. Image features will be used to reflect the visualization's -or depiction'scharacteristics. An example would be to measure the number of interest points for a real-world image. For the overall exploration the choice of the feature descriptor is crucial, since every descriptor is only capable of reflecting certain characteristics of the underlying data.  <ref type="formula">3</ref>The user annotates this set for interesting, respectively uninteresting, views (AS + versus AS − ).</p><p>(4) A classifier learns a mapping of the exploration set into potentially interesting views (CS + ), respectively uninteresting views (CS − ).</p><p>As <ref type="figure" target="#fig_1">Figure 3</ref> depicts, from a potentially very large exploration set, denoted as ES, only a limited amount of visualizations can be presented initially to the user. We will denote this subset as the representation set RS. The choice of the items in RS can be random, deterministic, or iteratively adaptable (cf. Section 5). In the general feedbackdriven view exploration framework the representation choice adapts according to the user's decisions. In an exploratory search phase a uniformly distributed sample should be made available, while in a confirmatory search only subpopulations of ES need to be presented. Generally, users might not be able to manually assess the entire data set. Hence, after a broad beginning only parts of the exploration space will be presented to the user. From RS the users can either choose visualizations of interest or express their dislike. Thus, an implicit knowledge gets explicitly available and accessible to the framework. A model learner is used to reflect the expressed user preferences by classifying the unseen items in ES as potentially relevant, denoted as CS + , or potentially irrelevant, denoted as CS − . We can assess the model learner's (un-)certainty in the classification. Relevant and irrelevant items can be matched to both classification sets CS + and CS − to find visualizations with an (un-)certain interestingness mapping.</p><p>The task is now to find a good mapping f : ES → RS, such that the user on the one hand will find interesting patterns and on the other hand is still able to explore the dataset without loosing too many details. A secondary goal is to let the user iterate only a few times through the feedback loop.</p><p>Another basic idea of the feedback-driven view exploration framework is that user decisions should have an impact on the exploration. Hence, the task of a decision support system, as described in Section 5, is to assess the stability and convergence of the exploration path. <ref type="figure">Figure</ref> 4 outlines potential intervention points in the feedback-driven view exploration framework. As an example, the choice of the data set implies a (feature-based) modeling of the data. While this choice might be appropriate in an early exploration phase, it might be too restrictive, respectively broad, in the later phases. Thus, it might be beneficial to switch from a scatter plot visualization view to a parallel coordinate visualization with an appropriate modeling scheme. One heuristic for this recommendation could be that the exploration path stays rather unspecific and does not converge even after a number of iterations. Another intervention point is the outcome of the model learner. Here, the decision support acts as a supervision instance, which, e.g, allows assessing the certainty of the classification subsystem.</p><p>Name Bild: DecisionSupportIntervention <ref type="figure">Fig. 4</ref>. The Decision Support can change essential parameters in the Relevance Feedback Driven View Exploration Framework if the exploration convergence stagnates: For example, it can recommend switching to a more appropriate visualization type with an appropriate modeling scheme or ask for a confidence score if the user annotation is obviously misleading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Exemplified Instantiation of Feedback-Driven View Exploration Framework</head><p>In the following section we want to present one instantiation of the general semi-automatic exploration work flow from Section 3. In each of the following sections we will outline the overall idea for the respective work flow step, describe the current implementation and reflect our design rationale by describing alternatives and further prospects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Visualization</head><p>The general idea of the Visualization step is to illustrate the given exploration set (ES) in a reasonable manner. This step initiates our framework's interaction pipeline in <ref type="figure" target="#fig_0">Figure 2</ref>. The choice of the visualization technique is important and depends on the given data set. Effective visualizations help in the decision-making process, while reading ineffective visualizations can be time-consuming and potentially leads to wrong decisions. In our exemplified instantiation of the feedback-driven view exploration framework we use scatter plot visualizations to represent a continuous high-dimensional data set. The choice of this visualization has several reasons. First of all, scatter plots prove to be powerful and intuitive visualizations for user decisions. They are used in a large variety of domains and are familiar to most users. Second, we can separate the high-dimensional data set into individual plots allowing the user to judge the importance over all pairwise dimension combinations.</p><p>As mentioned above, the choice of the visualization technique depends on the data set under consideration. In our case, scatter plots are appropriate, but in case of other data types, such as temporal, hierarchical or textual data, alternative visualization techniques are better suited for the view space exploration in our pipeline. To name just a few alternative examples, line charts are suitable for temporal data, treemaps can represent hierarchical data, and word clouds can be used to depict text content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Modeling</head><p>The general idea of the Modeling step is to characterize all visualizations of the exploration set ES and to compute a uniform model for the Model Learning step (cf. Section 4.5). It computes a feature-based vector for every visualization. By this means, the similarity for each individual visualization can be automatically compared and used for further sampling or classification methods.</p><p>We decided to use the Scagnostics approach <ref type="bibr" target="#b33">[34]</ref> to characterize the scatter plot contents, since it is capable of describing point distributions by meaningful measures. This approach extracts a nine dimensional feature vector characterizing the scatter plots for: outlying, skewed, clumpy, convex, skinny, striated, stringy, straight, and monotonic features. These measures can characterize the shape of scatter plots well. Thus, the decision classifier can identify the user's preferences in the form of "find more dense" or "find highly coherent scatter plots".</p><p>Depending on the chosen visualization (cf. Section 4.1), different descriptors have to be used to extract feature vectors. While, Kernel Density Estimators or Regressional features could be used to extract suitable features for scatter plot point distributions, image-based descriptors will be more appropriate to describe real world images. In the case of structure conveying visualizations, such as treemaps or matrices, one option is to apply an Edge-Histogram Descriptor or line extraction algorithm <ref type="bibr" target="#b10">[11]</ref> to describe the general shape of the visualizations content. For text visualizations, a dictionary-based approach can be applied to compare the textual content inside visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Representatives</head><p>The general idea of the Representatives step is to select a manageable number of items from the exploration set ES. This presentation set, denoted as RS, is presented and judged by the user. Hence, its functionality highly influences the exploration process. The selection procedure is exchangeable in our implementation of the view space exploration pipeline.</p><p>In the current implementation, we are experimenting with contentbased sampling-based approaches, such as discussed in <ref type="bibr" target="#b14">[15]</ref>, to select a range of items in ES. A Min-/Max sampling option selects two representatives for each of the feature value ranges (cf. Section 4.2). For the Scagnostics example, 18 representatives can be judged by the user: two items (one min-value and one max-value representative) for each of the nine Scagnostics features. To increase the number of items in RS and to reflect the data distribution, a quantile sampling, a (stratified) bootstrapping and a stratified normal sampling method can be applied. The user can select how many items should be retrieved, resulting in | f eatures| × requestedSamplingItems items in RS.</p><p>One reason to apply sampling is that RS is available instantaneously without much computational effort. One obvious disadvantage is that the sampling potentially shows a series of outliers in the data distribution. However, this effect can be neglected in case of the quantile sampling method (amountQuantiles &gt; 2).</p><p>As stated above further design alternatives are possible and may be considered if the representation items are not perceived as appropriate. One computational expensive solution would be to apply a densitybased clustering in every projection pane of the feature space. N modeling features would lead then to N projection panes. From the clustering results a range of representatives could be selected by choosing, e.g., the medoid of the found clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Relevance Feedback</head><p>The general idea of the Relevance Feedback mechanism in a semiautomatic exploration pipeline is to give the user the ability to steer the retrieval process. The user can categorize the presented items into relevant, irrelevant, and neutral examples. Relevant annotated items, denoted as AS + , represent potential hits for the search process. Irrelevant examples, denoted as AS − , depict items that lead to wrong or uninteresting search paths.</p><p>In the current implementation, depicted in <ref type="figure">Figure 1</ref>, the user can click on green and red buttons to express his like, respectively dislike.</p><p>Alternatively to the binary decision approach, a weighted relevance feedback could be implemented for finer granularity assessment of the user feedback. In this case, the users would have to judge the interestingness of the presented items in terms of a linear scale. Also a star rating, as it is known from product reviews, would be possible. We decided against a weighted relevance feedback system, since these kinds of decisions might be hard to judge for the user in the beginning of the exploration process and involve additional interaction overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Model Learning</head><p>The goal of the Model Learning step is to reflect the user's preferences. In the best case, the system learns the user's intention after only one iteration and retrieves only positive examples. The worst case scenario is that the model learning cannot grasp the user's intention after a finite number of steps, leading to always negative examples. The pipeline would then iterate until all irrelevant items are excluded and only relevant examples are left. Hence, the search eventually converges.</p><p>A model learner has to be able to revise and refine previous decisions. Whenever the system restricts existing decisions we assume that the user also refined his/her understanding of the explored items. Thus, we assume that the exploration path is "correct". On the other hand, a revision of existing decisions corresponds to a potentially "wrong" exploration path. . Potentially wrong decisions are intercepted by the decision support system to keep the model learning in a consistent state. The outcome of each decision can be anticipated without applying it to the model learner by using the quick-check functionality button.</p><p>On top of the exploration steering function of this component we put another prerequisite on the system: It should externalize its decisions in a visual depiction (cf. Section 6.2). In our current implementation we decided to use a classification system to approximate the user's preferences. Our model learner is inspired by the idea of an iterative decision tree, such as presented in <ref type="bibr" target="#b34">[35]</ref>. In contrast to a normal decision tree, iterative decision trees retain most of its structure after the initial training. This allows the user to perceive the structural development over time and can only be achieved if a fundamental confinement of the decision tree algorithms gets derestrict: Nodes corresponding to a parameter (-range) can occur multiple times in the same decision tree. However, in line with the decision tree logic, these multiple occurrences may not violate already applied range restrictions (value &gt; 0.5 leads to yes, but also value ≤ 0.5 should lead to yes).</p><p>In a standard course of action, we are expanding the decision leafs in each learning iteration of the pipeline. We are differentiating between outer decisions and inner decisions. While outer decisions modify the outer boundary of the decision space formed by the n selected features (cf. Section 4.2), inner decisions lead to subareas in the already excluded/included decision space, which should be included, respectively excluded, from the search.</p><p>For outer decisions two cases are possible without violating the idea of a decision tree: 1) A yes node, representing a set of relevant classified items, on a yes path gets split up. In this case, the user found that the classification is too unspecific and should be narrowed. One example for this case is shown in <ref type="figure" target="#fig_0">Figure 12 (c)</ref>, where the monotonic feature range was modified from [0.09, 1.0] to [0.12, 1.0]. 2) A no node,representing a set of irrelevant classified items, on a no path gets split up. In this case, the user found that the classification is too specific and should be broaden.</p><p>Inner decisions are improving constraints set in earlier decisions. Here, also two alternatives are possible without violating the decision tree idea: 1) A no node on a yes path gets split up. In this case the user found that learned constraint is limiting the exploration and should be made less restrictive. 2) A yes node on a no path gets split up. In this case the user found that learned constraint was not restrictive enough and should be strengthened. One example for this case is shown in <ref type="figure" target="#fig_0">Figure 12 (c)</ref>, where a monotonic value above 0.006 alone would lead to a positive classification. This classification gets restricted by the sparsity feature descriptor below 0.11. In both presented cases of an inner decision parallel decision paths, or split-ups, could be a result.</p><p>Alternatively, adaptive learning systems could be applied to learn the user preference model. Here, for example multi-agent learners, such as presented in <ref type="bibr" target="#b26">[27]</ref> could incorporate likelihood considerations into the learning process, which would be beneficial if many views show similar content. The application of neural networks, such as presented in <ref type="bibr" target="#b36">[37]</ref>, could be an alternative. Both mentioned model learners are able to learn non-linear decision boundaries in high-dimensional decision spaces. We decided against these sophisticated methods due to the following reasons: 1) They mostly cannot meet our prerequisite of being visually interpretable/traceable. 2) Their application would lead to immense computational efforts and results in long waiting times for the users. 3) Many of these approaches require a full training <ref type="figure">Fig. 6</ref>. Additional meaningful decisions can be recommended to the user by retrieving the most similar scatter plots to the already relevant, respectively irrelevant, annotated views.</p><p>after each of the user decisions. Support-Vector machine classification has been considered, but is not yet implemented. Here, visual depictions are available, such as presented in <ref type="bibr" target="#b16">[17]</ref>. The training process is more complex than with the presented approach, but still feasible and a full training is not always necessary as <ref type="bibr" target="#b5">[6]</ref> demonstrates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Enhanced Decision Support for Feedback-Driven View Exploration</head><p>One of the primary advantages of the presented exploration framework (cf. Section 3) is that it allows for an automatic supervision of the exploration process. This supervision can be used to investigate and monitor the actions taken by the user. Thus, it becomes possible to make use of a user feedback loop whenever an action is not meaningful, potentially incorrect, or could be improved on the fly.</p><p>Users are notified about a potential intervention with the help of dialogs. These dialogs contrast the current user selection with an automatically created suggestion. Most importantly, the decision support system forecasts both options' outcome and presents them to the user.</p><p>In the case of conflicting decisions (cf. Section 5.1) between the user and the decision support system, the user decision are preferred to the algorithmic decisions.</p><p>In the following we are referring to our implementation of the feedback-driven view exploration framework as it is described in Section 4. Specifically, we are rendering scatter plot visualizations modeled/described by the scagnostic feature set. We are applying a sampling-based approach to find representatives. The user gives binary feedback, whether an item is relevant or rather irrelevant; the incremental decision tree algorithm classifies the exploration set ES into positive CS + and negative classified items CS − .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Handling Potentially Wrong Feedback Decisions</head><p>Decisions are ambiguous and potentially wrong if the same view (scatter plot) has been marked both irrelevant and relevant in the current iteration. In both cases the user has to revise and disambiguate the current decision in an Error Dialog, depicted in <ref type="figure" target="#fig_2">Figure 5</ref>.</p><p>The error dialog allows previewing the decision outcome with the help of a quick check functionality. Its purpose is to anticipate the CS + and CS − outcome without applying the decisions to the classification model learner.</p><p>If this kind of error occurs multiple times the decision support system suggests enabling an auto-highlighting functionality that keeps track of the annotation sets and holds them in a consistent state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Handling Missing Decisions</head><p>Missing decisions can occur whenever the same scatter plot is shown multiple times in one presentation set and the user marks a scatter plot as relevant, respectively irrelevant, but does not apply the same choice on the second occurrence of the scatter plot. Multiple occurrences can happen, e.g., when applying sampling-based representation finding approaches on a small data set. In case of Min-/Max sampling, multiple presentations of the same item are even likely and cannot be ruled out. The decision support system keeps track of these missing values and fills them automatically to retain a consistent learning model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Recommending Additional Decisions</head><p>The decision support system is able to do more than a mere failure handling. If the user is satisfied with her/his relevance feedback in one iteration, the intra-presentation set similarity to the positive and negative examples is calculated. If the similarity for an unannotated scatter plot is high to one of the items in AS + or AS − it becomes an annotation candidate for the respective annotation set. More specifically, we are calculating for every view in AS + and AS − a ranked list of similar views from ES. We are using the Euclidean distance on the Scagnostics feature vectors for calculating the similarity score. These ranking lists are unified for each annotation class by taking into account (a) a minimum similarity threshold -since we want to show only highly similar views-and (b) the potential reoccurrence of one view in the candidate lists -since we want to eliminate duplicate candidate views. The outcome of including annotation candidates into AS + and AS − are presented to the user in the query-expansion dialog shown in <ref type="figure">Figure 6</ref>. Here again, the user has the functionality to anticipate (quick-check) the results without applying them to the model learner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Exploration Set Expansion</head><p>Another decision support system functionality aims at assessing the search stability and convergence. For example, if the decision tree classifies more than 50% (user-parameter) of ES as irrelevant in the first iteration a great variety of potential scatter plot patterns may be lost. If the selected parameter is exceeded, the decision support system evaluates the classification certainty by comparing all irrelevant classified items (CS − ) to the items in the annotation set AS + and AS − . We construct a certainty ranking for all items in CS − . Again, we are using the Euclidean distance on the Scagnostics feature vectors for calculating the ranking score. The subset of items in CS − that have a distance higher than an adaptive threshold are treated as uncertain classification decisions and may be taken again into the exploration set ES for a further refinement. The certainty threshold increases with the number of feedback iterations. In other words, the fewer decisions have been taken by the user the less uncertainty is accepted. <ref type="figure" target="#fig_3">Figure 7</ref> shows the exploration set expansion dialog. A histogram view shows the number of (un-)certain decisions. If the classifier eliminates a great variety of scatter plot patterns (red bars), the user may decide to retain uncertain scatter plots. Uncertain decisions correspond to the scatter plots whose distance to the negative annotated set is larger than an adaptive certainty threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">View Space Explorer</head><p>In the following we will describe our graphical user interface for the Feedback-Driven View Exploration Framework. <ref type="figure">Figure 1</ref> depicts the visual interface, consisting of the View Explorer, the primary interaction component, and a range of meta visualizations, which help to track changes in the exploration process. <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">View Explorer</head><p>The View Explorer displays the presentation set RS to the user. It is depicted in <ref type="figure">Figure 1 (4)</ref>. The scatter plot selection process is described in Section 4.3. The displayed views are ordered according to the feature descriptor and the selected sampling method; i.e. for each applied feature descriptor one high and one low value in the case of Min-/Max sampling. While an alternative option would have been to <ref type="figure">Fig. 9</ref>. Users can annotate scatter plot views as uninteresting, neutral, or interesting with the red, white or green buttons. A tool tip shows that the view was selected into the presentation set RS, since its outlying value is in the 2 nd quantile of the respective feature range. sort the views according to their feature vector similarity, the applied ordering allows perceiving the feature descriptor's value ranges more effectively. A detail view for the user annotation options is depicted in <ref type="figure">Figure 9</ref>. A tool tip shows, next to the scatter plot's id and its axis metadata, a visual indication of the sampling set choice; the circled number represents the selected 2 nd quantile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Meta Visualizations</head><p>Two meta visualizations help the user to assess if an exploration path leads to a convergence (only interesting views). On top of that, the decision support system uses the displayed data to quantitatively assess the exploration convergence.</p><p>Feature Tube: <ref type="figure" target="#fig_4">Figure 10</ref> shows the Feature Tube, a stacked histogram view per feature descriptor (cf. Section 4.2). The histograms are sorted in ascending order to reveal the feature's value distributions. The current decision path corresponds to an interval selection in the ndimensional feature space, where n is the number of features under consideration. In our case, nine Scagnostics feature histograms are rendered. We are showing the decision path by a tube overlay, highlighting the selected feature intervals of interest. The overlay can be used to assess the specificity of the search. A narrow tube relates to a highly specific query -potentially in an advanced status of the exploration process-while a broad tube shows that the exploration is unspecific. Selected intervals can vary in their density of contained items (or views). Dense/sparse intervals show that the current exploration specificity maps to many, respectively few, possible views. By perceiving the change of Feature Tube between two model learning phases, users are able to judge their exploration advancement. Brushing and Linking is used to retrieve a scatter plot selection from the view explorer in all feature histograms.   <ref type="figure" target="#fig_0">Figure 12</ref> shows the Incremental Decision Tree, a visualization for the current classifier decisions. In an incremental decision tree every framework iteration corresponds to one level of the decision tree: Level 1 decisions correspond to the projection of the n-dimensional decision space onto the one dimensional subspace of the corresponding classification attribute. Level 2 decisions span a confusion matrix, in which the true-positive (upper right) field corresponds to all positively classified items (CS + ), the true-negative field (lower left) corresponds to all negatively classified items (CS − ). The items in false-positive (upper left) and falsenegative (lower right) are potential mis-classifications and cannot be rejected without any reservation. Thus, they remain in the exploration set ES. Level decisions &gt; 2 can be depicted with a MDS projection of the pairwise item similarity. We use of the classical MDS implementation in MDSJ <ref type="bibr" target="#b24">[25]</ref> for our purposes. During the annotation phase the user sees the tree visualization, as depicted in <ref type="figure">Figure 1</ref>  <ref type="bibr" target="#b4">(5)</ref>. However, if the user wants to get more details about the model learner meta visualizations for the 1D, 2D and nD levels are shown in a dialog on top of the incremental decision tree <ref type="figure" target="#fig_0">(Figure 12</ref>). The purpose of these meta visualizations is to allow the user to interpret how many items the classifier rejected from the exploration. Furthermore, the user can perceive how many items where close to the calculated decision border.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Measures of Exploration Convergence</head><p>For a quantitative assessment of change in the exploration process we are quantitatively measuring the appearance development of the feature tube and the incremental decision tree visualization. For the feature tube we are storing the covered tube area for each pipeline iteration and calculate the areal difference of the two shapes. If the difference area decreases in two subsequent iterations, the search converges gradually and we are able to measure a convergence factor. If the area change stagnates or even increases the user did not advance in the view exploration. For the incremental decision tree, we are able to measure a binary convergence factor. Either, in the negative case the model learner returns the same decision tree several times (no further learning improvement) or new tree leafs need to be added (learning progress). If the classification training results in the same tree twice we are interpreting the result as an exploration stagnation.</p><p>A wide range of other convergence measurements are possible. The simplest is to relate the number of items in ES before and after an application of the classifier. Another option is to calculate a similarity value for the decision tree appearance before and after the application of the classifier, as e.g., presented for general tree structures in <ref type="bibr" target="#b18">[19]</ref>. However, this option can only be applied if the decision tree is built from scratch, rather than not incrementally. In the future we are planning to experiment with an adaptive convergence measure that takes multiple decision criteria into account. In all cases of a slow or stagnating convergence we are applying counter measurements to steer the exploration process. The first measurement is to intervene in the representation finding (cf. Section 4.3). In our case, we are changing the used sampling function. The next level of intervention is to increase the number of suggestions for annotation candidates (cf. Section 5.3).</p><p>While the number of suggestions decreases in the normal convergence cases, we are here boosting the lowest similarity, such that more (even less similar) items are recommended for annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Case Studies</head><p>To present the applicability of our View Space Explorer we showcase two exemplary exploration scenarios on two well-known, real-life numeric datasets: The Wine and the Communities and Crime data set, both from the UCI Machine Learning Repository <ref type="bibr" target="#b0">[1]</ref>. The two chosen datasets vary in size and complexity. We chose the wine dataset, because of its low number of scatter plot axis combinations and thus its understandability. This allows us to focus on the decision support's interventions in the exploration process. The second dataset (communities) is significantly more complex in the number of dimensions and allows us to focus -next to the presentation of (hidden) patterns-on the convergence development like it is necessary for information retrieval systems. We conducted our case studies with Ph.D. and Master students from the computer science area.</p><p>In the case studies we are searching for correlations in the axis combinations. The exploration of data correlations is challenging, since users must be able to describe the correlation to be found. In the feedback-driven view exploration approach we assume that users do not know in advance, which (Scagnostic) feature might be beneficial for the current question.</p><p>Wine Data Set The Wine data set results from a chemical analysis of 178 wines sub-categorized into three classes (red, white, rose wines). In total the dataset comprises 14 numeric continuous attributes, such as alcoholic strength, color intensity, or magnesium. We derived 90 axis combinations and converted them to scatter plots -short SPs-with 178 data points each. <ref type="figure" target="#fig_7">Figure 11</ref> shows us a sequence of interactions on the wine dataset. In the first iteration <ref type="figure" target="#fig_7">(Figure 11 (a)</ref>) the user annotated four relevant and six irrelevant SPs from 24 initially presented SPs. The presentation set RS results from a normal bootstrapping sampling of the initial 90 SPs. A review of the four relevant annotated SPs shows that they share a high monotonic value. Satisfied with the first annotation round the user clicks on Apply and sees a dialog, in which the decision support recommends adding 15 SPs to AS + and 68 SPs to AS − <ref type="figure" target="#fig_7">(Figure 11</ref> (b) background). The user declines both recommendations. Hence, the classifier is trained on the initial annotation set and results in 27 positively and 63 negatively classified SPs. A review of the classification uncertainty shows that all decisions were certain <ref type="figure" target="#fig_7">(Figure 11</ref> (b) front). Thus, the user can assume that no SP is lost due to a misclassification. The feature tube reveals that the highest concentration is in the monotonic value. It appears to be beneficial to choose SPs with a high monotonic value for this task. In the second feedback round the user selects seven relevant and six irrelevant SPs and the decision support recommends adding one relevant and four irrelevant SPs. Once again the user declines all recommendations. The subsequent classification results -again-in the same 27 positively and 63 negatively classified SPs. No more exploration progress is apparent and thus the user will see the same SPs in each subsequent feedback round. Accordingly,  the decision support switches the sampling method to "Stratified bootstrapping". In a final annotation round six relevant and five irrelevant SPs are chosen and the exploration finishes with 14 SPs.</p><p>In the 14 result SPs some patterns become visible <ref type="figure" target="#fig_7">(Figure 11 (c)</ref>). For example, the SPs 8 and 12 show that the wines' color is positively correlated with the amount of ash and the amount of flavonoids. A meta research reveals: "Flavonoids are antioxidant compounds found in plants, as well as tea, red wine and chocolate, . . . " <ref type="bibr" target="#b19">[20]</ref>.</p><p>Communities and Crime Data Set The Communities and Crime dataset combines socio-economic, law enforcement, and crime data for the US in the years 1990 to 1995. After a filtering of missing values the dataset contains 123 dimensions. All in all, 7002 scatter plots were generated from the possible axis combinations. <ref type="figure" target="#fig_0">Figure 12</ref> shows a sequence of actions on this data set. The final result of the exploration is given in <ref type="figure">Figure 1</ref>. Our goal is again to find hidden data correlations that can be semantically interpreted.</p><p>In order to decrease the exploration set not too much in an early exploration phase, the user selects SPs with a high skewness. This feature describes indirectly the data density and gives an intuition about the interrelation of two dimensions. As <ref type="figure" target="#fig_0">Figure 12</ref> (a) depicts, the user selects five relevant and six irrelevant SPs. Subsequently, the decision support recommends 2247 positive and 2045 negative SPs. This large amount of recommendations indicates that the decision support is uncertain about the exploration path direction. The user declines all recommendations and receives a classification uncertainty of 12.28% for the irrelevant classified SPs. Moreover, the uncertainty visualization in <ref type="figure" target="#fig_0">Figure 12</ref> (a -front) depicts that the majority of distances is significantly above the uncertainty threshold. Thus, the user decides to expand the exploration set with the uncertain SPs. All in all, the exploration set is reduced to 5251 SPs, leading to an exploration set decrease of 25.0%.</p><p>In the following second annotation round the user tries to narrow down the exploration and annotates thus six irrelevant and five relevant SPs with a stronger visible correlation. The annotation is depicted in <ref type="figure" target="#fig_0">Figure 12 (b)</ref>. Due to the reason that the recommendation threshold is adapted iteratively, a significantly lower amount of SPs (91 relevant; 344 irrelevant) gets recommended. However, the user once again declines all recommendations. In the subsequent certainty assessment the user sees that in 28.81% of the irrelevant classified decisions the classifier is uncertain. Hence, the user decides again to retain all uncertain scatter plots. All in all, the exploration set is reduced to 2536 SPs, leading to an exploration set decrease of 51.7%.</p><p>In the third annotation round, depicted in <ref type="figure" target="#fig_0">Figure 12</ref> (c), the user searches for SPs with a rather round scatter plot distribution, which relates to the Scagnostics convexity feature. Thus, the user annotates seven irrelevant and six relevant SPs and the decision support recommends adding one relevant and seven irrelevant SPs. One positive recommendation is accepted. The classification uncertainty is 34.12%. Accordingly, the exploration set is expanded with all uncertain SPs. All in all, the exploration set is reduced to 1900 SPs, leading to an exploration set decrease of 25.1%.</p><p>In the final annotation round the user chooses to filter SPs with a low density distribution, which relates to a strong skinny value. These dimension combinations often occur if a categorical value is related to a numeric value. Thus, six relevant and six irrelevant SPs are annotated. The decision support recommends adding 1 relevant SP. The classification uncertainty is 9.74%. In this annotation round the exploration set is not expanded anymore. All in all, the exploration set is reduced to 235 SPs, leading to an exploration set decrease of 87.6%. The search converges and we see the final result in <ref type="figure">Figure 1</ref>.</p><p>According to the result set depicted in <ref type="figure">Figure 1</ref> we can come to the following conclusions: First, we found that a high crime rate exists in areas, where the percentage of households with public assistance income is high. A similar correlation exists with the percentage of unemployment in these areas (SP A). Second, we found that in these areas the police budget is higher than in areas with a low crime rate (SP D). Third, we found that the police budget correlates with the number of police cars (SP B). Generally, SP C shows that more drug units exist the larger is the variety of drug types in that area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion and Extension</head><p>While our technique has proven useful, we have identified several areas where improvements or alternatives should be explored.</p><p>Firstly, we want to apply the view space exploration framework on data sets which allow for more than one meaningful visualization. As an example, we could represent the Wine or Communities and Crime data sets from Section 7 also with Parallel-Coordinate-Plots. This would allow representing different data aspects more prominently. In these cases, the view selection space will increase drastically, leading to new visualization and computation challenges. In line with this question we want to investigate when proven visualization techniques for building overviews without abstractions, esp. Scatterplot-, Parallel-Coordinate-, or Generalized Plot Matrices <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21]</ref>, can be outperformed with our iterative exploration approach. On the other hand, for arbitrary visualizations, which can not be represented in a small multiple manner, layout based approaches will not scale due to the screen space restrictions.</p><p>Secondly, we are already experimenting with a tight integration of the decision support system with the user feedback loop and the model learner. While the intervention process appears to improve the exploration, many alternatives to assess the search stability and convergence are possible. One particular research challenge is the degree of intervention in the process. Certain user groups might wish for guidance, others might feel uncomfortable with this supervision. Related to this question is that it might be beneficial to enhance Decision Support with a query negation function, allowing query suggestions, like 'Show non-correlated variables, instead of correlated'.</p><p>Thirdly, we are planning to experiment with implicit and finergranular relevance feedback mechanisms. Specifically, a range of design options becomes available, ranging from time-to-click measures  to eye-tracking approaches, to assess relevance of a view. It will also be interesting to explore, similar to the document term highlighting mechanism of <ref type="bibr" target="#b11">[12]</ref>, ways to highlight which local patterns would be responsible for a given scatter plot view being relevant for a user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>The interesting view problem is prevalent in visual data exploration approaches whenever the number of available data views to be investigated exceeds the user's willingness or ability to judge the views. While previous approaches centered around establishing effective overview abstractions to guide the user to interesting views, the focus is shifting to an automated calculation of interestingness. Whenever a proper definition of interestingness can be established it needs to be transformed into a quality measure. However, in most cases the formulation of interestingness is neither possible nor stable. Rather so, the understanding of interestingness develops in the sequence of actions taken on the data.</p><p>In this paper we motivate an iterative and interactive view space exploration approach that does not rely on any visual abstractions. We introduced a general feedback-driven view exploration framework in which a relevance feedback mechanism is applied to retrieve user preferences. On the automatic side, the system learns the user preferences and finds new interesting views by applying a classification on the data. The more the search advances, the more user preferences are learned and transformed to specific queries on the underlying data. To showcase our general ideas, we presented one instantiation of the feedback-driven view exploration framework. In this instantiation we render scatter plot visualizations modeled by the Scagnostic feature set. It has to be noted that the general idea is not limited to scatter plots, but allows rather any type of visualization technique as long as a descriptive feature vector space can be found. A sampling-based approach is used to find potential interesting views from an exploration set. In every interaction loop the exploration set is incrementally reduced by implicit queries resulting from the user's binary relevance feedback. An incremental decision tree algorithm classifies the exploration set into potentially relevant and irrelevant items. A novel decision support system is applied on top of the framework that supervises the decision process. It is used, on the one hand, to handle potentially inconsistencies in the annotation process and, on the other hand, to evaluate automatically the exploration convergence.</p><p>We evaluated our approach with a case-study driven evaluation, conducted to showcase its usefulness on two real-world data sets. The results reveal that our feedback-driven view space exploration framework shows to be effective and enhances the user understanding.</p><p>In conclusion, the presented feedback driven view space exploration framework serves as a basis for a range of visual analytics systems that allow tackling the interesting view problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>The interaction flow in the Feedback-Driven View Exploration Framework: The user chooses a dataset of interest. A meaningful visualization type is selected (automatically or manually). The underlying data is described by means of feature descriptors. A range of representatives are shown to the user, which are interactively tagged for their relevance in the exploration process. A model learner tries to reflect the user's preferences and shows a new representatives set to the user.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Four different sets are distinguished in the approach: (1) The exploration set ES contains all possible views. (2) A sampled version of the exploration set will be presented to the user (RS).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5. Potentially wrong decisions are intercepted by the decision support system to keep the model learning in a consistent state. The outcome of each decision can be anticipated without applying it to the model learner by using the quick-check functionality button.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>The classification system's certainty is assessed in the background.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 10 .</head><label>10</label><figDesc>The Feature Space Tube represents visually the exploration process advancements. A narrow tube overlays (right) corresponds to a highly specific query, while a broad tube (left) represents an unspecific exploration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 12 .</head><label>12</label><figDesc>(a) 1D decision on one classification attribute (b) 2D decision on two classification attributes (c) nD decision on n classification attributes The incremental decision tree allows assessing the complexity of the formulated exploration query. Additional meta visualizations depict the value distribution for 1D classification decisions (decision on one classification attribute), 2D decisions in a confusion matrix and nD decisions in a MDS projection of the classified items similarity. Incremental Decision Tree: Figure 1 (5) and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a) In the first annotation round the user selects four relevant and six irrelevevant scatter plots.(b) The decision support recommends adding a range of similar scatter plots to both annotation sets; After the classifier is trained all decisions are judged as certain.(c) The final result shows several data correlations. E.g. The amount of ash and flavoid influences a wine's color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 11 .</head><label>11</label><figDesc>Finding correlations in the Wine data set; After three annotation iterations the exploration set with initially 90 scatter plots is reduced to 14 scatter plots, containing the annotated data correlations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(a) First annotation round: The user selects five relevant and six irrelevevant scatter plots; The classifier uncertainty value is 12.28%; The exploration set is reduced to 5251 SPs. (b) Second annotation round: The user selects five relevant and six irrelevevant scatter plots; The classifier uncertainty value is 21.96%; The exploration set is reduced to 2536 SPs. (c) Third annotation round: The user selects six relevant and seven irrelevevant scatter plots; The classifier uncertainty value is 34.12%; The exploration set is reduced to 1900 SPs. (d) Fourth annotation round: The user selects six relevant and six irrelevevant scatter plots; The classifier uncertainty value is 9.74%; The exploration set is reduced to 235 SPs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Finding correlations in the Communities and Crime data set; After four annotation rounds the exploration set with 7002 scatter plots is reduced to 235 scatter plots, containing data correlations.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">A video showing the functional components and the main interaction work flow is available in the supplementary material.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">University of California (UCI) machine learning repository. Online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<ptr target="http://archive.ics.uci.edu/ml/" />
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m">Modern Information Retrieval -the concepts and technology behind search</title>
		<meeting><address><addrLine>Harlow, England</addrLine></address></meeting>
		<imprint>
			<publisher>Pearson Education Ltd</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Second edition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Focus plus context screens: Combining display technology with visualization techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, UIST &apos;01</title>
		<meeting>the 14th Annual ACM Symposium on User Interface Software and Technology, UIST &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dis-function: Learning distance functions interactively</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology (VAST), 2012 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2012-10" />
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Readings in information visualization: using vision to think</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incremental and decremental support vector machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cauwenberghs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="409" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Visualizing Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Cleveland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Hobart Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ScagExplorer: Exploring Scatterplots by Their Scagnostics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Visualization Symposium (PacificVis)</title>
		<imprint>
			<date type="published" when="2014-03" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pargnostics: Screen-space metrics for parallel coordinates. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kosara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1017" to="1026" />
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Features for image retrieval: an experimental comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="107" />
			<date type="published" when="2008-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Use of the hough transformation to detect lines and curves in pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="15" />
			<date type="published" when="1972-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semantic interaction for visual text analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Endert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, CHI &apos;12</title>
		<meeting>the 2012 ACM annual conference on Human Factors in Computing Systems, CHI &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="473" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A projection pursuit algorithm for exploratory data analysis. Computers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tukey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="881" to="890" />
			<date type="published" when="1974-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Data Mining: Concepts and Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Elsevier Ltd</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Data Mining: Concepts and Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Interest driven navigation in visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Dennis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1744" to="1756" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Visual classifier training for text document retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2839" to="2848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The parallel coordinates matrix. EuroVis-Short Papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="37" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual exploration of parameter influence on phylogenetic trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bremm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weissgraeber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hamacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goesele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Von Landesberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2014" />
			<publisher>PrePrints</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Chocolate and red wine can help stave off diabetes: High levels of antioxidants can regulate blood glucose levels. Online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hope</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-01-29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gplom: The generalized plot matrix for visualizing multidimensional multivariate data. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Im</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mcguffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2606" to="2614" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Intelligent Visual Analytics Queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Morent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneidewind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Dayal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Analytics Science and Technology</title>
		<meeting>the IEEE Symposium on Visual Analytics Science and Technology</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Introduction to Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Big data: The next frontier for innovation, competition, and productivity. Online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mckinsey Global Institute</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Mdsj: Java library for multidimensional scaling (version 0.2). online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pich</surname></persName>
		</author>
		<ptr target="http://www.inf.uni-konstanz.de/algo/software/mdsj/" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Relevance feedback: a power tool for interactive content-based image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Techn</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="644" to="655" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Norvig</surname></persName>
		</author>
		<title level="m">Artificial Intelligence: A Modern Approach. Pearson Education</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1996 IEEE Symposium on Visual Languages, VL &apos;96</title>
		<meeting>the 1996 IEEE Symposium on Visual Languages, VL &apos;96<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page">336</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Selecting good views of high-dimensional data using class consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="831" to="838" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Asymmetric bagging and random subspace for support vector machines-based relevance feedback in image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1088" to="1099" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automated analytical methods to support visual exploration of high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Magnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="584" to="597" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Subspace Search and Visualization to Make Sense of Alternative Clusterings in High-Dimensional Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Faerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Procedings of IEEE VAST</title>
		<meeting>edings of IEEE VAST</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visual exploration of time-series data with shape space projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="701" to="710" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Graph-theoretic scagnostics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2005. INFOVIS 2005. IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Incrementally optimized decision tree for noisy big data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications, BigMine &apos;12</title>
		<meeting>the 1st International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications, BigMine &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="36" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Value and relation display: Interactive visual exploration of large data sets with hundreds of dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hubball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Rundensteiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ribarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="494" to="507" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yegnanarayana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PHI Learning Pvt. Ltd</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
