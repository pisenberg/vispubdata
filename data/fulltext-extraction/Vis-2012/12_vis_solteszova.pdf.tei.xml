<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Perceptual-Statistics Shading Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Cagatay</forename>
								<surname>Turkay</surname>
								<roleName>Student Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Mark</forename>
								<forename type="middle">C</forename>
								<surname>Price</surname>
								<roleName>Student Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Ivan</forename>
								<surname>Viola</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<title level="a" type="main">A Perceptual-Statistics Shading Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Shading</term>
					<term>perception</term>
					<term>evaluation</term>
					<term>surface slant</term>
					<term>statistical analysis</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Underestimation of surface slant 0° 30° Measure the error in perception A new shading model Fig. 1. The concept of iterative evaluation-analysis-redesign of a visualization technique is shown on a stream surface dataset. Analysis of the perceived surface slant while using a chosen shading model – the Lambertian shading model [9] on the left leads to a statistical model of the perceived error plotted in the middle. The statistical model of the error is then taken into account in the new shading model which aims to compensate for it, shown on the right. Abstract—The process of surface perception is complex and based on several influencing factors, e.g., shading, silhouettes, oc-cluding contours, and top down cognition. The accuracy of surface perception can be measured and the influencing factors can be modified in order to decrease the error in perception. This paper presents a novel concept of how a perceptual evaluation of a visualization technique can contribute to its redesign with the aim of improving the match between the distal and the proximal stimulus. During analysis of data from previous perceptual studies, we observed that the slant of 3D surfaces visualized on 2D screens is systematically underestimated. The visible trends in the error allowed us to create a statistical model of the perceived surface slant. Based on this statistical model we obtained from user experiments, we derived a new shading model that uses adjusted surface normals and aims to reduce the error in slant perception. The result is a shape-enhancement of visualization which is driven by an experimentally-founded statistical model. To assess the efficiency of the statistical shading model, we repeated the evaluation experiment and confirmed that the error in perception was decreased. Results of both user experiments are publicly-available datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p> The major effort of computer graphics initially focused on the production of synthetic scenes that are indistinguishable from a photograph. From the visualization perspective, the user-centric aspect of rendering is more important than the physics-centric, and the focus is put on 3D scene understanding rather than on a physically-correct representation of a scene. From the user-centric aspect, 3D shape and depth cues are important . Shape perception is mostly based on local features of surfaces, i.e., patterns of reflected light that are based on the surface orientation and the illumination direction, and texture deformation that is based on local curvature. Depth cues allow for correct depth ordering of structures and depth judgment. To resolve these cues, the visual system @BULLET VeronikaŠoltészováVeronikaˇVeronikaŠoltészová and C ¸ a˘ gatay Turkay are with the Department of Informatics, University of Bergen, Norway, E-mail: (Veronika.Solteszova | Cagatay.Turkay)@ii.uib.no. @BULLET Mark C. Price is with the Psychology Faculty, University of Bergen, Norway, E-mail: Mark.Price@psysp.uib.no. @BULLET Ivan Viola is with the Department of Informatics, University of <ref type="bibr" coords="1,245.31,676.40,22.64,6.86">Bergen </ref> uses not only stereopsis, perspective and kinetic cues but also our understanding of occlusion, shadows and haze. The judgment of depth is based on the global features of the scene while the judgment of shape considers mostly the local properties of the objects in the scene. The user-centric aspect of rendering has been represented by styles that mimic techniques used in the craft of illustration. These techniques claim to be more efficient in terms of visual processing than a physics-centric representation of the same scene <ref type="bibr" coords="1,471.88,554.38,14.19,8.02" target="#b11">[12,</ref><ref type="bibr" coords="1,488.74,554.38,10.64,8.02" target="#b30"> 32]</ref> . Some rendering styles abstract from the realistic scene appearance by exaggerating the Lambertian shading gradient transitions <ref type="bibr" coords="1,476.43,574.31,13.74,8.02" target="#b28">[29]</ref>. Even though this approach has initially mimicked artwork, an increasing number of techniques are now motivated by new knowledge from vision re- search <ref type="bibr" coords="1,320.18,604.19,14.19,8.02" target="#b35">[37,</ref><ref type="bibr" coords="1,337.54,604.19,10.64,8.02" target="#b36"> 38]</ref> . Although perceptual evaluations of rendering techniques have been conducted in many recent reports, they have only rarely triggered a re-design of the original technique with the goal of perceptual improvement <ref type="bibr" coords="1,383.49,634.08,14.19,8.02" target="#b12">[13,</ref><ref type="bibr" coords="1,399.93,634.08,10.64,8.02" target="#b26"> 27]</ref>. The shading models mentioned above have an imperative character – an algorithm dictates the visual appearance that is displayed to the viewer. The viewer then extracts relevant information such as surface of objects, depth, and distances between them. The algorithm is independent of how accurately the intended information is conveyed. However, in contrast to the previous shading models, we present a shading model that starts as a classical imperative algorithm, but is then declaratively modified to improve the surface perception. This can be achieved through several iterations. In this paper we first analyze the error of perceived surface orienta-tions from shading, utilizing a common shading model (<ref type="figure" coords="2,224.24,53.38,29.28,8.02" target="#fig_14">Figure 1</ref>left). We perform statistical analysis on the data collected from a perceptual study that reveals systematic errors of human visual shape perception. This error, i.e., angular deviation between the ground-truth and perceived surface normals, is color coded and mapped to the stream surface in <ref type="figure" coords="2,51.47,103.20,31.46,8.02" target="#fig_14">Figure 1</ref>middle. From the statistical error description, we define a correction scheme. Next, we re-render the scene with a corrected rendering approach (<ref type="figure" coords="2,124.48,123.12,30.15,8.02" target="#fig_14">Figure 1</ref>right) and conduct another user study to analyze the new error trend. We propose a new concept of iterative modifications that allow the shading model to converge to a model with accurate perception where the distal and proximal stimulus match. The major contributions of this paper are: @BULLET a new concept: our work represents a next step in user-centric shading for scientific visualization that upgrades an imperative visualization algorithm with a declarative optimization, motivated by increasing the accuracy of perception, @BULLET new knowledge: through perceptual evaluation we obtained new knowledge about error-distribution in shape perception according to the scene characteristics, @BULLET a new shading model: we obtain a new shading model from the iterative evaluation and improvement concept that enhances surface shape perception, @BULLET a publicly-available dataset which includes results of our experiment as well as the look-up map stored as a texture. </p><p>Previous approaches, even if they evaluated some perceptual error, did not use it for any improvement scheme, which is a part of our declarative concept. Our work presents a missing link in the visualization pipeline shown in <ref type="figure" coords="2,116.93,370.63,30.64,8.02">Figure 2</ref>in red which opens a new field of possibilities. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p> For two millenia, scientists have been trying to elucidate the mechanisms in the human visual system (HVS) that are responsible for 3D shape perception. This topic remains an active area of multiple research disciplines such as psychology, neuroscience, computer science , mathematics, and physics. From the physics point of view, the sensory information is limited to patterns of light and is confined to their 2D projection on the retina. Using this sensory input, the HVS extracts information about the shape and the arrangement of objects with respect to their environment <ref type="bibr" coords="2,143.42,488.77,13.74,8.02" target="#b32">[34]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Perception of surfaces</head><p>The shape of an object is defined by the properties of its contour and its surface which does not change under similarity transformations. Despite the fact that the 2D retinal projection of the object depends also on its orientation relative to the observer, the percept of the shape tends to remain constant. This phenomenon is called shape constancy <ref type="bibr" coords="2,253.64,557.09,13.74,8.02" target="#b27">[28]</ref>. The HVS constructs a mental image of an object from a combination of top-down cognition and sensory input. At the lower sensory level, this includes the intensity variation of shading, texture gradients , edges and vertices. At the higher cognitive level, it includes salient features such as occlusion contours (object-background separa- tion) <ref type="bibr" coords="2,41.75,616.87,13.74,8.02" target="#b32">[34]</ref>. <ref type="bibr" coords="2,61.92,616.87,36.76,8.02">Cole et al. </ref>showed that certain shape cues can be extracted solely from important lines, even though shape cues from shaded images are more accurate <ref type="bibr" coords="2,108.36,636.80,9.52,8.02" target="#b5">[6]</ref>. However, shading alone cannot yield the depth structure of a scene correctly <ref type="bibr" coords="2,155.69,646.76,9.52,8.02" target="#b6">[7]</ref> . The depth cues from shading are poor when compared to the retinal disparity (stereopsis) and kinetic cues <ref type="bibr" coords="2,67.32,666.68,13.74,8.02" target="#b13">[14]</ref>. Shading is specified by multiple parameters, i.e., the local surface reflectance properties, the angles between the surface normal and the direction of the light sources and the viewer. The judgment of shape is therefore a result of observers' assumptions regarding several parameters . The assumptions can vary between observers. Belhumeur et al. <ref type="bibr" coords="2,42.77,726.46,10.45,8.02" target="#b1">[2] </ref>introduced the term bas-relief ambiguity; when an unknown object with Lambertian reflectance is viewed orthographically, there <ref type="figure" coords="2,285.12,208.33,19.76,7.37">Fig. 2</ref>. The concept of iterative evaluation and design of a rendering technique. The original visualization pipeline contains no cycles and ends at the stage when the image is perceived by the user. The new concept contains a loop; The accuracy of perception is evaluated and the original rendering method is modified based on the measured error in perception. is an implicit ambiguity in determining its 3D shape. For example , in a bumpy scene casting shadows, it is not possible to distinguish whether the light direction is more slanted or if the bumps in the scene are deeper. The object's visible surface f (x, y) is indistinguishable from a generalized bas-relief transformation of the object f (x, y) = λ f (x, y) + µx + νy. There is an evidence that the pictorial relief, i.e., the imaginary relief extracted from a 2D projection of a 3D scene, such as a rendering or a photograph, is systematically distorted relative to the actual structure of the observed scene <ref type="bibr" coords="2,384.30,377.12,9.71,8.02" target="#b6">[7,</ref><ref type="bibr" coords="2,396.94,377.12,10.64,8.02" target="#b32"> 34]</ref>. The variations among observers' judgments were revealed to be complex and thus could not be accounted for by a simple depth scaling transformation. However, subsequent analyses showed that almost all of the variance could be roughly accounted for by an affine shearing transformation in depth <ref type="bibr" coords="2,499.78,416.97,13.74,8.02" target="#b32">[34]</ref>. Mamassian and Kersten investigated the perception of local surface orientation on a simple smooth object, under various illumination con- ditions <ref type="bibr" coords="2,312.82,447.07,13.74,8.02" target="#b20">[21]</ref>. They analyzed perceived local orientations for several points on the surface and quantified the slant and tilt of the local tangent plane. By slant, we understand the angle between the surface normal and the view vector and, by tilt, the azimuth direction of the surface normal in the eye space <ref type="bibr" coords="2,405.45,486.92,9.52,8.02" target="#b5">[6]</ref>. This definition is illustrated in <ref type="figure" coords="2,285.12,496.88,29.53,8.02" target="#fig_1">Figure 3</ref> . Mamassian and Kersten observed that slant was underestimated for slants larger than 20 @BULLET and overestimated under this value. This systematic error in slant perception results from the lack of visual reference and indicates that relative slant is a more robust cue <ref type="bibr" coords="2,502.74,526.77,13.74,8.02" target="#b10">[11]</ref> . Because of the environmental cues, such as the presence of a frame <ref type="bibr" coords="2,518.31,536.74,13.74,8.02" target="#b34">[36]</ref>, and the absence of binocular disparity <ref type="bibr" coords="2,421.13,546.70,13.74,8.02" target="#b18">[19]</ref> , the brain receives information that the rendering is, in fact, flat. This information is in conflict with cues from shading and therefore, the mental image extracted from the rendering is flattened in a systematic fashion. To resolve these ambiguities, the HVS tends to assume a certain light direction <ref type="bibr" coords="2,356.85,596.73,13.74,8.02" target="#b23">[24]</ref>. Johnston and Passmore suggested that the slant discrimination declined with rotation of the light direction vector towards the viewpoint <ref type="bibr" coords="2,381.14,616.65,13.74,8.02" target="#b13">[14]</ref>. Follow-up studies indicated that this direction is from above the viewer and 12 @BULLET left from the vertical axis <ref type="bibr" coords="2,301.92,636.58,14.19,8.02" target="#b31">[33,</ref><ref type="bibr" coords="2,318.48,636.58,10.64,8.02" target="#b19"> 20]</ref>. O'Shea and colleagues studied the assumed slant of the light direction on purely diffuse surfaces with no shadows <ref type="bibr" coords="2,496.68,646.54,13.74,8.02" target="#b25">[26]</ref>. They demonstrated that the surface slants were most accurate when the light source was 20 @BULLET − 30 @BULLET above the viewer. Mingolla and Todd <ref type="bibr" coords="2,366.94,676.65,14.94,8.02" target="#b23">[24] </ref>concluded that the HVS initially assumed Lambertian reflection on all surfaces. Furthermore, they suggested that the surface orientation was detected locally, and global shape was determined by smoothing over local features. Fleming et al. studied mirror-material surfaces, i.e., surfaces riddled with specular highlights that contained no shading <ref type="bibr" coords="2,406.48,726.46,9.52,8.02" target="#b7">[8]</ref>. They concluded that the HVS can somehow exploit specular reflections to recover three-dimensional shape. The HVS treats specularities somewhat like textures, by using the systematic patterns of distortion across the image of a specular surface to recover 3D shape. Other studies also provide evidence about the influence of specular highlight on the perception of surfaces and demonstrate that the shininess of surfaces enhances the perception of curvature <ref type="bibr" coords="3,67.37,289.84,14.19,8.02" target="#b24">[25,</ref><ref type="bibr" coords="3,83.81,289.84,10.64,8.02" target="#b33"> 35]</ref>. Illustrators tended to exaggerate salient features such as curvature or important lines. Their methods have been mimicked by the graphics community. Exaggerated shading <ref type="bibr" coords="3,157.38,320.24,13.74,8.02" target="#b28">[29]</ref>, geometry manipulation <ref type="bibr" coords="3,264.69,320.24,13.74,8.02" target="#b14">[15]</ref>, light warping <ref type="bibr" coords="3,81.79,330.20,14.94,8.02" target="#b35">[37] </ref>and radiosity scaling <ref type="bibr" coords="3,175.57,330.20,14.94,8.02" target="#b36">[38] </ref>are good representatives. These techniques, however, were not derived from prior knowledge of a measured perceptual error. In contrast to prior work, we are presenting a novel concept where the visualization technique is based on a statistical model of the error in human perception. In particular, we target underestimation of surface slant of diffuse shaded surfaces. However, our concept can be applied to any self-chosen visualization technique that yields a measurable systematic error in perception. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Psychophysical experiments</head><p>The first experiments investigating human perception of 3D shapes were performed in the 19th century. The available information about these experiments is very poor, and therefore one should interpret their results with caution <ref type="bibr" coords="3,102.50,460.24,13.74,8.02" target="#b32">[34]</ref>. In the experiment of Mingolla and Todd <ref type="bibr" coords="3,264.69,460.24,13.74,8.02" target="#b23">[24]</ref>, observers judged slants and tilts of numerous regions within shaded images of ellipsoid surfaces under varying illumination direction. The ellipses also had various shape, orientation and surface reflectance. The works of Koenderink et al. <ref type="bibr" coords="3,162.68,500.60,14.94,8.02" target="#b16">[17] </ref>and Todd <ref type="bibr" coords="3,219.17,500.60,14.94,8.02" target="#b32">[34] </ref>describe the three most frequently employed experiments for probing perceived surfaces. </p><p>Relative depth probe task: Observers are exposed to a shaded surface. Two points on the surface are marked with dots of different colors. The observer is asked to choose which point he or she perceives closer in depth by pressing a dedicated key. Variations of this tasks were employed recently to assess visualization quality <ref type="bibr" coords="3,228.38,575.81,14.19,8.02" target="#b17">[18,</ref><ref type="bibr" coords="3,244.82,575.81,10.64,8.02" target="#b30"> 32]</ref>. <ref type="bibr" coords="3,42.19,601.20,13.74,8.02" target="#b15">[16]</ref>, allows one to determine the perceived orientation of a surface. re fe re n c e c u r v e <ref type="figure" coords="4,22.50,236.23,19.51,7.37">Fig. 5</ref>. Perceived surface slant as a function of the ground truth slant extracted from the dataset of Cole et al. <ref type="bibr" coords="4,169.94,245.69,8.31,7.37" target="#b5">[6]</ref>. Each dot represents the median of the entire set of trials at one sampling position. The overall estimation curve is a polynomial curve that is fitted to the data. The reference curve x = y indicates a perfectly accurate estimation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Analysis of the perceived surface slant</head><p>The perception literature reports that the surface slant, as deduced from monoscopic renderings of 3D objects viewed on a screen, is systematically distorted, however there is no model representing this phe- nomenon <ref type="bibr" coords="4,58.07,352.13,14.19,8.02" target="#b25">[26,</ref><ref type="bibr" coords="4,74.47,352.13,10.64,8.02" target="#b32"> 34]</ref>. The slant angle is understood as the angle between the surface normal and the viewing direction. We describe this effect with a mathematical model that was obtained through the statistical analysis of user responses. A model derived from statistical analysis of user evaluation has not been available before. It has been only attempted to model this effect as a parabolic function <ref type="bibr" coords="4,222.42,401.95,14.94,8.02" target="#b25">[26] </ref>or to use a simple shearing transformation in depth <ref type="bibr" coords="4,182.32,411.91,13.74,8.02" target="#b32">[34]</ref> . These approximations are consistent with the general expectation of perception but not founded on a statistical analysis of results of a perceptual study. We obtained our model by analyzing users' responses collected as a publicly available dataset by Cole and co-workers as described in Section 2.1. The dataset contained results with fully-shaded and line drawing conditions. We analyzed only the responses for the fullyshaded condition. The line-drawing condition was completely excluded . For each of the 1200 sampling positions, we obtained the ground truth normal including the slant and the tilt angles and a corresponding set of normals estimated by the participants. In addition, for each sampling position, the authors of the dataset published the median of the corresponding set of estimates. They aimed to compare surface perception of 3D object representations on flat screens using monoscopic vision <ref type="bibr" coords="4,92.95,552.18,9.52,8.02" target="#b5">[6]</ref> . The overall dependency of the estimated surface slant θ E and the ground truth θ G slant is approximated with a polynomial fitting curve of the 4 th degree and is shown in <ref type="figure" coords="4,239.72,573.13,29.79,8.02">Figure 5</ref>. The overall estimation curve shows the trend of how humans tend to underestimate the surface slant. We originally computed different fitting curves with various specifications and obtained their goodness of fit (R 2 value) using the curve fitting tool of Matlab <ref type="bibr" coords="4,210.26,612.98,13.74,8.02" target="#b21">[22]</ref>. For various types of fit, we obtained the following R 2 values: Fourier fit of 1 st degree – R 2 = 0.773, Fourier fit of 8 th degree – R 2 = 0.780, exponential fit – R 2 = 0.774, cubic fit – R 2 = 0.773, and for polynomial fits of 4 th degree – R 2 = 0.775, 5 th degree – R 2 = 0.775 and 8 th degree – R 2 = 0.776. As a trade-off between the complexity of the fit and the goodness of fit, we chose the polynomial fit of 4 th degree. However, the aggregated scatterplot in <ref type="figure" coords="4,176.41,686.61,30.91,8.02">Figure 5</ref>does not reveal a very interesting feature that is hidden in the dataset. We have separated the sampling positions into four groups according to the tilt φ of the ground truth normal: normals pointing upwards or north φ ∈ </p><formula>g(θ,φ) = θ* ggg(θ*,φ) = θ Fig. 7. Functions g(θ , φ ) = θ * and g −1 (θ * , φ </formula><p>) = θ rendered as color-coded plots. Since f = g −1 , the right plot is also the look-up map which allows to efficiently find the slant angle θ of a normal which is perceived as θ * . sistently with the work of Cole et al.) as the azimuth angle on a compass where the wind directions are N = 0 @BULLET , E = 90 @BULLET , S = 180 @BULLET and W = 270 @BULLET . In <ref type="figure" coords="5,51.83,343.94,29.67,8.02" target="#fig_6">Figure 6</ref> , we visualize the dependencies in each sector as scatterplots and fitted curves. The distribution and the sector estimation curves in the north and the south sector are very different. The slant of normals pointing north is underestimated less than average – the fitted curve is above the overall estimation curve. For the normals pointing south the situation is opposite. These slants are more underestimated than average – the fitted curve is under the overall estimation curve. The slant of normals pointing east and west are perceived very close to the average – the overall estimation curve. This finding is consistent with the statement of Todd that the underestimation of slant cannot be compensated by simple scaling in depth but by a shearing transformation in depth <ref type="bibr" coords="5,79.07,453.53,13.74,8.02" target="#b32">[34]</ref>. The crossing points of the sector estimation curves and the reference curves indicate the thresholds between over and underestimation of slant. In our results, these thresholds correspond to approximately 15 @BULLET − 25 @BULLET of the ground truth slant with the exception of the south sector. Mamassian and Kersten <ref type="bibr" coords="5,151.30,504.21,14.94,8.02" target="#b20">[21] </ref> expect this threshold to be approximately 20 @BULLET which is consistent with our finding of 15 @BULLET − 25 @BULLET . We also considered a similar factorization of samples according to the maximal curvature (low, middle, high) but we did not find any remarkable dependencies between the error and curvature. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The model of surface perception</head><p>In order to model the human perception of slant, we compute a 2D map f (θ * , φ ) = θ which predicts that the slant angle of a surface normal should be θ so that it is perceived as θ * . We divide the samples into bins that represent eight sectors: north, south, east, west, northwest , north-east, south-west, south-east. To obtain this map, we proceed as follows. For each sector, we calculate a polynomial fitting curve of the 4 th degree. Four of these sector curves (north, south, east, west) are plotted in <ref type="figure" coords="5,123.20,647.47,29.41,8.02" target="#fig_6">Figure 6</ref>. These curves represent a function </p><formula>g φ (θ G ) = θ E which </formula><p>maps the ground truth slant θ G in the sector φ to the estimated slant θ E . For each curve, we set two boundary conditions: the curve must intersect points (0, 0) and (90, 90) since it is expected that the estimation of these boundary values is correct. These boundary conditions also guarantee that all curves start and end with the same functional value of θ E and that the inverse function g −1 φ is defined on the whole interval of slant <ref type="bibr" coords="5,166.46,720.08,29.75,10.42">[0 @BULLET , 90 @BULLET ]</ref>. For g −1 φ , the following condition holds: </p><formula>g −1 φ (θ E ) = θ G . </formula><p>In other words, g −1 φ predicts how the slant angle of a surface normal should be so that it is perceived as </p><formula>θ E and therefore f (θ * , φ ) = g −1 φ (θ * ). </formula><p>So far, we have defined g −1 φ for eight values of tilt φ only. In order to fill the missing values in the 2D map, we fit a smooth surface to the eight g −1 φ aligned in polar coordinates according to their respective φ . To fit the surface, we used the surface fitting tool of Matlab <ref type="bibr" coords="5,527.31,373.08,13.74,8.02" target="#b21">[22]</ref>. Color-coded height maps of g(θ , φ ) and f (θ * , φ ) = g −1 (θ * , φ ) are shown in <ref type="figure" coords="5,328.84,393.00,29.04,8.02">Figure 7</ref>. The height map f , represented as a texture, allows for easy look-ups of the functional values of f at runtime. This texture is publicly-available for download <ref type="bibr" coords="5,420.10,412.93,13.74,8.02">[31]</ref>. While this texture is the best possible representation of our model, sometimes a functional approximation of f (θ * , φ ) might be required. We found that˜fthat˜ that˜f , which is a linear interpolation g −1 N=0 @BULLET and g −1 S=180 @BULLET , yields very similar, however not identical, results. With g −1 N and g −1 S as polynomials of 4 th degree with coefficients (5.77e-6, -1.19e-3, 7.3e-3, 0.11, 0.0) and (4.21e-6, -6.73e-4, 1.88e-2, 1.69, 0.0) respectively, we define˜fdefine˜ define˜f as follows: </p><formula>˜ f (θ , φ ) =| φ − 180 @BULLET 180 @BULLET | g −1 N (θ ) + (1− | φ − 180 @BULLET 180 @BULLET |)g −1 S (θ ) (1) </formula><p>Ideally, the statistical model should be defined for each illumination algorithm individually because different algorithms might yield different response curves regarding the surface slant. We have obtained this model from renderings of objects from purely diffuse and opaque materials . The mathematical model could be different for specular and shiny or semi-transparent surfaces. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE STATISTICAL SHADING MODEL</head><p>The shading information is one part of the sensory input which the human visual system uses for constructing its mental image of the 3D world. Indirectly, we are able to extract shape and deduce the surface normals from our mental image even though we are seeing only a 2D representation of an object, e.g., a photograph or a rendering on a computer screen. We have now analyzed and concluded that the surface normal we perceive is distorted from the ground truth normal of the depicted scene, and we have provided a mathematical model of this distortion. The difference between the ground truth and the estimated surface slant is mapped to a 3D model and plotted in <ref type="figure" coords="5,484.50,696.57,28.96,8.02" target="#fig_14">Figure 1</ref> . Illumination algorithms used in computer graphics were until now unaware of this perceptual model. With this new input information, we propose a concept of how an illumination model relying on surface normals can be corrected so that the mental image is closer to the depicted scene. A rendering of a given scene geometry (distal stimulus) using normal-based shading, evokes its corresponding mental image (proximal stimulus) which can yield different perceived normals as those of the original geometry. Our goal is to match the distal and the proximal stimulus, i.e., to specify a shading model where the normals of the mental image and the ground truth normals match. We achieve this by manipulating the normals that are input into our shading model using a perceptual model corresponding to the original shading algorithm . In Section 3.2, we described how to obtain such a model and its approximating function f (θ * , φ ) = θ . In our approach, we represented this function as a 2D look-up table stored as a texture where each pixel with coordinates (θ * , φ ) stores the value of f (θ * , φ ) = θ . A color-coded representation of the look-up map and the coordinate system are shown in <ref type="figure" coords="6,97.48,587.75,29.01,8.02">Figure 7</ref>. A surface normal n = (x, y, z) has ground truth slant θ G and tilt φ G , both given in projective space, but its slant is perceived as θ = θ G . We shade the point with a modified normal n = (x , y , z ) with slant θ = f (θ G , φ G ) and with the same tilt φ G . Notice that θ G = g(θ , φ G ), i.e., θ should be according to our theory perceived as θ G . The components of the modified normal n are then defined as follows: </p><formula>x = sin(θ ) √ x 2 +y 2 x y = sin(θ ) √ x 2 +y 2 y z = cos(θ ) (2) </formula><p>All illumination computation that follows is then executed with the new normalized surface normal n ||n || . The concept of adjusting surface normals according to a given perceptual model is applicable to any illumination computation scheme that is based on surface normals or gradients. To demonstrate the effect of our approach, we applied our model to Lambertian shading and used purely diffuse-reflective materials. In all settings, the light source conforms to the assumed light direction <ref type="bibr" coords="6,429.00,498.08,13.74,8.02" target="#b25">[26]</ref>. <ref type="figure" coords="6,448.93,498.08,30.05,8.02" target="#fig_14">Figure 1</ref>shows a stream surface before (left-most) and after our modification (right-most). <ref type="figure" coords="6,520.54,508.04,14.95,8.02;6,285.12,518.01,19.01,8.02" target="#fig_8">Fig- ure 8</ref>contains more examples. A-images show the original shading with no modification of surface normals versus B-images showing our statistical shading. We included both datasets defined as volumes as well as geometry to show the general applicability of our technique. Objects I (cervical) and II (pulley) were also used by <ref type="bibr" coords="6,484.98,557.86,38.27,8.02">Cole et al. </ref>in their user experiment. Dataset III is a CT scan of a mummy visualized using gradient-based shading. Datasets IV and V were reconstructed from laser scans of a bunny and an angel. Dataset V is a geometry representation of a stream surface. All surfaces were shaded using Lambertian shading without (A) or with (B) modification of surface normals. </p><p> On first reflection, it might seem that similar results could be obtained by simply enhancing the contrast of the image <ref type="bibr" coords="6,476.50,646.76,10.45,8.02" target="#b0">[1] </ref> as in the juxtaposed images in <ref type="figure" coords="6,351.63,656.72,29.01,8.02" target="#fig_10">Figure 9</ref>. Our method changes the intensities based on the surface normals, and therefore original intensities are mapped to a range of intensities. In contrast, global contrast enhancement maps the intensities to a single value. This shows that a global contrastenhancement is a bijective function while the statistical shading is not. This effect is plotted in <ref type="figure" coords="6,372.14,706.53,29.37,8.02" target="#fig_10">Figure 9</ref>. The standard deviation σ of global contrast enhancement is always zero which is not the case for statistical shading. Therefore, the same results cannot be obtained by simply enhancing the contrast of the image. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VERIFICATION</head><p> Our hypothesis is that the modification of normals causes the estimation of surface slant to be closer to the ground truth. To obtain empirical support for our hypothesis, we studied perceptual judgments during the original shading condition (A) as opposed to our statistical shading condition (B). We then formally analyzed the difference in performance between the two conditions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">The Experiment</head><p>In order to measure the effectiveness of our technique, we conducted a new gauge-figure experiment. Instead of just relying on the results of the experiment of Cole and co-workers <ref type="bibr" coords="7,174.77,537.10,9.52,8.02" target="#b5">[6]</ref>, we again tested condition A (original shading). This assured an appropriate control baseline, as we used a different rendering framework. Cole et al. generated their images with YafaRay which is a free raytracing engine <ref type="bibr" coords="7,251.46,566.99,14.94,8.02" target="#b38">[40] </ref>and defined their source of illumination as an environment map. We employed the commonly used Lambertian shading model and directional illumination. We selected four distal stimuli from the experiment of Cole et al. </p><p>– one organic dataset (cervical) and three man-made datasets (pulley, rockerarm, flange). Two of these stimuli are depicted in both shading conditions, in <ref type="figure" coords="7,96.82,636.80,30.30,8.02" target="#fig_8">Figure 8</ref>– I. (cervical) and II. (pulley). The stimuli were viewed on a flat computer screen using the same camera settings and viewport size as Cole et al. For each stimulus, we selected respectively 41, 42, 39 and 38 sampling positions for placing the gaugefigure from Cole's dataset. The positions were heuristically selected from the whole set in the following way. For each object, the ground truth slants were best-possibly distributed over the interval <ref type="bibr" coords="7,252.01,694.16,29.87,10.42">[0 @BULLET , 90 @BULLET ] </ref> and the numbers of positions in each of four sectors (N,E,S,W) regarding the ground truth tilt were also balanced. In total, we used 160 × 2 distinct test cases: 160 gauge-figure placing positions and two shading conditions for each position. Each participant solved 2/3 of all test cases so, in total, we collected at least 26 samples per test case and more than 8500 solved test cases overall. The collection of user responses is available for download <ref type="bibr" coords="7,423.72,474.21,13.74,8.02">[31]</ref>. Each of 40 participants attended two sessions. In each session he or she was tested on two pairs of stimuli with a 10 minute break between the pairs. The first pair of stimuli was presented in a different shading condition than the second. Half of the participants started with shading condition A and the other half with the shading condition B. The order was selected randomly in the first session, but in the second session, the order of shading conditions was reversed. For example, a random participant might be first presented with the stimuli cervical and pulley, and the shading condition A, then he had a short break to avoid fatigue and he continued with stimuli flange and rockerarm and the shading condition B. When this participant came to the second session , he started with the rockerarm, the flange, and shading condition A, and continued with the cervical, the pulley, and the shading condition B. The number of samples per position was balanced between participants. We hired 40 participants for a financial compensation of 35USD equivalent for both sessions. The group of participants included 19 female and 21 male participants of 19 different nationalities. Participants were 21-47 years old but 87.5% belonged to the age group 20-30. Most of the participants were university students at the bachelor , master or PhD level. All of them had normal or corrected vision (lenses or glasses). 18 participants had skills with computer-assisted 3D tasks such as education in visual computing, mathematics or experience with 3D computer games. 37 participants worked on two different days. In three cases, the first session was in the morning and the second in the afternoon of the same day. , the normality of the distribution is violated which can be deduced from the histogram. The orange dotted lines indicate the difference between the mean values of the shading conditions within the same interval. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0"></head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Accuracy measurement of participants</head><p>To determine the accuracy of each participant, we approximated his or her responses for each shading condition (A and B) by two polynomial fitted curves of the 4 th degree </p><formula>f A (θ G ) = θ E and f B (θ G ) = θ E . θ G and θ E indicate </formula><p> the ground truth slant and the estimated slant respectively . Each curve was computed from at least 106 samples. We define the error measure E(a, b) at an interval of slants <ref type="bibr" coords="8,203.35,385.07,16.68,8.02">[a,b] </ref>as the area of the surface enclosed by the reference curve R(θ G ) = θ G and the user response curve U(</p><formula>θ G ) = θ E : E(a, b) = b a ||U(θ G ) − R(θ G )||dθ G (3) </formula><p>In <ref type="figure" coords="8,41.64,448.94,32.59,8.02" target="#fig_12">Figure 10</ref>, we show the estimation curves of a selected participant for each shading condition – red for A and blue for B. The figure also illustrates the meaning of the surface area in a selected interval of slant angles (a,b). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head><p>To formally test whether the shading algorithm significantly improved participants' accuracy, we compared the error areas E between the two shading conditions A and B for each of the 4 intervals of the curve, </p><formula>i.e., E(0 @BULLET ,20 @BULLET ), E(20 @BULLET ,40 @BULLET ), E(40 @BULLET </formula><p> ,60 @BULLET ), and E(60 @BULLET ,80 @BULLET ). The division into subintervals was selected on a priori grounds. According to previous evidence <ref type="bibr" coords="8,91.50,557.09,14.94,8.02" target="#b20">[21] </ref>and also concluding from our own analysis, the underestimation of slant is zero at ca. 20 @BULLET of ground-truth slant and highest for slants 40 @BULLET − 60 @BULLET (see also <ref type="figure" coords="8,172.99,577.02,54.61,8.02" target="#fig_6">Figures 5 and 6</ref>). Hence we predicted different effects in each subinterval. We conducted a 4 × 2 repeated measures ANOVA with the curve interval (4 levels) as one factor and the shading condition (2 levels) as the other factor. Due to violations of sphericity according to Mauchly's test, reported degrees of freedom and p-values are Greenhouse-Geisser corrected <ref type="bibr" coords="8,57.59,636.80,14.19,8.02" target="#b9">[10,</ref><ref type="bibr" coords="8,73.53,636.80,10.64,8.02" target="#b22"> 23]</ref>. The main effect of the curve interval was significant <ref type="bibr" coords="8,22.50,646.76,3.49,8.02">[</ref><ref type="bibr" coords="8,45.23,666.68,10.46,8.02">08]</ref>, although the area between ideal and obtained curves was numerically greater for the shading condition B (our new approach). However, we obtained a significant interaction between the 2 factors , indicating that the beneficial effect of our shading algorithm differed for the different intervals of the curve [F(1.8, 70.9) = 4.2, p = 0.02] as shown in <ref type="figure" coords="8,87.10,716.50,37.94,8.02" target="#fig_14">Figures 11</ref>and 12. Difference contrasts showed that a significant benefit <ref type="bibr" coords="8,96.03,726.46,25.93,8.02">[F(1,39</ref> ) = 12.4, p = 0.001, r = 0.49] of the algorithm was obtained for the interval <ref type="bibr" coords="8,152.57,734.02,32.99,10.42">[40 @BULLET ,60 @BULLET ]</ref>. Even though the error bars indicating the 95%-confidence interval in <ref type="figure" coords="8,451.88,319.97,34.47,8.02" target="#fig_14">Figure 11</ref>do overlap, it does not imply that the effect is insignificant at 5% level <ref type="bibr" coords="8,493.76,329.94,9.52,8.02" target="#b2">[3]</ref> . For in- tervals <ref type="bibr" coords="8,311.46,339.76,3.48,7.96">[</ref>respectively, p = 0.35, 0.10, and 0.56. The effect of shading algorithm at the first 2 intervals was re-checked with non-parametric Wilcoxon tests <ref type="bibr" coords="8,458.04,359.82,14.94,8.02" target="#b37">[39] </ref>due to violations of normality for those distributions in a Shapiro-Wilk test <ref type="bibr" coords="8,489.83,369.79,13.74,8.02" target="#b29">[30]</ref>, but still failed to show significant differences (p = 0.23 and 0.09 respectively). <ref type="figure" coords="8,285.12,389.71,35.43,8.02" target="#fig_12">Figure 10</ref>illustrates that the difference in surface areas between the two user estimation curves in the intervals <ref type="bibr" coords="8,448.29,399.53,3.48,7.96">[</ref>is rather small compared to the interval <ref type="bibr" coords="8,464.62,407.23,33.12,10.42">[40 @BULLET ,60 @BULLET ] </ref>where the curves were expected to be further away from each other. Mean values and standard deviations of the error area distribution for each shading condition and for each interval of the curve are listed in <ref type="figure" coords="8,486.20,439.52,25.30,8.02" target="#tab_1">Table 1</ref>. In summary we found a highly significant effect of shading for angles in the interval <ref type="bibr" coords="8,358.27,457.06,32.99,10.42">[40 @BULLET ,60 @BULLET ]</ref>. Moreover, in this curve interval, our shading manipulation had an effect size r = 0.49 that would normally be regarded as impressively large within the psychological testing lit- erature <ref type="bibr" coords="8,312.82,489.35,9.71,8.02" target="#b3">[4,</ref><ref type="bibr" coords="8,325.34,489.35,6.47,8.02" target="#b4"> 5]</ref> , accounting for 24% of data variance (r 2 = 0.24). Additionally , the significance level of this effect was high enough to exclude arguments that the effect was a Type I statistical error caused by multiple sampling at different intervals. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Discussion</head><p> Based on the results obtained in our gauge-figure experiment, we created and applied a second model of correction as described in Section 3.2. Rendering results of this iterative process of evaluation and re-design are illustrated in <ref type="figure" coords="8,381.24,577.69,33.12,8.02" target="#fig_1">Figure 13</ref>. We have shown that our modification of normals leads to more <ref type="figure" coords="9,31.50,163.14,22.81,7.37" target="#fig_1">Fig. 13</ref>. Rendering results of a leopard gecko CT dataset of the iterative process evaluation and re-design: (a) the original Lambertian shading, (b) the result of a modification after the first user study, and (c) the result of a modification after the second user study. curate perception of normals slanted 40 @BULLET − 60 @BULLET . Our technique is not photorealistic. One could ask whether this is the case for other techniques that mimic methods from illustration and visual art? Were illustrators aiming to improve perception? We do not have access to a perceptual evaluation of other existing illustrative techniques such as light warping <ref type="bibr" coords="9,83.44,353.34,13.74,8.02" target="#b35">[37]</ref>, and exaggerated shading <ref type="bibr" coords="9,197.26,353.34,13.74,8.02" target="#b28">[29]</ref>. In <ref type="figure" coords="9,230.38,353.34,33.98,8.02" target="#fig_14">Figure 14</ref>, we juxtapose these to simple shearing along the z-axis, and with statistical shading in order to allow a subjective visual comparison. The two right-most visualization using the statistical shading model allow to compare the result of an approximative evaluation of f (θ , φ ) as defined in Equation 1 using functioñ f and precise evaluation using the lookup map. </p><formula>(a) (b) (c) (d) (e) (f ) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p> We described a new concept of the visualization pipeline which allows one to update the rendering algorithm with new knowledge about how the human visual system misperceives the shape of 2D object depictions . Specifically, we studied the perception of surface slant of Lambertian-shaded surfaces and found a systematic distortion. We captured this effect as a function which predicts how the surface slant should be presented so that it is perceived as the ground truth slant. The function allowed us to modify the surface normals or gradients in the Lambertian shading model in a manner that was shown, via empirical testing, to objectively improve slant perception. Even though the trend for improvement did not reach significance when pooled over all slant values, we found a significant improvement in the interval (40 @BULLET , 60 @BULLET ) where the distortion of the slant perception is the highest. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Lessons learned</head><p>We found that the perception of normals pointing upwards in the eye space is clearly the most precise when compared to all other directions. Perception of normals pointing downwards is clearly the most inferior. Accuracy in the left and right directions is very similar. This characteristic of perception is illustrated in <ref type="figure" coords="9,153.98,635.30,30.13,8.02">Figure 7</ref>in the plot of g(θ , φ ). This shows that human ability to estimate surface slant is best on surfaces where normals point upwards and worst on surfaces where normals point downwards. We have not found a similar dependency of the estimation error from higher order surface derivatives such as curvature. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Limitations and future work</head><p> We studied the distortion of human surface perception using stimuli rendered with Lambertian shading of diffuse and opaque surfaces. Therefore, we cannot make a statement about this distortion if a different rendering algorithm, e.g., shadowing or ambient occlusion, was to be used, or if the objects were to be made of a different material, e.g., semi-transparent or shiny. Each rendering algorithm and material should be studied individually and provided with a perceptual distortion model which is an inspiration for future research. Since we have not evaluated the results after the second iteration, we are not able say whether the iterations really converge to a perfect solution. Shape cues are not formed solely from shading. Even though shape extraction from a shaded image is more accurate, Cole et al. showed that certain shape cues can be extracted from line drawings as well <ref type="bibr" coords="9,311.54,395.25,9.52,8.02" target="#b5">[6]</ref>. Our method does not modify important lines since we are not deforming the objects. Therefore, we suggest that our method can be combined with a perception-enhancing geometry deformation in order to achieve the best results. We would like to raise awareness that since we modify shading, we also modify luminance in the final appearance of objects. Since the depth perception is affected by the luminance channel <ref type="bibr" coords="9,495.31,457.07,13.74,8.02" target="#b18">[19]</ref>, it might be worthwhile investigating how our modified shading influences the depth cues. Even though our aim was to show the effect on shape perception of (local) surface slant, we would like to encourage future studies of depth perception as well. The manipulation of shading can influence the appearance of objects' material. The reason is that variations in shape tend to dominate variations due to shading <ref type="bibr" coords="9,387.21,528.86,13.74,8.02" target="#b36">[38]</ref>. This effect is visible in <ref type="figure" coords="9,493.71,528.86,33.42,8.02" target="#fig_1">Figure 13</ref>. As we apply iterative modification of normals, the surface appears more shiny. This observation opens a new interesting direction of research to attempt to characterize a model that adjusts the cues from shading and contours while preserving the appearance of the material. We observed that techniques that mimic illustrators' techniques are pursuing the same goal and, in our qualitative judgment, yield similar subjective effects. Speculatively, this suggests an intriguing hypothesis that illustrators used exaggeration of shading to better match the distal and the proximal stimulus. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p>This work has been carried out within the IllustraSound research project (# 193170), which is funded by the VERDIKT program of the Norwegian Research Council with support of the MedViz network in Bergen, Norway (PK1760-5897-Project 11). The authors wish to thank the VisGroup at the University in Bergen, notably to Helwig Hauser, for discussions and to Herbert Grasberger who collaborated at scanning and creation of models IV and V displayed in <ref type="figure" coords="9,497.43,716.50,29.37,8.02" target="#fig_8">Figure 8</ref> . Finally , the authors thank the anonymous reviewers for their constructive feedback and helpful comments. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,31.50,160.34,250.38,7.56;3,31.50,169.73,250.38,7.64;3,31.50,179.19,250.38,7.64;3,31.50,188.44,250.38,7.87;3,31.50,198.12,250.38,7.64;3,31.50,207.37,241.64,7.87"><head>Fig. 3. </head><figDesc>Fig. 3. The slant angle θ is defined as the angle between the surface normal N at a point P and the viewing vector V. τ denotes the tangent plane at P and U the up vector of the viewer's coordinate-system. σ is a plane such that P ∈ σ and V⊥σ and ρ denotes the plane defined by V and N. The tilt angle φ is then defined as the angle in the left-handed system between U and A = ρ ∩ σ in the halfplane (ρ,V) defined by N. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,40.47,590.93,241.41,8.32;3,31.50,601.20,8.71,8.02"><head></head><figDesc>Gauge-figure task: This task, designed by Koenderink et al. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="3,31.50,725.59,250.38,7.37;3,31.50,735.05,233.07,7.37"><head>Fig</head><figDesc>Fig. 4. Example of (a) a bad placement and (b) a good orientation of a gauge figure (red-yellow Tissot's indicatrix) over a shaded surface. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="4,478.90,57.32,24.81,22.94;4,355.57,65.05,39.92,5.67;4,355.57,70.71,14.80,5.67;4,478.90,206.07,24.81,22.94;4,355.57,213.80,39.92,5.67;4,355.57,219.46,14.49,5.67;4,478.90,354.83,24.81,22.94;4,355.57,362.56,39.92,5.67;4,355.57,368.22,11.33,5.67;4,478.89,503.58,24.81,22.94;4,355.57,511.31,39.92,5.67;4,355.57,516.97,10.19,5.67"><head></head><figDesc>WEST re fe re n c e c u r v e Azimuth of normals EAST </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="4,285.12,670.91,250.38,7.37;4,285.12,680.37,250.38,7.37;4,285.12,689.83,250.38,7.37;4,285.12,699.30,250.38,7.37;4,285.12,708.76,195.24,7.37"><head>Fig. 6. </head><figDesc>Fig. 6. Approximation of slant perception in four different sectors. The reference curve indicates a perfectly accurate perception while the sector estimation curves approximate the perception of slants in their respective sectors. We also plotted the overall estimation curve which indicates the average perception of slants in all sectors. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="6,22.50,417.51,513.00,7.37;6,22.50,426.97,510.99,7.37"><head>Fig. 8. </head><figDesc>Fig. 8. The Lambertian shading using original normals (A) versus statistical shading model (B) shown on various datasets: I – cervical and II – pulley [6], III – a CT scan of a mummy, IV and V are geometry representations of laser scans of a bunny and an angel, and VI – a stream surface. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="7,31.50,364.59,250.38,7.37;7,31.50,374.06,250.38,7.37;7,31.50,383.52,250.38,7.37;7,31.50,392.98,153.08,7.56"><head>Fig. 9. </head><figDesc> Fig. 9. Comparison of a contrast-enhanced image and a statisticallyshaded image. We plotted the mean mapped intensities of a contrastenhanced image and statistical shading. The error bars represent the standard deviation σ of the mapped values. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12" coords="7,294.12,177.58,250.38,7.37;7,294.12,185.34,250.38,9.81;7,294.12,194.80,98.08,9.73"><head>Fig. 10. </head><figDesc>Fig. 10. The error areas of a selected participant for the original shading condition A – E A (0 @BULLET , 40 @BULLET ) filled with pink and for our shading condition B – E B (0 @BULLET , 40 @BULLET ) filled with blue. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13" coords="7,294.12,372.31,250.38,7.37;7,294.12,381.77,250.38,7.37;7,294.12,391.24,250.38,7.37;7,294.12,399.00,250.38,9.07;7,294.12,408.47,250.38,9.07;7,294.12,417.93,58.91,9.07"><head>Fig</head><figDesc> Fig. 11. Interaction plot between E for the two shading conditions: standard (A) and ours (B) in each of four subintervals of the curve. The vertical bars denote the 0.95 confidence interval. We found a significant improvement in the interval [40 @BULLET ,60 @BULLET ] – blue, a non-significant worsening in [0 @BULLET ,20 @BULLET ] – red, and non-significant improvements in [20 @BULLET ,40 @BULLET ] and in [40 @BULLET ,60 @BULLET ] – black. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14" coords="8,25.99,646.61,246.89,8.16;8,22.50,656.72,250.37,8.02;8,22.50,666.68,22.73,8.02"><head>F(1.</head><figDesc>5, 59.8) = 68.4, p &lt;0.00001]. A trend towards a main effect of the shading condition failed to reach significance [F(1, 39) = 3.3, p = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15" coords="9,31.50,262.59,513.00,7.37;9,31.50,272.05,392.44,7.56"><head>Fig. 14. </head><figDesc>Fig. 14. Comparison of (a) the Lambertian shading, (b) light warping, (c) exaggerated shading, (d) shearing along the z-axis and our approach using (e) the approximating functioñ f defined in Equation 1 and (f) the precise look-up texture to solve f (θ , φ , ). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false" coords="4,22.50,724.05,250.39,20.57"><figDesc coords="4,22.50,724.05,250.39,10.61;4,22.50,734.02,250.38,10.61">(315 @BULLET , 45 @BULLET ]; right or east φ ∈ (45 @BULLET , 135 @BULLET ]; downwards or south φ ∈ (135 @BULLET , 225 @BULLET ]; and left or west φ ∈ (225 @BULLET , 315 @BULLET ]. We define tilt (</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false" coords="8,314.95,337.49,117.01,10.42"><figDesc coords="8,314.95,337.49,117.01,10.42">0 @BULLET ,20 @BULLET ], [20 @BULLET ,40 @BULLET ], and [60 @BULLET ,80 @BULLET ]</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false" coords="8,285.12,397.27,250.38,20.38"><figDesc coords="8,451.77,397.27,83.72,10.42;8,285.12,407.23,33.12,10.42">0 @BULLET ,20 @BULLET ], [20 @BULLET ,40 @BULLET ], and [60 @BULLET ,80 @BULLET ]</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false" coords="8,285.12,623.94,250.38,107.15"><figDesc coords="8,285.12,623.94,27.62,7.37">Table 1.</figDesc><table coords="8,285.12,623.94,250.38,107.15">Table of mean values µ and standard deviations σ for the error 
area distribution within participants for each shading condition and each 
interval of the curve we analyzed. 

E A (a, b) 
E B (a, b) 
(a,b) 
µ 
σ 
µ 
σ 
(0 @BULLET ,90 @BULLET ) 
863.82 274.06 
813.34 
244.78 
(0 @BULLET ,20 @BULLET ) 
93.95 
73.075 104.1862 72.59458 
(20 @BULLET ,40 @BULLET ) 126.34 
58.52 
114.82 
44.6 
(40 @BULLET ,60 @BULLET ) 
314.9 
96.6 
273.54 
104.15 
(60 @BULLET ,80 @BULLET ) 284.08 
136.8 
275.38 
127.06 </table></figure>

			<note place="foot">It uses a Tissot&apos;s indicatrix, i.e., an ellipse of distortion – a mathematical tool that characterizes distortions from a map projection. When the indicatrix is aligned with a surface that is perpendicular to the viewing direction, it appears as a circle. When the surface is slanted from the viewing direction, it is seen as an ellipse. A gauge-figure consists of a Tissot&apos;s indicatrix and a stick perpendicular to the plane defined by the indicatrix. On each trial, the observers&apos; task is to align the indicatrix with the perceived shaded surface. At the same time, the stick should be aligned with the surface normal at the point where it intersects the surface. In Figure 4, we illustrate an example of a bad and a good orientation of a gauge figure. This task has been employed for example by O&apos;Shea et al. to measure the accuracy of surface perception under varying slant of the illumination direction [26]. ˇ Soltészová et al. utilized this test to compare the surface perception for different styles of shadow rendering [32]. Cole et al. conducted a large-scale gauge-figure experiment, where they compared the accuracy of surface perception from automatic and man-made line-drawing representations of objects compared to their fully-shaded renderings [6]. Their experiment is the most relevant for our work. Their study was performed on 14 different images, both organic and man made. On each object, they randomly selected 90, 180 or 210 positions. In all, they collected 275K solved gauge-figure trials accomplished by a total of 560 people and published this large dataset including user responses, datasets, scene settings and documentation. Depth-profile adjustment mask: On each trial, observers are exposed to a shaded surface overlaid by aligned and equally spaced dots. In a second separate window, these dots are presented over a blank background and the observer is asked to adjust them so that they fit the perceived height profile defined by the dots in the first window. Summary: Koenderink and colleagues compared these three tasks [17]. Coherent results can be achieved across observers and tasks. By far, the easiest and the most natural task to perform is the gauge-figure task. The judgment is instant, with no obvious reasoning; observers do not have to deduce their answers from their mental image . The pairwise depth-comparison task is also easy, but feels more boring and less natural. Observers have to abstract their answer from what they have perceived. It involves simple overt reasoning. The cross-section reproduction tasks feel not so much unnatural as indirect. With respect to reliability, the gauge-figure task is the most reliable. 3 PERCEPTUAL STATISTICS In the original visualization pipeline, the data pass through the following stages until they reach the observer. After the acquisition stage, the data can be analyzed, filtered or processed in the data enhancement stage and later mapped to visual properties. Finally, the data are rendered and presented to the user. In some cases, the effect on perception is evaluated. Even though this is a step towards the perceptual aspect of visualization, the link from the evaluation back to the design of the rendering technique is practically non-existent. In Figure 2, we show our new concept. We establish a new link that connects the results of an evaluation of a chosen rendering technique and the rendering technique itself. Starting from the rendering stage, the new pipeline now passes the following steps. The rendering is a distal stimulus which yields some sensory input which is interpreted by the HVS. This process is labelled perception. Evaluation refers to processing of the perceived information into the signal which corresponds to the ground truth and the error. Applying statistical methods to analyze the trends of the error allows us to model this error if it is systematic. This new knowledge is then sent to the rendering stage again. The rendering algorithm now becomes aware of the perceptual error it causes and can account for it. If we see the pipeline shown in Figure 2 as a directed graph, the new link makes the graph cyclic. This allows for the possibility to loop between the rendering stage, evaluation and improvement. In this paper, we present how this concept can be used to improve the perception of surface slant in visualizations viewed on monoscopic screens, which is systematically underestimated [7, 34].</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,40.76,74.58,232.12,7.13;10,40.76,84.05,208.42,7.13"  xml:id="b0">
	<monogr>
		<title level="m" type="main">Adobe Photoshop CS4 -The &quot; Curves</title>
		<author>
			<persName>
				<surname>Adobe</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,93.51,232.12,7.13;10,40.76,102.97,197.80,7.13"  xml:id="b1">
	<analytic>
		<title level="a" type="main">The bas-relief ambiguity</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Belhumeur</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Kriegman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Yuille</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="44" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,112.44,232.12,7.13;10,40.76,121.90,232.12,7.13;10,40.76,131.37,84.35,7.13"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Researchers misunderstand confidence intervals and standard error bars</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Belia</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Fidler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>William</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Cumming</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="389" to="396" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,140.83,232.12,7.13;10,40.76,148.81,167.52,8.61"  xml:id="b3">
	<monogr>
		<title level="m" type="main">Statistical power analysis for the behavioral sciences</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Routledge Academic Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>nd. edition</note>
</biblStruct>

<biblStruct coords="10,40.76,159.76,232.12,7.13;10,40.76,169.23,17.93,7.13"  xml:id="b4">
	<analytic>
		<title level="a" type="main">A power primer</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="159" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,178.69,232.12,7.13;10,40.76,188.15,232.12,7.13;10,40.76,197.62,178.85,7.13"  xml:id="b5">
	<analytic>
		<title level="a" type="main">How well do line drawings depict shape?</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Cole</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Sanik</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Decarlo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Finkelstein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Funkhouser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Rusinkiewicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Singh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">2828</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="289" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,207.08,232.12,7.13;10,40.76,216.55,136.25,7.13"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Shape from shaded random surfaces</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>De Haan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Erens</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Noest</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="2985" to="3001" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,226.01,232.12,7.13;10,40.76,235.48,181.84,7.13"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Specular reflections and the perception of shape</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Fleming</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Torralba</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Adelson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="798" to="820" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,244.94,232.12,7.13;10,40.76,254.41,226.60,7.13"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Lambertian shading</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gallardo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3D Lighting: History, Concepts and Techniques, page 117. Charles River Media</title>
		<meeting><address><addrLine>Inc., Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,263.87,232.12,7.13;10,40.76,273.34,125.38,7.13"  xml:id="b9">
	<analytic>
		<title level="a" type="main">On methods in the analysis of profile data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Geisser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">W</forename>
				<surname>Greenshouse</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="95" to="112" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,282.80,232.12,7.13;10,40.76,292.26,70.88,7.13"  xml:id="b10">
	<analytic>
		<title level="a" type="main">The ecological approach to visual perception</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Gibson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Houghton Mifflin</title>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,301.73,232.12,7.13;10,40.76,311.19,232.12,7.13;10,40.76,320.66,61.32,7.13"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Human facial illustration: Creation and psychophysical evaluation</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Gooch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Reinhard</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Gooch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="44" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,330.12,232.12,7.13;10,40.76,339.59,232.12,7.13;10,40.76,349.05,150.64,7.13"  xml:id="b12">
	<analytic>
		<title level="a" type="main">An approach to the perceptual optimization of complex visualizations</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">H</forename>
				<surname>House</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">S</forename>
				<surname>Bair</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="509" to="521" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,358.52,232.12,7.13;10,40.76,367.98,150.92,7.13"  xml:id="b13">
	<monogr>
		<title level="m" type="main">Shape from shading. I: Surface curvature and orientation. Perception</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Johnston</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Passmore</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="169" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,377.45,232.12,7.13;10,40.76,386.91,232.12,7.13;10,40.76,396.37,33.87,7.13"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Persuading visual attention through geometry</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Varshney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="772" to="782" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,405.84,232.12,7.13;10,40.76,415.30,207.91,7.13"  xml:id="b15">
	<monogr>
		<title level="m" type="main">Surface perception in pictures. Perception and &amp; Psychophysics</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Koenderink</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Van Doorn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kappers</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="487" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,424.77,232.12,7.13;10,40.76,434.23,168.82,7.13"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Ambiguity and the mental eye in pictorial relief</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Koenderink</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Van Doorn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kappers</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="431" to="448" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,443.70,232.12,7.13;10,40.76,453.16,232.12,7.13;10,40.76,462.63,232.12,7.13"  xml:id="b17">
	<analytic>
		<title level="a" type="main">About the influence of illumination models on image comprehension in direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Lindemann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1922" to="1931" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,472.09,232.12,7.13;10,40.76,481.55,61.10,7.13"  xml:id="b18">
	<monogr>
		<title level="m" type="main">Vision and art – the biology of seeing. Abrams, paperback edition</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Livingstone</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,491.02,232.12,7.13;10,40.76,500.48,107.75,7.13"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Prior knowledge on the illumination position</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Mamassian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Goutcher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,509.95,232.12,7.13;10,40.76,519.41,201.76,7.13"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Illumination, shading and the perception of local orientation</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Mamassian</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Kersten</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="2351" to="2367" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,528.88,232.12,7.13;10,40.76,538.34,84.08,7.13"  xml:id="b21">
	<monogr>
		<title level="m" type="main">Matlab: The language of technical computing. www. mathworks.com</title>
		<author>
			<persName>
				<surname>Mathworks</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,547.81,232.12,7.13;10,40.76,557.27,228.75,7.13"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Significance test for sphericity of a normal n-variate distribution</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Mauchly</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="204" to="209" />
			<date type="published" when="1940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,566.74,232.12,7.13;10,40.76,576.20,126.11,7.13"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Perception of solid shape from shading</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Mingolla</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Todd</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="137" to="151" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,585.66,232.12,7.13;10,40.76,595.13,232.12,7.13;10,40.76,604.59,122.97,7.13"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual discrimination of local surface structure: Slant, tilt, and curvedness</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">F</forename>
				<surname>Norman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Todd</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Norman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">M</forename>
				<surname>Clayton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">R</forename>
				<surname>Mcbride</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1057" to="1069" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,614.06,232.12,7.13;10,40.76,623.52,232.12,7.13;10,40.76,632.99,232.12,7.13;10,40.76,642.45,49.81,7.13"  xml:id="b25">
	<analytic>
		<title level="a" type="main">The assumed light direction for perceiving shape from shading</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">P</forename>
				<surname>O &apos;shea</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">S</forename>
				<surname>Banks</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Agrawala</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th symposium on Applied perception in graphics and visualization</title>
		<meeting>the 5th symposium on Applied perception in graphics and visualization</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,651.92,232.12,7.13;10,40.76,661.38,232.12,7.13;10,40.76,670.84,123.63,7.13"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Data visualization optimization via computational modeling of perception</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Pineo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="309" to="320" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,680.31,232.12,7.13;10,40.76,689.77,119.64,7.13"  xml:id="b27">
	<analytic>
		<title level="a" type="main">3-D shape perception</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Pizlo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Salach-Golyska</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception and Psychophysics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="695" to="714" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,699.24,232.12,7.13;10,40.76,708.70,232.12,7.13;10,40.76,718.17,37.86,7.13"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Exaggerated shading for depicting shape and detail</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Rusinkiewicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Burns</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Decarlo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1199" to="1205" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,727.63,232.12,7.13;10,40.76,737.10,183.72,7.13;10,285.12,54.06,71.37,7.13;10,384.91,54.06,88.68,7.13;10,502.03,54.48,33.47,6.15;10,303.38,63.95,196.06,6.15;10,303.38,72.99,131.90,7.13"  xml:id="b29">
	<analytic>
		<title level="a" type="main">An analysis of variance test for normality (complete samples)</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">S</forename>
				<surname>Shapiro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">B</forename>
				<surname>Wilk</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31] V. Soltészová. Perceptual-statistics</title>
		<imprint>
			<date type="published" when="1965" />
			<biblScope unit="page" from="3" to="4591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,82.45,232.12,7.13;10,303.38,91.92,232.12,7.13;10,303.38,101.38,232.12,7.13;10,303.38,110.85,17.93,7.13"  xml:id="b30">
	<analytic>
		<title level="a" type="main">Chromatic shadows for improved perception</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Soltészová</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Patel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Viola</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Non-Photorealistic Animation and Rendering</title>
		<meeting>the ACM SIGGRAPH/Eurographics Symposium on Non-Photorealistic Animation and Rendering</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="105" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,120.31,232.12,7.13;10,303.38,129.78,17.93,7.13"  xml:id="b31">
	<analytic>
		<title level="a" type="main">Where is the sun?</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sun</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Perona</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="183" to="184" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,139.24,232.12,7.13;10,303.38,148.70,65.31,7.13"  xml:id="b32">
	<analytic>
		<title level="a" type="main">The visual perception of 3D shape</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Todd</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="115" to="121" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,158.17,232.12,7.13;10,303.38,167.63,232.12,7.13;10,303.38,177.10,80.72,7.13"  xml:id="b33">
	<analytic>
		<title level="a" type="main">Perception of surface curvature and direction of illumination from patterns of shading</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Todd</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Mingolla</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="583" to="595" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,186.56,232.12,7.13;10,303.38,196.03,222.74,7.13"  xml:id="b34">
	<analytic>
		<title level="a" type="main">The influence of environmental cues on pictorial relief</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Van Doorn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Koenderink</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception -ECVP Abstract Supplement</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,205.49,232.12,7.13;10,303.38,214.96,232.12,7.13;10,303.38,224.42,73.72,7.13"  xml:id="b35">
	<analytic>
		<title level="a" type="main">Light warping for enhanced surface depiction</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Vergne</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pacanowski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Barla</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Granier</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Schlick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">28258</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,233.88,232.12,7.13;10,303.38,243.35,232.12,7.13;10,303.38,252.81,182.31,7.13"  xml:id="b36">
	<analytic>
		<title level="a" type="main">Improving shape depiction under arbitrary rendering</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Vergne</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pacanowski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Barla</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Granier</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Shlick</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1071" to="1081" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,262.28,232.12,7.13;10,303.38,271.74,85.52,7.13"  xml:id="b37">
	<analytic>
		<title level="a" type="main">Individual comparisons by ranking methods</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Wilcoxon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics bulletin</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="80" to="83" />
			<date type="published" when="1945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,281.21,232.12,7.13;10,303.38,290.67,36.26,7.13"  xml:id="b38">
	<monogr>
		<title level="m" type="main">Yafaray 0.0.9: Yet another free raycaster. www.yafaray. org</title>
		<author>
			<persName>
				<surname>Yafaray</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
