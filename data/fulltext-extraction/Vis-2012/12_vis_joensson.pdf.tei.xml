<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Daniel</forename>
								<forename type="middle">J ¨</forename>
								<surname>Onsson</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Joel</forename>
								<surname>Kronander</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Timo</forename>
								<surname>Ropinski</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Anders</forename>
								<surname>Ynnerman</surname>
							</persName>
						</author>
						<title level="a" type="main">Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Volume rendering</term>
					<term>photon mapping</term>
					<term>global illumination</term>
					<term>participating media</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. A CT scan of a hand rendered using the proposed historygram-based volumetric photon mapper. The insets show the high dynamic range achievable in shadowed areas resulting from multiple scattering, as well as the usage of different materials. When using our method only ∼ 30% of the light transport solutions need to be recomputed when changing the material of the bone. Abstract—In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p> Interactive Direct Volume Rendering (DVR) is an increasingly important method for exploration and presentation of data in a wide range of application domains. Rendering speeds for volume data have improved greatly over the past decades due to development of both hardware and algorithms. However, current methods for volumetric illumination in DVR are still severely limited, often only handling single-scattering, fixed illumination or not even taking volumetric selfshadowing into account <ref type="bibr" coords="1,122.03,576.31,13.74,8.12" target="#b14">[16]</ref>. This is in sharp contrast to the more complex models that have been deployed in off-line rendering of realistic looking images of both surface and volumetric objects <ref type="bibr" coords="1,241.98,596.24,9.52,8.12" target="#b3">[4]</ref>. Within DVR tradeoffs have usually been made in order to support interactive editing of the transfer function (TF), which is an integral part of any DVR pipeline. The driving force behind the desire to apply more realistic  nation is the fact that light is the fundamental carrier of visual information . The lighting used in the rendering of an image has an enormous impact on how it is interpreted by a human observer. By carefully designing the lighting setup, illumination can reveal strong visual cues <ref type="bibr" coords="1,312.71,545.75,14.19,8.12" target="#b19">[21,</ref><ref type="bibr" coords="1,329.55,545.75,11.95,8.12" target="#b21"> 23] </ref>describing global structures, local details and curvature of surfaces and volumetric structures that would otherwise be hidden from the observer. It has, furthermore, been shown that a perceptually important part of the light interaction in the scene is light that has scattered more than one time in the medium <ref type="bibr" coords="1,453.99,585.60,9.71,8.12" target="#b7">[8,</ref><ref type="bibr" coords="1,465.95,585.60,10.64,8.12" target="#b15"> 17]</ref>. In this work we enable highly realistic volume renderings at interactive rates, based on photon mapping. We achieve interactive frame rates, by introducing a novel approach where only light interactions that have been affected by the parameter changes are recomputed. Photon mapping (PM) is extensively used in computer graphics for rendering participating media <ref type="bibr" coords="1,406.83,646.67,14.19,8.12" target="#b12">[14,</ref><ref type="bibr" coords="1,424.74,646.67,10.64,8.12" target="#b13"> 15]</ref>, as it is an efficient method for producing physically plausible global illumination effects. Even though photon mapping can produce a wide range of illumination effects , it has so far been too expensive to be used in interactive volumetric illumination. This is due to the fact that all view-rays and all photons need to be recomputed as soon as the scattering parameters change, which prevents interactive TF editing. In this paper we introduce interactive photon mapping for DVR by proposing a novel concept , which we refer to as Historygrams. A Historygram is a histogram of the parameters used to compute a photon, or a viewing ray. Thus, Historygrams enable us to detect which photons and viewing rays are invalid based on a parameter change, for example, editing the TF. We then only recompute these invalid parts, and can thus achieve interactive rendering times while producing highly realistic images (see <ref type="figure" coords="2,22.50,93.14,26.40,8.12">figure 1</ref>). The main contributions of this paper are: @BULLET Enabling volumetric photon mapping for use in DVR, allowing interactive editing of the TF and, a range of perceptually important global illumination effects, such as multiple-scattering and specular materials. @BULLET Introduction of Historygrams, a novel concept for efficiently storing and evaluating the parameter history upon which a particular computed object (viewing ray segment or photon path) is dependent on. @BULLET Methods and data structures for efficient queries of individual Historygrams for large numbers of objects. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Interactive rendering of global illumination effects has been a long standing challenge in computer graphics. Here we focus on photon mapping techniques as well as those techniques proposed for interactive DVR. Ritschel et al. provide a more comprehensive overview of interactive global illumination techniques in a recent survey <ref type="bibr" coords="2,239.02,267.81,13.74,8.12" target="#b25">[27]</ref>. Photon Mapping. Photon mapping is a biased two-pass global illumination algorithm that often produces images with less noise than other Monte Carlo algorithms <ref type="bibr" coords="2,112.75,297.79,13.74,8.12" target="#b12">[14]</ref> . In the first pass, a photon map, representing the incident illumination in the scene, is generated by tracing photons from light sources through the scene. The second pass estimates the final rendering using ray-tracing, whereby the radiance in the scene is estimated by computing an approximation of the photon density given by the photon map computed in the first pass. However, for finite sample sets, this approximation smooths the true radiance and causes bias, i. e., a nonzero expected error. Still, PM is generally a consistent Monte Carlo method, meaning that, in the limit of using an infinite number of photons, the approximation converges to the true solution. Recent work on Progressive Photon Mapping (PPM) <ref type="bibr" coords="2,250.87,397.41,9.71,8.12" target="#b8">[9,</ref><ref type="bibr" coords="2,263.16,397.41,6.47,8.12" target="#b4"> 5]</ref>, provides a way to reduce bias by using several rendering passes where photons are progressively traced and discarded, updating the radiance estimates after each photon tracing pass in such a way that the approximation converges to the correct solution in the limit. PM for volumetric media was first introduced by Jensen and Christensen <ref type="bibr" coords="2,255.69,447.23,13.74,8.12" target="#b13">[15]</ref>. Jarosz et al. <ref type="bibr" coords="2,71.34,457.19,14.94,8.12" target="#b11">[13] </ref>improved on the original formulation by using a more efficient beam radiance query, instead of using redundant photon density estimations during ray marching. Recently, Jarosz et al. <ref type="bibr" coords="2,257.93,477.11,14.94,8.12">[12] </ref>also showed how to approximate the photon density as a set of photon beams, improving the performance further. In general our method is orthogonal to these concepts, however some minor modifications are necessary which we discuss in Section 7. None of the discussed methods effectively handle the effects of local parameter changes and, thus, need to recompute the entire photon map (all photon beams) and all view-rays even for small parameter changes. In contrast, Dmitriev et al. <ref type="bibr" coords="2,33.61,556.82,9.52,8.12" target="#b5">[6]</ref>, propose to reuse unaffected photons across frames in dynamic scenes. Using Quasi-Monte Carlo photon tracing they first randomly retrace a small set of photons to find regions where photons need to be recomputed. They then show how photons in affected regions can be found from the set of sparse samples with a high probability by using the periodicity of the generated quasi-random Halton sequence to find photons with similar paths. Although, the idea of reusing valid photons across frames is not new in computer graphics, to the authors knowledge these methods have not been applied in the context of volume rendering before and no previous work has considered adaptive photon retracing based on TF edits. Interactive Illumination for DVR. Traditionally, full global illumination effects have been too costly to be used in interactive DVR applications , and instead different approximations have been made. We address a few of these approaches, and refer the reader to a more complete survey by Jönsson et. al <ref type="bibr" coords="2,130.10,706.35,13.74,8.12" target="#b14">[16]</ref>. Several methods exploit texture slicing to estimate forward scattering , shadows and color bleeding <ref type="bibr" coords="2,139.43,726.37,14.19,8.12" target="#b16">[18,</ref><ref type="bibr" coords="2,155.67,726.37,11.21,8.12" target="#b30"> 32,</ref><ref type="bibr" coords="2,168.94,726.37,10.64,8.12"> 34]</ref>. While these approaches, can only be used in slice-based renderers, several ambient occlusion approaches are renderer independent. Hernell et al. perform a raycasting pass per voxel over a local spherical neighborhood <ref type="bibr" coords="2,496.17,63.26,13.74,8.12" target="#b10">[11]</ref>, while Ropinski et al. <ref type="bibr" coords="2,340.79,73.22,14.94,8.12" target="#b28">[30] </ref>compute local data histograms to obtain ambient occlusion effects. However, these methods are limited to local effects and do not, in contrast to our approach, incorporate physically based global illumination effects. To simulate global shadow effects, methods computing shadow volumes <ref type="bibr" coords="2,405.15,113.07,9.71,8.12" target="#b2">[3,</ref><ref type="bibr" coords="2,417.83,113.07,11.95,8.12" target="#b27"> 29] </ref>and deep shadow maps <ref type="bibr" coords="2,520.55,113.07,14.94,8.12" target="#b9">[10] </ref>have been presented. These methods sample the volumetric occlusion from the light sources utilizing efficient pre-computed data structures. More recently, Sundén et al. <ref type="bibr" coords="2,390.87,142.96,14.94,8.12" target="#b31">[33] </ref>have proposed exploiting the plane sweep paradigm to enable dynamic illumination with a low memory overhead at interactive frame rates. Kronander et al. <ref type="bibr" coords="2,474.88,162.88,14.94,8.12" target="#b18">[20] </ref> uses an efficient multi-resolution grid to store visibility information using Spherical Harmonics. Lindemann and Ropinski <ref type="bibr" coords="2,433.02,182.81,14.94,8.12" target="#b20">[22] </ref>have exploited spherical harmonics in a similar manner for enabling advanced material properties in the context of DVR. To achieve physically more plausible results , unbiased Monte Carlo methods have also been adopted for realtime DVR <ref type="bibr" coords="2,323.59,222.66,14.19,8.12" target="#b29">[31,</ref><ref type="bibr" coords="2,339.77,222.66,10.64,8.12" target="#b17"> 19]</ref>. However, interactivity is limited as TF updates are expensive since the complete volume transport has to be recomputed for all, even minor or local, TF changes. Alternatively, for real-time rendering of participating media the full global illumination solution can be approximated by focusing only on single scattering <ref type="bibr" coords="2,496.54,262.51,9.52,8.12" target="#b6">[7]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BACKGROUND</head><p>In this section we provide the theoretical background for volumetric photon mapping. Subsection 3.1 describes the details of light transport in a participating medium and establises notations, while we show how to numerically approximate the light transport using volumetric PM in Subsection 3.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Volumetric Illumination Model</head><p>In participating media, photons are affected by emission, in-scattering, absorption and out-scattering <ref type="bibr" coords="2,391.95,372.99,13.74,8.12" target="#b23">[25]</ref>. We start our derivation by considering a sample x along a viewing ray. Radiance L s (x, ω o ) emitted and scattered from x into the direction ω o can be defined as: </p><formula>L s (x, ω o ) = σ s L i (x, ω o ) + σ a L e (x, ω o ), </formula><formula>(1) </formula><p> where σ s is the scattering coefficient and σ a is the absorption coefficient . The radiance reaching a point x c along the viewing ray with direction ω o is the sum of the background radiance L 0 ( x 0 , ω o ), at the boundary of the volume and the accumulated emitted and in-scattered radiance from the medium. </p><formula>L(x c , ω o ) = T (x 0 , x c )L 0 (x 0 , ω o )+ x c x o T (x, x c )(σ s L i (x, ω o ) + σ a L e (x, ω o ))dx, </formula><formula>(2) </formula><p> where T (x i , x j ) is the transmittance between points x i and x j , describing how light is attenuated when traveling through the volume </p><formula>T (x i , x j ) = e − x j x i τ(x ′ )dx ′ , </formula><formula>(3) </formula><p> where τ(x ′ ) specifies the extinction at x ′ . One property of the transmittance , which we utilize in this work, is that the transmittance is multiplicative, i. e. that it can be divided into segments and multipled together: </p><formula>T ( x i , x j ) = T ( x i , x k ) · T ( x k , x j ). </formula><formula>(4) </formula><p>The in-scattered radiance, L i (x, ω), depends on radiance arriving at x from all directions, ω, over the sphere of directions ,Ω 4π , </p><formula>L i (x, ω) = Ω 4π s(x, ω ′ , ω)L(x, ω ′ )d ω ′ (5) </formula><p>where s(x, </p><formula>ω i , ω o ) </formula><p>represents the scattering function at the point x. In this work, we enable s( x, ω i , ω o ) to shift between phase function and BRDF depending on the material given by the TF. This allows the user to create surface-like materials within the volume. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Volumetric Photon Mapping</head><p>In this work we adopt the standard photon mapping framework for volumetric media, originally proposed by Jensen and Christensen <ref type="bibr" coords="3,264.69,76.59,13.74,8.12" target="#b13">[15]</ref>. Photon Tracing. In a first pass, a Markov random-walk approach is used to trace photons from light sources into and through the volume. For each photon, importance sampling is used to select from which light source the photon should be traced, and to generate a position and direction on the chosen light source. Photons traced through the volume may either pass unaffected or interact (be absorbed, or scattered ) at each point. To decide if and where the photon interacts with the media, we draw a sample from the probability distribution of a scattering or absorption event, by using the inversion method. The cumulative probability distribution for an interaction event is given by </p><formula>C(x) = 1 − T (x s , x) = 1 − e − x xs τ(x ′ )dx ′ , (6) </formula><p>where x s is the point at which the photon enters the volume and the transparency, T (x s , x), is computed using standard ray-marching. At each point where the photon interacts with the volume a copy of the photon flux and incoming direction of the photon is stored in the photon map. Russian roulette is used to decide if the photon is absorbed or scattered further in the medium. The probability that a photon is scattered is given by </p><formula>p(x) = σ s (x) τ(x) . </formula><formula>(7) </formula><p>If the photon is scattered, importance sampling of the phase function or BRDF is used to determine its new direction. Rendering. To render the final image, viewing rays are generated and ray-marching is used to evaluate equation (2). For each sampled point along the ray, the photon map is used to form an estimate of the in-scattered radiance. By using a spherical kernel of radius r, the n closest photons are used to estimate the in-scattered radiance </p><formula>L i (x, ω) ≈ 1 σ s (x) n ∑ p=1 s(x, ω p , ω) ∆Φ p (x, ω p ) 4 3 πr 3 , </formula><formula>(8) </formula><p>where Φ p is the flux of the photon, p, in direction ω p . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHOD</head><p>In this section we describe in detail how volumetric photon mapping can be extended to handle interactive TF and other rendering parameter changes, by using the Historygram concept in the context of DVR. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p>An important part of any DVR pipeline is the exploration of volume data by performing interactive TF changes. This affects light transport as the TF maps data values to material properties, such as transmittance , τ(x), scattering coefficient, σ s (x), absorption coefficient, σ a (x), scattering function, s(x, </p><formula>ω i , ω o )</formula><p>. Thus, any pre-computation which relies on volume material properties must be recomputed as soon as the user changes the TF. Furthermore, interactive data exploration using the TF means that the volumetric medium may change in every rendered frame. However, typically, the user does not make global changes to the TF, but, instead, focuses on exploring different objects in the volume, one at a time, or on tuning localized material properties . Consider, for example adjusting the diffuse color of the bone in <ref type="figure" coords="3,31.50,666.59,26.34,8.12">figure 1</ref> . This enables us to only recompute the parts of the light transport simulation which are affected by the changes, and reuse the ones that do not change. To accomplish this we introduce an efficient partition of the light transport calculations where we are using photons to partition the incident illumination in the volume and view-ray segments for partitioning the ray-marching computations, as illustrated in <ref type="figure" coords="3,31.50,726.37,26.28,8.12">figure 2</ref>. Each partitioning of the light transport solution stores its own Historygram specifying which parameters have been used during the <ref type="figure" coords="3,294.12,194.41,19.57,7.64">Fig. 2</ref> . To localize the effect of parameter changes on the light transport solution, we partition both the incident illumination using photons and view-rays using ray-segments. To encode the parameters used for the computation of each partition object, we store a separate Historygram for each object. In this scheme, using only two material parameters , depicted by light blue and light red, a simple Historygram using only two bits can be used to store the parameter history of each computational object (photon, ray-segment). When tracing photons from the light source, each photon inherits its ancestors Historygram due to scattering , while for ray-segments each Historygram is independent of the other segments Historygrams. </p><formula>P1 P2 P3 P4 Eye ⎫ ⎪ ⎬ ⎪ ⎭ ⎫ ⎪ ⎬ ⎪ ⎭ ⎫ ⎪ ⎬ ⎪ ⎭ ⎫ ⎪ ⎬ ⎪ ⎭ S1 S2 S7 S2 ⎫ ⎪ ⎬ ⎪ ⎭ S3 ⎫ ⎪ ⎬ ⎪ ⎭ S4 ⎫ ⎪ ⎬ ⎪ ⎭ S5 ⎫ ⎪ ⎬ ⎪ ⎭ S6 </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>computation </head><p>of this object (view-ray segment, photon). It is important to note that the parameters in our case consist of volume data intensities since this makes the created Historygram independent of current TFs, see section 4.3. Historygrams are a binary data structure defined to provide a minimal memory footprint, while at the same time, being efficient to query. When the user changes the TF we use the changed parameter values to form a query over all stored Historygrams and, thus, isolate the parts of the light transport solution which need to be recomputed. To recompute the light transport in the volume, we first update all invalid photons, i. e., retracing them from the last unaffected intersection. Afterwards, affected viewing-ray segments are updated. In section 4.2 we discuss how a general Historygram is constructed, stored and effectively queried. We then, in section 4.3, explain how we can efficiently store commonly used parameters in DVR using the Historygram data structure. Compared to a standard photon map, we store an additional Historygram for each photon in the photon map, encoding the history of the light path the photon has traversed. The exact details on how each photons Historygram is computed, are discussed in section 4.3.1. We additionally store a separate Historygram for each view-ray segment. To only update parts of the viewing rays at a time, the multiplicative property of the volume rendering integral is used which states that compositing transparency can be performed in any order. In section 4.3.2, we show how we can recompute only those segments of viewing rays, which are affected by a TF update. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Historygrams</head><p>A Historygram represents a set of parameters, which has been used during the computation of a particular object, e. g., a view-ray segment or a photon. Before we discuss the application of Historygrams, we will detail the notation of a Historygram and show how a Historygram is incrementally constructed. We then describe an efficient way of querying Historygrams, and how we can represent Historygrams using an efficient binary data structure. Notation. The Historygram, H, is a set of representable parameter sets Z i . A specific Z i represents a group of parameters represented as a single entry in the Historygram. To map an arbitrary parameter, x, to a representable set Z i we define a mapping, δ : x → {Z i , i = 1...n}. This mapping thus describes how arbitrary parameters are represented in the Historygram H. Constructing Historygrams. At first, the Historygrams of all objects are set to the empty set H 0 = / 0. During the computation of an object with Historygram H i , the parameters used , x j , j = 1...n, are added to <ref type="figure" coords="4,22.50,130.50,19.20,7.64">Fig. 3</ref>. Transfer function changes are mapped to a query Historygram, H q , in the form of a finite sequence of binary values. The current TF setting is represented by a dashed blue line, and the new TF setting by a solid red line. Given the difference in the TF setting, the changes are mapped to affected data value intervals. A query Historygram with a 6 bit representation is shown in the bottom. By intersecting the intervals with the support of the bins in the discrete Historygram representation, affected bins are set to 1, and unaffected bins are set to 0. </p><formula>the set H i+1 H i+1 = H i n j=1 δ (x j ), </formula><formula>(9) </formula><p>where H i is the previous Historygram and H i+1 is the new Historygram containing both the previous set of used parameters, and x. When the computation has completed, the Historygram will thus contain information about all parameters used during its lifetime. Historygram Queries. When the parameters specifying the global light transport solution change, we would like to evaluate which objects need to be updated. Therefore, equation 9 is used to map the changed parameters into a Query-Historygram H q . Then, for all objects we evaluate which subsets of parameters in the objects Historygram , H, is affected by the change, by intersecting the sets </p><formula>H u = H ∩ H q , </formula><formula>(10) </formula><p>where H u represents the set of affected parameter sets. If the resulting H u is non empty we recompute the object with Historygram H. Historygram Representation. We propose to use a binary representation of the Historygram H. This saves storage as only one bit needs to be used to represent if a subset of parameters Z i has been used. Furthermore, for Historygram queries, the union ∪, and intersection ∩, can then be evaluated using the OR and AND operator respectively. As these operations can be translated directly to hardware instructions, they are extremely fast to evaluate. Also, since we use a binary representation , we know that if H u is not equal to zero at least one parameter subset that was used during the computation has changed . All together, this allows us to efficiently answer the question if a computation has used a certain set of parameters or not. Thus, computations which are not affected by a set of parameter changes may be reused. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Historygrams for Photon Mapping in DVR</head><p>In a standard DVR pipeline, the TF is used to map scalar data values to optical properties. Using the fact that material properties in the volume directly correspond to data values through the TF mapping, we can use a mapping δ , to transform data values to a representable set of parameters Z i . This enables the Historygram computation to be independent of the current TF as only data values from the volume are used. An example of a δ (x) function, which maps data value x ∈ <ref type="bibr" coords="4,255.47,620.25,9.45,8.97">[0,</ref><ref type="bibr" coords="4,265.91,620.80,6.97,8.12" target="#b0"> 1] </ref>to a binary representable set in H is </p><formula>δ (x) = 1 &lt;&lt; f loor(x * (p − 1)), </formula><formula>(11) </formula><p>where &lt;&lt; denotes the left bit shift operator and p is the number of bits used for the Historygram. Typically, p is 32 or 64 such that the native bit shift operator can be used. This corresponds to uniformly discretizing the TF domain into a set of p bins. Each bin corresponds to the parameters specified through the TF for the range of data values represented by the bin. Query Historygrams are constructed in a similar manner. First, we map the TF change to the affected data values, and then we construct the query using δ (x) as in equation (11) (see <ref type="figure" coords="4,285.12,53.29,27.32,8.12">figure 3</ref> ). In the following two subsections, we explain how we facilitate the Historygram concept for photons and viewing-rays in the context of DVR. Based on the Historygram representation, it can be determined efficiently through binary processing, i. e., bitwise operations , if photons or viewing-rays are invalid. For storage, a single bit represents a change of a parameter, which means that for instance eight parameters can be represented using a single byte. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Photon Historygrams</head><p>As a photon traverses the medium it may be absorbed, or scattered in different directions depending on optical properties of the medium. This means that photons are dependent on previous interactions with the volumetric medium. Therefore we must take this into account when updating photon interactions. To do so, we create Historygrams based on the volume data intensity as discussed in the previous section . As soon as a photon interacts with the medium (scatters or absorbs , see Section 3.2), we store the Historygram, position, direction and power of the photon interaction. A scattered photon continues to use the Historygram, which means that the last photon interaction will know about all data that was used for all scattering events of that photon . Then, when the parameters change and a query Historygram has been created, we start by evaluating the last photon interaction. If the last photon interaction was not affected by the parameter change, we know that none of the previous ones where not either, and thus we do not need to update any of them. However, if the photon interaction was affected by the parameter change, we continue backwards until we find a photon interaction which was not affected. Given the position of the last valid photon interaction, and the material properties at that location, we can apply importance sampling to determine a new direction and restart photon tracing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">View-Ray Historygrams</head><p>For rays cast from the camera, we utilize Equation (4), which states that the transmittance between two points can be divided into smaller segments and multiplied together. Thus, each segment can be treated independently. This means, that, if the user changes a parameter which affects the inner parts of the volume, segments before and after do not need to be recomputed as they are not affected by the change. Using the same approach as for photon interactions, each segment forms its Historygram using equation (9) and equation (11). Therefore, we store the Historygram of each segment together with the color. When the user changes the material parameters we analyze if the segment has been affected, using the query Historygram, and recompute it if necessary . Generally we uniformly divide each view-ray into a user defined number of segments, V n . For a standard DVR pipeline the Historygram only needs to be computed the first time a segment is computed, as the underlying data does not change. The creation of Historygrams for view-rays is therefore performed as soon as the camera stops moving . Then, when performing incremental updates, the Historygram does not need to be updated. In some cases ray segments need to be recomputed even though the used volume data intensity is not affected by the parameter change. For instance, this occurs when one structure within the data casts a shadow on a another structure consisting of different intensity values. If the occluding structure is removed, then the remaining structure should be updated to take new photons into account. If this is not done the view segments including the remaining object will not be updated , and will appear to be in shadow even though they are not. It is therefore not enough to know the data intensity based Historygram alone. Instead, the spatial location of the changes is important. This issue can be handled in various ways, but we propose the use of Historygrams for this as well. One Historygram is allocated for each of the three dimensions of the data set. As an example, for a volume of dimensions 64 3 we can recognize spatial changes at voxel resolution using only 3 · 64 bits, i.e. 64 bits per dimension. When a photon interaction is removed or added due to a parameter change, a mapping function is used for each dimension to update a single, global, spatial Historygram. When all photons have been updated, this global spatial Historygram will contain information about where all illumination (a) Shadow ray-caster <ref type="bibr" coords="5,182.25,192.34,13.28,7.22" target="#b26">[28] </ref>(b) Our method using single scattering (c) Our method using multiple scattering <ref type="figure" coords="5,31.50,215.45,22.95,7.64">Fig. 4.</ref>(a) Synthetic Cornell Box (256 × 256 × 256 voxels) shaded using shadow volume propagation which simulates multiple-scattering with a diffusion process <ref type="bibr" coords="5,93.46,224.92,12.41,7.64" target="#b26">[28]</ref>, (b) our method using 4 million photons and single scattering, (c) our method using 4 million photons and multiple scattering. changes have been made. Then, when updating view-ray segments, in addition to the Historygram based on data intensity, the segment also queries the spatial Historygram for changes within the photon radius. In this paper, most changes made have been local, or affected the same data intensities. Therefore, the spatial Historygram evaluation has not been performed. It should, however, be considered for applications where illumination accuracy is of importance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IMPLEMENTATION</head><p>To realize the interactive application of the proposed Historygram method, we have implemented the described concepts using OpenCL. Data Structures. When the user changes the TF, it is neessecary to search for invalid photons and viewing-ray segments. Additionally, it is necessary to determine the order of scattering events for photons. For this purpose, we use an implicitly linked list where the photon interaction id determines the index into the list. In our implementation we store the Historygram for each photon interaction in addition to its position, direction and power. We apply the same implicitly linked list concept to view-ray segments where the Historygram is stored together with the color. Thus, when the TF changes, we can start at the last stored scattering event and move backwards in the list until a valid photon is found. In order to evaluate the in-scattered radiance during rendering, we need to be able to find nearby photons for a location x. To do so, we have adopted a chaining hash table as described by Alcantara et al. <ref type="bibr" coords="5,42.83,497.77,9.52,8.12" target="#b0">[1]</ref>, which allows us to find nearby photons in O(1) time. We use a hash function which maps the location x into uniformly distributed bins with the bin size equal to the photon radius. During photon tracing , the index of the bin is stored together with the index of the photon interaction in a list. The list can then be efficiently sorted on the GPU, from the left image to the right image can be performed 7.7 times faster using our Historygram method compared to a GPU complete discard and rerender all photon mapping implementation. based on bin index using radix sort <ref type="bibr" coords="5,421.07,246.35,13.74,8.12" target="#b24">[26]</ref>. The start and end of each bin are then found and used to query how many, and which, photon interactions are near a location. Since the photon radius is used for the bin width, all photons within the given radius can be found by querying the 27 surrounding bins of a location. When the user changes the TF, and a photon is determined to be invalid, we move it from the current location in the hash table to the new location. Algorithm. During the photon tracing process we create a Historygram for each photon interaction using equation 11, with p set to 64, which allows us to use native instructions on the GPU when evaluating Historygrams. As soon as the camera stops moving, we start a ray-casting pass which generates and stores the Historygram for each view-ray segment. Then, when the user starts to change parameters, we create the Historygram H q by comparing the new parameter to the old one and add it if changed. When a photon interaction is found invalid , we set the occupied location in the hash to the maximum integer value. To avoid the use of atomic operations, we reuse locations of the removed photon interactions in the hash table. Then, when the hash table has been sorted, we can determine the last index of the hash by evaluating the number of existing, added and removed photon interactions . Once the photons have been updated, we can start to evaluate view-ray segments. In order to increase the work-group load distribution we update all segments independently and then composite them in a separate step. To incorporate realistic material shading effects, we support different material models. We primarily use isotropic phase functions, although we also support Henyey-Greenstein and the Schlick approximation . For BRDF specification we use the microfacet distribution as given by Ashikimin <ref type="bibr" coords="5,367.24,525.31,10.45,8.12" target="#b1">[2] </ref>or the recently published ABC model <ref type="bibr" coords="5,516.41,525.31,13.74,8.12" target="#b22">[24]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS AND EVALUATION</head><p>In this section, we show the quality and performance of our method on a number of both real world and synthetic examples. All tests were performed on a computer with an Intel Xeon 2.67 GHz processor, 6 GB random access memory and an Nvidia Geforce 570 graphics card. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results</head><p> Using a full global illumination simulation, perceptually important effects , such as multiple-scattering, color bleeding and realistic material functions can be incorporated in the DVR pipeline. <ref type="figure" coords="5,482.80,636.71,30.44,8.12">Figure 4</ref>shows a synthetic Cornell Box (256 × 256 × 256 voxels) shaded using shadow volume propagation as proposed by Ropinski et. al. <ref type="bibr" coords="5,484.69,656.63,13.74,8.12" target="#b26">[28]</ref>, which uses a diffusion process for approximating multiple-scattering, our method using single scattering, and our method using multiple scattering (2 light bounces). As can be seen in the renderings, the diffusion approximation fails to account for multiple scattering in these media, and works best for dense objects. Using single scattering, our method is able to accurately render the thin media in the interior of the room, the transparent box as well as the solid objects in the scene. Multiple scattering effects provide a visually pleasing result, and color-bleeding <ref type="figure" coords="6,22.50,238.31,19.93,7.64">Fig. 6</ref>. Results achieved with our method. a) displays a CT scan of a woman, rendered using 2.1 million photons, 9 view segments, single scattering, and three light sources. A microfacet BRDF function (Ashikimin-Shirley <ref type="bibr" coords="6,316.21,247.77,8.64,7.64" target="#b1">[2]</ref>) was used to add specular reflections to the blood vessels, and an isotropic phase function was used for the bone structures. Varying the material properties of the outer skin layer requires 74% of the photons to be retraced and 24% of the view segments to be recomputed. b) displays a CT scan rendered using 1.6 million photons and 7 view segments. Removing the kidney content requires 35% of the photons and 9% of the view segments to be recomputed. Changing the color of the vessels requires 24% of the photons and 4% of the view segments to be recomputed, thereby enabling speedups of approximately 7 times. <ref type="figure" coords="6,22.50,310.16,24.70,7.64" target="#tab_1">Table 1</ref>. Performance measurements for the data sets used in this paper. As can be seen in the photon tracing and gathering columns with and without Historygrams, interactive editing is enabled in almost all cases with up to 15 times speedup. from the blue medium in the interior of the room can be seen on the walls, the transparent box in the lower right also shows the effect of sub-surface scattering. <ref type="figure" coords="6,32.46,557.41,29.23,8.12">Figure 6</ref>(a) shows a rendering of a CT scan of a woman (resolution 512 × 512 × 625). The images were rendered using single scattering, 2 million photons, 9 view-ray segments, and three light sources. Specular blood vessels and the diffuse bone structure eases the perception of the vessel structure. Changing the transfer function for values affecting the outer skin layer requires recomputing 74% of the photons and 24% of the view segments (see <ref type="figure" coords="6,134.32,617.19,26.20,8.12">figure 6</ref> (a)). As can be seen in the photon tracing and gathering columns in table 1, enabling Historygrams reduces the computation time being non-interactive to interactive in almost all cases. Thus, interactive updates which could not otherwise be performed are now possible. In general our method also performs well on larger data sets, as the photon representation is independent of the resolution of the data set. However, one could also argue that a higher resolution data set requires more photons to display high-frequency shadows. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation and Performance</head><p>The performance of our method is affected by a number of parameters, the most important being: @BULLET P n -The number of photons traced into the scene. @BULLET V n -The number of view-ray segments. @BULLET S n -The maximum order of scattering events used in photon trac- ing. To evaluate the effect of these parameters on the TF update performance , we varied the material properties of one artificial and one medical data set. In the artificial Cornell box data set (256 × 256 × 256 voxels) we enabled nearest neighbor filtering to avoid partial volume effects and changed the color the sphere (see <ref type="figure" coords="6,451.11,616.78,26.83,8.12" target="#fig_2">figure 7</ref> ). For the medical data set we chose the Cenovix data set (361 × 331 × 361), where the vessel material was changed (see <ref type="figure" coords="6,421.33,636.71,26.81,8.12" target="#fig_4">figure 8</ref>). <ref type="figure" coords="6,458.64,636.71,29.80,8.12" target="#fig_2">Figure 7</ref>(b) and 8(b) shows how our method compare to a GPU volume photon mapper without our Historygrams. For both single, S n = 1, and multiple scattering , S n = 2, our method has a considerable speedup (≈ 15 times for the Cornell box and ≈ 8 times for the Cenovix data set). The constant speedup for varying number of photons occur since the relative amount of recomputation needed is approximately the same. For the Cornell box, the spatial locality of the data allows for better usage of the hardware , both in terms of cache coherency and work-group utilization which result in increased performance improvement. <ref type="figure" coords="6,479.55,726.37,29.59,8.12" target="#fig_2">Figure 7</ref>(shows the relative speedup using our method compared to a standard GPU photon mapper. Consistent speedups of an order of magnitude are achieved for both single and multiple scattering. (c) shows the update time for retracing invalid photons and recomputing invalid view-ray segments using different number of photons in the scene (generated with single scattering). shows the relative speedup using our method compared to a standard GPU photon mapper, speedups in the order of 6 − 8 times are achieved for both single and multiple scattering when using more than 0.5 million photons. (c) shows the update time for retracing invalid photons and recomputing invalid view-ray segments using different number of photons in the scene (generated with single scattering). for different number of photons traced into the scene, P n . From these two plots, we can see that the photon gathering is considerably more expensive than the photon tracing. <ref type="figure" coords="7,163.63,486.00,31.07,8.12">Figure 9</ref>shows the effect of TF updates when varying the number of view-rays segments. In table 1, the parameters used for each data set rendered in the paper is presented together with the update time for both the photon tracing and photon gathering stage. In the " Without Historygrams " column , the performance measurements are shown for the GPU photon mapper which recomputes everything for all changes. For the column " With Historygrams " , the number of view-ray segments, the initialization overhead, and the amount of recomputation shown in addition to the performance timings. The initialization overhead measures the additional time it takes to create and store the Historygrams, which is only performed once when the camera stops moving. The speedup gained varies depending on the amount of recomputations that are needed and the spatial locality of the data. For changes affecting the outer parts of the volume, such as 6(a) almost all of the light transport needs to be recomputed. However, even for these visually large changes it is beneficial to use Historygrams. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Memory consumption</head><p> We have also evaluated the overhead of storing and querying the Historygrams used in our method. Each photon interaction requires one Historygram in addition to the regular data which consist of the position , direction and power. To trade speed for lower memory consumption one could also use a single Historygram per photon. Each view-ray segment requires one color in addition to the Historygram. Note that the memory requirement for view-ray segments is independent on the sampling rate. For the color, we use the half data type which means that 8 bytes are required for the red, green, blue, and alpha components. Using 8 bytes (64 bits) for the Historygram and 8 bytes for the color, our method implies a 16 MB GPU memory overhead per view-ray segment for a viewport resolution of 1024 × 1024. Similarly for photons we generally use 8 bytes per photon Historygram, implying a minor memory overhead. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS AND FUTURE WORK</head><p> In this paper we have enabled the use of photon mapping in a interactive DVR pipeline. To reach interactive frame rates during parameter changes, which is of crucial importance in explorative volume rendering , we have introduced and applied the novel concept of Historygrams . Historygrams encode the history of a photon or a view-ray, which can then be used to only recompute photons and view-rays affected by specific parameter changes such as TF edits. No approximations are introduced in the final solution since all invalid photons and view-ray segments are recomputed, but we can still accomplish an order of magnitude speedup. We have shown results using several examples of real-world data sets yielding realistic renderings, as well as synthetic data used for controlled performance measurements. We would like to point out that the concept of Historygrams can also be used for other rendering techniques. For general path tracing methods, e. g., path tracing or bi-directional path tracing our concept is directly applicable. The only requirement is that each path needs to be stored and incrementally update its own Historygram based on the parameters affecting the path generation. Cornell box Cenovix (a) <ref type="figure" coords="8,22.50,216.24,19.32,7.64">Fig. 9</ref>. Update times for changing the TF when varying the number of view-ray segments using 2.1 million photons and single scattering. The solid orange line corresponds to changing the material properties of the sphere in the Cornell box, <ref type="figure" coords="8,118.21,244.63,25.94,7.64" target="#fig_2">figure 7</ref> (a), and the blue dashed line represents the performance for the Cenovix data set scenario, <ref type="figure" coords="8,233.37,254.09,26.40,7.64" target="#fig_4">figure 8</ref>(a). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>photon </head><p>mapping use photon beams, both for photon queries and data representation <ref type="bibr" coords="8,75.72,293.19,13.74,8.12">[12]</ref>. Our method is also applicable for these methods, essentially a separate Historygram needs to be stored for each photon beam used for representing incident illumination in the scene. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,31.50,696.89,250.38,7.97;5,31.50,706.43,250.38,7.64;5,31.50,715.89,250.38,7.64;5,31.50,725.36,250.38,7.64;5,31.50,734.82,221.73,7.64"><head>Fig. 5. </head><figDesc>Fig. 5. A CT scan of an engine [256 × 256 × 256] rendered with multiple scattering (2 light bounces) and 2.1 million photons. Changing material properties from the left image to the right image can be performed 7.7 times faster using our Historygram method compared to a GPU complete discard and rerender all photon mapping implementation. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,31.50,208.79,513.00,7.97;7,31.50,218.32,513.00,7.64;7,31.50,227.79,513.00,7.64;7,31.50,237.25,378.06,7.64"><head>Fig. 7. </head><figDesc>Fig. 7. Performance evaluation for updating the material properties of the sphere in a synthetic Cornell Box data set (256 × 256 × 256 voxels) using 7 view-ray segments. (b) shows the relative speedup using our method compared to a standard GPU photon mapper. Consistent speedups of an order of magnitude are achieved for both single and multiple scattering. (c) shows the update time for retracing invalid photons and recomputing invalid view-ray segments using different number of photons in the scene (generated with single scattering). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,31.50,416.18,513.00,7.97;7,31.50,425.64,513.00,7.97;7,31.50,435.18,513.00,7.64;7,31.50,444.64,439.63,7.64"><head>Fig. 8. </head><figDesc>Fig. 8. Performance evaluation for updating the diffuse color of the blood vessels in the Cenovix data set (361 × 331 × 361) using 7 view-ray segments. (b) shows the relative speedup using our method compared to a standard GPU photon mapper, speedups in the order of 6 − 8 times are achieved for both single and multiple scattering when using more than 0.5 million photons. (c) shows the update time for retracing invalid photons and recomputing invalid view-ray segments using different number of photons in the scene (generated with single scattering). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false" coords="7,27.60,26.18,516.89,718.28"><figDesc coords="7,433.97,736.33,110.51,8.12;7,27.60,26.46,16.00,7.26;7,140.10,26.18,403.65,7.50">Recent methods for volumetric 2370 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 18, NO. 12, DECEMBER 2012</figDesc><table coords="8,61.85,51.70,172.25,136.42">2 

3 
4 
5 
6 
7 
8 
9 
10 

0 

0.1 

0.2 

0.3 

0.4 

0.5 

0.6 

Number of view−ray segments 
TF update time (sec) 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p>We thank all reviewers for their valuable comments which helped to greatly improve this paper. We would also like to thank Erik Sundén for supplying transfer functions, and Matthew Cooper for proofreading the manuscript. This work was partly supported by grants from the Excellence Center at Linköping and Lund in Information Technology (ELLIIT) and the Swedish e-Science Research Centre (SeRC). The presented concepts have been realized using the Voreen open source visualization framework (www.voreen.org). </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="8,40.76,445.53,232.12,7.22;8,40.76,455.00,141.52,7.22"  xml:id="b0">
	<monogr>
		<title level="m" type="main">Efficient Hash Table on the GPU</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">A</forename>
				<surname>Alcantara</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>Davis, California, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,464.46,232.12,7.22;8,40.76,473.93,108.74,7.22"  xml:id="b1">
	<analytic>
		<title level="a" type="main">An anisotropic phong brdf model</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ashikhmin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Shirley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Graphics Tools</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,483.39,232.12,7.22;8,40.76,492.85,232.12,7.22;8,40.76,502.32,17.93,7.22"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Adding shadows to a texture-based volume renderer</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Behrens</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Ratering</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,511.78,232.12,7.22;8,40.76,521.25,232.12,7.22;8,40.76,530.71,33.87,7.22"  xml:id="b3">
	<monogr>
		<title level="m" type="main">A survey on participating media rendering techniques. The Visual Computer</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Cerezo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Perez</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Pueyo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Seron</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Sillion</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="303" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,540.18,232.12,7.22;8,40.76,549.64,232.12,7.22;8,40.76,559.11,65.74,7.22"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Progressive photon mapping: A probabilistic approach</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">Z</forename>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Claude</forename>
				<surname>Knaus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 20011)</title>
		<meeting>SIGGRAPH 20011)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,568.57,232.12,7.22;8,40.76,578.03,232.12,7.22;8,40.76,587.50,41.84,7.22"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Interactive global illumination using selective photon tracing</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Dmitriev</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Brabec</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Myszkowski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-P</forename>
				<surname>Seidel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EGSR</title>
		<meeting>. EGSR</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,596.96,232.12,7.22;8,40.76,606.43,232.12,7.22;8,40.76,615.89,232.12,7.22;8,40.76,625.36,39.75,7.22"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Epipolar sampling for shadows and crepuscular rays in participating media with single scattering</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Engelhardt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Dachsbacher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Interactive 3D Graphics and Games, I3D &apos;10</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="119" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,634.82,232.12,7.22;8,40.76,644.29,78.14,7.22"  xml:id="b7">
	<analytic>
		<title level="a" type="main">The perception of surface blacks and whites</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">L</forename>
				<surname>Gilchrist</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">240</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,653.75,232.12,7.22;8,40.76,663.25,232.12,7.11;8,40.76,672.68,104.93,7.22"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Progressive photon mapping</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Hachisuka</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ogaki</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">W</forename>
				<surname>Jensen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH Asia</title>
		<imprint>
			<biblScope unit="volume">1308</biblScope>
			<biblScope unit="page" from="1" to="130" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,682.14,232.12,7.22;8,40.76,691.61,230.02,7.22"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Gpu-accelerated deep shadow maps for direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hadwiger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kratz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sigg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Bühler</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics hardware</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,701.07,232.12,7.22;8,40.76,710.54,232.12,7.22;8,40.76,720.00,121.64,7.22;8,285.12,53.98,250.38,7.22;8,303.38,63.44,232.12,7.22;8,303.38,72.91,232.12,7.22;8,303.38,82.37,106.93,7.22"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Local Ambient Occlusion in Direct Volume Rendering A comprehensive theory of volumetric radiance estimation using photon points and beams</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Hernell</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ljung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Jarosz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Nowrouzezahrai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Sadeghi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">W</forename>
				<surname>Jensen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 2011)</title>
		<meeting>SIGGRAPH 2011)</meeting>
		<imprint>
			<date type="published" when="2010-01" />
			<biblScope unit="page" from="548" to="5591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,91.84,232.12,7.22;8,303.38,101.30,232.12,7.22;8,303.38,110.77,153.08,7.22"  xml:id="b11">
	<analytic>
		<title level="a" type="main">The beam radiance estimate for volumetric photon mapping</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Jarosz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Zwicker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">W</forename>
				<surname>Jensen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum (Proceedings of Eurographics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="557" to="566" />
			<date type="published" when="2008-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,120.23,232.12,7.22;8,303.38,129.70,156.15,7.22"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Global illumination using photon maps</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">W</forename>
				<surname>Jensen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rendering Techniques</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,139.16,232.12,7.22;8,303.38,148.63,232.12,7.22;8,303.38,158.09,216.85,7.22"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient simulation of light transport in scences with participating media using photon maps</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">W</forename>
				<surname>Jensen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">H</forename>
				<surname>Christensen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH 1998, SIGGRAPH &apos;98</title>
		<meeting>SIGGRAPH 1998, SIGGRAPH &apos;98</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,167.55,232.12,7.22;8,303.38,177.02,232.12,7.22;8,303.38,186.48,29.89,7.22"  xml:id="b14">
	<monogr>
		<title level="m" type="main">Interactive Volume Rendering with Volumetric Illumination</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Jönsson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Sundén</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,195.95,232.12,7.22;8,303.38,205.41,232.12,7.22;8,303.38,214.88,89.28,7.22"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Discounting the color of mutual illumination: A 3d shape-induced color phenomenon</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Kersten</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Hurlbert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Investigative Ophthalmology and Visual Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,224.34,232.12,7.22;8,303.38,233.81,232.12,7.22;8,303.38,243.27,146.66,7.22"  xml:id="b16">
	<analytic>
		<title level="a" type="main">A model for volume lighting and modeling</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kniss</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Premoze</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Hansen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Shirley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mcpherson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="150" to="162" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,252.73,232.12,7.22;8,303.38,262.20,232.12,7.22;8,303.38,271.66,55.77,7.22"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Exposure render: An interactive photo-realistic volume rendering framework</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kroes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">H</forename>
				<surname>Post</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">P</forename>
				<surname>Botha</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Accepted. , to appear</note>
</biblStruct>

<biblStruct coords="8,303.38,281.13,232.12,7.22;8,303.38,290.59,232.12,7.22;8,303.38,300.06,232.12,7.22;8,303.38,309.52,69.29,7.22"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficient visibility encoding for dynamic illumination in direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kronander</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Jönsson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Löw</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ljung</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Unger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="462" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,318.99,232.12,7.22;8,303.38,328.45,151.61,7.22"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Depth discrimination from shading under diffuse lighting</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Langer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Bülthoff</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="649" to="660" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,337.92,232.12,7.22;8,303.38,347.38,232.12,7.22;8,303.38,356.84,69.95,7.22"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Advanced light material interaction for direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Lindemann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/EG Int. Symp. on Volume Graphics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,366.31,232.12,7.22;8,303.38,375.77,232.12,7.22;8,303.38,385.24,161.98,7.22"  xml:id="b21">
	<analytic>
		<title level="a" type="main">About the Influence of Illumination Models on Image Comprehension in Direct Volume Rendering</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Lindemann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vis Proceedings)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1922" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,394.70,232.12,7.22;8,303.38,404.17,232.12,7.22;8,303.38,413.63,85.36,7.22"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Brdf models for accurate and efficient rendering of glossy surfaces</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Löw</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kronander</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Unger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,423.10,232.12,7.22;8,303.38,432.56,196.11,7.22"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Optical models for direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Max</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="108" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,442.02,232.12,7.22;8,303.38,451.49,232.12,7.22;8,303.38,460.95,178.78,7.22"  xml:id="b24">
	<monogr>
		<title level="m" type="main">High Performance and Scalable Radix Sorting: A case study of implementing dynamic parallelism for GPU computing . Parallel Processing Letters</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Merrill</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Grimshaw</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="245" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,470.42,232.12,7.22;8,303.38,479.88,232.12,7.22;8,303.38,489.35,33.87,7.22"  xml:id="b25">
	<analytic>
		<title level="a" type="main">State of the art in interactive global illumination</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ritschel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Grosch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Dachsbacher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kautz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page" from="31160" to="188" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,498.81,232.12,7.22;8,303.38,508.28,232.12,7.22;8,303.38,517.74,107.70,7.22"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Advanced Volume Illumination with Unconstrained Light Source Positioning</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Döring</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">Rezk</forename>
				<surname>Salama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,527.21,232.12,7.22;8,303.38,536.67,232.12,7.22;8,303.38,546.13,46.27,7.22"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Interactive volumetric lighting simulating scattering and shadowing</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Döring</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Salama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PacificVis (IEEE Pacific Visualization )</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,555.60,232.12,7.22;8,303.38,565.06,232.12,7.22;8,303.38,574.53,232.12,7.22;8,303.38,583.99,137.14,7.22"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Interactive volume rendering with dynamic ambient occlusion and color bleeding</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Meyer-Spradow</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Diepenbrock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Mensmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Hinrichs</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum (Proceedings of Eurographics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="567" to="576" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,593.46,232.12,7.22;8,303.38,602.92,228.71,7.22"  xml:id="b29">
	<analytic>
		<title level="a" type="main">Gpu-based monte-carlo volume raycasting</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Salama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Conference on Computer Graphics and Applications</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="411" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,612.39,232.12,7.22;8,303.38,621.85,232.12,7.22;8,303.38,631.32,232.11,7.22;8,303.38,640.78,135.35,7.22"  xml:id="b30">
	<analytic>
		<title level="a" type="main">A directional occlusion shading model for interactive direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Schott</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Pegoraro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Hansen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Boulanger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Bouatouch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="855" to="862" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Proceedings. of EG</note>
</biblStruct>

<biblStruct coords="8,303.38,650.24,232.12,7.22;8,303.38,659.71,232.12,7.22;8,303.38,669.17,81.25,7.22;8,285.12,676.79,31.50,9.07;8,313.08,678.64,222.42,7.22;8,303.38,688.10,232.12,7.22;8,303.38,697.61,232.12,7.11;8,303.38,707.03,69.29,7.22"  xml:id="b31">
	<analytic>
		<title level="a" type="main">Image plane sweep volume illumination A multidirectional occlusion shading model for direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Sundén</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Soltészová</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Patel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bruckner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Viola</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">123</biblScope>
			<biblScope unit="page" from="2125" to="2134" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>[. 34]</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
