<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SeiVis: An Interactive Visual Subsurface Modeling Application</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Thomas</forename>
								<forename type="middle">H</forename>
								<roleName>Student Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Wolfgang</forename>
								<surname>Freiler</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Fritz</forename>
								<forename type="middle">M</forename>
								<surname>Gschwantner</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Helmut</forename>
								<surname>Doleisch</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Gabor</forename>
								<surname>Heinemann</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Markus</forename>
								<surname>Hadwiger</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<title level="a" type="main">SeiVis: An Interactive Visual Subsurface Modeling Application</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Seismic visualization</term>
					<term>volume deformation</term>
					<term>exploded views</term>
					<term>seismic interpretation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. A screenshot of our application illustrating our novel joint time/depth domain visualization for a seismic reflection dataset with two interactively interpreted seismic horizons. The two 3D views on the left show volume renderings of the seismic in time and depth domain, respectively, cut open at the horizons. The two 2D views on the top right show our interpretation views in time and depth as well. The 2D slice view on the bottom right shows the reflection data from the top in combination with well positions. Abstract—The most important resources to fulfill today&apos;s energy demands are fossil fuels, such as oil and natural gas. When exploiting hydrocarbon reservoirs, a detailed and credible model of the subsurface structures is crucial in order to minimize economic and ecological risks. Creating such a model is an inverse problem: reconstructing structures from measured reflection seismics. The major challenge here is twofold: First, the structures in highly ambiguous seismic data are interpreted in the time domain. Second, a velocity model has to be built from this interpretation to match the model to depth measurements from wells. If it is not possible to obtain a match at all positions, the interpretation has to be updated, going back to the first step. This results in a lengthy back and forth between the different steps, or in an unphysical velocity model in many cases. This paper presents a novel, integrated approach to interactively creating subsurface models from reflection seismics. It integrates the interpretation of the seismic data using an interactive horizon extraction technique based on piecewise global optimization with velocity modeling. Computing and visualizing the effects of changes to the interpretation and velocity model on the depth-converted model on the fly enables an integrated feedback loop that enables a completely new connection of the seismic data in time domain and well data in depth domain. Using a novel joint time/depth visualization, depicting side-by-side views of the original and the resulting depth-converted data, domain experts can directly fit their interpretation in time domain to spatial ground truth data. We have conducted a domain expert evaluation, which illustrates that the presented workflow enables the creation of exact subsurface models much more rapidly than previous approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Even with the recent trend towards alternative and renewable energy sources, more than half of today's energy demand is still fulfilled by fossil fuels and will continue to be so in the next couple of years. According to the International Energy Outlook 2010 <ref type="bibr" coords="1,223.60,561.41,14.94,8.02" target="#b21">[22] </ref> The oil in place, however, is limited, and thus the efficient valorization of existing reservoirs is an important goal. For the planning of production wells to drill into oil and gas reservoirs, one has to have an exact model of the subsurface structures. These include the different geological layers, the boundaries between these layers—called seismic horizons—, but also faults, as well as other structures. The basis for creating such a subsurface model is usually a seismic survey. Today, a typical survey contains 3D seismic reflection data—called seismic cubes—, as well as additional data such as well logs and well tops. </p><p>The Seismic Cube is a regular grid of scalar values. It is acquired by sending seismic waves into the ground. At a seismic horizon, part of the waves will be reflected, while others will proceed. The reflected waves are then measured on the ground using a 2D grid of geophones. The result is a set of 1D traces along the z-axis, one for each geophone, with z corresponding to the two-way travel time of the seismic wave, and f (z) being the measured amplitude. The seismic traces are then usually time-or depth-migrated. In this process, the actual lateral positions of the reflection events in the x, y-plane have to be computed, as in the original data one does not know from which direction the event actually arrived at the geophone. For a 3D survey, the migrated 1D traces are combined to form a 3D seismic cube. The dimensions of the resulting volume are lateral distances for the geophone grid, and time or depth on the z-axis, depending on the migration technique. Even though the depth migration delivers depth on the z-axis, this value does not directly correspond to actual spatial depth in the real world, because the so-called provelocities used in the depth-migration do not account for the horizontal energy in the seismic waves <ref type="bibr" coords="2,219.39,103.20,9.52,8.02" target="#b6">[7]</ref>. Well Data. Two kinds of data are aquired from exploration wells: Well logs are 1D datasets that log several properties of the subsurface along the drill hole. Well tops contain information on the position of subsurface layer boundaries. Both can function as ground truth data when interpreting the seismic cube. Well log and well top data come in three different types: (1) measured in spatial depth at the drill holes, (2) measured in spatial depth, and converted to the time-or depthmigration domain, or (3) measured directly in the time domain. Unlike well data available in the time domain, the much more common and also more accurate data only available in the spatial depth domain cannot be used directly for interpreting a time-migrated seismic measurement . In the conventional workflow for seismic interpretation, after finishing the interpretation, the extracted features are converted into the spatial depth domain. Only then can the interpretation be matched to the ground truth data available only in the spatial depth domain. Depth conversion is the process of computing actual spatial depths for seismic structures using the extracted horizons and a velocity model. Each subsurface layer is assumed to consist of a single material only, or an equal distribution of a mixture of materials. This makes it possible to assign an average velocity value to each layer. In the same way subsurface layers do not intersect, neither do their boundaries . Here, we assume that boundaries do not fold over, and thus can be defined as a function over the lateral domain, i.e., a heightfield. According to our domain expert collaborators, this is a reasonable assumption that subsumes the largest part of seismic interpretation work. These two constraints make it possible to interpret the depth conversion process as a piecewise linear scaling of layers along the z-axis. Contributions. We present an integrated application that employs a novel interactive, visual workflow for the creation of subsurface models . Our main contribution is the combination of three previously separated modules, namely horizon extraction, velocity modeling, and depth conversion (<ref type="figure" coords="2,88.90,422.99,29.01,8.02">Figure 2</ref>a ), into a fully integrated update loop (<ref type="bibr" coords="2,258.53,422.99,14.35,8.02;2,22.50,432.95,25.69,8.02">Figure 2 b </ref>). This results in a completely new interpretation workflow that shows the original data and the depth-converted data in a novel joint time/depth domain visualization, with linked live updates in all views. This for the first time enables depth-domain ground-truth data to be integrated directly into a time domain-based workflow. For the horizon extraction module, we build on the basic approach of previous work <ref type="bibr" coords="2,59.04,492.73,9.52,8.02" target="#b8">[9]</ref>, but introduce a novel, more precise cost function. We are able to integrate the depth conversion directly into the rendering pipeline via a novel live volume deformation technique, allowing live evaluation of the results from horizon extraction and velocity modeling . We show the benefits of our application via an evaluation with our domain expert partners, who have started to use our system in practice. In addition, we present a novel volume-shading approach tailored to highlighting horizon structures, as well as a new approach to exploded views using a single-pass ray casting algorithm. Both techniques enhance the visualization of dense seismic reflection data considerably. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We review related work clustered into three areas that are relevant for our application. Seismic Interpretation and Depth Conversion. Etris et al. <ref type="bibr" coords="2,262.42,636.47,10.45,8.02" target="#b6">[7] </ref>explain the need for depth conversion of the seismic interpretation and why depth migration, even though resulting in a seismic in the depth domain, is not sufficient to get a good subsurface model. Pepper and Bejarano <ref type="bibr" coords="2,112.22,676.65,14.94,8.02" target="#b15">[16] </ref> give a good overview of seismic interpretation techniques in general. There exist a couple of fully automatic horizon extraction approaches. Keskes et al. <ref type="bibr" coords="2,212.76,696.57,13.74,8.02" target="#b9">[10]</ref>, and Lavest and Chipot <ref type="bibr" coords="2,64.70,706.53,13.74,8.02" target="#b11">[12]</ref>, present abstract outlines for this kind of approaches. Faraklioti and Petrou <ref type="bibr" coords="2,103.03,716.50,9.52,8.02" target="#b7">[8]</ref>, as well as Blinov and Petrou <ref type="bibr" coords="2,228.99,716.50,10.45,8.02" target="#b1">[2] </ref>parametrization. The parametrization, however, is not necessarily equal for all features and might even vary throughout a feature. Moreover , having to adjust parameters is inconvenient due to lengthy com- putations. Patel et al. <ref type="bibr" coords="2,335.27,214.37,14.94,8.02" target="#b14">[15] </ref> present an interactive workflow for horizon extraction . In a pre-processing step, they compute a hierarchy of possible surface patches, which the user can then interactively put together to create the horizon surfaces. In previous work <ref type="bibr" coords="2,361.40,254.89,9.52,8.02" target="#b8">[9]</ref>, we have presented an interactive workflow for the seismic horizon extraction module, which is based on well positions . Rather than tagging horizons on axis-aligned slices, the well positions are triangulated, and interaction is performed on the sides of the resulting prisms. This makes it possible to easily integrate additional data, such as logs and tops acquired at these wells, directly into the interpretation workflow. This workflow restricts most of the user interaction to the unfolded prism sides, allowing easy interaction on a 2D plane, while the actual surface computation exploits global energy minimization to compute a minimal cost path around the prism, and a real 3D minimal cost surface on the inside. Volume Deformation and Exploded Views. Westermann and Rezk-Salama <ref type="bibr" coords="2,335.92,375.11,14.94,8.02" target="#b22">[23] </ref> propose a method for free-form volume deformation on graphics hardware. A key element of their approach is to not deform the volume itself, but rather the mapping into the volume. Rezk-Salama et al. <ref type="bibr" coords="2,354.86,404.99,14.94,8.02" target="#b16">[17] </ref>describe an approach for volume deformation that works by adaptively subdividing the volume into blocks which can be linearly deformed. They reached interactive rendering speeds for small datasets on then-available programmable graphics hardware. Their approach, however, does not work when using advanced memory layouts like bricking. Schulze et al. <ref type="bibr" coords="2,436.87,454.81,14.94,8.02" target="#b20">[21] </ref> have presented an approach for non-physically-based direct volume deformation. They resample the volume during deformation and render the deformed volume with standard volume rendering. Their technique allows deformation of moderately-sized volumes at voxel resolution at interactive framerates, but the affected area must be limited. Bruckner et al. <ref type="bibr" coords="2,349.96,515.25,10.45,8.02" target="#b2">[3] </ref>present exploded views for volume data. In their approach, the dataset is first split into multiple convex parts which are then transformed using a force-directed layout. They render these parts one by one. Therefore, the parts have to be sorted according to their visibility and after rendering blended into a single buffer. Volume Visualization for Seismic Data. Engel et al. <ref type="bibr" coords="2,499.49,565.73,10.45,8.02" target="#b5">[6] </ref>give a comprehensive overview of the basics of volume graphics, including slicing and ray casting-based approaches. Meaningful visualization of 3D seismic data is a hard problem, since seismic volume data are very dense and noisy. Gradients cannot be used well in large parts of the volume, and generally have different semantics than for example in typical medical datasets. Where a strong gradient in a computed tomography (CT) scan usually corresponds to a material boundary, in seismic reflection data the subsurface boundaries are represented as local extrema, where the gradients are usually very small. This means that volume illumination with gradient-based approaches like the Blinn-Phong model <ref type="bibr" coords="2,430.43,675.98,10.45,8.02" target="#b0">[1] </ref> in combination with classical volume rendering approaches does not work well for these data. Castanie et al. <ref type="bibr" coords="2,350.49,696.57,9.71,8.02" target="#b3">[4,</ref><ref type="bibr" coords="2,363.31,696.57,7.47,8.02" target="#b4"> 5] </ref> were the first to use pre-integrated ray casting for seismic visualization. They give an overview of the special demands for visualization of seismic data and demonstrate the advantages of ray casting compared to slicing approaches for direct volume rendering of seismic data. Video requires Adobe Reader 9+, please see supplemental material. <ref type="figure" coords="3,31.50,157.03,19.60,7.37">Fig. 3</ref>. Fundamental visualization views for our joint time/depth domain workflow. The user can select prisms in the timeslice view (left). The volume view (center) allows visualizing each prism in the context of the volume (in both domains). The main interaction for the horizon extraction happens in the interpretation views (right), showing the unfolded prism sides alongside well data in the time and spatial depth domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Patel </head><p>et al. <ref type="bibr" coords="3,81.33,188.79,14.94,8.02" target="#b14">[15] </ref>present a volume rendering technique that employs gradient-free shading. They argue that local ambient occlusion as presented by Ropinski et al. <ref type="bibr" coords="3,127.19,208.72,13.74,8.02" target="#b17">[18]</ref> , a common gradient-free shading approach , is not a good fit for seismic data. The reasons are not only the time-and memory-intensive precomputation, but also the high frequency and noisy nature of seismic data. Instead, they propose a technique called forward scattering. However, since their particular approach is based on slicing, their technique cannot easily be adapted to ray casting. Lampe et al. <ref type="bibr" coords="3,138.10,268.49,14.94,8.02" target="#b10">[11] </ref>present a technique to deform and render volumes along curves. They illustrate two applications, one of which is the visualization of seismic reflection data along well logs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">WORKFLOW</head><p> The conventional workflow (Section 3.1) for creating subsurface models and the novel workflow that we propose (Section 3.2) share the same three conceptual modules: Horizon extraction, velocity modeling , and depth conversion. However, as indicated by the illustrations in <ref type="figure" coords="3,40.94,357.69,29.24,8.02">Figure 2</ref>, they differ vastly in how these modules are integrated, as well as implemented. In the conventional workflow, the three modules are connected in a pipelined fashion, where a final result of one module is the input for the next. In contrast, in our workflow the three modules are tightly integrated, and all computations happen on the fly. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Current Practice</head><p> The following description of the current practice is based on the industry standard software Schlumberger Petrel <ref type="bibr" coords="3,198.21,436.11,13.74,8.02" target="#b19">[20]</ref> . While implementation details might vary for different software tools, to our knowledge the workflow description reflects the common practice in the industry. Horizon Extraction. The horizon extraction is usually carried out as a combination of 2D segmentations on the axis-aligned slices of the seismic reflection data. Depending on the variation in the data, up to ten slices are skipped between 2D segmentations, and filled by interpolation or automatic growing. On a single slice, the human interpreter typically tags the desired horizons, starting with an automatic trace, which is then manually refined. The auto tracer of Petrel uses a local approach, which—unlike our global approach—cannot be forced through constraint points and stops at ambiguous areas. The horizon extraction process is very lengthy and accounts for the major part of the time in the typical workflow. Tagging several horizons on tens to hundreds of slices takes at least several hours but can easily keep an interpreter busy for multiple days, if the structures are not clearly visible or ambiguous. The output of the horizon extraction module is a set of surfaces describing the boundaries of the subsurface layers. Velocity Modeling. After the horizon extraction is finished, the resulting horizon surfaces are used as a basis for creating a velocity model. The velocity model is defined in a table view, where for every subsurface layer the corresponding top and bottom boundaries (horizons or other surfaces), as well as velocities are set. Once all desired layers are defined, a volume containing per-voxel velocities (the socalled velocity cube) can be computed off-line. Depth Conversion. Finally, based on the velocity cube, the depth conversion can be computed. Using the per-voxel velocities, the original volume and the extracted horizons can be resampled, again offline , from top to bottom into a new, depth-converted dataset. Integration. Creating the velocity cube, as well as the final depth conversion, requires the user to manually create a new derived dataset, as well as lengthy computations. In addition, the derived datasets are not coupled. An update in one of the modules does not automatically trigger the re-evaluation of subsequent modules. Instead, a new derived data set has to be set up manually. This results in the linear workflow illustrated in <ref type="figure" coords="3,381.02,228.64,31.24,8.02">Figure 2</ref>a , where each module requires the result of the previous module as input. Due to the lengthy computations in between, usually no intermediate results are pushed to the next module in the pipeline. A major drawback of this approach is that mistakes that occur during the horizon extraction often only become visible after finishing the complete pipeline, when matching the depth converted data to the ground truth data, which is available only in depth. In an ideal workflow, the interpreter would go back to the interpretation and fix mistakes (indicated by the green arrow in <ref type="figure" coords="3,529.54,308.34,14.95,8.02;3,294.12,318.31,24.51,8.02">Fig- ure 2 a</ref>). More commonly, however, a shortcut is taken to save time, by locally " hot fixing " the velocity cube to match the features, accepting a possibly unphysical velocity model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Joint Time/Depth Domain Workflow</head><p> Horizon Extraction. Instead of extracting the horizons on axisaligned slices, we build on the basic approach presented in previous work <ref type="bibr" coords="3,314.86,386.47,9.52,8.02" target="#b8">[9]</ref>, triangulating the well positions and tagging horizons on the sides of the resulting prisms. For interaction, the sides of each prism are unfolded into a single 2D image. By using the well positions as the prism corners, we can incorporate the information of three wells into each 2D view. For extracting a horizon, the user just has to place a single seed-point. Using a global minimal path algorithm, we find the optimal path around the prism sides, which is then used to compute the minimal surface for the prism body. If the path or surface do not fit, the user can drag a node in the path to a desired position. A new optimal path is then computed to pass through that position. The surface can automatically be extended to neighboring prisms using the data on the shared face. Using asynchronous computations of the optimization for multiple prisms, changes by the user on one prism are automatically propagated throughout the complete dataset in the background. Section 4.2 introduces a new cost function that is specifically suited to seismic data, enhancing the precision of the horizon extraction. Velocity Modeling. For velocity modeling, we automatically sort the horizons and allow the user to specify the velocities for the resulting layers. In contrast to the conventional workflow, we do not need to compute a velocity cube explicitly, but store only this description. Depth Conversion. Instead of resampling the original dataset into the depth domain off-line, we compute the depth conversion live during rendering (Section 6.2). The volume, as well as the unfolded prism sides, are deformed live, using the compact conceptual velocity model described above to determine indirect texture look-ups accordingly. Joint Time/Depth Domain Interaction. By removing the penalties for computing a velocity cube and resampling into the depth domain , we can now compute the depth conversion in real time. All three modules are connected, and updates can be triggered automatically whenever the user modifies the state of any module. This allows for a completely new workflow, in which for the first time, ground truth data that are only available in the depth domain, can be integrated directly into the horizon extraction process in the time domain. We call this technique Joint Time/Depth Domain Interaction (Section 6). To take full advantage of our live depth conversion, creating a horizon segmentation and the velocity for the resulting layer go hand in hand. Horizon extraction and velocity modeling, as well as velocity modeling and depth conversion, are connected in a bidirectional manner. This allows one to directly derive the velocity for a layer by matching well tops, available in time and depth, or the other way around, to automatically use well tops only available in spatial depth as constraints during the interpretation in time by reverse-converting them using the created velocity model. However, because the data is not always exact, the main interaction is user-steered. If the user is unsure about a segment of the horizon, the segmented boundary can be dragged to a different position in the time domain, immediately visualizing how the model fits the ground truth data in the spatial depth domain. <ref type="figure" coords="4,54.88,162.97,30.29,8.02">Figure 3</ref> illustrates this process. Since all computations happen in real time, enabling a live feedback loop at any stage during the interpretation, the interpretation can always be matched perfectly to the ground truth data in the first pass. This eliminates the need for costly post-processing or " hot fixing " the velocity cube. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discussion</head><p> Most seismic interpretation is done in the time domain. However, additional ground truth data gathered from exploration wells are usually available in spatial depth only. By placing the depth conversion at the end of the interpretation pipeline, as in the conventional workflow , the interpretation is often a guessing game where errors only become apparent once the completed interpretation is depth-converted and matched to the ground truth data. " Hot fixing " these errors in the velocity cube often results in an unphysical velocity model. Having a live depth conversion of the intermediate interpretations, as in our proposed workflow, makes a huge difference for the interpretation workflow. For the first time, features in the time as well as the spatial depth domain can be matched live during interpretation, eliminating the need for a cumbersome back and forth between the different modules , and the need for taking shortcuts that result in incorrect models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">HORIZON EXTRACTION</head><p> Our horizon extraction module is based on a graph-based global optimization with the following properties: A voxel in the volume maps to a node in the graph. Directly neighboring voxels are connected by an edge, and four neighboring voxels in a plane, connected by a cycle of four edges, form a facet. Costs are assigned to edges and facets based on their bounding voxels. The minimal path around each prism is the set of connected edges with the least combined cost bounded by a predefined start and end point. The minimal surface on the inside of the prism is the set of facets with the least combined cost that forms a closed surface that is bounded by the minimal path. While the same basic idea was also used in previous work <ref type="bibr" coords="4,177.76,497.77,9.52,8.02" target="#b8">[9]</ref>, the cost function used there has several shortcomings, which we describe in Section 4.1 to motivate the development of a new cost function. We propose a new waveform-based cost function (Section 4.2), as well as a new render mode based on this cost function (Section 5). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Motivation for the New Cost Function</head><p>The cost function presented in <ref type="bibr" coords="4,136.91,570.12,10.45,8.02" target="#b8">[9] </ref>consists of two components. The first one defines the snappiness to ridge and valley lines/surfaces. The second component defines the smoothness of the resulting interpretation . Both components are based solely on the gray values of the current sample, ignoring the neighborhood. The snappiness term at a node is defined as the distance of the amplitude at the current node f (x, y, z) to a predefined target amplitude t. The cost g 1 for an edge or a facet F is then defined as the sum over all nodes belonging to the edge/facet as: </p><formula>g 1 (F) = ∑ F |t − f (x, y, z)| . </formula><formula>(1) </formula><p>The target value t is predefined globally as the minimum or maximum amplitude in the dataset. Even though it has proven to be quite effective, this basic cost function has a major problem: Horizons are indicated in the data by local extrema of the 1D waves at each (x, y)-position. As can be seen in  Figure 4 a , the resulting costs, however, are not necessarily an indicator for extrema. Even though locally g 1 will assign the lowest cost to an extremum, the costs at different positions in the volume or for different horizons are not comparable, as each extremum might deviate from the global target value by a different amount. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The New Waveform-Based Cost Function</head><p> To overcome the problems described in Section 4.1, we propose to replace the snappiness term of the cost function with a new term, based on the local waveform of the 1D trace. The obvious approach to such a term would be to compute the derivative, e.g., via central differences , to find extrema, and then use the result of the central difference computation as the cost. In addition, one could modulate the result to enhance the extrema; for example, using a smooth bump function such as: </p><formula>φ (v) = exp − 1 1−v 2 for |v| &lt; 1 0 else, (2) </formula><p> where v is set to the derivative f = d f (x, y, z)/dz scaled with a userdefined scale factor α to define the threshold for mapping the result to zero. <ref type="figure" coords="4,305.57,480.07,30.13,8.02" target="#fig_1">Figure 4</ref>b shows the plot of the cost defined as: </p><formula>g φ (F) = ∑ F 1 − φ (α · f (x, y, z)). </formula><formula>(3) </formula><p>For the plot, minima are canceled out using the second derivative. While this is a much better result compared to the old cost function in most places (compare for example the small local maximum marked by the green box), especially the sharp features are desired, some problems become obvious in the plot. While minima can be canceled out effectively using the second derivative, this is not true for saddles, resulting in undesired low costs at the two saddle-points marked by the blue boxes. In addition, the strong maximum marked with the magenta box was assigned a relatively high cost due to the fact that it has two samples on its peak which results in an asymmetry of the samples around the peak. These shortcomings can be removed by the use of the following non-linear waveform-based term to replace g 1 : </p><formula>g wave (F) = ∑ F 1 − n ∑ k=1 ϕ s (x, y, z, k), </formula><formula>(4) </formula><p>where n is a predefined 1D neighborhood size, and </p><formula>ϕ s (x, y, z, k) =      ϕ(x, y, z, k) if (k ≥ s) or (k &lt; s and ϕ(x, y, z, k + 1) = 0) 0 else, </formula><formula>(5) with ϕ(x, y, z, k) =      1 n if f (x, y, z − k) &lt; f (x, y, z) and f (x, y, z + k) &lt; f (x, y, z) 0 else, </formula><formula>(6) for maxima, or ϕ(x, y, z, k) =      1 n if f (x, y, z − k) &gt; f (x, y, z) and f (x, y, z + k) &gt; f (x, y, z) 0 else, (7) </formula><p>for minima, respectively. This cost function is a simple step function which basically returns a smaller value the closer the current sample point is to a local extremum in the predefined neighborhood, and 1 if there is no extremum in the neighborhood. The additional constraint in ϕ s provides an implicit smoothing, using s to define the minimal feature size. The resulting cost-plot is shown in <ref type="figure" coords="5,168.73,218.83,30.30,8.02" target="#fig_1">Figure 4</ref>c . As can be seen, the problems for the derivative-based term are canceled out in this plot, while the sharp features for the maxima are retained as desired. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">COST FUNCTION-BASED VOLUME RENDERING</head><p>Inspired by the gradient magnitude-modulated shading presented by Levoy <ref type="bibr" coords="5,56.95,280.05,13.74,8.02" target="#b12">[13]</ref>, and the cost function presented in Section 4.2, we have developed a shading approach that focuses on highlighting horizon structures. While in horizon extraction local waveform inspection is common, to our knowledge there are no attempts to exploit the local waveform for enhancing the volume rendering of seismic data. Prototyping the Cost Function. With the non-linear filter presented in the previous section, we can roughly estimate the distance of the current sample to a local minimum or maximum in the trace. While the cost function term shown in Equation 4 maps extrema to low cost for the rendering, we would like to assign large opacity to the extrema and low opacity to the remaining data. Therefore we can directly use the term from Equation 5 to modulate the opacity during volume rendering . The resulting opacity is a direct indicator of the local cost. This makes it possible to prototype the cost function parameters, such as the neighborhood size, while getting an on-the-fly visualization of the resulting local costs. Areas of low cost, corresponding to the horizon structures, are rendered opaque, while areas of high cost will be rendered transparently. Even though this technique cannot replace the additional global optimization for extracting the horizons, it can give a good idea of how the global optimization will behave. Horizon Enhancing Shading. In addition to using this technique for prototyping the cost function, it also works well as a general approach to highlighting horizon structures in seismic reflection data. Common illumination models use the gradient for shading. For visualizing horizons, this is not suitable as the gradient vanishes at the local extrema indicating the horizons. Hence we compute the inverse of the local cost on-the-fly during rendering, and use it to modulate the opacity from the transfer function, in the same way as the gradient magnitude is used for gradient magnitude-modulated shading <ref type="bibr" coords="5,253.88,559.03,13.74,8.02" target="#b12">[13]</ref>. Performance is mostly dependent on the neighborhood size. We show performance for k = 1, k = 2, and k = 3 in <ref type="figure" coords="5,206.51,578.98,25.26,8.02" target="#tab_1">Table 1</ref>, compared to a shader using standard Phong shading without modulation. It can be seen that, while there is a performance loss for neighborhoods larger than three voxels, rates are still interactive. For the performance comparison we adjusted the transfer functions such that transparency was similar for the standard and cost-modulated shading methods, as the modulation usually results in much more transparent images. <ref type="figure" coords="5,529.54,193.26,14.95,8.02;5,294.12,203.22,22.92,8.02">Fig- ures 5</ref> a -c show a comparison of the quality with different neighborhood sizes. <ref type="figure" coords="5,350.14,213.18,30.50,8.02">Figure 5</ref>d shows a rendering using the same transfer function with standard Phong shading. The cost-based rendering was set up to highlight local maxima only. A big advantage of this approach is that horizons can efficiently be highlighted without adjusting the transfer function. While similar results could be achieved with a carefully designed transfer function with amplitude-based shading, using the proposed render mode requires no user interaction at all. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">JOINT TIME/DEPTH DOMAIN INTERACTION</head><p> Our joint time/depth domain workflow is only possible with live computation of the depth conversion results. Therefore, an efficient rendering pipeline (Section 6.1) and support for live volume deformation (Section 6.2) are essential. In addition, we present a simple implementation of a single-pass exploded views algorithm (Section 6.3), based on the same technique as the live deformation. This enables efficient exploration of the dense seismic reflection data. <ref type="figure" coords="5,294.12,406.81,30.70,8.02">Figure 6</ref>shows our integrated pipeline for rendering seismic volume data and horizon surfaces with the application of deformation and exploded views. In the remainder of this chapter, circled numbers and letters refer to this figure. While the figure illustrates the pipeline for the volumetric case, we use the same pipeline for the unfolded prism views to provide depth conversion of this view during interpretation. The main difference is that the heightfield geometry c , as well as the boundaries texture a , are of one dimension lower (compare <ref type="figure" coords="5,512.71,476.55,25.31,8.02" target="#tab_2">Table 2</ref>). The pipeline is divided into two major blocks: the interpretation block on the left, and the rendering block on the right. Interpretation comprises three modules. The horizon extraction module 1 , and the velocity modeling module 2 , are described in Section 3.2. The output of 1 is a 2D heightfield that covers the complete volume domain, plus a 1D heightfield for the boundary of the current prism. Both are constantly updated during the interpretation process. Each heightfield corresponds to a single horizon, and is stored as a layer in the first channel of the 3D or 2D boundaries texture a on the rendering side, and is also available to the depth conversion module on the interpretation side. The velocity modeling module 2 outputs a velocity value for each layer, which is stored into the 1D velocities texture b . The surface deformation module 3 takes the updated heightfields from 1 , and converts the values from the time to the depth domain using the velocity model from 2 . Compared to recomputing the deformation for the complete volume, very little data needs to be processed, allowing real time updates (compare <ref type="figure" coords="5,427.11,656.38,25.18,8.02" target="#tab_3">Table 3</ref>). The resulting depth-converted heightfields are stored in the second channel of the 2D or 3D boundaries texture a . In addition, the depth conversion module outputs the maximum scaling factor d needed to cover the depth conversion at any x, y-position. Rendering. The data is shared between all views and steps in the visualization pipeline. <ref type="figure" coords="5,375.57,716.50,26.03,8.02" target="#tab_2">Table 2</ref>gives an overview of the shared textures and buffers. Basically all of our views make use of vertex and fragment shaders to exploit the possibilities of the programmable OpenGL horizon, we use a single generic vertex buffer c , covering the complete x, y-domain, but without the depth (z) information at the vertices. We render the surfaces one by one and use the boundaries texture a in the vertex stage to assign the appropriate z-values to each vertex. Invalid fragments, i.e., the fragments belonging to triangles in the mesh that are not yet covered by the interpretation, are discarded. Additionally , we use the fragment shader to compute several properties of the surfaces on the fly. Using the data which is already available for the other rendering stages on the GPU, several properties can be plotted directly onto the surface without precomputing a separate texture. The amplitude can be looked up directly from the volume texture. Cost or deviation from the target amplitude can be computed on the fly based on data from the same texture. The distance to other surfaces can be evaluated using the boundaries texture. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Rendering Pipeline</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Volume Deformation</head><p>The volume deformation required for the depth conversion is highly constrained. Deformation only needs to be applied to the depth axis of the volume, in order to convert its unit from time to spatial depth in the subsurface. We represent horizons as heightfields, and we can safely assume that no horizons intersect. Thus, every two adjacent horizons enclose one subsurface layer. Furthermore, the velocity for each layer in the volume can be assumed to be constant, using an average value. Thus, the deformation can be simplified to a piecewise linear stretching or compression of the volume between each two adjacent horizons. Taking these constraints into account, it is possible to implement the deformation in a simple and efficient manner. This enables depth conversion at real-time frame rates during volume and slice rendering, without precomputing a deformed volume. Concept. Our approach is inspired by the work of Westermann and Rezk-Salama <ref type="bibr" coords="6,89.64,478.22,13.74,8.02" target="#b22">[23]</ref>. Conceptually, we never deform the original volume, but render a virtually deformed volume, converting the lookups in this volume into the original volume space on the fly in the fragment shader. We do that by converting only the layer boundaries (which are the result of the interpretation in progress) from time to depth. The n-th deformed boundary b d n can be computed as </p><formula>b d n (x, y) = n ∑ k=1 (b k (x, y) − b k−1 (x, y)) · v k (8) </formula><p>from the time domain boundaries b n and velocities v n . <ref type="figure" coords="6,484.32,149.02,30.31,8.02">Figure 7</ref>illustrates the deformation with this simple iterative computation of the deformed boundaries. The boundaries have to be recomputed only when a velocity value is changed or a horizon is modified. Computational complexity is O(n), with n the number of vertices that need to be updated . Since the computation is independent for each x, y-position, we have parallelized it using OpenMP. Even for the surfaces of the large dataset shown in <ref type="figure" coords="6,346.99,218.76,33.15,8.02">Figure 10</ref>, consisting of roughly a million quads, the update time for a couple of horizons is interactive (see <ref type="figure" coords="6,481.97,228.72,25.18,8.02" target="#tab_3">Table 3</ref>). For volume rendering, we use a single-pass ray caster. The ray caster is set up to cast into a virtual volume, resized with the scaling factor d , which is set to the maximum value of the bottom boundary to fit the deformed volume. During ray casting, the depth-converted boundaries are used to compute the actual look-up in the original volume . Rendering the unfolded prism sides can be done in a similar manner. For each side, we set up a quad that fits the size of the deformed side, and the same indirect texture look-up as described for volume rendering is used for the slice rendering. Rendering Setup. In the setup step of the ray caster 5 , the extents of the bounding geometry have to be adapted to fit the deformed volume . This is done by scaling the z-axis of the bounding geometry with the deformation factor d . Fragment Shader. In the ray casting stage 6 the coordinates for the volume texture look-up have to be modified in the fragment shader. The pseudo code in <ref type="figure" coords="6,360.26,388.52,30.87,8.02">Figure 8</ref>illustrates the conversion of the virtual (deformed) coordinates to the actual sampling position in undeformed volume coordinates in the fragment shader. The sample position in the deformed space is used to look up the id of the current layer. Using the layer id, the layer's upper boundary is fetched for each (x, y)position in original and deformed space. Using the layer's velocity, the z-position in the layer is then transformed back into undeformed volume space, resulting in the sample position in volume space. The same principle is used for the main interpretation view containing the unfolded prism sides. To apply the depth conversion to the slice views, we simply scale the side of the quads corresponding to the volume's z-axis, and use the same fragment shader code shown in <ref type="figure" coords="6,285.12,508.20,30.13,8.02">Figure 8</ref>to compute the position for the texture look-ups. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Exploded Views</head><p>The general approach to exploded views <ref type="bibr" coords="6,430.18,539.52,9.71,8.02" target="#b2">[3,</ref><ref type="bibr" coords="6,441.80,539.52,11.21,8.02" target="#b13"> 14,</ref><ref type="bibr" coords="6,454.93,539.52,11.95,8.02" target="#b18"> 19] </ref> for volume rendering is setting up the bounding geometry around each part of the volume , rendering each of the parts separately, and then compositing the <ref type="figure" coords="6,34.13,725.78,18.86,7.37">Fig. 6</ref> . Rendering pipeline for joint time/depth interaction. Horizon extraction 1 ,velocity modeling 2 and deformation 3 modules constantly update the texture data a , b .The data is shared over all views and the different steps 4 , 5 and 6 in the rendering pipeline. <ref type="figure" coords="6,403.32,724.78,20.13,7.37">Fig. 7</ref>. Illustration of the surface deformation (<ref type="figure" coords="6,451.50,734.25,20.14,7.37">Fig. 6</ref> 3 ) with computation of deformed boundaries. <ref type="figure" coords="7,31.50,49.65,25.17,7.37" target="#tab_3">Table 3</ref><ref type="figure" coords="7,494.77,59.11,30.72,7.37">Figure 10</ref>). results. These techniques make very flexible exploded views possible, allowing translation and rotation of arbitrary cut planes along/around arbitrary axes. However, the same constraints of our application scenario which allow us to set up the simple volume deformation approach described above also make much of this flexibility unnecessary . We use the seismic horizons as the cut geometry, and then for the explosion itself compute layers of piecewise translations along the zaxis . This is sufficient to enable unobstructed views onto the surfaces. Integration into the Rendering Pipeline. The data already available for the deformed rendering makes it possible to deploy exploded views, using the z-axis for translation, and the horizons as cut surfaces. We use a single-pass ray casting approach without any additional setup besides a modified scale factor. Again, we set up a virtual volume with a modified size for the z-axis. To comply with the spacing between the different layers, here the summed up spacing for all horizons is added to the scale factor for the volume's z-axis. Adding the spacing to the scale factor for the depth conversion allows us to combine the exploded views with the depth conversion. Fragment Shader. The fragment shader for rendering the exploded view is only a slight modification of the shader described in Section 6.2. We interpret the spacing as empty space preceding each horizon . Thus, the offset to get to the deformed layer is not a direct look-up in the deformed boundaries texture, but the spacing corresponding to all preceding horizons has to be added. Assuming a uniform spacing, this is simply layerId times spacing. To check whether the sample position is inside the spacing or in the volume, the deformed boundary value of the bottom boundary of the current layer has to be fetched. If the current sample position is larger than the deformed boundary value minus the size of the spacing, the sample is inside the spacing. If that is the case, we can set the current sample's alpha value to zero and proceed with the next sample. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Performance</head><p> We have measured the rendering performance for the live deformation and exploded views with two different datasets: The first dataset, shown in <ref type="figure" coords="7,67.02,514.41,33.57,8.02">Figure 11</ref> , is moderately sized with 240 × 240 × 1509 <ref type="figure" coords="7,31.50,716.12,19.81,7.37">Fig. 8</ref>. Pseudo code for live volume deformation. Virtual (deformed) coordinates are converted to undeformed coordinates on the fly during rendering in the fragment shader. The syntax is similar to GLSL. els, and at 330MB fits completely into GPU memory. The second dataset (<ref type="figure" coords="7,325.59,169.71,33.39,8.02">Figure 10</ref>) comprises 1422 × 667 × 1024 voxels, and on our system does not fit into GPU memory at roughly 4GB. For rendering the large dataset, we use an octree representation. While the visualization can fall back on lower resolution levels of the octree, the surface extraction always uses the highest resolution. The surfaces cover the complete x, y extents of both datasets with a resolution of one vertex per voxel resulting in 57.600 and 948.474 quads, respectively. Computation of the deformed surfaces was done on the CPU using a dual six-core Xeon X5680 at 3.33Ghz. Rendering was done on a NVIDIA Geforce GTX 580 with 1.5GB of memory, with the volume rendered screen-filling into a 1024 × 1024 viewport with two samples per voxel. Performance for the ray casting algorithm with live depth conversion , as presented in Section 6.2, is shown in <ref type="figure" coords="7,453.53,289.68,24.93,8.02" target="#tab_3">Table 3</ref>. In comparison to the standard ray casting algorithm used for rendering the undeformed volume, this technique requires three additional texture look-ups and four floating point operations per sample to compute the sample position in the original volume. In addition, to get the layer id of the current sample, a number of additional texture look-ups have to be performed. The actual number depends on the search algorithm used. Right now we step through all layers from top to bottom until reaching the current sample point. This results in the performance loss shown in <ref type="figure" coords="7,515.36,369.38,25.76,8.02" target="#tab_3">Table 3</ref>, when adding more layers. Performance for the single-pass ray casting with exploded views, described in Section 6.3, can be seen in <ref type="figure" coords="7,515.83,389.31,25.29,8.02" target="#tab_3">Table 3</ref>. Compared to the depth-conversion shader, there is virtually no difference in computational complexity (the texture fetch, described above, to decide whether the sample is inside the spacing area can be cached when computing the current layer). However, we currently do not employ empty space skipping in the explosion spacing, which results in a performance loss. Overall, performance stays well withing the limits needed for interactivity for both datasets. For the large dataset it can be seen that rendering speeds scale very well, using the octree representation. Since the surfaces are deformed at full resolution there is a bigger performance penalty, however, update rates are still interactive and updates are only needed when surfaces or the velocity model is updated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EVALUATION</head><p> We have evaluated our system in a real-world scenario with our domain expert partners, in order to compare our workflow with the industry standard as described below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Setup</head><p> For comparison, we asked our partners to provide us with a typical application scenario. To avoid an interpretation session over several days with our expert partner we asked for a rather small dataset. We were provided with a moderately-sized dataset consisting of 325 inlines and 275 crosslines at 151 samples per trace (<ref type="figure" coords="7,443.37,636.38,29.83,8.02">Figure 5</ref>was produced with the same dataset). The dataset covers an area of roughly 7.5 × 6.5km in western Hungary. Time between samples was 4ms. In addition to the seismic cube, we were provided with a total of 39 well positions, with well tops for two horizons each, of which five were available in depth and time, and the remaining 34 in depth only. A large part of the dataset was covered by the resulting triangulation. We added 10 more positions so that it is possible to create the interpretation up to the volume's boundaries without falling back to a slice-based approach. The task for the interpreter was then to interpret the horizon defining the top boundary of a clay layer throughout the volume. Well tops <ref type="figure" coords="8,22.50,49.70,24.97,7.37" target="#tab_4">Table 4</ref>. Timings for the interpretation process. Initial Interpretation corresponds to a first complete extraction of the horizon. Velocity-and DC Computation correspond to the time needed to compute the velocity cube and the depth conversion, respectively. Refine describes the time used by the expert to refine the automatic interpretation between the manually interpreted slices and inside prisms after the first complete run. indicating the top and bottom boundaries of this layer were provided. Velocity modeling is usually done using well logs. Using our joint time/depth workflow, the interpreter could simply adjust the velocity values such that the well tops available in time and depth were matching . For comparison, we gave the expert one hour with our workflow, and one hour with the standard workflow using the Petrel <ref type="bibr" coords="8,238.40,186.78,14.94,8.02" target="#b19">[20] </ref>software framework, and asked to create an interpretation, as complete as possible, without sacrificing exactness. A comparison of the resulting interpretations is shown in <ref type="figure" coords="8,122.69,216.66,29.84,8.02">Figure 9</ref>. <ref type="figure" coords="8,161.13,216.66,27.25,8.02" target="#tab_4">Table 4</ref> shows timing comparisons of the different steps. For quality comparison, we were provided with the actual interpretation of the same horizon used for production, which was created manually over several working days. Before starting the evaluation, we gave our partners an in-depth introduction to our framework and provided guidance during a test drive with a different dataset for several hours. Even though we also supervised the actual evaluation run, the expert was able to work on his own and did not ask for any further assistance. We conducted a second evaluation session to get an indication of how well our approach scales to larger datasets. For this test, we had two students with basic knowledge in seismic interpretation interpret a horizon in the large dataset introduced above. The dataset measures 1422 × 667 × 1024 voxels and covers an area of roughly 17.8 × 8.3km. The sampling rate in depth was 2ms. We were provided with 15 well tops in spatial depth and six in time, covering the center of a salt dome. The outer region was covered by triangulating arbitrary positions defined by the students. The task was to interpret a horizon above the salt dome. The resulting area of interest was a rectangle above the salt dome, measuring roughly 800 × 600 pixels. For comparison, we were provided with a production surface of the same area which was created in roughly two working days by our domain experts. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>App </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Results</head><p> Joint Time/Depth Domain Workflow. After the test drive, the domain expert decided to approach the interpretation task in the following way: First, he adjusted the velocity model to match the well tops available in the time as well as depth domain. Then he started with seeding a horizon at one prism and adjusted the 2D curve on the prism side. Using the live depth conversion, he was able to directly match the interpretation to the well tops regardless of the domain they were available in. In the background, our system would use the intermediate interpretation to recursively create interpretations on the neighboring prisms as well as compute the optimal surface on the inside. After being satisfied with the current prism, the expert would then proceed to a neighboring prism and check the precomputed curve and adjust it if necessary. The expert was able to go over all prisms in well under one hour. After finishing the complete horizon, he quickly checked the result by skimming inlines and crosslines and looking at the extracted horizon overlaid with the amplitude. The exploded views were very helpful in this step, as he could get a clear look at the horizon in context of the volume and also look at the volume data itself, which was revealed by cutting at the horizon position. He then proceeded to adjust a few imprecisions resulting from the 3D optimization. After the last change, the expert had to wait only for a few seconds for the final result, as the optimization runs continuously in the background. Conventional Workflow. For the comparison run, the expert interpreted the same horizon using Petrel, which is the industry standard software for geological modeling. The software offers automated tracing on 2D slices, as well as in 3D. From what we could gather from testing these automated approaches are both local. Starting from a seed in 2D, or an interpreted slice in 3D, the horizon is propagated into as many neighboring pixels/slices as possible. When the data gets ambiguous, the auto-tracer stops. It is also not possible to set constraints besides the initial seed. If the interpretation is wrong, it needs to be fixed manually and 3D traces between two interpreted slices do not necessarily connect these slices. When doing the interpretation, the expert started out with a single slice and fully tagged the horizon on this slice using a combination of piecewise auto-tracing and manual intervention for corrections, as well as to connect the automatically traced parts at areas where the automatic approach stopped. After that he used the 3D auto-tracer for a first result. Besides the described disadvantages of using a local approach, a big advantage compared to our global approach is that the auto-tracer computes a result nearly instantly . However, according to our expert the resulting surfaces are far from complete and need thorough inspection. As a result they are used mostly for guidance during a manual interpretation rather than for directly producing final results. After this first slice, the expert gradually refined the interpretation by manually adjusting every tenth slice followed by another 3D trace. After 60 minutes, the expert finished 18 <ref type="figure" coords="8,285.12,668.80,19.45,7.37">Fig. 9</ref> . Comparison of the horizons extracted during the expert evaluation . a shows a screen capture of Petrel with the extracted surface using the conventional workflow. b shows the result using our workflow . The relative height is encoded in the surface coloring, but with slightly different colormaps for a and b . We imported the result from Petrel into our application to compare it to our result. Error plots on the ground truth surface are shown in c . The left image shows Petrel, with gaps in the surface marked in yellow, the right shows our result. <ref type="figure" coords="9,31.50,210.28,22.90,7.37">Fig. 10</ref>. Screenshot of the 1422 × 667 × 1024 voxel dataset. The horizon surface, which was interpreted during our evaluation, clearly shows the important features of the dataset. slices with a distance of ten, covering roughly 60% of the dataset. Comparison. <ref type="figure" coords="9,94.15,273.67,30.25,8.02">Figure 9</ref>shows comparisons of the created surfaces. For the manually interpreted part, it can be seen that the results of both approaches are quite similar. The lower third shows the part that was not reached within the time frame. There, large holes and also a phase jump can be seen, which clearly shows that the automatic tracing alone is not sufficient to reach acceptable results with the conventional workflow . After the 60 minutes, we also measured the time for computing the velocity model and the deformed seismic cube (see <ref type="figure" coords="9,230.32,343.41,25.18,8.02" target="#tab_4">Table 4</ref>). After the interpretation, we conducted a brief interview with the expert . The expert was impressed by the live depth conversion in combination with the prism-based workflow. Having three well tops on each 2D slice and being able to match the interpretation directly to the tops in the depth domain was really helpful in finding the correct surfaces. A big advantage of the global optimization used for the automatic tracing is the possibility to set constraints and force the auto-tracer through defined points. Also, it will always result in a closed surface even when the data is unclear. A point that we did not expect was made by the expert that the prism-based approach was also very motivating in contrast to the standard approach of going from slice to slice. The data on nearby slices is often very similar, making slice-based interpretation a very tedious process so that subtle, but important, changes are sometimes missed by the interpreter. Student Evaluation. Since the second evaluation session was carried out by students rather than experts we do not want to make any claims regarding the quality of the extracted surfaces besides the fact that all important structures were found by the students and are visible in the resulting surface (compare <ref type="figure" coords="9,151.67,534.93,32.75,8.02">Figure 10</ref>). After a brief introduction, both students were able to work on their own. The two students approached the dataset slightly differently. Student 1 added 25 additional pseudo well positions to cover the area of interest outside the provided well tops. The result were rather large prisms used for the surface extraction. Student 2 added roughly 100 additional points resulting in much smaller prisms. As a result, Student 1 spent only about two and a half hours on the extraction of the horizon on the prism sides, but had to wait about an hour for the computation of the 3D surface. Student 2 on the other hand spent about four hours tuning the horizon on the large amount of prisms, but since the computation on the smaller prisms ran much faster, Student 2 barely had to wait for the computation. Conclusion. We can say that the expert was able to work with our system on his own after a short introduction. He was able to extract surfaces close to manual interpretations in a very short time. While we used a small dataset with the domain expert, we are able to show that the presented approach scales well for larger datasets with the additional student evaluation. Being able to match an interpretation in the time domain to ground truth data in the depth domain not only speeds up the interpretation process significantly, but also allows for very exact results without tedious back and forth between the different domains. By using asynchronous computations in the background, it is also possible to minimize waiting times for the interpretation, even though the global optimization technique is much more computationally demanding than local approaches. Following the evaluation, our partners installed our application on a testing system where it is now used for experimental projects. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Saltdome </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Channels </head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSIONS AND FUTURE WORK</head><p> In this paper, we have introduced and evaluated SeiVis, a novel, interactive application for integrated seismic interpretation and the creation of subsurface models. The main contributions are a novel joint time/depth domain workflow for creating subsurface models, merging time and spatial depth domains using on-the-fly volume deformation, live exploded views using seismic horizons as cutting geometry between volume parts, a horizon-enhancing shading mode, and the integration of these techniques into an integrated workflow for seismic interpretation and depth conversion. The expert evaluation that we have conducted has clearly shown the advantages of this new workflow. In the future, we would like to extend the interpretation capabilities of our system to include the extraction of faults, in order to be able to create more complete subsurface models. We think of computing a likelihood of belonging to a fault for each voxel, and using this likelihood as an additional input to the cost function to steer the horizon tracker along faults, using the same global optimization process. <ref type="figure" coords="9,310.36,716.12,7.39,7.37">11</ref>. Example rendering of a dataset of size 240 × 240 × 1509 with heavily compressed top and bottom layers, using exploded views in combination with standard direct volume rendering. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,285.12,231.54,250.38,7.37;4,285.12,241.01,250.38,7.37;4,285.12,250.47,250.38,7.37;4,285.12,259.93,241.27,7.37"><head>Fig. 4. </head><figDesc>Fig. 4. Comparison of the cost obtained via different cost functions, to the amplitude maxima in an example 1D seismic trace. a shows the old snappiness term from [9] (Equation 1). The derivative-based term is shown in b (Equation 3), and the non-linear term in c (Equation 4). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,56.67,49.65,487.83,7.37;7,31.50,58.81,463.27,7.70"><head>. </head><figDesc>Performance comparison of the live depth conversion and exploded views. We used standard ray casting without illumination for the comparison. Dataset 1 is shown in Figure 11 and measures 240 × 240 × 1509 voxels, dataset 2 consists of 1422 × 667 × 1024 voxels (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="9,294.12,320.79,250.37,8.02;9,294.12,330.76,250.37,8.02;9,294.12,340.72,65.49,8.02"><head></head><figDesc>Parts of this work were funded by the Austrian Research Funding Agency (FFG) in the scope of the COMET K1 project " RT-Analysis 3D " (No.824190). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="9,294.12,715.82,250.38,7.70;9,294.12,725.59,250.38,7.37;9,294.12,735.05,180.20,7.37"><head>Fig. </head><figDesc>Fig. 11. Example rendering of a dataset of size 240 × 240 × 1509 with heavily compressed top and bottom layers, using exploded views in combination with standard direct volume rendering. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false" coords="1,31.50,561.41,250.38,173.16"><figDesc coords="1,241.02,561.41,40.85,8.02;1,31.50,571.38,250.37,8.02;1,31.50,581.34,114.80,8.02">by the U.S. Energy Information Administration, worldwide marketed energy will rise by 50% until the year 2035.</figDesc><table coords="1,31.50,608.95,250.38,125.63">@BULLET Thomas Höllt and Markus Hadwiger are with King Abdullah University of 
Science and Technology, Saudi Arabia, 
E-mail: {thomas.hollt|markus.hadwiger}@kaust.edu.sa. 
@BULLET Wolfgang Freiler and Helmut Doleisch are with the SimVis GmbH, Austria, 
E-mail: {freiler|doleisch}@simvis.at. 
@BULLET Fritz-M. Gschwantner is with the VRVis Research Center, Austria, 
E-mail: gschwantner@vrvis.at. 
@BULLET Gabor Heinemann is with the Heinemann Oil GmbH, Austria, 
E-mail: gheinemann@heinemannoil.com. 

Manuscript received 31 March 2012; accepted 1 August 2012; posted online 
14 October 2012; mailed on 5 October 2012. 
For information on obtaining reprints of this article, please send 
e-mail to: tvcg@computer.org. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false" coords="2,22.50,43.57,513.00,700.87"><figDesc coords="2,242.59,716.50,30.28,8.02;2,22.50,726.46,250.37,8.02;2,22.50,736.42,250.37,8.02">later on, employ connected component analysis for 3D surface reconstruction of seismic horizons. These fully automatic approaches all require</figDesc><table coords="2,285.12,43.57,250.38,116.41">Depth 
Conversion 

Depth 
Conversion 
Horizon 
Extraction 
Velocity 
Modeling 

user-steered comp. 

optional reinterpretation 
live update loop 

automatic comp. 

well tops 
in depth 

a 
b 

Horizon 
Extraction 
Velocity 
Modeling 

Fig. 2. The conventional workflow a with multiple user-steered com-
putations, compared to our novel joint time/depth modeling workflow b 
with a fully integrated, automatic live update loop. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true" coords="5,31.50,143.95,513.00,596.50"><figDesc coords="5,31.50,656.91,250.38,7.37;5,31.50,666.38,225.23,7.37">Table 1. Performance for cost function-based rendering compared to Phong shading (base). See Section 6.4 for measurement setup.</figDesc><table coords="5,55.47,682.22,202.44,58.23">Neighborhood 
Rendering Times 
Size 
cf-based base (Phong) 
% of base 

3 (k = 1) 
28fps 
28fps 
100% 
5 (k = 2) 
25fps 
28fps 
89% 
7 (k = 3) 
21fps 
28fps 
75% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true" coords="6,22.50,50.74,513.00,126.22"><figDesc coords="6,22.50,50.74,513.00,7.40;6,22.50,60.21,464.59,7.40">Table 2. Textures and buffers needed in our pipeline in addition to basic volume rendering. a , b , and c correspond to Figure 6. #B and #L represent the number of boundaries and the number of layers, respectively. Sizes are given in number of 32-bit floating point entries.</figDesc><table coords="6,22.50,76.05,489.88,100.91">Texture/Buffer 
Dim. 3D/2D 
Type 
Function 
Size 3D 
Size 2D 

boundaries a 
3D/2D 
luminance-α texture 
layer boundaries in original (.r) and 
deformed (.a) space 

x · y · #B · 2 x · #B · 2 

velocities b 
1D 
luminance texture 
layer velocities 
#L 
#L 
heightfield geometry c 
2D/1D 
vertex buffer 
generic vertex buffer for horizons 
x · y · 3 
x · 2 

pipeline. We used this, for example, to streamline the horizon sur-
face rendering part 4 of the pipeline. Instead of creating geometry 
for each </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,40.76,66.75,232.12,7.13;10,40.76,76.22,232.12,7.13;10,40.76,85.68,200.32,7.13"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Models of light reflection for computer synthesized pictures</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">F</forename>
				<surname>Blinn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th annual conference on Computer graphics and interactive techniques, SIGGRAPH &apos;77</title>
		<meeting>the 4th annual conference on Computer graphics and interactive techniques, SIGGRAPH &apos;77</meeting>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="page" from="192" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,95.15,232.12,7.13;10,40.76,104.61,232.12,7.13;10,40.76,114.07,77.26,7.13"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Reconstruction of 3-d horizons from 3-d seismic datasets</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Blinov</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Petrou</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1421" to="1431" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,123.54,232.12,7.13;10,40.76,133.00,232.12,7.13;10,40.76,142.47,37.86,7.13"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploded views for volume data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bruckner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Gröller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1077" to="1084" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,151.93,232.12,7.13;10,40.76,161.40,232.12,7.13;10,40.76,170.86,41.84,7.13"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Advances in seismic interpretation using new volume visualization techniques</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Castanie</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Levy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Bosquet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">First Break Journal</title>
		<imprint>
			<biblScope unit="page" from="69" to="72" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,180.33,232.12,7.13;10,40.76,189.79,232.12,7.13;10,40.76,199.25,232.12,7.13;10,40.76,208.72,49.81,7.13"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Volumeexplorer: Roaming large volumes to couple visualization and data processing for oil and gas exploration</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Castanie</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Levy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Bosquet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization Conference &apos;05</title>
		<meeting>IEEE Visualization Conference &apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="247" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,218.18,232.12,7.13;10,40.76,227.65,166.57,7.13"  xml:id="b5">
	<monogr>
		<title level="m" type="main">Real-Time Volume Graphics</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Engel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hadwiger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">M</forename>
				<surname>Kniss</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Rezk-Salama</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weiskopf</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>A K Peters, Ltd</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,237.11,232.12,7.13;10,40.76,246.58,195.38,7.13"  xml:id="b6">
	<analytic>
		<title level="a" type="main">True depth conversion: More than a pretty picture</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">L</forename>
				<surname>Etris</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">J</forename>
				<surname>Crabtree</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Dewar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Pickford</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CSEG Recorder</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="11" to="22" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,256.04,232.12,7.13;10,40.76,265.51,169.76,7.13"  xml:id="b7">
	<monogr>
		<title level="m" type="main">Horizon picking in 3d seismic data volumes. Machine Vision and Applications</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Faraklioti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Petrou</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="216" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,274.97,232.11,7.13;10,40.76,284.44,232.12,7.13;10,40.76,293.90,232.12,7.13;10,40.76,303.36,163.68,7.13"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Interactive seismic interpretation with piecewise global energy minimization</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Höllt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Beyer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Gschwantner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Muigg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Doleisch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Heinemann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hadwiger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Pacific Visualization Symposium 2011</title>
		<meeting>the IEEE Pacific Visualization Symposium 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,312.83,232.12,7.13;10,40.76,322.29,232.12,7.13;10,40.76,331.76,90.43,7.13"  xml:id="b9">
	<monogr>
		<title level="m" type="main">Automatic extraction of 3-d seismic horizons. SEG Technical Program Expanded Abstracts</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Keskes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Zaccagnino</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Rether</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Mermey</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="page" from="557" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,341.22,232.12,7.13;10,40.76,350.69,232.12,7.13;10,40.76,360.15,202.09,7.13"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Curve-centric volume reformation for comparative visualization</title>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">D</forename>
				<surname>Lampe</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Correa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Hauser</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1235" to="1242" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,369.62,232.12,7.13;10,40.76,379.08,199.92,7.13"  xml:id="b11">
	<monogr>
		<title level="m" type="main">Building complex horizons for 3-d seismic. SEG Technical Program Expanded Abstracts</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Lavest</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Chipot</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="159" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,388.54,232.12,7.13;10,40.76,398.01,154.52,7.13"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Levoy</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications IEEE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,407.47,232.12,7.13;10,40.76,416.94,232.12,7.13;10,40.76,426.40,69.95,7.13"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Using deformations for browsing volumetric data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Mcguffin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Tancau</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Balakrishnan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization 2003</title>
		<meeting>IEEE Visualization 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,435.87,232.12,7.13;10,40.76,445.33,232.12,7.13;10,40.76,454.80,163.68,7.13"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Seismic volume visualization for horizon extraction</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Patel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bruckner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Viola</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">E</forename>
				<surname>Gröller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Pacific Visualization Symposium</title>
		<meeting>the IEEE Pacific Visualization Symposium</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,464.26,232.12,7.13;10,40.76,473.73,232.12,7.13;10,40.76,483.19,149.77,7.13"  xml:id="b15">
	<monogr>
		<title level="m" type="main">Advances in seismic fault interpretation automation . Search and Discovery Article 40170, Poster presentation at AAPG Annual Convention</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pepper</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Bejarano</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="19" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,492.65,232.12,7.13;10,40.76,502.12,232.12,7.13;10,40.76,511.66,232.12,6.86;10,40.76,521.05,103.82,7.13"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast volumetric deformation on general purpose hardware</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Rezk-Salama</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Scheuering</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Soza</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Greiner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGGRAPH/EUROGRAPHICS workshop on Graphics hardware, HWWS &apos;01</title>
		<meeting>the ACM SIGGRAPH/EUROGRAPHICS workshop on Graphics hardware, HWWS &apos;01</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,530.51,232.12,7.13;10,40.76,539.98,232.12,7.13;10,40.76,549.44,232.12,7.13;10,40.76,558.91,69.29,7.13"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Interactive volume rendering with dynamic ambient occlusion and color bleeding</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Meyer-Spradow</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Diepenbrock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Mensmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">H</forename>
				<surname>Hinrichs</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="567" to="576" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,568.37,232.12,7.13;10,40.76,577.83,232.12,7.13;10,40.76,587.30,172.77,7.13"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Similarity-based exploded views</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ruiz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Viola</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Boada</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bruckner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Feixas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sbert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Symposium on Smart Graphics</title>
		<meeting>8th International Symposium on Smart Graphics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="154" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,596.76,232.12,7.13;10,40.76,606.23,192.90,7.13"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Petrel seismic to simulation software</title>
	</analytic>
	<monogr>
		<title level="m">Schlumberger Information Solutions</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,615.69,232.12,7.13;10,40.76,625.16,232.12,7.13;10,40.76,634.62,232.12,7.13;10,40.76,644.09,152.59,7.13"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Direct volume deformation</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Schulze</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Bühler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hadwiger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Computer Vision and Computer Graphics. Theory and Applications Communications in Computer and Information Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="59" to="72" />
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,653.55,232.12,7.13;10,40.76,663.02,37.86,7.13"  xml:id="b21">
	<monogr>
		<title level="m" type="main">Energy Information Administration</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<forename type="middle">S</forename>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,672.48,232.12,7.13;10,40.76,681.94,159.54,7.13"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Real-time volume deformations</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Rezk-Salama</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="451" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
