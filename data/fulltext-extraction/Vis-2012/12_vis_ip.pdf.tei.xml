<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Yiu</forename>
								<surname>Cheuk</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Amitabh</forename>
								<surname>Ip</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Joseph</forename>
								<surname>Varshney</surname>
								<roleName>Fellow, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<surname>Jaja</surname>
								<roleName>Fellow, Ieee</roleName>
							</persName>
						</author>
						<title level="a" type="main">Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Volume exploration</term>
					<term>volume classification</term>
					<term>normalized cut</term>
					<term>Information-guided exploration</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. We explore a volume dataset with an intensity-gradient histogram segmentation hierarchy. 1. We compute a 2D intensity-gradient histogram from a volume dataset. 2. We mimic the user visual search of shapes in the histogram by recursively segmenting the histogram image using normalized cuts. 3. We construct a multi-resolution hierarchy for interactive exploration. 4. Users traverse this hierarchy to discover features in the volume data and compose meaningful visualizations. Abstract—Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient 2D histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Identifying and visualizing meaningful features in large volume datasets remains a significant challenge <ref type="bibr" coords="1,175.36,458.07,13.74,8.02" target="#b21">[20]</ref> . Visualization of the features that you know are in the data is hard. It is even harder to find the features that you do not know are there. While we have made significant strides in building up a substantial body of knowledge over the last two decades in direct volume rendering, much of these advances have addressed issues surrounding how to depict the data; what to depict remains an important problem. We seek a visualization approach that highlights meaningful information, guides users to explore, and allows the users to associate high-level knowledge with low-level raw data. We carry this out by visually segmenting the intensity-gradient histogram of a volumetric dataset into a hierarchy for exploration. We first outline the three most important components of the data exploration challenge facing us today. Information Challenge: Detecting and displaying meaningful features, trends, and anamolies in data is an important challenge in visualization. This is becoming an increasingly significant challenge as our ability to acquire data is surpassing our ability to meaningfully analyze it. In this paper we seek a way to locate and visualize data with the highest information content using simple statistically-based information-theoretic measures. </p><p> Completeness Challenge: Exhaustive data exploration is a tedious and time-intensive exercise and yet is important to ensure that we do not overlook any important features in the data. We need mechanisms that facilitate a complete data exploration. In this paper we show how to construct an exploration hierarchy to accomplish this goal using a top-down subdivision strategy to cover the entire feature space of a volume dataset. Semantic Challenge: Current computational approaches may identify potentially informative regions by using low-level attributes such as statistics of data, the derivatives of the scalar field, or even embed the data into its own principal dimensions or manifold. However semantically driven navigation of the data is still a task that is designated for the user. We facilitate addressing this challenge by providing an intuitive and interactive volume exploration interface that is based on natural groupings that are often seen to be semantically related. In practice, users manually search for regions of interest by inspecting different areas of a feature space. Popular exploration subspaces for such a feature space include 1D density and 2D intensitygradient . Histograms are often used to aid this search and have been implemented in several popular visualization packages, such as, Voreen <ref type="bibr" coords="1,321.10,696.57,13.74,8.02" target="#b28">[27]</ref>, VisIt <ref type="bibr" coords="1,359.26,696.57,9.52,8.02" target="#b2">[3]</ref>, and ImageVis3D <ref type="bibr" coords="1,435.52,696.57,9.52,8.02" target="#b10">[9]</ref>. For example, ImageVis3D provides a trapezoidal tool for this exploration task in <ref type="figure" coords="1,494.76,706.53,29.73,8.02" target="#fig_0">Figure 2</ref>. We mimic this user search process by applying image segmentation to recursively divide the histogram into intuitive regions. We show effective discovery of interesting regions by traversing a hierarchy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Contributions</head><p>We present a visual-data-driven approach to volume data exploration. Users explore a hierarchy to search for regions of interest from coarse to fine. @BULLET We address the information challenge by extracting informative regions using image segmentation on reduced statistics. We mimic user explorations by visually segmenting the 2D histograms . We show these automatic 2D histogram segments wellapproximate meaningful 3D volume segments. These segments fit the shape of the histogram and cover the entire domain. We discuss this segmentation approach in Section 4. @BULLET We address the completeness challenge by constructing a complete exploration hierarchy. This hierarchy organizes segments of different sizes from coarse to fine. We progressively visualize the volume dataset by traversing this hierarchy. We show the construction of this hierarchy in Section 5.1. @BULLET We assist the exploration by using information-theoretic measures of the volumetric data segments. We evaluate the entropies of the segments and the information gains of the subdivisions. We show how they can assist the exploration in Section 5.2. @BULLET We address the semantic challenge by providing intuitive interactions to explore segments at different sizes. Users can effectively identify regions of interest by traversing the hierarchy of segments. This interaction is detailed in Section 5.3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this paper we show how to interactively explore a volume dataset using a histogram segmentation hierarchy. The two areas of research that are the closest to our work are transfer function design and visual data segmentation, which we overview them next. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Transfer Function Design</head><p> Transfer functions directly influence the visualization by assigning optical properties such as color and opacity to voxels. Previous work has devoted a lot of effort on transfer function generation. Pfister et. al. <ref type="bibr" coords="2,63.17,426.37,14.94,8.02" target="#b30">[29] </ref> present a survey of different approaches to transfer function design. Traditionally, a transfer function maps voxels to colors and opacity according to a 1D function of the scalar values . Subsequent work has considered multiple attributes and has involved the design of transfer functions using multiple dimensions. Fujishiro et. al. <ref type="bibr" coords="2,83.49,476.18,14.94,8.02" target="#b12">[11] </ref>and Zhou et. al. <ref type="bibr" coords="2,166.02,476.18,14.94,8.02" target="#b45">[46] </ref>analyze the topology of the scalar field to generate transfer functions. Tzeng et. al. <ref type="bibr" coords="2,257.94,486.14,14.94,8.02" target="#b41">[42] </ref> paint on the volume data to design high-dimensional transfer functions . Sereda et. al. <ref type="bibr" coords="2,99.79,506.07,14.19,8.02">[36,</ref><ref type="bibr" coords="2,117.19,506.07,11.95,8.02"> 37] </ref> compute LH histograms to detect material boundaries and transfer functions. Salama et. al. <ref type="bibr" coords="2,228.37,516.03,14.94,8.02" target="#b35">[34] </ref>include abstract semantic attributes to assist in domain-specific visualization design. Kim and Varshney <ref type="bibr" coords="2,118.90,535.96,14.94,8.02" target="#b23">[22] </ref>use volumetric saliency to enhance the visualization. Correa and Ma <ref type="bibr" coords="2,129.25,545.92,9.71,8.02" target="#b6">[5,</ref><ref type="bibr" coords="2,141.17,545.92,7.47,8.02" target="#b7"> 6] </ref>have recently incorporate size and visibility into transfer functions. Ruiz et. al. <ref type="bibr" coords="2,186.77,555.88,14.94,8.02" target="#b34">[33] </ref>generate automatic transfer functions based on information divergences. A popular transfer function attribute is the derivatives of the scalar field, often the gradient of the intensity. Kindlmann and Durkin <ref type="bibr" coords="2,257.94,586.38,14.94,8.02" target="#b24">[23] </ref> use the derivatives to show better separation of materials and boundaries . Kniss et. al. <ref type="bibr" coords="2,89.47,606.30,14.94,8.02" target="#b25">[24] </ref>use fixed shape widgets to interactively design 2D transfer functions. Roettger et. al. <ref type="bibr" coords="2,158.45,616.26,14.94,8.02" target="#b33">[32] </ref>create transfer functions by clustering the 2D volume histogram according to the spatial connectivity of the volume dataset. Users interact with a 1D histogram to manipulate the 2D non-parametric segments in Maciejewski et. al.'s sys- tem <ref type="bibr" coords="2,40.94,656.11,13.74,8.02" target="#b27">[26]</ref>. Instead of the volume histograms, Selver and Güzeliç <ref type="bibr" coords="2,257.94,656.11,14.94,8.02" target="#b36">[35] </ref>initialize the transfer function by fitting radial basis functions to the histograms of the image slices in a volume dataset. Most recently, Wang et. al. <ref type="bibr" coords="2,67.31,686.00,14.94,8.02" target="#b43">[44] </ref>learn a Gaussian Mixture Model from the volumetric scalar field and use the resulting ellipses to compose transfer functions. In this paper, we show how to automatically identify segments of interest from the intensity-gradient histograms. We organize these segments from coarse to fine to facilitate the exploration process. Our segments are non-parametric and tightly cover the feature space. Users can interact with these segments directly on the intensity-gradient his- tograms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Data Segmentation</head><p>Separating 2D images and 3D volumes into meaningful regions is a long-standing and challenging problem. Here we present a small subset of recent results from the vast literature on this topic. Freixenet et. al. <ref type="bibr" coords="2,327.78,126.21,14.94,8.02" target="#b11">[10] </ref>survey different approaches to segment 2D images. Mean-shift image segmentation <ref type="bibr" coords="2,406.01,136.18,10.45,8.02" target="#b5">[4] </ref>treats the image as probability distribution and finds the segmentation according to local maxima. Graph-based segmentation approaches model the pixels as nodes and the image as a connected graph and then they partition the graph to solve the segmentation problem. Felzenszwalb and Huttenlocher <ref type="bibr" coords="2,525.04,176.03,10.45,8.02" target="#b9">[8] </ref>use a boundary predicate and a greedy algorithm to segment images. Sharon et. al. <ref type="bibr" coords="2,336.59,195.95,14.94,8.02" target="#b37">[38] </ref> introduce an algebraic multigrid inspired segmentation algorithm. 3D volume segmentation is a natural extension to the 2D image segmentation problem. Huang and Ma <ref type="bibr" coords="2,432.65,226.21,14.94,8.02" target="#b15">[14] </ref> apply the region growing technique to volume segmentation. Sherbondy et. al. <ref type="bibr" coords="2,490.15,236.18,14.94,8.02" target="#b38">[39] </ref>accelerate volume segmentation with programmable graphics hardware. Segmentation of organs from medical data is a prime application of volume segmentation. Grady et. al. <ref type="bibr" coords="2,400.85,266.07,14.94,8.02" target="#b14">[13] </ref>apply random walk segmentation to detect organs from medical volumes. Fuller et. al. <ref type="bibr" coords="2,474.49,276.03,14.94,8.02" target="#b13">[12] </ref> use supportvector machines to segment retinal layers. Many systems incorporate user guidance to perform interactive segmentation. Bartz et. al. <ref type="bibr" coords="2,511.16,295.95,10.45,8.02" target="#b0">[1] </ref>use a seeded point to segment the bronchi in the lungs. Prassni et. al. <ref type="bibr" coords="2,520.56,305.92,14.94,8.02" target="#b31">[30] </ref> incorporate user guidance to minimize the uncertainties in the segmentation . Kniss et. al. <ref type="bibr" coords="2,356.99,325.84,14.94,8.02" target="#b26">[25] </ref>use supervised manifold distance to segment volume data. Torsney-Weir et. al. <ref type="bibr" coords="2,414.44,335.80,14.94,8.02" target="#b40">[41] </ref>estimate visual responses to guide the search for the image segmentation parameters. In this paper, we use the popular normalized-cut approach <ref type="bibr" coords="2,510.76,356.10,14.94,8.02" target="#b39">[40] </ref>to directly segment the intensity-gradient histogram of a volume data and construct the transfer function. The normalized-cut approach to 2D image segmentation has been extensively used for a variety of applications and it has been mapped on a variety of architectures including multi-core and many-core GPUs <ref type="bibr" coords="2,404.01,405.92,13.74,8.02" target="#b16">[15]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW</head><p>We segment the intensity-gradient histogram of a volumetric dataset into a hierarchy of regions. We have observed that these regions express meaningful features and boundaries in the 3D volumes. The resulting hierarchy guides users to interactively explore the dataset. <ref type="figure" coords="2,285.12,479.55,30.14,8.02">Figure 1</ref>shows an overview of our approach. Information Challenge: We address the information challenge by segmenting intensity-gradient 2D histograms of a volumetric dataset into potential regions of interest. The histogram is the most commonly used tool to help in transfer function design. Kniss et. al. <ref type="bibr" coords="2,336.52,535.29,14.94,8.02" target="#b25">[24] </ref> have shown that 2D segments in the intensitygradient domain correspond to meaningful 3D regions in the dataset. Users recognize these shapes and patterns from the histogram's image and explore the corresponding 3D regions. We mimic this user behavior by employing the normalized-cut image segmentation to extract such potential regions of interest from a 2D intensity-gradient histogram. </p><p> Completeness Challenge: The normalized-cut segments collectively span the entire intensity-gradient histogram. In order to also cover features of different sizes, we recursively apply the normalizedcut algorithm to obtain a hierarchy of segments. This multilevel hierarchy organizes the segments from coarse to fine. We have found this to be highly usable for interactive exploration. Semantic Challenge: To address the semantic challenge, we provide interactive exploration with the multilevel segmentation hierarchy . Users traverse through the hierarchy to sift for meaningful features. They can cull away the irrelevant segments and subdivide the relevant segments to explore the details. We evaluate the entropies and information gain in this hierarchy to aid the exploration. These information theoretic measures assist the users in deciding where to shows the results from our approach in which we automatically produce a reasonable number of segments. Users can visualize the surfaces by progressively hiding the solid segments, tooth holding material, dentine, and the enamel. Images courtesy of <ref type="bibr" coords="3,191.72,418.27,8.86,7.37" target="#b10">[9,</ref><ref type="bibr" coords="3,202.79,418.27,11.08,7.37" target="#b33"> 32,</ref><ref type="bibr" coords="3,216.09,418.27,11.08,7.37" target="#b42"> 43] </ref>explore. The exploration composes a visualization with features of different sizes. </p><formula>(a) (b) (c) (d) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Comparison</head><p>We show a visual comparison of the Tooth dataset in <ref type="figure" coords="3,229.87,488.66,29.74,8.02" target="#fig_0">Figure 2</ref>. The corresponding segments and histograms in the intensity-gradient domain are shown beneath the rendered image. <ref type="figure" coords="3,192.31,508.58,28.97,8.02" target="#fig_0">Figure 2</ref> (a) shows a userspecified visualization in ImageVis3D. In <ref type="figure" coords="3,187.44,518.54,30.10,8.02" target="#fig_0">Figure 2</ref> (b), spatial transfer function <ref type="bibr" coords="3,75.88,528.51,14.94,8.02" target="#b33">[32] </ref>connects voxels and histogram pixels in a bottom-up fashion and oversegments the histogram into many regions. Our topdown segmentation is progressive and only divides the histogram into a manageable number of segments. Region-growing techniques with parametric shapes show limited coverage. <ref type="figure" coords="3,74.31,578.32,42.49,8.02" target="#fig_0">Figure 2(b)</ref> shows the Gaussian mixture transfer func- tion <ref type="bibr" coords="3,48.97,588.28,14.19,8.02" target="#b42">[43,</ref><ref type="bibr" coords="3,66.68,588.28,10.65,8.02" target="#b43"> 44]</ref>. Automatic fitting produces the left visualization and requires manual resize, translate, rotate, and split operations on the transfer-function ellipses to produce the visualization on the right. Our visual segmentation approach produces a small number of freeform segments, that tightly fit the histogram and guarantee a complete coverage . We recursively apply the segmentation to also cover features of different sizes. <ref type="figure" coords="3,41.46,658.02,29.34,8.02" target="#fig_0">Figure 2</ref> (c) shows our results. We show the tooth surfaces by identifying and hiding solid segments of tooth holding material, dentine, and the enamel. The key advantages of our approach include: @BULLET Assisting region search by visually segmenting the intensitygradient histogram into collectively exhaustive and mutually exclusive segments. @BULLET The multilevel segmentation hierarchy completely covers features of all sizes. </p><p>@BULLET Users interacts with a familiar and augmented feature space that is intuitive. No new features are introduced to disrupt the work- flow. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head> 4 VOLUME SEGMENTATION BY NORMALIZED CUT ON 2D </head><p>TOGRAMS </p><p> We aim to mimic how users would visually process an intensitygradient histogram. Given a 3D intensity field, we compute its derivative , the gradient, to form a 2D intensity-gradient histogram. We plot the intensity on the horizontal axis and gradient on the vertical axis. Users locate shapes and patterns from this 2D histogram to decide how to explore the 3D volume. As shown in <ref type="figure" coords="3,479.99,180.68,29.66,8.02" target="#fig_0">Figure 2</ref>(a), users use widgets of different shapes to highlight the intensity-gradient histogram and visualize the regions of interest. We aid this tedious process by using image-segmentation algorithms to cut along the shape of this histogram. Previous work <ref type="bibr" coords="3,424.66,220.53,14.19,8.02" target="#b25">[24,</ref><ref type="bibr" coords="3,442.64,220.53,11.21,8.02" target="#b27"> 26,</ref><ref type="bibr" coords="3,457.63,220.53,11.21,8.02" target="#b33"> 32,</ref><ref type="bibr" coords="3,472.61,220.53,11.95,8.02" target="#b43"> 44] </ref>has shown that the continuity in the intensity-gradient domain reasonably approximates the spatial continuity in the dataset. We refer our readers to Kniss et. al.'s <ref type="bibr" coords="3,351.03,250.42,14.94,8.02" target="#b25">[24] </ref> work, for specific examples of how intensitygradient histogram shapes map to corresponding volume regions in datasets. Normalized-cut image segmentation <ref type="bibr" coords="3,435.59,280.96,14.94,8.02" target="#b39">[40] </ref>divides the histogram into continuous shapes that we seek. It models an image as a graph and finds the best way to partition this graph into k components. Every pixel in the image is considered as a node on the graph. The edge weights, w(u, v), between the nodes, u and v, are computed as color and location similarities between the pixels. The closer the pixels, the stronger the edge weight is. The details of the similarity measure we used can be found in <ref type="bibr" coords="3,372.02,350.70,9.52,8.02" target="#b8">[7]</ref>. The normalized cut seeks to disconnect the graph, V , into components A, B by removing the edges with the least normalized cost. The formulation of the normalized cut is as follows: </p><formula>cut(A, B) = ∑ u∈A,v∈B w(u, v) assoc(A,V ) = ∑ u∈A,t∈V w(u,t) Ncut(A, B) = cut(A, B) assoc(A, V) + cut(A, B) assoc(B, V) </formula><p> where, cut(A, B) is the total weight of edges connecting components A and B, assoc(A,V ) is the total weight of the edges of A in V , and Ncut(A, B) normalizes cut(A, B) by the edge weights of A and B. This normalization favors balanced segments, since small cuts will have a smaller denominator, and therefore, the value of Ncut(A, B) is increased. Finding the minimum Ncut(A, B) is a NP-complete problem . This is usually approximated by solving an eigenvalue problem: </p><formula>(D −W )y = λ Dy d(u) = ∑ v w(u, v) </formula><p>where W is the adjacency matrix of the image graph with edge weights w(u, v), D is a diagonal matrix with entries, d(u), and λ is an eigenvalue. We can use the resulting eigenvectors, y to partition the graph. Yu and Shi <ref type="bibr" coords="3,375.96,646.11,14.94,8.02" target="#b44">[45] </ref>show how to find k partitions by finding k eigenvectors of the eigenvalue problem. We segment the intensity-gradient histogram using a normalizedcut approach to mimic a semantically meaningful segmentation of the volume dataset. We construct a 2D histogram image from the volume dataset. We apply the logarithmic function to map the large range of frequencies to grayscale pixels. We trade the 3D spatial connectivity information for a compact abstraction in the form of a 2D histogram. The size of the histogram representation is independent of the size of the volume; it is only dependent on the bin sizes and precision, which <ref type="figure" coords="4,38.38,464.92,3.32,7.37">5</ref>. When we increase k from 4 to 5, the volume box is segmented into empty space and the cylindrical material that holds the tooth. Although this is a legitimate segmentation, it does not segment the tooth, the region of interest. </p><p> can be controlled during the histogram construction. The normalizedcut segmentation procedure divides a 2D histogram into multiple segments . These non-parametric segments fit the histogram tightly as they completely cover the histogram's intensity-gradient domain. <ref type="figure" coords="4,32.46,564.82,31.36,8.02" target="#fig_1">Figure 3</ref>shows example segments of the Tooth dataset and how this normalized-cut approach to the intensity-gradient histogram segmentation results in intuitively meaningful segments. We overlay the segments onto the 2D histograms and show the corresponding 3D segments . The normalized-cut separates the tooth from exterior material at k = 2. At k = 10, the segments distinguish solid components and the tooth crown and the root are easily identified. The segments at k = 20, distinguish material boundaries from the solid components. In our experiments, we construct a histogram from the dataset and store it as a grayscale image. We compute the normalized cut using Cour et. al. <ref type="bibr" coords="4,67.08,664.45,9.86,8.02" target="#b8">[7]</ref> 's software. We find 256 × 256 is an appropriate resolution and we show approximation of the same histogram at various resolutions in <ref type="figure" coords="4,73.31,684.37,29.02,8.02" target="#fig_2">Figure 4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">HIERARCHICAL EXPLORATION</head><p> We recursively segment the histogram to form a hierarchy for interactive exploration. A common problem in segmentation is determining the desired number of segments, k. Searching for an appropriate k by repeating the segmentation is a tedious exercise. Furthermore, as k increases, the new segments may not subdivide any region of interest. For example, <ref type="figure" coords="4,417.09,247.74,30.32,8.02">Figure 5</ref>shows the segmentation of the Tooth dataset with k = 4 and k = 5. We see an additional segment that divides up the box instead of the tooth as k increases from 4 to 5. The newly-divided segments represent the empty space and the material that holds the tooth. Although these are legitimate segments, most users would prefer to segment the tooth. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Multilevel Segmentation Hierarchy</head><p>To eliminate the need for a predetermined k, we recursively apply normalized cuts to segment the histogram and build a binary hierarchy . This hierarchy lets users to explore the histogram segments from coarse to fine details. Users interactively subdivide and explore selective regions of interest. For example, the users may interactively subdivide the tooth while keeping the box intact. This hierarchy covers the entire intensity-gradient domain with segments of different sizes to ensure an exhaustive exploration. Any cut through this segmentation hierarchy covers the entire dataset. We can traverse this hierarchy to explore the dataset at varying levels of detail in different regions of the volume. <ref type="figure" coords="4,463.89,432.02,29.99,8.02" target="#fig_4">Figure 6</ref>shows how the parent histogram nodes in the hierarchy are subdivided into the children histogram nodes. In this example, we choose to explore the tooth while keeping the segment of tooth-holding materials and space intact at the first level. The second level of the hierarchy shows the segmentation of the solid tooth crown in the third (lower-rightmost) arc. The third level contains segments of the tooth root and the shell of the crown. We can compose a visualization that covers the whole tooth with these segments at different sizes as shown on the right of that <ref type="figure" coords="4,300.81,521.69,23.16,8.02">figure.</ref>This multilevel segmentation hierarchy provides a mechanism for users to compose visualizations by flexibly combining segments of different sizes. Given the shapes of the histogram segments or corresponding volume regions, users can efficiently decide where to explore and refine. In the next section we show how information-theoretic measures can support in the intuitive segmentation of the hierarchy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Information Content</head><p>We evaluate the information content of a segment or a subdivision to aid the exploration. In addition to the user's intuition and domain knowledge, information content can serve as an auxiliary assistance when traversing the segmentation hierarchy. The use of informationtheoretic measures is increasingly popular in visualization <ref type="bibr" coords="4,501.52,656.16,9.52,8.02" target="#b1">[2]</ref>. Kim and JaJa <ref type="bibr" coords="4,319.05,666.12,14.94,8.02" target="#b22">[21] </ref>build information-aware octrees to extract isosurfaces. Jänicke et. al. <ref type="bibr" coords="4,340.15,676.08,14.19,8.02" target="#b18">[17,</ref><ref type="bibr" coords="4,357.78,676.08,11.21,8.02" target="#b19"> 18,</ref><ref type="bibr" coords="4,372.42,676.08,11.95,8.02" target="#b20"> 19] </ref>apply information theoretic measures to visualize flow. Ruiz et. al. <ref type="bibr" coords="4,382.65,686.05,14.94,8.02" target="#b34">[33] </ref>compose automatic transfer functions based on information divergence. We compute the entropy at each segment and evaluate the information gain at each subdivision of the segmentation hierarchy. Our goal is to lead users to explore segments that are more informative. To assist user exploration, we characterize the segments and the subdivision 2358 IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 18, NO. 12, DECEMBER 2012 with two different information theoretic measures: (a) Entropy, and (b) Information Gain. Segment Entropy: We use entropy to characterize the complexity of a segment. For each segment (the nodes in the hierarchy), we extract sub-volumes, V , by grouping the voxels with the corresponding intensities and gradient values. We compute the entropy in the sub-volumes, H(V ), as follows: </p><formula>H(V ) = − ∑ i p(v i ) lg 2 p(v i ) </formula><p>where v i is a voxel in V , p(v i ) is the probability of v i . p(v i ) can be computed by analyzing how many voxels have the same intensity as v i in V . This classic Shannon entropy measures how many bits are required to encode V . A high number of bits required represents a higher complexity. In <ref type="figure" coords="5,51.55,435.96,29.37,8.02" target="#fig_5">Figure 7</ref> (a), we color the segments of the Tooth dataset according to their entropy. It shows that the tooth contains a higher entropy than the empty space and tooth-holding material. However, when we further subdivide the tooth in <ref type="figure" coords="5,144.25,465.85,30.61,8.02" target="#fig_5">Figure 7</ref>(b) the entropies of different components start converging and it becomes less clear which segment should be further explored. To address this we next discuss how to evaluate the information gain. Information Gain: We use information gain to evaluate the effect of subdividing a segment. The information gain is the reduction in entropy after a subdivision. This measure has been widely used in building decision trees <ref type="bibr" coords="5,128.62,539.32,13.74,8.02" target="#b32">[31]</ref>, where the attribute with the highest information gain subdivides the training data. We compute this by subtracting the entropy of the children nodes from the parent node: </p><formula>G(V ) = (H(V ) − ∑ j |V j | |V | H(V j ))/H(V ) </formula><p>where V j are the sub-volumes of V . We normalize this gain by the entropy before the subdivision. <ref type="figure" coords="5,151.10,616.87,30.32,8.02" target="#fig_5">Figure 7</ref>(b) shows how information gain can distinguish segments with similar entropy. In this case subdividing the high information gain segment separates the dentine boundary from the enamel crown. The entropy reduction highlights potential structures, even if the complexity of the segments are similar. When the entropy reduction is low, it means that the subdivision does not sufficiently reduce the complexity of the segment. However, if the entropy reduction is high, it suggests that the complexity is lowered in the sub-segments, which is likely to happen as a result of separation of two meaningfully different structures into the two sub-segments. While, the noise in the dataset may affect the computation of the true entropy, the relative nature of the information-gain measure should reduce this noise effect. <ref type="bibr" coords="5,322.17,453.73,9.74,7.37">(a) </ref>shows the tooth segment has a higher entropy (in red) than the empty space and tooth-holding material. Further subdivision the tooth in (b) results in segments with converging entropies. In an alternate approach, we evaluate the information gain on those segments. The subdivision with the highest information gain (in blue) separates the dentine boundary from the enamel crown. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Interactive Exploration</head><p>The users interact with segments at different levels of the hierarchy and compose visualizations on the intensity-gradient histogram. Interactive and multilevel exploratory approaches have been shown effective on large and complex datasets, such as, lengthy molecular simu- lations <ref type="bibr" coords="5,320.39,586.63,14.94,8.02" target="#b29">[28] </ref>and very large gigapixel images <ref type="bibr" coords="5,454.59,586.63,13.74,8.02" target="#b17">[16]</ref> . This interactive approach allows users to incorporate their knowledge in the exploration process. The main interactions in this procedure are subdividing or hiding a segment. Users inspect the segments and decide the subsequent exploration process. Hand editing of segments, such as, manual translation, rotation, resizing, or reshaping of segments is not required in the results presented in this work. We present the dataset in a bi-segment configuration to start the exploration . Similar to other related work, we overlay the segments on the intensity-gradient histogram for the users to relate to the volume regions . By default, we color the segments using a randomly-generated color map. Clicking on any segment subdivides it into two components . Users can visualize the entropy or information gain using a color-coded visualization with an appropriate key press. Users may also choose to change the colors and opacities of each segment. These interactions allow a user to inspect and focus on regions of interest. We also provide shortcuts to clear the opacity of any segment to allow the user to easily cull away any segment. We show how to exhaustively explore the Tooth dataset and compose a boundary visualization similar to the user-specified visualization in <ref type="figure" coords="6,48.10,408.05,29.08,8.02" target="#fig_0">Figure 2</ref>(a). The supplementary video shows this visualization can be constructed in less than a minute. <ref type="figure" coords="6,168.73,418.01,29.94,8.02" target="#fig_6">Figure 8</ref>presents an example of the interactive exploration process. The hierarchy on the top right shows the subdivision and the numbers indicate the order of subdivision . The corresponding histograms and visualizations are shown on the left. The colors of the nodes are the colors of the corresponding segments. The crossed-out leaves indicate that we decided to cullaway those segments by setting the opacity to zero. Their subtrees are not further explored. The exploration starts with the full dataset. The initial segments in step 1 divide the tooth from the rest of data, the first (lower-leftmost) arc in the histogram. We focus on the tooth from step 2 onwards. Step 2 shows the crown and the root. Step 3 segments the shell of the crown in yellow. Step 4 shows the second (lower-middle) arc is the root of the tooth and separates it from noise (this is best seen in the video). We first select the root and then remove the noise. Step 5 divides the root into the solid blob-like dentine component and its boundary. We keep the dentine boundary and move on to the tooth crown represented by the third (lower-rightmost) arc in step 6. Step 7 divides the arc, the left half shows the boundary between the enamel and the dentine and the right half shows the solid enamel component. We show the boundary by hiding the solid component and move on to explore the last noise-like segment between the first (lower-leftmost) and second (lower-middle) arcs in step 7. In step 8, the lower half of the noise-like component shows the noise, however the top half shows the boundary of the pulp along with a small piece of the tooth-holding material at the back. We hide the noise, then further segment the pulp boundary in step 9. This allows us to remove the tooth-holding material and arrive at our final visualization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>We apply this exploration approach to visualize a variety of volume datasets: Implementation and Experimental Setup: We compute a six-level normalized-cut hierarchy for each histogram by using Cour et. al.'s <ref type="bibr" coords="6,336.33,359.81,10.45,8.02" target="#b8">[7] </ref>normalized cut software in Matlab. We only store the finest level of the segmentation and access the rest according to a binary-tree order. We visualize the segments as freeform components on a 2D intensity-gradient transfer function. We implement our application with Qt and the NVIDIA CUDA SDK volume rendering example. The preprocessing in Matlab takes about 15 seconds per histogram. This preprocessing can be avoided completely if we can perform normalized cut with an accelerated eigensolver at exploration time as discussed in Section 7. We performed all experiments on a Linux workstation with an Intel Xeon 5140 and a NVIDIA GeForce 260GTX GPU. For each dataset, we show a visualization and the corresponding exploration hierarchy. The numbering shows the order of the subdivision steps along the hierarchy. We illustrate the key steps and their corresponding visualizations on the left side of each figure. We also highlight segments corresponding to interesting structures of the datasets. The supplementary video shows the interactive composition process. Our results show our approach follows human intuition in segmenting histograms into meaningful components. Engine: The engine block's histogram shows a distinctive arc-like region that represents the main engine block and the space around it. The segmentation separates this solid arc region from the other scattered arc with high intensity and gradient in the histogram. The high intensity and high gradient arc represents the internal structures and is shown in <ref type="figure" coords="6,319.75,602.91,29.08,8.02" target="#fig_7">Figure 9</ref>(b). <ref type="figure" coords="6,365.35,602.91,29.25,8.02" target="#fig_7">Figure 9</ref>(a) shows the arc region that represents the space and the engine block regions shows a high information gain. We subdivide the arc to separate the space and noise from the engine block. We then obtain the surface of the engine block by subdividing another level. The final visualization shows the engine block surface and the internal structures in <ref type="figure" coords="6,389.46,652.73,29.02,8.02" target="#fig_7">Figure 9</ref>. Foot: <ref type="figure" coords="6,323.22,666.68,35.20,8.02" target="#fig_8">Figure 10</ref> shows the visualization of the Foot dataset. Although the histogram in this foot dataset does not exhibit any distinctive arc shapes, our visual segmentation technique can still divide the histogram into meaningful segments. Step 1 separates the bones from the rest. We subdivide the box of spaces and the flesh in steps 2-5, to obtain segments corresponding to the joints, the flesh, and the skin. <ref type="figure" coords="6,285.12,726.46,33.90,8.02" target="#fig_8">Figure 10</ref>(b) shows the visualization of the bones and the joints. We compose the visualization with the bones, the joints, and the skin. Tomato: We distinguish different parts of a tomato in <ref type="figure" coords="7,244.65,362.61,33.49,8.02" target="#fig_10">Figure 11</ref>. The red low intensity and high gradient region is the skin in <ref type="figure" coords="7,31.50,402.46,34.51,8.02" target="#fig_10">Figure 11</ref>(a) is at the center of the histogram, whose segmentation would not have been possible with an intensity-only 1D histogram. Visible Human Male Head: We present the head of the visible human male dataset as an example in <ref type="figure" coords="7,170.97,438.09,33.68,8.02" target="#fig_0">Figure 12</ref>. Similar to the Foot dataset, Step 1 shows the bones. Step 2 shows the teeth. Steps 3, 4, and 5 divide the low-intensity arc region progressively and show the flesh (step 4) and the skin (step 5). Step 6 divides the low-intensity and highgradient regions into the sinus and some noise. We remove the noise and show the bone, skin, teeth, and sinus in the final visualization. Hurricane Isabel: We visualize the pressure field of the hurricane Isabel dataset. This is a continuous scalar field with no abrupt boundaries and is different from the previous examples with clear material changes. <ref type="figure" coords="7,66.49,533.51,34.98,8.02" target="#fig_1">Figure 13</ref>shows the exploration hierarchy of the hurricane. Step 1 separates the land and the atmospheric regions. Step 2 segments the hurricane eye from the atmospheric region. The rainbands from the eyewall structures of the hurricane are separated in Step 3. By inspecting the entropy of the segments in (c), we decide to switch our focus onto the eye of the hurricane. Steps 4 and 5 show regions of different pressures in the hurricane eye. We compose the final visualization with the hurricane eye segments, the eyewall and the rainbands. <ref type="figure" coords="7,31.50,613.21,33.22,8.02" target="#fig_1">Figure 13</ref>(a) and (b) show the separated eyewall and the rainbands. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS AND FUTURE WORK</head><p>In this paper we present a hierarchy of normalized-cut-assisted visual segmentation of an intensity-gradient histogram to assist in the volume exploration process. In contrast with existing approaches in <ref type="figure" coords="7,266.93,666.68,14.95,8.02;7,31.50,676.65,28.57,8.02" target="#fig_0">Fig- ure 2(b)</ref>and (c), our top-down segmentation approach produces fewer segments and a superior coverage. Our visual approach also well approximates user-specified visualizations in <ref type="figure" coords="7,190.53,696.57,30.06,8.02" target="#fig_0">Figure 2</ref>(a). We address the information challenge by using a visual segmentation of intensitygradient histograms to locate various meaningful volumetric segments. These segments completely cover the intensity-gradient domain in the image space and identify features of different sizes. We show that any </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>cut </head><p>in the segmentation hierarchy covers the entire dataset. Exploring along this hierarchy addresses the completeness challenge. We assist the volumetric data exploration process by using information-theoretic measures. The users can identify meaningful components and material boundaries through a concise interactive exploration procedure. These interactions address the semantic challenge by allowing users to adaptively explore the dataset and associate their knowledge with the corresponding data segments. We believe our hierarchical approach naturally extends to larger datasets. The key is to perform the normalized-cut segmentation ondemand . This is critical for visualizing a large dataset because it can limit the subdivisions and segmentation to only the necessary ones. The hierarchical nature ensures that the complexity of subdividing volumes does not grow. Another possible avenue of advancement is to study other, more sophisticated measures of information content for the volumetric subdivisions. The general entropy characterizes the worst-case uncertainty. We believe this may be improved by considering the spatial structure in the volume datasets. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,31.50,323.63,250.38,7.37;3,31.50,333.09,250.38,7.37;3,31.50,342.55,250.38,7.37;3,31.50,352.02,250.38,7.37;3,31.50,361.48,250.38,7.37;3,31.50,370.95,250.38,7.37;3,31.50,380.41,250.38,7.37;3,31.50,389.88,250.38,7.37;3,31.50,399.34,250.38,7.37;3,31.50,408.81,250.38,7.37;3,31.50,418.27,195.67,7.37"><head>Fig. 2. </head><figDesc>Fig. 2. Comparison of the Tooth Dataset visualization: (a) shows a user-specified visualization in the ImageVis3D manual using trapezoidal widgets. (b) shows how the spatial transfer function oversegments the histogram into many regions; (c) shows the Gaussian mixture elliptical transfer function. The ellipses do not fully cover the histogram. The left visualization shows the automatic starting configuration. The users can then resize, rotate, and split the ellipses to obtain the right visualization . (d) shows the results from our approach in which we automatically produce a reasonable number of segments. Users can visualize the surfaces by progressively hiding the solid segments, tooth holding material, dentine, and the enamel. Images courtesy of [9, 32, 43] </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,22.50,186.53,513.00,7.37;4,22.50,195.99,513.00,7.40"><head>Fig. 3. </head><figDesc>Fig. 3. We show normalized-cut histogram segmentations of the Tooth dataset at different k's. (a) shows the separation of the tooth and the volume box. (b) shows segments of the crown and root of the tooth. At k = 20, (c) shows material boundaries that are separated from the solid components. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,22.50,315.99,250.38,7.40;4,22.50,325.46,18.93,7.37"><head>Fig. 4. </head><figDesc> Fig. 4. k = 20 segmentations of the Tooth's histogram at various resolu- tions. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,22.50,464.92,250.38,7.37;4,22.50,474.39,250.38,7.37;4,22.50,483.85,250.38,7.37;4,22.50,493.32,74.87,7.37"><head>Fig</head><figDesc>Fig. 5. When we increase k from 4 to 5, the volume box is segmented into empty space and the cylindrical material that holds the tooth. Although this is a legitimate segmentation, it does not segment the tooth, the region of interest. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,31.50,239.11,513.00,7.37;5,31.50,248.58,473.30,7.37"><head>Fig. 6. </head><figDesc>Fig. 6. A multilevel segmentation hierarchy enables users to compose visualizations with segments of different sizes. Assembling the red-framed segments produces the visualization on the right. Similar to a level-of-details hierarchy, a cut in this hierarchy covers the entire dataset. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,294.12,453.73,250.38,7.37;5,294.12,463.19,250.38,7.37;5,294.12,472.66,250.38,7.37;5,294.12,482.12,250.38,7.37;5,294.12,491.58,250.38,7.37;5,294.12,501.05,147.19,7.37"><head>Fig. 7. </head><figDesc>Fig. 7. (a) shows the tooth segment has a higher entropy (in red) than the empty space and tooth-holding material. Further subdivision the tooth in (b) results in segments with converging entropies. In an alternate approach, we evaluate the information gain on those segments. The subdivision with the highest information gain (in blue) separates the dentine boundary from the enamel crown. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,22.50,305.52,250.38,7.37;6,22.50,314.98,250.38,7.37;6,22.50,324.45,250.38,7.37;6,22.50,333.91,158.56,7.37"><head>Fig. 8. </head><figDesc>Fig. 8. This shows an example of the interactive exploration process. The hierarchy on the right shows the subdivision steps. The left shows the corresponding visualizations and histogram segments at different steps. The process is detailed in Section 5.3. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="6,285.12,221.02,250.38,7.37;6,285.12,230.48,250.38,7.37;6,285.12,239.95,250.38,7.37;6,285.12,249.41,124.67,7.37"><head>Fig. 9. </head><figDesc>Fig. 9. Visualization of the Engine dataset: in (a) the solid arc region shows a high information gain. We subdivide this arc to separate the engine block from the space and the noise and visualize it along with the internal structures shown in (b). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="7,31.50,302.39,250.38,7.37;7,31.50,311.85,250.38,7.37;7,31.50,321.32,250.38,7.37;7,31.50,330.78,36.21,7.37"><head>Fig. 10. </head><figDesc>Fig. 10. Visualization of the Foot dataset. Each component of the foot, such as, the bone (Step 1), the joints (Step 3), and the flesh (Step 4) are shown along the composition hierarchy. (a) shows the separated bones and joints. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="7,266.93,372.57,14.95,8.02;7,31.50,382.53,250.38,8.02;7,31.50,392.50,250.38,8.02"><head></head><figDesc>Figure 11(c). The blue locular cavities in Figure 11(b) are characterized by high intensity and high gradient. Notice the yellow collumella in </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="7,294.12,302.39,250.38,7.37;7,294.12,311.85,250.38,7.37;7,294.12,321.32,250.38,7.37;7,294.12,330.78,158.21,7.37"><head>Fig. 11. </head><figDesc>Fig. 11. Visualization of the Tomato dataset. Steps 1-4 lead to the skin segment in (c). Steps 5-6 show the columella and placenta in (a) The locular cavity is shown in (b). The visualization shows the skin, locular cavity, columella, and placenta of the tomato. </figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p>We thank the anonymous reviewers for their constructive comments and suggestions that have greatly improved the presentation of this work. This work has been supported in part by the NSF grants: CCF 05-41120, CMMI 08-35572, CNS 09-59979 and the NVIDIA CUDA Center of Excellence. Any opinions, findings, conclusions, or recommendations expressed in this article are those of the authors and do not necessarily reflect the views of the research sponsors. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="7,312.38,670.84,232.12,7.13;7,312.38,680.31,232.12,7.13;7,312.38,689.77,177.84,7.13"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Hybrid segmentation and exploration of the human lungs</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Bartz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Mayer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Fischer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Rio</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Thust</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">P</forename>
				<surname>Heussel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">U</forename>
				<surname>Kauczor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Straßer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,312.38,699.24,232.12,7.13;7,312.38,708.70,232.12,7.13;7,312.38,718.17,227.78,7.13"  xml:id="b1">
	<analytic>
		<title level="a" type="main">An information-theoretic framework for visualization</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jänicke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1206" to="1215" />
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,312.38,727.63,232.12,7.13;7,312.38,737.10,232.12,7.13;7,532.75,26.46,16.00,7.26"  xml:id="b2">
	<monogr>
		<title level="m" type="main">A contract based system for large data visualization</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Childs</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Brugger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Bonnell</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Meredith</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Miller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Whitlock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Max</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,30.75,26.18,481.76,7.50;8,22.50,302.39,250.38,7.37;8,22.50,311.85,250.38,7.37;8,22.50,321.32,250.38,7.37;8,22.50,330.78,233.79,7.37"  xml:id="b3">
	<monogr>
		<title level="m" type="main">Visualization of the Visible Human Male Head dataset. The hierarchy progressively (2-6) reveals the bone, teeth, flesh, skin, and sinus. (a) shows the sinus segment and (b) shows the teeth segment. We compose the visualization with the bone, teeth, skin and sinus</title>
		<author>
			<persName>
				<forename type="first">Ip</forename>
				<surname>Et</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Al</forename>
				<surname>Hierarchical</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Exploration</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Volumes</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Multilevel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Of</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Intensity-Gradient…</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Fig</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,367.98,232.12,7.13;8,40.76,377.87,59.38,6.15"  xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Visualization</title>
		<imprint>
			<biblScope unit="page" from="191" to="198" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,386.91,232.12,7.13;8,40.76,396.37,232.12,7.13;8,40.76,405.84,220.89,7.13"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Mean shift: a robust approach toward feature space analysis</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Comaniciu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Meer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="61910" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,415.30,232.12,7.13;8,40.76,424.77,232.12,7.13;8,40.76,434.23,232.12,7.13;8,40.76,444.12,40.25,6.15"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Size-based transfer functions: A new volume exploration technique</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Correa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1380" to="138710" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,453.16,232.12,7.13;8,40.76,462.63,232.12,7.13;8,40.76,472.09,213.16,7.13"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Visibility histograms and visibility-driven transfer functions</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">D</forename>
				<surname>Correa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="192" to="204" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,481.55,232.12,7.13;8,40.76,491.02,232.12,7.13;8,40.76,500.48,184.19,7.13"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Spectral segmentation with multiscale graph decomposition</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Cour</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Benezit</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1124" to="1131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,509.95,232.12,7.13;8,40.76,519.41,232.12,7.13;8,40.76,528.88,17.93,7.13"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient graph-based image segmentation</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Felzenszwalb</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Huttenlocher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="181" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,538.34,232.12,7.13;8,40.76,547.81,232.12,7.13;8,40.76,557.27,43.62,7.13"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Tuvok, an architecture for large scale volume rendering</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Fogal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Krüger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Vision, Modeling, and Visualization</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,566.74,232.12,7.13;8,40.76,576.20,232.12,7.13;8,40.76,585.66,209.06,7.13"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Yet another survey on image segmentation: Region and boundary information integration</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Freixenet</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Muñoz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Raba</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Martí</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Cufí</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="408" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,595.13,232.12,7.13;8,40.76,604.59,232.12,7.13;8,40.76,614.06,214.13,7.13"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Automating transfer function design for comprehensible volume rendering based on 3D field topology analysis (case study)</title>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Fujishiro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Azuma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Takeshima</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="467" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,623.52,232.12,7.13;8,40.76,632.99,232.12,7.13;8,40.76,642.45,232.12,7.13;8,40.76,651.92,171.84,7.13"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Segmentation of three-dimensional retinal image data</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">R</forename>
				<surname>Fuller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">J</forename>
				<surname>Zawadzki</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Choi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">F</forename>
				<surname>Wiley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Werner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Hamann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1719" to="172670590" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,661.38,232.12,7.13;8,40.76,670.84,232.12,7.13;8,40.76,680.31,193.94,7.13"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Random walks for interactive organ segmentation in two and three dimensions: Implementation and validation</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Grady</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Schiwietz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Aharon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="773" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,689.77,232.12,7.13;8,40.76,699.24,206.94,7.13"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Rgvis: Region growing based techniques for volume visualization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Huang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Graphics</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,708.70,232.12,7.13;8,40.76,718.17,232.12,7.13;8,40.76,727.63,76.24,7.13"  xml:id="b16">
	<analytic>
		<title level="a" type="main">On implementing graph cuts on CUDA</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hussein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Varshney</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Davis</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First workshop on General Purpose Processing on Graphics Processing Units</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,40.76,737.10,232.12,7.13;8,285.12,302.39,250.38,7.37;8,285.12,311.85,250.38,7.37;8,285.12,321.32,250.38,7.37;8,285.12,330.78,250.38,7.37;8,285.12,340.25,250.38,7.37;8,285.12,349.71,250.38,7.37;8,285.12,359.18,234.30,7.37;8,303.38,396.37,232.12,7.13;8,303.38,405.84,220.49,7.13"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Saliency-assisted navigation of very large land- Fig. 13. Visualization of the pressure field of the Hurricane Isabel dataset We magnify the bottom part of the histogram in steps 2-6 and (c) to better show the segments. Steps 1-3 divide the hurricane into its major components: the eye, the eyewall, and the rainbands. (c) shows the entropy of the Hurricane eye is higher than the other segments after step 3. We focus on the hurricane eye in steps 4-6. (a) shows the eyewall segment and (b) shows the rainbands segment. scape images</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">Y</forename>
				<surname>Ip</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Varshney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="171737" to="1746" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,415.30,232.12,7.13;8,303.38,424.77,232.12,7.13;8,303.38,434.23,232.12,7.13;8,303.38,443.70,37.86,7.13"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Visual exploration of climate variability changes using wavelet analysis</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jänicke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bottinger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Mikolajewicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Scheuermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1375" to="1382" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,453.16,232.12,7.13;8,303.38,462.63,232.12,7.13;8,303.38,472.09,37.86,7.13"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Measuring complexity in Lagrangian and Eulerian flow descriptions</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jänicke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Scheuermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1783" to="1794" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,481.55,232.12,7.13;8,303.38,491.02,232.12,7.13;8,303.38,500.48,132.78,7.13"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual analysis of flow features using information theory</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Jänicke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Scheuermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="40" to="49" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,509.95,232.12,7.13;8,303.38,519.41,232.12,7.13;8,303.38,529.30,54.60,6.15"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Top scientific visualization research problems</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Johnson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="13" to="17" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,536.86,232.12,8.61;8,303.38,547.81,232.12,7.13;8,303.38,557.35,232.12,6.86;8,303.38,566.74,157.63,7.13"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Information-aware 2 n -tree for efficient out-of-core indexing of very large multidimensional volumetric data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Jaja</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Scientific and Statistical Database Management</title>
		<imprint>
			<date type="published" when="2007-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,576.20,232.12,7.13;8,303.38,585.66,232.12,7.13;8,303.38,595.13,69.29,7.13"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Saliency-guided enhancement for volume visualization</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kim</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Varshney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="925" to="932" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,604.59,232.12,7.13;8,303.38,614.06,232.12,7.13;8,303.38,623.52,107.45,7.13"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Semi-automatic generation of transfer functions for direct volume rendering</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">L</forename>
				<surname>Kindlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">W</forename>
				<surname>Durkin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,632.99,232.12,7.13;8,303.38,642.45,232.12,7.13;8,303.38,651.92,232.12,7.13;8,303.38,661.80,83.29,6.15"  xml:id="b25">
	<analytic>
		<title level="a" type="main">Multidimensional transfer functions for interactive volume rendering</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kniss</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Kindlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Hansen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,670.84,232.12,7.13;8,303.38,680.31,232.12,7.13;8,303.38,689.77,162.27,7.13"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Supervised manifold distance segmentation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kniss</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Wang</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1637" to="1649" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,699.24,232.12,7.13;8,303.38,708.70,232.12,7.13;8,303.38,718.17,232.12,7.13;8,303.38,727.63,192.38,7.13"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Structuring feature space: A non-parametric method for volumetric transfer function generation</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Maciejewski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Woo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Ebert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1473" to="1480" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,303.38,737.10,232.12,7.13;9,49.76,54.06,232.12,7.13;9,49.76,63.52,232.12,7.13;9,49.76,73.41,116.76,6.15"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Voreen: A rapid-prototyping environment for ray-casting-based volume visualizations</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Meyer-Spradow</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Mensmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Hinrichs</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="6" to="13" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,82.45,232.12,7.13;9,49.76,91.92,232.12,7.13;9,49.76,101.38,232.12,7.13;9,49.76,111.27,131.11,6.15"  xml:id="b29">
	<analytic>
		<title level="a" type="main">MDMap: A system for data-driven layout and exploration of molecular dynamics simulations</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Patro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">Y</forename>
				<surname>Ip</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bista</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Cho</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Thirumalai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Varshney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BioVis</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,120.31,232.12,7.13;9,49.76,129.78,232.12,7.13;9,49.76,139.24,232.12,7.13;9,49.76,149.13,83.29,6.15"  xml:id="b30">
	<analytic>
		<title level="a" type="main">The transfer function bakeoff</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Pfister</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Lorensen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Bajaj</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Kindlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Schroeder</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<forename type="middle">S</forename>
				<surname>Avila</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Martin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Machiraju</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lee</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="16" to="22" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,158.17,232.12,7.13;9,49.76,167.63,232.12,7.13;9,49.76,177.10,232.12,7.13;9,49.76,186.99,16.34,6.15"  xml:id="b31">
	<analytic>
		<title level="a" type="main">Uncertainty-aware guided volume segmentation</title>
		<author>
			<persName>
				<forename type="first">J.-S</forename>
				<surname>Prassni</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Hinrichs</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1358" to="1365" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,196.03,232.12,7.13;9,49.76,205.49,17.93,7.13"  xml:id="b32">
	<monogr>
		<title level="m" type="main">C4.5: programs for machine learning</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Quinlan</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Morgan kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,214.96,232.12,7.13;9,49.76,224.42,107.75,7.13"  xml:id="b33">
	<analytic>
		<title level="a" type="main">Spatialized transfer functions</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Roettger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bauer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stamminger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,233.88,232.12,7.13;9,49.76,243.35,232.12,7.13;9,49.76,252.81,232.12,7.13;9,49.76,262.28,142.35,7.13"  xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic transfer functions based on informational divergence</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ruiz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bardera</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Boada</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Viola</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Feixas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Sbert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1932" to="1941" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,271.74,232.12,7.13;9,49.76,281.21,232.12,7.13;9,49.76,290.67,173.01,7.13"  xml:id="b35">
	<analytic>
		<title level="a" type="main">High-level user interfaces for transfer function design with semantics</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">R</forename>
				<surname>Salama</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Keller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Kohlmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1021" to="1028" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,300.14,232.12,7.13;9,49.76,309.60,232.12,7.13;9,49.76,319.07,232.12,7.13;9,49.76,328.53,121.64,7.13;9,31.50,336.15,29.35,8.97;9,57.30,337.99,224.58,7.13;9,49.76,347.46,232.12,7.13;9,49.76,356.92,194.12,7.13;9,31.50,364.54,30.85,8.97;9,58.81,366.39,223.07,7.13;9,49.76,375.85,232.12,7.13;9,49.76,385.32,147.58,7.13"  xml:id="b36">
	<analytic>
		<title level="a" type="main">Semiautomatic transfer function initialization for abdominal visualization using self-generating hierarchical radial basis function networks Visualization of boundaries in volumetric data sets using LH histograms Automating transfer function design for volume rendering using hierarchical clustering of material boundaries</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">A</forename>
				<surname>Selver</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">Güzeliç</forename>
				<surname>Sereda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bartroli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Serlie</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Gerritsen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis</title>
		<meeting><address><addrLine>Sereda, A. Vilanova, and F. Gerritsen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="395" to="409208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,394.78,232.12,7.13;9,49.76,404.25,230.06,7.13"  xml:id="b37">
	<analytic>
		<title level="a" type="main">Hierarchy and adaptivity in segmenting visual scenes</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Sharon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Galun</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Sharon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Basri</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Brandt</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NATURE</title>
		<imprint>
			<biblScope unit="issue">7104</biblScope>
			<biblScope unit="page">442810</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,413.71,232.12,7.13;9,49.76,423.17,232.12,7.13;9,49.76,432.64,120.28,7.13"  xml:id="b38">
	<analytic>
		<title level="a" type="main">Fast volume segmentation with simultaneous visualization using programmable graphics hardware</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sherbondy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Houston</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Napel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,442.10,232.12,7.13;9,49.76,451.57,232.12,7.13;9,49.76,461.03,139.16,7.13"  xml:id="b39">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Malik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,470.50,232.12,7.13;9,49.76,479.96,232.12,7.13;9,49.76,489.43,232.12,7.13;9,49.76,498.89,232.12,7.13;9,49.76,508.78,121.55,6.15"  xml:id="b40">
	<analytic>
		<title level="a" type="main">Tuner: Principled parameter finding for image segmentation algorithms using visual response surface exploration</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Torsney-Weir</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Saad</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Moller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Hege</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Weber</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Verbavatz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bergner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1892" to="1901" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,517.82,232.12,7.13;9,49.76,527.28,232.12,7.13;9,49.76,536.75,232.12,7.13;9,49.76,546.64,83.29,6.15"  xml:id="b41">
	<analytic>
		<title level="a" type="main">An intelligent system approach to higher-dimensional classification of volume data</title>
		<author>
			<persName>
				<forename type="first">F.-Y</forename>
				<surname>Tzeng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">B</forename>
				<surname>Lum</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,555.68,232.12,7.13;9,49.76,565.14,232.12,7.13;9,49.76,574.61,190.17,7.13"  xml:id="b42">
	<analytic>
		<title level="a" type="main">Volume exploration using ellipsoidal Gaussian transfer functions</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Shan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Dong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Chi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PacificVis</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,584.07,232.12,7.13;9,49.76,593.54,232.12,7.13;9,49.76,603.00,232.12,7.13;9,49.76,612.89,116.76,6.15"  xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient volume exploration using the Gaussian mixture model</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Dong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Shan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Chi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1560" to="1573" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,621.93,232.12,7.13;9,49.76,631.39,232.12,7.13;9,49.76,641.28,83.29,6.15"  xml:id="b44">
	<analytic>
		<title level="a" type="main">Multiclass spectral clustering</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">X</forename>
				<surname>Yu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Shi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="313" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,650.32,232.12,7.13;9,49.76,659.79,232.12,7.13;9,49.76,669.25,232.12,7.13;9,49.76,678.72,166.26,7.13"  xml:id="b45">
	<analytic>
		<title level="a" type="main">Automatic transfer function generation using contour tree controlled residue flow model and color harmonics</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Takatsuka</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15120</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1481" to="148810" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
