<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Turbulence Visualization at the Terascale on Desktop PCs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Marc</forename>
								<surname>Treib</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Kai</forename>
								<forename type="middle">B</forename>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Florian</forename>
								<surname>Reichl</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Charles</forename>
								<surname>Meneveau</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Alex</forename>
								<surname>Szalay</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">R</forename>
								<forename type="middle">¨</forename>
								<surname>Udiger Westermann</surname>
							</persName>
						</author>
						<title level="a" type="main">Turbulence Visualization at the Terascale on Desktop PCs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Visualization system and toolkit design</term>
					<term>vector fields</term>
					<term>volume rendering</term>
					<term>data streaming</term>
					<term>data compression</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Visualizations of structures in 1024 3 turbulence data sets on 1024 × 1024 viewports, directly from the turbulent motion field. Left: Close-up of iso-surfaces of the Δ Chong invariant with direct volume rendering of vorticity direction inside the vortex tubes. Middle: Direct volume rendering of color-coded vorticity direction. Right: Close-up of direct volume rendering of R S. The visualizations are generated by our system in less than 5 seconds on a desktop PC equipped with 12 GB of main memory and an NVIDIA GeForce GTX 580 graphics card with 1.5 GB of video memory. Abstract—Despite the ongoing efforts in turbulence research, the universal properties of the turbulence small-scale structure and the relationships between small-and large-scale turbulent motions are not yet fully understood. The visually guided exploration of turbulence features, including the interactive selection and simultaneous visualization of multiple features, can further progress our understanding of turbulence. Accomplishing this task for flow fields in which the full turbulence spectrum is well resolved is challenging on desktop computers. This is due to the extreme resolution of such fields, requiring memory and bandwidth capacities going beyond what is currently available. To overcome these limitations, we present a GPU system for feature-based turbulence visualization that works on a compressed flow field representation. We use a wavelet-based compression scheme including run-length and entropy encoding, which can be decoded on the GPU and embedded into brick-based volume ray-casting. This enables a drastic reduction of the data to be streamed from disk to GPU memory. Our system derives turbulence properties directly from the velocity gradient tensor, and it either renders these properties in turn or generates and renders scalar feature volumes. The quality and efficiency of the system is demonstrated in the visualization of two unsteady turbulence simulations, each comprising a spatio-temporal resolution of 1024 4. On a desktop computer, the system can visualize each time step in 5 seconds, and it achieves about three times this rate for the visualization of a scalar feature volume.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p> Hydrodynamic turbulence is one of the most thoroughly explored phenomena among complex multi-scale physical systems. It has important applications in engineering thermo-fluid systems, in the geosciences and environmental transport, even in astrophysics. In recent years, high performance computing <ref type="bibr" coords="1,163.52,582.63,14.94,8.45" target="#b19">[20] </ref> and new experimental measurement techniques <ref type="bibr" coords="1,108.02,592.59,14.19,8.45" target="#b21">[22,</ref><ref type="bibr" coords="1,124.88,592.59,11.95,8.45" target="#b41"> 42] </ref>applied to the study of various types of turbulent flows have enabled significant progress. Yet, modeling and understanding turbulent flows remains a scientifically deep, techno- @BULLET <ref type="bibr" coords="1,43.70,646.37,171.73,7.66">Marc Treib, Kai Bürger, Florian Reichl, and Rüdiger </ref>logically relevant, but fundamentally unsolved, problem. One grand challenge that significantly increases the complexity of turbulence analysis is turbulence's inherently vectorial and tensorial structure: one describes turbulent flows using velocity and vorticity vector fields, and velocity gradient and stress tensor fields. Some of the most salient features of turbulent flows have emerged from an examination of the velocity gradient tensor. It is defined according to </p><formula>A i j = ∂ u i ∂ x j , </formula><p> where we use index notation; u i (x,t), i = 1, 2, 3 denote the three components of the velocity vector field (which in turbulent flows depend on position vector x and time t). Such gradient fields of fluid velocity provide a rich characterization of the local quantitative and qualitative behavior of flows, which is evident from the linear approximation in the neighborhood of an arbitrary point. Since A is a second-rank tensor , it has nine components (in three dimensions) and these contain rich information about the local properties of the flow. Since the tensor A encodes much information through each of its matrix elements, analysis of its properties is quite challenging. Therefore, certain scalar quantities that characterize basic properties of A have been proposed and are often analyzed as scalar fields, e.g. the vorticity magnitude, the dissipation rate, the angle between vorticity and the strain-rate eigenvectors , or the magnitude of the rotation tensor, to name just a few. One of the primary challenges in turbulence research is to endow the traditional statistical analysis of metrics (e.g. the average of an alignment angle) with more geometrical insights into the overall structure of turbulence affecting more than one specific property. Even though a number of different feature metrics are known, no single feature can alone explain all relevant effects. This means that different features must be explored simultaneously and in an interactive fashion , to be seen in relation to each other. Only then can one proceed with evaluating more meaningful statistical metrics. For example, one would like to visualize the high vorticity, high rotation, or high Q regions in the flow, but in relation with the alignments of the local strain-rate eigen-directions, or together with another scalar field such as R. Particularly the question whether the geometric trends in the small-scale turbulence structures are also shared by the coarse-grained (or filtered) velocity gradient tensor plays a determining role in turbulence research. A visual indication of the relationship between velocity increments and the filtered velocity gradients at coarser scales can enable further insights into the complicated multi-scale behavior of turbulence. The visual exploration of many different intrinsic features of turbulence , however, is very challenging. The major reason is that the fine-scale structures are fully resolved only at the very highest resolution in both space and time. For instance, in the current paper we will address the visualization of two terascale turbulence simulations, each comprised of one thousand time steps of size 1024 3 , making every time step as large as 12 GB (3 floating-point values per velocity sample ). These data sets contain direct numerical simulations of forced isotropic turbulence (see <ref type="figure" coords="2,113.32,362.76,20.02,8.45">Fig. 1</ref> , left) and magneto-hydrodynamic turbulence (see <ref type="figure" coords="2,71.53,372.72,21.01,8.45">Fig. 1</ref>, middle and right), respectively. For a detailed descriptions of the simulation and database methods used let us refer to <ref type="bibr" coords="2,32.62,392.65,14.94,8.45" target="#b25">[26] </ref>and the web page at http://turbulence.pha.jhu.edu. For such data it is simply not feasible to precompute multiple feature volumes and inspect these volumes simultaneously, in particular because the number of potentially interesting features and scales is so large. Furthermore , to be able to faithfully represent even the smallest features in the data, highly accurate reconstruction schemes are necessary which work directly on the turbulence field by reconstructing features in turn during visualization. As a consequence, visualization systems necessary to explore the full turbulence spectrum require an innovative approach that provides extreme I/O capabilities, combined with computational resources that allow for an efficient feature reconstruction and rendering. Since the data to be visualized is so large that even storing one single time step in CPU memory can become problematic, bandwidth limitations in paging the data from disk become a major bottleneck. Following the requirements in turbulence visualization, we have developed a new holistic approach which combines scalable data streaming and feature-based visualization with novel hardware and software solutions, such as a deep integration of GPU computing. We employ the capabilities of wavelet-based data compression and on-the-fly GPU data decoding and encoding to reduce memory access and bandwidth limitations. Because our approach reduces disk access and CPU-GPU data transfer, it is suitable for the analysis of small-scale turbulence structures on desktop systems which are not equipped with large main memory. To preserve even the finest structures, feature extraction is embedded into the visualization process, based on the direct computation of vector field derivatives and on-the-fly evaluation of gradient tensor-based feature metrics. Our system distinguishes from previous approaches for visualizing turbulent flow fields in that it eases bandwidth and memory limitations throughout the entire visualization pipeline. In particular, the system @BULLET compresses vector data at very high fidelity, @BULLET works on the compressed data up to the GPU, using on-the-fly GPU decompression and rendering, @BULLET enables caching of derived feature volumes via on-the-fly GPU compression, @BULLET provides multi-scale feature visualization via on-the-fly gradient tensor evaluation. </p><p> Our paper is structured in the following way: First, we review previous systems and algorithms for the visualization of large volumetric data sets. We then give an overview of our system, including its internal structuring as well as the basic functionality in a nutshell. Here we aim at giving information about what the system provides and how this is achieved, but we do not answer the question why the particular choices have been made. This question is addressed in the upcoming section, where we motivate our design decisions and discuss tradeoffs involved in making our system practical for visualizing large turbulence simulations. This also involves the demonstration of some advanced features which are made possible by these choices. Finally, we describe the streaming and visualization performance of our system and discuss its preprocessing costs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Previous efforts in large volume visualization can be classified into two major categories: a) Parallelization and b) data compression and outof-core strategies. There is a vast body of literature on parallelization strategies for volume visualization on parallel computer architectures and a comprehensive review is beyond the scope of this work; however , some of the most recent works have addressed volume rendering on both GPU <ref type="bibr" coords="2,334.68,306.69,9.71,8.45" target="#b7">[8,</ref><ref type="bibr" coords="2,346.64,306.69,11.95,8.45" target="#b29"> 30] </ref>and CPU <ref type="bibr" coords="2,395.70,306.69,14.94,8.45" target="#b17">[18] </ref>clusters. A different avenue of research has addressed the visualization of large volumetric data on desktop PCs. These works employ out-ofcore techniques to dynamically load only the required part of a data set into memory, and many employ some form of compression to reduce the immense data volume. Vitter <ref type="bibr" coords="2,405.01,357.03,14.94,8.45" target="#b40">[41] </ref> provides a general overview including detailed analyses of many out-of-core algorithms. The most recent works focussing on the direct rendering of large-scale volume data <ref type="bibr" coords="2,302.31,386.91,9.71,8.45" target="#b5">[6,</ref><ref type="bibr" coords="2,314.27,386.91,11.95,8.45" target="#b13"> 14] </ref>employ an octree of volume bricks. During rendering, the octree is traversed on the GPU and visited nodes are tagged for refinement or coarsening. The tags are read back to the CPU which then updates the GPU working set accordingly. Such approaches allow for on-demand streaming of data and efficient rendering in a single pass, provided that all data required for the current view is available in GPU memory. In turbulent flow fields, however, using a lower-resolution approximation of the velocity data results in a significant distortion of the extracted features and is thus not admissible. Specifically for large flow data, Ellsworth et al. <ref type="bibr" coords="2,385.37,476.58,10.45,8.45" target="#b6">[7] </ref>present a particle-based visualization system that precomputes a large number of particle traces which can then be displayed interactively. In the following, we review the most popular compression options in the context of volume rendering. For a general overview of data compression, we refer to the book by Sayood <ref type="bibr" coords="2,449.72,526.92,13.74,8.45" target="#b33">[34]</ref>. Lossless: Lossless compression typically employs some form of prediction to exploit spatial and temporal redundancy in the data. The prediction remainders are then compressed via any general-purpose compression approach. To the best of our knowledge, all existing work employing lossless compression in the context of volume rendering has addressed only integer-valued data <ref type="bibr" coords="2,430.19,586.69,14.19,8.45" target="#b10">[11,</ref><ref type="bibr" coords="2,447.52,586.69,10.64,8.45" target="#b11"> 12]</ref>. Outside of volume rendering, some fast lossless floating-point compressors exist <ref type="bibr" coords="2,509.06,596.66,9.71,8.45" target="#b1">[2,</ref><ref type="bibr" coords="2,521.29,596.66,10.64,8.45" target="#b26"> 27]</ref>. However, in particular for floating-point data, lossless compression usually achieves only quite modest compression rates. Hardware-supported formats: Some special fixed-rate compression formats such as S3TC are implemented directly by graphics hardware. This means that rendering, including hardware-supported interpolation , is possible directly from the compressed form, thus reducing GPU memory requirements. By adding a second, CPU-based compression stage, the compression rate can be improved <ref type="bibr" coords="2,480.72,676.36,14.19,8.45" target="#b30">[31,</ref><ref type="bibr" coords="2,497.45,676.36,10.64,8.45" target="#b31"> 32]</ref> . However , the fixed-rate first stage allows little or no control over the quality vs. compression rate trade-off, and these formats lack support for floating-point data. Additionally, while decompression is extremely fast, the compression step is usually quite involved. Vector quantization: In vector quantization, a data set is represented by a small codebook of representative values and, for each data point, an index into this codebook. This allows for very fast decoding on the GPU via a single indirection <ref type="bibr" coords="3,157.21,144.92,14.19,8.45" target="#b9">[10,</ref><ref type="bibr" coords="3,175.01,144.92,10.64,8.45" target="#b34"> 35]</ref>. By employing deferred filtering <ref type="bibr" coords="3,63.43,154.88,9.52,8.45" target="#b8">[9]</ref>, hardware-supported texture filtering becomes possible. However, the construction of a good codebook is extremely timeconsuming , and it is difficult to satisfy the very high quality requirements of our application. Transform coding: Transform coding approaches are used in most popular image and video compression schemes, such as the various JPEG and MPEG standards. The basic idea is to express the input data as coefficients to a set of basis functions with the goal of contracting most of the energy into few coefficients, so that most coefficients have very small values. In a following quantization step, these small coefficients are reduced to zero and need not be stored. The remaining coefficients are typically further compressed using an entropy coding scheme such as Huffman or arithmetic coding. The most commonly used transforms are the discrete cosine transform (DCT) and the discrete wavelet transform (DWT), both of which have been applied to volume rendering <ref type="bibr" coords="3,140.84,304.32,14.19,8.45" target="#b27">[28,</ref><ref type="bibr" coords="3,158.75,304.32,10.64,8.45" target="#b44"> 45]</ref>, <ref type="bibr" coords="3,177.03,304.32,14.19,8.45" target="#b14">[15,</ref><ref type="bibr" coords="3,194.95,304.32,11.21,8.45" target="#b15"> 16,</ref><ref type="bibr" coords="3,209.89,304.32,11.21,8.45" target="#b32"> 33,</ref><ref type="bibr" coords="3,224.81,304.32,10.64,8.45" target="#b42"> 43]</ref>. Woodring et al. <ref type="bibr" coords="3,53.95,314.28,14.94,8.45" target="#b43">[44] </ref>analyze the application of JPEG 2000 compression to a large climate simulation. For data with little or no local correlation, Lakshminarasimhan et al. <ref type="bibr" coords="3,127.80,334.21,14.94,8.45" target="#b24">[25] </ref>present an alternative approach based on coefficient reordering and spline fitting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SYSTEM FUNCTIONALITY, ALGORITHMS, AND FEATURES</head><p>Our approach begins with a sequence of 3D turbulent motion fields, each given on a Cartesian grid. In a preprocess, each vector field is partitioned into a set of equally sized bricks. An overlap between adjacent bricks enables proper interpolation at brick boundaries. Every brick is compressed separately and written to disk. The preprocess is outlined in <ref type="figure" coords="3,72.35,425.21,19.81,8.45" target="#fig_0">Fig. 2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Compression Algorithm</head><p>Once the bricked volume representation has been constructed, a wavelet-based scheme is used for compression, including run-length and Huffman encoding of the coefficient stream. We use the GPU compression scheme recently proposed by Treib et al. <ref type="bibr" coords="3,226.40,485.51,13.74,8.45" target="#b38">[39]</ref>, which has been tailored explicitly to support both encoding and decoding on current GPU architectures. The wavelet compression builds upon the fast CUDA implementation of the discrete wavelet transform (DWT) by van der Laan et al. <ref type="bibr" coords="3,99.99,525.36,13.74,8.45" target="#b39">[40]</ref>. The compression algorithm is slightly modified to handle vector data, yet the basic stages remain mostly unchanged. In the first stage, a hierarchical DWT is performed separately on each component of the velocity vectors using the CDF 9/7 wavelet <ref type="bibr" coords="3,213.77,565.21,9.52,8.45" target="#b4">[5]</ref> . The floatingpoint wavelet coefficients C i are quantized into integer values c i via standard scalar dead-zone quantization, i.e., </p><formula>c i = sign(C i ) |C i |/Δ l , </formula><p>where Δ l is the quantization step that is used at level l of the wavelet pyramid. Because the coefficients at coarser scales carry more energy than the coefficients at smaller scales, the quantization steps are decreased with increasing scale, i.e., starting at the finest level l = 0 with a user-defined step size Δ 0 , on subsequent levels the step size is set to </p><formula>Δ l = Δ 0 / 2 l . </formula><p>Here, Δ 0 provides control over the compression rate and reconstruction quality. The quantized wavelet coefficients are finally concatenated into a sequential coefficient stream in scan-line order. A run-length encoder followed by a Huffman encoder convert the coefficient stream into a highly compact form. an arbitrary point, </p><formula>x 0 : u i (x,t) = u i (x 0 ,t) + A i j (x 0 ,t)(x j − x 0 j ) + .... </formula><p> Since A is a second-rank tensor, it has nine components (in three dimensions ) and these contain rich information about the local properties of the flow. The decomposition </p><formula>A i j = S i j + Ω i j , where S i j = 1 2 A i j + A ji , Ω i j = 1 2 A i j − A ji , </formula><p> is commonplace and separates A into its symmetric part (the strainrate tensor S) and its antisymmetric part (the rotation-rate tensor Ω Ω Ω). The tensor S has three real eigenvalues λ 's that in incompressible flow add up to zero, and if they are different (non-degenerate case) the tensor S has three orthogonal eigenvectors that define the principal axes of S. These indicate directions of maximum rate of fluid extension (λ α &gt; 0) and contraction (λ γ &lt; 0), and an intermediate fluid deformation that can be either extending or contracting in the third direction. Ω Ω Ω describes the magnitude and direction of the rate of rotation of fluid elements and is simply related to the vorticity vector ω ω ω = ∇ ∇ ∇ × u. Since the tensor A encodes much information through each of its matrix elements , an analysis of its properties is quite challenging. Therefore, certain scalar quantities that characterize basic properties of A have been proposed and are often analyzed as scalar fields. For example, it has been found convenient to define the following five scalar invariants <ref type="bibr" coords="4,98.00,487.86,9.71,8.45" target="#b2">[3,</ref><ref type="bibr" coords="4,109.95,487.86,10.83,8.45" target="#b28"> 29]</ref>: </p><formula>Q = − 1 2 Trace(A 2 ) = − 1 2 A i j A ji := − 1 2 3 ∑ i=1 3 ∑ j=1 A i j A ji , R = − 1 3 A i j A jk A ki , </formula><formula>Q S = − 1 2 S i j S ji , R S = − 1 3 S i j S jk S ki , V 2 = S i j S ik ω j ω k . </formula><p> Additional commonplace, Galilean invariant vortex definitions involve non-trivial combinations of A, S and Ω Ω Ω, such as the Q Hunt and Δ Chong -criterion <ref type="bibr" coords="4,82.49,599.65,9.71,8.45" target="#b3">[4,</ref><ref type="bibr" coords="4,94.44,599.65,11.21,8.45" target="#b16"> 17,</ref><ref type="bibr" coords="4,107.89,599.65,10.83,8.45" target="#b18"> 19]</ref>: </p><formula>Q Hunt = 1 2 |Ω Ω Ω| 2 − |S| 2 &gt; 0, Δ Chong = Q Hunt 3 3 + det A 2 2 &gt; 0. </formula><p>Further vortex classifications employ additional information from the vorticity, or eigenvalues through an eigendecomposition of symmetric tensors. For example, the λ 2 -criterion <ref type="bibr" coords="4,166.68,665.02,14.94,8.45" target="#b20">[21] </ref>identifies vortex regions by λ 2 &lt; 0, where λ 2 is the second largest eigenvalue of the symmetric tensor S 2 + Ω Ω Ω 2 . Another option is the enstrophy production, which is defined as </p><formula>E = S i j ω i ω j . </formula><p>One striking observation in turbulence research was the preferential vorticity alignment found by Ashurst et al. <ref type="bibr" coords="4,176.22,716.21,9.52,8.45" target="#b0">[1]</ref>. They observed that the most likely alignment of the vorticity vector ω ω ω was with the intermediate eigenvector β β β S , the direction corresponding to the eigenvalue λ β that could be either positive or negative. For a random structureless gradient field, no such preferred alignment would be expected, and on na¨ıvena¨ıve grounds one might have expected the vorticity to align with the most extensive straining direction instead. Therefore, the observations generated sustained interest in the problem of alignment properties of the vorticity field and relationships with features related to the strainrate tensor—e.g. its eigenvectors' directions. For this reason, our system provides mappings of the vector components of ω ω ω (or one of the eigenvectors α S , β S , γ S of the strain-rate tensor) to RGB colors during volume ray-casting. Besides analyzing the small-scale turbulence structures, a substantial amount of research has been devoted to the statistical features of velocity increments in the inertial range <ref type="bibr" coords="4,432.08,355.84,14.19,8.45" target="#b12">[13,</ref><ref type="bibr" coords="4,448.88,355.84,10.64,8.45" target="#b36"> 37]</ref>. In particular, it has been shown that a relationship between velocity increments at scale Δ and coarse-grained (or filtered) velocity gradients˜Agradients˜ gradients˜A = G Δ * A at scale Δ can be established. Here, G Δ is a convolution kernel—usually an averaging box filter—of characteristic scale . To enable a visual multi-scale analysis of turbulence, our system allows simultaneously extracting and visualizing features from filtered velocity fields at different (user-selected) scales. As filtering and differentiation are linear operations, filtering is performed on the velocity vector field instead of the gradient tensor field. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DESIGN DECISIONS AND TRADEOFFS</head><p>We now consider some of the decisions made in the implementation of our system that make it suitable for visualizing large turbulence data. In particular, we want to emphasize the possible tradeoffs that allow the user to choose between highest quality and highest speed. As we will show, despite the careful design of the system with regard to the application-specific requirements, not always can it respond interactively to the user inputs. This is because of the extreme amounts of data to be processed and the complex shaders to be evaluated. However , our results demonstrate a system performance that facilitates an interactive exploration for most of the supported visualization options. The bricked data representation the system builds upon is necessary to keep the chunks of data that are processed at run-time manageable. In addition, the bricked representation has the advantage of enabling view frustum culling, resulting in a considerable reduction of the data to be streamed to the GPU. The integration of occlusion culling is also possible, but the turbulence structures are typically so small and scattered that no significant gain can be expected. We also want to mention that level-of-detail rendering strategies as they are typically employed in volume ray-casting have not been considered, because the continuous transition between multiple scales of turbulence in one image has been determined inappropriate by turbulence researchers. To avoid access to neighboring bricks in tri-linear/tri-cubic data interpolation and gradient computation, a 4-voxel-wide overlap is stored around each brick. Thus, the smaller the bricks, the more additional memory is required to store the overlaps. On the other hand, the larger the bricks, the fewer disk seek operations have to be performed for reading the bricks from disk. Consequently, we make the bricks as large as possible, yet we consider that a certain number of decompressed bricks (at least 4) should fit into GPU memory as a working set. We chose a brick size of 248 3 in our system, so that a brick including the overlap can be stored in a texture of size 256 3 . This results in a memory overhead of about 10%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature Reconstruction</head><p>The visualization system by default reconstructs turbulence features directly from the velocity field during ray-casting. It would also be possible to precompute certain (scalar) feature volumes in a preprocess and to visualize these volumes. However, such an approach is problematic in the current scenario. First, it would cause a significant increase of the overall memory consumption. Second, the system would become inflexible to the extent of the precomputed features, prohibiting an interactive steering of the feature extraction processes. Third, quality losses are introduced by re-sampling a scalar feature volume instead of a direct feature reconstruction. Two examples demonstrating the quality differences are shown in <ref type="figure" coords="5,31.50,232.92,19.95,8.45" target="#fig_2">Fig. 6</ref>. The images clearly reveal that certain fine-scale structures can no longer be reconstructed from the scalar feature volumes. Even though the principal shapes are still maintained, a detailed analysis of the bending, stretching, merging, and separating behavior of the turbulence features is no longer possible.  On the other hand, ray-casting a feature volume can be a viable approach to obtain an overview of the turbulence structures. Therefore, our system supports the construction and storage of scalar feature volumes for fast previewing purposes (see also Section 5). Even though the construction of such a volume on the GPU is straightforward using the system's functionality, this volume might be too large to be stored on the GPU in uncompressed form. The requirement to tackle this problem has significantly steered our selection of the compression scheme to be used in the system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Lossy Compression</head><p>Because of the extreme data volumes to be handled by our system, the reduction of this volume becomes one of the most important requirements . Without any reduction, expensive disk-to-CPU data transfer becomes the major performance bottleneck since only a very small portion of an entire turbulence sequence can be stored in main memory . To meet this requirement, we have embedded a data compression layer into the system. This layer encapsulates a compression scheme that can be used for arbitrarily-sized bricks and, thus, can be integrated seamlessly into the system architecture. In the decision which compression to use, the following aspects have been considered. First of all, it is required that no features will be destroyed due to the compression, and that possible quality losses do not affect the features' shapes significantly. For floating-point data, compression schemes like S3TC and vector quantization <ref type="bibr" coords="5,240.84,706.25,14.94,8.45" target="#b33">[34] </ref>do not adhere to this constraint. Second, the compression rate must be so high that the data can be streamed from disk and decompressed at a rate that keeps pace with the data processing speed. Especially due to this requirement, lossless compression schemes are problematic. In general, lossless schemes, for instance as proposed in <ref type="bibr" coords="5,486.11,63.06,9.71,8.45" target="#b1">[2,</ref><ref type="bibr" coords="5,497.83,63.06,10.64,8.45" target="#b26"> 27]</ref>, can only achieve a rather moderate compression rate. A last consideration arises from the particular requirement of our system to generate scalar feature volumes on-the-fly for the purpose of fast previewing. This functionality goes hand in hand with the possibility to efficiently compress the generated feature volumes on the GPU, so that they can be efficiently streamed to the CPU and buffered in RAM. While the compressed volumes could also be stored on the GPU, the time required to transfer the compressed data between the CPU and the GPU is negligible compared to the compression time. Thus, all generated data is always buffered on the CPU. To support this option, an alternative data flow as illustrated in <ref type="figure" coords="5,483.41,173.81,21.37,8.45" target="#fig_3">Fig. 7</ref>is realized in our system. This rules out compression schemes such as vector quantization, because the construction of the vector codebook in the coding phase can not be performed at sufficient rates in general.  Lossy compression schemes based on the discrete wavelet transform , in combination with coefficient quantization and entropy coding , are well known to achieve very high compression rates at high fidelity <ref type="bibr" coords="5,322.62,371.21,13.74,8.45" target="#b37">[38]</ref>. Compression schemes based on transform coding also have a long tradition in visualization, for instance to reduce memory and bandwidth limitations in volume visualization <ref type="bibr" coords="5,483.39,391.14,14.19,8.45" target="#b15">[16,</ref><ref type="bibr" coords="5,501.01,391.14,11.21,8.45" target="#b32"> 33,</ref><ref type="bibr" coords="5,515.66,391.14,11.21,8.45" target="#b42"> 43,</ref><ref type="bibr" coords="5,530.29,391.14,10.64,8.45" target="#b44"> 45]</ref>. However, only with the possibility to perform the entire compression pipeline on the GPU <ref type="bibr" coords="5,375.15,411.06,16.51,8.45" target="#b38">[39]</ref>—including encoding and decoding—can the full potential of wavelet-based compression be employed for large data visualization. <ref type="figure" coords="5,294.12,564.80,18.96,8.60">Fig. 8</ref>. Rate-distortion curves showing dB (P)SNR vs. bits per voxel for two different turbulence fields. <ref type="figure" coords="5,294.12,705.58,19.84,8.60">Fig. 9</ref>. Graphs showing RMSE vs. quantization step, and maximum error vs. RMSE for two different turbulence fields. RMSE and quantization step are of the same order of magnitude, while the maximum error is consistently about 1 order of magnitude larger than RMSE. </p><p>To assess the compression rate and reconstruction quality of the wavelet-based GPU coder, we have performed tests using two different turbulence simulations, each consisting of time steps of size 1024 3 . On each brick a three-level DWT was performed, and the wavelet coefficients were compressed as described. Rate-distortion curves in (P)SNR vs. bits per voxel (where each voxel contains a 3-component floating-point vector) for both data sets are given in <ref type="figure" coords="6,215.29,112.87,20.51,8.45">Fig. 8</ref> . In addi- tion, <ref type="figure" coords="6,40.83,122.84,20.80,8.45">Fig. 9</ref>plots RMS error vs. quantization step as well as maximum error vs. RMS error. The graphs demonstrate that the user can directly control the compression error by choosing an appropriate quantization step size. The rate-distortion curves demonstrate the high reconstruction quality of the wavelet-based compression. On the other hand, they do not provide an intuitive notion of the visual quality. Therefore, in Figs. 10 and 11, we compare the visual quality of the rendered structures in the compressed motion fields to those in the original fields. For comparison purposes we use different compression rates. Even though it is clear that the compression quality depends on the visualization parameters, such as the transfer function, the selected iso-value, and on the feature that is visualized, a component-wise wavelet transform can very effectively reduce the memory consumption , yet it achieves a very high reconstruction quality. In particular, in the middle images in Figs. 10 and 11 the structures are reproduced at almost no visual difference at a remarkable compression rate of 32:1. Let us finally mention that the selected compression scheme can in principle be extended to also exploit the motion coherence between successive time steps for increasing the compression rate. The basic idea is to not compress every time step separately, but rather to encode the differences between a time step and one or more preceding (or, in some cases, succeeding) time steps. Popular video compression algorithms such as MPEG typically employ block-based motion compensation , and this approach has been applied to volume compression as well <ref type="bibr" coords="6,312.91,102.91,13.74,8.45" target="#b14">[15]</ref> . However, any temporal prediction scheme obviously requires access to one or more other time steps to use as input. If these time steps can not be held in RAM in uncompressed form, then such a prediction necessarily triggers additional decompression steps and thus significantly increases the processing time. In our application, the possible gain in compression rate does not justify the increase in compression/decompression time. Therefore, our system compresses each time step separately. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multi-Scale Analysis</head><p>As we have emphasized in the introduction, one challenging endeavor in turbulence research is the analysis of the shape and evolution of structures at different scales. To enable such an analysis, it is necessary to filter the velocity field using a low-pass filter. A linear convolution filter is used in practice. It can then be instructive to compare the original data with the filtered version, or multiple instances filtered with different radii. Both the initial and the filtered data are made accessible to the shader, and they are ray-cast simultaneously. Many options for combined visualizations are now possible, for example, iso-surfaces for different iso-values and with different colorings (<ref type="figure" coords="6,474.56,292.39,20.50,8.45" target="#fig_1">Fig. 5</ref>(c)), or the conditional visualization of fine features depending on coarse features (<ref type="figure" coords="6,288.56,312.31,23.09,8.45" target="#fig_0">Fig. 12</ref>). Because a large range of scales may contain relevant features, these scales can not be precomputed but must be determined interactively at run-time. Furthermore, the interesting scales are often quite large, requiring filter radii of 20 and more voxels, so that an on-the-fly filtering during rendering is not feasible. The large filter radii also make a separate filtering of each brick impossible, because values from adjacent bricks are required in the convolution. Unfortunately it is also impossible to keep all 26 neighbors of one brick in GPU memory at the same time, such that the bricks required for filtering have to be streamed and accessed sequentially. As a consequence, every brick needs to be loaded from the CPU and decompressed multiple times. To avoid this, we have restricted our system to the execution of separable filters, i.e. filters that can be expressed as 3 successive 1D filters, one along each coordinate axis. In this case, only 3 filtering passes are required, and in each pass only the 2 neighbors along the current filter direction need to be available (as long as the filter radius is not larger than the brick size). In each pass, the bricks are traversed in an order which ensures that each brick needs to be decompressed only once. <ref type="figure" coords="6,325.25,706.25,25.41,8.45">Fig. 13</ref>illustrates this ordering. All intermediate results and the final filtered result are compressed in turn on the GPU and buffered in CPU memory. Consequently, additional losses will occur, besides those which are introduced by the <ref type="figure" coords="7,31.50,128.07,23.46,8.60">Fig. 13</ref>. Brick ordering during separable filtering in x and y dimension (left and right, respectively). The z dimension is analogous. One exemplary working set during each filtering pass is indicated in red. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>encoding </head><p>of the initial vector field. On the other hand, because the data becomes smoother and smoother after each filtering pass, at the same compression rate ever better reconstruction quality can be achieved. In all of our examples, the additional losses were only very minor, and noticeable differences between single-pass and multi-pass filtering on the compressed vector field could hardly be observed. This is demonstrated in <ref type="figure" coords="7,68.57,229.96,26.27,8.45" target="#fig_7">Fig. 14</ref>for a particular feature iso-surface in the isotropic turbulence data set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PERFORMANCE</head><p>In this section, we evaluate the performance of all components of our system and provide accumulated timings for the most time-consuming operations. All presented timings were performed on a desktop PC with an Intel Xeon E5520 CPU (quad core, 2266 MHz), 12 GB of DDR3-1066 RAM, and an NVIDIA GeForce GTX 580 graphics card with 1.5 GB of video memory. We used a standard hard disk providing a sustained data rate of about 100 MB/s. Our statistics are based on the two terascale turbulence simulations referenced in the introduction and shown in <ref type="figure" coords="7,195.44,506.89,20.59,8.45">Fig. 1</ref>. Each comprises one thousand turbulent motion fields of size 1024 3 . The vector samples are stored as 3 floating-point values. Both data sets were compressed to 3.0 bpv at a compression rate of 32:1. The compression rates for individual bricks ranged from 53:1 to 22:1, depending on their content. The performance of all operations in our system scales roughly linearly in the spatial resolution of the data, so the system performance for data sets of different sizes can be easily extrapolated from the numbers listed below. Although preprocessing time is not as important as visualization time, it is still significant for the practical visualization of very large data sets. On our test system, preprocessing takes about 3 minutes per time step. The majority of this time is spent reading the uncompressed data from disk; the compression of one time step—once stored in CPU memory—takes only about 10 seconds. This time includes the upload of the raw data to the GPU, the compression on the GPU, and the download of the compressed data to the CPU. <ref type="figure" coords="7,41.46,676.36,28.92,8.45" target="#tab_1">Table 1</ref> summarizes typical timings for visualizing one (compressed ) brick of size 256 3 and one (compressed) time step consisting of 5 3 bricks. We give separate times for data streaming and compression , performing data operations on the GPU, and rendering. For comparison , the statistics also include timings for an uncompressed data set. Rendering was always to a 1024 × 1024 viewport. The entire volume was shown so that view-frustum culling did not have any effect— in zoomed-in views where some bricks can be culled, decompression and ray-casting are faster accordingly. Furthermore, high transparency was assigned to the structures to eliminate any effects of early ray termination . Which feature metric was used had no significant effect on the performance. Since the visualization performance for different time steps and for the two different data sets was very similar, they are not listed separately in the table. One can see that the upload and decompression of all bricks of one time step takes 3.0 seconds. This is slightly faster than the upload of the uncompressed data, which takes 3.2 seconds (at a throughput of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>reason lies </head><p> in the extremely complex shaders on the velocity gradient tensor, which are evaluated at every sample point to evaluate the selected feature metrics. As an alternative, a preview-quality visualization of a precomputed scalar feature volume using tri-linear interpolation takes about 1.5 seconds. The computation and compression of a scalar feature volume from a compressed vector field requires about 9.3 seconds. If the whole feature volume can be stored on the GPU, e.g. on a Quadro or Tesla card with 4-6 GB of video memory, rendering takes only 0.2 seconds. Since in this case the feature volume does not need to be compressed, it can be generated on the GPU in about 5.1 seconds. A very expensive operation is filtering of the 3D velocity field. This operation requires the entire data set to be 3 times uploaded to the GPU, decompressed, filtered along one dimension, and compressed. Even though the raw compute time to filter the data on the GPU is only 0.3 seconds per filtering pass for a filter with a support of 51, it takes about 40 seconds until the result is available in CPU memory . This time is vastly dominated by the GPU decompression, and in particular the GPU compression of the intermediate and final results . Compression is about 3 times as expensive as decompression because the run-length and Huffman encoders are more complex than the respective decoders <ref type="bibr" coords="8,107.33,664.30,13.74,8.45" target="#b38">[39]</ref>. In particular, Huffman encoding requires a round-trip to the CPU, where the Huffman table is constructed. Table 2 summarizes the startup and per-frame time required for some common scenarios as outlined above. These times do not include the times required to load the data from disk, because disk access is performed concurrently with rendering and processing and can usually be hidden. From the measured timing statistics it becomes clear that for the given data sets our system can not achieve fully interactive display rates. The reason is that the system was developed with the intent of visualizing extremely large turbulence data sets, which require complex shaders for feature extraction including high-quality interpolation . This is necessary to provide the significant amounts of fine detail at the smallest scale. However, the memory-efficient design of our system makes it well suited for implementation on desktop machines. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we have presented a system for the exploration of very large and time-dependent turbulence data on desktop PCs. The interactive exploration of terascale data with limited available memory and bandwidth is made possible by the integration of a wavelet-based compression scheme. A fast GPU implementation of both compression and decompression provides the necessary throughput for fast streaming of velocity data and the efficient storage of derived data. We have demonstrated that the very high quality of the compression ensures the faithful preservation of turbulence features. A preview mode in the renderer based on precomputed feature volumes allows the interactive navigation to features of interest at only slightly reduced quality. On the other hand, the high-quality rendering of time-dependent image sequences is accelerated by an order of magnitude compared to the use of uncompressed data. By using our system, a turbulence researcher can interactively explore terascale data sets and tune visualization parameters. While it is still too early to report on application-specific results, a first trend has already been discovered with the help of our system which had not been observed before: In multi-scale visualizations such as <ref type="figure" coords="8,495.42,726.17,23.48,8.45" target="#fig_0">Fig. 12</ref>, the large-scale vortices contain small-scale vortices that appear to form helical bundles within the large-scale vortices. They appear to wrap around the large-scale ones. These visualizations suggest new statistical measures such as the alignment angle between large-and smallscale vorticity, to be implemented in future research as a result of the present observations. While our current system is tailored for desktop PC systems, we believe that many of the presented techniques also have applications in supercomputing. When moving to the petascale, computing will enable numerical simulations at unprecedented resolution and complexity , going beyond even the present turbulence data sets. Although the raw compute power of separate visualization computers keeps pace with those of supercomputers, bandwidth and memory issues in networking and file storage significantly restrict the reachable limits. For visualizing the peta-or even exabytes of data we will be confronted with, writing the raw data to disk or moving them across the network has to be avoided. A promising direction for future research is the integration of a compression layer similar to the one used in our system, which could alleviate bandwidth limitations between compute nodes and the visualization system. This could allow the immediate visualization of data too large even to be stored on disk. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,31.50,111.88,107.60,8.60"><head>Fig. 2. </head><figDesc>Fig. 2. Preprocessing pipeline. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,22.50,194.74,513.00,9.33;4,22.50,203.38,342.99,10.36;4,365.49,204.20,170.00,9.40"><head>Fig. 5. </head><figDesc>Fig. 5. Turbulence visualizations. (a) Direct volume rendering of E. (b) Two semi-transparent iso-surfaces of Q Hunt . (c) Fine-scale iso-surfaces (gray) and coarse-scale iso-surfaces colored by vorticity direction. (d) Direct volume rendering of λ 2 ; negative values are red, positive values green. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,31.50,440.52,250.38,8.60;5,31.50,449.98,174.64,8.60"><head>Fig. 6. </head><figDesc>Fig. 6. Features reconstructed from the turbulent motion field (left) and from a precomputed scalar feature volume (right). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,294.12,313.53,250.38,8.60;5,294.12,323.00,110.55,8.60"><head>Fig. 7. </head><figDesc> Fig. 7. Alternative data flows at run-time support construction and reuse of derived feature volumes. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,22.50,391.95,250.38,9.33;6,22.50,401.42,250.37,8.60;6,22.50,410.88,250.38,8.60;6,22.50,420.35,74.85,8.60"><head>Fig. 10. </head><figDesc>Fig. 10. Visual quality comparison for an iso-surface in Q Hunt in the isotropic turbulence data set. Structures are reconstructed from the original vector field (top), and a compressed version at 3.0 bpv (middle) and 1.3 bpv (bottom). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="6,22.50,666.66,250.38,9.41;6,22.50,676.13,250.37,8.60;6,22.50,685.59,250.38,8.60;6,22.50,695.06,31.89,8.60"><head>Fig. 11. </head><figDesc>Fig. 11. Visual quality comparison for an iso-surface in R S in the MHD turbulence data set. Structures are reconstructed from the original vector field (top), and a compressed version at 3.0 bpv (middle) and 1.3 bpv (bottom). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,285.12,488.34,250.37,8.60;6,285.12,497.80,250.37,8.60;6,285.12,507.27,129.34,8.60"><head>Fig. 12. </head><figDesc>Fig. 12. Multi-scale turbulence analysis in a " focus+context " manner. Iso-surfaces in the fine-scale data (red) are extracted only within isosurfaces of the coarse-scale version. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="7,31.50,341.27,34.36,10.36;7,65.86,342.09,216.02,9.40;7,31.50,351.56,250.37,8.60;7,31.50,361.02,250.38,8.60;7,31.50,370.49,250.38,8.60;7,31.50,379.95,250.38,8.60;7,31.50,389.42,32.01,8.60"><head>Fig. 14. </head><figDesc>Fig. 14. λ 2 iso-surface in an isotropic turbulence simulation. Left: A 3D smoothing filter with support 25 was applied to the compressed vector field in one pass. Right: The same filter as before was used, but now the filter was separated and filtering was performed in 3 passes. After each pass, the intermediate results were compressed and buffered on the CPU. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="8,22.50,403.15,512.99,8.60;8,22.50,412.23,513.00,8.99;8,22.50,422.08,513.00,10.18;8,22.50,431.54,38.86,8.60"><head>Fig. 15. </head><figDesc>Fig. 15. Visualizations of forced isotropic turbulence. (a) Direct volume rendering of the velocity magnitude in the whole data set. Images (b-f) show a closeup on a 256 3 subregion at the center of the simulation domain. (b) Velocity magnitude. (c) Vorticity magnitude. Images (d-f) show iso-surfaces of invariants of the velocity gradient tensor (from left to right: Q Hunt , Q Ω , Q S ). In all three images, iso-surfaces of a value equal to 1.0E-2 are shown. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true" coords="7,294.12,133.36,250.39,234.70"><figDesc coords="7,294.12,133.36,250.39,8.60;7,294.12,142.82,122.14,8.60">Table 1. Timings for individual system components. Where appropriate, values are given as min–avg–max.</figDesc><table coords="7,300.10,160.07,240.17,207.99">Data streaming 
per brick per time step 
Read from disk 
35–60–88 ms 
4.2 s 
Upload &amp; decompress (vector-valued) 
18–32–39 ms 
3.0 s 
Compress &amp; download (vector-valued) 48–105–230 ms 
10.3 s 
Upload &amp; decompress (scalar) 
7–14–16 ms 
1.3 s 
Compress &amp; download (scalar) 
23–43–56 ms 
4.2 s 

GPU processing 
per brick per time step 
Compute metric 
28 ms 
2.1 s 
Filter (per pass) 
3.9 ms 
0.3 s 

Rendering 
per brick per time step 
Ray-cast, on-the-fly feature, tri-linear 
6–25–35 ms 
2.1 s 
Ray-cast, on-the-fly feature, tri-cubic 
27–150–205 ms 
12.1 s 
Ray-cast, multi-scale, tri-cubic 
54–305–415 ms 
24.4 s 
Ray-cast, precomp. feature, tri-linear 
0.8–2.3–3.9 ms 
0.2 s 
Ray-cast, precomp. feature, tri-cubic 
1.7–6.5–10 ms 
0.6 s 

Data streaming (uncompressed) 
per brick per time step 
Read from disk 
1.9 s 
2.3 min 
Upload or download (vector-valued) 
34 ms 
3.2 s 
Upload or download (scalar) 
11 ms 
1.1 s 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true" coords="7,303.33,374.54,231.95,59.04"><figDesc coords="7,319.88,374.54,198.86,8.60">Table 2. Aggregate timings for some common scenarios.</figDesc><table coords="7,303.33,387.68,231.95,45.90">Scenario 
startup per frame 
Preview rendering (precomp. feature, tri-linear) 
9.3 s 
1.5 s 
Standard rendering (on-the-fly feature, tri-linear) 
0.0 s 
4.9 s 
HQ rendering (on-the-fly feature, tri-cubic) 
0.0 s 
15.1 s 
HQ rendering w/ multi-scale analysis 
40.8 s 
29.8 s 

</table></figure>

			<note place="foot" n="3">.2 Visualization Algorithm For visualizing the 3D vector field, we use GPU ray-casting on the bricked volume representation [24]. At every sample point along a ray, one or multiple scalar features are derived from the velocity gradient Fig. 3. Basic system data flow at run-time. tensor (see Section 3.3), and the respective values are mapped to color and opacity. The velocity gradient tensor is computed on-the-fly via central differences between interpolated velocity values. The system supports tri-linear interpolation for fast previewing purposes and tricubic interpolation [36] for high-quality visualization. The visual difference between tri-linear and tri-cubic interpolation is demonstrated in Fig. 4. For shading purposes, gradients are approximated locally by central differences on six additional feature samples. The bricks are traversed on the CPU in front-to-back order. If the compressed representation of the current brick is not residing in CPU memory, it is loaded from disk and cached in RAM using a LRU strategy . After all data for the current time step has been loaded, the CPU starts prefetching subsequent time steps asynchronously. The brick is then streamed to the GPU, where a CUDA kernel is executed to decompress the data and store it in texture memory. Our system leverages GPU texture memory to take advantage of hardware-supported texture filtering. Streaming to the GPU works asynchronously, meaning that the transmission stalls neither the CPU nor the GPU. Once the data has been decompressed, a CUDA ray-casting kernel is launched. It invokes one thread for every pixel covered by the screen-aligned rectangle enclosing the projected vertices of the brick&apos;s bounding box. Each thread first determines if the respective view ray intersects the bounding box and terminates if no hit was detected. Otherwise , the current frame buffer content at the pixel position is read, and the brick data is re-sampled along the ray to obtain the color and opacity contribution to be accumulated with the current values. Early ray termination is performed whenever the opacity has reached a value of 0.99. Fig. 3 illustrates the basic system data flow at run-time. Based on a set of basic rendering modalities, i.e., direct volume rendering (DVR) including iso-surface rendering and scale-invariant volume rendering [23], our system supports a number of different visualization options, for example, the simultaneous rendering of isosurfaces of multiple turbulence features, or a combination of different techniques such as DVR and iso-surface rendering. Furthermore, a comparative visualization of the same feature at different scales is supported by enabling simultaneous operations on the initial and filtered data (see Section 4.3). By incorporating shader dependencies, the visualization of features can be made dependent on the existence or properties of other features. Some examples of different visualization options are shown in Fig. 1 and Fig. 5. Fig. 4. Comparison of tri-linear (left) vs. tri-cubic (right) filtering when rendering iso-surfaces. With tri-linear interpolation, the silhouettes of high-frequent iso-surfaces are poorly resolved. 3.3 Turbulence Features In our system, turbulence features are derived from the velocity gradient tensor. The gradient fields of fluid velocity provide a rich characterization of the local quantitative and qualitative behavior of flows, which is evident from the linear approximation in the neighborhood of</note>

			<note place="foot" n="4">.2 GB/s over PCI-E). It has to be mentioned, however, that the decompression on the GPU blocks the GPU so that no other tasks can be performed. When uploading uncompressed data, the data transfer could be performed in parallel with other GPU tasks, such as rendering . Thus, operations on uncompressed data are usually slightly faster than the operations on the compressed data, but only if the data is already available in CPU memory. This can not be assumed in general , e.g., when stepping through multiple time steps, or when multiple (e.g. filtered) volumes are required simultaneously (see Sections 3.2 and 4.3). Whenever disk access becomes necessary, working on the compressed data becomes significantly faster. Reading a single compressed time step from disk takes only about 4.2 s. Additionally, reading can be performed concurrently with decompression and rendering, and, thus, it can usually be hidden completely. In contrast, reading an uncompressed time step from disk takes about 2.3 minutes. Our display rates can not be compared to those reported for raycasting of large scalar fields [6, 14], even though volume ray-casting on the bricked velocity field representation is used. This is because a) classical volume ray-casting systems typically make use of levelof-detail rendering, which is not admissible in our application, and b) exploit empty space skipping, which has no effect in our scenario where the data sets do not contain empty space. It is also worth mentioning that much more complex shaders are executed by our system for feature reconstruction. In our case, high-quality visualization using on-the-fly feature extraction and tri-cubic interpolation takes about 15.1 seconds, of which only 3 seconds are required for decompressing the velocity field and 12.1 seconds are required for ray-casting. The</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p> This publication is based on work supported by Award No. UK- C0020, made by King Abdullah University of Science and Technology (KAUST). </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="9,49.76,329.87,232.12,7.51;9,49.76,339.33,232.11,7.51;9,49.76,348.64,155.39,7.66"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Alignment of vorticity and scalar gradient with the strain rate in simulated Navier-Stokes turbulence</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ashurst</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kerstein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kerr</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Gibson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of Fluids</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2343" to="2353" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,358.26,232.12,7.51;9,49.76,367.57,232.12,7.66;9,49.76,377.19,32.76,7.51"  xml:id="b1">
	<monogr>
		<title level="m" type="main">FPC: A high-speed compressor for double-precision floating-point data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Burtscher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Ratanaworabhan</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="18" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,386.66,232.13,7.51;9,49.76,395.97,201.67,7.66"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Exact solution of a restricted Euler equation for the velocity gradient tensor</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">J</forename>
				<surname>Cantwell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of Fluids, A</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="782" to="793" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,405.58,232.12,7.51;9,49.76,414.90,219.40,7.66"  xml:id="b3">
	<analytic>
		<title level="a" type="main">A general classification of three-dimensional flow fields</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">S</forename>
				<surname>Chong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Perry</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">J</forename>
				<surname>Cantwell</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of Fluids</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="765" to="777" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,424.51,232.12,7.51;9,49.76,433.83,232.12,7.66;9,49.76,443.44,76.14,7.51"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Biorthogonal bases of compactly supported wavelets</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Daubechies</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">C</forename>
				<surname>Feauveau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5 3</biblScope>
			<biblScope unit="page" from="485" to="560" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,452.91,232.12,7.51;9,49.76,462.22,232.12,7.66;9,49.76,471.69,200.29,7.66"  xml:id="b5">
	<analytic>
		<title level="a" type="main">GigaVoxels: Rayguided streaming for efficient and detailed voxel rendering</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Crassin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Neyret</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lefebvre</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Eisemann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIG- GRAPH Interactive 3D Graphics and Games (I3D)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,481.30,232.12,7.51;9,49.76,490.62,182.47,7.66"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Interactive terascale particle visualization</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Ellsworth</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Green</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Moran</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="353" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,500.23,232.12,7.51;9,49.76,509.70,232.12,7.51;9,49.76,519.01,186.94,7.66"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Large data visualization on distributed memory multi-GPU clusters</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Fogal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Childs</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Shankar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Krüger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">D</forename>
				<surname>Bergeron</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Hatcher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Graphics (HPG)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,528.63,232.12,7.51;9,49.76,537.94,232.12,7.66;9,49.76,547.40,133.20,7.66"  xml:id="b8">
	<analytic>
		<title level="a" type="main">High-quality rendering of compressed volume data formats</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Fout</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Akiba</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">E</forename>
				<surname>Lefohn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kniss</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EG/IEEE VGTC Visualization (EuroVis)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="77" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,557.02,232.12,7.51;9,49.76,566.33,228.42,7.66"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Time-varying, multivariate volume data reduction</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Fout</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ahrens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Applied Computing</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1224" to="1230" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,575.95,232.12,7.51;9,49.76,585.26,160.79,7.66"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Lossless compression of volume data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">E</forename>
				<surname>Fowler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Volume Visualization (VVS)</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,594.88,232.12,7.51;9,49.76,604.19,232.12,7.66;9,49.76,613.66,137.98,7.66"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequential data compression of very large data in volume rendering</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Fraedrich</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bauer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Stamminger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision, Modeling and Visualization (VMV)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,623.12,201.36,7.66"  xml:id="b12">
	<monogr>
		<title level="m" type="main">Turbulence, the legacy of A.N. Kolmogorov</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<surname>Frisch</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,632.74,232.12,7.51;9,49.76,642.20,232.13,7.51;9,49.76,651.52,214.79,7.66"  xml:id="b13">
	<monogr>
		<title level="m" type="main">A single-pass GPU ray casting framework for interactive out-of-core rendering of massive volumetric datasets. The Visual Computer</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Gobbetti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Marton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Iglesias Guitián</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7" to="9797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,661.13,232.12,7.51;9,49.76,670.44,232.12,7.66"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Real-time decompression and visualization of animated volume data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Guthe</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Straßer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="349" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,680.06,232.12,7.51;9,49.76,689.37,225.78,7.66"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Interactive rendering of large volume data sets</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Guthe</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Wand</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gonser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Straßer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,698.84,232.12,7.66;9,49.76,708.45,36.74,7.51"  xml:id="b16">
	<analytic>
		<title level="a" type="main">An objective definition of a vortex</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Haller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">525</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,49.76,717.92,232.13,7.51;9,49.76,727.23,232.12,7.66;9,49.76,736.70,117.62,7.66"  xml:id="b17">
	<analytic>
		<title level="a" type="main">MPI-hybrid parallelism for volume rendering on large, multi-core systems</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Howison</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">W</forename>
				<surname>Bethel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Childs</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In EG Parallel Graphics and Visualization</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,53.81,232.12,7.51;9,312.38,63.12,224.35,7.66"  xml:id="b18">
	<monogr>
		<title level="m" type="main">Eddies, streams, and convergence zones in turbulent flows. Centre for Turbulence Research</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hunt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Wray</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Moin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page">88</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,72.74,232.12,7.51;9,312.38,82.05,232.12,7.66;9,312.38,91.52,105.24,7.66"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Study of high-Reynolds number isotropic turbulence by direct numerical simulation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ishihara</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Gotoh</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kaneda</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="165" to="180" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,100.98,232.12,7.66;9,312.38,110.45,91.08,7.66"  xml:id="b20">
	<analytic>
		<title level="a" type="main">On the identification of a vortex</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Jeong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Hussain</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="69" to="94" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,120.06,232.13,7.51;9,312.38,129.38,221.85,7.66"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Applications of holography in fluid mechanics and particle dynamics</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Katz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Sheng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="531" to="555" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,138.84,232.12,7.66;9,312.38,148.45,76.80,7.51"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Scale-invariant volume rendering</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kraus</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,157.91,232.12,7.51;9,312.38,167.23,211.31,7.66"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Acceleration techniques for GPU-based volume rendering</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Krüger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="287" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,176.84,232.12,7.51;9,312.38,186.31,232.12,7.51;9,312.38,195.62,232.12,7.66;9,312.38,205.08,180.15,7.66"  xml:id="b24">
	<analytic>
		<title level="a" type="main">Compressing the incompressible with ISA- BELA: In-situ reduction of spatio-temporal data</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lakshminarasimhan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Shah</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Ethier</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Klasky</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Latham</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Ross</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Samatova</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel and Distributed Computing (Euro-Par)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="366" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,214.70,232.12,7.51;9,312.38,224.17,232.12,7.51;9,312.38,233.63,232.12,7.51;9,312.38,242.94,117.39,7.66"  xml:id="b25">
	<analytic>
		<title level="a" type="main">A public turbulence database cluster and applications to study Lagrangian evolution of velocity increments in turbulence</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Perlman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Wan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Yang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Meneveau</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Burns</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Szalay</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Eyink</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Turbulence</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,252.56,232.13,7.51;9,312.38,261.87,232.12,7.66;9,312.38,271.34,120.43,7.66"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Fast and efficient compression of floatingpoint data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Lindstrom</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Isenburg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization )</title>
		<meeting>. Visualization )</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1245" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,280.95,232.12,7.51;9,312.38,290.27,232.12,7.66;9,312.38,299.88,3.99,7.51"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Texture hardware assisted rendering of time-varying volume data</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Lum</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Clyne</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,309.35,232.12,7.51;9,312.38,318.66,232.12,7.66;9,312.38,328.28,74.82,7.51"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Dynamics of the velocity gradient tensor invariants in isotropic turbulence</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Martin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ooi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">S</forename>
				<surname>Chong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Soria</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics of Fluids</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2336" to="2346" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,337.74,232.12,7.51;9,312.38,347.05,232.12,7.66;9,312.38,356.67,84.11,7.51"  xml:id="b29">
	<analytic>
		<title level="a" type="main">Sort-first parallel volume rendering</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Moloney</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ament</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weiskopf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Möller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8 2</biblScope>
			<biblScope unit="page" from="1164" to="1177" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,366.13,232.12,7.51;9,312.38,375.45,232.13,7.66;9,312.38,384.91,198.01,7.66"  xml:id="b30">
	<analytic>
		<title level="a" type="main">Two-stage compression for fast volume rendering of time-varying scalar data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Nagayasu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Ino</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Hagihara</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics and Interactive Techniques (GRAPHITE)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="275" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,394.53,232.12,7.51;9,312.38,403.84,232.12,7.66;9,312.38,413.31,117.87,7.66"  xml:id="b31">
	<analytic>
		<title level="a" type="main">A decompression pipeline for accelerating out-of-core volume rendering of time-varying data</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Nagayasu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Ino</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Hagihara</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3 2</biblScope>
			<biblScope unit="page" from="350" to="362" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,422.92,232.12,7.51;9,312.38,432.24,232.12,7.66;9,312.38,441.85,3.99,7.51"  xml:id="b32">
	<analytic>
		<title level="a" type="main">Rapid high quality compression of volume data for visualization</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">G</forename>
				<surname>Nguyen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Saupe</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="49" to="57" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,451.16,224.25,7.66"  xml:id="b33">
	<monogr>
		<title level="m" type="main">Introduction to Data Compression</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Sayood</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>3rd. edition</note>
</biblStruct>

<biblStruct coords="9,312.38,460.78,232.12,7.51;9,312.38,470.09,152.16,7.66"  xml:id="b34">
	<analytic>
		<title level="a" type="main">Compression domain volume rendering</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schneider</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="293" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,479.56,232.12,7.66;9,312.38,489.02,104.92,7.66"  xml:id="b35">
	<analytic>
		<title level="a" type="main">Fast third-order texture filtering</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Sigg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hadwiger</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GPU Gems 2</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="313" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,498.64,232.12,7.51;9,312.38,507.95,190.03,7.66"  xml:id="b36">
	<analytic>
		<title level="a" type="main">The phenomenology of small-scale turbulence</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Sreenivasan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Antonia</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="435" to="472" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,517.42,232.12,7.66;9,312.38,526.88,154.09,7.66"  xml:id="b37">
	<monogr>
		<title level="m" type="main">JPEG 2000: Image Compression Fundamentals, Standards and Practice</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">S</forename>
				<surname>Taubman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">W</forename>
				<surname>Marcellin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,536.50,232.12,7.51;9,312.39,545.81,232.12,7.66;9,312.39,555.28,107.58,7.66"  xml:id="b38">
	<analytic>
		<title level="a" type="main">Interactive editing of gigasample terrain fields</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Treib</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Reichl</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Auer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics )</title>
		<meeting>. Eurographics )</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="383" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,564.89,232.12,7.51;9,312.39,574.21,232.12,7.66;9,312.39,583.67,143.51,7.66"  xml:id="b39">
	<analytic>
		<title level="a" type="main">Accelerating wavelet lifting on graphics hardware using CUDA</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">J</forename>
				<surname>Van Der Laan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Jalba</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">B T M</forename>
				<surname>Roerdink</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Parallel and Distributed Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1 3</biblScope>
			<biblScope unit="page" from="132" to="146" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.39,593.29,232.12,7.51;9,312.39,602.60,222.33,7.66"  xml:id="b40">
	<analytic>
		<title level="a" type="main">External memory algorithms and data structures: Dealing with massive data</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Vitter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2 2</biblScope>
			<biblScope unit="page" from="209" to="271" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.39,612.22,232.12,7.51;9,312.39,621.53,232.11,7.66;9,312.39,631.15,3.99,7.51"  xml:id="b41">
	<analytic>
		<title level="a" type="main">Measurement of the velocity gradient tensor in turbulent flows</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Wallace</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Vukoslavcevic</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="157" to="181" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.39,640.61,232.12,7.51;9,312.39,649.92,168.76,7.66"  xml:id="b42">
	<analytic>
		<title level="a" type="main">A multiresolution framework for volume rendering</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Westermann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Volume Visualization (VVS)</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.39,659.54,232.12,7.51;9,312.39,669.01,232.12,7.51;9,312.39,678.31,232.11,7.67;9,312.38,687.77,154.36,7.66"  xml:id="b43">
	<analytic>
		<title level="a" type="main">Revisiting wavelet compression for large-scale climate data using JPEG 2000 and ensuring data precision</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Woodring</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Mniszewski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Brislawn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Demarle</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ahrens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Large-Scale Data Analysis and Visualization (LDAV)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,697.39,232.12,7.51;9,312.38,706.70,232.12,7.66;9,312.38,716.32,32.76,7.51"  xml:id="b44">
	<analytic>
		<title level="a" type="main">Volume rendering of DCT-based compressed 3D scalar data</title>
		<author>
			<persName>
				<forename type="first">B.-L</forename>
				<surname>Yeo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Liu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T. Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29" to="43" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
