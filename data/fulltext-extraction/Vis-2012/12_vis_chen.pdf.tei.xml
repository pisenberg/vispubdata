<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Jian</forename>
								<surname>Chen</surname>
								<roleName>Member, Ieee</roleName>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Haipeng</forename>
								<surname>Cai</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Alexander</forename>
								<forename type="middle">P</forename>
								<surname>Auchus</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">David</forename>
								<forename type="middle">H</forename>
								<surname>Laidlaw</surname>
								<roleName>Senior Member, Ieee</roleName>
							</persName>
						</author>
						<title level="a" type="main">Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent advances in display technologies for scientific visualization have allowed once exotic and expensive techniques to become so inexpensive , accessible, and lightweight that they can be used directly in scientific research. Visualization researchers have increasingly been  using advanced displays to build applications and toolkits in three dimensions (3D) using a variety of techniques <ref type="bibr" coords="1,459.01,575.67,13.73,8.12" target="#b24">[25]</ref>. Our collaborators in brain sciences are also excited about making use of such displays in data analysis (<ref type="figure" coords="1,357.75,595.60,20.11,8.12">Fig. 1</ref>). However, the DMRI data are often highly dense, imposing greater visualization challenges to produce legible visualizations . Nevertheless, usability studies are necessary for visualizations to reach their full potential; guidelines are needed concerning the added value or appropriateness of alternative solutions that will lead to more fundamental insights into why a particular solution is effective <ref type="bibr" coords="1,327.15,655.38,13.74,8.12" target="#b22">[23]</ref>. Brain researchers are using DMRI techniques to study human brain structure in pathological conditions, such as stroke and Alzheimer's disease. DMRI is a MRI technique that measures the directional dependence of motion of water molecules in tissue. Experimental evidence has shown that water diffusion is anisotropic in organized tissues , such as white matter and muscle, and that reconstructing the orientation and curvature of white matter can provide detailed information about pathways. The curves (or fibers) are portrayed graphically using streamline algorithms or glyphs such as hyperstreamlines initialized at seed points to show fiber tracts. Tracts following similar directions are called fiber bundles <ref type="bibr" coords="2,128.25,73.22,13.73,8.12" target="#b37">[38]</ref>. Displaying the fiber tracts as tubes is a popular way to visualize DMRI data. Given the advances in image capturing and processing techniques, we can display human brain features at millimeter scales, making the visualization highly dense, where a whole-brain tractography can have about ten thousand tubes within the volume of a human head. Numerous studies have found benefits in using large stereoscopic displays. Most would agree that large displays lead to fundamentally different user experiences <ref type="bibr" coords="2,120.55,153.31,9.50,8.12" target="#b6">[7]</ref>. Some have reported benefits in task completion time when using large displays and have suggested that people tend to use more egocentric navigation strategies on large displays and hence improve their task performance <ref type="bibr" coords="2,206.01,183.20,13.73,8.12" target="#b41">[42]</ref>. This is true even when a semi-immersive display with small field-of-view (FOV) is used for tasks requiring mental rotation. Psychophysics studies also suggested that bigger is better when the amount of information is the same, because visual acuity increases with distance through the socalled Aubert-Forster law <ref type="bibr" coords="2,118.40,233.02,9.52,8.12" target="#b5">[6]</ref>. The law states that " objectively small objects can be distinguished as two at greater distances from the fovea than objectively larger objects subtending the same visual angle " (page 471 in <ref type="bibr" coords="2,51.79,262.90,13.45,8.12" target="#b34">[35]</ref> ). These interesting results suggested that we should always choose large displays. The overarching objective of our work is to systematically understand the relationships between display characteristics and dense data visualization. The present study is the first to study dense streamtube visualizations on size and viewing distance tradeoffs and the uses of stereopsis to understand whether, if we equalize the retinal images between conditions, we need to have a large display. Our work is motivated by the visual complexity of the streamtubes brain researchers use in answering their scientific questions. We sampled every voxel of a DMRI capture from a normal person, yielding tractography with about ten thousand dense lines rendered using tubes and displayed under two monitors: a small 24 ′′ and a large 72 ′′ displays with or without stereo (<ref type="figure" coords="2,50.06,392.80,19.70,8.13" target="#fig_0">Fig. 2</ref>). The retinal images were kept similar in size between conditions, at least between the large and small displays under the same mono/stereo conditions by carefully arranging FOV and viewing distance. Participants could rotate the data during the experiment. The evaluation covered major and representative fiber bundles in the brain regions suggested by neurologists; the metrics for user task performance were accuracy, task completion time, and subjective comments in post-study interviews. Our data were carefully selected by computer scientists and brain researchers working together. This paper contributes to the growing literature on design and evaluation of scientific visualization using large displays. It describes new results in which experimental evidence on display characteristics was systematically collected, and discusses how to explore this evidence to examine human task performance and guide display choices based on stereo and size when the retinal images are the same. This paper also contributes to experimental task collection for diffusion MRI studies, as we have made the datasets publicly accessible for benchmarking future experimental studies <ref type="bibr" coords="2,122.28,562.96,9.52,8.12" target="#b7">[8]</ref> . In addition, applying these results appropriately to design can also increase the usefulness of high-impact large-display applications in practical scientific visualization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK</head><p>Many people have addressed, with quantitative or anecdotal advice, how best to use displays for a variety of cognitive and user performance benefits in 3D <ref type="bibr" coords="2,101.88,636.70,9.51,8.12" target="#b6">[7]</ref> . In general, it is believed that when the complexity of 3D data increases, stereoscopic display often provides better insight into the datasets. A major benefit of stereoscopy is binocular disparity that provides a better depth awareness. For example, Ware and Franck studied stereo, interaction, and motion in a network graph data visualization <ref type="bibr" coords="2,89.69,686.52,13.74,8.12" target="#b45">[46]</ref>. A stereo display was found to be 1.6 times more accurate than a two-dimensional (2D) display in detecting paths of length two through the complex structures, and stereo combined with head-coupled motion produced the best results. In their visualization comparison, the graph sizes ranged from 24 to 132 nodes with 32 to 176 arcs where participants could still see the structure clearly. </p><p> In the present study, where the number of tubes used could reach thousands , we expected some improvement of stereo over 2D but perhaps not as much as in Ware and Franck's study <ref type="bibr" coords="2,440.56,73.22,13.73,8.12" target="#b45">[46]</ref>. Bowman summarized and comprehensively discussed the factors related to immersion that can have an impact on visualization experi- ences <ref type="bibr" coords="2,307.82,104.23,9.51,8.12" target="#b6">[7]</ref>. These factors include FOV, field of regard (FOR), display size, stereoscopy, head-based rendering, realism of lighting, and frame and refresh rates. Laha et al. studied three of these (head tracking, FOR, and stereoscopic rendering) in the volume rendering of mouse limb and fossil datasets <ref type="bibr" coords="2,374.71,144.08,13.75,8.12" target="#b23">[24]</ref>. Their experimental tasks were mostly open-ended; participants had 1 to 1.5 minutes to describe what they could see and the experimental results were evaluated by experts for quality. Though their study suggested that high levels of FOR, stereo, and head tracking improved task performance in general, they also found stereo worsen task performance on internal feature search and general descriptive tasks. Many of our DMRI structures are related to internal structures in dense tubes, and it is thus worth considering whether or not stereo is helpful when data are highly dense. Many studies have addressed the benefit of displaying images in large size. For one thing, large size can increase FOV when users are free to move. And the benefit of large FOV seems to be substantial. For example, a large field of view (FOV) has been found to improve task performance and generate better situation awareness and presence in navigating 3D environments <ref type="bibr" coords="2,401.01,284.67,13.73,8.12" target="#b41">[42]</ref> . Pausch et al. attributed the benefits to a sense of presence that inspires more efficient egocentric and cognitive strategies for 3D navigation in letter search tasks <ref type="bibr" coords="2,497.34,304.59,13.73,8.12" target="#b28">[29]</ref>. The large-size display has also been found to make possible different forms of visual presentation and interaction modalities. For example , a large display with gigapixels can accommodate more data to support more scalable visualizations <ref type="bibr" coords="2,430.74,345.56,13.74,8.12" target="#b46">[47]</ref> . Ball, North, and Bowman reported that when display reached the giga-pixel scale, interaction with walking improved task performance <ref type="bibr" coords="2,453.61,365.49,9.51,8.12" target="#b1">[2]</ref>. Similarly, in large 3D virtual environments, Ruddle, Payne, and Jones found that participants moved more and that such movement improved task perfor- mance <ref type="bibr" coords="2,310.77,395.37,13.74,8.12" target="#b36">[37]</ref>. Zanbaka et al. also found the benefits of FOV to improve memory <ref type="bibr" coords="2,317.52,405.33,13.74,8.12" target="#b47">[48]</ref> . Our study attempts to separate the interactivity and visualization to keep the interaction techniques constant and study the visualization factor alone. Users can only rotate the data. We also kept a constant FOV and a constant number of pixels so that the retinal projections were the same size among viewing conditions. This setting allowed us to ask a different set of questions and compare the effect of viewing small-close and large-far images. While the aforementioned studies used an approach called display characteristic-specific study method <ref type="bibr" coords="2,417.60,486.15,9.52,8.12" target="#b6">[7]</ref>, Swan et al. were among the first to compare the practical uses of displays and justified the value of empirical studies in practical uses <ref type="bibr" coords="2,410.57,506.08,13.73,8.12" target="#b40">[41]</ref> . Their study provided a comprehensive evaluation of four display types (desktop, CAVE, workbench , and Wall), stereopsis, movement type, and frame of reference in a map-based battlefield visualization environment. They found that desktop outperformed CAVE. Similarly, Demiralp et al. compared the effect of context on shape perception of a set of potato-shaped objects and found that CAVE were not beneficial in accomplishing tasks; fishtank had sharper images leading to better user experiences <ref type="bibr" coords="2,518.36,575.82,13.71,8.12" target="#b10">[11]</ref>. Prabhat et al.'s experiment compared a small fishtank and a CAVE for some volume rendering of biomedical datasets for counting tasks and reported that the CAVE was significantly more efficient than the other two displays <ref type="bibr" coords="2,333.49,615.67,13.74,8.12" target="#b31">[32]</ref> . They suggested that the benefits came from the embodied interaction, i.e., from the fact that participants could move their bodies freely and look at large " body-scale " images. In fact, Mizell, Jones, and Slater suggested that the " super-scaling " of visual features made possible by interactivity and zooming in large environments also improved task performance for some engineering tasks <ref type="bibr" coords="2,484.33,665.47,13.73,8.12" target="#b25">[26]</ref>. Existing results seem to suggest that high-quality images or large feature size are more important than display size when interaction is relatively the same (e.g., in <ref type="bibr" coords="2,383.02,696.48,14.33,8.12" target="#b10">[11]</ref> ) and that when the users work in a relatively low-resolution environment (e.g., CAVE), enabling interaction can compensate for the low-resolution by displaying larger features to retain or improve task performance as in <ref type="bibr" coords="2,443.01,726.37,13.73,8.12" target="#b31">[32]</ref> . Following the suggestion of Swan et al. to design tasks within the application context to establish usage guidelines <ref type="bibr" coords="3,138.61,53.29,13.74,8.12" target="#b40">[41]</ref>, we have designed tasks that brain researchers would perform but have place these tasks in the context of display characteristics studies. It is not surprising that performance depends on data and task characteristics . Qi et al. compared four volume-visualization problems related to identification and judgment of size, shape, density, and connectivity of objects in a volume using three displays: a head-mounted display (HMD) and a fishtank with and without haptic input <ref type="bibr" coords="3,246.09,123.04,13.73,8.12" target="#b32">[33]</ref>. This work suggested that, even though the HMD had larger fields of regard (FOR), fishtanks were better in providing overview and context, both useful in the volume visualization tasks and haptic-input-aided comprehension. Laha et al. were among the first to report that stereo worsens task performance in occluded structures <ref type="bibr" coords="3,217.37,172.84,13.74,8.12" target="#b23">[24]</ref>. Inspired by these previous work, here we study very dense datasets with low legibility . We also expand the area of study by running a dataset under a broad range of task conditions, including bundle tracing and some other tasks from the DMRI domain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>Our experiments used a 2 × 2 × 5 within-subject design with the three independent variables of size (small and large), stereo (mono and stereo), and tasks. In general, we wanted to know if size and stereo have an impact on task performance (time and accuracy) on DMRI tasks using streamtube visualizations, especially when the retinal images are about the same. We had two general hypotheses: (1) we followed the bigger was better <ref type="bibr" coords="3,146.75,303.68,9.68,8.12" target="#b5">[6,</ref><ref type="bibr" coords="3,159.51,303.68,11.96,8.12" target="#b41"> 42] </ref>and hypothesized that adding stereo and increasing display size would improve task accuracy and reduce completion time for DMRI visualizations; (2) furthermore, the greater the complexity of spatial tasks, the greater the benefit of an improved display. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Display Settings 3.1.1 Equipment</head><p>We used two displays for the experiment with stereopsis on or off: a 24 ′′ small display (Alienware's OptX AW2310) and a 72 ′′ large display (Mitsubishi WD-73738 3D Ready TV) with their native 1920 × 1080 pixel resolution (<ref type="figure" coords="3,118.74,417.01,21.03,8.12" target="#fig_0">Fig. 2</ref>). Displays were calibrated to be of roughly equivalent brightness and contrast. We set up the displays so that when either display was viewed from a specific distance, the visual angle and hence the size of the retinal image would be identical (<ref type="figure" coords="3,34.94,456.86,20.17,8.12">Fig. 3</ref>). We used a 60 @BULLET viewing angle, an optimal value suggested by Ware <ref type="bibr" coords="3,65.42,466.83,14.94,8.12" target="#b44">[45] </ref> that was achieved by taking into account the horizontal display size and the viewing distance. Coupled with the horizontal screen size of 531.3 mm, we set the participants a comfortable viewing distance of 1.5 ft (460.1mm) for the small display. In order to get identical retinal images, the large display was 4.5 ft (1380.3mm) away from the user. We asked participants to keep their heads as static as possible, although they were free to move closer or further away. In our software implementation, we also kept the software FOV at 60 @BULLET to equalize the two FOVs, as in our previous study <ref type="bibr" coords="3,216.53,546.53,14.93,8.12" target="#b27">[28] </ref>following the suggested optimal solution by Czerwinski, Tan, and Robertson <ref type="bibr" coords="3,264.69,556.49,13.75,8.12" target="#b9">[10]</ref>. To minimize the environmental effects, all lights were turned off during the study; and there was minimal reflective light in the room. During the experiment, participants could rotate the data by leftmouse dragging and the speed of the mouse movement was scaled to the screen size. No zoom was enabled so as to make it impossible to change the retinal images substantially. This setting gave a kinetic depth effect to permit the viewer to integrate spatial information over time and gain a continuous depiction of the spatial structure, similar to <ref type="bibr" coords="3,31.50,646.15,13.74,8.12" target="#b45">[46]</ref>. <ref type="figure" coords="3,31.50,676.55,22.40,8.12" target="#fig_2">Fig. 4</ref>illustrates the stereoscopic setting. Both displays supported stereoscopic rendering which was turned on or off to control stereopsis . The participants saw the same visual angle of each pixel across displays. The stereo used frame sequential (or quad buffer) stereo in that each eye saw the full resolution of the entire screen, similar to <ref type="bibr" coords="3,41.21,726.37,13.75,8.12" target="#b40">[41]</ref>. Participants sat at the same viewing distance as in the mono condition with the software FOV set to 60 @BULLET for each eye <ref type="bibr" coords="3,248.57,736.33,9.52,8.12" target="#b7">[8]</ref>. The (a) Small stereo (b) Large stereo stereo was implemented using the viewing distance (or focal length), camera (eye) position and separation, software FOV, and viewing frustum . The eyes (camera) looked straight towards the screen along parallel vectors, separated by the viewing distance divided by 30 (30 was empirically chosen to avoid double images; any number between 20 and 30 worked well on our displays). The code was implemented in OpenGL running on a nVidia Quadro 4000 (by PNY) graphics card <ref type="bibr" coords="3,311.27,292.31,9.52,8.12" target="#b7">[8]</ref>. <ref type="figure" coords="3,326.56,292.31,20.41,8.12">Fig. 5</ref>shows two camera shots of images presented on the two displays in stereoscopic mode captured from the eye positions when all lights in the room were off, as in the experiments. The datasets were scaled to fill the screen and be displayed at zero disparity to reduce the discomfort with stereo viewing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Stereo Implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Keep Contrast Constant</head><p>Contrast determines the quality of the display in terms of brightness or luminance between white and black, and thus affects our ability to see details in visualizations. We displayed the ANSI 4 × 4 checkerboard pattern on each display, measured the brightness readings on a AMPROBE LM-100 light meter at the center of all white squares and all black squares, and calculated the contrast ratio using two methods . The first ratio was computed as (average (all white readings) average (all black readings)) / (average (all white readings) + average (all black readings)), which is a good measure when gray-scale visualizations are presented. The ratios were 0.979 and 0.975 on the small and large displays accordingly. the ANSI ratio was also computed by dividing white to black readings, yielding 92.2 for the small and 78.1 for the large displays. We also took the approach that " human observer is always needed to carry out a color matching experiment " <ref type="bibr" coords="3,513.98,494.24,14.89,8.12" target="#b41">[42] </ref>and asked participants if they observed differences of displays that would affect their task performance, Our study participants reported no contrast problems while performing the tasks. Participants wore the stereo glasses only in the stereo condition. To keep the retina image brightness the same, we could have had the participants to wear the stereoscopic glasses in 2D, similar to <ref type="bibr" coords="3,514.50,554.32,14.92,8.12" target="#b40">[41] </ref>and our previous study <ref type="bibr" coords="3,363.42,564.29,13.75,8.12" target="#b14">[15]</ref>. We did not do this because the present study was also designed to be faithful to real-world usage so as to ensure external validity. Wearing glasses did make the stereoscopic images dimmer than the 2D mono settings by about 50% measured using the same light meter. No complaints were received in several pilot studies about the low luminance caused by the glasses. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Tasks</head><p>Each participant completed 20 tasks on each display. They provided the answer by clicking on the result button on the screen. The first decision we have to make was to place those visual cues for tasks. Neurologists suggested to cover questions related to five representative fiber bundles in brain anatomy: corpus callosum (CC, interhemispheric fibers), cingulum bundles CG, (ventral-dorsal oriented), corticospinal tract (CST, cranial-caudal oriented), ILF (interior longitudinal occipitotemporal fasciculus, anterior to posterior), and IFO (inferior frontaloccipital fasciculus, anterior to posterior to lateral). The five bundles were chosen also because they represented two distinct (1) The screen aspect ratio is 16:9. (2) The unit is mm. </p><formula>(3) </formula><p>The display condition is small-mono. For the large-mono condition, all lengths should be multiplied by three; all angles are the same. A A <ref type="figure" coords="4,22.50,269.49,18.83,7.64">Fig. 3</ref>. Display setting (mono).  categories of fibers: association (i.e., intra-hemispheric) and commissural (i.e., inter-hemispheric) fibers. Also, the size and numerosity (number count) varied among these fibers, providing a range of suggestions on how visual design could serve knowledge discovery in these distinct structures. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Task Selection Approach</head><p> Our approach to selecting tasks was to review the literature and discuss with four brain researchers their activities and expectations for an interactive visualization design. The results indicated that 3D visualizations of fiber tractography could be used to answer questions in the following categories with some subtasks in each category: (1) certain numerical measurement metrics <ref type="bibr" coords="4,141.52,576.38,9.51,8.12" target="#b8">[9]</ref>, (2) spatial relationships of fiber bundles (e.g., for resolving brain connectivity), (3) pathological condition search and manipulation (e.g., is there a lesion? How can fibers be cut to remove a tumor?), (4) comparisons (e.g., how different are two bundle volumes in two hemispheres? Are two brain tractographies the same? Are they normal?), (5) categorical (e.g., to which anatomical structure does a bundle belong?), (6) tube tracing (e.g., where does a tube bundle go?) and (7) understanding of functional or structural images. Our experiments included five tasks chosen from these seven categories (<ref type="figure" coords="4,50.46,676.55,20.07,8.12">Fig. 1</ref> ) and our selection criteria balanced task difficulty, usefulness , and experiment length as tested in several pilot studies. The first criterion was related to data. We excluded those conditions for which we either did not have a ground truth or could not simulate graphically due to unknown pathological characteristics. One such task was tumor detection. Understanding tumors, in particular knowing if a tumor infiltrated, displaced edematous tracts, or destroyed </p><p>(a) small-stereo (b) large-stereo physical screen upper boundary physical screen lower boundary <ref type="figure" coords="4,285.12,156.38,18.59,7.64">Fig. 5</ref>. Photos of the two stereoscopic displays: the dataset was scaled to fill the screen during the experiment. tubes, was crucial to surgical planning <ref type="bibr" coords="4,427.33,353.85,13.73,8.12" target="#b19">[20]</ref> , yet generating tumor effects was unlikely to be grounded because we did not know how the tubes would change. In a previous study, we placed tumors in an area and asked people to judge if tumor and tracts were in contact, and we found that the task became arbitrarily more or less complex depending on tumor location <ref type="bibr" coords="4,351.65,403.66,13.74,8.12" target="#b30">[31]</ref>. Thus we excluded such tasks from this study. We also excluded tasks in category two for which we did not have enough data. Finally, we excluded CG fibers in the summative evaluation because most CG fibers from our tractography were too short to be clinically meaningful. The second data selection criterion was related to tasks. We excluded those open-ended qualitative tasks, such as in category 7, which would deserve a full-blown study, perhaps with the insight-based evaluation method or well-controlled experiment <ref type="bibr" coords="4,445.96,483.79,13.71,8.12" target="#b23">[24]</ref>. We did use this task in a pilot study as a complex task, but decided to remove it because pilot participants (neurologists) commented that they would need more than 10 minutes to describe the data features meaningfully. This may suggest that our datasets were far more complex than in Laha et al.'s study <ref type="bibr" coords="4,306.59,533.61,13.75,8.12" target="#b23">[24]</ref>, where their participants were given about a minute to work on descriptive tasks. Task difficulty was also a consideration. The choice of the tasks related to these seven categories could differ widely and affect task difficulty profoundly. For example, gauging if two bundles are the same or not (a binary-choice task) is much easier than considering the percentage difference between two bundles (a numerosity task). We originally used the numerosity task (task 5) because it would be more interesting, but changed it to the binary-choice one, because pilot study results suggested that participants guessed the answers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Example Tasks</head><p> Our final task set includes five tasks based on the above selection criteria . All tasks only have either right or wrong answers and there is only one correct answer for each question. Participants must make a choice before moving on to the next. Our pilot test results show that task difficulty is within a reasonable range and participants can provide an answer in our settings. The accuracy of each task is defined by the percentage of correct answers. Since we were not interested in differences among tasks, tasks were executed sequentially by alternating the complexity in the order of the task index below. Task completion time, accuracy, and subjective workload were recorded. <ref type="figure" coords="5,41.46,53.29,45.77,8.12">Fig. 1a (FA)</ref>shows a sample stimulus for comparing the average fractional anisotropy (FA) values in two boxes. The participants were instructed to choose the box covering voxels of higher average FA values. The participant was also told that FA was a quantity used in DMRI to measure the anisotropy in each voxel of the brain volumes. The FA color map was shown on the right: the redder the color, the higher the FA value, following the color mapping in Zhang et al. <ref type="bibr" coords="5,264.75,113.07,13.70,8.12" target="#b48">[49]</ref>. Participants indicated the higher FA value by pressing the 'Similar' or '1 is higher' or '2 is higher' button from the three choices. The FA value similarity threshold was set at 0.05, i.e., the two box values were considered similar if the difference was less than 0.05. We chose this value because the small threshold was not clinically interesting given the measurement uncertainty. The chances of selecting each of the three answers were about the same. <ref type="figure" coords="5,41.46,192.90,25.77,8.12">Fig. 1b</ref>(TRACING) shows a sample interface for the fiber-tracing task in the DMRI streamtube visualizations; the yellow spheres mark the starting points and the three boxes show possible ending positions. Participants were asked to find the box in which the ending points lay. They were told that the marked fibers belonging to the same bundle followed the same orientation. Participants were also told that the three boxes were placed at the end of bundles, each belonging to one of the three anatomical orientations (anterior-posterior, dorsal-ventral, and left-right), and that no two enclosed the bundles on the same orientation . For example, the box 1 in <ref type="figure" coords="5,152.89,282.57,25.60,8.12">Fig. 1b</ref>covers cranial-caudal fibers, the box 2 (the correct answer) encloses anterior to posterior fibers, and the box 3 is at the end of the only inter-hemispheric fibers. <ref type="figure" coords="5,41.46,312.59,25.86,8.12">Fig. 1c</ref>(NAMING) shows the dataset used in the bundle-naming task: participants were asked to name the fiber bundle marked in yellow . The participants, regardless of their background, were trained to recognize the fiber bundles in order to ensure sufficient knowledge about the task and datasets. During the experiment, a cheat sheet was provided displaying the CC, CST, ILF, and IFO bundles, so they did not have to remember the names. <ref type="figure" coords="5,41.46,382.46,25.09,8.12">Fig. 1d</ref> (LESION) shows a task condition for the lesion task: participants were asked to locate the lesion and indicate it by right-clicking as close to the center of the lesion area as possible. Participants were also told that the lesion was located in one of the five bundles and they need to right-mouse click the center of the lesion (where the red cross is in <ref type="figure" coords="5,50.14,432.27,24.14,8.12">Fig. 1d</ref> ). All points within the lesion area in the screen coordinates were considered to be the correct answers. <ref type="figure" coords="5,41.46,452.34,25.57,8.12">Fig. 1e</ref>(SAME BUNDLE) shows an example of task 5, in which participants were asked whether or not the fibers in yellow all belonged to the same bundle. 50% of the data were in the same bundle and 50% were not. The choice of distracting fibers was based on fiber orientations; often fibers from the closest perpendicular bundles were selected. The example in <ref type="figure" coords="5,125.10,502.14,25.20,8.12">Fig. 1e</ref>shows that the highlighted fibers do belong to the same bundle, with a set from the CST (cranial-caudal oriented). In the not-the-same-bundle condition, we would add noisy fibers from the CC (inter-hemispheric) bundles and ask the participants to make a judgment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Diffusion MRI Datasets 3.3.1 Dimensions of legibility in DMRI visualizations</head><p>The ultimate goal of the experimental study is to guide the design of effective visualizations when choosing displays, and thus the data characteristics of the application must be considered <ref type="bibr" coords="5,226.15,606.69,13.73,8.12" target="#b26">[27]</ref>. Clutter is a notorious problem in DMRI tractography when a uniform sampling at each voxel of DMRI is used, as witnessed by the continuous efforts to improve spatial structure understanding <ref type="bibr" coords="5,205.25,636.58,13.75,8.12" target="#b13">[14]</ref>. Clutter remains a problem in all further stages in the data-analysis pipeline, since it can limit structural recognition and visual segmentation <ref type="bibr" coords="5,219.23,656.50,13.73,8.12" target="#b35">[36]</ref>. In graphics, clutter can be addressed by managing occlusion <ref type="bibr" coords="5,211.61,666.46,14.92,8.12" target="#b12">[13] </ref>and enhancing legibility so that individual graphics items are unambiguous and can be read by the users (p. 175 <ref type="bibr" coords="5,135.63,686.38,10.07,8.12" target="#b4">[5]</ref>) even when displayed in 3D or small pixels <ref type="bibr" coords="5,55.03,696.34,13.74,8.12" target="#b20">[21]</ref>. Bertin's three dimensions of legibility for map drawings (<ref type="figure" coords="5,250.78,706.44,24.62,8.12" target="#tab_2">Table 2</ref>), density, angular legibility, and retinal legibility, can be usefully applied to 3D visualizations. We added the dimension of context <ref type="bibr" coords="5,269.19,726.37,9.52,8.12" target="#b2">[3]</ref>, i.e., the direct relevance of the surrounding data to the tasks at hand. We believe that context is orthogonal to the other dimensions applicable to DMRI visualizations: it can provide spatial references and thus aid the tasks at hand, but it can also obscure the internal structures, making diagnosis more difficult due to occlusion. The most obvious examples of this occur when small U-shaped fibers are shown in such a way that we cannot see inside regardless of visualization method, and when the seeding resolution becomes so high that removing irrelevant fibers would require significant user interaction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Density</head><p>The first factor that could affect our results is the visual clutter caused by dense streamtube visualizations. Given different displays, we would expect adding stereo and increasing size to help legibility in general. In this study, we did not vary density in the datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Context</head><p> We collaboratively identified a three-step workflow to choose context presentation, expanded from the information visualization mantra: overview first, zoom and filter, then detail-on-demand <ref type="bibr" coords="5,491.75,382.53,13.73,8.12" target="#b39">[40]</ref>, and from the report of neurologists' data analysis workflow in <ref type="bibr" coords="5,486.11,392.50,13.74,8.12" target="#b11">[12]</ref>. In the first step, initial global examination of the data, the full brain is examined , since this can facilitate the study of related measurement metrics that can provide more robust markers of white-matter structural integrity <ref type="bibr" coords="5,328.03,432.35,9.52,8.12" target="#b8">[9]</ref>. The second step is a deeper analysis in which some fiber tracts are removed from the whole brain in such a way that some contexts are preserved. This partial brain study is an intermediate data-exploration stage in which users remove some irrelevant blocking fibers and focus on the study at hand before approaching the region of interest (ROI). The final step is to investigate a certain ROI that is associated with task-relevant bundles, so as to make a more precise pathological assessment without visual occlusion after the surrounding fibers are sufficiently understood. Using this workflow, here we used fibers from the half-hemispherical partial volume to reduce the complexity of seeing the full volume while preserving some context information. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Tube Rendering</head><p> Tractography data were computed from the source MRI images captured from a normal human brain at resolution (0.9375×0.9375×4.52 mm 3 ). Diffusion tensors of each seeding resolution are calculated with tricubic B-spline interpolation and then fiber tracts are approximated using the second-order Runge-Kutta solver <ref type="bibr" coords="5,454.05,612.56,9.71,8.12" target="#b3">[4,</ref><ref type="bibr" coords="5,466.70,612.56,10.64,8.12" target="#b48"> 49]</ref> . During the tractography , the full volume seeding algorithm <ref type="bibr" coords="5,457.35,622.53,14.93,8.12" target="#b42">[43] </ref>is adopted for seed selection to produce a tractography sequence. <ref type="figure" coords="5,294.12,676.55,26.06,8.12" target="#tab_3">Table 3</ref> shows our experimental design, which followed random ordering with a Latin square design. Each participant (column 1) performed 20 tasks (4 datasets × 5 task types) on each display (row); the order of the displays followed a Latin-square design. We prepared four data groups with each of the CC, CST, ILF, and IFO (column 3) to counterbalance the task difficulties on four displays (column 2). The task difficulties depend on these four datasets and the only changes were the target locations on these bundles. The clinical validity of these data conditions were also confirmed by neurologists. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experimental Design 3.4.1 Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Participants</head><p> Twelve medical residents on rotation to the neurology department volunteered for the study. Half of them were female and their average age was 32.5 years. One reason for choosing this expert group was that we observed in a pilot study the significant main impact of expertise on timing. Though the accuracies were about the same between expert and novice groups and were consistent in all task conditions, we recruited only neuroscientists in the formal study to avoid the confounding factor of participant expertise. </p><p>In that pilot study, we compared performance with 10 participants: five novices (avid computer users who had no knowledge in medicine) and five experts (neuroscientists). One reason to run this pilot study was that recruiting busy medical experts had been difficult and timeconsuming . If they got similar performances, we might in the future use members of the general public to run this type of study. The other reason was due to participants' expertise. Though past work used novices to replace experts in 3D flow studies <ref type="bibr" coords="6,192.23,471.84,13.73,8.12" target="#b14">[15]</ref> , we thought doctors might outperform the general population, since they were used to examining images. In addition, we hoped to learn the population usage patterns in the study so that results obtained would be suitable for the end users. The novice group included participants who were undergraduate computer science majors. The medical expert group had faculty and residents in the neurology department of the University of Mississippi Medical Center. That pilot study aimed to discover performance differences between novices and experts. Because we found a significant main effect in that pilot study, we chose to use medical experts only in the formal experiment presented here. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Procedure</head><p> Participants were asked to confirm that they had the normal and normal color vision. Participant stereoscopy was tested using our own pictorial presentation; all confirmed during training that they could see stereo on our displays. Participants were told about brain structure and were given a brief description of DMRI techniques and their clinical use. They also had a short (about 15 minutes) warm-up session that presented two trials under each of the tasks, using different data from the formal study for each condition: these training sessions ensured that the participants understood the conditions and the brain anatomical structures. An example training document, with video and audio, is available online at <ref type="bibr" coords="6,125.48,706.44,9.51,8.12" target="#b7">[8]</ref>. Participants completed 80 tasks total or 20 tasks on each display. The task completion time was recorded from the time when the model was loaded to when the answer button was clicked. Participants were allowed to change their answers and that time was included as well. The time between clicking an answer button and clicking the " next " button to advance the task was not recorded. Participants were suggested to take breaks between these two clicks when needed. They filled out a post-questionnaire to rate their experiences in the four display conditions and their overall experience . Participant generally spent 1 to 1.5 hours to finish the experiment and were compensated for their participation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS AND ANALYSES</head><p>We collected 960 data points with 12 participants while performing five tasks using two displays with on and off stereopsis. Before a statistical analysis was conducted, we used a quantile-quantile plot (QQ plot), a graphical method, to test the normality. We removed outliers if they lay more than three standard deviation of the mean in each experimental condition. Overall, we removed about 10 outliers from the 960 samples. All error bars in all graphs in this result section represent one standard error from the mean. We first looked the overall main effects by performing two types of factorial analyses: three-way (size, stereo, and task) and two-way (display and task). We called the combined size and stereo conditions " display " , because it allowed us to examine individual devices. We then performed the Tukey post-hoc analysis on the display factor when there was significant main effect. We summarize overall performance measurement results and test statistics in <ref type="figure" coords="6,431.76,283.75,20.71,8.13" target="#fig_4">Fig. 6</ref>and show performance by tasks in <ref type="figure" coords="6,327.17,293.72,20.28,8.12" target="#fig_8">Fig. 7</ref>. We omit the F and p values in the text part if the values are in the figures. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Performance by Task 4.2 Performance Summary</head><p>We were surprised to see that our first hypothesis that size and stereo would improve task performance was not supported. A three-way ANOVA, with stereotype, size, and task being within-subject factors, was used to analyze task completion time and accuracy. There was a significant main effect by tasks ((F(4, 19) = 48.1, p &lt; 0.0001), size (F(1, 19) = 5.28), p = 0.02), and stereopsis (F(1, 19) = 11.1, p = 0.001) settings for task completion time. Only tasks and stereopsis settings were significant for the accuracy (task: F(4, 19) = 8.36, p &lt; 0.0001; stereopsis: F(1, 19) = 21.1, p &lt; 0.0001). Size had no effect on accuracy. There was a significant two-way interaction between stereopsis and task (F(4, 19) = 3.4, p = 0.01). A two-way ANOVA with display (stereotype and size combined) and task showed that a significant main effect of display on task performance (time: F<ref type="bibr" coords="6,348.85,476.83,12.51,8.00" target="#b2">(3,</ref><ref type="bibr" coords="6,362.37,476.79,8.30,8.12" target="#b18"> 19</ref></p><formula>) = 5.5, p &lt; 0.001; accuracy: F(3, 19) = 7.17, p &lt; 0</formula><p>.0001). SM (15.4 s) had the best task completion time, followed by LM (18.0 s), SS (19.2 s), and LS (21.2 s) (<ref type="figure" coords="6,456.42,496.72,29.78,8.12" target="#fig_4">Fig. 6(c)</ref>). LM (0.87) and SM (0.88) also led to the most accurate answers, followed by LS (0.75) and SS (0.77) (<ref type="figure" coords="6,366.10,516.64,29.03,8.12" target="#fig_4">Fig. 6(f)</ref>). A post-hoc Tukey test revealed two groups: &lt; SM, LM &gt; and &lt; SS, LS &gt; and no significant main effect was found for the displays within the same group. Because task completion time is very influential, the following sections report the results by task only rather than the overall results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Task Completion Time and Accuracy</head><p>We first examined for which tasks we could observe the significant main effect. <ref type="figure" coords="6,331.43,596.86,21.16,8.12" target="#fig_8">Fig. 7</ref>plots the performance by tasks. The small display outperformed the large display for the FA and SAME BUNDLE tasks and the main effect of size on task completion time was significant (<ref type="figure" coords="6,288.56,626.74,36.43,8.12" target="#fig_0">Fig. 7a 1-2</ref>). The mono also outperformed the stereo condition in task completion time for the FA, LESION, and SAME BUNDLE tasks and the main effect of stereopsis on task completion time was significant (<ref type="figure" coords="6,288.56,656.63,37.51,8.12" target="#fig_8">Fig. 7b 1-3</ref>). Because both main effects of size and stereo were significant, we collapsed the data by stereopsis for the FA and SAME BUNDLE tasks to learn under which condition, the main effect occurred. We found that the main effect of size on task completion time was only significant in the mono condition but not in stereo (FA: mono: F(1, 1)=4.7, p=0.03, &lt;mean: S: 15.4s vs. L: 19.3s&gt;; stereo: F(1,1)=0.7, p=0.40, &lt;mean: S: 19.7s vs. L: 21.8s&gt;; SAME BUNDLE: mono: F(1,1)=6.3, p=0.01, &lt;mean: S:8.6s vs. L: 11.8s&gt;; stereo: F(1, 1)=2.4, p=0.13,  &lt;S: 10.8s vs. L: 13.1&gt;). For both tasks, the small display had better task completion time than the large display when the display was mono. But under the stereoscopic condition, size did not have a significant impact on task performance. The increase in accuracy would be more important than efficacy in clinical setting and it was calculated from the percentage of correct answers. The main effect of size on accuracy was not significant (<ref type="figure" coords="7,53.31,414.03,24.27,8.12" target="#fig_8">Fig. 7d</ref>). The mono conditions led to more accurate answers for LESION and SAME BUNDLE (<ref type="figure" coords="7,165.96,424.00,38.34,8.12" target="#fig_0">Fig. 7e 1-2</ref>). There was a trend that the mono conditions led to more accurate answers for TRACING (F(1, 2) = 2.6, p = 0.1), though the effect was not significant. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Combined Display Effects</head><p>When evaluating the displays by task, we observed that the displays had significant impact on efficiency for the FA and SAME BUNDLE tasks; and the only differences of mean was between SM and LS. The impact of display on efficiency was also significant for the LESION task and two groups were found: &lt; SM, LM &gt; and &lt; SS, LS &gt; (<ref type="figure" coords="7,258.63,519.97,23.25,8.12" target="#fig_8">Fig. 7f</ref>1-2). For FA, though we did not observe significant differences of display on accuracy, LM led to the most accurate answers (about at least 6% higher than all other conditions) (<ref type="figure" coords="7,156.35,560.66,68.42,8.12" target="#fig_8">Fig. 7f first column</ref>). Considering these tasks were used for medical diagnosis, this accuracy differences were high enough to be considered important. Similar observations could be made for the TRACING tasks where LM also led to the highest accuracy (<ref type="figure" coords="7,81.59,600.51,23.68,8.12" target="#fig_8">Fig. 7f</ref>second column). We did not find any significant main effect of size and stereo on TRACING and NAMING (<ref type="figure" coords="7,255.55,610.48,19.86,8.12" target="#fig_8">Fig. 7</ref>). Participants generally felt NAMING was an easy task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Subjective Ratings and Comments</head><p>We collected subjective self-evaluation data using a post-questionnaire asking about the effectiveness (EFFE, this system's capabilities to meet requirements), overall satisfaction (SAT, using this system is not a frustrating experience), ease of use (EoU), and efficiency (EFFI, don't have to spend too much time correcting things with this system) for the four display conditions (<ref type="figure" coords="7,145.22,706.44,19.61,8.12" target="#fig_6">Fig. 8</ref>) on a scale of 7 with 1 being the worst and 7 the best. In general, participants were positive about all display conditions and were comfortable using them all, as all mean scores are larger than 4.5.  , Small-Stereo (LS), Large-Mono (LM), and Small- Mono (SM) with regard to effectiveness (EFFE), satisfaction (SAT), ease of use (EoU), and efficiency (EFFI). </p><p> Participants thought the small displays were easier to use, more efficient , and more effective than the large display. They suggested that they did not need the large display to understand the brain datasets. About half the participants remarked that they would use the stereoscopic setting with the small-stereo display because they felt the stereo allowed better depth so they could see better. They especially commented that they liked small-stereo for the TRACING tasks. On the one hand, they felt they could touch the tubes on the small-stereo with clearer depiction. Tubes on the display were too far to reach especially in the stereoscopic case. This might explain why participants rated SS highest in almost all categories except for effectiveness (<ref type="figure" coords="7,505.77,655.64,21.50,8.12" target="#fig_6">Fig. 8</ref>first column). Almost all participants preferred the small display and five of the 12 participants commented that they were confident to infer 3D shapes from mono images because the mono images were used in their textbooks. Almost all participants felt that the large display seemed overwhelming , especially when stereo was activated. They thought the stereo was " cool " but offered them no benefits for the DMRI tasks, at least in its current form. Participants generally reported that they looked much harder at the stereoscopic conditions simply because the structures became clearer for some tasks and thus more interesting. However, doing this did not improve accuracy. This might explain why participants spent much longer looking in the LS condition (<ref type="figure" coords="8,244.85,487.69,24.21,8.12" target="#fig_8">Fig. 7c</ref>) but had the worst accuracy (<ref type="figure" coords="8,122.52,497.65,22.04,8.12" target="#fig_8">Fig. 7f</ref>). They felt the stereoscopic display for LESION was the worst possible combination. Three participants saw possible value for tasks different from those in our experiment. They would like to have multiple-views on the large displays, so they could place multiple data side-by-side for comparative analyses, a task frequently performed by neurologists. Four participants who preferred small displays reported that the screen size of the small monitor matched their expected size of the human brain and they did not need the large display to understand the data. Perhaps most remarkably to visualization design, participants also suggested using more non-photorealistic rendering or illustrationbased techniques similar to those used in their textbooks to show the bundles. The current tube rendering did not seem to help very much to 'assist' them to 'see' more. Some of them remarked that they liked using hand-held devices for them to 'carry' the data, hold them close-by their eyes, and experiment with how best to see the complex structures. the effect might be small <ref type="bibr" coords="9,122.68,53.29,13.74,8.12" target="#b43">[44]</ref>. Additionally, the stereoscopic images were darker than the mono displays or that the stereoscopic display had low contrast. An interesting future direction would be to study how performance varies with differences in screen contrast and brightness. One way to do this is to compare 3D TV with some high-end display with compatible brightness and contrast to examine if performance differences will be found. Our results also indicate that our knowledge about stereoscopic viewing for dense tube-based visualizations is limited. We need to understand shape as a collection of mutually dependent lines for shape representations. One way is to alter the data rendering method to increase internal structure legibility. One solution might be to allow effective surface structure detection by adding a " cap " at the end of a tube to allow the perception of surfaces and provide a clear view of those broken fibers, for example, depicting the tensor field with glyphs or volume rendering methods <ref type="bibr" coords="9,172.00,203.92,13.73,8.12" target="#b21">[22]</ref> . We may alter the datarendering method to increase visual legibility, especially since the rendering method will alter the perceived structure, for example by applying flow maps <ref type="bibr" coords="9,95.40,233.81,14.93,8.12" target="#b15">[16] </ref>or showing topological structures <ref type="bibr" coords="9,233.72,233.81,14.19,8.12" target="#b29">[30,</ref><ref type="bibr" coords="9,250.01,233.81,10.65,8.12" target="#b38"> 39]</ref>. One possibility is to study the tradeoffs between display characteristics and more advanced depth-enhancement techniques, e.g., adding halos and providing better color design <ref type="bibr" coords="9,137.47,263.70,13.74,8.12" target="#b18">[19]</ref>. </p><formula>T R A C IN G N A M IN G L E S IO N S A M E B U N D L E F(1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Size Experience</head><p>In general, contrary to our hypothesis, the large screen did not improve task performance. This result could have at least two explanations. First, it might be argued that the brain structures are familiar to medical school clinicians and that they are used to examining 2D structures in textbooks as well as 3D structures. This may explain why participants dislike the large displays or in another words, they would suggest a different use in multiple-views. The brain tractography visualization on the small monitor was presented at its expected actual size and that there might not be a benefit from presenting it larger-than-life. Also, participants were experts who had good mental model about the brain structure, that they did not need the large display to provide situation awareness, as in other settings <ref type="bibr" coords="9,159.90,407.76,13.74,8.12" target="#b27">[28]</ref>. Second, we might posit that the size experience is enhanced in 'super-scale' as large as our body size <ref type="bibr" coords="9,49.67,427.69,13.75,8.12" target="#b25">[26]</ref>, but our large display did not support zooming to bring large model to participants' eyes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Retinal Images Experience</head><p>We observed that the small display improved task completion time only when the display was in mono mode. Under the stereo display condition, the two sizes performed equally well. Since the far-large and near-close should project the same retinal images when the stereotype was the same, we might predict that the retinal image was a stable estimate of task performance only under the stereoscopic condition. With the mono display, retinal image was generally a good estimate of accuracy but not of task completion time, at least for the tasks used here. There did appear to be a penalty associated with large-stereo viewing . A number of participants stated that they found viewing the same DMRI tubes in the LS mode somewhat stressful. Part of this stress may be due to the difficulty of the tasks: trying to find the structures from several tens of tubes in a tangle of thousands of tubes is not easy. They also felt some loss of control of the data when they sat further away. For example, while performing the TRACING tasks, participants used their fingers to point to the tubes to trace them; but they could not do this on the far-large settings. We also suspected that coupling a bodycentric view so that participants could move their bodies around or to zoom would improve viewing accuracy in the stereoscopic mode. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Tasks</head><p>Not surprisingly, we found a main effect of task type on completion time, since the tasks differed in difficulty and cognitive activity involved . The stereo and size had no significant effects on accuracy for NAMING tasks, suggesting that NAMING might not require stereo viewing or large displays. Indeed, all participants described that this was the simplest task. Originally, we thought FA and SAME BUN- DLE were very different tasks because FA was similar to visually mapping the colors to numerical values while SAME BUNDLE involved counting and searching for differences, and because in the FA tasks the target fibers constituted only a small chunk of the overall structure, while participants needed to find only one difference in order to answer the SAME BUNDLE questions. The two tasks apparently shared some similarities with regard to the display choices. Participants also reported that they mostly focused their attention on the fibers within the two boxes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Implications for Design</head><p>In this study, we used DMRI data carefully selected with neurologists in a controlled experiment to learn the impact of stereo and size on a set of DMRI tasks. The results can be generalized to cases where users examine large dense tube visualizations. We have the following recommendations for designers in choosing size and stereo: (1) Stereo seems to have a greater impact on performance than size at least for the tasks and visualizations in this study. We will need to design better stereoscopic display experience that makes it useful for visual feature extraction from dense dataset; (2) When a stereo display is chosen, the task execution time did not vary with display size as long as the retinal image is unchanged. Thus the retinal image is a fairly good estimate of task execution time for the task and datasets we have studied; and (3) For tasks that require seeing a fiber track (e.g, FA and TRACING tasks), large-mono display may be a better choice. For complex tasks that require shape understanding from thin tubes along the depth dimension (e.g., LESION), further considerations are needed to balance the stereo and mono displays. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>Overall, we think we still know very little about complex dense dataset visualizations in 3D environments. One future direction is perhaps to revisit those complex 3D shape understandings for better visualization experience <ref type="bibr" coords="9,352.52,392.41,9.70,8.12" target="#b0">[1,</ref><ref type="bibr" coords="9,365.09,392.42,11.21,8.12" target="#b17"> 18,</ref><ref type="bibr" coords="9,379.15,392.42,10.65,8.12" target="#b33"> 34]</ref> . Previous work has shown that large displays and stereoscopic displays can increase task performance in many types of environments. This study focuses on the impact of displays on streamtube visualizations in real-world DMRI tasks measured with medical doctors. The major contribution of this article is to provide the first quantitative estimate of the benefits of stereo and size for perceiving dense structured tube data based on the taxonomy of legibility . We provide a taxonomy of legibility and a rare counterexample in which small mono displays were sufficient. Our results surprised us: the easy-to-understand large stereo did not yield the best performance as we expected. All the possibilities are to be further investigated, but they do not detract from the practical utility of our findings. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,294.12,181.09,250.38,7.64;3,294.12,190.55,167.98,7.64"><head>Fig. 2. </head><figDesc>Fig. 2. Brain researchers view 3D diffusion MRI tractography on two displays (here showing the stereoscopic mode). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,22.50,420.06,111.11,7.64"><head>Fig. 4. </head><figDesc>Fig. 4. Display setting (stereo). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,31.50,304.23,513.02,7.64;7,31.50,313.70,121.41,7.64"><head>Fig. 6. </head><figDesc>Fig. 6. Task completion time and accuracy by display characteristics across all tasks. All error bars in the graphs in this result section represent one standard error from the mean. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="7,294.12,494.31,250.37,7.64;7,294.12,503.76,250.40,7.64;7,294.12,513.23,250.39,7.64;7,294.12,522.70,124.92,7.64"><head>Fig. 8. </head><figDesc>Fig. 8. Subjective rating scores comparing these four displays ordered in Large-Stereo (LS), Small-Stereo (LS), Large-Mono (LM), and Small- Mono (SM) with regard to effectiveness (EFFE), satisfaction (SAT), ease of use (EoU), and efficiency (EFFI). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="8,22.50,426.40,505.54,7.64"><head>Fig. 7. </head><figDesc>Fig. 7. Task completion time and accuracy by tasks. Different color symbols in c and f represent different Tukey groups from post-hoc analyses. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false" coords="4,301.62,196.27,217.39,112.47"><figDesc coords="4,331.93,196.27,27.67,7.64">Table 1.</figDesc><table coords="4,301.62,196.27,217.39,112.47">Tasks (SIM: simple; CPX: complex). 

Complexity 
Acronym 
Type 
SIM 
FA 
Which of boxes 1 and 2 has higher 
average FA value? 
CPX 
TRACING 
Which of the boxes covers the ending 
points of the tubes originating from 
the yellow spheres? 
SIM 
NAMING 
What is the name of the fiber bundle? 
CPX 
LESION 
Is there a lesion in the given region? 
SIM 
SAME 
Do the yellow fibers belong to the 
BUNDLE 
same bundle? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false" coords="5,313.46,153.08,211.69,103.12"><figDesc coords="5,362.86,153.08,112.89,7.64;5,313.46,172.86,38.07,7.22;5,380.38,172.86,30.56,7.22;5,313.46,182.73,23.02,7.22;5,380.38,182.73,81.88,7.22;5,313.46,192.19,121.13,7.22;5,380.38,201.65,144.78,7.22;5,380.38,211.12,93.40,7.22;5,313.46,220.58,51.03,7.22;5,380.38,220.58,126.46,7.22;5,380.38,230.05,92.74,7.22;5,313.46,239.52,23.34,7.22;5,380.38,239.52,113.76,7.22;5,380.38,248.97,115.56,7.22">Table 2. Dimensions of legibility. Dimensions definition density number of marks per area angular legibility -a global picture occupying the right scale on the primary axes -shape of a readable variable retinal legibility separate foreground and background by using the right amount of ink context visual objects in surroundings often embedded with other related objects</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true" coords="6,50.45,59.32,194.49,180.43"><figDesc coords="6,94.55,59.32,106.27,7.64">Table 3. Experimental Design.</figDesc><table coords="6,50.45,79.49,194.49,160.25">participant 
display 
data 
p1-3 
SM 
CC1 
CST1 
ILF1 
IFO1 
LM 
CST2 ILF2 
IFO2 
CC2 
SS 
IFO3 
CC3 
CST3 ILF3 
LS 
ILF4 
IFO4 
CC4 
CST4 
p4-6 
LM 
CC1 
CST1 
ILF1 
IFO1 
SM 
CST2 ILF2 
IFO2 
CC2 
LS 
IFO3 
CC3 
CST3 ILF3 
SS 
ILF4 
IFO4 
CC4 
CST4 
p7-9 
SS 
CC1 
CST1 
ILF1 
IFO1 
LS 
CST2 ILF2 
IFO2 
CC2 
SM 
IFO3 
CC3 
CST3 ILF3 
LM 
ILF4 
IFO4 
CC4 
CST4 
p10-12 
LS 
CC1 
CST1 
ILF1 
IFO1 
SS 
CST2 ILF2 
IFO2 
CC2 
LM 
IFO3 
CC3 
CST3 ILF3 
SM 
ILF4 
IFO4 
CC4 
CST4 

</table></figure>

			<note place="foot">SM LM SS LS SM LM SS LS SM LM SS LS SM LM SS LS SM LM SS LS</note>

			<note place="foot" n="5"> DISCUSSION 5.1 Stereo Experience Doubt is raised by the observation that stereo viewing leads to worse task performance, against our hypothesis and general findings that two eyes are better than one. Most participants commented that the stereoscopic viewing of dense tubes triggered pictorial depth, but to our surprise few perceived any benefit in using stereoscopic display. In LESION and SAME BUNDLE, participants were more accurate with monocular than with binocular presentations. Note that both tasks required the participants to derive patterns from tubes. We think this negative effect is perhaps more related to some intrinsic drawback with stereoscopic displays for pattern analysis tasks that require seeing internal structures. This lesion structures are somewhat similar to the internal structures in the Laha et al.&apos;s study where that study also presents detrimental stereoscopic performance [24]. Their paper reports that such negative stereo experience could have been caused by participants&apos; eye strains from the stereoscopic viewing. The other explanation for the worse task performance on the large stereo display is related to cue conflicts. One important distance cue is that our eyes converge more for near than for far objects [17]. This convergence effect also explains why we always look smaller in mirrors. or images on the Wheatstone stereoscopic display look smaller even though the retinal image is not changed. The visual system &quot; thinks &quot; it is looking at a closer object and scales the visual perception in the direction of the object&apos;s physical size. This effect might explain why participants felt the lesion areas &apos;shrank&apos; with the distance in stereo. To some extent, the lesion area &quot; looked smaller &quot; in the stereo mode as participants commented, thus making the visual search difficult. On the other hand, we are likely to get more correct stereo-readings on the near-small display than the far-large display. In our setting, the disparity increases with the viewing distance and does not exactly match physical eye separations. We did this purposefully to equalize the retinal images. Then the stereo disparity for the near view would be more close to the physical eye separation compared to the far view, which would have slightly exaggerated disparity, though</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p>The authors wish to thank the anonymous reviewers for their insightful remarks. The authors thank the participants for their time and effort, Dr. Juebin Huang and Dr. Stephen Correia for task analysis, Julianna Calabrese (Sacred Heart Catholic School) for her voice-over training , and Katrina Avery for her editorial support. This work was supported in part by NSF IIS-1018769, IIS-1016623, IIS-1017921, DUE- 0817106, ABI-1147261, OCI-0923393, EPS-0903234, DBI-1062057, and CCF-1785542, and NIH (RO1-EB004155-01A1). </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="9,312.38,632.91,232.13,7.22;9,312.38,642.37,232.11,7.22;9,312.38,651.83,77.24,7.22"  xml:id="b0">
	<analytic>
		<title level="a" type="main">Texturing of layered surfaces for optimal viewing</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bair</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>House</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1125" to="1132" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,661.30,232.13,7.22;9,312.38,670.77,232.12,7.22;9,312.38,680.23,232.12,7.22;9,312.38,689.70,49.80,7.22"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Move to improve: promoting physical navigation to increase user performance with large displays</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Ball</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Bowman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>. of the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,699.16,232.09,7.22;9,312.38,708.62,65.29,7.22"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual objects in context</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bar</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="617" to="629" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,312.38,718.09,232.12,7.22;9,312.38,727.55,232.11,7.22;9,312.38,737.02,59.98,7.22"  xml:id="b3">
	<analytic>
		<title level="a" type="main">In vivo fiber tractography using DT-MRI data</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">J</forename>
				<surname>Basser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Pajevic</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Pierpaoli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Duda</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Aldroubi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance in Medicine</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="625" to="632" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,53.98,232.12,7.22;10,40.76,63.45,82.68,7.22"  xml:id="b4">
	<monogr>
		<title level="m" type="main">Semiology of graphics: diagrams, networks, maps</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Bertin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>University of Wisconsin Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,72.91,232.09,7.22;10,40.76,82.37,146.10,7.22"  xml:id="b5">
	<monogr>
		<title level="m" type="main">Sensation and perception in the history of experimental psychology</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Boring</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1942" />
			<publisher>Appleton-Century-Crofts Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,91.83,232.12,7.22;10,40.76,101.30,127.52,7.22"  xml:id="b6">
	<analytic>
		<title level="a" type="main">Virtual reality: how much immersion is enough?</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Bowman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Mcmahan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="36" to="43" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,110.77,142.23,7.22;10,198.46,110.77,74.42,7.22;10,40.76,120.23,185.95,7.22"  xml:id="b7">
	<monogr>
		<title level="m" type="main">DMRI display study, https://sites.google.com/site/simplevisualizationlanguage</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Auchus</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,129.70,232.12,7.22;10,40.76,139.16,232.15,7.22;10,40.76,148.62,232.12,7.22;10,40.76,158.09,17.93,7.22"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Quantitative tractography metrics of white matter integrity in diffusion-tensor MRI</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Correia</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Voorn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Tate</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Paul</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Salloway</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Malloy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="568" to="581" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,167.55,232.12,7.22;10,40.76,177.06,232.10,7.11;10,40.76,186.49,69.94,7.22"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Women take a wider view</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Czerwinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Tan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Robertson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>. of the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,195.95,232.14,7.22;10,40.76,205.41,232.13,7.22;10,40.76,214.87,232.11,7.22;10,40.76,224.34,69.27,7.22"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Cave and fishtank virtual-reality displays: A qualitative and quantitative comparison</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Demiralp</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Jackson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Karelitz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="323" to="330" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,233.81,232.09,7.22;10,40.76,243.27,232.11,7.22;10,40.76,252.74,232.12,7.22;10,40.76,262.20,17.93,7.22"  xml:id="b11">
	<analytic>
		<title level="a" type="main">2010 IEEE visualization contest winner: Interactive planning for brain tumor resections</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Diepenbrock</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Prassni</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Lindemann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Bothe</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ropinski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="6" to="13" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,271.66,232.10,7.22;10,40.76,281.13,232.09,7.22;10,40.76,290.59,90.08,7.22"  xml:id="b12">
	<analytic>
		<title level="a" type="main">A taxonomy of 3D occlusion management for visualization</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Elmqvist</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Tsigas</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1095" to="1109" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,300.06,232.10,7.22;10,40.76,309.52,232.11,7.22;10,40.76,318.99,202.06,7.22"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Depth-dependent halos: Illustrative rendering of dense line data</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Everts</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Bekker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Roerdink</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Isenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1299" to="1306" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,328.45,232.12,7.22;10,40.76,337.91,232.10,7.22;10,40.76,347.38,144.64,7.22"  xml:id="b14">
	<analytic>
		<title level="a" type="main">Comparing 3D vector field visualization methods: A user study</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Forsberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1219" to="1226" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,356.85,232.10,7.22;10,40.76,366.31,232.12,7.22;10,40.76,375.78,232.12,7.22;10,40.76,385.23,17.93,7.22"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Coherent structures of characteristic curves in symmetric second order tensor fields</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Hlawatsch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Vollrath</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Sadlo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Weiskopf</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="781" to="794" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,394.70,232.11,7.22;10,40.76,404.17,232.11,7.22;10,40.76,413.63,179.09,7.22"  xml:id="b16">
	<analytic>
		<title level="a" type="main">The convergence of robotics, vision, and computer graphics for user interaction</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hollerbach</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Thompson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Shirley</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1088" to="1100" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,423.10,232.10,7.22;10,40.76,432.56,188.83,7.22"  xml:id="b17">
	<monogr>
		<title level="m" type="main">Perceiving and representing shape and depth</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Interrante</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,442.02,232.12,7.22;10,40.76,451.49,130.38,7.22"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Visualizing 3D flow</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Interrante</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Grosch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="49" to="53" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,460.95,232.13,7.22;10,40.76,470.42,232.13,7.22;10,40.76,479.88,232.11,7.22;10,40.76,489.35,142.44,7.22"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Diffusion tensor imaging of cerebral white matter: a pictorial review of physics, fiber tract anatomy, and tumor imaging patterns</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Jellison</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Field</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Medow</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Lazar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Salamat</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Alexander</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Neuroradiology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">356</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,498.81,232.13,7.22;10,40.76,508.27,232.09,7.22;10,40.76,517.74,70.16,7.22"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Designing pixel-oriented visualization techniques: Theory and applications</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Keim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="78" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,527.21,232.10,7.22;10,40.76,536.67,232.10,7.22;10,40.76,546.14,143.28,7.22"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Curvature-based transfer functions for direct volume rendering: Methods and applications</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Kindlmann</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Whitaker</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Tasdizen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Moller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,555.60,232.12,7.22;10,40.76,565.06,232.11,7.22;10,40.76,574.53,61.31,7.22"  xml:id="b22">
	<analytic>
		<title level="a" type="main">User studies: why, how, and when?</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kosara</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Healey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Interrante</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="20" to="25" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,583.99,232.13,7.22;10,40.76,593.46,232.09,7.22;10,40.76,602.92,165.03,7.22"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Effects of immersion on visual analysis of volume data</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Laha</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Sensharma</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Schiffbauer</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Bowman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="597" to="606" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,612.39,232.15,7.22;10,40.76,621.85,232.11,7.22;10,40.76,631.31,128.89,7.22"  xml:id="b24">
	<monogr>
		<title level="m" type="main">Virtual realitybased interactive scientific visualization environments. Trends in Interactive Visualization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Laviola</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Forsberg</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Van Dam</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="225" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,640.78,232.12,7.22;10,40.76,650.25,232.10,7.22;10,40.76,659.71,189.39,7.22"  xml:id="b25">
	<monogr>
		<title level="m" type="main">Comparing immersive virtual reality with other display modes for visualizing complex 3D geometry</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Mizell</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Jones</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Slater</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Spanlang</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,669.18,232.12,7.22;10,40.76,678.63,232.12,7.22;10,40.76,688.10,17.93,7.22"  xml:id="b26">
	<analytic>
		<title level="a" type="main">A nested model for visualization design and validation</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Munzner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="921" to="928" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,697.57,232.09,7.22;10,40.76,707.03,232.12,7.22;10,40.76,716.50,161.54,7.22"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Increased display size and resolution improve task performance in information-rich virtual environments</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ni</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Bowman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Chen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Graphics Interface</title>
		<meeting>. of Graphics Interface</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="139" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,725.96,232.14,7.22;10,40.76,735.42,232.10,7.22;10,303.38,53.98,135.88,7.22"  xml:id="b28">
	<analytic>
		<title level="a" type="main">Quantifying immersion in virtual reality</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pausch</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Proffitt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Williams</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 24th annual conference on computer graphics and interactive techniques</title>
		<meeting>. of the 24th annual conference on computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,63.45,232.10,7.22;10,303.38,72.95,232.08,7.11;10,303.38,82.37,92.53,7.22"  xml:id="b29">
	<monogr>
		<title level="m" type="main">Topological Methods in Data Analysis and Visualization II: Theory, Algorithms, and Applications</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Peikert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Hauser</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Carr</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Fuchs</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,91.83,232.13,7.22;10,303.38,101.30,232.10,7.22;10,303.38,110.77,107.34,7.22"  xml:id="b30">
	<monogr>
		<title level="m" type="main">Effects of illumination, texture, and motion on task performance in streamtube visualization of diffusion tensor MRI</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Penney</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Chen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,120.23,232.14,7.22;10,303.38,129.70,232.08,7.22;10,303.38,139.16,232.09,7.22;10,303.38,148.62,112.32,7.22"  xml:id="b31">
	<analytic>
		<title level="a" type="main">A comparative study of desktop, fishtank, and cave systems for the exploration of volume rendered confocal data sets</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Prabhat</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Katzourin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Wharton</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Slater</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="551" to="563" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,158.09,232.11,7.22;10,303.38,167.55,232.13,7.22;10,303.38,177.02,232.11,7.22;10,303.38,186.49,121.37,7.22"  xml:id="b32">
	<analytic>
		<title level="a" type="main">A comparison of immersive HMD, fish tank VR and fish tank with haptics displays for volume visualization</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Qi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Taylor</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Healey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Martens</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 3rd Symposium on Applied Perception in Graphics and Visualization</title>
		<meeting>. of the 3rd Symposium on Applied Perception in Graphics and Visualization</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,195.95,232.12,7.22;10,303.38,205.41,232.09,7.22;10,303.38,214.87,117.63,7.22"  xml:id="b33">
	<analytic>
		<title level="a" type="main">Volume illustration: Nonphotorealistic rendering of volume models</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Rheingans</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Ebert</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="264" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,224.34,232.11,7.22;10,303.38,233.81,95.76,7.22"  xml:id="b34">
	<monogr>
		<title level="m" type="main">Dictionary of theories, laws, and concepts in psychology</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Roeckelein</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Greenwood Pub Group</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,243.27,232.11,7.22;10,303.38,252.74,85.28,7.22"  xml:id="b35">
	<analytic>
		<title level="a" type="main">Measuring visual clutter</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Rosenholtz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Nakano</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,262.20,232.13,7.22;10,303.38,271.66,232.11,7.22;10,303.38,281.13,232.12,7.22;10,303.38,290.59,33.86,7.22"  xml:id="b36">
	<monogr>
		<title level="m" type="main">Navigating large-scale virtual environments: what differences occur between helmet-mounted and desk-top displays? Presence: Teleoperators &amp; Virtual Environments</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Ruddle</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Payne</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Jones</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="157" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,300.06,232.11,7.22;10,303.38,309.52,232.08,7.22;10,303.38,318.99,53.49,7.22"  xml:id="b37">
	<analytic>
		<title level="a" type="main">Feature extraction for DW-MRI visualization: The state of the art and beyond</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Schultz</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Schloss Dagstuhl Scientific Visualization Workshop</title>
		<meeting>. of Schloss Dagstuhl Scientific Visualization Workshop</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,328.45,232.11,7.22;10,303.38,337.91,91.41,7.22"  xml:id="b38">
	<monogr>
		<title level="m" type="main">Topological features in 2D symmetric higher-order tensor fields</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Schultz</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="841" to="850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,347.38,232.10,7.22;10,303.38,356.85,232.10,7.22;10,303.38,366.31,93.23,7.22"  xml:id="b39">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Shneiderman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Symposium on Visual Language</title>
		<meeting>. of IEEE Symposium on Visual Language</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,375.78,232.12,7.22;10,303.38,385.23,232.11,7.22;10,303.38,394.70,147.93,7.22"  xml:id="b40">
	<analytic>
		<title level="a" type="main">A comparative study of user performance in a map-based virtual environment</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Swan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Gabbard</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Hix</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Schulman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Kim</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Virtual Reality</title>
		<meeting>. of IEEE Virtual Reality</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,404.17,232.13,7.22;10,303.38,413.63,232.10,7.22;10,303.38,423.10,157.12,7.22"  xml:id="b41">
	<analytic>
		<title level="a" type="main">Physically large displays improve performance on spatial tasks</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Tan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Gergle</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Scupelli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Pausch</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer- Human Interaction (TOCHI)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="99" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,432.56,232.14,7.22;10,303.38,442.02,232.12,7.22;10,303.38,451.49,200.05,7.22"  xml:id="b42">
	<analytic>
		<title level="a" type="main">DTI visualization with streamsurfaces and evenly-spaced volume seeding</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Vilanova</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Berenschot</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Van Pul</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eurographics Symposium on Visualization</title>
		<meeting>. of the Eurographics Symposium on Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,460.95,232.12,7.22;10,303.38,470.42,191.62,7.22"  xml:id="b43">
	<analytic>
		<title level="a" type="main">Dynamic stereo displays</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>. of the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="310" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,479.88,232.11,7.22;10,303.38,489.35,141.01,7.22"  xml:id="b44">
	<monogr>
		<title level="m" type="main">Information Visualization: Perception for Design</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
	<note>second. edition</note>
</biblStruct>

<biblStruct coords="10,303.38,498.81,232.11,7.22;10,303.38,508.27,232.11,7.22;10,303.38,517.74,69.27,7.22"  xml:id="b45">
	<analytic>
		<title level="a" type="main">Evaluating stereo and motion cues for visualizing information nets in three dimensions</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Ware</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Franck</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="140" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,527.21,232.10,7.22;10,303.38,536.67,232.11,7.22;10,303.38,546.18,232.10,7.11;10,303.38,555.60,69.94,7.22"  xml:id="b46">
	<analytic>
		<title level="a" type="main">Beyond visual acuity: the perceptual scalability of information visualizations for large displays</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Yost</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Haciahmetoglu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>North</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the SIGCHI conference on Human factors in computing systems</title>
		<meeting>. of the SIGCHI conference on Human factors in computing systems</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,565.06,232.10,7.22;10,303.38,574.53,232.13,7.22;10,303.38,583.99,232.10,7.22;10,303.38,593.46,102.80,7.22"  xml:id="b47">
	<analytic>
		<title level="a" type="main">Comparison of path visualizations and cognitive measures relative to travel technique in a virtual environment</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Zanbaka</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Lok</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Babu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ulinski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hodges</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="694" to="705" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,602.92,232.12,7.22;10,303.38,612.39,232.09,7.22;10,303.38,621.85,183.62,7.22"  xml:id="b48">
	<analytic>
		<title level="a" type="main">Visualizing diffusion tensor MR images using streamtubes and streamsurfaces</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Zhang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Demiralp</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Laidlaw</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="454" to="462" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
