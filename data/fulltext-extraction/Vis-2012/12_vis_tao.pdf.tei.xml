<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structure-Aware Lighting Design for Volume Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Yubo</forename>
								<surname>Tao</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Hai</forename>
								<surname>Lin</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Feng</forename>
								<surname>Dong</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Chao</forename>
								<surname>Wang</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Gordon</forename>
								<surname>Clapworthy</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Hujun</forename>
								<surname>Bao</surname>
							</persName>
						</author>
						<title level="a" type="main">Structure-Aware Lighting Design for Volume Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Automatic lighting design</term>
					<term>structural dissimilarity</term>
					<term>lighting similarity</term>
					<term>lighting stability</term>
					<term>volume rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>—Lighting design is a complex, but fundamental, problem in many fields. In volume visualization, direct volume rendering generates an informative image without external lighting, as each voxel itself emits radiance. However, external lighting further improves the shape and detail perception of features, and it also determines the effectiveness of the communication of feature information. The human visual system is highly effective in extracting structural information from images, and to assist it further, this paper presents an approach to structure-aware automatic lighting design by measuring the structural changes between the images with and without external lighting. Given a transfer function and a viewpoint, the optimal lighting parameters are those that provide the greatest enhancement to structural information-the shape and detail information of features are conveyed most clearly by the optimal lighting parameters. Besides lighting goodness, the proposed metric can also be used to evaluate lighting similarity and stability between two sets of lighting parameters. Lighting similarity can be used to optimize the selection of multiple light sources so that different light sources can reveal distinct structural information. Our experiments with several volume data sets demonstrate the effectiveness of the structure-aware lighting design approach. It is well suited to use by novices as it requires little technical understanding of the rendering parameters associated with direct volume rendering.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In volume visualization, direct volume rendering has been widely used for the analysis and presentation of volumes in a variety of fields, ranging from medicine and engineering to geophysics and biology. Meanwhile, many classification methods based on the information extracted from the volume have been proposed to identify and analyze features of interest. However, the perception of complex structures inside the volume depends not only on the classification, but also on the rendering parameters, most particularly the viewpoint and lighting parameters. The viewpoint determines how many features can be presented in the rendered image. The lighting has a major impact on the viewer's perception of the shape and detail of features <ref type="bibr" coords="1,250.93,395.30,9.52,8.07" target="#b2">[3]</ref>. For example, the effect of specular reflections <ref type="bibr" coords="1,183.26,405.27,10.45,8.07" target="#b7">[8] </ref>assists the judgement of convexity/concavity and the perception of the smoothness of structural surfaces. While automatic viewpoint selection has received wide attention in volume visualization in recent years <ref type="bibr" coords="1,168.58,445.82,9.71,8.07" target="#b1">[2,</ref><ref type="bibr" coords="1,181.64,445.82,11.21,8.07" target="#b11"> 12,</ref><ref type="bibr" coords="1,196.20,445.82,11.21,8.07" target="#b24"> 25,</ref><ref type="bibr" coords="1,210.75,445.82,10.64,8.07" target="#b28"> 29]</ref>, relatively little research has considered the lighting design problem in direct volume rendering. During volume rendering, once the transfer function and the viewpoint are specified, the visual perception of features in the volume is mainly decided by the lighting parameters. A result of poor lighting design is that meaningful information is not conveyed effectively to the users, which undermines the fundamental goal of visualization . Unfortunately, the specification of appropriate lighting parameters is a very complex and labor-intensive process, especially for novices due to their limited technical understanding of the rendering process. Automatic lighting design has been well investigated for polygon rendering in computer graphics and isosurface rendering in scientific visualization. A perceptual quality metric <ref type="bibr" coords="1,186.95,576.04,14.94,8.07" target="#b23">[24] </ref>has been proposed to evaluate the ability of a rendered image to communicate information about the scene, and information entropy-based metrics (e.g., lighting entropy <ref type="bibr" coords="1,61.30,605.93,13.74,8.07" target="#b9">[10]</ref>, illumination entropy and multi-scale entropy <ref type="bibr" coords="1,244.83,605.93,14.34,8.07" target="#b25">[26]</ref>) have also been developed for automatic lighting design. Despite the fact that structural information plays a significant role in the human visual system (HVS) <ref type="bibr" coords="1,421.98,304.63,13.74,8.07" target="#b26">[27]</ref> , none of these existing methods have considered the use of structural information to evaluate the lighting parameters. They evaluate images rendered individually under different lighting configurations, but then fail to assess how well these configurations improve the presentation of structural information. In fact, evaluation of the enhancement of structural information that results from different lighting configurations can be implemented naturally for direct volume rendering. Direct volume rendering treats each voxel as a radiance emitter, and the basic information of features can be shown in a rendered image even without applying any external lighting. Hence, the quality of an external lighting configuration can be assessed by the amount of additional structural information conveyed by the lighting. Based on this observation, this paper presents a novel method to evaluate lighting quality based on the structural information in the rendered images, which is in line with the basic mechanism of the HVS. An approach is proposed to support highly automated configuration of the lighting for direct volume rendering. The main contributions are summarized as follows: 1) We propose a multi-scale homogeneity-weighted structural dissimilarity metric (MS-HWSD), which captures the difference in structural information between two images. When the MS-HWSD is applied to measure the dissimilarity between images rendered with and without external lighting (the illuminated and unilluminated images, respectively), it indicates the quality of the lighting configuration in terms of its ability to provide structural information. 2) We also put forward three lighting characteristics in terms of lighting goodness, lighting similarity and lighting stability in a similar fashion to the view characteristics <ref type="bibr" coords="1,431.57,585.50,9.71,8.07" target="#b0">[1,</ref><ref type="bibr" coords="1,443.83,585.50,6.47,8.07" target="#b1"> 2]</ref> . Lighting goodness measures the lighting quality based on the MS-HWSD from </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>@BULLET </head><p> (1); light similarity measures whether a light source is highly representative, and evaluates the complementarities between multiple light sources; lighting stability provides an extra measure on the light sources by considering the structural similarity of images rendered from neighboring light sources. 3) An automatic lighting design approach has been developed, based on the lighting characteristics proposed in (2). It supports the design of single and multiple light sources and can cope with different illumination models and find optimal solutions for various lighting parameters. To the best of our knowledge, this is the first paper to address structure-aware lighting design for volume visualization. The paper is structured as follows. Related work is discussed in Section 2, while Section 3 explains the motivation for the work, with further details. Section 4 describes the MS-HWSD, and in Section 5, we propose three lighting characteristics. Section 6 describes the automatic lighting design techniques. In Section 7, we present and discuss the results obtained by applying the proposed techniques to various volumes and validate their effectiveness by user studies. Finally, we draw conclusions in Section 8. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Lighting design has long been an active research topic in computer graphics, and many lighting design methods have been proposed over the years. Traditional methods usually directly manipulate the lighting parameters, such as the light position and intensity. The specification of appropriate lighting parameters in volume visualization is generally a trial-and-error data-exploration process, which is time consuming and labor intensive, especially for novice users. A great deal of attention has been paid to inverse lighting design, which is a major category of semi-automatic lighting design in computer graphics; it is surveyed in <ref type="bibr" coords="2,135.66,235.37,13.74,8.07" target="#b18">[19]</ref> . The general idea of inverse lighting design is to allow users to interact with the desired lighting effects through indirect user interfaces or to generate a desired lighting image through painting, based on which the lighting parameters are solved via optimization in an automatic manner. Poulin and Fournier <ref type="bibr" coords="2,257.93,275.22,14.94,8.07" target="#b20">[21] </ref>suggested direct manipulation of highlights and shadows to infer the optimal lighting parameters implicitly. Schoeneman et al. <ref type="bibr" coords="2,237.97,295.14,14.94,8.07" target="#b21">[22] </ref>optimized the lighting intensities at given positions to minimize the difference between the user-painted image and the rendered image. Pellacini et al. <ref type="bibr" coords="2,42.79,325.03,14.94,8.07" target="#b19">[20] </ref>proposed a non-linear optimization technique for a general painting interface to derive all the lighting parameters. However, the effectiveness of a painting interface is significantly less than direct and indirect interfaces, according to a later evaluation in <ref type="bibr" coords="2,214.01,354.92,13.74,8.07" target="#b13">[14]</ref> , mainly because the desired goal images are usually obtained by sketching rather than painting. Furthermore, without a clear definition of features at the data exploration stage, it is difficult to directly manipulate the lighting effects or to paint the desired lighting images in order to derive appropriate lighting parameters for volume visualization. Besides indirect and painting interfaces, several metrics have been proposed for automatic lighting design. Kawai et al. <ref type="bibr" coords="2,220.44,426.10,14.94,8.07" target="#b12">[13] </ref>presented subjective impressions of rendering qualities, such as pleasantness and privateness, which are maximized by optimizing lighting parameters. A perceptual quality metric involving six terms has been investigated for automatic lighting design by Shacked and Lischinski <ref type="bibr" coords="2,235.74,465.95,13.74,8.07" target="#b23">[24]</ref>. The goal is to evaluate the effectiveness in communicating information about the scene, such as shape, detail and relationships. No user study has been performed to validate this quality metric. Lighting entropy, which measures the brightness distribution of the visible pixels, has been used by Gumhold <ref type="bibr" coords="2,111.69,515.76,14.94,8.07" target="#b9">[10] </ref>to automatically determine the optimal light position, while Vázquez <ref type="bibr" coords="2,129.38,525.72,14.94,8.07" target="#b25">[26] </ref>developed illumination entropy and multi-scale entropy for lighting design by looking into color distribution and pixel correlation. However, all of these metrics are derived using the illuminated image only and do not take into account the presentation of structural information. In contrast, the proposed MS-HWSD in this paper follows the basic principles of the HVS by measuring structural differences between the unilluminated and illuminated images . Consequently, it can achieve considerably better results than those produced by existing methods. There are several methods for optimizing lighting parameters in visualization . Marks et al. <ref type="bibr" coords="2,114.29,626.79,14.94,8.07" target="#b17">[18] </ref>introduced Design Galleries to explore the parameter space for light selection and placement. It automatically generates and organizes rendered images under various lighting parameters , and allows users to select the lighting parameters by choosing satisfying images. LightKit developed by Halle and Meng <ref type="bibr" coords="2,257.93,666.64,14.94,8.07" target="#b10">[11] </ref>suggests the default light parameters of the three-point lighting model, while Light Collages presented by Lee et al. <ref type="bibr" coords="2,184.83,686.57,14.94,8.07" target="#b15">[16] </ref>places light sources for surfaces to support better shape perception. In direct volume rendering , Chan et al. <ref type="bibr" coords="2,89.11,706.49,10.45,8.07" target="#b3">[4] </ref> adaptively refined the ambient, diffuse and specular coefficients to enhance the image quality. The lighting parameters are adjusted by minimizing the information deviation between the image and ray at each pixel. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATION</head><p>This work is motivated by one of the basic assumptions of the HVS -that it is highly sensitive to structural information <ref type="bibr" coords="2,475.93,435.45,13.74,8.07" target="#b26">[27]</ref>. From this, the effectiveness of lighting can be assessed by the amount of structural information that is conveyed by the rendered image. Structural dissimilarity between two images can be quantified by calculating the variation of pixel colors in local regions. Direct volume rendering usually regards each voxel as an illuminating particle with a certain level of density, and the mapping from the density to the optical property is specified by the classification. Each feature is assigned a distinct optical property, so some basic structural information of features can be revealed expressively without using external lighting. The purpose of applying external lighting is to emphasize shape and to highlight details on the surfaces of structures. The proposed approach for structure-aware lighting design searches for lighting parameters that will make interesting structures more per- ceptible. An illuminated image can be thought of as the sum of an unilluminated image and the lighting effect, so the evaluation of the lighting effectiveness can be reasonably approximated by measuring the structural changes (i.e., dissimilarity) between the unilluminated and illuminated images. To this end, we introduce a structural dissimilarity metric (SDIM) to measure these changes. On the other hand, over-strong or improper illumination may lead to the loss of structural details, so some structural information may be reduced by the introduction of external lighting. We therefore introduce a homogeneity metric to distinguish between structural enhancement and structural weakening. By combining these two elements, this paper proposes a homogeneity-weighted structure dissimilarity metric (HWSD) to estimate the enhancement of structural information produced by the lighting . As the viewing conditions (e.g., image resolution and viewing distance) also have an important impact on the perceivability of <ref type="figure" coords="3,31.50,132.07,20.20,7.55">Fig. 2</ref>. The pipeline of homogeneity-weighted structural dissimilarity metric (HWSD). The structural dissimilarity metric (SDIM) measures perceptual structural differences between the unilluminated and illuminated images. The homogeneity metric (H) estimates how uniform the pixels are in a local region within an image, and is used to distinguish structural enhancement and degradation due to the lighting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>tural information </head><p>from the image, we extend the proposed metric to the multi-scale HWSD (MS-HWSD) to incorporate structural changes at different resolutions. A clear advantage of the MS-HWSD is that it reflects the characteristics of the HVS. <ref type="figure" coords="3,164.01,240.78,20.81,8.07" target="#fig_1">Fig. 1</ref>illustrates the power of the MS-HWSD. The three images in <ref type="figure" coords="3,153.46,250.74,20.38,8.07" target="#fig_1">Fig. 1</ref> (b)-(d) are rendered from different light positions. They have the same lighting entropy, as the information entropy-based metric is not sensitive to the HVS. The shape on the top of the engine and the detail on the structural surface are more clearly conveyed in <ref type="figure" coords="3,125.54,290.59,20.27,8.07" target="#fig_1">Fig. 1</ref>(b), and the MS-HWSD can generate a consistently perceived difference of visual structures similar to the HVS. Further, as in work on viewpoint selection, we propose three lighting characteristics: lighting goodness, lighting similarity and lighting stability, to assist the evaluation of different lighting configurations. While lighting goodness is purely based on the structure dissimilarity (i.e., the MS-HWSD), lighting similarity looks into the structural information revealed by different lights, and lighting stability helps to select stable light positions -these three elements form the basis of the proposed method for automatic lighting design. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MULTI-SCALE HOMOGENEITY-WEIGHTED STRUCTURAL DISSIMILARITY METRIC</head><p>The homogeneity-weighted structure dissimilarity metric (HWSD) is composed of the structural dissimilarity metric and the Homogeneity metric. The high-level procedure of the HWSD is shown in <ref type="figure" coords="3,246.35,451.92,19.81,8.07">Fig. 2</ref>. Structural Dissimilarity Metric. The Structural DissIMilarity metric (SDIM) is based on the Structural SIMilarity (SSIM) index measure introduced by Wang et al. <ref type="bibr" coords="3,164.81,486.22,13.74,8.07" target="#b26">[27]</ref>. The SSIM was originally used to evaluate the degradation of visual quality between a reference image and a distorted image; in this, it regarded image degradations as the perceived structural changes. In the context of lighting design, the unilluminated image and the illuminated image are considered as the reference image and the distorted image, respectively, and the SSIM is used to measure perceived structural changes between them. For completeness, we briefly review the SSIM. The SSIM measures the local structural similarity for each corresponding pair of pixels in their local neighborhoods. It separates the structural similarity measurement into three comparisons: luminance, contrast and structure. Suppose x and y represent the local neighborhoods from the unilluminated and illuminated images, respectively. The number of the pixels in each neighborhood is N (N = 11 × 11 is suggested in <ref type="bibr" coords="3,261.71,615.89,13.44,8.07" target="#b26">[27]</ref>). The luminance comparison is performed by the Gaussian weighted mean intensities </p><formula>µ x = ∑ N i=1 w i x i and µ y = ∑ N i=1 w i y i . </formula><p>The luminance function l(x, y) is defined as follows: </p><formula>l(x, y) = 2µ x µ y + c 1 µ 2 x + µ 2 y + c 1 , </formula><formula>(1) </formula><p>where c 1 is a constant based on the range of the pixel values and is included to avoid the introduction of a singularity. The luminance function gradually declines as the intensity of y increases. This formulation is qualitatively consistent with Weber's law, which states that a just-noticeable difference in the intensity change is approximately proportional to the original intensity, as the HVS is more sensitive to a relative change in luminance, rather than an absolute one. Similarly, the contrast function c(x, y) is an estimate of the signal contrast and is defined as: </p><formula>c(x, y) = 2σ x σ y + c 2 σ 2 x + σ 2 y + c 2 , </formula><formula>(2) </formula><p>where </p><formula>σ x = (∑ N i=1 w i (x i − µ x ) 2 ) 1/2 and σ y = (∑ N i=1 w i (y i − µ y ) 2 ) 1/2 , </formula><p> and the constant c 2 has the same functionality as c 1 . The contrast function monotonically decreases when the local variance of y becomes gradually different from that of x. This formulation also obeys the contrast masking feature of the HVS. The SSIM assumes that the structural information in an image is determined by the structure of objects in the scene, and is independent of the average luminance and contrast. Thus, the structural similarity is quantified through a correlation between the images, as follows: </p><formula>s(x, y) = σ xy + c 3 σ x σ y + c 3 , </formula><formula>(3) </formula><p>where σ xy defines the inner product between the vectors </p><formula>x − µ x and y − µ y , σ xy = ∑ N i=1 w i (x i − µ x )(y i − µ y )</formula><p>, and the constant c 3 has the same functionality as c 1 . The structure function decreases when the intensity in y increases in a manner uncorrelated to the intensity in x. The overall similarity measure is the composition of the three components , and the formulation of the SSIM is as follows: </p><formula>SSIM(x, y) = l(x, y) · c(x, y) · s(x, y) = (2µ x µ y + c 1 )(2σ xy + c 2 ) (µ 2 x + µ 2 y + c 1 )(σ 2 x + σ 2 y + c 2 ) </formula><p>, </p><formula>(4) </formula><p>where c 3 = c 2 /2 to simplify the formulation. It is worth pointing out that the three components are relatively independent. For example, a change of luminance or contrast does not influence the structure of the image. <ref type="figure" coords="3,322.69,406.24,21.46,8.07" target="#fig_3">Fig. 3</ref>shows two illuminated images of the vismale data set, together with their SSIM images. <ref type="figure" coords="3,421.60,416.20,20.64,8.07" target="#fig_3">Fig. 3</ref>(c)-(e) show the luminance, contrast and structure comparisons between (a) and (b), respectively. The SDIM proposed in this work is a distance metric for measuring structural differences between the unilluminated and illuminated images. The SDIM is the converse of SSIM, defined as follows: </p><formula>SDIM(x, y) = 1 − SSIM(x, y). </formula><formula>(5) </formula><p>As the SSIM value lies in (<ref type="bibr" coords="3,390.16,493.20,20.19,8.17">−1, 1]</ref>, the valid range of the SDIM is [0, 2), with higher values indicating higher structural dissimilarity. When the lighting has no effect on features in the illuminated image (i.e., x = y), the SDIM reaches its minimum 0. Loza et al. <ref type="bibr" coords="3,459.59,523.19,14.94,8.07" target="#b16">[17] </ref>introduced another structural dissimilarity definition DSSIM = 1 SSIM − 1. However, this is non-monotonic for the SSIM range (<ref type="bibr" coords="3,429.71,543.02,20.20,8.17">−1, 1]</ref>, so it is inappropriate for lighting quality evaluation. The SDIM measures structural differences in terms of the justnoticeable intensity, local contrast and structures of the features between the unilluminated and illuminated images. For instance, the specular reflection enhances shape perception of features <ref type="bibr" coords="3,502.71,592.93,9.52,8.07" target="#b7">[8]</ref>, and the SDIM can estimate these differences by the just-noticeable intensity change on the surfaces of features. Edges and contours contain a wealth of information about the structures of features <ref type="bibr" coords="3,496.38,622.82,13.74,8.07" target="#b14">[15]</ref>, and the SDIM can identify such information by evaluating the changes in local contrast due to the lighting. The SDIM can also capture the increasing of local variances of the details on the surface revealed by the lighting. Homogeneity Metric. By the symmetry of Equation 5, the SDIM measures only structural differences between the two images, without indicating which contains the clearer structures. This is sufficient for the evaluation of image degradation, where the reference image is known to have satisfactory quality, so the degradation must lie in the other image. However, as previously mentioned, in lighting design, additional external lighting may either enhance or diminish structural perception, such as the highlights in <ref type="figure" coords="3,429.15,736.38,20.48,8.07" target="#fig_3">Fig. 3</ref>(h), so we need to further distinguish between these possibilities when considering the effect of using external lighting. Insufficient and excessive illumination can both fail to present structural details effectively <ref type="bibr" coords="4,107.41,439.67,13.74,8.07" target="#b9">[10]</ref> , but insufficient illumination is not applicable to our approach. This is because, compared to the unilluminated image, lighting never locally decreases the brightness of features in the illuminated image (if the ambient lighting coefficient is 1), so we need merely to avoid over-illumination. In this work, the homogeneity metric is used to identify the over-lit areas in the illuminated image. Homogeneity is a metric indicating how uniform the pixels are in a local region within an image <ref type="bibr" coords="4,241.39,511.76,9.52,8.07" target="#b4">[5]</ref>. This is estimated by applying the standard deviation σ and the entropy e to a local neighborhood x of size N. The definition of the standard deviation σ x is the same as that of the contrast function of the SSIM, and the formulation of the entropy e x in the local region is defined as follows: </p><formula>(a) (b) (c) (d) (e) (f) (g) (h) (i) (j) </formula><formula>e x = − ∑ J j=1 p j logp j , where p j = #x i = j N </formula><p>is the probability of the pixel value at the j-th bin of the histogram of x, and the intensity level in the histogram is J. The maximum entropy occurs when all pixel values in x are different (at different bins of the histogram), and the entropy reaches its minimum when all pixel values are in the same bin of the histogram. Although the original homogeneity definition in <ref type="bibr" coords="4,204.44,627.00,10.45,8.07" target="#b4">[5] </ref>further contains the edge value and the 4-th moment of the intensity distribution components , we found that, in practice, they make little contribution to the lighting design results, and a reduced form offers an equivalent capability of evaluating the uniformity and improves the computational efficiency. For example, the use of the original homogeneity generates the same optimal light source as the reduced form for the engine data set in <ref type="figure" coords="4,45.04,696.74,20.34,8.07" target="#fig_7">Fig. 5</ref>(a). Hence, we define the homogeneity metric of a local region x as follows: </p><formula>H(x) = (1 − σ x σ max )(1 − e x e max ), (6) </formula><p> where σ max and e max are the maximum values of the standard deviation and the entropy in both unilluminated and illuminated images, respectively. The homogeneity increases when the intensities in the local region become much more similar. The valid range of the homogeneity is <ref type="bibr" coords="4,321.98,447.20,9.45,7.96">[0,</ref><ref type="bibr" coords="4,332.42,447.30,6.14,8.07" target="#b0"> 1]</ref>, with higher values indicating higher uniformity. When the illuminated image is compared to the unilluminated image , the homogeneity metric provides a good measure of the structural weakening from over-illumination -a large increase of homogeneity implies the creation of more flat regions due to the use of lighting that is too strong, while a significant decrease suggests structural enhancement resulting from lighting that is more appropriate. Homogeneity-Weighted Structural Dissimilarity Metric. We combine the structural-dissimilarity metric and the homogeneity metric to form a Homogeneity-Weighted Structural Dissimilarity metric (HWSD) as follows: </p><formula>HW SD(x, y) = SDIM(x, y)(H(x) − H(y)), </formula><formula>(7) </formula><p> where H(x) and H(y) are the homogeneity values of the local neighborhoods x and y from the unilluminated and illuminated images, respectively . The HWSD value grows quickly when the lighting reveals structures more clearly than the unilluminated image. The HWSD utilizes the difference of the homogeneity values to distinguish structural enhancement and degradation. When the lighting enhances the structures in the illuminated image, the homogeneity value H(y) decreases compared to H(x), and this results in a positive HWSD value. Higher positive HWSD values represent more structural enhancement in the illuminated image. On the other hand, when the lighting weakens the structures in the illuminated image, for example , over-illumination produces more flat and less structural regions with the increased homogeneity value H(y), and this leads to a negative HWSD value to penalize this situation. Negative HWSD values indicate that the external lighting actually diminishes the overall structural perception in the illuminated image. Figs. 3(g) and (j) show two HWSD results. Compared to <ref type="figure" coords="5,137.60,195.86,19.91,8.07" target="#fig_3">Fig. 3</ref> (g), the HWSD values of the overilluminated region in <ref type="figure" coords="5,107.45,205.82,19.72,8.07" target="#fig_3">Fig. 3</ref>(h) are negative in the corresponding region in <ref type="figure" coords="5,40.72,215.78,19.48,8.07" target="#fig_3">Fig. 3</ref>(j). Since the SDIM and homogeneity metric are both defined in local neighborhood regions, the HWSD preserves the information of the pixels' correlation properly, which is an important factor in lighting design <ref type="bibr" coords="5,58.53,255.76,13.74,8.07" target="#b25">[26]</ref>. In contrast to the symmetry of SSIM and SDIM, the HWSD is not commutative, as HWSD(x, y) = -HWSD(y, x). The valid range of the HWSD is (−2, 2). Multi-Scale HWSD. As the perceptibility of structural information in the image depends on its resolution and viewing distance, a single-scale method may be inappropriate for all lighting evaluations. Additionally, the multi-scale extension of SSIM (MS-SSIM) proposed in <ref type="bibr" coords="5,40.31,330.20,13.74,8.07" target="#b27">[28]</ref>, has proven to produce better results than the single-scale SSIM for image quality assessment. We propose a multi-scale HWSD metric (MS-HWSD) to evaluate the structural enhancement generated by the lighting at different resolutions . A low-pass filter is employed to downsample the unilluminated and illuminated images successively by a factor of 2, and the HWSD is applied to the filtered images at each scale. The MS-HWSD is obtained by averaging all single-scale HWSD values as follows: </p><formula>MS-HW SD(X,Y ) = 1 N s N s ∑ j=1 ( 1 M j M j ∑ i=1 HW SD(x j i , y j i )), </formula><formula>(8) </formula><p> where X and Y are the unilluminated and illuminated images, respectively , x j i and y j i are the local neighborhoods at the i-th pixel of the filtered unilluminated and illuminated images at the j-th scale, M j is the total number of pixels in the filtered image at the j-th scale, and N s is the number of scales used. The inner summation is a mean HWSD, which evaluates the overall structural enhancement at the j-th scale by taking the average over all pixels in the image. As the MS-HWSD incorporates all enhancements of the structural information at the multiple scales, it improves the efficiency and robustness of the HWSD. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LIGHTING CHARACTERISTICS</head><p> As mentioned in Section 3, to evaluate and compare different lighting configurations, we propose three lighting characteristics: lighting goodness, lighting similarity and lighting stability. Lighting Goodness. Lighting goodness measures the effectiveness of different lighting configurations in terms of conveying structural information. External lighting may improve various aspects of structural perception, such as the shape of features, details of surfaces and feature occlusion relationships. A lighting configuration is good if it reveals a greater level of structural information. The SDIM is designed to measure the structural changes between unilluminated and illuminated images, and the MS-HWSD identifies the structurally enhanced regions in the illuminated image at different scales. Thus, the MS-HWSD can be used to measure lighting goodness -it is desirable that the lighting has a high MS-HWSD value. <ref type="figure" coords="5,216.07,706.49,21.02,8.07" target="#fig_5">Fig. 4</ref>shows three rendered results under different light configurations. In terms of the MS-HWSD, <ref type="figure" coords="5,79.27,726.42,21.01,8.07" target="#fig_5">Fig. 4</ref>(c) has the highest value, while <ref type="figure" coords="5,220.72,726.42,21.01,8.07" target="#fig_5">Fig. 4</ref>(a) has the lowest value. Lighting Similarity. Lighting similarity estimates the similarities with regard to the structural information revealed by different lighting configurations. This is a very useful measure to see whether a light source is highly representative, and also to judge the complementarities between two light sources. The multi-scale extension of SSIM (MS-SSIM) <ref type="bibr" coords="5,476.47,103.27,14.94,8.07" target="#b27">[28] </ref> is a good metric to evaluate the structural similarity of illuminated images under different lighting configurations. To compare two different lighting configurations, the MS-SSIM is calculated directly based on two illuminated images, in contrast to the MS-HWSD based on the unilluminated and illuminated images. Two lighting configurations with a high MS-SSIM value are similar, as they convey a great deal of similar structural information in their illuminated images. However, lighting similarity based on the MS-SSIM is not transitive, i.e., if lighting configuration A is similar to lighting configuration B and C, it does not mean light configuration B is similar to light configuration C, and actually the illuminated images under lighting configuration B and C may be significantly different. In <ref type="figure" coords="5,422.84,222.82,21.00,8.07" target="#fig_5">Fig. 4</ref>, the lighting configuration in <ref type="figure" coords="5,304.28,232.78,21.00,8.07" target="#fig_5">Fig. 4</ref>(c) is the most similar to that in <ref type="figure" coords="5,448.31,232.78,20.83,8.07" target="#fig_5">Fig. 4</ref>(b), and the lighting configuration in <ref type="figure" coords="5,354.89,242.74,20.80,8.07" target="#fig_5">Fig. 4</ref>(a) is the most dissimilar to the other lighting configurations. Lighting similarity can be used to search for representative lighting configurations. If a lighting configuration is similar to many others, it is representative and hence is a good candidate for conveying the corresponding structures. Another application of lighting similarity is that the design of multiple light sources should consider lights that, individually, produce low similarity as they can enhance the perception of different structures. Lighting Stability. Lighting stability indicates the amount of change of structural perception when the position of a light source is moved within a small neighborhood. It can be also evaluated through the MS-SSIM. The MS-SSIM is applied successively to the image illuminated from the current investigated lighting position and the images illuminated from each of a set of neighbouring positions. These MS- SSIM values are summed to obtain the quantified stability value for the current lighting position; a larger stability value implies a more stable light source. In lighting design, lighting stability can be integrated with lighting goodness to help choose an optimal light in terms of both structural perception and stability. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">AUTOMATIC LIGHTING DESIGN</head><p>Many illumination models can be used for direct volume rendering. Without loss of generality, let us firstly consider the Blinn-Phong local illumination model. This model can be calculated in real time, and hence is well suited to fast quality evaluation of the lighting. Formally, the color of a rendered voxel can be expressed as: </p><formula>C = (k a + k d ( ˆ N · ˆ L))C T F + k s ( ˆ N · ˆ H) n , </formula><formula>(9) </formula><p>where k a , k d , and k s are the ambient, diffuse, and specular lighting coefficients respectively, n is the shininess exponent, C T F is the color from the transfer function, ˆ N is the normalized gradient direction of the voxel, ˆ L is the light direction, andˆHandˆ andˆH is the normalized half-way direction. In order to distinguish features in the visual representation, the color from the transfer function is used for the ambient and diffuse components. Light sources are chosen to be white to preserve the original hue for the visual labeling of features, and this is applied only to the specular component. First, we consider the selection of the light position for a single point light source at a fixed viewpoint. The candidate positions for the light source are considered to be located on a fixed-distance bounding sphere in the volume, referred to as the light-position sphere. The HEALPix package <ref type="bibr" coords="5,363.54,676.49,10.45,8.07" target="#b8">[9] </ref>is used to generate evenly distributed candidate positions over the light-position sphere. A number of candidate positions (we use 768) are generated as the initial candidates. The algorithm evaluates the MS-HWSD values of these candidate positions, and then generates sampling positions in regions where the MS-HWSD values are highest to further search for the optimal light position that is, the one with the highest value. The optimal light position for the engine data set is shown in <ref type="figure" coords="6,229.80,266.22,20.10,8.07" target="#fig_7">Fig. 5</ref>(a), in which the shape of large structures and the detail on the top surface are clearly revealed. A deformed light-position sphere is illustrated in <ref type="figure" coords="6,22.50,296.11,20.48,8.07" target="#fig_7">Fig. 5</ref>(b) for the lighting quality comparison (the MS-HWSD) of this selection. It is clear that, for the engine data set viewed from this point, there are three areas of high lighting quality. Multiple Light Sources. The automatic design process for single light sources can be extended to consider the design when using multiple light sources. A possible approach would be to search for the optimal light positions by evaluating all possible combinations of the candidate positions, though this has the obvious shortcoming of poor scalability with the number of light sources. If M is the number of the candidate positions and K is the number of light sources, there are O(M K ) lighting configurations. In practice, users usually place light sources one by one. Although this may not lead to the globally optimal configuration, it is easy and flexible for users, and it allows straightforward use of the MS-HWSD. After the first optimal light source has been selected, the image rendered under the first light source serves as the unilluminated image for the next selection. Thus, light sources can be added successively until a satisfactory result is obtained. This approach scales well with the number of light sources, as the computational complexity is O(MK). During the design of multiple light sources, it is desirable that different light sources reveal different structural information. Two light sources positioned closely together will put light energy into similar regions; while this may make, for example, the areas near edges more perceptible by increasing the contrast, it does not introduce any additional structural information. For this, we use lighting similarity as a second criterion in the search for the next light source. This light source should not only further enhance structural information in the rendered image but should also have low similarity in relation to each of the previously selected light sources. Thus, the measure for the next light source l is modified as follows: </p><formula>E(l) = αMS-HW SD(X,Y ) + (1 − α) 1 K s K s ∑ i=1 MS-SDIM(Z l , Z i ), (10) </formula><p> where X is rendered by all previously selected light sources, Y is rendered by adding the current light source l, Z l and Z i are rendered individually under the light source l and the i-th selected light source, respectively, and K s is the number of previously selected light sources. The MS-SDIM is the multi-scale extension of SDIM as follows: </p><formula>MS-SDIM(Z l , Z i ) = 1 − MS-SSIM(Z l , Z i )</formula><p>, where the MS-SSIM <ref type="bibr" coords="6,257.93,696.53,14.94,8.07" target="#b27">[28] </ref>is the multi-scale SSIM. The parameter α in the range <ref type="bibr" coords="6,219.24,706.39,9.46,7.96">[0,</ref><ref type="bibr" coords="6,229.69,706.49,6.97,8.07" target="#b0"> 1] </ref>is used to balance the structural enhancement in the first term and the dissimilarity between the light sources in the second term. The user can adjust α according to their specific applications. If α = 0, the user obtains a light source which is most dissimilar to the previously selected light sources, while if α = 1, the next light source has the highest lighting goodness value, but lighting similarity is not considered. From our experiments, α = 0.4 offers a good balance. Using multiple light sources significantly improves the results. <ref type="figure" coords="6,285.12,317.18,20.04,8.07" target="#fig_7">Fig. 5</ref>(c) depicts the optimal configuration of two light sources for the engine data set. Compared to <ref type="figure" coords="6,393.46,327.14,19.96,8.07" target="#fig_7">Fig. 5</ref>(a), more structural details can be perceived under two light sources, especially the details on the side of the engine. Other Lighting Parameters. Apart from introducing additional light sources, other parameters of the light source can also be adjusted automatically to provide better structure perception, based on the MS- HWSD. These include the diffuse and specular coefficients and the shininess exponent. The optimal lighting parameter is sought in the parameter domain by iteratively evaluating the goodness measure of the current lighting parameters for each light position. An extension from using point light sources to directional light sources is also straightforward , as the light direction can be directly sampled on the bounding sphere of the volume as for the light position. <ref type="figure" coords="6,448.45,456.53,19.89,8.07" target="#fig_7">Fig. 5</ref> (d) shows the optimal shininess exponents for the two optimal light sources in <ref type="figure" coords="6,502.38,466.49,19.76,8.07" target="#fig_7">Fig. 5</ref>(c). Other Illumination Models. As the lighting design method requires only unilluminated and illuminated images, it can easily be applied to other illumination models. Local illumination models, such as Blinn-Phong, primarily reveal the structural shape and local details, while global illumination models further depict the occlusion relationships between structures through mutual shadowing. Thus, we integrate shadows into direct volume rendering and employ our approach to select the optimal lighting parameters . Shadows can increase the MS-HWSD value by introducing the shadowing edges, which is a clear occlusion aspect of the spatial relationships between features. On the other hand, as shadows remove lighting from features, the MS-HWSD value would be reduced compared to local illumination models, and this is helpful for avoiding the over-shadowing associated with complex geometries, which produces complex, highly structured cast shadows that reduce structural perception. Thus, the MS-HWSD favors a light position with a good balance between the benefits of the shadowing edges introduced and the drawbacks of over-shadowing. <ref type="figure" coords="6,411.25,656.81,21.04,8.07" target="#fig_9">Fig. 6</ref>shows the optimal results of the light position for a vortex data set without and with shadowing. Compared to the rendered result without shadowing in <ref type="figure" coords="6,487.73,676.73,20.42,8.07" target="#fig_9">Fig. 6</ref>(a), the rendered result in <ref type="figure" coords="6,349.42,686.69,19.95,8.07" target="#fig_9">Fig. 6</ref> (b) provides more information about the structure arrangement by the inclusion of shadows, but does not have so many shadow regions that the local contrast of structures is reduced. Stable Light Source. In some applications, users require stable lighting conditions. For this, lighting stability can be integrated with lighting goodness, with the modified lighting quality being defined by: </p><formula>E(l) = β MS-HW SD(X,Y ) + (1 − β ) 1 K n K n ∑ i=1 MS-SSIM(Y, Z i ), (11) </formula><p>where X is the unilluminated image, Y is an illuminated image under the light source l, and Z i is an illuminated image under the i-th neighbor light position, K n is the number of neighbor light positions (K n = 8 is satisfactory), and the parameter β is in the range <ref type="bibr" coords="7,215.43,343.91,9.46,7.96">[0,</ref><ref type="bibr" coords="7,225.88,344.01,6.14,8.07" target="#b0"> 1]</ref>. The lighting quality is a weighted combination of the structural enhancement in the first term, and the stability between the light being considered and its neighbors in the second term. Users can adjust β according to their needs; if β is reduced, the selected light source becomes more stable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RESULTS AND DISCUSSION</head><p>We have implemented the automatic lighting design discussed above. The rendered results are generated through pre-integrated direct volume rendering <ref type="bibr" coords="7,85.96,439.16,9.52,8.07" target="#b6">[7]</ref>, which is implemented in a GPU-based ray-casting volume renderer. The shadow ray technique is integrated into the volume renderer to compute shadow effects. The unilluminated and illuminated images are two 512 × 512 floating-point textures. The MS-HWSD is applied to the intensity channel of gray images, while for the color images, it is obtained by summing the MS-HWSD values calculated for the R, G, B components individually. As the HVS normally uses intensity variations to determine shape, the sum is a rough approximation of the intensity. On the other hand, as different features are often classified by distinct colors, the separate evaluation can preserve this visual labeling information of features. The number of scales used for results presented in this paper is 4. The MS-HWSD and MS-SSIM evaluation are performed on the GPU, which improves the computational efficiency by exploiting the massive parallelism of the GPU and avoiding texture read-back. Although the computational times for the automatic lighting design from a fixed viewpoint depend greatly on the data set due to the need to render the illuminated images, the computational times for the MS-HWSD evaluation are relatively fixed. In our experiments with image sizes of 512 × 512, the average evaluation was about 12 seconds for all 768 light positions on an Intel Core i5 760 (2.80 GHz) processor with an NVIDIA GeForce GTX 470. The proposed automatic lighting design approach is used to seek an adequate configuration of the lighting parameters. We now consider the effectiveness of each of the three lighting characteristics described in Section 5. Lighting Goodness. Figs. 5 and 6 show the lighting design results of the engine and vortex data sets based on the proposed lighting goodness criterion for single light source, two light sources and shadowing . The selected light sources improve shape and detail perception by enhancing local contrast, and introduce shadows which assist the understanding of spatial occlusion relationships. As can be seen from <ref type="figure" coords="7,381.60,73.44,20.30,8.07" target="#fig_7">Fig. 5</ref> (b), the lighting qualities above the engine are better than those behind it. This is usually true for opaque objects, as the front surfaces receive less lighting from lights behind the object to enhance the visual contrast of the global structures and surface details, and this makes them less perceptible for scene interpretability . The selection of the first light source for opaque objects is similar to the key light in the three-point lighting model, which is a standard method used in visual media. However, there is a significant difference: each voxel of the volume is taken as a radiance emitter, while the subject in the three-point lighting model usually does not emit lights. Nevertheless, we can still follow the principles of threepoint lighting, for example we can apply the MS-HWSD only to the light positions within the valid range of the key light and search for the optimal key light for opaque objects. The light behind the scene, called the rim light in the three-point lighting model, is normally used to visually separate the subject from the background. In volume visualization, a light behind transparent structures can also produce good visual perception as the radiance will not be occluded by the back structures and can traverse the whole volume to reveal the internal structures clearly. In <ref type="figure" coords="7,467.24,262.90,20.17,8.07" target="#fig_5">Fig. 4</ref>(a), the optimal light position selected by lighting entropy <ref type="bibr" coords="7,444.18,272.86,14.94,8.07" target="#b9">[10] </ref>is located at the back of the light-position sphere. <ref type="figure" coords="7,388.30,282.82,20.58,8.07">Fig. 7</ref> (d) gives another example for the engine data set. The global structure of the engine in the unilluminated image is very clear due to the appropriate classification, but the light source selected by the MS-HWSD provides shape and boundary cues for the internal structures and it also conveys more structural details on the left and right surfaces of the engine. As the radiance from the external light is slightly absorbed in the transparent structures, its contribution to the rendered result is limited . It is not easy to recognize the lighting effects on transparent structures. Thus, automatic lighting design approaches usually favor structures that are more opaque. This is reasonable in volume visualization , since the users often highlight important structures with a high opacity value to make them more visible during the classification process. <ref type="figure" coords="7,327.22,412.51,21.32,8.07" target="#fig_10">Fig. 8</ref>shows an example for the vismale head data set. The skin is set transparent to make the skull visible. Although there may be many structural details on the skin, the optimal light sources selected by lighting entropy, multi-scale entropy <ref type="bibr" coords="7,442.32,442.40,14.94,8.07" target="#b25">[26] </ref>and the MS-HWSD all improve structure perception much more for the skull than for the skin. In addition, it is difficult to enhance the perception of transparent structures against a white background, as white light enhances the luminance value of sampled points during the ray casting, and this makes the illuminated color and the background hard to distinguish. Three methods have been used to select the optimal light sources for the seven volume data sets used in the visual comparisons in <ref type="figure" coords="7,520.63,512.31,20.50,8.07" target="#fig_5">Fig. 4</ref>, <ref type="figure" coords="7,294.12,522.27,38.19,8.07">Fig. 7 and</ref><ref type="figure" coords="7,335.61,522.27,20.85,8.07" target="#fig_10">Fig. 8</ref>. Lighting entropy prefers lighting effects with an even intensity distribution. As the unilluminated image of the hydrogen atom data set has many areas of high intensity, the optimal light source is selected by lighting entropy to retain the original dark areas, as shown in <ref type="figure" coords="7,341.24,562.12,20.69,8.07" target="#fig_5">Fig. 4</ref>(a). This lighting makes little contribution to the internal shape perception compared to the other selected light sources. Multi-scale entropy is based on 4 levels of Haar wavelet decomposition and is calculated by the Shannon entropy of the wavelet coefficients . Thus, multi-scale entropy prefers an even distribution of the wavelet coefficients. As shown in <ref type="figure" coords="7,415.36,611.93,19.55,8.07">Fig. 7</ref>(b), the result from multi-scale entropy is more easily affected by rendering artifacts, as these tend to make the intensity distribution of the wavelet coefficients more even. The MS-HWSD is derived from the principles of the HVS, and the optimal lighting parameters found by the MS-HWSD generate rendered images that convey the most significant structural information compared to the unilluminated image, such as the shape in <ref type="figure" coords="7,512.48,671.71,20.81,8.07">Fig. 7</ref>(b) and the detail in <ref type="figure" coords="7,356.15,681.67,20.44,8.07">Fig. 7</ref> (d). The MS-HWSD prefers lighting parameters that render images with better luminance, contrast and structure enhancements, as shown in <ref type="figure" coords="7,393.74,701.60,23.17,8.07" target="#fig_3">Fig. 3.</ref>Lighting Similarity. <ref type="figure" coords="7,388.65,716.45,22.42,8.07" target="#fig_7">Fig. 5</ref>shows the effectiveness of lighting similarity in the design of multiple light sources. <ref type="figure" coords="7,481.03,726.42,20.78,8.07">Fig. 7</ref>(f) presents an example for a tomato data set. The two light sources selected <ref type="figure" coords="8,22.50,203.63,19.48,7.55">Fig. 7</ref>. Visual comparison of three lighting design methods for five volume data sets. The optimal lighting parameters from left to right in each sub-figure are selected using lighting entropy, multi-scale entropy and the proposed MS-HWSD, respectively: (a) tooth, (b) teapot, (c) daisy pollen grain, (d) engine, (e) tomato with one light source, (f) tomato with two light sources. by lighting entropy are spatially separated, as it also considers light source independence based on conditional entropy. However, multiscale entropy does not take into account light source independence, and hence the selected light sources have a high overlap of illumination . In the proposed greedy approach, lighting similarity is used as the light source independence criterion to select the next light source. Although it may not find the same light sources as the brute-force approach (<ref type="figure" coords="8,53.83,486.93,21.73,8.07" target="#fig_7">Fig. 5</ref> has the same light sources as selected by the bruteforce approach, but the light sources in <ref type="figure" coords="8,171.77,496.90,20.84,8.07">Fig. 7</ref> (f) are slightly different from the brute-force approach), the proposed greedy approach has good scalability and can obtain a satisfactory result. Furthermore, the user can adjust the parameter α to balance the structural enhancement and the dissimilarity between the light sources. </p><formula>(a) (b) (c) (d) (e) (f) </formula><formula>(a) (b) (c) (d) (e) </formula><p>An example in which representative light sources are selected is shown in <ref type="figure" coords="8,58.90,576.98,24.06,8.07">Fig. 9.</ref><ref type="figure" coords="8,88.38,576.98,21.07,8.07" target="#fig_7">Fig. 5</ref>(b) is the deformed light-position sphere for the selection of the first representative light source, which is the one with the highest MS-HWSD value, as shown in <ref type="figure" coords="8,202.68,596.90,20.76,8.07" target="#fig_7">Fig. 5</ref>(a). We then select as the next representative light source, the one with the smallest similarity to the previously selected light sources -this is expected to reveal structural information that was not presented by the previous light sources. This corresponds to the case α = 0 in Equation 10. The deformed similarity sphere compared to the first representative light source is displayed in <ref type="figure" coords="8,126.33,656.68,20.86,8.07">Fig. 9</ref>(a), and the second representative light source is selected from this sphere. As shown from the deformed light-position sphere, the worst light position in <ref type="figure" coords="8,192.85,676.60,19.83,8.07" target="#fig_7">Fig. 5</ref> (b) does not necessarily have the smallest similarity with the optimal light position. Similarly, <ref type="figure" coords="8,59.63,696.53,31.20,8.07">Fig. 9(b)</ref>shows the deformed similarity sphere compared to the first two representative light sources, and the third representative light source can be selected from this sphere. These three representative light sources collectively give a good visualization of the engine data set by revealing different structures through lighting effects. Lighting Stability. <ref type="figure" coords="8,372.39,417.20,31.58,8.07" target="#fig_10">Fig. 8(d)</ref>shows the most stable light position for the vismale data set, and the optimal light source based only on the MS-HWSD is shown in <ref type="figure" coords="8,384.91,437.12,19.62,8.07" target="#fig_10">Fig. 8</ref>(c). The most unstable light position is usually opposite the viewpoint and produces few lighting effects on structures. In this case, a small deviation from the most unstable light position would generate significantly different lighting effects. Lighting goodness and lighting stability are combined in Equation 11 to search for a stable and good light source. As shown in <ref type="figure" coords="8,487.09,486.94,19.72,8.07" target="#fig_10">Fig. 8</ref>(e) with β = 0.4, the shape and local details on the frontal skull are more easily perceptible. User Study. A user study was performed to verify that the proposed MS-HWSD is an effective lighting goodness metric by comparing two images with the same volume and viewpoint, but with different light positions. We randomly selected 20 pairs of light positions for each of the vismale and engine data sets illustrated in <ref type="figure" coords="8,511.05,565.97,24.44,8.07;8,285.12,575.94,21.11,8.07" target="#fig_3">Figs. 3  and 5</ref>, respectively. As in the viewpoint comparison, it is effective to compare pairs with nearby light positions as the lighting effects of the pairs are sufficiently different to allow comparisons but not so different that the comparisons become meaningless. We used an angular separation of π(b) <ref type="figure" coords="9,31.50,197.01,19.03,7.55">Fig. 9</ref> . Lighting similarity analysis for the engine data set. The lightingsimilarity sphere is deformed and colored similar to the deformed lightposition sphere. Blue light positions are more dissimilar to the previous selected light source(s) than red ones. (a) The lighting-similarity sphere compared to the optimal light source, as shown in <ref type="figure" coords="9,216.95,234.86,19.70,7.55" target="#fig_7">Fig. 5</ref>(a). (b) The lighting-similarity sphere compared to the first two light sources. each pair was compared by 9-23 users. <ref type="figure" coords="9,41.46,290.28,25.22,8.07" target="#fig_1">Fig. 10</ref>(b) </p><p>shows, for each pair and each data set, the proportion of the tests in which the image with the higher MS-HWSD value was selected. For 35 of the 40 pairs (87.5%), the image with the higher MS-HWSD value was chosen in more than 50% of the selections; for 23 (more than half) of the pairs, the selection rate was greater than or equal to 80%. Overall, the user preferences were consistent with the MS-HWSD comparison in 78.9% of the pairs (521 comparisons). The lowest percentage achieved was 33.3%, for the 15th pair of the engine data set. In this pair, the image with the overall higher MS- HWSD value had highlights in some regions, and it was found that users generally do not like highlights. However, with minor exceptions , the MS-HWSD proved itself a good lighting quality metric for measuring the enhancement of structural information. Another user study was conducted to find out if the proposed approach identifies a better optimal light source in terms of structural information than other methods, from the user's point of view. Users viewed test sets and were asked to select which image reveals the object's structural information best. Lighting entropy, multi-scale entropy and the MS-HWSD were compared using the eight sets of images shown in Figs. 4, 7 and 8, which include seven with a single light source and one with two light sources. The test sets were presented in a random order, and the three images in a test set were also displayed randomly. The images were analyzed by 36 users, some of whom had previous knowledge of volume rendering. <ref type="figure" coords="9,41.46,534.03,27.10,8.07" target="#tab_1">Table 1</ref> shows the statistics from the data collected. Users generally preferred the lighting parameters selected by the MS-HWSD over those from lighting entropy and multi-scale entropy. For a single light source, the selection percentages of the MS-HWSD were highest in six of the seven test sets, the exception being the pollen. In the tomato test set, 66.67% preferred the MS-HWSD an absolute majority of the users. For multiple light sources (tomato2), the proposed approach based on the MS-HWSD and lighting similarity was again found to provide better lighting parameters than other two. For the pollen data set, the multi-scale entropy performed better than the MS-HWSD; this may be accounted for by the fact that the light sources selected by the multi-scale entropy and MS-HWSD are similar and the users found it difficult to decide which is the best. For the engine, while the light source selected by the MS-HWSD reveals more detail information on the surface, the selection percentage of the MS-HWSD is not much higher than that of the multi-scale entropy. This may be because users often prefer clear global structures to clear local details. The users were also asked about the reasons for their selections. One noticeable comment for the teapot data set was that illumination effects make the teapot lid clearer. For each pair of images, the proportion of selections in which the image with the higher MS-HWSD value was chosen. Limitations. Since the definition of a good lighting configuration is highly subjective and depends greatly on the specific application, it is hard to generate absolutely optimal lighting parameters for all situations. This also explains the variations in the results from our user studies. For the MS-HWSD, we simply average all single-scale HWSD values. Although it worked well in our experiments, it would be better to use an image synthesis-based approach, similar to that used in MS-SSIM <ref type="bibr" coords="9,342.48,423.63,13.74,8.07" target="#b27">[28]</ref>, to calibrate the weight of each scale, as the relative importance between different scales may be different. As in lighting entropy and multi-scale entropy, the proposed MS- HWSD is an image-space-based metric. It may be beneficial to integrate object-space information for automatic lighting design, such as the importance of features, and domain knowledge may also be important for the lighting design in specific applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>In this paper, we have presented a structure-aware automatic lighting design approach for volume visualization. The basic idea is to measure the structural differences between images with and without external illumination at different resolutions in order to quantify the quality of the lighting configurations. We proposed three lighting characteristics: lighting goodness, lighting similarity and lighting stability, on which to base automatic lighting design techniques. Our experiments, together with the user study, demonstrated the effectiveness of the proposed techniques, which release users from the intensive and laborious work needed to find the optimal lighting configuration. Since the proposed automatic lighting design searches only for the optimal lighting parameters for a fixed viewpoint, we plan to extend the proposed method to support interactive viewpoint changes. One possible solution is to optimize the pre-computed lighting parameters on the viewing sphere. In addition, we will extend the proposed lighting design techniques to time-varying volumes. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,285.12,322.21,250.38,7.55;2,285.12,331.67,250.38,7.55;2,285.12,341.14,250.39,7.55;2,285.12,350.60,250.38,7.55;2,285.12,360.06,250.38,7.55;2,285.12,369.53,250.38,7.55;2,285.12,378.99,236.14,7.55"><head>Fig. 1. </head><figDesc> Fig. 1. Lighting quality evaluation based on the MS-HWSD. All three illuminated images have the same lighting entropy 2.41, but different MS- HWSD values for different lighting parameters. Higher MS-HWSD values mean the lighting reveals structural information more clearly compared to the unilluminated image. (a) The unilluminated image. (b) Illuminated image with MS-HWSD = 0.324. (c) Illuminated image with MS-HWSD = 0.249. (d) Illuminated image with MS-HWSD = 0.234. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,22.50,309.84,513.01,7.55;4,22.50,319.31,513.00,7.55;4,22.50,328.77,513.00,7.55;4,22.50,338.23,513.00,7.55;4,22.50,347.70,513.00,7.55;4,22.50,357.16,513.00,7.55;4,22.50,366.63,513.00,7.55;4,22.50,376.09,308.30,7.55"><head>Fig. 3. </head><figDesc>Fig. 3. SSIM and HWSD results of the vismale data set under two different light sources. Darker areas in SSIM results indicate larger structural differences between the unilluminated and illuminated images. Brighter areas in HWSD results mean greater structural enhancement between the unilluminated and illuminated images. The mean SDIM [= (1 -SSIM)] of the illuminated image (b) is lower than the value of the illuminated image (h), but the mean HWSD of (b) is larger than the value of (h). This is because the homogeneity metric successfully distinguishes enhancement and degradation in structural perception, and the HWSD values of the over-illuminated region in (h) are negative in the corresponding region in (j). (a) The unilluminated image. (b) An illuminated image. (c) The SSIM's luminance comparison of (a) and (b). (d) The SSIM's contrast comparison of (a) and (b). (e) The SSIM's structure comparison of (a) and (b). (f) The SSIM result of (a) and (b). (g) The HWSD result of (a) and (b). (h) Another illuminated image. (i) The SSIM result of (a) and (h). (j) The HWSD result of (a) and (h). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,31.50,126.38,250.39,7.55;5,31.50,135.85,250.38,7.55;5,31.50,145.31,250.38,7.55;5,31.50,154.78,250.38,7.55;5,31.50,164.24,153.58,7.55"><head>Fig. 4. </head><figDesc> Fig. 4. Visual comparison of three lighting design methods for a hydrogen atom data set. The sphere in the bottom-left corner is used to illustrate the lighting effect. (a) Optimal light source using lighting entropy . (b) Optimal light source using multi-scale entropy. (c) Optimal light source using the proposed MS-HWSD. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="6,22.50,197.01,513.00,7.55;6,22.50,206.48,513.00,7.55;6,22.50,215.94,512.99,7.55;6,22.50,225.40,513.00,7.55;6,22.50,234.87,381.94,7.55"><head>Fig. 5. </head><figDesc>Fig. 5. Automatic lighting design for the engine data set. (a) The first optimal light source. (b) The deformed light-position sphere for the first optimal light source. The radius of each light position is proportional to the normalized lighting quality (the MS-HWSD) and the color mapping from blue to red corresponds to lighting quality from low to high. (c) Two optimal light sources (α = 0.4 in Equation 10). The shininess exponent is 40. (d) The optimal shininess exponents for the two light sources in (c). The shininess exponent is searched from 20 to 80 with step size 1. The optimal shininess exponents are 47 and 74 for the two lights. Highlights are reduced to improve structure perception. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="7,31.50,197.01,250.39,7.55;7,31.50,206.48,250.38,7.55;7,31.50,215.94,250.39,7.55;7,31.50,225.40,141.17,7.55"><head>Fig. 6. </head><figDesc> Fig. 6. Automatic lighting design without and with shadowing for the vortex data set. Shadowing provides more perceptual cues for the spatial relationships of features. (a) Optimal light source without shadowing. (b) Optimal light source with shadowing. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="8,22.50,366.89,513.00,7.55;8,22.50,376.36,513.00,7.55;8,22.50,385.82,379.94,7.55"><head>Fig. 8. </head><figDesc>Fig. 8. Visual comparison of three lighting design methods and lighting stability analysis for the vismale data set: (a) optimal light source using lighting entropy, (b) optimal light source using multi-scale entropy, (c) optimal light source of the proposed MS-HWSD (β = 1.0 in Equation 11), (d) most stable light source (β = 0.0), (e) optimal light source based on lighting goodness and stability (β = 0.4). </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13" coords="9,294.12,145.80,250.38,10.50;9,294.12,157.13,250.37,7.55;9,294.12,166.60,250.37,7.55;9,294.12,176.06,160.45,7.55"><head>Fig. 10. </head><figDesc>Fig. 10. (a) θ × ϕ distribution of the pairs of selected light positions for the vismale and engine data sets in our study (20 pairs per data set). (b) For each pair of images, the proportion of selections in which the image with the higher MS-HWSD value was chosen. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true" coords="9,308.20,205.68,222.22,112.81"><figDesc coords="9,367.62,205.68,103.39,7.55">Table 1. User study statistics.</figDesc><table coords="9,308.20,225.74,222.22,92.75">Selection Percentage (%) 
Test Sets 
Lighting Entropy Multi-Scale Entropy 
MS-HWSD 
tooth 
16.67 
36.11 
47.22 
teapot 
30.55 
27.78 
41.67 
atom 
22.22 
33.33 
44.44 
pollen 
11.11 
47.22 
41.67 
engine 
25.00 
33.33 
41.67 
tomato 
19.44 
13.89 
66.67 
vismale 
27.78 
22.22 
50.00 
tomato2 
30.55 
27.78 
41.67 

</table></figure>

			<note place="foot" n="8"> radians [23]. In the random selection, we rejected light positions that were close to previously selected light positions, and discouraged pairs whose MS-HWSD values were too close for meaningful comparisons, such as light positions that were both behind the object. Fig. 10(a) shows the selected pairs of distributions. As the definition of good lighting is highly subjective, and this judgement is hard to quantify, we use paired comparisons [6] and asked users: &quot; Which of the two images reveals the object&apos;s structural information (shape and detail) better? &quot; . We randomly select 10 pairs from the 20 selected pairs for each data set, giving a total of 20 pair comparisons for each user. The pairs were presented in a random sequence , and the two images of each pair were shown in a random left-right order; 33 users were used, giving a total of 660 comparisons;</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p>The authors wish to thank all participants in the user study for their contributions to the evaluation, and the anonymous reviewers for their valuable comments. This work was partially supported by National Natural Science Foundation of China No. 60873122 and No. 60903133, and 863 Program Project 2012AA12A404. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="10,40.76,74.54,232.12,7.17;10,40.76,84.01,165.13,7.17"  xml:id="b0">
	<monogr>
		<title level="m" type="main">What object attributes determine canonical views? Perception</title>
		<author>
			<persName>
				<forename type="first">V</forename>
				<surname>Blanz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">J</forename>
				<surname>Tarr</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">H</forename>
				<surname>Bülthoff</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="575" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,93.47,232.12,7.17;10,40.76,102.94,232.12,7.17;10,40.76,112.40,133.42,7.17"  xml:id="b1">
	<analytic>
		<title level="a" type="main">View selection for volume rendering</title>
		<author>
			<persName>
				<forename type="first">U</forename>
				<forename type="middle">D</forename>
				<surname>Bordoloi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-W</forename>
				<surname>Shen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;05</title>
		<meeting>IEEE Visualization &apos;05<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,121.87,232.12,7.17;10,40.76,131.33,232.11,7.17;10,40.76,140.80,110.47,7.17"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Distortion in 3D shape estimation with changes in illumination</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Caniard</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">W</forename>
				<surname>Fleming</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of APGV &apos;07</title>
		<meeting>APGV &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="99" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,150.26,232.13,7.17;10,40.76,159.72,232.11,7.17;10,40.76,169.19,17.93,7.17"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Quality enhancement of direct volume rendered images</title>
		<author>
			<persName>
				<forename type="first">M.-Y</forename>
				<surname>Chan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Wu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Qu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Volume Graphics &apos;07</title>
		<meeting>Volume Graphics &apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,178.65,232.12,7.17;10,40.76,188.12,232.11,7.17;10,40.76,197.58,37.85,7.17"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Contrast enhancement based on a novel homogeneity measurement</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">D</forename>
				<surname>Cheng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Xue</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<forename type="middle">J</forename>
				<surname>Shi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2687" to="2697" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,207.05,232.12,7.17;10,40.76,216.51,17.93,7.17"  xml:id="b5">
	<monogr>
		<title level="m" type="main">The Method of Paired Comparison</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">A</forename>
				<surname>Daivid</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1963" />
			<publisher>Halner Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,225.98,232.12,7.17;10,40.76,235.44,232.11,7.17;10,40.76,244.91,232.12,7.08;10,40.76,254.37,165.15,7.17"  xml:id="b6">
	<analytic>
		<title level="a" type="main">High-quality pre-integrated volume rendering using hardware-accelerated pixel shading</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Engel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Kraus</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ertl</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGGRAPH/EUROGRAPHICS workshop on Graphics hardware &apos;01</title>
		<meeting>the ACM SIGGRAPH/EUROGRAPHICS workshop on Graphics hardware &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,263.83,232.12,7.17;10,40.76,273.30,232.11,7.17;10,40.76,282.76,17.93,7.17"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Specular reflections and the perception of shape</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">W</forename>
				<surname>Fleming</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Torralba</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">H</forename>
				<surname>Adelson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="798" to="820" />
			<date type="published" when="2004-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,292.23,232.11,7.17;10,40.76,301.69,232.12,7.17;10,40.76,311.16,232.12,7.17;10,40.76,320.62,157.72,7.17"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Healpix: A framework for highresolution discretization and fast analysis of data distributed on the sphere</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">M</forename>
				<surname>Górski</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Hivon</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Banday</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<forename type="middle">D</forename>
				<surname>Wandelt</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">K</forename>
				<surname>Hansen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Reinecke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Bartelmann</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Astrophysical Journal</title>
		<imprint>
			<biblScope unit="volume">622</biblScope>
			<biblScope unit="page" from="759" to="771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,330.09,232.12,7.17;10,40.76,339.55,232.11,7.17;10,40.76,349.02,78.51,7.17"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Maximum entropy light source placement</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Gumhold</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;02</title>
		<meeting>IEEE Visualization &apos;02<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,358.48,232.12,7.17;10,40.76,367.94,232.12,7.17;10,40.76,377.41,157.77,7.17"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Lightkit: A lighting system for effective visualization</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Halle</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Meng</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;03</title>
		<meeting>IEEE Visualization &apos;03<address><addrLine>Washington , DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,386.87,232.13,7.17;10,40.76,396.34,232.12,7.17;10,40.76,405.80,158.67,7.17"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic view selection for time-varying volumes</title>
		<author>
			<persName>
				<forename type="first">G.-F</forename>
				<surname>Ji</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H.-W</forename>
				<surname>Shen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Visualization&apos;06)</title>
		<meeting>. Visualization&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1109" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,415.27,232.12,7.17;10,40.76,424.73,232.12,7.17;10,40.76,434.20,74.14,7.17"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Radioptimization: Goal based rendering</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">K</forename>
				<surname>Kawai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">S</forename>
				<surname>Painter</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">F</forename>
				<surname>Cohen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;93</title>
		<meeting>SIGGRAPH &apos;93<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="147" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,443.66,232.13,7.17;10,40.76,453.12,231.84,7.17"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Toward evaluating lighting design interface paradigms for novice users</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">B</forename>
				<surname>Kerr</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Pellacini</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">2826</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="269" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,462.59,232.12,7.17;10,40.76,472.05,232.11,7.17;10,40.76,481.52,71.74,7.17"  xml:id="b14">
	<analytic>
		<title level="a" type="main">The internal representation of solid shape with respect to vision</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">J</forename>
				<surname>Koenderink</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">J</forename>
				<surname>Doorn</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="211" to="216" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,490.98,232.12,7.17;10,40.76,500.45,232.12,7.17;10,40.76,509.91,207.16,7.17"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Light collages: Lighting design for effective visualization</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">H</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Hao</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Varshney</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;04</title>
		<meeting>IEEE Visualization &apos;04<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="281" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,519.38,232.12,7.17;10,40.76,528.84,232.11,7.17;10,40.76,538.31,212.23,7.17"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Structural similarity-based object tracking in video sequences</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Loza</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Mihaylova</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Canagarajah</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Bull</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Fusion 9th International Conference on</title>
		<imprint>
			<date type="published" when="2006-07" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,547.77,232.12,7.17;10,40.76,557.23,232.12,7.17;10,40.76,566.70,232.12,7.17;10,40.76,576.16,232.12,7.17;10,40.76,585.63,232.12,7.17;10,40.76,595.09,47.38,7.17"  xml:id="b17">
	<analytic>
		<title level="a" type="main">Design galleries: A general approach to setting parameters for computer graphics and animation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Marks</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Andalman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">A</forename>
				<surname>Beardsley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Freeman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Gibson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Hodgins</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Kang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Mirtich</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Pfister</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Ruml</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Ryall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Seims</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Shieber</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;97</title>
		<meeting>SIGGRAPH &apos;97<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM PressAddison-Wesley Publishing Co</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="389" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,604.56,232.12,7.17;10,40.76,614.02,144.49,7.17"  xml:id="b18">
	<analytic>
		<title level="a" type="main">A survey of inverse rendering problems</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Patow</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">X</forename>
				<surname>Pueyo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="663" to="687" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,623.49,232.12,7.17;10,40.76,632.95,157.81,7.17"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Lighting with paint</title>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Pellacini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Battaglia</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">K</forename>
				<surname>Morley</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Finkelstein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">269</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,642.41,232.12,7.17;10,40.76,651.88,221.60,7.17"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Lights from highlights and shadows</title>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Poulin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Fournier</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of I3D &apos;92</title>
		<meeting>I3D &apos;92<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,661.34,232.13,7.17;10,40.76,670.81,232.12,7.17;10,40.76,680.27,74.14,7.17"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Painting with light</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Schoeneman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Dorsey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Smits</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Arvo</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Greenberg</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;93</title>
		<meeting>SIGGRAPH &apos;93<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="143" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,689.74,232.12,7.17;10,40.76,699.20,232.12,7.17;10,40.76,708.67,59.54,7.17"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Perceptual models of viewpoint preference</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Secord</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Lu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Finkelstein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Singh</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Nealen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">30109</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="10912" />
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,718.13,232.12,7.17;10,40.76,727.60,222.85,7.17"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Automatic lighting design using a perceptual quality metric</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Shacked</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Lischinski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="215" to="226" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,737.06,232.13,7.17;10,303.38,54.02,232.12,7.17;10,303.38,63.49,232.12,7.17;10,303.38,72.95,118.36,7.17"  xml:id="b24">
	<analytic>
		<title level="a" type="main">A feature-driven approach to locating optimal viewpoints for volume visualization</title>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Takahashi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Fujishiro</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Takeshima</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Nishita</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization&apos;05</title>
		<meeting>IEEE Visualization&apos;05<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="495" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,82.42,232.11,7.17;10,303.38,91.88,231.15,7.17"  xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic lightng source placement for maximum visual information recovery</title>
		<author>
			<persName>
				<forename type="first">P.-P</forename>
				<surname>Vázquez</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="156" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,101.35,232.12,7.17;10,303.38,110.81,232.12,7.17;10,303.38,120.27,154.44,7.17"  xml:id="b26">
	<analytic>
		<title level="a" type="main">Image quality assessment: From error visibility to structural similarity</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Bovik</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">R</forename>
				<surname>Sheikh</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">P</forename>
				<surname>Simoncelli</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,129.74,232.12,7.17;10,303.38,139.20,232.12,7.17;10,303.38,148.67,232.12,7.17;10,303.38,158.13,17.93,7.17"  xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-scale structural similarity for image quality assessment</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Wang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<forename type="middle">P</forename>
				<surname>Simoncelli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">C</forename>
				<surname>Bovik</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 37th IEEE Asilomar Conference on Signals, Systems and Computers</title>
		<meeting>37th IEEE Asilomar Conference on Signals, Systems and Computers</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1398" to="1402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,167.60,232.12,7.17;10,303.38,177.06,232.12,7.17;10,303.38,186.53,232.11,7.17;10,303.38,195.99,17.93,7.17"  xml:id="b28">
	<analytic>
		<title level="a" type="main">iView: A feature clustering framework for suggesting informative views in volume visualization</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Zheng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Ahmed</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Mueller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1959" to="1968" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
