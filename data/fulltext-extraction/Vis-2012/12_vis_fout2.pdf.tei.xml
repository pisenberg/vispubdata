<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.4.1" ident="GROBID" when="2016-09-09T15:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fuzzy Volume Rendering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Nathaniel</forename>
								<surname>Fout</surname>
							</persName>
						</author>
						<author>
							<persName>
								<forename type="first">Kwan-Liu</forename>
								<surname>Ma</surname>
								<roleName>Fellow, Ieee</roleName>
							</persName>
						</author>
						<title level="a" type="main">Fuzzy Volume Rendering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms—Uncertainty visualization</term>
					<term>verifiable visualization</term>
					<term>volume rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>(a) Standard Volume Rendering (b) Fuzzy Volume Rendering Fig. 1. (a) Conventional volume rendering of the aneurism dataset seems to show possible stenoses of cerebral vessels. (b) However, fuzzy volume rendering with the same parameters produces a range of possible renderings, reflecting the uncertainty in the visualiza-tion. The two images shown here represent the endpoints of the uncertainty range, from which we can conclude that there are in fact no stenoses in these large vessels. This example shows how inclusion of uncertainty in rendering allows more reliable evaluation. Abstract—In order to assess the reliability of volume rendering, it is necessary to consider the uncertainty associated with the volume data and how it is propagated through the volume rendering algorithm, as well as the contribution to uncertainty from the rendering algorithm itself. In this work, we show how to apply concepts from the field of reliable computing in order to build a framework for management of uncertainty in volume rendering, with the result being a self-validating computational model to compute a posteriori uncertainty bounds. We begin by adopting a coherent, unifying possibility-based representation of uncertainty that is able to capture the various forms of uncertainty that appear in visualization, including variability, imprecision, and fuzziness. Next, we extend the concept of the fuzzy transform in order to derive rules for accumulation and propagation of uncertainty. This representation and propagation of uncertainty together constitute an automated framework for management of uncertainty in visualization, which we then apply to volume rendering. The result, which we call fuzzy volume rendering, is an uncertainty-aware rendering algorithm able to produce more complete depictions of the volume data, thereby allowing more reliable conclusions and informed decisions. Finally, we compare approaches for self-validated computation in volume rendering, demonstrating that our chosen method has the ability to handle complex uncertainty while maintaining efficiency.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p> Uncertainty is inherent in any computational endeavor, and visualization is no exception. Uncertainty arises from many disparate sources and takes on various forms. Although there is no consensus as to how to define uncertainty, it is generally accepted that natural variability and systematic error are not the only relevant forms of uncertainty , and in fact many other forms are encountered in practice, including limited-resolution measurement, limited-precision computation/storage , incomplete or missing data, and credibility of the source, to name a few. As both researchers in the field of visualization and visualization clients have recognized in the last few years, in order to provide an effective visualization it is necessary to provide a complete and accurate visual representation of the data. A complete representation should include information on the uncertainty in the results, whether that be quantitative or qualitative. This concept is closely related to the idea of verifiable visualization as put forth by Kirby et al. <ref type="bibr" coords="1,42.95,643.32,13.74,8.02" target="#b17">[18]</ref> . A verifiable visualization is aware of the presence and ram@BULLET Nathaniel Fout is with UC Davis, e-mail: natefout@gmail.com. @BULLET Kwan-Liu Ma is with UC Davis, e-mail: klma@ucdavis.edu. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org. ifications of errors, not only in the data but as introduced by the visualization algorithm. The guiding hypothesis is that incorporation of uncertainty in the visualization will provide a more accurate representation of the data, which will in turn allow more reliable interpretation and insight, leading to more informed decisions. In volume rendering, uncertainty arises in association with the volume data, as well as from the volume rendering algorithm itself. Past work in the area of volume rendering uncertainty has focused on only one aspect of the total uncertainty, most commonly the uncertainty in the volume data or else in the classification process. However, there are many other sources of uncertainty in the volume rendering pipeline, such as quantization of scalar values, limited precision in computation and compositing, and approximation in integration along rays. In order to manage these disparate forms of uncertainty in one context, a comprehensive model of complex uncertainty must be employed . Self-validated computational (SVC) models are especially useful in this regard, as they provide an automated solution to this problem and are able to produce relatively tight a posteriori uncertainty bounds. While early SVC techniques, such as Interval Algebra <ref type="bibr" coords="1,529.56,674.29,14.94,8.02" target="#b24">[26] </ref>and Affine Arithmetic <ref type="bibr" coords="1,375.08,684.25,9.52,8.02" target="#b1">[2]</ref>, are limited to representing only one type of uncertainty, more recent models are able to represent various types of uncertainty in one form. In this work, we propose an approach for verification of volume rendering that is based on advances in uncertainty analysis in the fields of reliable computing and information and evidence theory. The objec-tive of our work is to identify, quantify, and communicate the various forms of uncertainty in the volume rendering algorithm. To this end, we adopt a possibilistic framework for uncertainty as proposed by Dubois and Prade <ref type="bibr" coords="2,88.45,83.27,13.74,8.02" target="#b11">[12]</ref> , with uncertain quantities represented as trapezoidal possibility distributions (TPDs). Such a representation is able to represent both imprecision and fuzziness. In order to represent statistical uncertainty, we employ the probability-possibility transform described recently by Dubois et al. <ref type="bibr" coords="2,141.75,123.12,13.74,8.02" target="#b9">[10]</ref> . We then discuss how to propagate uncertainty represented as TPDs by applying concepts from fuzzy arithmetic, based on ideas by Zadeh <ref type="bibr" coords="2,155.73,143.05,14.94,8.02" target="#b35">[37] </ref>and Dubois and Prade <ref type="bibr" coords="2,255.70,143.05,13.74,8.02" target="#b10">[11]</ref>. Bringing these ideas together into one system allows us to build a SVC model that provides an automated uncertainty analysis for volume rendering , an approach which we call fuzzy volume rendering. We use fuzzy volume rendering to compute uncertainty bounds and to analyze the various forms of uncertainty in the algorithm by altering the rendering parameters, demonstrating that fuzzy volume rendering is a relatively efficient method for verifiable volume rendering. The end result is a comprehensive assessment of the total uncertainty in volume rendering. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Although our work addresses uncertainty in volume visualization, our approach is based on research in the areas of information theory, evidence theory, and fuzzy set theory. However, we restrict our discussion to the more concrete aspects of uncertainty analysis, as a complete discussion of these subjects is beyond the scope of the presented work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Uncertainty Visualization</head><p>In uncertainty visualization, the objective is to display the data and its corresponding uncertainty in the same visualization. Challenges and outstanding problems in uncertainty visualization are discussed by Boukhelifa and Duke <ref type="bibr" coords="2,113.74,372.08,9.52,8.02" target="#b5">[6]</ref> . In an effort to construct a common language of uncertainty, several authors have proposed classifications of uncertainty in the context of visualization <ref type="bibr" coords="2,177.34,392.00,14.94,8.02" target="#b33">[35] </ref><ref type="bibr" coords="2,195.11,392.00,13.74,8.02" target="#b30">[32]</ref> . A survey of research on incorporating uncertainty in scientific visualization is given by Pang et al. <ref type="bibr" coords="2,73.42,411.93,14.94,8.02" target="#b27">[29] </ref>and more recently by Johnson and Sanderson <ref type="bibr" coords="2,255.21,411.93,13.74,8.02" target="#b16">[17]</ref>. Connected with uncertainty is the concept of verification, which is discussed by Kirby and Silva <ref type="bibr" coords="2,127.86,432.44,14.94,8.02" target="#b17">[18] </ref>in the context of simulation science. Closely related to our work is research on verification of CFD simulations by Aeschliman et al. <ref type="bibr" coords="2,115.98,452.36,9.52,8.02" target="#b0">[1]</ref>. They also propose as part of verification an analysis of uncertainty, but they consider random and systemic error within a probabilistic context. Kronander et al. <ref type="bibr" coords="2,190.69,472.29,14.94,8.02" target="#b20">[21] </ref>explore the effects of computational precision, quantization, and sampling rate on the actual numerical errors incurred in volume rendering, proposing a model in order to guide selection of these parameters. Another related work by Correa et al <ref type="bibr" coords="2,77.08,512.14,10.45,8.02" target="#b6">[7] </ref>considers modeling and propagation of uncertainty, but addresses uncertainty by conducting a sensitivity analysis based on a probabilistic model. On the other hand, Streit et al. <ref type="bibr" coords="2,225.28,532.06,14.94,8.02" target="#b32">[34] </ref>consider modeling uncertainty in terms of fuzzy sets, but their work focuses on a consistent spreadsheet display of uncertainty and not on modeling and propagation. In terms of exploring the inherent uncertainty in the volume rendering algorithm, Kniss et al. <ref type="bibr" coords="2,138.45,582.46,14.94,8.02" target="#b19">[20] </ref>proposed a statistical approach for classification uncertainty which was formulated in terms of risk. Lundström et al. <ref type="bibr" coords="2,85.71,602.38,14.94,8.02">[22] </ref> also addressed uncertainty in classification using a probabilistic model, opting to incorporate user interaction and animation as a way of exploring the uncertainty in the transfer function . Zheng et al. <ref type="bibr" coords="2,86.16,632.27,14.94,8.02" target="#b36">[38] </ref> focused on computing the uncertainty in reconstruction and proposed an approach for reducing the uncertainty with upsampling in the backprojection stage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Uncertainty Analysis</head><p>Uncertainty Analysis (UA) is the study of the effects of uncertainty on computation. This process consists of first identifying and characterizing the relevant types of uncertainty. There are several existing automated UA methods, with Interval Algebra (IA) <ref type="bibr" coords="2,207.09,716.50,14.94,8.02" target="#b24">[26] </ref>being the first such method, in which a quantity is represented by an interval, with interval operations propagating the error through computation. Affine </p><p>Arithmetic (AA) <ref type="bibr" coords="2,348.10,53.38,10.45,8.02" target="#b1">[2] </ref> is an extension of IA in which a quantity is represented by an affine term in order to maintain correlations between dependent variables. Similar approaches include Generalized Interval Arithmetic <ref type="bibr" coords="2,339.56,83.27,13.74,8.02" target="#b15">[16]</ref>, Lazy Arithmetic <ref type="bibr" coords="2,420.86,83.27,13.74,8.02" target="#b22">[24]</ref>, and Taylor Arithmetic <ref type="bibr" coords="2,522.80,83.27,9.52,8.02" target="#b4">[5]</ref>. Fuzzy set theory was introduced by L. Zadeh <ref type="bibr" coords="2,453.92,93.23,14.94,8.02" target="#b35">[37] </ref>in order to model a unique type of uncertainty, namely fuzziness. From this theory, the concept of the fuzzy number was introduced, as well as operations on fuzzy numbers based on the extension principle, thereby yielding Fuzzy Algebra (FA). While the previous methods only deal with one type of uncertainty, several approaches have been developed in order to consolidate multiple types of uncertainty in one form. Examples that use a probabilistic framework include Probability Bounds Analysis as described by Roy and Oberkampf <ref type="bibr" coords="2,343.16,183.10,14.94,8.02" target="#b29">[31] </ref>and a Monte-Carlo method developed by Baccou and Chojnacki <ref type="bibr" coords="2,338.89,193.07,9.52,8.02" target="#b2">[3]</ref>. Other methods are based on mixing fuzzy numbers and random variables, including Random Fuzzy Variables by Ferrero and Salicone <ref type="bibr" coords="2,334.76,212.99,13.74,8.02" target="#b12">[13]</ref>, Type-2 Fuzzy Numbers by Mencattini et al. <ref type="bibr" coords="2,518.32,212.99,13.74,8.02" target="#b21">[23]</ref>, and Random Fuzzy Intervals by Baudrit et al. <ref type="bibr" coords="2,458.09,222.95,9.52,8.02" target="#b3">[4]</ref>. Finally, Zhou et al. <ref type="bibr" coords="2,296.08,232.92,14.94,8.02" target="#b37">[39] </ref>describe a model of temporal uncertainty that uses TPDs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">UNCERTAINTY ANALYSIS FRAMEWORK</head><p> In this section, we describe how existing methods in uncertainty analysis can be used to construct an automated uncertainty analysis framework capable of managing the types of uncertainty encountered in volume rendering. There are three principle components of uncertainty analysis: characterization of uncertainty, analysis of effects of uncertainty on output, and communication of uncertainty. In the next sections, we address each of these components, which we refer to as uncertainty modeling, uncertainty propagation, and uncertainty visualization , respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Uncertainty Representation</head><p> In order to represent the various forms of uncertainty in volume rendering , we need a characterization of uncertainty that is amenable to quantitive analysis. Several such classifications exist, but an especially succinct and commonly-accepted system is described by Klir and Yuan <ref type="bibr" coords="2,323.46,416.92,14.94,8.02" target="#b18">[19] </ref>in the context of information and evidence theories. Briefly, three types of quantitative uncertainty are described, based on probability, possibility, and fuzzy set theories. Probability represents a specific kind of uncertainty characterized by conflict, discord, or strife in choosing one option among many alternatives. In possibility theory, we are concerned with the uncertainty associated with a finite set of possible alternatives, which is called nonspecificity. On the other hand, fuzzy set theory deals with assignment to fuzzy sets whose boundaries are inherently imprecise, which is termed fuzziness. As we show in the following sections, it is possible to represent all the relevant forms of uncertainty in volume rendering with these three uncertainty modalities. In our system, we adopt a possibilistic framework for uncertainty. To this end, we choose as our representation of uncertainty the Trapezoidal Possibility Distribution (TPD), as described by Dubois and Prade <ref type="bibr" coords="2,308.72,566.56,13.74,8.02" target="#b11">[12]</ref>. A normalized trapezoidal possibility distribution (TPD) is defined as: </p><formula>π T PD (x; a, b, c, d) =          0 x &lt; a a−x a−b a ≤ x &lt; b 1 b ≤ x ≤ c d−x d−c c &lt; x ≤ d 0 d &lt; x (1) </formula><p>where a, b, c, and d are the parameters defining a trapezoid, as shown in <ref type="figure" coords="2,294.88,666.68,29.56,8.02" target="#fig_1">Figure 2</ref>. The core of the TPD is defined as the interval <ref type="bibr" coords="2,502.85,666.54,16.92,7.96">[b, c] </ref>and represents the region of highest possibility. The intervals <ref type="bibr" coords="2,501.79,676.50,17.42,7.96">[a, b] </ref>and <ref type="bibr" coords="2,285.12,686.46,17.38,7.96">[c, d] </ref>are called the left and right boundary, respectively, and represent regions of graded possibility, transitioning from impossible to fully possible. Unlike a probability distribution, the actual value under consideration is guaranteed to lie within support of the possibility distribution , similar to the fundamental property of IA/AA. However, unlike IA or AA, a TPD provides gradations of possibility, weaker than the  . In our system, a quantity and its associated uncertainty is represented by a trapezoidal possibility distribution (TPD), as defined by the four parameters a, b, c, and d. corresponding degrees of probability offered by a probability distribution but accounting for imprecision in the data. Furthermore, the fundamental difference between probability and possibility dictates that the integral of a possibility distribution need not be 1, as for probability distributions. Choosing a possibility-based representation allows us to find a common ground among the various incarnations of uncertainty, with the result being a single unified framework for uncertainty, as shown in <ref type="figure" coords="3,31.50,282.75,30.21,8.02">Figure 3</ref>. Let us first consider fuzziness and nonspecificity. There is a close connection between possibility theory and fuzzy set theory , and in fact possibility theory can be formulated in terms of fuzzy set theory since the level set of fuzzy sets (also called α-cuts) provides nested sets <ref type="bibr" coords="3,93.57,322.60,13.74,8.02" target="#b18">[19]</ref>. In this context, π(x) is directly related to fuzzy set membership, so that the membership function µ(x) can be interpreted as the degree of membership or the degree of possibility; that is, π(x) = µ(x). Therefore, the transformation from fuzzy membership function to possibility distribution is actually a change of interpretation , with the mathematical transform being the identity function. Now let us consider discord and nonspecificity. Although probability and possibility are two distinct aspects of uncertainty, it is possible to work with these quantities in the same context via the probabilitypossibility transformation, wherein we transform from a probability distribution function p(x) to a possibility distribution function π * (x). While there have been several such transformations proposed, an especially useful transform described by Dubois et al. <ref type="bibr" coords="3,207.97,442.15,14.94,8.02" target="#b9">[10] </ref> is based on confidence intervals. Normally, a confidence level 1 − α is selected based on constant α, resulting in a single interval. However, if we take all possible values of α ∈ <ref type="bibr" coords="3,115.27,471.90,9.46,7.96">[0,</ref><ref type="bibr" coords="3,125.72,472.04,6.97,8.02" target="#b0"> 1] </ref> then we end up with a set of nested confidence intervals. <ref type="bibr" coords="3,95.44,482.00,45.64,8.02">Dubois et al. </ref> show that this process is a probabilitypossibility transformation that is maximally specific, meaning that it minimizes the loss of information by finding the most informative possibility distribution π * (x) for a given probability distribution p(x). The resulting possibility distribution for a unimodal symmetric p(x) is: </p><formula>π * (x) = −|x| −∞ p(y)dy + +∞ |x| p(y)dy (2) </formula><p>We can compute the confidence interval for a given α as </p><formula>CI(α) = α π * (x), α π * (x) </formula><formula>(3) </formula><p>where α π * (x) and α π * (x) are the infimum and supremum of the α-cut of π * (x), respectively. The α-cut of a set function A(x) is a member of the level set and is defined as α A(x) = {x : A(x) ≥ α} </p><formula>(4) </formula><p>so that the infimum and supremum of this set correspond to the lower and upper bounds of the given interval, assuming the set is convex. This approach also allows us to incorporate pdf s of infinite support by transforming them to possibility distributions and limiting the support based on a reasonable level of confidence. The probability-possibility transformation establishes possibility theory as a common ground from which to analyze complex uncertainty . This makes sense in light of the fact that possibility theory is capable of representing both nonspecificity and discord (albeit with some <ref type="figure" coords="3,294.12,144.45,21.22,7.37">Fig. 3</ref>. Our possibility-based framework depends on transforming probability-based uncertainty and fuzziness to a possibility-based representation . We rely upon recent work in the area of probability-possibility transforms for the former. As for the latter, the transformation is merely one of interpretation, since possibility theory and fuzzy set theory are mathematically equivalent. limitation), whereas probability theory is quite limiting and can only represent discord. It is important to note that the lack of equivalency between possibility and probability implies some loss of information when converting from probability to possibility, but we minimize the loss of information by carefully choosing the transform. Having justified the choice of possibility distribution as the representation of complex uncertainty, we now discuss our motivation for using trapezoidal distributions. Limiting the form to a trapezoidal distribution allows more efficient computation of uncertainty with only a minor impact on flexibility. This is due to the observation that trapezoidal distributions naturally model the primary forms of uncertainty that are encountered in most computations. For instance, both truncation and rounding errors are typically given in terms of error bounds, especially in the case of floating-point computation where rounding errors are not random. There are two potential representations of bounded uncertainty corresponding to the uniform possibility distribution π 2 (x) and uniform probability distribution p 2 (x). The former is applicable when we have no knowledge about the value other than it is restricted to be within the bounds, whereas the latter indicates some additional knowledge about where the value lies within the bounds; namely, that it is equally likely to be anywhere. The representation for possibilistic bounded uncertainty is then given as: </p><formula>π 2 (x; B) = 1 −B ≤ x ≤ +B 0 otherwise (5) </formula><p> where B defines the bounds of possibility. Probabilistic bounded uncertainty , when transformed based on Equation 2, yields: </p><formula>π * (x; B) =    x + 1 : −B ≤ x &lt; 0 1 − x : 0 ≤ x ≤ B 0 : otherwise (6) π * (x) </formula><p>is a triangular possibility distribution, since the integration of a constant gives a linear expression. Consider also data or measurement uncertainty, which usually consists of both systematic error and noise. Systematic error is naturally represented as bounded uncertainty, whereas noise often assumes a Gaussian distribution. In order to represent Gaussian noise we can perform a transformation from p G (x, σ ) to π * G (x), which requires numerical integration of p G (x, σ ). Alternatively, a slightly less specific transformation is to just approximate π * G (x) by the triangular possibility distribution of the same support, since this is computationally more efficient and still meets the consistency criteria, based on the fact that triangular possibility distributions serve as a least upper bound for the family of symmetric pdf s <ref type="bibr" coords="3,388.16,686.39,13.74,8.02" target="#b9">[10]</ref>. In fact, this implies that any unimodal symmetric pd f is efficiently transformed to a triangular possibility distribution. Finally, we note that the most common representation of uncertainty in fuzzy set theory is the fuzzy number, which is usually represented as a triangular characteristic function. We contend, therefore, that most 2337 FOUT AND MA: FUZZY VOLUME RENDERING distributions encountered in practice can be characterized as having one of two forms, as shown in <ref type="figure" coords="4,131.19,180.08,28.91,8.02" target="#fig_2">Figure 4</ref> : bounded (uniform) or centralized (triangular). The bounded uncertainty form is defined by upper and lower limits on the actual value. Nothing more is known about the actual value; in particular, it cannot be assumed that the most likely value is the midpoint. On the other hand, in addition to having upper and lower limits, centralized uncertainty identifies a single most likely value within the bounds, with other values having intermediate degrees of possibility. The distinction between these two is important centralized uncertainty embodies significantly more information than bounded uncertainty. A possible source of confusion is data expressed in the form x ± δ . Although the apparent meaning is that the most likely value is x, this expression is also used to denote a value within the interval [x − δ , x + δ ], when in fact the mostly likely value may not be known. Thus care must be taken when determining the correct possibilistic form for a given uncertain quantity. Given a number with uncertainty in both bounded and centralized form, the resulting composite form is trapezoidal, as shown in <ref type="figure" coords="4,257.93,341.13,14.95,8.02;4,22.50,351.09,17.57,8.02" target="#fig_2">Fig- ure 4</ref>. The linear boundaries result from triangular distributions, and the rectangular core results from uniform distributions. An important aspect of this form is that the core, which represents the most likely possibility, is not restricted to a single value. On the other hand, when part of the composite uncertainty does have a centralized form, this is reflected in the boundaries as graded possibility. That is, the trapezoidal distribution can effectively represent both bounded and centralized uncertainty in one form. Another advantage of adopting trapezoidal distributions is that operations on numbers of this form, being analogous to operations on trapezoidal fuzzy numbers, are already well-established. The DSW algorithm <ref type="bibr" coords="4,60.74,462.32,10.45,8.02" target="#b8">[9] </ref>and the Vertex method <ref type="bibr" coords="4,162.13,462.32,10.45,8.02" target="#b7">[8] </ref>provide efficient means of computing operations on fuzzy numbers based on IA. The application of these methods requires some care and is beyond the scope of our exposition, but suffice it to say that the Vertex method is appropriate for TPDs representing only nonspecificity/discord, whereas the DSW algorithm is appropriate for TPDs having fuzziness, with or without nonspecificity/discord. At times it may be necessary to convert TPDs into other numbers , primarily real numbers and intervals. Conversion of a TPD to a real number is called defuzzification and is discussed at length by Ross <ref type="bibr" coords="4,43.29,563.59,13.74,8.02" target="#b28">[30]</ref>. Conversion of a TPD to an interval is accomplished by specifying the level of presumption α in Equation 3 in order to compute a confidence interval. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Uncertainty Propagation</head><p> In addition to defining a representation of uncertainty, in order to compute the uncertainty in visualization we must model the propagation of uncertainty. There are two aspects to propagation of uncertainty, based on whether the source of the uncertainty is the data or the algorithm itself. At each stage of the algorithm, uncertainty from both the data and from previous stages is propagated to the next stage. In addition, each stage has the potential to contribute its own uncertainty, which we call uncertainty accumulation. This uncertainty must be added to the overall uncertainty and propagated through the remaining stages of the algorithm, as shown in <ref type="figure" coords="4,129.12,714.85,29.02,8.02">Figure 5</ref>. In order to accumulate uncertainty with TPDs, we dilate the core and/or boundaries, as shown in <ref type="figure" coords="4,139.68,736.42,29.75,8.02" target="#fig_2">Figure 4</ref>. Accumulation of bounded uncertainty dilates the core and boundaries: </p><formula>π T PD (x; a, b, c, d) ⊕ π 2 (x; B) = π T PD (x; a − B, b − B, c + B, d + B) (7) </formula><p> where ⊕ is defined as the accumulation operator. In contrast, accumulation of centralized uncertainty dilates the boundaries only: </p><formula>π T PD (x; a, b, c, d) ⊕ π (x; B) = π T PD (x; a − B, b, c, d + B) (8) </formula><p>This model of uncertainty accumulation is simple and efficient, but discards any information regarding the source of the individual components of uncertainty that form a TPD. This means that variable dependencies have the potential to cause inflation of boundaries, similar to IA. If a stage of the visualization algorithm can be expressed as a combination of elementary operations, then we can simply use fuzzy algebra to propagate the uncertainty. However, for an arbitrary function we must establish a law of propagation that preserves the form of the TPD (i.e. provides closure) and that faithfully transforms the degrees of possibility. We will consider both crisp functions as well as uncertain functions; that is, functions in which the mapping itself introduces an element of uncertainty. An ordinary function f can be extended to take as arguments TPDs in addition to real numbers. Such a function essentially passes on the uncertainty from the input to the output without altering it; that is, the uncertainty is directly propagated from input to output. This mapping can be defined based on the extension principle for fuzzy transforms <ref type="bibr" coords="4,326.27,460.70,13.74,8.02" target="#b35">[37]</ref>. Accordingly, the evaluation of f given a possibility distribution π(x) is </p><formula>π(y) = sup x∈ f −1 (y) π(x) f −1 (y) = / 0 0 f −1 (y) = / 0 (9) </formula><p>If f is a 1-1 mapping then this simplifies to </p><formula>π(y) = π( f −1 (y)) </formula><formula>(10) </formula><p>for f −1 (y) = / 0. The difficulty in applying these equations directly to TPDs is that the resulting possibility distribution will not generally be trapezoidal in shape. However, as demonstrated in <ref type="figure" coords="4,467.95,581.80,29.29,8.02" target="#fig_3">Figure 6</ref>(a) we can <ref type="figure" coords="4,285.12,697.19,19.79,7.37">Fig. 5</ref> . Our possibility-based framework allows propagation of uncertainty associated with data acquisition, regardless of the type of uncertainty . Furthermore, each stage will add uncertainty related to the operation, a process which we call accumulation, and this uncertainty must be propagated through the remaining stages. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Exact Mapping </head><p>(b) Max-max Fuzzy Mapping (c) Max-min Fuzzy Mapping (c) A fuzzy function not only propagates uncertainty but accumulates additional uncertainty related to the fuzziness of the mapping. There are several options for computing the output, based on how the uncertainty in the function and input are combined: max-max (b), max-min (c), and max-prod (c). When constraining the output form to be trapezoidal, both max-min and max-prod produce the same results. compute a trapezoidal approximation of the resulting distribution at the cost of a potential decrease in specificity, which means that some information is lost in the process (this information loss is of the same type as that lost during the probability-possibility transform). A fuzzy functioñ f defines an uncertain mapping such that each real value in the domain is mapped to a fuzzy number in the range. We can generalize this concept to formulate a function that maps each real value to an uncertain quantity described by a possibility distribution . In this case, the uncertainty in the input is further amplified by the uncertainty in the function, resulting in a combined propagation/accumulation (see <ref type="figure" coords="5,130.59,393.29,30.39,8.02" target="#fig_3">Figure 6</ref>). As discussed by Dubois and Prade <ref type="bibr" coords="5,54.36,403.25,13.74,8.02" target="#b10">[11]</ref> , there are three options for evaluating a fuzzy function depending on how we combine the possibility of the TPD and the function: max-min, max-max, and max-prod. In the max-min method, for each f (x) in the domain of the TPD the minimum of the function possibility and TPD possibility is taken, whereas in the max-max option the maximum is taken. In the max-prod option the possibilities are multiplied. Although all three methods map into <ref type="bibr" coords="5,222.86,462.88,9.46,7.96">[0,</ref><ref type="bibr" coords="5,233.31,463.03,6.14,8.02" target="#b0"> 1]</ref>, the results have slightly different interpretations, which are beyond the scope of our discussion. In order to derive the equation of propagation, we note that a fuzzy function is actually a set of ordinary functions α f , where each function is associated with a level of presumption α. For α = 1 there is one function, but for α = 1 there are two functions: one on the left of α = 1, α f L , and one on the right, α f R . According to the extension principle, the max-min fuzzy mapping is: </p><formula>π(y) = sup α∈(0,1] π( α f −1 L (y)) ∧ α ∧ π( α f −1 R (y)) </formula><formula>(11) </formula><p>where ∧ is the min operator. Likewise, for the max-max mapping we have: </p><formula>π(y) = sup α∈(0,1] π( α f −1 L (y)) ∨ α ∨ π( α f −1 R (y)) </formula><formula>(12) </formula><p>where ∨ is the max operator. The max-prod fuzzy mapping is defined as: </p><formula>π(y) = sup α∈(0,1] π( α f −1 L (y)) × α ∨ π( α f −1 R (y)) × α (13) </formula><p>Again, the resulting distributions will not necessarily be trapezoidal in shape, so we impose a trapezoidal approximation by altering the projected boundaries to be linear. With this approximation, the maxmin and max-prod mappings both give the same result. As shown in <ref type="figure" coords="5,31.50,726.46,30.26,8.02" target="#fig_3">Figure 6</ref> , the max-max mapping essentially accumulates the uncertainty in the fuzzy mapping into the core, thereby providing a more conservative, pessimistic bounds for uncertainty. On the other hand, the max-min/max-prod mappings accumulate the fuzzy mapping uncertainty into the boundaries, with the core being directly transformed. The latter is more consistent with our definitions of accumulation, so we adopt this method exclusively in our work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Application to Visualization</head><p>So far we have described an uncertainty representation along with rules for propagation of uncertainty in computation. Together, these elements constitute an uncertainty analysis framework, which we can apply to visualization algorithms in order to achieve verification. This is accomplished by substituting TPDs for real numbers in the algorithm , while augmenting the system with rules for accumulation and propagation of uncertainty, as described in the previous section. The result is a self-validated visualization algorithm that offers the client the option of exploring the uncertainty in the visual results. Furthermore , an a posteriori sensitivity analysis can be achieved by altering the individual accumulated uncertainties and observing their effect on the resultant uncertainty in the rendering. Verifiable visualization provides both quantitative and qualitative information which can be used to further the goal of the visualization. The quantitative results include boundaries on rendering primitives and objects, such as lines, surfaces, and volumetric regions. The qualitative results include insights as to the reliability of the visualization and the confidence that one can place in the renderings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VERIFIABLE VOLUME RENDERING</head><p>We now show how the proposed framework can be applied to volume rendering. Volume rendering is an excellent method to analyze, as it is computational intensive with several stages, and includes all of the various forms of quantitative uncertainty in one algorithm. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overview</head><p> The primary means of visualizing scalar volume data is volume rendering , which is most often accomplished using the ray-casting algorithm . In order to track uncertainty accumulation and propagation in volume rendering, we will use a script-like notation to represent the volume rendering pipeline. In this notation, each operation has two symbols, depending on whether only data or data with uncertainty are input/output. In this notation, the standard volume rendering pipeline without uncertainty is expressed as: </p><formula>Volume &gt; F quantization | F f iltering | F classi f ication | F lighting | F integration &gt; Image (14) </formula><p>2339 FOUT AND MA: FUZZY VOLUME RENDERING where &gt; and indicates data input/output and | symbolizes a stage in the pipeline, wherein data is transformed by a function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Acquisition</head><p>The initial source of uncertainty in volume rendering is the inherent uncertainty in the data itself, which we refer to as acquisition uncertainty (U vol ). In the case of volumes derived from physical measurements (e.g. medical imaging data), uncertainty may arise from imprecision in measurements well as random variation in measurement parameters. In the case of volume data resulting from computer simulations, uncertainty arises from limited precision computation and storage, truncation and approximation error in discretization, as well pseudo-random variation in model parameters, if applicable. As uncertainty in data processing is often disregarded, acquisition uncertainty is not always available for analysis. When it is available, it is generally lumped together into one term and reported either as a bounded nonspecificity: </p><formula>U vol = π 2 (x; B vol ) (15) </formula><p>or else a standard deviation (centralized discord): </p><formula>U vol = π * (x; B vol ) (16) </formula><p>where B vol indicates the range of uncertainty. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Quantization</head><p> A second potential source of uncertainty is quantization (U quant ). Often volume data is computed in floating-point format but is subsequently quantized to limited-range integer formats. This form of uncertainty is referred to as quantization noise, and its quantification can be derived based on either probabilistic analysis or possibilistic analysis . If nothing is known regarding the probability distribution of the quantization input then we can analyze quantization noise in the context of possibility theory. Based on a quantization step size q, the quantization uncertainty is a uniform possibility distribution bounded by ±q/2: </p><formula>U quant = π 2 (x; q/2) (17) </formula><p>That is, without additional information regarding the input there is no single most likely value, resulting in bounded uncertainty. On the other hand, if we have additional information about the pdf of the quantization input then we can perform an analysis based on probability theory, wherein the pdfs of the input and output of quantization are related based on principles of sampling theory. A complete treatise on this topic is given by Widrow and Kollar <ref type="bibr" coords="6,160.41,473.05,13.74,8.02" target="#b34">[36]</ref> , but basically if the quantization step size is sufficiently small then the quantization noise is a perfectly uniform pdf bounded by ±q/2. The resulting quantization uncertainty, being a uniform pdf, is transformed by Equation 2 to a triangular possibility distribution: </p><formula>U quant = π * (x; q/2) (18) </formula><p> Therefore, we have two potential representations of quantization uncertainty . Since the probabilistic alternative is more specific, we adopt this form in our analysis. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Volume Reconstruction</head><p> The volume rendering algorithm operates on scalar fields, so an important step is reconstruction of a continuous scalar field from the sampled volume data. The uncertainty at this step (U f iltering ) can be derived from sampling theory, as long as a few conditions are met. First, the volume signal must be bandlimited, and second, we assume that the trilinear interpolation filter is used. Error bounds based on these assumptions were first formulated based on linear interpolation of 1D signals by Smith and Gossett <ref type="bibr" coords="6,131.07,665.79,13.74,8.02" target="#b31">[33]</ref>, and later extended to bilinear and trilinear interpolation by Zheng et al. <ref type="bibr" coords="6,156.99,675.75,13.74,8.02" target="#b36">[38]</ref> . The error bound for reconstruction using trilinear interpolation is based on a third order Taylor expansion, with the resulting truncation bound given as: </p><formula>B f iltering ≤ d 2 vol 8 F xx + F yy + F zz + d 3 vol 4 (F xxy + F xyy + F xxz + F xzz + F yyz + F yzz + 3F xyz ) (19) </formula><p>where d vol is the sampling distance of the volume (i.e. voxel resolution) and F m = max| f m |, so that the bound depends on the mixed/partial derivatives f xx , f yy , f zz , f xxy , f xyy , f xxz , f xzz , f yyz , f yzz , and f xyz . Without additional information, bounds on these derivatives must be computed via finite difference formulae, which introduces an additional component of uncertainty that must be accounted for. Both of these error bounds fall into the category of truncation error, which is represented as bounded uncertainty. Therefore, the final expression for reconstruction uncertainty can be written as: </p><formula>U f iltering = π 2 (x; B f iltering ) (20) </formula><p>where B f iltering incorporates uncertainty of derivative estimates based on finite difference error bounds. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Classification</head><p>Classification is usually accomplished by a continuous functional mapping called the transfer function. Classification based on the transfer function obeys the basic principles of propagation of uncertainty as set out in Section 3.2. In particular, propagation based on a conventional transfer function is accomplished by Equation 9. On the other hand, a conventional transfer function can easily be fuzzified in order to express the uncertainty in the mapping itself, or else to determine the sensitivity of the final rendering in terms of the transfer function. The second general approach to classification is clustering and segmentation. There are two formulations of uncertain clustering, depending on the nature of the clusters. In probabilistic cluster- ing <ref type="bibr" coords="6,299.19,330.41,14.94,8.02" target="#b13">[14] </ref><ref type="bibr" coords="6,316.74,330.41,13.74,8.02" target="#b19">[20]</ref> , each cluster is a crisp set, so that an element either belongs to a given cluster or else it does not. However, the membership of each element is not known, which means that for each set an element has a corresponding measure which indicates the probability of that element belonging to the set. In fuzzy clustering <ref type="bibr" coords="6,481.45,370.26,14.94,8.02" target="#b14">[15] </ref><ref type="bibr" coords="6,499.09,370.26,13.74,8.02" target="#b23">[25]</ref>, each cluster is a fuzzy set, which means that an element may belong to a cluster with a varying degree of membership; each element thus has a measure of the degree of membership for each cluster. The key difference between these two approaches is that in the former an element in reality belongs to only one cluster, whereas in the latter it belongs to many clusters at once. The appropriate model for volume data depends on several factors, including the nature of the subject that the volume is modeling as well as the native sampling rate. In medical data, for instance, there may be distinct tissue boundaries, which would support a probabilistic model. However, if the resolution of the scan is low compared to the scale of the tissues then a single voxel may contain the contributions of multiple tissues, in which case a fuzzy model is more appropriate. The latter case, which is also referred to as the partial volume effect, is very common. The problem with the methods that we have mentioned so far is that they operate on exact data only. In order to propagate the uncertainty leading up to classification, the method must accommodate degrees of membership/probability with associated uncertainty, yielding in turn optical properties with uncertainty. One way to accomplish this is to simply implement the above methods using TPDs and fuzzy algebra. An alternative is to design the clustering analysis with explicit consideration of uncertainty, as in the area of fuzzy clustering of fuzzy data. An excellent review of work in this area is given by Oliveira and Pedrycz <ref type="bibr" coords="6,316.24,610.17,13.74,8.02" target="#b26">[28]</ref>. In order to compute the uncertainty in fuzzy clustering of fuzzy data, we consider a general fuzzy clustering function f C , so that the actual clustering algorithm is left open for specification. Some clustering algorithms may model the data better and in so doing produce better clustering, and so we designate ω val (in the range <ref type="bibr" coords="6,483.19,660.64,9.46,7.96">[0,</ref><ref type="bibr" coords="6,493.64,660.78,6.63,8.02" target="#b0"> 1]</ref>) to be the validity of the clustering model (similar to the credibility of the user in the case of transfer function specification). The clustering function takes as arguments a scalar value and its associated uncertainty and returns a membership grade/uncertainty for each cluster: </p><formula>f C (v, u(v)) = N c=1 {µ c (v), η c (v, u(v))} (21) </formula><p> where v is the scalar value, u(v) is its associated uncertainty, c designates the cluster (of which there are N), µ c is the membership function for cluster c, and η c is the uncertainty associated with membership in cluster c. The resultant intensity can then be computed by the membership-weighted mean of the optical properties of each constituent cluster: </p><formula>I(v) = 1 N N ∑ c=1 I c µ c (v) </formula><formula>(22) </formula><p>However, in order to compute the resultant uncertainty we take the maximum of the uncertainties from the constituent clusters: </p><formula>U classi f ication = max{1 − ω val , max{η c } N c=1 } (23) </formula><p>which is consistent with the idea that the clustering is only as reliable as the least reliable cluster assignment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Lighting</head><p> When the volume contains surfaces or regions of high gradient magnitude , using a surface-based lighting model can facilitate better appreciation of the 3D structure. Many such models have been developed, but for our purposes the basic Phong shading model suffices. In order to compute the diffuse and specular light, it is necessary to reconstruct the gradient field and its associated uncertainty. Quantification of this uncertainty is an open problem; however, we can simply treat the gradient field as three separate scalar fields and apply Equation 19 to each field, which results in three additional uncertainty terms. Therefore, the total uncertainty in lighting is computed as: </p><formula>U light = U gradX +U gradY +U gradZ (24) </formula><p> The uncertainty in the lighting computation itself is automatically handled by fuzzy operations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Integration</head><p> The accumulation of emitted light along a particular direction incident to the image plane is an integration along the image ray. Error bounds on the integration can be computed from quadrature rules for numerical integration, thereby allowing us to quantify the integration uncertainty (U integration ). Error bounds depend on the integration rule chosen and are based on the remainder terms of a Taylor expansion . Conventional volume rendering is based on Reimann integration, whose error bound for an integration from a to b is: </p><formula>B integration ≤ b − a 24 f (c)h 2 (25) </formula><p>where h is the integration step size and c ∈ <ref type="bibr" coords="7,182.32,487.31,16.59,7.96">[a, b]</ref>. Novins and Arvo <ref type="bibr" coords="7,266.94,487.45,14.94,8.02" target="#b25">[27] </ref>proposed an approach for bounding the second derivative term f (c), assuming that the classified volume field is piecewise polynomial. They also propose an alternative numerical integration using a power series expansion, in which the remainder term is evaluated in order to monitor the accumulated error, with the goal of computing the integral to a specified tolerance. Regardless of the integration rule used, as long as the derivatives can be bounded appropriately then the remainder term can be bounded, thereby yielding bounded possibilistic uncertainty: </p><formula>U integration = π 2 (x; B integration ) (26) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Image Construction</head><p>Sufficient sampling in the image plane is also necessary in order to prevent aliasing. This contributes an additional amount of uncertainty according to the viewport parameters, which can be bounded by the image reconstruction error <ref type="bibr" coords="7,128.86,646.58,13.94,8.02" target="#b36">[38]</ref>: </p><formula>B image ≤ d 2 img 8 (F xx + F yy ) + d 3 img 4 (F xxy + F xyy ) (27) </formula><p>where d img is the interpixel distance and F xx , F yy , F xxy , and F xyy are the largest magnitudes of the mixed/partial derivatives f xx , f yy , f xxy , and f xyy , respectively. The uncertainty due to image reconstruction/perception is then: </p><formula>U image = π 2 (x; B image ) (28) </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Fuzzy Volume Rendering</head><p>Having identified and quantified the relevant sources of uncertainty in volume rendering, we can now describe the construction of a verifiable volume rendering pipeline: in which each color channel is represented not by a real number, but rather by a TPD. We will consider some basic approaches, but a full treatise on this topic is beyond our scope. Let us begin by considering how to display an image in which each pixel is an interval, as would be produced by IA (Interval Algebra) or AA (Affine Algebra). We could display multiple images side-by-side, where each individual image corresponds to a position within the interval. In the simplest case we could display two images -one representing the lower bound and one representing the upper bound. If we restrict our focus to displaying only one image, then there are several possibilities, two of which are projection to the interval midpoint and interactive selection of one point. These methods can also be used directly for display of TPDs by specifying of a level of presumption α in Equation 3, which yields a confidence interval. Alternatively, we could represent the fuzzy image by four images, based on rendering using the endpoints of the core and support, as shown in <ref type="figure" coords="8,98.02,649.09,28.96,8.02">Figure 7</ref> . A single image can be produced by defuzzification to a real number, or by user interaction with an appropriate interface. Regardless, the goal is to communicate the uncertainty in the rendering, either directly or indirectly via exploration. </p><p>As an illustration of these ideas, consider the renderings shown in <ref type="figure" coords="8,22.50,706.53,30.52,8.02">Figure 1</ref>of the Aneurism dataset. In conventional volume rendering, the rendering parameters are set and the result is a single image. However , there is no indication given as to how reliable this image is, and whether other images are possible given the same settings. For this particular dataset and rendering parameters, it is difficult to assess the patency of the vessels. Fuzzy volume rendering, on the other hand, produces a set of possible renderings that provides an affordance for exploring the reliability. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>In order to evaluate our approach, we implemented a volume renderer using IA, AA, and the proposed approach based on TPDs, which we will designate TA for TPD Algebra. Our baseline implementation is software-based, since it is not possible to control floating-point rounding mode on the GPU, and this is necessary in order to preserve the fundamental invariant property. This version produces absolute uncertainty bounds, with the actual value guaranteed to be within the range. In comparing IA to AA, we find that the bounds for AA are generally tighter than those for IA. The relative differences of the bounds depends primarily on the sample spacing along the ray. As sample distance decreases and the samples are spaced closer together, the degree of dependency increases, giving AA an advantage. Consider two consecutive samples a small distance apart. There is a high likelihood that they reside within the same cube of voxels, and therefore when these samples are composited there will be a high degree of dependency , with the possibility of cancellation between the affine terms representing voxel uncertainty. These dependencies are represented as first-degree correlations in AA, and they serve to decrease the ble range of values. Numerical stability also plays a minor role, so that as more samples are composited the greater stability of IA gives it a small advantage, but unless there are no dependencies then this advantage is overshadowed by the magnitude of reduction in bounds that AA offers. In comparing uncertainty bounds from IA/AA to bounds derived from TA, it is necessary to consider what elements of uncertainty are being represented. Bounds from IA/AA represent only nonspecificity, and will be correspondingly narrow compared to bounds from TA. If we consider only nonspecificity, bounds from TA and IA will be identical . In <ref type="figure" coords="9,62.10,596.94,29.13,8.02" target="#fig_5">Figure 8</ref> , we compare bounds derived from these three methods for the Lobster dataset, demonstrating that TA is able to capture additional uncertainty that IA/AA cannot. In addition, TA is almost as efficient as IA, and significantly more efficient than AA. Another advantage of TA over IA and AA is its ability to represent more and less likely values in an accurate, flexible way. When dealing with the two main forms of uncertainty, IA discards the additional information that centralized uncertainty offers, whereas TA incorporates this information into the boundaries. On the other hand, AA, by mandating a single central value, assumes that all uncertainty is centralized. However , there may not be a single most likely value, and even when there is it may not be the exact center of the range. TA allows one or more most likely values (i.e. the core) located anywhere within the range. To summarize, IA is the most efficient, limited to tracking imprecision, and cannot represent centralized uncertainty. AA is the least efficient,  limited to tracking imprecision, and cannot represent bounded uncertainty . TA is somewhat efficient, manages all modes of uncertainty, and is able to represent both bounded and centralized uncertainty. While our software implementation is able to provide correct bounds, it is not interactive, and so it serves as more of an off-line tool that can be use to provide absolute verification once the rendering parameters have been determined. As an alternative, we also describe a GPU version of fuzzy volume rendering that performs the uncertainty analysis without rounding-mode control. This implementation runs in real-time and is very useful for interactively exploring the effects of uncertainty on rendering. Timing results for this version are compared to standard volume rendering in <ref type="figure" coords="9,452.46,366.50,29.71,8.02" target="#fig_6">Figure 9</ref>. Rendering was performed on a NVIDIA GeForce GTX480 with 1.5 GB of graphics memory. Our volume renderer uses proxy geometry to raycast the volume . TPDs, having four parameters, map well to GPU data types. In order to represent each color component as a TPD, we use frame buffers bound with four color textures and take advantage of multiple rendering targets to write the results of a single pass. Two frame buffers of this type are used in a ping-pong fashion, in order to composite the images. Shaders implement the volume rendering stages, modified with the uncertainty analysis, including accumulation and propagation rules. In order to correctly propagate uncertainty in reconstruction , however, native filtering cannot be used. After rendering, a final pass is required to accumulate the integration uncertainty and to defuzzify the resulting fuzzy image into the main framebuffer. Our GPU-based fuzzy volume renderer allows interactive modulation of the rendering parameters in order to explore the effects of the various individual elements of uncertainty, as shown in <ref type="figure" coords="9,464.93,525.90,29.02,8.02">Figure 7</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p> In this paper we present fuzzy volume rendering, a system that provides verifiable volume rendering via uncertainty analysis. This system is based on work in the field of reliable computing, and in this context we show how to apply existing uncertainty management methods to conventional volume rendering in order to compute a posteriori uncertainty bounds, thereby yielding fuzzy volume rendering. The quantification of uncertainty provides an opportunity to assign a degree of confidence, which in turns allows us to draw reliable conclusions and make informed decisions based on the visualization. We demonstrate this by showing the possible range of volume renderings resulting from a given parameter configuration, with comparisons to IA/AA in order to showcase the comprehensive nature of such an approach. In future work, we would like to investigate the adaptation of the proposed framework to perform sensitivity analysis, as well as explore the use of embedded uncertainty analysis to automatically control reliability . We would also like to extend this work to encompass more complex lighting models. Finally, we would like to more thoroughly explore the problem of how to display uncertain images as produced by fuzzy volume rendering. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2343">FOUT AND MA: FUZZY VOLUME RENDERING</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,33.49,699.32,244.40,6.86;1,31.50,708.78,144.33,6.86"><head></head><figDesc>Manuscript received 31 March 2012; accepted 1 August 2012; posted online 14 October 2012; mailed on 5 October 2012. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,31.50,156.27,250.38,7.37;3,31.50,165.74,250.38,7.37;3,31.50,175.20,106.01,7.37"><head>Fig. 2</head><figDesc> Fig. 2. In our system, a quantity and its associated uncertainty is represented by a trapezoidal possibility distribution (TPD), as defined by the four parameters a, b, c, and d. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,22.50,119.94,513.00,7.37;4,22.50,129.40,513.00,7.37;4,22.50,138.87,443.74,7.37"><head>Fig. 4. </head><figDesc>Fig. 4. Bounded uncertainty (red, green) is characterized by a uniform distribution bounded by upper and lower limits. Centralized uncertainty (yellow, orange) identifies a single most likely value, with other values having degrees of possibility. Accumulation of bounded and centralized forms of uncertainty as a trapezoidal form maintains all the information while providing an efficient means of propagating uncertainty. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,31.50,224.61,513.00,7.37;5,31.50,234.07,513.00,7.37;5,31.50,243.54,513.00,7.37;5,31.50,253.00,513.00,7.37;5,31.50,262.47,274.72,7.37"><head>Fig. 6. </head><figDesc>Fig. 6. (a) An ordinary function passes on the uncertainty in the data without additional accumulation. However, in general the resulting distribution will not be exactly trapezoidal, so we opt for a less specific trapezoidal approximation instead. (b) and (c) A fuzzy function not only propagates uncertainty but accumulates additional uncertainty related to the fuzziness of the mapping. There are several options for computing the output, based on how the uncertainty in the function and input are combined: max-max (b), max-min (c), and max-prod (c). When constraining the output form to be trapezoidal, both max-min and max-prod produce the same results. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,31.50,387.00,250.38,7.37;9,31.50,396.47,250.38,7.37;9,31.50,405.93,250.38,7.37;9,31.50,415.40,250.38,7.37;9,31.50,424.86,250.38,7.37;9,31.50,434.33,250.38,7.37;9,31.50,443.79,250.38,7.37;9,31.50,453.25,250.38,7.37;9,31.50,462.72,142.47,7.37"><head>Fig. 8. </head><figDesc>Fig. 8. Fuzzy volume rendering of the Lobster dataset: In the images on the left we render the width of the uncertainty bounds, with darker values indicating wider bounds. On the right, a part of one scan line is shown in order to facilitate comparison between the different approaches. Affine Algebra produces the tightest bounds, but at a significant computational cost, whereas Interval Algebra produces somewhat wider bounds. TPD Algebra produces comprehensive bounds that incorporate all relevant forms of quantitative uncertainty, with inner and outer bounds to identify more and less likely values, respectively. </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="9,294.12,180.14,250.38,7.37;9,294.12,189.60,250.38,7.37;9,294.12,199.06,250.38,7.37;9,294.12,208.53,250.38,7.37;9,294.12,217.69,250.38,7.70;9,294.12,227.46,26.79,7.37"><head>Fig. 9. </head><figDesc> Fig. 9. A GPU-based version of Fuzzy Volume Rendering is able to provide real-time uncertainty analysis during volume rendering, although it is substantially slower than conventional volume rendering. Shown in this figure are timing results in frames per second for rendering from various size datasets with a 1024 × 1024 viewport and sampling rate of 4/voxel. </figDesc></figure>

			<note place="foot">where £ represents data input/output, ⊕ is the accumulation operator , and represents processing with propagation of uncertainty. This symbolic representation of fuzzy volume rendering makes it clear that the rendering and its uncertainty are being computed in parallel. Based on this formula we can make several observations as to how the total uncertainty in volume rendering is related to the individual factors and parameters. Let us first consider factors related to the volume data itself. In terms of data acquisition, we can decrease the overall uncertainty by increasing the acquisition precision, for instance by using more advanced scanners or higher-precision computation. However , any uncertainty due to natural variation cannot be decreased. This concept is consistent with principles from information theory, in which it is known that uncertainty due to nonspecificity can be decreased/eliminated with additional information, whereas uncertainty due to discord cannot be reduced. Another way to reduce uncertainty is to increase the volume sampling rate by decreasing the sample distance (d vol in Equation 19). In terms of the volume rendering algorithm, we can identify five parameters that play an important role in determining the resultant uncertainty: quantization step size (q), integration step size (h), image sampling distance (d img ), transfer function fuzziness, and pipeline precision. Decreasing the first four of these parameters will decrease the overall uncertainty, as will increasing the precision. An interesting observation is made by considering the effects of changing the integration step size. According to Equation 25, decreasing the integration step size decreases the total uncertainty. However, decreasing the integration step size also increases the number of samples, but each sample brings with it an additional amount of uncertainty, so that the uncertainty increases. Therefore, there is an optimal integration step size that balances these competing effects in order to minimize the overall uncertainty. Consider now the image sampling distance, whose uncertainty is given by Equation 27. Increasing the pixel distance increases the uncertainty; this means that a high resolution image will have less uncertainty than a low resolution image, which seems intuitive. Classification deserves special consideration, as there are several factors that contribute to classification uncertainty. First of all, improvements in acquisition resolution can decrease uncertainty by reducing partial volume effects. In addition to this, increased knowledge and confidence in the definition of classes will serve to decrease uncertainty as well. This is more a matter of modeling, however, and falls under the category of validation as opposed to verification. Although we attempt to represent this mode of uncertainty in our system, a comprehensive treatment would indeed require validation, which is beyond the scope of our work. A final observation regarding classification involves uncertainty in transfer functions. Often a high-frequency transfer function is used to visualize a surface or boundary within the volume, with very sharp, crisp surfaces being desirable from an aesthetic viewpoint. However, high-frequency transfer functions will introduce significant uncertainty in the volume rendering. In fact, as we make the surface sharper the amount of uncertainty increases -in the extreme case the uncertainty bounds will degenerate (the bound of uncertainty is equal to the range of the data). This leads to the idea of an &apos;invalid&apos; transfer function -a transfer function that causes degeneration of uncertainty bounds. This important concept has not been discussed previously in volume rendering literature, but is important to address if rendering is to be used in making important decisions. It is not immediately apparent as to how to display an image generated by fuzzy volume rendering. Such an image will consist of pixels 2341 FOUT AND MA: FUZZY VOLUME RENDERING (a) Low U vol (b) Low-Mid U vol (c) High-Mid U vol (d) High U vol (e) U class {A} (f) U class {B} (g) U class {C} (h) U class {D} (i) U light {A} (j) U light {B} (k) U light {C} (l) U light {D} (m) U integ {A} (n) U integ {B} (o) U integ {C} (p) U integ {D} Fig. 7. The sensitivity of the resultant uncertainty with respect to uncertainty of individual components is explored by interactively changing the accumulation of one uncertainty term while holding the other terms constant. (a)-(d) The effects of increasing amounts of acquisition uncertainty on the final rendering are shown. The images are based on the midpoint of the core of the TPD image. Another way to explore the uncertainty is to consider only the uncertainty accumulated from one stage, and to show the range of possible renderings based on points A, B, C and D of the TPD, as defined in Equation 1. Using this approach, the range of uncertainty is shown for classification (e)-(h), lighting (i)-(l), and integration (m)-(p). Interestingly, uncertainty in these renderings sometimes appears as green due to the mixing of blue and orange. We observe that equal amounts of uncertainty have varying effects on the magnitude of the resultant uncertainty, depending upon how early the uncertainty is accumulated.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS </head><p> This research is sponsored in part by the National Science Foundation through grants CCF 1025269, CCF 0811422, OCI 0905008, OCI 0850566, and OCI 0749227, and the Department of Energy through grants DE-FC02-06ER25777 and DE-FC02-12ER26072, program manager Lucy Nowell. We would like to thank the reviewers for their extensive recommendations and substantial efforts towards improving the quality of this paper. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="10,40.76,169.23,232.12,7.13;10,40.76,178.69,232.12,7.13;10,40.76,188.16,232.12,7.13;10,40.76,197.62,128.69,7.13"  xml:id="b0">
	<analytic>
		<title level="a" type="main">A proposed methodology for computational fluid dynamics code verification, calibration, and validation</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Aeschliman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Oberkampf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Blottner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l. Congress on Instrumentation in Aerospace Simulation Facilities</title>
		<imprint>
			<date type="published" when="1995-07" />
			<biblScope unit="page" from="2701" to="2713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,207.08,232.12,7.13;10,40.76,216.63,232.12,6.86;10,40.76,226.01,122.20,7.13"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Affine arithmetic</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">V A</forename>
				<surname>Andrade</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">L D</forename>
				<surname>Comba</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Stolfi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l. Conf. on Interval and Computer-Algebraic Methods in Science and Engineering</title>
		<imprint>
			<date type="published" when="1994-03" />
			<biblScope unit="page" from="36" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,235.48,232.12,7.13;10,40.76,244.94,232.12,7.13;10,40.76,254.41,232.12,7.13;10,40.76,263.87,202.37,7.13"  xml:id="b2">
	<analytic>
		<title level="a" type="main">Combining probability and possibility to respect the real state of knowledge on uncertainties in the evaluation of safety margins</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Baccou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Chojnacki</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ENBIS/EMSE Conference Design and Analysis of Computer Experiments, Saint-Etienne (France)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,273.34,232.12,7.13;10,40.76,282.80,232.12,7.13;10,40.76,292.26,206.87,7.13"  xml:id="b3">
	<analytic>
		<title level="a" type="main">Joint propagation and exploitation of probabilistic and possibilistic information in risk assessment</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Baudrit</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Dubois</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Guyonnet</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="593" to="608" />
			<date type="published" when="2006-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,301.73,232.12,7.13;10,40.76,311.19,232.12,7.13;10,40.76,320.66,17.93,7.13"  xml:id="b4">
	<analytic>
		<title level="a" type="main">Computation and application of taylor polynomials with interval remainder bounds</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Berz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Hoffstatter</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliable Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,330.12,232.12,7.13;10,40.76,339.59,232.12,7.13;10,40.76,349.05,150.32,7.13"  xml:id="b5">
	<analytic>
		<title level="a" type="main">Uncertainty visualization: why might it fail?</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Boukhelifa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Duke</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int&apos;l Conf on Human Factors in Computing Systems</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="4051" to="4056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,358.52,232.12,7.13;10,40.76,367.98,232.12,7.13;10,40.76,377.45,79.47,7.13"  xml:id="b6">
	<analytic>
		<title level="a" type="main">A framework for uncertainty-aware visual analytics</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Correa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y.-H</forename>
				<surname>Chan</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K.-L</forename>
				<surname>Ma</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visual Analytics Science and Technology &apos;09</title>
		<imprint>
			<date type="published" when="2009-10" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,386.91,232.12,7.13;10,40.76,396.37,177.33,7.13"  xml:id="b7">
	<monogr>
		<title level="m" type="main">Vertex method for computing functions of fuzzy variables. Fuzzy Sets and Systems</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Dong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Shah</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="65" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,405.84,232.12,7.13;10,40.76,415.30,232.12,7.13;10,40.76,424.77,17.93,7.13"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Fuzzy computations in risk and decision analysis</title>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Dong</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Shah</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">F</forename>
				<surname>Wong</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Civil Engineering and Environmental Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="201" to="208" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,434.23,232.12,7.13;10,40.76,443.70,232.12,7.13;10,40.76,453.16,129.51,7.13"  xml:id="b9">
	<analytic>
		<title level="a" type="main">Probability-possibility transformations, triangular fuzzy sets, and probabilistic inequalities</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Dubois</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Foulloy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Mauris</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Prade</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reliable Computing</title>
		<imprint>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,462.63,232.12,7.13;10,40.76,472.09,110.47,7.13"  xml:id="b10">
	<monogr>
		<title level="m" type="main">Fuzzy sets and systems: theory and applications</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Dubois</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Prade</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
	<note>1st. edition</note>
</biblStruct>

<biblStruct coords="10,40.76,481.55,232.12,7.13;10,40.76,491.02,188.04,7.13"  xml:id="b11">
	<monogr>
		<title level="m" type="main">Possibility theory: an approach to computerized processing of uncertainty</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Dubois</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Prade</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Plenum Press</publisher>
		</imprint>
	</monogr>
	<note>1st. edition</note>
</biblStruct>

<biblStruct coords="10,40.76,500.48,232.12,7.13;10,40.76,509.95,232.12,7.13;10,40.76,519.41,191.86,7.13"  xml:id="b12">
	<analytic>
		<title level="a" type="main">The random-fuzzy variables: a new approach to the expression of uncertainty in measurement</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ferrero</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Salicone</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Instrumentation and Measurement</title>
		<imprint>
			<biblScope unit="page" from="1370" to="1377" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,528.88,232.12,7.13;10,40.76,538.34,232.12,7.13;10,40.76,547.81,221.74,7.13"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Volume visualization based on statistical transfer-function spaces</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Haidacher</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Patel</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Bruckner</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Kanitsar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Gröller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Visualization Symposium &apos;10, PacVis &apos;10</title>
		<imprint>
			<date type="published" when="2010-03" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,557.27,232.12,7.13;10,40.76,566.74,232.12,7.13;10,40.76,576.20,232.12,7.13;10,40.76,585.66,119.55,7.13"  xml:id="b14">
	<analytic>
		<title level="a" type="main">A comparison of neural network and fuzzy clustering techniques in segmenting magnetic resonance images of the brain</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Hall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Bensaid</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Clarke</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Velthuizen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Silbiger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Bezdek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="672" to="682" />
			<date type="published" when="1992-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,595.13,232.12,7.13;10,40.76,604.59,232.12,7.13;10,40.76,614.06,152.82,7.13"  xml:id="b15">
	<analytic>
		<title level="a" type="main">A generalized interval arithmetic</title>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Hansen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interval Mathematics, Lecture Notes in Computer Science</title>
		<editor>K. Nickel</editor>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="7" to="18" />
			<date type="published" when="1975" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,623.52,232.12,7.13;10,40.76,632.99,232.12,7.13;10,40.76,642.45,17.93,7.13"  xml:id="b16">
	<analytic>
		<title level="a" type="main">A next step: Visualizing errors and uncertainty</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Johnson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sanderson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications IEEE</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="6" to="10" />
			<date type="published" when="2003-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,651.92,232.12,7.13;10,40.76,661.38,188.28,7.13"  xml:id="b17">
	<analytic>
		<title level="a" type="main">The need for verifiable visualization</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Kirby</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Silva</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications IEEE</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="78" to="83" />
			<date type="published" when="2008-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,670.84,232.12,7.13;10,40.76,680.31,101.17,7.13"  xml:id="b18">
	<monogr>
		<title level="m" type="main">Fuzzy sets and fuzzy logic: theory and applications</title>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Klir</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Yuan</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
	<note>1st. edition</note>
</biblStruct>

<biblStruct coords="10,40.76,689.77,232.12,7.13;10,40.76,699.24,232.12,7.13;10,40.76,708.70,152.85,7.13"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Statistically quantitative volume visualization</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kniss</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Van Uitert</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Stephens</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G.-S</forename>
				<surname>Li</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Tasdizen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Hansen</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization Conf. &apos;05, VIS &apos;05</title>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="287" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,40.76,718.17,232.12,7.13;10,40.76,727.63,232.12,7.13;10,40.76,737.10,94.13,7.13;10,285.12,54.06,250.38,7.13;10,303.38,63.52,232.12,7.13;10,303.38,72.99,232.12,7.13;10,303.38,82.45,35.00,7.13"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Estimation and modeling of actual numerical errors in volume rendering Uncertainty visualization in medical volume rendering using probabilistic animation</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Kronander</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Unger</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Mller</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Ynnerman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum IEEE Trans. on Visualization and Computer Graphics</title>
		<editor>22] C. Lundstrom, P. Ljung, A. Persson, and A. Ynnerman</editor>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">136</biblScope>
			<biblScope unit="page" from="893" to="9021648" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,91.92,232.12,7.13;10,303.38,101.38,232.12,7.13;10,303.38,110.93,232.12,6.86;10,303.38,120.31,113.26,7.13"  xml:id="b21">
	<analytic>
		<title level="a" type="main">Type-2 fuzzy sets for modeling uncertainty in measurement</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mencattini</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Salmeri</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Lojacono</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 IEEE International Workshop on Advanced Methods for Uncertainty Estimation in Measurement</title>
		<meeting>the 2006 IEEE International Workshop on Advanced Methods for Uncertainty Estimation in Measurement</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="8" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,129.78,232.12,7.13;10,303.38,139.24,144.93,7.13"  xml:id="b22">
	<analytic>
		<title level="a" type="main">Lazy arithmetic</title>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Michelucci</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J.-M</forename>
				<surname>Moreau</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computers</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="961" to="975" />
			<date type="published" when="1997-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,148.70,232.12,7.13;10,303.38,158.17,232.12,7.13;10,303.38,167.63,208.46,7.13"  xml:id="b23">
	<analytic>
		<title level="a" type="main">Modified fuzzy c-mean in medical image segmentation</title>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Mohamed</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Ahmed</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Farag</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int&apos;l. Conf. on Acoustics, Speech, and Signal Processing &apos;99</title>
		<imprint>
			<date type="published" when="1999-03" />
			<biblScope unit="page" from="3429" to="3432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,177.10,195.46,7.13"  xml:id="b24">
	<monogr>
		<title level="m" type="main">Interval analysis</title>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Moore</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
	<note>1st. edition</note>
</biblStruct>

<biblStruct coords="10,303.38,186.56,232.12,7.13;10,303.38,196.03,190.74,7.13"  xml:id="b25">
	<analytic>
		<title level="a" type="main">Controlled precision volume integration</title>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Novins</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Arvo</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Volume Visualization Workshop &apos;92</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="83" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,205.49,232.12,7.13;10,303.38,214.96,215.73,7.13"  xml:id="b26">
	<monogr>
		<title level="m" type="main">Advances in Fuzzy Clustering and its Applications</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">V</forename>
				<surname>Oliveira</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Pedrycz</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,224.42,232.12,7.13;10,303.38,233.88,197.33,7.13"  xml:id="b27">
	<monogr>
		<title level="m" type="main">Approaches to uncertainty visualization. The Visual Computer</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">T</forename>
				<surname>Pang</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">M</forename>
				<surname>Wittenbrink</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">K</forename>
				<surname>Lodha</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="370" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,243.35,232.12,7.13;10,303.38,252.81,17.93,7.13"  xml:id="b28">
	<monogr>
		<title level="m" type="main">Fuzzy logic with engineering applications</title>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Ross</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
	<note>3rd. edition</note>
</biblStruct>

<biblStruct coords="10,303.38,262.28,232.12,7.13;10,303.38,271.74,232.12,7.13;10,303.38,281.21,232.12,7.13;10,303.38,290.67,70.62,7.13"  xml:id="b29">
	<analytic>
		<title level="a" type="main">A comprehensive framework for verification , validation, and uncertainty quantification in scientific computing</title>
		<author>
			<persName>
				<forename type="first">C</forename>
				<forename type="middle">J</forename>
				<surname>Roy</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">L</forename>
				<surname>Oberkampf</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods in Applied Mechanics and Engineering</title>
		<imprint>
			<biblScope unit="volume">200</biblScope>
			<biblScope unit="page" from="25" to="282131" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,300.14,232.12,7.13;10,303.38,309.60,232.12,7.13;10,303.38,319.07,221.40,7.13"  xml:id="b30">
	<analytic>
		<title level="a" type="main">Revealing uncertainty for information visualization</title>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Skeels</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Lee</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Smith</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Robertson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conf. on Advanced Visual Interfaces , AVI &apos;08</title>
		<meeting>. of Conf. on Advanced Visual Interfaces , AVI &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="376" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,328.53,232.12,7.13;10,303.38,337.99,232.12,7.13;10,303.38,347.46,147.65,7.13"  xml:id="b31">
	<analytic>
		<title level="a" type="main">A flexible sampling-rate conversion method</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Smith</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Gossett</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int&apos;l. Conf. on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="1984-03" />
			<biblScope unit="page" from="112" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,356.92,232.12,7.13;10,303.38,366.39,232.12,7.13;10,303.38,375.85,160.16,7.13"  xml:id="b32">
	<analytic>
		<title level="a" type="main">A spreadsheet approach to facilitate visualization of uncertainty in information</title>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Streit</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Pham</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Brown</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="61" to="72" />
			<date type="published" when="2008-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,385.32,232.12,7.13;10,303.38,394.78,232.12,7.13;10,303.38,404.25,108.91,7.13"  xml:id="b33">
	<analytic>
		<title level="a" type="main">A typology for visualizing uncertainty</title>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Thomson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Hetzlera</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Maceachrenb</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Gaheganb</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Pavel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE-5669</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,413.71,232.12,7.13;10,303.38,423.17,76.16,7.13"  xml:id="b34">
	<monogr>
		<title level="m" type="main">Quantization Noise</title>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Widrow</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">I</forename>
				<surname>Kollar</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>1st. edition</note>
</biblStruct>

<biblStruct coords="10,303.38,432.64,232.12,7.13;10,303.38,442.10,194.57,7.13"  xml:id="b35">
	<analytic>
		<title level="a" type="main">The concept of a linguistic variable and its application to approximate reasoning</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Zadeh</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="199" to="249" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,451.57,232.12,7.13;10,303.38,461.03,232.12,7.13;10,303.38,470.50,147.33,7.13"  xml:id="b36">
	<analytic>
		<title level="a" type="main">VDVR: Verifiable volume visualization of projection-based data</title>
		<author>
			<persName>
				<forename type="first">Z</forename>
				<surname>Zheng</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">W</forename>
				<surname>Xu</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Mueller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1515" to="1524" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,303.38,479.96,232.12,7.13;10,303.38,489.43,232.12,7.13;10,303.38,498.89,208.89,7.13"  xml:id="b37">
	<analytic>
		<title level="a" type="main">Modeling and performance analysis using extended fuzzy-timing Petri nets for networked virtual environments</title>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Zhou</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Murata</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<forename type="middle">A</forename>
				<surname>Defanti</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Sys. Man Cyber. Part B</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="737" to="756" />
			<date type="published" when="2000-10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
