<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Direct Volume Editing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-10-19">19 October 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Bürger</surname></persName>
							<email>buergerk@in.tum.de.</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Krüger</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rüdiger</forename><surname>Westermann</surname></persName>
							<email>westerma@in.tum.de.manuscript</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><forename type="middle">Rüdiger</forename><surname>Westermann</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Technische Universität München</orgName>
								<address>
									<addrLine>tum.3D</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Technische Universität München</orgName>
								<address>
									<addrLine>tum.3D</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Direct Volume Editing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-10-19">19 October 2008</date>
						</imprint>
					</monogr>
					<note type="submission">received 31 March 2008; accepted 1 August 2008; posted online</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Volume editing</term>
					<term>GPU</term>
					<term>painting</term>
					<term>carving</term>
					<term>annotations</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Interactive visual exploration of volumetric scalar fields is required in many different areas ranging from medicine and engineering to physics and biology. To support the exploration task, volume rendering techniques have been developed to a high degree of sophistication over the last decade. Today, direct volume rendering of data sets as large as 512 <ref type="bibr" target="#b2">3</ref> and beyond is possible at fully interactive rates on commodity desktop systems, and especially due to the rapid advancements in graphics hardware technology these capabilities are continually increasing.</p><p>Volume rendering is a powerful means for visualizing 3D scalar fields, and especially if used in combination with semi-automatic transfer functions and different rendering styles does it allow for an effective visual communication of complex structures in such fields and relationships between them. In practical applications, however, to improve the analysis process it is often desired to not only render the data but also to interactively edit this data. Examples thereof include the manual classification and segmentation of structures, the removal of structures to uncover regions of interest and thus to isolate important parts of the data, or the coloring of parts to emphasize relevant structures and to give extra information about them. Such mechanisms can help to effectively reveal and communicate the relevant information in 3D scalar fields and to create images that are easy to understand even by a non-experienced user.</p><p>Today we see, that the core functionality that is required to support the aforementioned mechanisms is available on recent graphics processing units (GPUs). Specifically, it is now possible to directly write into 3D textures on the GPU, and to efficiently apply local operations on the data stored in these textures, such as filtering or gradient computation. Thus, the time is ripe for opening a new area in volume visualization, which is concerned with the development of techniques for interactive volume editing. One of the research challenges here is to develop novel algorithms that are tailored to the specific GPU functionality, and which can directly be incorporated into interactive volume rendering tools to enable immediate visual feedback. This core methodology, if designed in a generic way without the restriction to a particular application, then has the potential to be used in a number of different scenarios. In particular, to support the editing process and to avoid putting the burden completely on the user, optional constraints can be integrated into these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Contribution</head><p>The primary focus of this paper is the development of fast and flexible methods for user-guided volume editing, such as coloring, erasing, pasting, segmentation, and annotation. Our long-term goal is to realize a volume processing tool exhibiting similar functionality to current image processing tools, which allow the user to interactively perform a multitude of image adjustments and enhancements. To achieve interactivity, all of the algorithms proposed in this work run entirely on the GPU, and they have been integrated into a GPU-based volume ray-caster to provide immediate visual feedback. We introduce some novel ways to leverage advanced GPU functionality like geometry shaders and the possibility to directly render into 3D textures, and we effectively exploit computational and bandwidth capacities on recent GPUs. Therefore, all of the editing operations demonstrated throughout this paper were executed at frame rates of 100 fps and higher. In combination with novel mechanisms to perform these operations at sub-voxel accuracy, a framework for visibility-guided interactive volume editing is presented.</p><p>Some of the editing techniques we introduce can effectively be used for volume illustration, where the basic goal is to enhance the perception of structures in the data and the relationships between them by emphasizing important features. In particular, we extend the work on direct volume illustration by Bruckner and Gröller <ref type="bibr" target="#b4">[5]</ref>, in that we provide an alternative way to annotate structures in a volume data set and show the use of high-resolution selection volumes for sub-voxel editing effects. Even though our techniques are not restricted to volume illustration, this particular application demonstrates the high potential of using these techniques as basic methodology.</p><p>Our paper makes the following specific contributions:</p><p>• We present an efficient GPU realization of the volume painting method proposed by Bruckner and Gröller <ref type="bibr" target="#b4">[5]</ref>, and we demonstrate the use of this method for interactive volume coloring as well as structure elimination and enhancement. This method was used in <ref type="figure" target="#fig_0">Figures 1a and 1b</ref>, respectively, to color an iso-surface, to erase parts of it and to add additional structures to it.</p><p>• We extend on the idea of selection volumes and present a volume editing technique that is independent of the volume resolution. It edits on a high-resolution selection volume and can, therefore, be used to apply editing effects at sub-voxel accuracy.  <ref type="figure" target="#fig_0">Figure 1c</ref> shows an example, where the upper text was painted on an iso-surface in the original volume, whereas the lower text was painted on an iso-surface in an upsampled sub-volume.</p><p>• We introduce surface particles to compute a local iso-surface parametrization. By using such particles, 2D textures can be mapped onto an iso-surface. This allows generating annotations that are aligned with an iso-surface, and which can effectively be used to give additional information about areal structures visible in the current view. <ref type="figure" target="#fig_0">Figure 1a</ref> shows a classified iso-surface which is enhanced by surface-aligned annotations.</p><p>• Building on the concept of surface particles, we present shapealigned "see-through" textures to generate windowed cutaways on iso-surfaces in 3D scalar fields. By using such textures, occlusions can effectively be reduced and important internal parts of a volume can be exposed. This method was used in <ref type="figure" target="#fig_0">Figure 1d</ref> to interactively generate a cutaway view of the piggy bank data set.</p><p>The remainder of this paper is organized as follows. In Section 2 we review previous work that is related to ours. The specific volume coloring technique we use in this paper, as well as its efficient realization on recent GPUs, is presented in Section 3. Section 3.3 is dedicated to the use of this technique for structure removal and enhancement. In Section 4 we present high-resolution selection volumes and demonstrate their use for sub-voxel accurate volume editing. Section 5.1 introduces structure-aligned textures for volume augmentation and annotation. We conclude the paper with a discussion of the advantages and limitations of our work, and we present some ideas for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The idea to emphasize certain aspects of 3D data by using different rendering styles in the drawing of a single image of the data is at the core of non-photorealistic rendering techniques <ref type="bibr" target="#b8">[9]</ref>. In the context of volume visualization this approach has been shown very useful to accentuate particular features in the data and thus to accommodate faster and better understanding of complex structures and the relationships between them. Over the last decade, a number of different so-called volume illustration techniques have been proposed, many of which have been integrated into GPU-based volume rendering systems to achieve interactive user-control.</p><p>Interrante et al. <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15]</ref> used curvature-directed strokes and dense sets of integral curves to convey surface shape. A general volume illustration rendering pipeline to enhance important features and regions was proposed by Ebert and Rheingans <ref type="bibr" target="#b7">[8]</ref>. Viola et al. <ref type="bibr" target="#b35">[36]</ref> suggested importance driven volume rendering to highlight interesting structures in volume data based on user-selected object importance. Different rendering styles including point stippling <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b23">24]</ref>, temporal domain enhancement <ref type="bibr" target="#b27">[28]</ref>, 2D texture synthesis on cross-sections of a volumetric model <ref type="bibr" target="#b28">[29]</ref>, and volumetric halos to improve depth perception of 3D structures <ref type="bibr" target="#b3">[4]</ref> have been used to enhance the expressiveness of volume visualizations. A new approach that uses the shape of the object to be illustrated to control its rendering styles, and which also allows to adapt the objects shape to a given curve skeleton, was presented in <ref type="bibr" target="#b5">[6]</ref>.</p><p>Especially if used in combination with focus+context techniques to combine multiple aspects of the data into a single visual event <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b2">3]</ref>, illustrative volume rendering has been shown to be very effective in communicating the essential information in complex volumetric data sets. An interactive system providing a toolbox of automatic illustration methods as well as focus+context mechanisms to enable selective exploration of volume data was presented by Bruckner et al. <ref type="bibr" target="#b4">[5]</ref>. In particular, they introduced screen-space aligned annotations to add extra information about particular structures and selection volumes to locally modulate the appearance of a volume. Our work builds on these mechanisms and extends them towards a more general use for volume illustration.</p><p>Finally it should be mentioned, that there is also ongoing research on the user interfaces used to directly interact with volumetric data sets in virtual environments, including aspects of 3D haptic input devices as well as haptic rendering techniques. Even though these aspects are important in the design of a volume editing tool, they are not addressed in our current work. Instead, we abstract from the input devices used and rather focus on the editing operations triggered by the user via these devices. Due to this reason we will not attempt to review the vast body of literature related to these issues, however, in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref> some devices and interaction models are discussed and many useful references on these subjects are given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VOLUME COLORING</head><p>The specification of appearance properties of volume data is typically performed via color transfer functions. Based on the seminal work by Kindlemann and Durkin <ref type="bibr" target="#b16">[17]</ref> on the design of feature-specific transfer functions that can be derived automatically from a data classification using first and higher-order statistics, such approaches have now been developed to a high degree of sophistication. Nevertheless, automated classification of volumes remains a challenging task, and semiautomatic techniques which allow the user to interactively guide the classification process often result in a more accurate assignment of appearance properties. Examples thereof include the user-guided selection of seed voxels to initialize automated region-growing <ref type="bibr" target="#b19">[20]</ref> or more sophisticated segmentation algorithms like the random walker <ref type="bibr" target="#b9">[10]</ref>, the dual-domain approach of Kniss et al. <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18]</ref>, or the machinelearning approach by Tzeng et al. <ref type="bibr" target="#b33">[34]</ref>, where a transfer function is iteratively refined from user-defined segmentations in 2D volume slices.</p><p>To support semi-automatic classification and segmentation of 3D volume data we now describe an interactive technique for voxel coloring. This technique works in the 3D domain, and it thus allows the user to consider the 3D shape of the structures to be colored as well as the spatial relationships between them. <ref type="figure" target="#fig_1">Figure 2</ref> demonstrates the application of this approach for the classification of a human skull. The proposed technique has been integrated into a GPU-based volume raycaster, enabling the user to obtain immediate visual feedback about the result of the issued operations. Later in the text we show how to overcome the restriction of volume coloring to the initial volume resolution by exploiting selection volumes for sub-voxel coloring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">3D Texture Painting</head><p>Initially, a 3D scalar field of size T x , T y , T z is loaded into a 3D texturethe source texture-on the GPU. Scalar values are mapped to color and opacity via a selected transfer function. If the user only wants to paint on an iso-surface in the scalar field, a one component 3D texture is used instead of a RGBA texture. Coloring always works on an additional 3D texture-the color texture-on the GPU, into which the user paints with the selected color. In iso-surface coloring this texture is initialized with a constant material color, otherwise it is initialized with the source color values. Working on such a copy allows for a special paint mode in which the paint operation resets the color by copying respective values from the source texture. In iso-surface painting, colors are reset by zeroing.</p><p>The 3D color texture is rendered using texture-based volume raycasting <ref type="bibr" target="#b22">[23]</ref>, i.e., by sampling the texture along the rays of sight and by blending color and opacity contributions according to the selected blend equation. In iso-surface rendering, sampling is performed in the source texture. Once the iso-surface is hit along a ray, the surface normal at this position is fetched from a pre-computed normal map and a local lighting model is evaluated. In this model, the color at the sample position in the color texture is used as material color. Upon initialization, the user starts painting the volume with a virtual brush. To position the brush in 3D space we either use a simple mouse-based interface or a six degree-of-freedom input device, i.e. a PHANToM Desktop Device Premium 1 from Sensable Technologies. This also allows us to give haptic feedback to the user, for instance, if painting is on an iso-surface and force feedback indicates that the brush touches the surface. To detect a contact between a surface and the brush we simply test the brush center point for being in close proximity to the surface, i.e. by sampling the volume at this point and testing whether the value is closer to the iso-value than a given tolerance. If this is the case, force feedback along the inverse gradient direction at this point is issued.</p><p>In our work we use a sphere-like volume brush for painting, which means that voxels closer to the brush center point than the selected sphere radius are painted with the current paint color. To manipulate the color of a voxel at position P, indicated by Color P , we use the paint equation proposed in <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b11">12]</ref>:</p><formula xml:id="formula_0">Color P = lerp(Color C OP Color P , Color P , G),<label>(1)</label></formula><p>The brush shape G is set such that a spherical color falloff with increasing distance to the brush center point is simulated:</p><formula xml:id="formula_1">G = 0, if |P C − P| &gt; m F (|P C − P|) else.<label>(2)</label></formula><p>Here, OP is one of a number of operations like REPLACE, ADD, or BLEND, which can be selected to modulate the initial volume color, P C is the position of the center point, Color C is the brush color, and m is the support of a user-defined falloff function F, which is used to simulate smooth color fading. When using a volume brush to color a volume data set, the color of every voxel contained in the brush volume has to be updated according to the selected color modulation function. In principle, the color update can be performed on the CPU, requiring the modulated texture to be reloaded onto the GPU. Even if it is possible to only replace those parts of the GPU texture that were affected by the coloring operation, this strategy still results in significant bandwidth requirements due to frequent data uploads to the GPU in the course of painting. To overcome this limitation, we propose a novel technique that runs entirely on the GPU and minimizes CPU-GPU data transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">GPU Implementation</head><p>To efficiently update 3D texture elements that are affected by a coloring operation, we exploit novel features of current Direct3D 10 class graphics hardware. Specifically, we use the geometry shader to create geometry on the GPU, we employ new functionality to update slices of a 3D texture directly on the GPU, and we utilize instanced render calls to reduce the number of calls that have to be issued from the application program. In <ref type="figure">Figure 3</ref> an overview of the pipeline setup for rendering into a 3D texture is shown.  <ref type="figure">Fig. 3</ref>. Illustration of the pipeline setup for painting into a 3D texture on the GPU. A single vertex is issued by the application program, and it is duplicated by the input assembler. In the geometry shader, every point is amplified to one quadrilateral, which in turn is sent to the rasterizer. The rasterizer uses slice IDs to route generated fragments into corresponding 3D texture slices. In the pixel shader the fragments are colored with respect to the selected modulation function.</p><p>Before the painting process is started, the user selects the specific brush parameters including the cutoff radius m used in Equation 2. From this radius the extend of the brush bounding box in local texture coordinate space is computed, yielding the size n x × n y × n z of the sub-volume that is affected by the coloring operation. These values are computed on the CPU and sent to the GPU as constant shader variables. To compute the position of the brush center point P in local texture coordinates in the range [0,1], we either use the coordinate returned by the 3D input device, or, if painting is on an iso-surface, it can also be determined from the fragments depth under the mouse cursor.</p><p>The application program then renders into a viewport of size T x , T y . A single vertex-with a coordinate equal to P scaled by T x , T y , T zis sent to the GPU, where it is rendered as instanced geometry with instance count n z . This causes the GPU to generate a stream of n z vertices, all of which carry the position P and an instance ID running from 0 to n z − 1. These vertices are passed through the vertex shader to the geometry shader, which, for each incoming vertex, spawns a quadrilateral centered at P x , P y and covering n x × n y pixels. The ID of the 3D texture slice into which this quadrilateral is to be rendered is computed as</p><formula xml:id="formula_2">SID = P z − n z 2 + IID,<label>(3)</label></formula><p>where IID is the instance ID of every vertex. This slice ID is used by the rasterizer to direct the fragment into the corresponding z-slice of the 3D texture. In the pixel shader, for every fragment its distance to the brush center is computed and Equations 1 and 2 are evaluated.</p><p>Updated color values are then written into the respective position of the 3D color texture slice, and the updated texture can immediately be used in the rendering pass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Structure Removal and Enhancement</head><p>The method proposed in the previous section can efficiently be used to paint color into a volume. Moreover, it provides a means to interactively erase parts from the volume and to add new structures to it. Erasing is performed by painting voxels with zero opacity, thus making structures completely transparent. Even though the erasing operation is conceptually simple, it does provide a very powerful means to interactively create cutaway views. In particular it can be used when traditional volume cutaway techniques have difficulties, e.g., when occluded and occluding structures are close together and have similar material properties. <ref type="figure">Figure 4</ref> shows such a case and a cutaway view that was generated by our method. Without using a data segmentation or a highly detailed clip geometry that can accurately separate structures from each other, in such scenarios the automated generation of a cutaway view remains a challenging task. <ref type="figure">Fig. 4</ref>. Parts of bone iso-surface in a MRI data set were removed manually to reveal interior brain structures.</p><p>In the current implementation, new structures can only be added to iso-surfaces in the scalar field, i.e., if iso-surface rendering is performed. This operation is realized by a slight change of the color modulation function. Instead of replacing or modulating the colors stored in the 3D color texture, a density offset is painted into the source volume. By adding offsets of different strength and different size and shape, a number of editing effects can be achieved (see <ref type="figure" target="#fig_2">Figure 5)</ref>.</p><p>When erasing or adding iso-surface structures, surface normals have to be updated accordingly. This is accomplished by a) finding all voxels in the pre-computed normal map that are contained in the brush volume, b) re-computing the normals using central differences in the source volume, and c) writing updated normals into the normal map. Steps a) and c) are performed in exactly the same way as described for volume coloring, with the only difference that the brush volume has to be slightly enlarged to capture all affected voxels. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SELECTION VOLUMES</head><p>The volume coloring method as described so far restricts the accuracy of the coloring process to the resolution of the given volume data set. This allows one to assign voxel properties on a per-voxel basis, but the method is not capable of assigning such properties at sub-voxel accuracy. On the other hand, in particular if color painting is used to manually segment objects in the data, sub-voxel accuracy is required to determine correct segment boundaries. Similar to surface-based segmentation methods, where the mesh is not constrained to lie on voxel boundaries, our goal is to provide a much higher spatial resolution in regions where the user expects voxel-based classification to fail.</p><p>For this purpose we use selection volumes as introduced by Gröller [5], who stated, that "A selection volume specifies a particular structure of interest in a corresponding data volume. It stores real values in the range [0,1] where zero means not selected and one means fully selected.". A selection volume has the same spatial resolution as the original volume and its voxel values are used to modulate the initial data values. To make selection volumes applicable for data segmentation, we extend them in several ways: Firstly, in addition to extent and position the user can select the resolution of the selection volume. Secondly, the selection volume is "filled" with data values by resampling the source texture. It can thus be seen as an upsampled version of a sub-volume, and it is accompanied by a color volume of equal resolution to support voxel editing. Thirdly, the GPU volume ray-caster, which is used to render the original volume and the selection volume in combination, is adapted appropriately. This means, that the raycaster not only finds the intersection points between the rays and the selection volume but also adapts the step size within this volume to its resolution. In iso-surface rendering, a uniform step size is used to avoid cracks at selection volume boundaries.</p><p>In <ref type="figure">Figure 6</ref> we illustrate the use of selection volumes for sub-voxel classification, segmentation, and modeling. The leftmost image shows two voxel-sized structures that have been segmented manually in a selection volume. Due to the increased resolution of this volume, object boundaries can be resolved at very high accuracy. In the middle images, structures in the interior of a volume were classified by using a particular color transfer function. In the right image a high-resolution selection volume was used to obtain smooth structure boundaries. The rightmost image shows the effect of iso-surface enhancement in a high-resolution selection volume and the low-resolution base volume. Text was painted onto an iso-surface by manually adding density offsets into the respective source textures.  <ref type="figure">6</ref>. The use of selection volumes is demonstrated: a) two small features are segmented at sub-voxel accuracy. b) a sub-volume at the initial and a much higher resolution is rendered with a different transfer function than the initial volume. c) editing effects on an iso-surface in the initial volume and a high-resolution selection volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Upsampling</head><p>To build a selection volume two different strategies are pursued. For direct volume rendering, voxel colors are tri-linearly interpolated in the initial color texture. For iso-surface rendering, a piecewise quadratic tensor product spline is used for resampling the source texture (see <ref type="figure" target="#fig_6">Figure 7)</ref>. This results in a C 1 -continuous quasi-interpolant exhibiting a smooth gradient field. </p><formula xml:id="formula_3">v i−1 , v i ) and B := 0.5 (v i , v i+1 ) are computed.</formula><p>Then, a quadratic Bézier-spline with the control polygon A, v i , B is constructed using the DeCasteljau algorithm. Thus, at x the associated index i has to be computed first by rounding to the next integer, i.e.,i := x + 0.5 . The parameter p i at which to evaluate the spline is then given as p i (x) := 0.5 + x − i. Observing that the interpolation to compute A is collinear with the interpolation between A and v i (and analogously for B and v i+1 ), only two linearly interpolated fetches are necessary. These fetches can be performed by the GPU as  Since the interpolated nodes lie halfway between the samples of the initial volume, we introduce a transition region that is half a voxel wide (with respect to the initial grid). In this region, tri-linear interpolation in the source texture is performed to guarantee C 0 continuity between the selection volume and the source volume. In the interior, the selection volume is built by tri-quadratic quasi-interpolation in the source texture, and a smooth normal map is computed on-the-fly from this volume. <ref type="figure">Figure 6(d)</ref> demonstrates the fine editing details that can be achieved by applying the operations described so far on a high-resolution selection volume.</p><formula xml:id="formula_4">A := lerp (v i−1 , v i , 0.5 + 0.5 • p) and B := lerp (v i , v</formula><p>In general, selection volumes can be used to add fine structures or color details to a 3D volume or an iso-surface in it. Selection volumes can thus be used to directly paint additional text on a surface, which provides a general means for adding surface-aligned annotations. However, as writing text on a curved surface in 3D is rather cumbersome, we propose an alternative GPU method to automatically align 2D textures containing text or other annotations on an isosurface. For a good description of the process to be used to automatically place screen-space annotations we refer the reader to <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SURFACE PARTICLES</head><p>We start our description by introducing GPU surface particles, which are used to map a 2D grid consisting of vertices and edges between them onto an iso-surface, i.e., to find a local surface parametrization. Our approach is similar in spirit to the one proposed by Ropinski et al. <ref type="bibr" target="#b30">[31]</ref>, but, in contrast, it is performed directly in 3D object space, and it operates entirely on the GPU. The 2D grid is rendered on top of the iso-surface as a textured polygon mesh. The texture contains the annotation to be used, for instance, a bit-mapped text or a pattern indicating a particular property.</p><p>A surface particle can be thought of as a particle moving on the surface. The direction of the movement is given by an external direction field that is defined by the user when placing the annotation. In any case, to move a particle on the surface we compute its trajectory P(u) in a vector field v, starting at an initial position (x, y, z) on the surface. This requires to solve the ordinary differential equation:</p><formula xml:id="formula_5">∂ P ∂ u = v(P(u))<label>(4)</label></formula><p>with initial condition P(0) = (x, y, z). To numerically solve this equation we employ classical Euler integration using a fixed step size Δu. For a thorough overview of particle tracing in vector fields let us refer here to the state-of-the-art report by Laramee et al. <ref type="bibr" target="#b24">[25]</ref>, and to <ref type="bibr" target="#b20">[21]</ref> for the efficient implementation of particle tracing on programmable GPUs.</p><p>It is clear, that in general the numerical integration brings away the particle from the surface. Even if the vector field is everywhere defined in the local surface tangent plane, a particle is moving away from the surface in non-planar regions. To avoid this behavior, after every integration step we trace the particle back onto the surface, resulting in the following steps that have to be performed:</p><p>• Integration From the previous particle position, P, and the velocity at this position, v, the new position P = P + Δu • v is computed. In the very first iteration v is set to zero.</p><p>• Backtracing P is corrected by tracing the particle back onto the selected iso-surface.</p><p>• Vector lookup The velocity vector v at position P is determined. This can be as simple as a texture lookup into a 3D vector field, or a 2D vector field if a surface parametrization exists, or it can be a more complex computation such as a curvature estimation.</p><p>While it is clear how to perform particle integration and vector lookup, the method to trace particles back to the surface requires some further explanation. In principle, moving it back onto the surface would require to bend the line segment connecting the current and the fixed previous particle position around the surface, thereby constraining the bending to the plane defined by this line segment and the surface normal at the previous position. Since this approach requires some exhaustive computations, we approximate it by iteratively correcting the current position towards the surface, thereby assuming the surface to be locally flat. <ref type="figure">Figure 8</ref> illustrates this approximation for a particle that has left the surface after integration.</p><p>Back-tracing is performed by using the surface normal at the previous position, i.e. the gradient of the scalar field at this position, scaled by the difference between the scalar values at the previous and the current position. The direction of this vector determines whether the current position is inside the surface or outside. Note that using the normal at the current position is not feasible in general, since this point is not on the surface and the normal at this point may be affected by noise. Given this direction, the current particle is traced from the current position into this direction until the difference between the scalar values at the corrected position and the selected iso-value drops below a user-given tolerance. In this case we have reached the surface and terminate the correction. If the particle crosses the iso-surface, which is indicated by increasing difference between the scalar value at the particle position and the iso-value, the step size is halved and the trace is restarted at the last position.</p><p>The accuracy of the proposed method depends on the local curvature of the iso-surface. The less planar the surface is, the higher can be the length distortion of a line segment connecting the previous and the current point. The reason therefore is, that we only consider the normal at the previous point to determine the direction into which the particle is corrected. This problem could be alleviated by also considering the curvature direction in the plane spanned by the previous surface normal and the advection direction, but as the step size we use for particle integration is typically small, i.e. in the order of the voxel size, in our experiments length distortions did not result in any noticeable artifacts.</p><p>Iso sur fa c e Normal Force Backtrace <ref type="figure">Fig. 8</ref>. One particle advection step is illustrated: Firstly, the particle is moved into the direction of the vector field (red) to an intermediate position (green). In the next step it is traced into the direction of the previous normal vector until it reaches the surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Volume Annotations</head><p>Volume annotations in the form of arrows and labels have a long history in hand-made technical and medical illustrations. Textual annotations are typically used in two different ways. They are either placed directly on the surface of a structure-aligning their shape to the surface shape-or they are placed in screen-space close to the image of a structure, and they are then connected to the structure with a line. In general, the former method has the advantage that annotations remain fixed to a structure when the user interacts with the volume, while freefloating labels have to be rearranged in screen-space to avoid overlapping annotations, crossing of connecting lines, or placements too far away from the structure. Free-floating annotation, on the other hand, are advantageous for pointing to small structures which do not cover enough space on screen to allow the user to read the annotation on it. Therefore, our system supports both approaches to annotate volumes, and it thus allows the user to flexibly select the appropriate choice.</p><p>By using surface particles we can now construct a regular grid, which is aligned with an iso-surface and can be textured with an arbitrary annotation. As the process is performed entirely on the GPU, the user can interactively place high-resolution annotations in the volume. To start the process, the user first selects a texture, the annotation texture, which is to be used as annotation. Then, some additional information has to be specified:</p><p>• The position on the iso-surface where the annotation is to be centered.</p><p>• The orientation of the annotation.</p><p>To specify the annotation center point the user picks a point on the iso-surface. The orientation of the annotation texture is specified by picking a second point and by interpreting the vector from the first to the second point as the u-axis of the local (u,v) surface parametrization. In the following, we will call this vector the orientation vector. Given this information, a set of surface particles is traced to generate a grid that is aligned with the surface.</p><p>At first, two surface particles are spawned at the annotation center point. One of them is traced along the orientation vector, and the other one is traced into the inverse direction. Both particles are traced for a number of equidistant steps and their intermediate positions are written into a GPU render target. Both the number of steps and the step size in voxel units can be selected by the user.</p><p>At every particle position the direction vector moving the particle along the surface is computed from the direction vector at the previous position. Starting with the normalized projection of the orientation vector into the tangent plane at the annotation center point, at every upcoming position the same procedure is performed with the previous direction vector. That is, for a particle at position P u we compute a tangent frame consisting of three mutually orthonormal vectors: N, the surface normal, F the direction vector in the local tangent plane, and B, the cross product between N and F. Initially, F is computed from the given orientation vector, O, as follows:</p><formula xml:id="formula_6">F = O × N × O | O × N × O | (5)</formula><p>In the next advection step, O is set to F, and the projection is with respect to the current tangent plane. Surface normals are computed by tri-linear interpolation of the gradients at adjacent voxel centers. Finally, the particle is advected using F and it is then traced back to the surface as described in the previous paragraph. <ref type="figure">Fig. 9</ref>. Surface-aligned annotations. Left: the annotation grid. Right: an annotation texture that is mapped onto the grid. <ref type="figure" target="#fig_0">Fig. 10</ref>. Images from a volume editing session. From left to right: the initial data set, structures are removed, surface color is applied, annotations are added. The rightmost image is taken from the classical anatomy book "Gray's Anatomy" by Henry Gray <ref type="bibr" target="#b10">[11]</ref> for comparison.</p><p>After the two surface particles that were released at the annotation center point have been traced for n steps, a number of 2n + 1 surface points are stored in a GPU render target. If these points are connected they form a line on the surface, centered at the annotation center point and oriented along the annotation direction. To expand this "line" to a full 2D grid, at every point we trace two additional surface particles into direction B and into the inverse direction. Tracing these particles for m steps results in a set of (2m + 1) • (2n + 1) points, from which a regular triangular annotation grid is built (see <ref type="figure">Figure 9</ref>). All grid points are rendered into a vertex buffer, which is then used to render the grid using an appropriate index buffer residing in GPU memory. The grid is textured with the selected annotation texture, and it is rendered before ray-casting the volume to initialize the depth buffer. To avoid depth fighting between the iso-surface and the annotation grid, the grid is slightly shifted towards the viewer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Windowed Cutaway Views</head><p>In this paragraph, we show how to efficiently create a shape-aligned windowed cutaway section on an iso-surface by exploiting an annotation grid as introduced before. In technical illustrations, cutaways are often used to reduce occlusions and expose important internal parts. There is a vast body of literature related to this issue that we will not attempt to overview here, however, Diepstraten et al. <ref type="bibr" target="#b6">[7]</ref> and Li et al. <ref type="bibr" target="#b25">[26]</ref> discuss some of the mechanisms to automatically generate cutaway views and provide many useful references on this subject.</p><p>Starting with such a surface-aligned grid, we proceed in two stages. Firstly, we duplicate the mesh and displace the vertices of the copy along the inverse surface normal direction at the center vertex. The length of the displacement can be selected by the user to generate thin or thick cutaway sections. Secondly, both meshes are connected along their borders to build a closed mesh. This mesh is then used as a clip geometry as proposed by Weiskopf et al. <ref type="bibr" target="#b36">[37]</ref>, and it is directly incorporated into the texture-based volume ray-caster.</p><p>Prior to ray-casting, we render a layered depth-buffer of the mesh from the current view. During volume rendering, every ray first samples these buffers and then tests all samples along the ray for being inside or outside the mesh, i.e. by testing whether a sample is in-between a front and a back face of the cutaway mesh. Samples inside the mesh do not contribute to the final ray color, thus cutting away the volume contained in it. <ref type="figure" target="#fig_0">Figure 1(d)</ref> demonstrates the use of a shape-aligned cutaway to expose internal parts of a volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">PERFORMANCE ANALYSIS</head><p>Throughout this paper we have shown a number of different effects that were generated by the proposed volume editing techniques. A typical use of these techniques is demonstrated in <ref type="figure" target="#fig_0">Figure 10</ref>, where a human skull data set was interactively processed and augmented to obtain an illustrative image as shown in "Gray's Anatomy" <ref type="bibr" target="#b10">[11]</ref>. In the following, we investigate the performance of these techniques in more detail. Timings were performed on a 2.4 GHz Core 2 Duo processor and an NVIDIA 8800GTX graphics card with 768 MB local video memory. Image generation was done at 1280 × 1024 resolution. Regardless of this extreme resolution, for all models shown we achieve real-time performance with update rates of 50 fps and higher, including editing and rendering.</p><p>All brush-based editing effects like coloring, erasing, and adding, as well as resulting normal map updates, were executed in less than 3 ms up to a brush extend of 64 3 voxels. The times it takes to build a selection volume at different resolutions, i.e., from (3 × 2) 3 to (64 × 8) <ref type="bibr" target="#b2">3</ref> , is given in <ref type="table" target="#tab_1">Table 1</ref>. As can be seen, even at a resolution as high as 128 <ref type="bibr" target="#b2">3</ref> , GPU-based resampling is still capable of achieving interactive rates. Finally, we measured the time it takes to construct a surface-aligned annotation grid by means of the method described in Section 5. <ref type="table" target="#tab_2">Table  2</ref> shows respective times for varying grid sizes. From these timings it can be concluded, that the proposed method is fast enough to allow for interactive placements of annotation textures on high-resolution surface structures. In particular, since the rendering of these textures only consumes an insignificant amount of time, many of them can be used simultaneously on a single object. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Covered voxels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>In this paper, we have presented a number of GPU-based techniques for interactive volume editing. By efficiently using novel functionality on recent GPUs, we have developed a technique for interactive volume painting. We have further shown that this technique provides a powerful means to erase structures in a volume and thus to isolate features in it. In combination with high-resolution selection volumes these techniques can effectively be used for manual volume segmentation at sub-voxel accuracy. We have also introduced structure-aligned annotations to supplement classical free-floating annotations that are placed in screen-space, and we have demonstrated how to utilize this approach to interactively create windowed cutaway views. In particular, as all of these operations are performed in the 3D domain, with immediate visual feedback provided, they are very intuitive to use and allow the user to quickly observe the relationships between relevant features in the data. In the future we will further extend some of the proposed techniques: Firstly, we will develop semi-automatic volume segmentation techniques by combining manual segmentation as proposed with automatic techniques on the GPU, like the random walker approach. We believe that such a combination can considerably improve the segmentation process, both with respect to accuracy and speed. Secondly, we are aware that the construction of structure-aligned annotations as described in this work can produce distortions and even folds in highly curved regions. In the future we will investigate the use of constraint mass-spring systems on the GPU to avoid such artifacts. Thirdly, we will pursue research on the integration of focus+context approaches into direct volume editing techniques. In this way, additional visual cues can be provided to the user, resulting in an improved understanding of complex structural relationships in 3D.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>We present basic methodology for interactive volume editing, such as coloring, carving, enhancement, and annotation at sub-voxel accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>An iso-surface in the visible human head data set is shown. The surface was colored to emphasize the anatomy of the human skull. Surface-aligned annotations, described in Section 5, were added.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Interactive volume editing was used to manually remove structures from an iso-surface and to add structures to it.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig.</head><label></label><figDesc>Fig. 6. The use of selection volumes is demonstrated: a) two small features are segmented at sub-voxel accuracy. b) a sub-volume at the initial and a much higher resolution is rendered with a different transfer function than the initial volume. c) editing effects on an iso-surface in the initial volume and a high-resolution selection volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Denoting initial samples with v i in voxel coordinates (i.e., ranging from 0 to N − 1 for N voxels), additional samples at positions x ∈ [i − 0.5, i + 0.5[ are computed in two steps. First, intermediate values A := 0.5 (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>i+1 , 0.5 • p), where lerp(a, b, c) := a+c•(b − a). Finally, the second stage of the DeCasteljau algorithm to yield the final value v res := lerp (A , B , p) is computed in a pixel shader.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>The piecewise quadratic spline used for upsampling a selection volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Timing statistics for tri-quadratic iso-surface and trilinear color resampling. All times are given in milliseconds.</figDesc><table><row><cell>Scaling</cell><cell>3 3</cell><cell>11 3</cell><cell>19 3</cell><cell>32 3</cell><cell>64 3</cell></row><row><cell>2</cell><cell cols="4">0.14 0.19 0.24 0.51</cell><cell>2.7</cell></row><row><cell>4</cell><cell cols="3">0.16 0.31 0.76</cell><cell>2.5</cell><cell>17.9</cell></row><row><cell>8</cell><cell>0.2</cell><cell>1.0</cell><cell cols="3">4.29 17.1 134.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Timing of surface-aligned construction of annotation grids.</figDesc><table><row><cell></cell><cell cols="2">Gridsize</cell></row><row><cell cols="3">11 2 21 2 41 2</cell><cell>81 2</cell></row><row><cell>Time (in ms) 1.6</cell><cell>2.0</cell><cell cols="2">3.6 14.7</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A haptic interaction method for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Sobierajski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE VIS &apos;96: Proceedings of the 7th conference on Visualization &apos;96</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="197" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Illustrative contextpreserving volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Illustrative context-preserving exploration of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1559" to="1569" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enhancing depth-perception with flexible volumetric halos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Volumeshop: An interactive system for direct volume illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization 2005</title>
		<meeting>IEEE Visualization 2005</meeting>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="671" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Shape-aware volume illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurographics 2007)</title>
		<meeting>Eurographics 2007)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="705" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Interactive cutaway illustrations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diepstraten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proceedings of Eurographics 2003)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="523" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Volume illustration: Non-photorealistic rendering of volume models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization 2000 (Conference Proceedings)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Non-Photorealistic Rendering. AK Peters Ltd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gooch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gooch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Random walks for interactive organ segmentation in two and three dimensions: Implementation and validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schiwietz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Gray&apos;s anatomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1901" />
			<publisher>Running Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Direct wysiwyg painting and texturing on 3d shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeberli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="215" to="223" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Two-level volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">I</forename><surname>Bischi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="242" to="252" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A constraintbased technique for haptic volume exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ikits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Brederson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIS &apos;03: Proceedings of the 14th IEEE Visualization 2003 (VIS&apos;03)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Illustrating surface shape in volume data via principal direction-driven 3D line integral convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Illustrating transparent surfaces with curvature-directed strokes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Vis</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-automatic generation of transfer functions for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Durkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VVS &apos;98: Proceedings of the 1998 IEEE symposium on Volume visualization</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multidimensional transfer functions for interactive volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interactive texture-based volume rendering for large data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mcpherson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Painter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="52" to="61" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Interactive volume segmentation with the pavlov architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kreeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PVGS &apos;99: Proceedings of the 1999 IEEE symposium on Parallel visualization and graphics</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A particle system for interactive visualization of 3D flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kipfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kondratieva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="744" to="756" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ClearView: An interactive context preserving hotspot visualization technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics (Proceedings Visualization / Information Visualization</title>
		<imprint>
			<date type="published" when="2006-09" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Acceleration Techniques for GPU-based Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient stipple rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IADIS Computer Graphics and Visualization</title>
		<meeting>IADIS Computer Graphics and Visualization</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The state of the art in flow visualization: Dense and texture-based techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Doleisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vrolijk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interactive cutaway illustrations of complex 3d models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salesin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonphotorealistic volume rendering using stippling techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Vis</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hardware-accelerated parallel non-photorealistic volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Non-photorealistic Rendering and Animation (NPAR)</title>
		<imprint>
			<date type="published" when="2002-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Volumetric illustration: designing 3d models with internal textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Owada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Okabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Igarashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="322" to="328" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">on-the-fly&quot; voxelization for 6 degrees-of-freedom haptic virtual sculpting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VRCIA &apos;06: Proceedings of the 2006 ACM international conference on Virtual reality continuum and its applications</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Internal labels as shape cues for medical illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Prani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Hinrichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Fall Workshop on Vision, Modeling, and Visualization (VMV07)</title>
		<meeting>the 12th International Fall Workshop on Vision, Modeling, and Visualization (VMV07)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="203" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Haptics for scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><forename type="middle">M</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH &apos;05: ACM SIGGRAPH 2005 Courses</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">174</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Smith. Paint. Technical Memo</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="1978-07" />
		</imprint>
		<respStmt>
			<orgName>Computer Graphics Lab, New York Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An intelligent system approach to higher-dimensional classification of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-Y</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Illustrative visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bhler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sousa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stredney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>IEEE</publisher>
			<pubPlace>Vis</pubPlace>
		</imprint>
	</monogr>
	<note>Tutorial #4</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Importance-driven volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization 2004 (Conference Proceedings)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="139" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Volume clipping via per-fragment operations in texture-based volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Vis</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="93" to="100" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
