<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Relation-Aware Volume Exploration Pipeline</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-10-19">19 October 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Ming-Yuen</forename><surname>Chan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Huamin</forename><surname>Qu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ka-Kei</forename><surname>Chung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai-Ho</forename><surname>Mak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Yingcai</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
								<address>
									<addrLine>Clear Water Bay</addrLine>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Relation-Aware Volume Exploration Pipeline</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-10-19">19 October 2008</date>
						</imprint>
					</monogr>
					<note type="submission">received 31 March 2008; accepted 1 August 2008; posted online</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Exploratory Visualization</term>
					<term>Relation-Based Visualization</term>
					<term>Visualization Pipeline</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Volume exploration is an important issue in scientific visualization. Research on volume exploration has been focused on revealing hidden structures in volumetric data. While the information of individual structures or features is useful in practice, spatial relations between structures are also important in many applications and can provide further insights into the data. In this paper, we systematically study the extraction, representation, exploration, and visualization of spatial relations in volumetric data and propose a novel relation-aware visualization pipeline for volume exploration. In our pipeline, various relations in the volume are first defined and measured using region connection calculus (RCC) and then represented using a graph interface called relation graph. With RCC and the relation graph, relation query and interactive exploration can be conducted in a comprehensive and intuitive way. The visualization process is further assisted with relation-revealing viewpoint selection and color and opacity enhancement. We also introduce a quality assessment scheme which evaluates the perception of spatial relations in the rendered images. Experiments on various datasets demonstrate the practical use of our system in exploratory visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Effective volume visualization is a challenging yet important problem. It concerns not only the rendering of scalar or vector datasets as images, but also how to discover meaningful information and present them in a comprehensible manner. The ultimate goal of the visualization process is to provide useful insights into datasets. It relies on exploration techniques to facilitate the search of useful features in the volume and visualization techniques to convey these findings to viewers through rendered images. With the advancement of data acquisition techniques and scientific simulation methods, the difficulties in data exploration and analysis have increased with the complexity and size of the volumes. It requires efficient ways of understanding the data by extracting meaningful features in the volume and providing effective visual representations of the data to viewers.</p><p>Most of the conventional methods place emphasis in conveying details of the desired features or structures by exposing them clearly to viewers in the results. However, spatial relations between the structures in a volume are also of interest to viewers. For example, surgical planning for cardiovascular operations requires not only a proper illustration of the shape of the pathological vessels and organs, but also the spatial relations (e.g., how close they are) between them. Such spatial relation information of structures is crucial for visual analysis and the understanding of volumetric data in various applications.</p><p>Volume visualization, especially direct volume rendering, provides a powerful scheme for users to understand the spatial relations between structures as more structures can now be revealed in a single volume rendered image. Unlike the relations between opaque objects in typical 3D computer graphics, spatial relation analysis for volume rendered images is more complicated due to the property of semitransparent structures. The relations between multi-transparent layers may be misinterpreted in the rendered images because of missing depth order information and severe overlapping. Therefore, traditional methods such as scene graph are no longer adequate in dealing with the complicated relation between structures in volume rendered images. Current volume visualization systems highly depend on manual inspection to reveal various relations such as separate, overlapping, touching, and enclosing between 3D structures. The process is timeconsuming and prone to error. Thus, a systematic and semi-automatic scheme to explore the spatial relations between structures is highly desirable and can greatly facilitate the visualization process. To achieve this, we first need a precise way to describe all possible spatial relations between 3D structures. These spatial relations may be fuzzy because of the nature of some volumetric data. Then, an efficient and automatic way of extracting basic structures in a volume and establishing their spatial relations can be developed. Quantitative measurements become possible after the relations are recognized. By abstracting the volume as a set of structures together with the relations among them, a more comprehensible and manageable interface is available for viewers to accomplish visualization tasks more easily.</p><p>In this paper, we propose a relation-aware visualization pipeline for exploring volumetric data. Relations between structures in a volume are defined with respect to region connection calculus and are represented as a relation graph for easy understanding and navigation. Visualization techniques are suggested for revealing the spatial relations. The objective of this work is to deliver a new visualization paradigm for better understanding, presentation, navigation, and visualization of volumes based on relations. The advantage of relation-driven visualization is that it allows analysis of data in a new perspective and exploration on the data can be carried out based on relations instead of low-level parameter adjustment. To our best knowledge, this is the first comprehensive visualization framework dedicated to revealing and analyzing the relations between structures in volumetric data. The contributions of the paper are listed as follows:</p><p>• Spatial relation formulations based on region connection calculus are proposed to define and measure relations between structures, which can be incorporated in the visualization pipeline. • Based on the measured relations, we design a comprehensive framework dedicated to relation exploration and visualization. • To assess the correctness and expressiveness of the results in revealing the relations in the volume, a relation-based image quality measurement is proposed to evaluate the rendered image quality based on the composition and relations between structures in the image and data domains. This paper is organized as follows. We first introduce the previous work in Section 2. An overview of the proposed framework is described in Section 3. The spatial relation definitions and measurements are covered in Section 4. The relation graph interface for presentation and navigation of relations is described in Section 5. The proposed relation-based image quality assessment scheme is described in Section 6. The visualization methods for relations are covered in Section 7. The experimental results and discussions are described in Section 8 and 9. Finally, the conclusions are drawn in Section 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p>In this section, we first review the typical visualization pipeline and its various enhancements. Then, related work on spatial relation is discussed. We will also briefly survey previous work on segmentation and classification, illustrative visualization, viewpoint selection, and graph interface.</p><p>Volume Exploration In a typical volume exploration pipeline, volumetric data are turned into images through data processing, classification, rendering parameter settings, rendering, and user interaction phases. The pipeline can be enhanced and tailored for different applications. Tremendous efforts have been spent to automate the whole process. For example, <ref type="bibr" target="#b20">[21]</ref> suggested an intuitive exploration framework in which visualization is based on analogy (provenance information) and query-by-examples. VisTrails <ref type="bibr" target="#b0">[1]</ref> simplifies the specification of visualization pipelines in multiple-views and provides a scalable mechanism for generating different visualizations. A comprehensive knowledge-based system for volume exploration and navigation can be found in <ref type="bibr" target="#b14">[15]</ref>. To the best of our knowledge, none of the previous pipelines have fully addressed the issues of spatial relations between structures in volumes.</p><p>Spatial Relation Spatial relations between 3D objects have been studied in several research fields. In computer graphics, scene graph <ref type="bibr" target="#b22">[23]</ref> is a commonly used tree data structure for representing the hierarchical relation of geometric objects. The major purpose of scene graph is to efficiently model and organize objects. In contrast, our work focuses on data analysis. Thus, more relations other than hierarchy are considered. The query, revealing, and enhancement of various relations are addressed in our work but not in the scene graph. In volume visualization, previous work mainly focuses on the topology of iso-surfaces and their relations. For example, <ref type="bibr" target="#b13">[14]</ref> used topology information in raster-based representation of data for efficient rendering. The topological features in a volume were also considered in a framework proposed in <ref type="bibr" target="#b24">[25]</ref>. The contour tree has been used to explore the relation between iso-surfaces and their evolution <ref type="bibr" target="#b23">[24]</ref>. The spatial ranges, extent, and shape of structures in the context of fuzzy classification were considered in <ref type="bibr" target="#b15">[16]</ref>. However, general spatial relations between transparent and fuzzy objects have not been fully addressed before. Spatial relations have also been studied in the field of artificial intelligence. Randell and Cohn <ref type="bibr" target="#b6">[7]</ref> developed a theory based on the connectivity between regions to give a reasoning on spatial relations. Various spatial relations can be defined using algebraic logic <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18]</ref>. We found that the algebraic logic provides a solid foundation for spatial reasoning. Thus, we adopt and extend the algebraic logic to formulate the relations between structures in a volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmentation and Classification</head><p>Important features in volumetric data can be better revealed through appropriate segmentation or classification. Segmentation is a well studied problem in computer vision and medical imaging. Some well-established segmentation methods can be found in various books and surveys <ref type="bibr" target="#b10">[11]</ref>. In volume visualization, classification is usually achieved by transfer function specification. Transfer function design has been a hot research topic in scientific visualization for many years. An excellent survey can be found in <ref type="bibr" target="#b12">[13]</ref>. A preliminary segmentation or classification based on domain knowledge is usually performed in typical systems in order to identify interesting features for users' specific requirements. In our framework, we also conduct a preliminary segmentation before relation analysis for more accuracy.</p><p>Illustrative Rendering Illustrative rendering <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20]</ref> can help revealing important features in a volume for interactive exploration and visual analysis. Non-photorealistic and importance-driven volume rendering <ref type="bibr" target="#b25">[26]</ref> is more effective in some applications. Various illustration techniques have been proposed and can be found in existing visualization systems. VolumeShop <ref type="bibr" target="#b3">[4]</ref> combines artistic visual styles and expressive visualization techniques to improve the expressiveness of the rendered images. Semantic layers <ref type="bibr" target="#b18">[19]</ref> allow intuitive specification of visual styles to volumetric attributes using fuzzy logic. Illustra-tive rendering techniques such as suggestive lines are exploited in our system to enhance the relations between structures.</p><p>Viewpoint Selection Viewpoint selection is an important issue in volume visualization and has been studied by several researchers. Takahashi et al. <ref type="bibr" target="#b23">[24]</ref> proposed a view-entropy-based method to choose proper views for revealing important features in the volume. Bordoloi and Shen <ref type="bibr" target="#b2">[3]</ref> suggested that good viewpoints should provide higher visibilities to the more important voxels and thus proposed a voxelbased entropy function as a goodness measure of viewpoints. In this paper, we extend the viewpoint selection method in <ref type="bibr" target="#b2">[3]</ref> to better reveal the relation between structures.</p><p>Graph Interface Graph can naturally represent relations between objects. In recent years, various graph-based interfaces have been developed. For example, Jankun-Kelly and Ma developed a focus + context graph visualization method called MoireGraphs <ref type="bibr" target="#b11">[12]</ref> for graphs with image nodes. Ma <ref type="bibr" target="#b16">[17]</ref> proposed the use of an image graph to demonstrate resulting images with respect to parameter changes. General node-link graph visualization methods have been used in volume visualization to support visual programming <ref type="bibr" target="#b20">[21]</ref>. In this paper, we design a graph interface called relation graph tailored for spatial relation encoding, analysis, and exploration. For a graph-based interface, visual clutter reduction and graph interaction are two fundamental and well investigated problems. To reduce visual clutter, various approaches such as filtering, clustering, and line displacement have been proposed in graph visualization <ref type="bibr" target="#b8">[9]</ref>. Yi et al. <ref type="bibr" target="#b27">[28]</ref> summarized a set of interaction techniques like Select, Encode, Abstract/Elabotrate, and Connect to help evaluate interaction techniques in information visualization. Most of these visual clutter reduction and graph interaction techniques can be directly applied to our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FRAMEWORK OVERVIEW</head><p>Our proposed relation-based visualization pipeline consists of several processes and an overview of the framework is shown in <ref type="figure">Fig. 1</ref>. Given a volumetric data, different segments of structures are extracted and treated as primitive entities for relation establishment. Based on relation logic and measurements, relations between entities are derived. These relations and entities are represented in a node-link diagram called relation graph. With supported interactions and selection facilities as well as relation query operations, patterns of structures and their relations can be discovered by viewers.</p><p>In the interaction feedback loop, users can refine the relation graph and select interesting structures and relations for detailed analysis. The selected relation entities are visualized with the help of the proposed critical-region-based solution for viewpoint selection and image enhancement. The intermediate results are then evaluated using our relation-based image quality assessment scheme which consists of a set of relation rules and quality measures. The results are also enhanced to improve visual perception and resolve ambiguities in relations. This guarantees that the relations are faithfully revealed in the final results. The details of each process will be covered in the later sections. Spatial relations have significant implications in volume understanding. The spatial composition of structures and their spatial locations and relative positions in a volume are important information to be acquired in the analysis process. Viewers give a proper reasoning to form ideas through the spatial relations between structures. High-level reasoning and interpretation, as well as measurements of the data, can also be conducted based on this information. In fact, many user interactions (e.g., rotation of data) performed are for exploring the spatial relations between observed objects. Such information should be properly delivered in the visualization process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Relation Definitions</head><p>The previous work on spatial reasoning <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18]</ref> in artificial intelligence provides a well-established theoretical foundation for an abstract and qualitative description of spatial relations between structures. In the past, mathematical topology, which considers points as the primitive elements, formed the fundamental aspect of spatial reasoning. However, many recent works tend to take regions of space as the primitive elements as it is more intuitive to our reasoning in physical objects. Region Connection Calculus (RCC) <ref type="bibr" target="#b17">[18]</ref>, as a widely adopted region-based approach in spatial reasoning, suggests several logical definitions on spatial relations. This theory is founded on the basis of connectivity C between regions S and various relations can be derived using a set of algebraic logic <ref type="table">(Table 1)</ref> based on this connectivity property. Spatial relations are classified into different hierarchical classes using the algebraic logic of RCC. Given any two objects, it can be first classified as connected (C) or discrete from (DR). Then, they can be further classified into one of its sub-classes until the bottom of the hierarchy. DC (separate), EC (touch), P (part-of), and PO (partially overlap) are the typical relations found in volumes. In addition to the basic relations defined in RCC, there are several extensions <ref type="bibr" target="#b5">[6]</ref> which further distinguish the region inside and outside of the convex boundary of the object. In this paper, we only use the basic relations (DC, EC, NT PP, T PP, EQ, T PPi, NT PPi, PO) in the original RCC in our system and categorize them into four relations (DC, EC, PO, P), according to their original hierarchical structure <ref type="bibr" target="#b17">[18]</ref>, for visualization and analysis. The relations can give abstract reasoning on volumetric data. In the later sections, the logic will be turned into quantitative measures which indicate the degree of conformation to relation definitions and are used for relation analysis. In practice, such relations can be commonly found between structural layers in simulation datasets or anatomical structures in medical datasets. For example, nested layers in a protein dataset can be interpreted as a series of "part-of" (P) or "partially overlapping" (PO) relations. More examples will be shown in the experiments. <ref type="table">Table 1</ref>. Algebraic logic representing spatial relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description logical expression</head><formula xml:id="formula_0">DC(s i , s j ) disconnected ¬C(s i , s j ) P(s i , s j ) part of ∀s k [C(s k , s i ) → C(s k , s j )] PP(s i , s j ) proper part of P(s i , s j ) ∧ ¬P(s j , s i ) EQ(s i , s j ) identical with P(s i , s j ) ∧ P(s j , s i ) O(s i , s j ) overlapping ∃s k [P(s k , s i ) ∧ P(s k , s j )] DR(s i , s j ) discrete from ¬O(s i , s j ) PO(s i , s j ) partially overlapping O(s i , s j ) ∧ ¬P(s i , s j ) ∧ ¬P(s j , s i ) EC(s i , s j ) externally connected C(s i , s j ) ∧ ¬O(s i , s j ) TPP(s i , s j ) tangential proper part PP(s i , s j ) ∧ ∃s k [EC(s k , s i ) ∧ EC(s k , s i )] NTPP(s i , s j ) nontangential proper part PP(s i , s j ) ∧ ¬∃s k [EC(s k , s i ) ∧ EC(s k , s j )]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Primitive Elements</head><p>To apply RCC, we assume that a volume consists of different structures or spatial regions with physical boundaries. The whole volume is first segmented into smaller homogenous regions called segments which form the basic components of the volume in the relation computation. While an anatomical structure may be classified as one or a set of components, it will be perceived as a coherent entity in the relation graph (Section 5) owing to strong connectivity and similar intensity values.</p><p>We apply typical region growing and watershed approaches <ref type="bibr" target="#b1">[2]</ref> on the volume to preliminarily segment different basic structures in a volume. The segmentation process is marker-controlled and is driven by a criterion function (e.g., gradient). The level-set based approach is also applied to take the shape prior into account in the segmentation. For deriving abstract relations in the volumes, the segmentation is not necessarily very accurate (e.g., over-segmented) and can be refined in the later steps. The overlapping of regions may occur due to the fusing of structures, vague boundaries, or partial volume effect. A confidence value is defined to capture the uncertainty in such segmented regions. Consider that different classes a i of structures can be modeled as a set of Gaussian mixture models with respect to their intensities. Each region can be mapped to one of the classes with a specific intensity profile. In the overlapping or boundary regions between the segmented regions (or background), we can estimate the constitution as conditional probabilities at voxel x (i.e., confidence values):</p><formula xml:id="formula_1">p x (a i ) = p x (a i |I(x)) ∑ n k=0 p x (a k |I(x))<label>(1)</label></formula><p>where I(x) is the intensity at x and n is the number of constituent components. This information is used in calculating the fuzzy relations between the components later. In fact, other segmentation methods can also be applied and confidence values are available for those multilabel approaches. For hard segmentation, the confidence value will be 1. A hash table is used to store the label combinations that exist in the volume and each voxel is assigned a key representing its label information. The number of combinations is usually limited because overlapping is not common and usually involves only two segments in typical volumes. Therefore, this approach allows efficient memory usage. Although the table lookup may introduce overhead, it does not affect the exploration and rendering speed as label information is only required for preprocessing relations and assessing image quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Relation Measures</head><p>After the segmentation, we have a set of segmented structures S = {s i |i = 1 . . . n} which are the basic components in the volume. To quantitatively measure the relations, we extend the original RCC logic and express the relations in a numeric and precise manner. Based on the spatial logic in <ref type="table">Table 1</ref>, we apply fuzzy logic <ref type="bibr" target="#b9">[10]</ref> and define a specific membership function for each relation. As precise boundaries of structures may be hard to define in a volume, fuzzy relations <ref type="bibr" target="#b21">[22]</ref> are defined for vague regions, as a generalization of the original RCC. Each part of the structure is assigned a confidence value in the segmentation process. This value indicates the uncertainty in classification of a part to a certain class of structures and is considered in the membership functions.</p><p>To apply fuzzy logic <ref type="bibr" target="#b9">[10]</ref> in spatial reasoning, the relations are defined in the general form of</p><formula xml:id="formula_2">R = {((s i , s j ), r con (s i , s j ))|(s i , s j ) ∈ S × S}<label>(2)</label></formula><p>where (s i , s j ) is an ordered pair of segments in S and r con is a membership function. We have to first define the membership function r con for connectivity, which is the foundation of all relations in RCC. At every point x in the volume space, we examine its connectivity with the segment s i and s j . We define a binary function φ (x) which returns 1 if it is connected to both segments, or else 0. The portion of the segments being connected with other segments indicates the degree of connectivity. The membership function is therefore expressed as</p><formula xml:id="formula_3">r con (s i , s j ) = ∑ x∈S η x φ (x) ∑ x∈s i s j η x<label>(3)</label></formula><formula xml:id="formula_4">η x = max{p(s 1 ), . . . , p(s n )}<label>(4)</label></formula><p>where η x represents the maximum confidence value at point x. The membership functions of the rest of the spatial relations defined in RCC <ref type="table">(Table 1</ref>) can be derived from the connectivity r con <ref type="bibr" target="#b9">[10]</ref> as</p><formula xml:id="formula_5">                       r dc (s i , s j ) = 1 − r con (s i , s j ) r p (s i , s j ) = min s k ∈S {max{1 − r con (s k , s i ), r con (s k , s j )}} r pp (s i , s j ) = min{r p (s i , s j ), 1 − r p (s j , s i )} r eq (s i , s j ) = min{r p (s i , s j ), r p (s j , s i )} r o (s i , s j ) = max s k ∈S {min{r p (s k , s i ), r p (s k , s j )}} r po (s i , s j ) = min{r o (s i , s j ), 1 − r p (s i , s j ), 1 − r p (s j , s i )} r dr (s i , s j ) = 1 − r o (s i , s j ) r ec (s i , s j ) = min{r c (s i , s j ), 1 − r o (s i , s j )} r t pp (s i , s j ) = min{r pp (s i , s j ), max s k ∈S {min{r ec (s k , s i ), r ec (s k , s j )}}} r nt pp (s i , s j ) = min{r pp (s i , s j ), 1 − max s k ∈S {min{r ec (s k , s i ), r ec (s k , s j )}}}</formula><p>where r represents the strength of each relation. A threshold σ on the strength is defined to determine the existence of each relation. With segmented structures, relations between them are automatically computed using these rules and membership functions. The objective is to establish the relations between different parts of the volume such that classification and navigation can be carried out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATION GRAPH</head><p>Given a set of derived relations, we need an intuitive way to present them to viewers. We introduce an interface called relation graph (see <ref type="figure">Fig. 7</ref>) to facilitate the display and navigation of structures and their relations. The nodes and links in the relation graph represent the segments and the spatial relations between them respectively. Compared with typical semantic net representation, our graph representation not only provides an abstract illustration and communication of the relations between entities, but also facilitates exploration of useful relations in complex scenarios. The contour tree was used in <ref type="bibr" target="#b24">[25]</ref> to capture the topological evolution of a level set as the iso-value varies. It can effectively show the nesting relations (i.e., inclusion and separation) of iso-surfaces as a graph. Our relation graph is also a node-link diagram, but we focus on structure segments instead of iso-surfaces. In addition, we consider a more complete set of spatial relations.</p><p>Note that given any two nodes in the graph, we can always derive a relation. The relation graph turns out to be a complete weighted graph. A large number of links and nodes may result in severe visual clutter. Therefore, we design an informative graph layout scheme and propose some graph interaction methods for scalable and easy exploration of relations between structures in the volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Layout</head><p>The y-axis in the relation graph represents the scalar value or feature value of the segments. Each node is mapped to a y-position according to the average scalar value of the corresponding structure such that structures of the same category lie on a similar height level in the graph. To utilize the space, nodes at each level are evenly placed on the horizontal position. The nodes and edges can be clustered together or dispelled away to reduce visual clutter. In our system, we define a reference point (e.g., center of the volume) and sort the horizontal position of the nodes based on the distance between segments and the reference point to preserve their relative position in the volume. Relations and their strengths are encoded using the color and width of the links respectively. With this layout, segments belonging to the same class tend to be positioned together and the types and strengths of links between segments can be easily identified.</p><p>Graph Interaction Systematic exploration of the relation graph and extraction of meaningful information from it are critical issues. Therefore, a set of user operations are supported to allow interactive exploration on the relations.</p><p>• Filtering -Users can filter nodes of specific segment size or type (e.g., insignificant or unwanted structures) and enable or disable the display of certain types of relations to reduce visual clutter.</p><p>In our system, very weak links and small isolated nodes (i.e., noise) can be automatically filtered out. • Selection -Users can select any node or link in the graph. A thumbnail image can be displayed next to each node for previewing the segment. Segments are highlighted in the slice view and rendering window upon selection.</p><p>• Node clustering and expanding -Users can group similar nodes together into a single node to reduce visual clutter or expand the clustered nodes for detailed analysis. Nodes belonging to the same class with similar scalar or average values can be automatically clustered together. Each class of nodes is represented as either a single node or aggregation of nodes. • Viewpoint selection -For any selected nodes and relations, users can enable automatic viewpoint selection to better reveal the relations from some optimal viewpoints (see Section 7). • Relation query -Users can select one or a set of nodes, specify some filtering conditions (e.g., type and size), and then query the graph according to certain relations. All the nodes that satisfy the filtering conditions and connect to the selected nodes with the specified relations will be extracted and shown in a separate graph along with the selected nodes. With these user interactions, the clutter in the graph can be reduced and the structures and their relations can be explored by users in an intuitive and efficient way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATION ANALYSIS</head><p>After selecting the relations or structures of interest in the relation graph, the selected entities can be visualized in volume rendered images. However, the rendered images may raise ambiguity to viewers' perception. Because of poor viewpoint selection or rendering parameter settings, spatial relations in the images may be misinterpreted by viewers. In this section, we first examine the perceived spatial relations in rendered images, and then propose two schemes to evaluate the quality of volume rendered images from the relation point of view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Spatial Relations in Rendered Images</head><p>In the rendering process, different structures are projected on the rendered image and each of them can be represented as a layer in the image with certain opacity and boundary. The layers hold different kinds of relations between themselves in the image. They are perceived by viewers to interpret the spatial relations between structures in the volume. For example, two separate layers in an image can be interpreted as two separate structures in the volume. However, different from the spatial relations which are invariant in the volume space, the perceived relations in the image may be different from different viewpoints, and are thus view-dependent. For example, separate objects may be interpreted as connected or overlapping from the images rendered at certain viewpoints. The perceived relation can be affected by occlusion, visual appearance, and spatial position of structures to viewers. The relation may not be correctly perceived by viewers and ambiguities arise in the projected images (See <ref type="figure">Fig. 3(a)</ref>).</p><p>Our objective is to ensure that spatial relations are correctly revealed without being affected by perceived relations between the structures in the images. Therefore, we propose an image quality assessment scheme to evaluate the coherence of spatial relations in volume and image domains. The evaluation process is divided into two partsrule-based relation analysis to check the consistency of the objective relations existing in 3D space and the "subjective" relations perceived in 2D images, and image quality measurements to assess the perceived image quality in revealing the relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Rule-Based Relation Analysis</head><p>For each rendered image, we consider all the segments in the volume and compute their corresponding visible layers and projection layers. The projection layer captures the region in which the segment projects on the image and the visible layer is the region in the image where the segment is visible to viewers. This can be achieved by analyzing the sampled points falling into the segments in the ray-casting process and their accumulated opacities on the image.</p><p>In the image relation analysis, the relations in the image domain are evaluated by applying RCC methodology on the visible layers of individual entities (segments). Any disagreement between the relations in volume and image domains are examined on a rule-by-rule basis. To simplify the presentation, we categorize the aforementioned relations into four main classes, namely separate, touch, overlap, and enclose.</p><p>We derive several relation rules based on the perception of relations in images and summarize them in <ref type="table" target="#tab_1">Table 2</ref>. The compliance with these rules ensures no ambiguity regarding the spatial relation perceived by viewers in the rendered image. The results are classified into three categoriesagree, disagree, and ambiguous. Agree means that the relations perceived in the image can faithfully reveal the relations in the volume while disagree means that the result is misleading. For example, separate objects should maintain the same relation in the image and connected objects should not be separate in the image due to rendering artifacts. Ambiguous cases, on the other hand, may be interpreted by viewers in different ways and can cause potential ambiguity. For example, overlapping of semi-transparent segment layers may imply a separate or overlap relation due to the blending effect. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Relation-Based Quality Assessment</head><p>Even if the rules are followed in the result, the relation can still be unclear. For example, two connected structures may be perceived as a single structure if they have a similar appearance and unclear boundaries in the image. As the rules only verify the general consistency of the relation in image and volume domains, some detailed quality measures are still needed to estimate the effectiveness of the result in conveying the relation information. Due to poor rendering parameter settings and other artifacts, the visible layers (structures) and thus the relations may not be well-perceived. For example, part of the structure may be assigned a low opacity or occluded by other structures and the relation becomes less obvious to viewers. Several quality metrics including integrity, effective visibility, boundary strength, and visual difference are proposed.</p><p>Integrity A structure (projection layer) may be occluded and become fragmented such that users may not perceive these fragments as one single structure. We interpret the integrity factor as the entropy of fragments,</p><formula xml:id="formula_6">integrity = (1 − ∑ C p c (x)logp c (x)) −1 (5)</formula><p>where C is the set of fragments (disconnected components in the visible layer of a structure) and p c (x) is the probability of a point x in the layer lying on fragment c. It attains the highest value for a single visible fragment and lowest value for large number of small fragments in similar size. Effective Visibility It is the accumulated opacity in the ray-casting process that the segment contributes to the final image. For each sample point, its contribution to the image is α(1 − α accum ) where α and α accum are the assigned opacity of the sample point and the previously accumulated opacity. The effective visibility of a segment at a point on the image is given by compositing visibilities of all the sampling points falling into the segment.</p><p>Boundary Strength It shows the clarity of the edges of the projection layer (i.e., silhouette of the structure) which may overlap with other layers. It is derived from the response of the edge filter (Canny edge detector) convolving on the boundary of the projection layer on the image. A high boundary strength can avoid misunderstanding on connectivity between discrete layers.</p><p>Visual Difference It indicates whether different visible layers are differentiable in the image. The visual difference between the layers is interpreted as the Euclidean distance between the average color of the layers in the CIE LUV color space, which can effectively estimate the visual variation of layers perceived by viewers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RELATION VISUALIZATION</head><p>With the proposed relation analysis, we have a systematic way of checking whether relations have been well revealed in rendered images. To further facilitate users to generate effective volume rendered images that can better reveal various spatial relations and address the ambiguity cases, we propose two advanced visualization techniques, namely relation-revealing viewpoint selection and relation-based illustrative visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Separate</head><p>Overlap Touch Enclose <ref type="figure">Fig. 2</ref>. Critical regions (pink) in different spatial relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Relation-Revealing Viewpoint Selection</head><p>Viewpoint selection plays a critical role for revealing relations. Good viewpoints can correctly reveal the relations while bad ones may lead to misperception. A good viewpoint is determined by the exposure of an important region in the volume <ref type="bibr" target="#b2">[3]</ref>. Although the interval volume in <ref type="bibr" target="#b23">[24]</ref> can effectively capture the region between different isosurfaces, the region of interest (ROI) in our case depends on the specific structures and relations concerned and may not be related to any iso-surfaces. In our relation-based visualization, we first define critical regions to depict the ROIs which can give a proper perception of the relations.</p><p>In each relation, a critical region in which the relation appears is defined. Visualizing these regions with the related structures can facilitate the understanding of the relations by viewers. The critical region is defined as the region between the related structures. Next, we will describe critical regions for various relations.</p><p>Separate Relation Objects are spatially disconnected (DC) and a gap interval which can be opaque or transparent is present between them. Such relations can be visualized by presenting the gap and preserving the context as well to viewers.</p><p>Touch Relation Objects are externally connected (EC) with each other and the relation is visualized at the touching regions which can be boundaries or surfaces.</p><p>Overlap Relation Objects are partially overlapping (PO) with each other and the overlapping region is defined as the critical region.</p><p>Enclose Relation An object is embedded in another object (P) and the critical region is the interval between the boundaries of the inner and outer objects.</p><p>A formal definition of the critical regions is shown in Eq. 6 and an illustration is given in <ref type="figure">Fig. 2</ref>. Given any two segments c i and c j , the critical regions of different relations are defined as,</p><formula xml:id="formula_7">Region dc = {x|x ∈ convex(c i , c j ) ¬(c i c j )} Region ec/po = {x|x ∈ c i c j } Region p = {x|x ∈ c j ¬c i }<label>(6)</label></formula><p>For example, in separate relations we define only the gap between the structures instead of the whole interval volume as the ROI. The region can be computed by finding the convex hull covering the related structures while excluding the structures. Similarly, for the touch, overlap, and enclose we define the intersecting surface or volume as the ROI. Based on the critical regions, we can perform viewpoint selection and view synthesis. The appropriateness of a viewpoint is determined by the exposure and visibility of the critical regions in the final view. The critical regions of the relations and structures concerned are considered as the regions of interest and we perform view-entropy analysis <ref type="bibr" target="#b2">[3]</ref> to select proper views for these regions. Moreover, view synthesis is also performed based on the critical regions. Opacity modulation and importance-driven volume rendering techniques <ref type="bibr" target="#b25">[26]</ref> are applied to improve the visibility of these regions by selectively suppressing the context in the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Relation-Enhancing Illustrative Visualization</head><p>Good viewpoints may not always be available and ambiguities may be unavoidable in volume rendered images. To address this problem, visual cues are added to the relation graph and volume rendered images to alert viewers and resolve the ambiguities.</p><p>To ensure that the spatial relations are not misperceived in the rendered image, the evaluation results from Section 6 are presented in the relation graph to alert users. Based on the visibility measure, the nodes of invisible segments become semi-transparent in the graph to indicate the hidden or unclear structures in the image. The links between the visible nodes represent the relations revealed in the image. A segment is considered not well-perceived if any of its integrity, effective visibility, visual difference, or boundary strength is too low. Similarly, a relation is not well-perceived if it is classified as ambiguous or disagree. The nodes and links of these problematic structures and relations are highlighted in the relation graph. The boundaries of the nodes are thickened and the links are rendered as thick dashed lines to allow users to easily identify them in the graph.</p><p>To enhance the perception and resolve the ambiguities of a selected relation <ref type="figure">(Fig. 3)</ref>, visual aids can be applied on the image. For the ambiguous cases, we use suggestive lines on the silhouette of the structures (i.e., boundaries of projection layers) to encode the proper relation. In fact, wrong perceptions are due to the unclear depth order of structures and their connectivity (separate or overlap). The suggestive lines are therefore selectively added on the image as visual cues to describe this information. <ref type="figure">Fig. 3(b)</ref> and 3(c) give an example use of the suggestive lines to resolve ambiguity in overlap and enclose relations on images. A suggestive line is added on the boundary of the projection layer of a segment which is closer to viewers for overlapping layers in the image. If other overlapping segments are connected (touch or overlap) in the volume domain, the boundary of the overlapping region in the image will be highlighted with broken suggestive lines. Different possible spatial relations are presented in different ways. To enhance the perception, other depth cues <ref type="bibr" target="#b4">[5]</ref> and illustrative visualization techniques <ref type="bibr" target="#b26">[27]</ref> may also be applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EXPERIMENTS</head><p>We conducted experiments on various datasets to demonstrate the effectiveness and utility of our pipeline. Our system was run on a Dell machine (Pentium Core2Duo 6400, 2G RAM) equipped with an NVIDIA GeForce 7600GTS graphics card. For simple illustration, the relations are categorized into separate, touch, overlap, and enclose. The links representing these relations are colored blue, red, yellow, and green, respectively.</p><p>We first used the relation graph to illustrate different spatial relations derived from a hydrogen molecule dataset obtained by simulation. Regions at three scalar values were selected and a relation graph was computed. The separate relation between nodes from different layers are removed. <ref type="figure" target="#fig_0">Fig. 4</ref> shows the result of the experiment. In the graph, the red links between the nodes of the outer layer indicate a touch relation. The blue and green links show the separate and enclose relations between the nodes. By observing the graph, the connectivity and nested-layer topology of the molecules can be easily recognized. To demonstrate the relation analysis on volume rendered images, we conducted an experiment on a knee CT dataset (379 × 229 × 305) as shown in <ref type="figure" target="#fig_1">Fig. 5(a)</ref>. The bones and their relations are shown in the relation graph ( <ref type="figure" target="#fig_1">Fig. 5(b)</ref>). They are loosely connected, which result in touch and separate relations. The connected surfaces and the gap intervals between the bones at the joint position provide useful information for diagnosis of defects and surgical planning. We chose a rendered image for evaluation and the results are encoded in the relation graph in <ref type="figure" target="#fig_1">Fig. 5(c)</ref>. The node of the left fibula is semi-transparent as it is not visible in the image. The right fibula is partially occluded by the tibia in the image and the spatial relation (i.e., touch) between them is ambiguous from this image. Similarly, the touch relations between the patellas and femurs are not clear. These ambiguities are indicated in the highlighted links between the nodes of the bones. The enhanced images in <ref type="figure" target="#fig_1">Fig. 5</ref>(c) with suggestive lines drawn on the related bones clearly indicate the separate and touch relations. From the experiment, we can see that the ambiguous relations shown in the rendered image are clearly revealed in the graph and the suggestive lines in the image can help express the actual relation between the structures.</p><p>To demonstrate the use of the relation graph in navigation and analysis, an experiment was conducted on an angiographic dataset (256cubic), as shown in <ref type="figure" target="#fig_2">Fig. 6</ref>. The data was acquired from a patient suffering from arterial aneurysm (the bright balloon-like bulge). The aneurysm and the vessels close to it must be identified in the surgical planning procedures. The vessel tree was segmented and branches were found by breaking the bifurcation of the extracted vessel skeleton. In the relation graph, the branches of the vessels are represented as nodes at similar intensity levels and the aneurysm is represented as another node with much higher intensity. Only the touch relation is illustrated in the graph as it is the main concern of this analysis. The links between the aneurysm and vessel branches indicate that the aneurysm is attached to some branches. To visualize the aneurysm and the connected vessel branches, those links were selected and optimal views were generated based on the view analysis. From this experiment, we can see that the relation graph provides an intuitive navigation interface for users to systematically explore the relations between structures and can assist the volume analysis (e.g., medical diagnosis).</p><p>Finally, an experiment on a human body dataset (512 × 512 × 469) ( <ref type="figure">Fig. 7)</ref> was conducted to demonstrate a sample workflow of the interactive exploration process with the supported operations. An artificial  object (bullet) was put into the data and the relation graph was used to analyze the spatial relation between the object with other structures. Although the object has been displayed in the rendered images, it was occluded by contextual structures and the spatial relation information was ambiguous due to the loss of depth perception. Operations like rotation and clipping were required to reveal the object. Therefore, the relation graph was used to ease the difficulty in the visualization and analysis. As the body consists of various anatomical structures like bones and organs, it results in a complicated relation graph and preliminary filtering is necessary. The links of strong separate relation, which represent the structures far from each other, have been made invisible to reduce visual clutter. Class clustering was further performed to cluster nodes according to their class (scalar value). A collapsed view on the structures and their associated relations was generated. To remove unwanted structures from the graph, a relation query was then performed to extract all the nodes that have enclose, overlap, touch or weak separate relation with the object. The resulting graph shows that the extracted nodes are all located near the chest position. The extracted class nodes can be selected and expanded for further analysis.</p><p>In the expanded view of the relation graph, we can examine the spatial relation between the object with other structures. For example, it is separate from the bones and organs but is enclosed by the lung. Visual analysis can also be performed using the rendered images generated based on the selected structures or relations. A complete workflow and the results are shown in <ref type="figure">Fig. 7</ref>. From this experiment, we can see that the graph can give an intuitive navigation of complex data and allow interactive exploration on spatial relations in the data. The performance of the system allows real-time exploration of the volumetric data. Although it takes time to segment the volume and measure the relations, the preprocessing operations are only performed once and the visualization and exploration processes can then be performed interactively. The processing time for the segmentation of volumes depends on the algorithm used. In our experiment, the watershed segmentation algorithm took about 30s to generate the segments for the angiographic dataset. The relation computation also depends on the number of segments found in the volume. Although it takes O(n 2 ) time for preprocessing, the logic computation is efficient and the number of segments are usually within a manageable size (∼ 50) for user manipulation and analysis. For the angiographic dataset, it took about 10s to compute the relations between the vessel segments. The quality assessment on the resulting images only involves several operations on the images and can be performed efficiently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">DISCUSSIONS</head><p>From the experiments, we can see that our enhanced pipeline can effectively organize and visualize relations between different structures in volumetric data. The utility of our relation-aware pipeline is threefold: as a comprehensive solution for relation-critical applications, as a general effectiveness metric for volume rendered images, and as an exploration and analysis scheme for volumetric data. For relation-critical applications such as vessel and bone surgeries, our new pipeline provides a complete framework for users to organize, display, query, and enhance the relations between different structures in volumetric data. For general volume visualization, our relation analysis methods can help detect whether any misleading relations may be unexpectedly introduced in the final direct volume rendered images. For the exploration of unknown complex datasets, our relation graph interface can help users easily understand the structures and their relations in the data. Because transparency is widely used in volume visualization systems, the risk of mis-perception or ignorance of relations is greatly increased for complex datasets. With our new pipeline, for relation-related tasks, errors can be reduced and the response time can be shortened.</p><p>One major weakness of our method is that our results are based on segmentation. Precise segmentation is actually not required at the beginning and the segmentation problem can be fixed during the latter stage. The RCC and segmentation are based on fuzzy classification. Different thresholds can lead to different segmentations. The resulting relation graph may actually provide useful feedback to the segmentation process. For example, if the relation graph shows that two structures are touching each other but it is untrue according to the domain knowledge, then users can choose a different threshold. Our framework does not require transfer functions. However, if a transfer function is available, it may help our system to automatically filter out the structures that users are not interested in and focus on the structures of high interest. For example, we can modulate the opacity of the node in the graph. For each node in the graph, we simply render the corresponding segments using the transfer function supplied by the users. If the accumulated opacity is larger, then the node will become more opaque and more visible. For totally transparent structures, the nodes will be automatically pruned out. We will further explore this idea in the future. Another concern is that the graph may become visually cluttered, making it less useful. Fortunately, graph visualization is a thoroughly studied problem in information visualization and many excellent clutter-reduction methods can be exploited. <ref type="figure">Fig. 7</ref>. Exploration on a human body dataset: (a) An object (bullet) was inserted into the human body; (b) A relation graph was constructed and (c) the nodes were clustered according to their class to reduce visual clutter; (d) Nodes related to the object were extracted by relation queries; (e) The extracted nodes were expanded for detailed analysis; (f) Images were generated for revealing the selected relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">CONCLUSION</head><p>This paper described a new visualization paradigm for exploration of spatial relations between structures in volumes. The relation exploration can provide users with insights into the volumes in different perspectives. Several methods have been presented to facilitate the exploration process. Spatial relations are defined based on spatial reasoning logic (RCC) and a relation graph interface is designed for interactive exploration of relations. To the best of our knowledge, it is the first time RCC is introduced to volume visualization for exploring useful spatial relations. To improve the visualization of relation, a criticalregion-based approach is suggested for viewpoint selection and image enhancement. To guarantee satisfactory results which can effectively convey the relation information, a quality assessment scheme is proposed and enhanced views are generated for the purpose. In summary, our pipeline allows classification, exploration, and visualization of relations and facilitates the analysis of volumetric data in various applications. Complicated datasets can result in a large number of small segments which require efforts to classify and cluster them interactively in the relation graph. In the future, more advanced techniques will be developed to facilitate user interactions on the graph such that important features can be identified and desired results are achieved more easily. Also, we will extend our framework to visualize other relations and explore the use of the methods in different applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 4 .</head><label>4</label><figDesc>Experiment on a hydrogen dataset to demonstrate different spatial relations between the extracted layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 .</head><label>5</label><figDesc>Relation evaluation on a CT knee dataset: (a) An overview of the knee; (b) A relation graph and images generated to reveal the selected relations on the graph; (c) A selected image (left bottom) with ambiguous relation (in small boxes) and the relation graph encoded with evaluation information (left top) and enhanced images (right, 1-3) with suggestive lines for resolving the ambiguous relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 .</head><label>6</label><figDesc>Navigation on an angiographic dataset using relation graph: (a) An overview of the data; (b)-(c) The optimal views generated for the selected relation links.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Relation Visualization User Interactions Image Evaluation Graph Construction Segmentation Intermediate DVRIs Volume Data Segmented Structures Relation Estimation Relation Graph Viewpoint Selection Image Enhancement Relation Coherence Image Quality Enhanced DVRIs Relation Selection Clustering and Filtering Relation Query</head><label></label><figDesc></figDesc><table /><note>Fig. 1. Flow chart showing the relation-aware visualization pipeline.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Rule-based relation analysis.</figDesc><table><row><cell>Volume</cell><cell>Image</cell><cell>Separate</cell><cell>Connect</cell><cell>Overlap</cell><cell>Inclusion</cell></row><row><cell>Separate (DC)</cell><cell></cell><cell>Agree</cell><cell cols="3">Ambiguous Ambiguous Ambiguous</cell></row><row><cell>Connect (EC)</cell><cell></cell><cell>Disagree</cell><cell>Agree</cell><cell cols="2">Ambiguous Ambiguous</cell></row><row><cell>Overlap (PO)</cell><cell></cell><cell>Disagree</cell><cell>Disagree</cell><cell cols="2">Ambiguous Ambiguous</cell></row><row><cell>Inclusion (P/Pi)</cell><cell></cell><cell>Disagree</cell><cell>Disagree</cell><cell>Disagree</cell><cell>Ambiguous</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work is supported by HK RGC grant CERG 618705 and 618706. We thank the anonymous reviewers for their valuable comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">VisTrails: Enabling interactive multiple-view visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bavoil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Crossno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The morphological approach to segmentation: the watershed transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical Morphology in Image Processing</title>
		<editor>E. R. Dougherty</editor>
		<imprint>
			<publisher>Marcel Dekker</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="433" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">View selection for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bordoloi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Volumeshop: an interactive system for direct volume illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="671" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enhancing depth-perception with flexible volumetric halos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1344" to="1351" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Qualitative spatial representation and reasoning with the region connection calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gooday</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Gotts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">GeoInformatica</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="316" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Qualitative spatial representation and reasoning: an overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Hazarika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fundamenta Informaticae</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Feature aligned volume manipulation for illustration and visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1069" to="1076" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A taxonomy of clutter reduction for information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1216" to="1223" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fuzzy spatial reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esterline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dozier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Homaifar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Fuzzy Systems Association Conference</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="162" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Yet another survey on image segmentation: Region and boundary information integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freixenet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Muñoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Raba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cufí</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="408" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">MoireGraphs: Radial focus+context visualization and interaction for graphs with visual nodes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Jankun-Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Transfer functions in direct volume rendering: design, interface, interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Course notes of ACM SIGGRAPH</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">IStar: A raster representation for scalable image and volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1424" to="1431" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">LiveSync: deformed viewing spheres for knowledge-based navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1544" to="1551" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Local histograms for design of transfer functions in direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lundstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1570" to="1579" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image graphs -a novel approach to visual data exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A spatial logic based on regions and connection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Randell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Representation and Reasoning</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic layers for illustrative volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rautek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1336" to="1343" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Volume illustration: Nonphotorealistic rendering of volume models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction of Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="264" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Querying and creating visualizations by analogy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1560" to="1567" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fuzzy spatial relations between vague regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schockaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Cock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Kerre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Intelligent Systems</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="221" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scene graphs in the new millennium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="56" to="57" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A feature-driven approach to locating optimal viewpoints for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nishita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="495" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Introducing topological attributes for objective-based visualization of simulated datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Nielson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Volume Graphics</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="137" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Importance-driven feature enhancement in volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="408" to="418" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visualizing intersecting surfaces with nested-surface techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weigle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="503" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Toward a deeper understanding of the role of interaction in information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Jacko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1224" to="1231" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
