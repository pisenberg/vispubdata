<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish</forename><surname>Chandak</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Lauterbach</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Taylor</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimin</forename><surname>Ren</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Dinesh</forename><surname>Manocha</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Secondary</forename><surname>Frustum</surname></persName>
						</author>
						<title level="a" type="main">AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Sound propagation</term>
					<term>interactive system</term>
					<term>auralization the listener Constribution to Edge Diffraction Specular Reflection + Query direct contribution Query direct contribution Visible Surface Approximation {∆1</term>
					<term>...</term>
					<term>∆Κ} triangles</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically subdivided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Sound simulation and spatialized audio rendering can significantly enhance the realism and sense of immersion in interactive virtual environments. They are useful for computer-aided acoustic modeling, multi-sensory visualization, and training systems. Spatial sound can be used for development of auditory displays or provide auditory cues for evaluating complex datasets <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b32">33]</ref>.</p><p>A key component of 3D audio rendering is interactive sound propagation that simulates sound waves as they reflect or diffract off objects in the virtual environment. One of the main challenges in sound rendering is handling complex datasets at interactive rates. Current visual rendering systems can render datasets composed of millions of primitives at real-time rates (i.e. 10-30 fps) on commodity desktop systems. On the other hand, interactive sound rendering algorithms are only limited to scenes with a few thousand triangles. Therefore, most interactive applications typically use precomputed, static sound effects based on fixed models of propagation.</p><p>In this paper, we address the problem of interactive sound propagation in complex datasets from point sources. The exact solution to modeling propagation is based on solving the Helmholtz-Kirchhoff integration equation. The numerical methods to solve this equation tend to be compute and storage intensive. As a result, fast algorithms for complex scenes mostly use geometric methods that propagate sound based on rectilinear propagation of waves and can accurately model transmission, early reflection and edge diffraction <ref type="bibr" target="#b10">[11]</ref>. The most accurate geometric approaches are based on exact beam or pyramid tracing, which keep track of the exact shape of the volumetric waves as they propagate through the scene. In practice, these approaches are mainly limited to static scenes and may not be able to handle complex scenes with curved surfaces at interactive rates. On the other hand, approximate geometric methods based on path-tracing or ray-frustum tracing can handle complex, dynamic environments, but may need a very large number of samples to overcome aliasing errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main results:</head><p>We present a novel volumetric tracing approach that can generate propagation paths for early specular reflections and edge diffraction by adapting to the scene primitives. Our approach is general and can handle all triangulated models with moving objects. The underlying formulation uses a simple adaptive representation that augments a 4-sided frustum <ref type="bibr" target="#b18">[19]</ref> with a quadtree and adaptively generates sub-frusta. We exploit the representation to perform fast intersection and visibility computations with scene primitives. As compared to prior adaptive algorithms for sound propagation, our approach provides an automatic balance between accuracy and interactivity to generate plausible sound rendering in complex scenes. Some novel aspects of our work include:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">AD-Frustum:</head><p>We present a simple representation to adaptively generate 4-sided frusta to accurately compute propagation paths. Each sub-frustum represents a volume corresponding to a bundle of rays. We use ray-coherence techniques to accelerate intersection computations with the corner rays. The algorithm uses an area subdivision method to compute an approximation of the visible surface for each frustum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Edge-diffraction:</head><p>We present an efficient algorithm to perform edge diffraction on AD-Frustum based on the Uniform Theory of Diffraction <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b36">37]</ref>. These include efficient techniques to compute the shape of diffraction frustum and the actual contribution that the diffraction makes at the listener.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Handling complex scenes:</head><p>We use bounding volume hierarchies (BVHs) to accelerate the intersection computations with AD-Frusta in complex, dynamic scenes. We present techniques to bound the maximum subdivision within each AD-Frustum based on scene complexity and thereby control the overall accuracy of propagation by computing all the important contributions.</p><p>We have applied our algorithm for interactive sound propagation in complex and dynamic scenes corresponding to architectural models, outdoor scenes, and game environments. In practice, our algorithm can accurately compute early sound propagation paths with up to 4-5 reflections at 4-20 frames per second on scenes with hundreds of thousands of polygons on a multi-core PC. Our preliminary comparisons indicate that propagation based on AD-Frusta can offer considerable speedups over prior geometric propagation algorithms. We also evaluate the accuracy of our algorithm by comparing the impulse responses with an industrial strength implementation of an image source method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Organization:</head><p>The rest of the paper is organized in the following manner. We briefly survey related work on geometric sound propagation and interactive sound rendering in Section 2. Section 3 describes the AD-Frustum representation and intersection computations. We present algorithms to enumerate propagation paths in Section 4 and highlight techniques to handle complex environments in Section 5. We describe the overall performance and accuracy in Section 6. . Overview of our algorithm: AD-Frusta are generated from sound sources (primary frusta) and by reflection and diffraction (secondary frusta) from the scene primitives. Approximate visible surfaces are then computed for each frustum (quadtree update). Next, each updated frustum checks if the listener lies inside it and is visible. If visible, its contributions are registered with the audio rendering system. The audio rendering system queries the direct contribution of a sound source every time it renders its audio block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head><p>The two main approaches to sound propagation are numerical methods and geometric approaches <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b31">32]</ref>. In practice, the numerical solutions are too slow for interactive applications or dynamic scenes. In this section, we focus on geometric propagation techniques, which are primarily used to model early specular reflection and diffraction paths. Recently, techniques based on acoustic radiosity have also been developed to handle diffuse reflections for simple indoor scenes. At a broad level, the geometric propagation methods can be classified into ray-based or particle-based tracing, image source methods, and volumetric tracing.</p><p>Ray-based or Particle-based Techniques: Some of the earliest methods for geometric sound propagation are based on tracing sampled-rays <ref type="bibr" target="#b15">[16]</ref> or sound-particles (phonons) <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b22">23</ref>] from a source to the listener. Recent improvements, including optimized hierarchies and exploiting ray-coherence, make it possible for ray-based and particle-based methods to handle complex, dynamic scenes on commodity hardware <ref type="bibr" target="#b38">[39]</ref> or handle massive models <ref type="bibr" target="#b19">[20]</ref>. However, due to discrete sampling of the space, these methods have to trace large number of paths or particles to avoid aliasing artifacts.</p><p>Image Source Methods: These methods are the easiest and most popular for computing specular reflections <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref>. They compute virtual sources from a sound source recursively for every reflection and can have exponential complexity in the number of reflections. They can guarantee all specular paths up to a given order. However, they can only handle simple static scenes or very low order of reflections at interactive rates <ref type="bibr" target="#b16">[17]</ref>. Many hybrid combinations <ref type="bibr" target="#b3">[4]</ref> of ray-based and image source methods have also been proposed and used in commercial room acoustics prediction softwares (e.g. ODEON).</p><p>Volumetric Methods: The volumetric methods trace pyramidal or volumetric beams to compute an accurate geometric solution. These include beam tracing that has been used for specular reflection and edge diffraction for interactive sound propagation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b8">9]</ref>. The results of beam tracing can be used to guide sampling for path tracing <ref type="bibr" target="#b9">[10]</ref>. However, the underlying complexity of beam tracing makes it hard to handle complex models. Other volumetric tracing methods are based on triangular pyramids <ref type="bibr" target="#b7">[8]</ref>, ray-beams <ref type="bibr" target="#b24">[25]</ref>, ray-frusta <ref type="bibr" target="#b18">[19]</ref>, as well as methods developed for visual rendering <ref type="bibr" target="#b11">[12]</ref>.</p><p>Interactive Sound Propagation: Various approaches have been proposed to improve the performance of acoustic simulation or handle complex scenarios. These include model simplification algorithms <ref type="bibr" target="#b12">[13]</ref>, use of scattering filters <ref type="bibr" target="#b35">[36]</ref>, and reducing the number of active sound sources by perceptual culling or sampling <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40]</ref>. These techniques are complementary to our approach and can be combined to handle scenarios with multiple sound sources or highly tessellated objects in the scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ADAPTIVE VOLUME TRACING</head><p>Our goal is to perform interactive geometric sound propagation in complex and dynamic scenes. We mainly focus on computing paths that combine transmission, specular reflection, and edge diffraction up to a user-specified criterion from each source to the receiver. Given the underlying complexity of exact approaches, we present an approximate volumetric tracing algorithm. <ref type="figure" target="#fig_0">Fig. 1</ref> gives a top level view of our algorithm. We start by shooting frusta from the sound sources. A frustum traverses the scene hierarchy and finds a list of potentially intersecting triangles. These triangles are intersected with the frustum and the frustum is adaptively sub-divided into sub-frusta. The sub-frusta approximate which triangles are visible to the frustum. The sub-frusta are subsequently reflected and diffracted to generate more frusta, which in turn are traversed. Also, if the listener is inside a frustum and visible, the contribution is registered for use during audio rendering stage.</p><p>Our approach builds on using a ray-frustum for volumetric tracing <ref type="bibr" target="#b18">[19]</ref>. We trace the paths from the source to the receivers by tracing a sequence of ray-frusta. Each ray-frustum is a simple 4-sided frustum, represented as a convex combination of four corner rays. Instead of computing an exact intersection of the frusta with a primitive, ray-frustum tracing performs discrete clipping by intersecting a fixed number of rays for each frustum. This approach can handle complex, dynamic scenes, but has the following limitations:</p><p>• The formulation uses uniformly spaced samples inside each frustum for fast intersection computations. Using a high sampling resolution can significantly increase the number of traced frusta.</p><p>• The approach cannot adapt to the scene complexity efficiently.</p><p>In order to overcome these limitations, we propose an adaptive frustum representation, AD-Frustum. Our goal is to retain the performance benefits of the original frustum formulation, but increase the accuracy of the simulation by adaptively varying the resolution. Various components of our algorithm are shown in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">AD-Frustum</head><p>AD-Frustum is a hierarchical representation of the subdivision of a frustum. We augment a 4-sided frustum with a quadtree structure to keep track of its subdivision and maintain the correct depth information, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. Each leaf node of the quadtree represents the finest level sub-frustum that is used for volumetric tracing. An intermediate node in the quadtree corresponds to the parent frustum or an internal frustum. We adaptively refine the quadtree in order to perform accurate intersection computations with the primitives in the scene and generate new frusta based on reflections and diffraction.</p><p>Representation: Each AD-Frustum is represented using an apex and a quadtree. Each 2D node of the quadtree includes: (a) corner rays of the sub-frustum that define the extent of each sub-frustum; (b) intersection status corresponding to completely-inside, partiallyintersecting with some primitive, or completely-outside of all scene primitives; (c) intersection depth, and primitive id to track the depth value of the closest primitive; (d) list of diffracting edges to support diffraction calculations. We also associate a maximum-subdivision depth parameter with each AD-Frustum that corresponds to the maximum depth of the quadtree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Intersection Tests</head><p>The AD-Frusta are used for volumetric tracing and enumerating the propagation paths. The main operation is computing their intersection with the scene primitives and computing reflection and diffraction It is augmented with a quadtree structure, where P is the 2D plane of quadtree. We use two sets of colors to show different nodes. Each node stores auxiliary information about corresponding sub-frusta.</p><p>frusta. The scene is represented using a bounding volume hierarchy (BVH) of axis-aligned bounding boxes (AABBs). The leaf nodes of the BVH are triangle primitives and the intermediate nodes represent an AABB. For dynamic scenes, the BVH is updated at each frame <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b42">43]</ref>. Given an AD-Frustum, we traverse the BVH from the root node to perform these tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intersection with AABBs:</head><p>The intersection of an AD-Frustum with an AABB is performed by intersecting the four corner rays of the root node of the quadtree with the AABB, as described in <ref type="bibr" target="#b25">[26]</ref>. If an AABB partially or fully overlaps with the frustum, we apply the algorithm recursively to the children of the AABB. The quadtree is not modified during this traversal.</p><p>Intersection with primitives: As a frustum traverses the BVH, we compute intersections with each triangle corresponding to the leaf nodes of the BVH. We only perform these tests to classify the node as completely-inside, completely-outside or partially-intersecting. This is illustrated in <ref type="figure">Fig. 3</ref>, where we show the completely-outside regions in green and completely-inside regions in orange. This intersection test can be performed efficiently by using the Plücker coordinate representation <ref type="bibr" target="#b30">[31]</ref> for the triangle edges and four corner rays. The Plücker coordinate representation efficiently determines, based on an assumed orientation of edges, whether the sub-frustum is completely inside, outside or partially intersecting the primitive. This test is conservative and may conclude that a node is partially intersecting, even if it is completely-outside. If the frustum is classified as partiallyintersecting with the primitives, we sub-divide that quadtree node, generate four new sub-frusta, and perform the intersection test recursively. The maximum-subdivision depth parameter imposes a bound on the depth of the quadtree. Each leaf node of the quadtree is classified as completely-outside or completely-inside.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Visible Surface Approximation</head><p>A key component of the traversal algorithm is the computation of the visible primitives associated with each leaf node sub-frustum. We use an area-subdivision technique, similar to classic Warnock's algorithm <ref type="bibr" target="#b40">[41]</ref>, to compute the visible primitives. Our algorithm associates intersection depth values of four corner rays with each leaf node of the quadtree as well as the id of the corresponding triangle. Moreover, we compute the minimum and maximum depth for each intermediate node of the triangle, that represents the extent of triangles that partially overlap with its frustum. The depth information of all the nodes is updated whenever we perform intersection computations with a new triangle primitive.</p><p>In order to highlight the basic subdivision algorithm, we consider the case of two triangles in the scene shown as red and blue in <ref type="figure">Fig. 3</ref>. In this example, the projections of the triangles on the quadtree plane overlap. We illustrate different cases that can arise based on the relative ordering and orientation of two triangles. The basic operation compares the depths of corner rays associated with the frustum and updates the node with the depth of the closer ray (as shown in <ref type="figure">Fig.  3(a)</ref>). If we cannot resolve the closest depth (see <ref type="figure">Fig. 3(d)</ref>), we apply the algorithm recursively to its children (shown in orange). <ref type="figure">Fig.  3(b)</ref> shows the comparison between a partially-intersecting node with a completely-inside node. If the completely-inside node is closer, i.e., all the corner rays of the completely-inside node are closer than the minimum depth of the corner rays of the partially-intersecting node, then the quadtree is updated with the completely-inside node. Otherwise, we apply the algorithm recursively to their children as in <ref type="figure">Fig.  3</ref>(e). Lastly, in <ref type="figure">Fig. 3(c)</ref>, both the nodes are partially-intersecting and we apply the algorithm recursively on their children.</p><p>This approach can be easily generalized to handle all the triangles that overlap with an AD-Frustum. At any stage, the algorithm maintains the depth values based on intersection with all the primitives traversed so far. As we perform intersection computations with a new primitive, we update the intersection depth values by comparing the previous values stored in the quadtree. The accuracy of our algorithm is governed by the resolution of the leaf nodes of the quadtree, which is based on the maximum-subdivision depth parameter associated with each AD-Frustum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Nodes Reduction</head><p>We perform an optimization step to reduce the number of frusta. This step is performed in a bottom up manner, after AD-Frustum finishes the scene traversal. We look at the children of a node. Since, each child shares atleast one corner-ray with its siblings, we compare the depths of these corner-rays. Based on the difference in depth values, the normals of the surfaces the sub-frustum intersects, and the acoustic properties of those surfaces we collapse the children nodes into the parent node. Thus, we can easily combine the children nodes in the quadtree that hit the same plane with similar acoustic properties. Such an approach can also be used to combine children nodes that intersect slightly different surfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ENUMERATING PROPAGATION PATHS</head><p>In the previous section, we described the AD-Frustum representation and presented an efficient algorithm to compute its intersection and visibility with the scene primitives. In this section, we present algorithms to trace the frusta through the scene, and compute reflection and diffraction frusta. We start the simulation by computing initial frusta around a sound source in quasi-uniform fashion <ref type="bibr" target="#b26">[27]</ref> and perform adaptive subdivision based on the intersection tests. Ultimately, the sub-frusta corresponding to the leaf nodes of the quadtree are used to compute reflection and diffraction frusta.</p><p>Specular Reflections: Once a frustum has completely traced a scene, we consider all the leaf nodes within its quadtree and compute a reflection frustum for all completely-intersecting leaf nodes. The corner rays of sub-frustum associated with the leaf nodes are reflected (see <ref type="figure" target="#fig_3">Fig. 5</ref>) at the primitive hit by that sub-frustum. The convex combination of the reflected corner rays creates the parent frustum for the reflection AD-Frustum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Edge Diffraction</head><p>Diffraction happens when a sound wave hits an object whose size is the same order of magnitude as its wavelength, causing the wave to scatter. Our formulation of diffraction is based on the uniform theory of diffraction (UTD) <ref type="bibr" target="#b14">[15]</ref>, which predicts that a sound wave hitting an edge between the primitives is scattered in a cone. The half-angle of the cone is determined by the angle that the ray hits the edge. The basic ray-frustum tracing algorithm can compute edge diffraction based on UTD <ref type="bibr" target="#b33">[34]</ref>. This involves identifying diffraction edges as part of a pre-process and computing diffraction paths using frusta tracing. In this section, we extend the approach described in <ref type="bibr" target="#b33">[34]</ref> to handle AD-Frusta.</p><p>Finding diffracting edges: In a given scene, only a subset of the edges are diffraction edges. For example, any planar rectangle is represented by two triangles sharing an edge, but that edge cannot result in diffraction. Most edges in a model are shared by at least two triangles. As part of a pre-computation step, we represent the adjacency information using an edge-based data structure that associates all edges that can result in diffraction with its incident triangles. As part of the tracing algorithm, we compute all triangles that intersect a sub-frustum. Next, we check whether the sub-frustum intersects any of the edges of that triangle and based on that update the list of diffracting edges  <ref type="figure">Fig. 3</ref>. Visibility computation based on area subdivision: We highlight different cases that arise as we resolve visibility between two triangle primitives (shown in red and blue) from the apex of the frustum. In cases (a)-(b) the quadtree is refined based on the intersection depth associated with the outermost frustum and compared with the triangles. However, in cases (c)-(e) the outermost frustum has to be sub-divided into sub-frusta and each of them is compared separately. <ref type="figure">Fig. 4</ref>. Generating a diffraction frustum from an edge. The resulting wedge is shown as red and we show the generation of diffraction shadow frustum from the original sub-frustum. Note that the origin for the frustum is not just the edge, but the whole area of the sub-frustum that overlaps the edge.</p><p>for that sub-frustum. We perform these tests efficiently using Plücker coordinates. Computing Diffraction Frusta: Our adaptive diffraction approach is similar to the diffraction formulation described in <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37]</ref>. There are two main problems that arise in simulating edge diffraction using frusta: first, finding the shape of the new frustum that corresponds to the real diffraction as predicted by the UTD; second, computing the actual contribution that the diffraction makes to the sound at the listener.</p><p>Given a diffraction edge, we clip the sub-frustum against the edge to find the interval along the edge that it intersects. The diffraction cone originates from the respective part of the edge and its orientation and shape are predicted by the UTD based on the angle of the edge. The angle is computed from the triangles incident to the edge. Notice that we perform an approximation similar to <ref type="bibr" target="#b36">[37]</ref> in that we ignore the non-'shadow' part of the diffraction. As part of frustum tracing, we ensure that the origin of the diffraction frustum is not limited to lie on the edge, but is chosen as the whole area of the frustum that overlaps the edge (see <ref type="figure">Fig. 4</ref> for illustration). We compute this area by clipping the quadrilateral defined by the intersection of the frustum with the triangle's plane against the triangle edge. This computation extends the frustum shape beyond the actual diffraction field originating from the edge. This has the important practical advantage that it will include the direct contribution of the original frustum for parts of the frustum that do not overlap with the triangle. As a result, this formulation actually adds back direct contributions that would have been lost due to the discrete nature of the frustum representation. One special case occurs if just one corner of the frustum is inside the triangle, since in that case the clipped frustum has five edges. We handle this case by using a conservative bounding frustum and performing an additional check for inclusion when we compute all the contributions to the listener. Note that UTD is valid only for scenes with long edges, like the outdoor city scene or large walls and doors of architecture models. We therefore perform edge-diffraction on such models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Contributions to the Listener</head><p>For the specular reflections the actual contribution of a frustum is determined by finding a path inside all the frusta from the sound source to the listener. In case of diffraction, we have to ensure that the subfrustum is actually in the real diffraction shadow part of the frustum. There are three distinct possibilities: first, the sub-frustum can be part of the direct contribution as described above. In that case, the contribution is simply computed like a direct one. The second case is that the sub-frustum is not a direct one, but also not inside the diffraction cone, i.e. inside the conservative bounding frustum. In that case, it can be safely ignored. Finally, if the listener's location is inside the diffraction frustum, we can compute the exact path due to all diffraction events. The UTD formulation predicts the intensity of the sound field inside the diffraction cone, which depends on several variables, but most importantly the angle to the line of visibility (see <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37]</ref> for more details). For the frustum representation, the equation can either be evaluated while computing the exact path, or per sub-frustum, i.e. by discretizing the equation. In our formulation, we chose the latter such that the contribution can be evaluated very quickly per frustum, with a slight impact on the exact timing of the diffraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">COMPLEX SCENES</head><p>In this section, we give a brief overview of how to govern the accuracy of our algorithm for complex scenes. The complexity of the AD-Frustum tracing algorithm described in Sections 3 and 4 varies as a function of the maximum-subdivision depth parameter associated with each AD-Frustum. A higher value of this parameter results in a finer subdivision of the quadtree and improves the accuracy of the intersection and volumetric tracing algorithms (see <ref type="figure" target="#fig_3">Fig. 5</ref>). At the same time, the number of leaf nodes can potentially increase as an exponential function of this parameter and significantly increase the number of traced frusta through the scene. Here, we present techniques for automatic computation of the depth parameter for each AD-Frustum. We consider two different scenarios: capturing the contributions from all important objects in the scene and constant frame-rate rendering.</p><p>Our basic algorithm is applicable to all triangulated models. We do not make any assumptions about the connectivity of the triangles and can handle all polygonal soup datasets. Many times, a scene consists of objects that are represented using connected triangles. In the context of this paper, an object corresponds to a collection of triangles that are very close (or connected) to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Maximum-subdivision depth computation</head><p>One of the main challenges is to ensure that our algorithm doesn't miss the important contributions in terms of specular reflections and diffraction. We take into account some of the characteristics of geometric sound propagation in characterizing the importance of different objects. For example, many experimental observations have suggested that low-resolution geometric models are more useful for specular reflections <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b35">36]</ref>. Similarly, small objects in the scene only have significant impact at high frequencies and can be excluded from the models in the presence of other significant sources of reflection and diffraction <ref type="bibr" target="#b9">[10]</ref>. Based on these characterizations, we pre-compute geometric simplifications of highly tessellated small objects and assign an importance function to each object based on its size and material properties.</p><p>Given an object (O) with its importance function, our goal is to ensure that the approximate frustum-intersection algorithm doesn't miss contributions from that object. Given a frustum with its apex (A) and We repeat this computation for all objects with high importance value in the scene. The maximum-subdivision depth parameter for that frustum is computed by considering the minimum size of the leaf nodes of the quadtree over all objects. Since we use a bounding box of O to compute the projection, our algorithm tends to be conservative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Constant frame rate rendering</head><p>In order to achieve target frame rate, we can bound the number of frusta that are traced through the scene. We first estimate the number of frustum that our algorithm can trace per second based on scene complexity, number of dynamic objects and sources. Given a bound on maximum number of frusta traced per second, we adjust the number of primary frusta that are traced from each source. Moreover, we use a larger value of the maximum depth parameter for the first few reflections and decrease this value for higher order reflections. We compute the first few reflections with higher accuracy by performing more adaptive subdivisions. We also perform adaptive subdivisions of a frustum based on its propagated distance. In this manner, our algorithm would compute more contributions from large objects in the scene, and tend to ignore contributions from relatively small objects that are not close to the source or the receiver. We can further improve the performance by using dynamic sorting and culling algorithms along with perceptual metrics <ref type="bibr" target="#b37">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">IMPLEMENTATION AND RESULTS</head><p>In this section, we highlight the performance of our algorithm on different benchmarks, describe our audio rendering pipeline, and analyze its accuracy. Our simulations were run on a 2.66 GHz Intel Core 2 Duo machine with 2GB of memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Performance Results</head><p>We perform geometric sound propagation using adaptive frustum tracing on many benchmarks. The complexity of our benchmarks ranges from a few hundred triangles to almost a million triangles. The performance results for adaptive frustum tracing and complexity of benchmarks are summarized in <ref type="table">Table 1</ref>. These results are generated for a maximum sub-division depth of 3. Further, the extent of dynamism in these benchmarks is shown in associated video. In <ref type="figure" target="#fig_4">Fig. 7</ref>, we show how the computation time for our approach and the number of frusta traced scale as we increase the maximum sub-division depth of AD-Frusta. Also, our algorithm scales well with the number of cores as shown in <ref type="figure">Fig. 8</ref>. The comparison of our approach with uniform frustum tracing <ref type="bibr" target="#b18">[19]</ref> is given in <ref type="table" target="#tab_2">Table 2</ref>. We chose a sampling resolution of  <ref type="table">Table 1</ref>. This table summarizes the performance of our system on six benchmarks. The complexity of a model is given by the number of triangles. We perform edge diffraction in two models and specular reflection in all. We use a value of 3 for the maximum sub-division depth for these timings. The results are computed for up to 4 orders of reflection. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Audio Rendering</head><p>Audio rendering is the process of generating the final audio signal in an application. In our case, it corresponds to the convolution of the filter generated by sound propagation simulation with the input audio to produce the final sound at the receiver. In this section, we outline an audio rendering pipeline that can be integrated with our geometric propagation approach to perform interactive audio rendering for scenes with moving sources, moving listener, and dynamic objects. The two main methods for performing interactive audio rendering are "direct room impulse response rendering" and "parametric room  <ref type="figure">Fig. 8</ref>. This figure shows that our algorithm scales well with the number of cores. It makes our approach favorable for parallel and many-core platforms. Reflections for up to 4th order were computed and larger of maximum sub-division depths similar to those in <ref type="table">Table 3</ref> were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Frusta  <ref type="bibr" target="#b18">[19]</ref> for results of similar accuracy. Our adaptive frustum formulation significantly improves the performance as compared to prior approaches.</p><p>impulse response rendering" <ref type="bibr" target="#b28">[29]</ref>. In "direct room impulse response rendering", impulse responses are pre-computed at some fixed listener locations. Next, the impulse response at some arbitrary listener position is computed by interpolating the impulse responses at nearby fixed listener locations. Such a rendering method is not very suitable when the source is moving or the scene geometry is changing. "Parametric room impulse response rendering" uses parameters like reflection path to the listener, materials of the objects in reflection path etc. to perform interactive audio rendering. However, in this case it is important that the underlying geometric propagation system is able to update these parameters at very high update rates. Sandvad <ref type="bibr" target="#b27">[28]</ref> suggests that update rates above 10 Hz should be used. In the DIVA system <ref type="bibr" target="#b28">[29]</ref>, an update rate of 20 Hz is used to generate artifact free audio rendering for dynamic scenes. We also use similar audio rendering techniques. <ref type="table">Table 3</ref> shows that we can update parameters at a high rate with maximum sub-division depth of 2 on a single core, as required by "Parametric room impulse response rendering". Similar update rates for a sub-division depth of 3 on a single core can be achieved by decreasing the order of reflection or by updating the low order reflections more frequently than higher order reflections (see <ref type="table">Ta-ble 3</ref>). Furthermore, we need to interpolate the parameters between the updates, as suggested in <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b34">35]</ref>, to minimize the artifacts due to the changing impulse responses. In order to demonstrate the accuracy of our propagation algorithm, we perform audio rendering offline in some benchmarks. Also, the impulse responses used to generate the final rendered audio contain only early specular reflections and no late reverberation. This is done so it is easy to evaluate the effect of early reflections computed by our adaptive frustum tracing algorithm. Late reverberations can be computed as a pre-processing step <ref type="bibr" target="#b28">[29]</ref> and can improve the audio quality.  <ref type="table">Table 3</ref>. This table shows the performance of adaptive frustum tracing on a single core for different maximum sub-division depths. The timings are further broken down according to order of reflection. Our propagation algorithm achieves interactive performance for most benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Order of Reflection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Accuracy and Validation</head><p>Our approach is an approximate volume tracing approach and we can control its accuracy by varying the maximum-subdivision depth of each AD-Frustum. In order to evaluate the accuracy of propagation paths, we compare the impulse responses computed by our algorithm with other geometric propagation methods. We are not aware of any public or commercial implementation of beam tracing which can handle complex scenes with dynamic objects highlighted in <ref type="table">Table 1</ref>. Rather, we use an industry strength implementation of image source method available as part of CATT-Acoustic TM software. We compare our results for specular reflection on various benchmarks available with CATT software (see <ref type="figure" target="#fig_7">Fig. 9</ref> and <ref type="figure" target="#fig_0">Fig. 10</ref>). The results show that our method gives more accurate results with higher maximum sub-division depths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ANALYSIS AND COMPARISON</head><p>In this section, we analyze the performance of our algorithm and compare it with other geometric propagation techniques. The running time of our algorithm is governed by three main factors: model complexity,  level of dynamism in the scene, and the relative placement of objects with respect to the sources and receiver. As part of a pre-process, we compute a bounding volume hierarchy of AABBs. This hierarchy is updated as some objects in the scene move or some objects are added or deleted from the scene. Our current implementation uses a linear time refitting algorithm that updates the BVH in a bottom-up manner. If there are topological changes in the scene (e.g. explosions), than the resulting hierarchy can have poor culling efficiency and can result in more intersection tests <ref type="bibr" target="#b38">[39]</ref>. The complexity of each frustum intersection test is almost logarithmic in the number of scene primitives and linear in the number of sub-frusta generated based on adaptive subdivision. The actual number of frusta traced also vary as a function of number of reflections as well as the relative orientation of the objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Comparison</head><p>The notion of using an adaptive technique for geometric sound propagation is not novel. There is extensive literature on performing adaptive supersampling for path or ray tracing in both sound and visual rendering. However, the recent work in interactive ray tracing for visual rendering has shown that adaptive sampling, despite its natural advantages, does not perform near as fast as simpler approaches that are based on ray-coherence <ref type="bibr" target="#b38">[39]</ref>. On the other hand, we are able to perform fast intersection tests on the AD-Frusta using ray-coherence and the Plücker coordinate representation. By limiting our formulation to 4-sided frusta, we are also able to exploit the SIMD capabilities of current commodity processors.</p><p>Many adaptive volumetric techniques have also been proposed for geometric sound propagation. <ref type="bibr" target="#b29">Shinya et al. [1987]</ref> traces a pencil of rays and require that the scene has smooth surfaces and no edges, which is infeasible as most models of interest would have sharp edges. <ref type="bibr" target="#b24">Rajkumar et al. [1996]</ref> used static BSP tree structure and the beam starts out with just one sample ray and is subdivided only at primitive intersection events. This can result into sampling problems due to missed scene hierarchy nodes. <ref type="bibr" target="#b6">Drumm and Lam [2000]</ref> describe an adaptive beam tracing algorithm, but it is not clear whether it can handle complex, dynamic scenes. The volume tracing formulation <ref type="bibr" target="#b11">[12]</ref> shoots pyramidal volume and subdivides them in case they intersect with some object partially. This approach has been limited to visual rendering and there may be issues in combining this approach with a scene hierarchy. The benefits over the ray-frustum approach <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18]</ref> are shown in <ref type="figure" target="#fig_3">Fig. 5</ref>. The propagation based on AD-Frustum traces fewer frusta.</p><p>In many ways, our adaptive volumetric tracing offers contrasting features as compared to ray tracing and beam tracing algorithms. Ray tracing algorithms can handle complex, dynamic scenes and can model diffuse reflections and refraction on top of specular reflection and diffraction. However, these algorithms need to perform very high su-  persampling to overcome noise and aliasing problems, both spatially and temporally. For the same accuracy, propagation based on AD-Frustum can be much faster than ray tracing for specular reflections and edge diffraction.</p><p>The beam tracing based propagation algorithms are more accurate as compared to our approach. Recent improvements in the performance of beam tracing algorithms <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b16">17]</ref> are promising and can make them applicable to more complex static scenes with few tens of thousands of triangles. However, the underlying complexity of performing exact clipping operations makes beam tracing more expensive and complicated. In contract, AD-Frustum compromises on the accuracy by performing discrete clipping with the 4-sided frustum. Similarly, image-source methods are rather slow for interactive applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Limitations</head><p>Our approach has many limitations. We have already addressed the accuracy issue above. Our formulation cannot directly handle diffuse, lambertian or "glossy" reflections. Moreover, it is limited to point sources though we can potentially simulate area and volumetric sources if they can be approximated with planar surfaces. Many of the underlying computations such as maximum-subdivision depth parameter and intersection test based on Plücker coordinate representation are conservative. As a result, we may generate unnecessary sub-frusta for tracing. Moreover, the shape of the diffraction frustum may extend beyond the actual diffraction field originating from the edge. Limitations of UTD-based edge diffraction are mentioned in Section 4.1. Currently, our audio rendering system does not perform interpolation of parameters, as suggested in <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b34">35]</ref>, and hence could result in some clicking artifacts when performing interactive audio rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>We present an adaptive volumetric tracing for interactive sound propagation based on transmissions, specular reflections and edge diffraction in complex scenes. Our approach uses a simple, adaptive frustum representation that provides a balance between accuracy and interactivity. We verify the accuracy of our approach by comparing the performance on simple benchmarks with commercial state-of-the-art software. Our approach can handle complex, dynamic benchmarks with tens or hundreds of thousands of triangles. The initial results seem to indicate that our approach may be able to generate plausible sound rendering for interactive applications such as conceptual acoustic design, video games and urban simulations. Our approach maps well to the commodity hardware and empirical results indicate that it may scale linearly with the number of cores.</p><p>There are many avenues for future work. We would like to use perceptual techniques <ref type="bibr" target="#b37">[38]</ref> to handle multiple sources as well as use scattering filters for detailed geometry <ref type="bibr" target="#b35">[36]</ref>. It may be possible to use visibility culling techniques to reduce the number of traced frusta. We can refine the criterion for computation of maximum-subdivision depth parameter based on perceptual metrics. It may be useful to use the Biot-Tolstoy-Medwin (BTM) model of edge diffraction instead of the UTD model <ref type="bibr" target="#b2">[3]</ref>. We also want to develop a robust interactive audio rendering pipeline which can integrate well with UTD. Finally, we would like to extend the approach to handle more complex environments and evaluate its use on applications that can combine interactive sound rendering with visual rendering.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1. Overview of our algorithm: AD-Frusta are generated from sound sources (primary frusta) and by reflection and diffraction (secondary frusta) from the scene primitives. Approximate visible surfaces are then computed for each frustum (quadtree update). Next, each updated frustum checks if the listener lies inside it and is visible. If visible, its contributions are registered with the audio rendering system. The audio rendering system queries the direct contribution of a sound source every time it renders its audio block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>AD-Frustum Representation: (a) A frustum, represented by convex combination of four corner rays and apex A. (b) A hierarchically divided adaptive frustum.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Beam tracing vs. uniform frustum tracing vs. adaptive frustum tracing: We show the relative accuracy of three different algorithm in this simple 2D model with only first-order reflections. (a) Reflected beams generated using exact beam tracing. (b)-(c) Reflected frusta generated with uniform frustum tracing for increased sampling: 2 2 samples per frustum and 2 4 samples per frustum. Uniform frustum tracing generates uniform number of samples in each frustum, independent of scene complexity. (d)-(e) Reflected frusta generated using AD-Frustum. We highlight the accuracy of the algorithm by using the values of 2 and 4 for maximum-subdivision depth parameter. (f) An augmented binary tree for the 2D case (equivalent to a quadtree in 3D) showing the adaptive frusta. Note that the adaptive algorithm only generates more frusta in the regions where the input primitives have a high curvature and reduces the propagation error.the plane of its quadtree (P), we compute a perspective projection of the bounding box of O on the P. Let's denote the projection on P as o. Based on the size of o, we compute a bound on the size of leaf nodes of the quadtree such that the squares corresponding to the leaf nodes are inside o. If O has a high importance values attached to it, we ensure multiple leaf nodes of the quadtree are contained in o.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 .</head><label>7</label><figDesc>This figure shows the effect of increasing the maximum subdivision depth of adaptive frustum tracing on the overall computation time of the simulation and the number of total frusta traced. Different colors are used for different benchmarks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Different Benchmarks: (a) Game Model with low geometric complexity. It has dynamic objects and a moving listener. (b) Sibenik Cathedral, a complex architectural model with a lot of details and curved geometry. It consists of moving source and listener, and a door that opens and closes. (c) City Scene with many moving cars (dynamic objects) and tall buildings which cause edge diffraction. It has a moving sound source, a static sound source, and a listener. (d) Soda Hall, a complex architectural model with multiple floors. The dimensions of a room are dynamically modified and the sound propagation paths recomputed for this new room using AD-Frusta. This scenario demonstrates the potential of our approach for conceptual acoustic design.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>(a) Theater benchmark with 54 triangles. (b) Impulse response generated by image source method for 3 reflections. (c)-(e) Impulse responses generated by our approach with maximum sub-division depth of 2, 4, and 5 respectively for 3 reflections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>(a) Factory benchmark with 174 triangles. (b) Impulse response generated by image source method for 3 reflections. (c)-(e) Impulse responses generated by our approach with maximum sub-division depth of 2, 4, and 5 respectively for 3 reflections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>Anish Chandak, E-mail: achandak@cs.unc.edu. • Christian Lauterbach, E-mail: cl@cs.unc.edu. • Micah Taylor, E-mail: taylormt@cs.unc.edu. • Zhimin Ren, E-mail: zren@cs.unc.edu. • Dinesh Manocha, E-mail: dm@cs.unc.edu. • Project Webpage: http://gamma.cs.unc.edu/SOUND Manuscript received 31 March 2008; accepted 1 August 2008; posted online 19 October 2008; mailed on 13 October 2008. For information on obtaining reprints of this article, please send e-mailto:tvcg@computer.org.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>This table presents a preliminary comparison of the number of frusta traced and time taken by Adaptive Frustum Tracing and Uniform Frustum Tracing</figDesc><table><row><cell></cell><cell></cell><cell>traced</cell><cell cols="2">Frusta Time</cell></row><row><cell></cell><cell>UFT</cell><cell>AFT</cell><cell>Gain</cell><cell>Gain</cell></row><row><cell>Theater</cell><cell>404K</cell><cell>56K</cell><cell>7.2</cell><cell>6.1</cell></row><row><cell>Factory</cell><cell>288K</cell><cell>40K</cell><cell>7.2</cell><cell>5.7</cell></row><row><cell>Game</cell><cell cols="2">2330K 206K</cell><cell>11.3</cell><cell>9.0</cell></row><row><cell>Sibenik</cell><cell cols="2">6566K 198K</cell><cell>33.2</cell><cell>21.9</cell></row><row><cell>City</cell><cell>377K</cell><cell>78K</cell><cell>4.9</cell><cell>5.2</cell></row><row><cell>Soda Hall</cell><cell>773K</cell><cell>108K</cell><cell>7.2</cell><cell>9.8</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank Paul Calamia, Nikunj Raghuvanshi, and Jason Sewall for their feedback and suggestions. This work was supported in part by ARO Contracts DAAD19-02-1-0390 and W911NF-04-1-0088, NSF awards 0400134, 0429583 and 0404088, DARPA/RDECOM Contract N61339-04-C-0043, Intel, and Microsoft.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image method for efficiently simulating small-room acoustics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Berkley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="943" to="950" />
			<date type="published" when="1979-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Phonon tracing for auralization and visualization of sound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bertram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Deines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mohring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jegorovs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast Time-Domain Edge-Diffraction Calculations for Interactive Acoustic Simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Calamia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">P</forename><surname>Svensson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Advances in Signal Processing</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Room acoustic prediction based on a unified treatment of diffuse and specular reflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-I</forename><surname>Dalenbäck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="899" to="909" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Real time walkthrough auralizationthe first year</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-I</forename><surname>Dalenbäck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Strömberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Institute of Acoustics</title>
		<meeting>the Institute of Acoustics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Comparative visualization for wave-based and geometric acoustics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Deines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bertram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mohring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jegorovs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nielson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The adaptive beam-tracing algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Drumm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Lam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-03" />
			<publisher>Acoustical Society of America</publisher>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="1405" to="1412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">RAMSETE -a new Pyramid Tracer for medium and large scale acoustic problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EURO-NOISE</title>
		<meeting>EURO-NOISE</meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Topological beam tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fortune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SCG &apos;99: Proceedings of the fifteenth annual symposium on Computational geometry</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A beam tracing approach to acoustic modeling for interactive virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Carlbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Elko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sondhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGGRAPH</title>
		<meeting>of ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="21" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsingos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Jot</surname></persName>
		</author>
		<title level="m">Survey of Methods for Modeling Sound Propagation in Interactive Virtual Environment Systems. Presence and Teleoperation</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive supersampling in object space using pyramidal rays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Genetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="29" to="54" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Significant facet retrieval for realtime 3D sound rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Joslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Magnetat-Thalmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM VRST</title>
		<meeting>the ACM VRST</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Acoustic Modeling Utilizing an Acoustic Version of Phonon Mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kapralos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jenkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Milios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Workshop on HAVE</title>
		<meeting>of IEEE Workshop on HAVE</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Geometrical theory of diffraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="116" to="130" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Calculating the acoustical room response by the use of a ray tracing technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krokstad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Strom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sorsdal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sound and Vibration</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="118" to="125" />
			<date type="published" when="1968-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Accelerated beam tracing algorithm. Applied Acoustic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Siltanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Savioja</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Adaptive sampling for frustum-based sound propagation in complex and dynamic environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lauterbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Congress on Acoustics</title>
		<meeting>the 19th International Congress on Acoustics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interactive sound propagation in dynamic scenes using frustum tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lauterbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1672" to="1679" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ReduceM: Interactive and Memory Efficient Ray Tracing of Large Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lauterbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-E</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eurographics Symposium on Rendering</title>
		<meeting>of the Eurographics Symposium on Rendering</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">RT-DEFORM: Interactive Ray Tracing of Dynamic Scenes using BVHs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lauterbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-E</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Interactive Ray Tracing</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multisensory perception: Beyond the visual in visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Loftin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science and Engineering</title>
		<imprint>
			<biblScope unit="volume">05</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="56" to="58" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Listener-based Analysis of Surface Importance for Acoustic Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Deines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hering-Bertram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1680" to="1687" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Real-time Beam Tracer with Application to Exact Soft Shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Overbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Symposium on Rendering</title>
		<imprint>
			<date type="published" when="2007-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Predicting RF coverage in large environments using ray-beam tracing and partitioning tree represented geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Naylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Feisullin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wirel. Netw</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="154" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-level ray tracing algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reshetov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soupikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hurley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1176" to="1185" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cubed Sphere&quot;: A New Method for the Solution of Partial Differential Equations in Spherical Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ronchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Iacono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paolucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>The</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Physics</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="93" to="114" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamic aspects of auditory virtual environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sandvad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Audio Engineering Society 100th Convention preprints</title>
		<imprint>
			<date type="published" when="1996-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Creating interactive virtual acoustic environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Savioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huopaniemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Väänänen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Audio Engineering Society (JAES)</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="675" to="705" />
			<date type="published" when="1999-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Principles and applications of pencil tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shinya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Naito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGGRAPH</title>
		<meeting>of ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Plücker coordinate tutorial</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shoemake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ray Tracing News</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The room acoustic rendering equation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Siltanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kiminki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Savioja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1624" to="1635" />
			<date type="published" when="2007-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Auditory representation of scientific data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Focus on Scientific Visualization</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="337" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Edge Diffraction in Frustum Tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lauterbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chandak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>University of North Carolina at Chapel Hill</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A versatile software architecture for virtual audio simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Auditory Display (ICAD)</title>
		<meeting><address><addrLine>Espoo, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Instant sound scattering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsingos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dachsbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dellepiane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eurographics Symposium on Rendering</title>
		<meeting>the Eurographics Symposium on Rendering</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Modeling acoustics in virtual environments using the uniform theory of diffraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsingos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ngan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Carlbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGGRAPH</title>
		<meeting>of ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="545" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Perceptual audio rendering of complex virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsingos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Drettakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="258" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">State of the Art in Ray Tracing Dynamic Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gunther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ize</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eurographics State of the Art Reports</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-resolution sound rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Straßer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPBG&apos;04 Symposium on Point -Based Graphics</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="3" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A hidden-surface algorithm for computer generated half-tone pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Warnock</surname></persName>
		</author>
		<idno>TR 4-15, NTIS AD-753 671</idno>
		<imprint>
			<date type="published" when="1969" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Utah</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A software-based system for interactive sound synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Abel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Auditory Display (ICAD)</title>
		<meeting><address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Ray Tracing Dynamic Scenes using Selective Restructuring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-E</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Curtis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eurographics Symposium on Rendering</title>
		<meeting>of the Eurographics Symposium on Rendering</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
