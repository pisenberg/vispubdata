<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Effective Visualization of Short Routes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Degener</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruwen</forename><surname>Schnabel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Schwartz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Reinhard</forename><surname>Klein</surname></persName>
						</author>
						<title level="a" type="main">Effective Visualization of Short Routes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Maps</term>
					<term>Route visualization</term>
					<term>Space deformation</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In this work we develop a new alternative to conventional maps for visualization of relatively short paths as they are frequently encountered in hotels, resorts or museums. Our approach is based on a warped rendering of a 3D model of the environment such that the visualized path appears to be straight even though it may contain several junctions. This has the advantage that the beholder of the image gains a realistic impression of the surroundings along the way which makes it easy to retrace the route in practice. We give an intuitive method for generation of such images and present results from user studies undertaken to evaluate the benefit of the warped images for orientation in unknown environments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Navigating in an unknown environment can be a daunting task. Everyone has experienced the frustration felt as a newcomer in an unknown and complex place, for example when one is unable to locate the breakfast room in a large hotel. Usually there are many installments in such places that are supposed to assist navigation in this situation, most notably signposts and maps, either fixed at walls, like emergency plans, or handed out to visitors on leaflets. Although 2D maps are the predominant navigation aid, they often fail their purpose for the following reasons: First, the interpretation of a map can require considerable mental effort since the observer must locate her standpoint and orient the map properly <ref type="bibr" target="#b14">[15]</ref>. Furthermore, a correspondence between map and environment has to be established. Humans perform this task by identifying and matching landmarks in a scene (e.g. walls, corners, doors) with their map representation <ref type="bibr" target="#b22">[23]</ref>.</p><p>These landmarks act as primary nodes that help to organize spatial information and may be noticed due to their visual dominance, a characteristic shape or because of a personal significance. From a psychological point of view <ref type="bibr" target="#b28">[29]</ref>, the identification of landmarks constitutes the first of three stages in the acquisition of spatial knowledge. By traveling along a path in a first person perspective, landmarks are connected in the second stage to form procedural route knowledge. In a final stage structural survey knowledge is derived which is equivalent to inferring a map and which allows to estimate distances between way points or to derive shortcuts.</p><p>As maps show an abstract representation, the task of decrypting, recognizing and matching landmarks demands the observer's full attention. Matching such a representation to real world objects requires considerably more cognitive effort than matching photos or images rendered from an egocentric perspective <ref type="bibr" target="#b16">[17]</ref>. As a consequence, on mobile navigation devices classical maps are usually accompanied by images that show the environment from an egocentric perspective. As shown by Chittaro and Burigat <ref type="bibr" target="#b7">[8]</ref>, such representations are clearly superior to classical maps alone. While a combination of map and egocentric images is easily possible on mobile devices, a small set of views has to be selected and placed on a 2D canvas in the static case, where the visitor is only provided with a print out. Both choice and placement of appropriate views are clearly not trivial. Moreover, the correct interpretation of such annotated maps demands further mental efforts from the observer.</p><p>In this work we consider a novel means to convey directions in a single warped image of the path leading to the desired destination. In contrast to standard photos which cannot depict anything around a corner due to occlusion, our method uses an appropriate space deformation that aligns the route with the viewing direction. This way synthetic images can be generated from 3D models that give the impression of looking along the path all the way to the destination (see <ref type="figure">Fig. 1</ref>). Rendered from a roughly egocentric perspective, this image can be quickly grasped and easily oriented. Moreover, it contains realistic portrayals of important landmarks along the way which are crucial for orientation and way finding <ref type="bibr" target="#b24">[25]</ref>. As opposed to maps, the depiction of these features is not abstract but realistic and thus the required mental effort for matching and alignment of landmarks is greatly reduced. Perspective distortion in the image gives further important clues to the distance and relation of objects and junctions. In particular, the contributions of this paper are as follows:</p><p>• We propose a novel visualization technique for short routes that addresses the above mentioned shortcomings of maps and photos by showing the whole path contiguously as seen from an egocentric perspective within a single image.</p><p>• We introduce a non-standard space-deformation based camera model tailored to our visualization that enables simple and intuitive rendering of paths.</p><p>A weakness of the approach is that the generated images may sometimes fail to convey turns due to the straightening of the path. We show that we can alleviate this issue with the introduction of additional visual hints. Finally, the paper exemplifies the proposed camera model on several paths in a virtual environment and discusses the results of a user study that we undertook to evaluate the effectiveness of our route visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PREVIOUS WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Non standard cameras</head><p>As an alternative to the standard perspective pinhole camera numerous non-standard projection models which mostly aim at artistic and nonphoto-realistic rendering have been proposed in the past. We will give a brief account of these models which can be roughly grouped into four categories: non-planar projection surfaces, non-linear ray tracing, multi view interpolation and space deformations. Models which fall into the first category generalize the pinhole camera by replacing the projection plane by a non-planar surface. Löffelmann and Gröller introduce in <ref type="bibr" target="#b20">[21]</ref> an abstract camera model for ray tracing that renders a scene on arbitrary curved surface. The model is very general and allows even to specify non-orthogonal ray directions for each point. Similary, the models of Yonggao et al. <ref type="bibr" target="#b30">[31]</ref> and Levene <ref type="bibr" target="#b19">[20]</ref> which generalizes a set of non-standard projections proposed earlier by Inakage <ref type="bibr" target="#b15">[16]</ref> allow for non-planar projection surfaces. While Yonggao et al. show how their projection can be extended with 3D lenses, Levene's model can combine multiple projections into a single image. To generate survey renderings for complex scenes, Rademacher and Bishop <ref type="bibr" target="#b23">[24]</ref> defined a strip camera which is specified by a parametric curve and associated view directions. They also mention the possibility to generalize their model for parametric surfaces but do not actually pursue this idea. Finally, Yu and McMillan present in <ref type="bibr" target="#b31">[32]</ref> the generalized linear cameras (GLS) model which unifies most of the above models. A GLS is specified by a set of linear cameras, each of which is defined by three rays so that arbitrary projection surfaces and ray directions can be prescribed.</p><p>Another completely different approach to non-standard cameras is to combine several standard projections into a single image as first suggested by Agrawala et al. in <ref type="bibr" target="#b1">[2]</ref>. In their approach each object in the scene is assigned to a standard camera and rendered accordingly. These renderings are then composed into a single image while special care is taken to resolve occlusion issues. Instead of composing operations, Singh blends in <ref type="bibr" target="#b26">[27]</ref> several exploratory views by interpolating camera and viewport parameters smoothly over the scene. His approach was later extended in <ref type="bibr" target="#b9">[10]</ref> to to render animations non-linearly projected.</p><p>Non-linear ray tracing as introduced by Gröller in <ref type="bibr" target="#b13">[14]</ref> is another prominent mean to implement non-standard cameras. Instead of a deformed projection surface, the rays of sight itself are deformed by a 3D deflection or force field in three space. A different way to achieve the same effect is to bend rays of sight by deforming the surrounding space <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b8">9]</ref> using space deformations as introduced by <ref type="bibr">Barr [3]</ref> and Sederberg et al. <ref type="bibr" target="#b25">[26]</ref>. This approach was also recently pursued by Brosz et al. in <ref type="bibr" target="#b4">[5]</ref> where a space deformation is defined via a set of control surfaces. Moreover, the authors show that their model unifies several of the above cameras if parameters are chosen appropriately.</p><p>Although many of the above non-standard models are flexible enough to produce the path visualizations we are aiming at, these models are primarily designed to give artists and designers maximal freedom in the view specification by providing a high dimensional set of parameters. In contrast, the space deformation based approach described in this paper features only a small set of parameters which are tailored to our needs and can largely be derived automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Route visualization</head><p>Interactive route visualization on mobile devices is widespread and popular today and has accordingly been well studied in human computer interaction. Replacing or complementing traditional street maps with images on mobile navigation devices clearly helps people to orient themselves. This was shown in a user study conducted by Chittaro and Burigat <ref type="bibr" target="#b7">[8]</ref> which compared the traditional 2D map depiction to maps augmented by photographs taken from a pedestrian perspective. If photographs are replaced by 3D renderings, results seem to vary depending on the quality of the presentation: In <ref type="bibr" target="#b6">[7]</ref> Burigat and Chittaro present a mobile guide system based on a location aware pre- <ref type="figure">Fig. 1</ref>. Images rendered by our method give the impression of looking along a path all the way to the destination sentation of detailed and textured 3D models and evaluate it in a small user experiment. They report that subjects had no difficulty matching the perspective rendering with real world objects. The TellMaris system introduced in <ref type="bibr" target="#b17">[18]</ref> to guide tourists on leisure boats also features 3D renderings of the environment. A preliminary user study on that system was conducted by Kray et al. which compared several representations of route instructions: textual and spoken instructions, directional arrows, 2D maps, 3D renderings and multimodal combinations thereof. Although the preferred navigation strategy was to match buildings with the 3D depiction, the study revealed higher orientation and route finding times compared to standard 2D maps. However, the authors point out that subjects were well trained with maps. Moreover the quality of their 3D models appears to be somewhat inferior to those of Burigat and Chittaro as textures are only provided for a few objects.</p><p>In contrast to interactive route visualization where 3D representations are commonplace, methods for static visualizations of routes and driving directions traditionally resort to a 2D map like depiction due to occlusion issues: In <ref type="bibr" target="#b0">[1]</ref> Agrawala and Stolte introduce the line drive system which automatically abstracts and generalizes paths to stylist drawings that resemble hand drawn route maps. Their work was extended by <ref type="bibr" target="#b21">[22]</ref> to generate personalized driving instructions by compressing well-known fragments of routes. Lee et al. describe in <ref type="bibr" target="#b18">[19]</ref> the design of the MOVE system which is contextually optimized for in-car navigation systems.</p><p>Besides these methods our approach is also related to the work of Wood et al. <ref type="bibr" target="#b29">[30]</ref> who convert (camera) paths through a virtual scene to panoramic images for cel animations. Starting from an arbitrary placement of the initial frame successive frames are laid out according to the optical flow. Their method, however, fails for forward motions where the optical flow cannot be well approximated by a similarity transform and is thus not applicable in our case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROBLEM STATEMENT</head><p>Given a 3D-model of an environment and a path in the scene we consider the problem of generating a warped image of the route such that, regardless of junctions or curves, the entire way from the starting location to the destination and its immediate surroundings are visible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OVERVIEW</head><p>The above problem statement gives no indication to the methods viable for a satisfactory solution. Among the four principle approaches to non-standard cameras mentioned in sec. 2 -non-linear ray tracing, generalized projection surfaces, multi view interpolations and space deformations -we have chosen the latter for two reasons: Firstly, in contrast to multi-perspective rendering and generalized projection surfaces, space deformations guarantee that no part of the scene can appear more than once in the image, which would be highly irritating in our envisaged application scenario. Secondly, in our case, the space deformation can be specified intuitively and computed interactively.</p><p>To create a warped image, the user fist outlines the path to be visualized by an interactive walk-through of the given 3D scene. During the walk-through the path is recorded as a sequence of 3D positions in conjunction with up-vectors for capturing of orientation respectively (see <ref type="figure" target="#fig_0">Fig. 2</ref> top left). Optionally, special objects, used as visual hints in the final image, are inserted at strategic locations along the path, e.g. at sharp curves or junctions. Once the path has been outlined, the sequence of path-points is used to define constraints for a space deformation that aligns these points along a straight line, which will be the line of sight of the final warped image (see <ref type="figure" target="#fig_0">Fig. 2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>top right).</head><p>A secondary space deformation is applied to the result that enhances visibility of the route's surroundings ( <ref type="figure" target="#fig_0">Fig. 2 bottom left)</ref>. Finally the warped scene is rendered using a standard perspective projection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">SPACE DEFORMATION</head><p>Given the recorded ordered sequence of path-points P = {p 1 , . . . , p n } we seek a space deformation that aligns these points along a straight line of sight of the warped image. The deformation transforms our original geometry G into the warped geometry G which will be used In the top left image a path that was recorded during a virtual walk-through of the environment is depicted. Four additional paths are generated by auxiliary points as described in sec.5. The top right image displays the deformed geometry after application of the thin-plate spline warping. Please note that the path was indeed successfully straightened and the destination is visible. The effect of the secondary transformation is visible in the bottom left image where the same path is visualized after the secondary transform was applied. Note that significant and important detail in the surrounding of the path is now visible also at the end of the path that was occluded before (e.g. the stairs and boxes). Bottom right: occlusion issues may arise if a path does not run clearly around obstacles for rendering. In accordance with computer graphics standards we set the viewing direction along the negative z-axis. Thus, only the zcoordinates Z = {z 1 , . . . , z n } of the transformed points P have to be given to define the space deformation, as the x-and y-coordinates will have to be zero for them to lie on a straight line of sight.</p><p>While it would seem unnatural to change the order of points along the line of sight, there might be ample reason for adjusting the spacing of transformed path-points. For instance long uninterrupted sections of the route could be shortened in order to leave more image space to the important parts of the path. In our application we automatically layout points along the z-axis according to their distance along the path, but the user is allowed to adjust these depth values if desired. Please note that in principle methods similar to those used in <ref type="bibr" target="#b0">[1]</ref> could be used for automatic adaptation of depth values with respect to important parts of the path.</p><p>In order to define the up-and right-direction of our target geometry G and to have more control over the layout of the warped image we introduce four auxiliary samples s i,1 , . . . , s i,4 per path-point p i . These samples are located on a square centered at p i in the plane defined by the point p i and the normal n = p i+1 − p i (cf. <ref type="figure" target="#fig_1">Fig. 3 left)</ref>. The samples' target points s i,1 , . . . , s i,4 are located at corresponding locations on the xy-plane through z i , i.e. the plane parallel to the image plane passing through p i (cf. <ref type="figure" target="#fig_1">Fig. 3 right)</ref>. The side length of the square determines the scale of G with respect to the generated image. In fact, the auxiliary points s i, j can be interpreted as constraints to the first derivative of the space deformation. We need to control the scale of the deformation since, naturally, a path generated by a walk-through of a 3D environment will result in a set of path-points located in free space. Yet our intend is to show the surrounding geometry, e.g. buildings or walls, as well. To this end we set the side length of the squares to be approximately equal to the average distance of the path-points to the surrounding geometry. Since the squares are mapped to an area of space that will be visible in the image, the surrounding environment of the path will appear in the image as well.</p><p>For the computation of a globally smooth space deformation that adheres to the constraints introduced above, we employ thin-plate splines as described in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Warping with Thin-Plate Splines</head><p>In this section we will briefly state and discuss the properties of thinplate splines used for warping of the 3D-scene. The thin-plate spline was introduced by Duchon in <ref type="bibr" target="#b10">[11]</ref>. Thin-plate splines have been widely used for image alignment and shape matching. Two recent examples can be found in <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b5">[6]</ref>.</p><p>Given two sets of corresponding points</p><formula xml:id="formula_0">F = { f 1 , . . . , f n } ⊂ R d and G = {g 1 , . . . , g n } ⊂ R d the mapping Φ : R d → R that minimizes the bending energy B = R d d ∑ i=1 d ∑ j=1 (∂ i j Φ) 2<label>(1)</label></formula><p>under the constraints Φ( f i ) = g i is a thin-plate spline. In a sense, minimizing the sum of squares of all second order partial derivatives results in a globally smooth as-affine-as-possible mapping Φ. In fact, for an affine mapping the second order partial derivatives vanish and thus the resulting bending energy B evaluates to zero. Duchon proved uniqueness of the solution and gave a constructive formulation that separates affine and non-affine components of Φ:</p><formula xml:id="formula_1">Φ = Ax +W t K(x)<label>(2)</label></formula><p>where x ∈ R d+1 is a point in homogenous coordinates, A is an affine mapping,</p><formula xml:id="formula_2">W ∈ R n such that W t F = 0, K(x) ∈ R n and K(x) i = |x − f i |.</formula><p>Given Eq. 2 a thin-plate spline Φ for two point sets F and G can be found by solving two simple linear systems for A and W . As the number of constraints in our scenario and thus the dimensions of the resulting linear systems is relatively small an optimal thin plate spline can be computed interactively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Secondary Deformation</head><p>After the thin-plate spline deformation, the geometry surrounding the path runs mostly parallel to the viewing direction (see <ref type="figure" target="#fig_0">Fig. 2 top right)</ref>. Therefore it will only be visible under a very acute angle so that details and landmarks are hardly recognizable and often occluded. Due to the perspective projection the effect is even stronger for the more distant parts of the geometry G . Yet, as argued in sec. 1, especially the surroundings that provide the landmarks are crucial for successful localization and navigation. Thus it is necessary to improve the visibility and recognizability of the environment with a secondary transform.</p><p>Our solution to this problem is a second space transformation that maps parallels to the viewing direction onto parabolas (cf. <ref type="figure" target="#fig_0">Fig. 4 and  2 bottom left)</ref>, such that further parts of the geometry are bent towards the camera and details of the environment remain distinguishable in the warped image. To this extent, we apply to all points s ∈ R 3 the following transformation t :</p><formula xml:id="formula_3">R 3 → R 3 : t(s) = 1 − β 2 • s x , 1 − β 2 • s y , s z t (3) where β = s z α(z n −z 1 ) + z 1</formula><p>z n −z 1 and α &gt; 0. In all our examples we use α = 1.25. Note that for |α| ≤ 1 there will be a visible singularity at the tip of the paraboloid within the path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">VISUAL HINTS</head><p>As a result of the space deformation described in the last section, the original path is straightened and turns or junctions become less noticeable (see <ref type="figure">Fig. 1</ref>). However, since turns are important for way-finding, we emphasize these features by including additional visual hints in the warped images to facilitate their recognition. In the final renderings these visual hints appear as signs showing arrows that are inserted automatically by our software. The arrows mark the locations of junctions or sharp curves in the path and indicate the direction in which the user has to turn in order to follow the route. Moreover, an additional green arrow is used to highlight the destination (see <ref type="figure" target="#fig_4">Fig. 1 and Fig. 5</ref>).</p><p>The automatic insertion of visual hints analyzes the path and detects sharp corners using a threshold on the angle between consecutive path segments. A billboard equipped with a texture depicting an arrow is inserted into the 3D scene at the respective locations such that the arrow points into the direction of the turn. A similar billboard is inserted at the destination. The billboards are treated just like the remaining geometry during the warping and secondary transform so that they automatically appear at the correct locations in the warped image. To avoid undesired occlusion of important detail by billboards they are rendered transparently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">RESULTS</head><p>We applied the described system to several paths in two virtual environments -a small city model and a large office building. All paths were recorded from manual walk-throughs as described in section 4 and vary in both length and the number of turns. <ref type="figure" target="#fig_4">Figures 5 and 7</ref> show the results of seven interactive rendering sessions which each took us 10 − 15 minutes to generate. Using the interactive feedback we manually adapted the spacing of the auxiliary constraints to increase visibility. Although theoretically different spacings can be specified for individual samples along the path, we did not pursue this possibility. For the shown results the spacing was uniform along the whole path.</p><p>In some cases, the original path was also slightly modified to resolve occlusion issues as shown in the bottom right of figure 2. In this case the occlusion was resolved by moving the path manually away from the box in the foreground. Alternatively, the spacing of the auxiliary constraints at samples near the box could have been changed to achieve a similar effect. However, we found in our experiments that a manual adjustment of the path or auxiliary constraints is not necessary in most cases, even though our method does not explicitly guarantee an occlusion-free depiction of the path. As shown in <ref type="figure" target="#fig_4">Fig. 5</ref> and <ref type="figure" target="#fig_5">Fig. 7</ref> images produced by our method are visually appealing and clearly reflect even subtle features along the path like lanterns and doorways or the down pipe in the third example. Although such features are seldom found in standard maps we believe that they constitute very salient landmarks which provide the observer with valuable additional cues for navigation and to verify that the right track is still followed. Please note also, that the two virtual environments, which were taken from a computer game, show relatively little detail in geometry and texture. More realistic models as e.g. acquired by laser range scanners should exhibit a much higher amount of detail and thus more salient features that can aid orientation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Performance</head><p>The performance of our method depends on two major factors: the number of vertices in the geometry and the number of samples used for the thin-plate-spline. Given the parameters W ∈ R n , samples F ∈ R n and vertices x 1 , . . . , x m we have to calculate Φ = Ax i + W t K(x i ) for every vertex x i , resulting in a complexity of O(mn).</p><p>The calculation of A and W is done on an Intel Core 2 Duo with 2.4 GHz while the actual deformation is computed per vertex on a Nvidia GeForce 8800 GPU. With a scene consisting of ca. 2M vertices and roughly 200 constrained points it took an average of 58.5ms to solve the linear systems for A and W and 0.83s to apply the deformation to all the vertices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Limitations</head><p>Despite its general robustness, our warping method breaks down for very complex or long paths. <ref type="figure" target="#fig_3">Figure 6</ref> shows two examples in which our method fails to give satisfactory results. The first example shows a highly complex path which runs on two floors. As the path nearly intersects itself in two points a space deformation with very high distortion results. Furthermore, for such complex configurations the computed thin plate spline is not guaranteed to be a one-to-one mapping anymore. Even though the warping constraints are met, geometry from distant parts of the scene is warped into the path and renders it unrecognizable.</p><p>Another limitation of our method are long paths as shown in the second example in <ref type="figure" target="#fig_3">figure 6</ref>. While our method successfully discloses such long paths as desired, the available image area is clearly insufficient to depict all features along the path. Even if a manual adjustment of constraints can alleviate this problem by improving the allocation of image space to salient path segments, the limitation of our method to relatively short paths is clearly inherent to our approach. A trivial extension to long paths is, however, to split these into multiple segments for each of which an individual warped image is allotted.</p><p>From the images in figure 5 it becomes clear that the space deformation minimizes path occlusion very effectively. Although this  is certainly desirable, occlusion constitutes an important hint on the shape of the path. Therefore, in the absence of further information it is nearly impossible to identify turns in the warped images. The additional visual hints described in section 6 alleviate this problem by indicating position and direction of turns, but nonetheless most subjects usually need a short introduction when confronted with a warped image for the first time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">EXPERIMENTAL EVALUATION</head><p>In order to evaluate the benefits of our approach we conducted a user study on the set of synthetic examples generated with the 3D computer game level data. With the experiment we sought to evaluate the effectiveness of the warped image visualization with respect to the initial orientation that is required before advancing along the path, the ability to reach the destination without getting lost and the overall time required to reach the destination. In order to provide comparative data all tests were also undertaken using traditional maps. In the following design, procedure and results of the user study will be presented in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Design and Subjects</head><p>For each example a warped image and a traditional map were generated (see <ref type="figure" target="#fig_4">Fig. 5</ref>). The example cases were chosen so that a variety of different complexity levels are covered. Paths differ in the number of junctions, in the number of ignored junctions (junctions, which are not actually pursued), the number of distinctive landmarks and the degree of self-similarity of the surroundings. For example, the city scenario shows a relatively high amount of salient detail, while the office scenario provides few salient landmarks due to its repetitive structure.</p><p>A total of 40 subjects were recruited among students on our campus and among the authors' families and friends with roughly twice as many male as female participants. The average age was 27 and ranged between 19 and 60. The experiences with navigation in virtual environments varied strongly including several beginners. The set of subjects was divided into two equally sized groups G 1 and G 2 . Accordingly, we split our test routes in two sub sets S 1 and S 2 . In the experiment, group G 1 was confronted with a map on the set S 1 and with a an image on S 2 . For G 2 this association was vice versa. This way we obtained data for both image and map on all paths and could thus directly compare results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Procedure</head><p>We used a simple virtual walk-through software to simulate real-world orientation and navigation (see accompanying video). The software was controlled with keyboard and mouse in a manner similar to popular computer games. Before subjects were asked to proceed with the test they were given detailed instructions and had ample time to familiarize themselves with the software and the use of the controls. During two training scenarios, subjects were supervised by an experimenter who gave hints and explanations as necessary. After that subjects were unsupervised and measurements of experimental data commenced.</p><p>Each test took place in the following manner: Subjects were presented the warped image, or traditional map respectively, for ten seconds. Then the virtual walk-through application started with an arbitrary viewing direction that was not necessarily aligned with the direction of the path. Subjects were asked to walk to the depicted destination as quickly as possible and the time required to reach the destination was recorded automatically. By pressing a key they could display  <ref type="table">Table 1</ref>. Average (µ) and standard deviation (σ ) of walking times (s), map/image display times (s), time needed for initial orientation (s) and success rates. The average values in which our method performed better than traditional maps are printed in bold-font the image/map at any time during the walk-through but meanwhile the stopwatch was not held. If the destination was reached or the maximal time of 60s elapsed, the application terminated and the next test with a new scenario started.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Discussion</head><p>The average timings and success rates obtained in our experiments are listed in Tab. 1. A test was recorded as successful if the destination was reached within 60 seconds. The overall average walking time of subjects that were assisted by a traditional map was 33.8s. While the average walking time when subjects were given our images was slightly higher with 36.2s, the success rate increased from 72.0% to 73.2% and the time required for initial orientation decreased from 16s to 12.8s. Although the average walking time is slightly higher for warped images, the one-sided t-test µ walk map &lt; µ walk image yields a confidence of less than 78% which is clearly to small to deduce significant conclusions. Similarly, the one-sided t-test µ rate map &lt; µ rate image on the success rates yields only a confidence of 77%. In contrast the one-sided t-test µ orient image &lt; µ orient map confirms with a confidence of 95% that the time required for initial orientation is significantly lower with our method.</p><p>In summary, we conclude that even with 40 participants the extent of our user study was not sufficient to allow for definite statements about the aptitude of warped images for navigation tasks. However, concerning the initial orientation time our method is superior to traditional maps. The orientation time was measured as the time it took the participant to reach an arbitrary path point whose distance is at least a few meters from the starting location. The reduced orientation time suggests that warped images can indeed be more easily matched to the environment than 2D maps. Furthermore, it can be observed that the ratio between average map and image walking times varies greatly between paths. This suggests that there are a number of properties specific to a path that make images more or less suitable for navigation. We try to identify some of these properties below. However, in face of the potential complex interactions of these properties and the comparatively small number of participants our user study can only be regarded as a pre-study to a larger experiment that verifies the observations we made.</p><p>Despite these concerns, we think that the relatively small difference in average walking times for conventional maps and images is nevertheless remarkable if we consider the fact that we are taught to handle traditional maps at a very young age and practice that skill nearly every day, while subjects were confronted with the deformed image for the first time in their life. The observation that warped images are very intuitive is also in accordance with statements of many subjects that were asked about their experiences after the test.</p><p>Evaluating the statements of individual subjects we tried to deduce <ref type="figure">Fig. 8</ref>. We manually introduced a non-uniform scale adjustment of auxiliary control to improve the depiction of the target area and the perceived distances between waypoints (please compare to test case 3).</p><p>a set of properties of paths and images that influence the aptitude of warped images for navigation and explain the observed differences in the walking times. We identified in total four criteria on the images: Presence of distinctive features If a path exhibits well visible and distinctive features, as e.g. the bottle and the bike in test case 1 or bushes and tree in case 5, the orientation with warped images is greatly improved. These features take the function of landmarks in the sense of <ref type="bibr" target="#b24">[25]</ref> and serve as strong guidance during initial orientation and way-finding. In many cases the subjects explicitly stated the above mentioned features when asked about their way-finding strategy.</p><p>Prominent target In test 6 we observed in many cases that subjects walked past the goal although the path was correctly followed. The actual destination (a desk with a computer terminal) appears relatively small in this test due to the foreshortening of the perspective. In contrast, in traditional map depictions the target often appears highlighted or enlarged corresponding to its significance for navigation. Therefore enlarging the target in the warped images would possibly alleviate this problem. However, if the target area is clearly discernible as e.g. in test case 5 where environmental characteristics like the contrast between the snow covered ground and the interior serve as salient features, an artificial enlargement seems to be unnecessary.</p><p>Unexpected disclosure Although visible and salient features are a prerequisite for the successful navigation with warped images, the unexpected visibility of features in the foreground can also have a negative impact. E.g. in test 4, we observed that subjects were irritated by the fact that the prominent vending machines in the foreground are not immediately visible from the starting location in the simulation (see accompanying video). A similar effect was also observed at the first turn of test case 3. While in both cases the respective feature becomes visible by a slight change of position (a single step) or view, many subjects were handicapped by the controls and perception in our simulation environment and were thus unable to mimic these actions which would have been natural in real life. However, we suspect, that a large discrepancy in the visibility of foreground features will also have a bad influence on the navigation in real-world scenarios.</p><p>Incorrectly perceived distances Compared to an ordinary rendering, the distances along the path appear compressed in warped images in particular for long paths, which is mostly due to the secondary deformation described in section 5.2. The incorrect depiction of distances can be problematic in particular if distances between way points appear drastically distorted. An example is the quick succession of left and right turns in test number 2 which caused in many cases some irritation and subsequently a delay for reorientation. The overall success rate however was unaffected. Similar observations have been made in test case 7 for the first right turn and in case 3 near the end of the path.</p><p>While the presence of distinctive features is usually fixed and cannot be influenced, the three remaining aspects can be considered in the design of the warped image, i.e. in the placement of the transformed path points Z and the auxiliary constraints s i, j . Although this requires user intervention, the designer can specifically address the above problems. <ref type="figure">Figure 8</ref> shows an improved version of test number 3 were auxiliary constraints were modified to emphasize the characteristic context of the destination and to improve the depiction of distances near the end of the path.</p><p>In this work we proposed a novel short path visualization technique which is intuitive and facilitates navigation. To this end we introduced a custom tailored camera model that generates images which give the impression of looking along the path all the way to its destination.</p><p>Also a user study was conducted to evaluate the aptitude of the novel depiction for navigation. Although the extent of the study was not sufficient to derive definite statements, the preliminary results are promising. In particular when considering that participants are usually trained from preschool on to read and use traditional maps for navigation, the results of our experiment are very encouraging. Interestingly, participants that needed more than 50 seconds on average to complete the test using maps show a clear preference for the proposed visualization (on average those people are faster by a margin of 12s). This hints that in particular for people which have problems with traditional maps, our images are more intuitive and easier to understand. Moreover, we found that the initial orientation time was significantly lower with warped images. We therefore believe that our method constitutes a valuable alternative for path visualization.</p><p>We also deduced a set of image properties that seem to influence the quality of the warped images for way-finding tasks. While three of these image properties can be influenced by manual intervention and may thus serve as design guidelines for warped images, the presence of salient features along the path is indispensable for the success of our method. In summary, our method works best if the following criteria on the path are met:</p><p>Salient features The path must exhibit sufficient salient features that can serve as landmarks in navigation. While natural environments usually provide more than enough distinctive features, virtual environments and building interiors like multi-story car parks which are characterized by repetitive and self similar structure might not provide enough salient information.</p><p>Limited complexity As detailed in section 7 our warping method is currently limited to intersection free paths that do not pass near themselves. Paths inside a multi-story building running over multiple floors can therefore be problematic while our method is well suited for outside paths or paths on a single floor.</p><p>Limited length As a natural consequence of the limited image area the depiction of features along a very long path becomes compressed and less recognizable. Therefore, warped images are primarily intended for the depiction of relatively short paths.</p><p>Although these criteria limit the applications of our method to some extent, a large class of typical paths encountered in cities, hotels, ski resorts or fun parks meets the above requirements. For this important class of paths our method can provide an intuitive alternative for visualization.</p><p>Even though we used a manually designed virtual environment in our results and in the user study, our method is in principle not limited to such models. The space deformation concept of the warping algorithm is general enough to handle both polygonal models and point clouds. In face of the rapidly ongoing effort to build complete 3D city models either manually in collaborative projects <ref type="bibr" target="#b12">[13]</ref> or automatically by large scale terrestrial range sensing <ref type="bibr" target="#b11">[12]</ref> we therefore see many potential applications for our method in web-based services such as electronic map systems.</p><p>A promising direction of future work is an improved depiction of turns along the path. As explained in section 7.2, removing occlusion along the path also takes away important visual clues which make additional artificial hints at turns necessary. In future work we would like to explore more intuitive visualizations of turns in the warped images. Alternatively, it might also be possible to extent the warping algorithm in order to find a balance between the disclosure of salient path features and partial occlusion at turns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. In the top left image a path that was recorded during a virtual walk-through of the environment is depicted. Four additional paths are generated by auxiliary points as described in sec.5. The top right image displays the deformed geometry after application of the thin-plate spline warping. Please note that the path was indeed successfully straightened and the destination is visible. The effect of the secondary transformation is visible in the bottom left image where the same path is visualized after the secondary transform was applied. Note that significant and important detail in the surrounding of the path is now visible also at the end of the path that was occluded before (e.g. the stairs and boxes). Bottom right: occlusion issues may arise if a path does not run clearly around obstacles</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>On the left hand side the path in the scene is illustrated and the sample points on the path visualized as blue spheres. At each sample location a plane is defined by the path's tangent vector. The corners of a square centered about the sample point define auxiliary positions that are used to constrain the scale of space deformation. On the right hand side the path after the deformation is depicted. All sample positions lie on a straight line of sight.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>The image shows the effect of the applied secondary transformation as described in sec.5.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 .</head><label>6</label><figDesc>Our method fails on highly complex (left) and long paths (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Test cases 1 − 4 used in the user study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Test cases 5 − 7 used in the user study.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>All sceneries in this paper were taken from the popular Counter-Strike computer game. The authors wish to express their gratitude towards VALVe Corporation, Bellevue, WA for their permission.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rendering effective route maps: improving usability through generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stolte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="241" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Artistic multiprojection rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EWRT 2000</title>
		<meeting>the EWRT 2000</meeting>
		<imprint>
			<biblScope unit="page" from="125" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Global and local deformations of solid primitives. SIG-GRAPH</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Barr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="21" to="30" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generalized thin-plate spline warps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perriollat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chambon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Single camera flexible projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">F</forename><surname>Samavati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Sousa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NPAR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Global non-rigid alignment of 3-D scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Location-aware visualization of VRML models in GPS-based mobile guides</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Burigat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chittaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web3D</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Augmenting audio messages with visual directions in mobile guides: an evaluation of three approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chittaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Burigat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mobile HCI</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="107" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Sketching 3d scene projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<idno>2005-13</idno>
		<imprint/>
		<respStmt>
			<orgName>Washington University in St. Louis</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ryan: rendering your animation nonlinearly projected</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NPAR</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="129" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spline minimizing rotation-invariant semi-norms in sobolev spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Constructive Theory of Functions of Several Variables</title>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="volume">571</biblScope>
			<biblScope unit="page" from="85" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An automated method for large-scale, groundbased city model acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fruh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zakhor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="24" />
			<date type="published" when="2004-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Sketchup</surname></persName>
		</author>
		<ptr target="http://sketchup.google.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Nonlinear ray tracing: visualizing strange worlds. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="263" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Egocentric maps on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Duesterhoeft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Non-linear perspective projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Inakage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IFIP</title>
		<meeting>the IFIP</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="203" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Presenting route instructions on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Elting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Laakso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Coors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 International Conference on Intelligent User Interfaces</title>
		<meeting>the 2003 International Conference on Intelligent User Interfaces</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tourist information and navigation support by using 3d maps displayed on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Laakso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gjesdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sulebak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mobile HCI 2003 Workshop on Mobile Tourism Support</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Studying the effectiveness of MOVE: a contextually optimized in-vehicle navigation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="571" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A framework for non-realistic projections. Massachusetts Institute of Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ray tracing with extended cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Löffelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Visualization and Computer Animation</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="211" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Personalizing routes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Landay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UIST</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="187" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The development of map-reading skills</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Presson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Child Development</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="196" to="199" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multiple-center-of-projection images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rademacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A uniform handling of different landmark types in route directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-F</forename><surname>Richter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COSIT</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">4736</biblScope>
			<biblScope unit="page" from="373" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Free-form deformation of solid geometric models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Sederberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Parry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="151" to="160" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Fresh Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GI2002</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Interactive manipulation of projections with a curved perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sudarsanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-09" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="105" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Mind the gap: Mobile applications and wayfinding. In Workshop for User Experience Design for Pervasive Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Willis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<pubPlace>Munich, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multiperspective panoramas for cel animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Thayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Salesin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 97</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Nonlinear perspective projections and magic lenses: 3d view deformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beheshti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="76" to="84" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">General linear cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV (2)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="14" to="27" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
