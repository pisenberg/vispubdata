<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Vectorized Radviz and Its Application to Multiple Cluster Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sharko</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Georges</forename><surname>Grinstein</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">A</forename><surname>Marx</surname></persName>
						</author>
						<title level="a" type="main">Vectorized Radviz and Its Application to Multiple Cluster Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visualization</term>
					<term>Radviz</term>
					<term>Vectorized Radviz</term>
					<term>Clustering</term>
					<term>Multiple Clustering</term>
					<term>Cluster Ensembles</term>
					<term>Flattening Datasets</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Radviz is a radial visualization with dimensions assigned to points called dimensional anchors (DAs) placed on the circumference of a circle. Records are assigned locations within the circle as a function of its relative attraction to each of the DAs. The DAs can be moved either interactively or algorithmically to reveal different meaningful patterns in the dataset. In this paper we describe Vectorized Radviz (VRV) which extends the number of dimensions through data flattening. We show how VRV increases the power of Radviz through these extra dimensions by enhancing the flexibility in the layout of the DAs. We apply VRV to the problem of analyzing the results of multiple clusterings of the same data set, called multiple cluster sets or cluster ensembles. We show how features of VRV help discern patterns across the multiple cluster sets. We use the Iris data set to explain VRV and a newt gene microarray data set used in studying limb regeneration to show its utility. We then discuss further applications of VRV.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>Clustering algorithms are heuristic and not necessarily optimal. Furthermore, there is no universal clustering algorithm that will work well with any data set <ref type="bibr" target="#b0">[1]</ref>. Therefore it is common practice to run multiple clustering algorithms on the same dataset. The results of such multiple clusterings are called multiple cluster sets or cluster ensembles.</p><p>In many cases there are multiple viable cluster datasets that cannot be eliminated based on any quantitative measure or domain knowledge. The problem then becomes one of resolving the discrepancies in the clusters or for example identifying which clusters subsets are stable, where stable clusters are defined as those that consistently contain the same records across many clusterings.</p><p>Various methods have been developed to compare multiple sets of clustering results. Two of the most common techniques are the Rand index <ref type="bibr" target="#b1">[2]</ref> and the Jaccard coefficient <ref type="bibr" target="#b2">[3]</ref>. They reflect the relative proportion of records that are placed consistently in two separate sets of clustering algorithms. Another common approach is to use such data to generate a consensus clustering partition. Examples of this are a majority voting scheme <ref type="bibr" target="#b3">[4]</ref> and hierarchical agglomerative clustering algorithms <ref type="bibr" target="#b4">[5]</ref>. The rationale for these approaches is that "the judgment of a group is superior to those of individuals" <ref type="bibr" target="#b4">[5]</ref>.</p><p>Silhouette plots have also been used <ref type="bibr" target="#b5">[6]</ref>. But these approaches do not make comparisons at a record level, so it is not possible to identify which records are most anomalous and which sets of clusters are most affected.</p><p>Heat maps have been used to display the extent to which each record falls into the same cluster for multiple cluster sets. Again these do not simultaneously display each cluster and its relationships to the others <ref type="bibr" target="#b6">[7]</ref> <ref type="bibr" target="#b7">[8]</ref>.</p><p>Our approach is to use Radviz <ref type="bibr" target="#b8">[9]</ref>[10], a radial visualization, to both visually show cluster relationships and the records within each cluster.</p><p>A simple example of a Radviz visualization is illustrated in <ref type="figure" target="#fig_1">Figure 1</ref>. The dimensions are assigned points (called dimensional anchors or DAs) on the circumference of the circle and each point within the circle represents a record, or set of records, in the dataset. The location of each point within the circle is computed as a function of its relative attraction to the DAs.</p><p>This attraction to each DA is proportional to the magnitude of the coordinate for that dimension. The formulas for calculating the xand y-coordinates for each record in an RV visualization are: where x i and y i are the resulting transformed coordinates for record i, θ j is the angular position on the circle corresponding to dimension j, a i,j is the value for dimension j for record i, d is the number of dimensions and n the number of records. The computation is linear in the number of points and dimensions.</p><p>There are several interpretations for the location of a record in Radviz. One is that it is the first harmonic of the Discrete Fourier Transform <ref type="bibr" target="#b10">[11]</ref>. Another is more physically intuitive and easier to interpret. It is the equilibrium point resulting from springs attached from the record to each DA with the strength of the spring proportional to the magnitude of the coordinate value of that dimension. The higher the value for a particular dimension, the closer the projected point will be to the corresponding anchor. As examples, Record B has coordinates (1, 0, 0, 0). It is located on the circumference of the circle at dimension X1 and there is no ambiguity concerning its coordinate values.</p><p>Record C has coordinates (1, 1, 0, 0). Since this point is near the circumference of the circle, its values are also fairly self-evident. It has high values for X1 and X2 and low values for X3 and X4. Record A is at the center of the circle and has coordinates (1, 1, 1, 1). Points with coordinates (½, ½, ½, ½), (1, 0, 1, 0) or (0, 1, 0, 1) all project to the same position. Radviz is a lossy projection but tools are provided to help resolve that weakness.</p><p>Radviz is included in research visualization systems such as Orange <ref type="bibr" target="#b11">[12]</ref>, UVP <ref type="bibr" target="#b12">[13]</ref>, and Rapid Minor <ref type="bibr" target="#b13">[14]</ref>. Similar radial visualizations include Star Coordinates <ref type="bibr" target="#b14">[15]</ref>, SphereViz <ref type="bibr" target="#b15">[16]</ref>, SpringView <ref type="bibr" target="#b16">[17]</ref>, and FreeViz <ref type="bibr" target="#b17">[18]</ref>. There are two significant features of Radviz that make it such an important visualization to have in one's toolkit. The first is that an arbitrary number of DAs may be placed on the circumference of the circle making Radviz useful in dealing with high dimensional data sets. If the number of dimensions is very high, then the DAs may not be individually distinguished although the records may. The second is that DAs may be flexibly placed on the circumference. Moving a DA can change the location of records within the circle (some records will not move as they may be independent of that dimension). This can be done either manually or computationally. If a significant number of records have high values for two dimensions, placing their corresponding DAs near each other on the circumference will tend to draw those records closer to the DAs than if the two anchors were far apart on the circumference. If these DAs were on opposite sides of the circle they would pull records toward the center. The Class Discrimination Layout algorithm computes the location of DAs as a function of how effectively each dimension discriminates each class of records <ref type="bibr" target="#b18">[19]</ref>. The resulting visualizations result in points closer to the DAs and improved separation. It is both of these features that make Radviz particularly useful in analyzing and visualizing biological microarray <ref type="bibr" target="#b18">[19]</ref>[20] <ref type="bibr" target="#b20">[21]</ref>] or text mining <ref type="bibr" target="#b21">[22]</ref> data for example.</p><p>We describe an extension to Radviz called Vectorized Radviz (VRV) for visualizing multiple clustered datasets, or cluster ensembles, which takes advantage of these two important features. Vectorized Radviz partitions each dimension into many more dimensions. This provides the capability to computationally position these extra dimensions independently of each other. By breaking up a single dimension into multiple dimensions representing subset of its values, record patterns under that dimension may be more clearly identified.</p><p>Dimension reordering is an important component of our use of VRV. VRV is an example of a visual technique that depends greatly on the ordering of the data dimensions. The impact of dimension reordering has been studied for a number of visualizations including parallel coordinates, scatterplot matrices, star glyphs, and dimensional stacking <ref type="bibr" target="#b22">[23]</ref>. The basic approach is to use a measure of similarity such as Euclidean distance. Since finding an optimal reordering is an NP-complete problem, a heuristic algorithm is the goal <ref type="bibr" target="#b23">[24]</ref>. We describe how VRV reorders the dimensions starting with a Class Discrimination Layout algorithm <ref type="bibr" target="#b18">[19]</ref> followed by a greedy algorithm to further refine the placement of the dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODS</head><p>We start with a dataset that has been clustered several times using the same or different clustering algorithms. We then extend the data set by adding a new column for each additional clustering. The values for each dimension are the cluster number each record is assigned under that clustering. Generating a Vectorized Radviz from this extended cluster result dataset consists of three steps. The first is to further expand the number of dimensions by partitioning each into several new ones. In the second step we rearrange the dimensions on the circumference so as to group together those dimensions with most similar characteristics. In the third step we relocate these groups so that the most similar groups of dimensions are near each other. This results in a Radviz visualization with points away from the center and with more separation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dimension Expansion</head><p>Increasing the dimensionality of a data set in order to solve a complex problem is a technique used for example with support vector machines for clustering and separation <ref type="bibr" target="#b24">[25]</ref>. For VRV each dimension of the source dataset is extended to a set of multiple dimensions in VRV. If the original dimension is categorical, each of the new generated dimensions represents one or more values of that dimension. The coordinate values in each of these new dimensions are either of two values, yes or no, or more typically a zero or a one to facilitate computation. For example a single dimension such as weapon where the coordinate values are rifle, gun, sword, knife, screwdriver, and pen could be extended to six new dimensions Rifle, Gun, Sword, Knife, Screwdriver, and Pen each with coordinate values 0 or 1. For example, take a record that has the value Rifle as its value for the weapon dimension. In the flattened dataset, the value for the Rifle dimension will be 1 whereas the values for the other flattened dimensions (Gun, Sword, Knife, Screwdriver, and Pen) will all be zero. Thus each categorical dimension has been transformed from a single value to a vector where one element has the value one and the remaining elements have the value zero. This conversion of categorical data to binary has been called flattening <ref type="bibr" target="#b25">[26]</ref>. When comparing cluster datasets, each cluster algorithm results in a dimension where the values of each of those dimensions represent the clusters each record is assigned to. For example, if a hierarchical clustering technique has assigned a record to the third cluster, the value of the hierarchical cluster dimension for that record is 3. Dimension expansion in this case results in flattened dimensions representing every cluster in each of the cluster sets. So the Radviz display is no longer treating each cluster set as an entity in the visualization but every single cluster in every cluster set as a separate entity. This provides much greater flexibility in how the cluster sets are represented in the visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Grouping Dimensions into Classification Sectors</head><p>The location of a record depends on the relative position of the DAs on the circumference of the circle. If the dimensions having high values for a record are close together on the circumference, the record will be drawn towards the corresponding DAs. On the other hand if the DAs are not close to each other, the points will be pulled toward the interior of the circle. The objective then is to place DAs as close to each other whose corresponding dimensions have high values for a significant subset of the records in the dataset. One method for effectively placing dimensions on the circumference of the Radviz display is the Class Discrimination Layout algorithm <ref type="bibr" target="#b18">[19]</ref>. The t-Statistic is used to group the dimensions that similarly discriminate the records. The t-Statistic is a measure of the difference between the means of two separate populations. The class discrimination layout algorithm requires that the records be classified in some manner. Then for each dimension, the t-Statistic for each classification group is calculated with respect to all of the other records. This measures the extent to which the average value of the dimension for each class is different from the average value for all of the remaining classes (this is a different metric as those in <ref type="bibr" target="#b23">[24]</ref> and <ref type="bibr" target="#b22">[23]</ref>). The dimension is assigned to the classification group with the highest t-Statistic. Those dimensions assigned to the same classification group then have their DAs placed close together on the circumference of the circle into what we define a classification sector. We illustrate the process using the data in <ref type="table" target="#tab_1">Table 1</ref>. It is clear that for dimension X1 the t-Statistic calculated for class A (average = 11.3) versus the remaining records (average = 3) is significantly higher than the corresponding t-Statistic for class B (average = 3) versus the remaining records (average = 7.2) or class C (average = 3) versus the remaining records (average = 7.2). By similar calculations dimension X2 will be assigned to class B and dimension X3 to class A. Therefore, the Radviz display will have dimensions X1 and X3 close to each other as they are both assigned to class A.</p><p>The set of dimensions which all have the highest t-Statistic associated with the same class is called a classification sector. In the example above dimensions X1 and X2 comprise a classification sector associated with class A.</p><p>This technique is especially useful when applied to the comparison of flattened multiple cluster datasets where each dimension represents a cluster in a particular cluster dataset. Typically several cluster algorithms run on the same dataset will produce some clusters similar across all of the algorithms. By flattening the cluster datasets, individual clusters in one algorithm can be placed near similar clusters from other algorithms. The clusters from separate algorithms close to each other on the circumference of the circle then represent stable clusters, i.e. the records in these clusters are the same or at least roughly the same.</p><p>Since we need a classifier to apply the class discrimination layout algorithm, we arbitrarily select one set of clusters as the classifier. The number of groups, or classification sectors, will then equal the number of clusters in the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Repositioning Classification Sectors</head><p>Once the DAs have been grouped together on the circumference of the circle into classification sectors, we reorder these sectors to have those most similar close to each other. This is possible since each classification sector is associated with a specific class of records. We can then define a classification sector similarity measure by comparing the averages of each of the original non-vectorized dimensions for each record class.</p><p>To illustrate this concept, consider VRV applied to the multiple cluster dataset. Each VRV dimension represents an individual cluster in some cluster set. Each classification sector corresponds to a single cluster in the cluster set used as the classifier. So each classification sector represents the clusters that are most like the corresponding cluster in the cluster set used as the classifier. For purposes of analyzing multiple cluster sets, it is desirable to have classification sectors most similar to each other near each other on the circumference of the circle. This is because clusters that are the most similar would tend to have the greatest likelihood of having records not falling into the same sets of clusters but would be scattered among the most similar clusters. The closer these dimensions are to each other the more likely the points will be located near the circumference of the circle and therefore more amenable to visual interpretation.</p><p>A greedy algorithm based on the differences between the average values across all of the dimensions for each classification sector is used to reposition the classification sectors in the VRV display. The average values of the dimensions in each classification sector over each class of records are calculated. The Euclidean distance between these average values is calculated for each of the original dimensions for the two classes of records associated with these two classification sectors. The pair with the smallest distance is selected first. These two sectors are placed next to each other. Then the pair of clusters with the next smallest difference is identified. If it is possible to place these two clusters next to each other in light of the pairs that have already been picked, then that pair is selected and the DAs are placed next to each other. If not, the pair with the next smallest distance is selected. This process continues until all of the clusters have been selected. This algorithm is O(nd), where n is the number of records and d is the number of dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ILLUSTRATIVE APPLICATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Description of Dataset</head><p>We select the Iris dataset <ref type="bibr" target="#b26">[27]</ref> for its simplicity to illustrate VRV applied to a multi-cluster dataset. Three cluster sets of ten clusters each (again for simplicity) were generated. Two K-Means clusterings, KM1 and KM2, were generated with respectively 1000 and 100,000 iterations. The third cluster set was generated using hierarchical clustering. The algorithms were implemented using the R-Project <ref type="bibr" target="#b27">[28]</ref>. The resulting dataset then consists of three additional columns, one for each of the clustering algorithms used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Description of Terminology Used in Visualizations</head><p>In the visualizations that follow the individual clusters are represented by the following structure:</p><p>algorithm -cluster number</p><p>where "algorithm" is one of the following: KM1 -K-means clustering with 1000 iterations KM2 -K-means clustering with 100,000 iterations HC -hierarchical clustering Thus KM2-4 represents the fourth cluster from the KM2 (100,000 iterations) algorithm while HC-7 represents the seventh cluster from the hierarchical clustering algorithm. This visualization is not very informative. In particular, no statement can be made about the stability of each of the clusters i.e. what proportion of the records in each cluster is consistently clustered by the other algorithms. To do this we would need to be able to identify the cluster associated with each point, i.e. which dimension each point is associated with. . We applied jittering to spread out points that are plotted at the same location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Visualization Characteristics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Radviz Before Vectorization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Radviz After Vectorization</head><p>In order to provide more insight into the behaviour of individual clusters, the cluster sets must be analyzed on a cluster-by-cluster basis. This is achieved by flattening the datasets whereby each cluster in each cluster set becomes a dimension in Vectorized Radviz, labelled in <ref type="figure">Figure 3</ref> with the number after the cluster designation (KM1-1, …, KM-10, KM2-1, …KM2-10, HC-1, …,HC-10). (It should be noted that jittering was applied to this visualization in order to reflect the number of records associated with each point. Without jittering, records with the same cluster patterns would fall exactly on top of each other.) This visualization however is still of limited value as the points lie close to the center of the circle. It is a characteristic of Radviz that the most significant dimensions for near-center points cannot be identified without additional tools such as pop-ups or lines drawn to each dimension. Thus although each point represents a record, or multiple records, appearing in the same cluster in each of the three cluster sets, there is no clear indication of the relation among the individual clusters. We want to be able to discern visually which clusters tend to have common points in them. The order of the dimensions is still arbitrary being simply the cluster number for each algorithm. This begs for some more intelligent ordering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Class Discrimination Layout</head><p>To enhance the visualization in <ref type="figure">Figure 3</ref>, we apply the Class Discrimination Layout algorithm. The resulting visualization is shown in <ref type="figure">Figure 4</ref>. The classifying dimension was KM1. Each sector of KM1 is represented as sectors in order starting at 3:00 o'clock as on the face of a clock. Each sector is numbered according to the corresponding KM1 cluster. As discussed in section 2.2, the purpose of the Class Discrimination Layout algorithm is to group dimensions together that most effectively discriminate the same class of records based on the calculated t-Statistic. This will draw highly-related records outwards from the center. The benefit of this is that the resulting visualization will more effectively separate the records while at the same time grouping those records with similar characteristics closer to each other.</p><p>The grouping of the dimensions has special meaning in the context of comparing cluster sets. Since each dimension reflects a cluster in a particular cluster set, the grouping of dimensions (which in VRV represent clusters) in a classification sector indicates those clusters are similar i.e. there are a significant number of records that belong to each of those clusters. An example of this is sector 10, which is between 3:00 and 4:00 o'clock. The point in that sector, which lies virtually on the circumference of the circle, represents those points that are in the tenth cluster of KM1, the seventh cluster of KM2, and the fourth cluster of HC. <ref type="figure">Fig. 3</ref>. Vectorized Radviz visualization of three cluster sets based on the iris dataset. Each original dimension corresponding to the three clustering algorithms is flattened into ten dimensions corresponding to the ten clusters in each cluster set. The color indicates which cluster in the KM1 cluster set the records represented by each point belong to. The order of the dimensions is arbitrary and simply the cluster number for each algorithm. This does not improve on <ref type="figure">Figure 3</ref> but begs for some intelligent ordering.</p><p>Also, if two clusters from one cluster set are grouped with one cluster of another algorithm, it suggests that the first algorithm subdivided the cluster from the second algorithm into two separate clusters. An example of this occurrence is classification sector six. There are four clusters of KM2 (9, 1, 8, and 3) and three clusters of HC <ref type="bibr">(10, 7, and 8)</ref> in the same sector as the sixth sector of KM1.</p><p>The distance from a point to the circumference also has significance. The points on, or near, the circumference represent those records that are the most stable i.e. these records are in the same clusters for each of the cluster sets. This results from the Class Discrimination Layout algorithm which groups the dimensions that most discriminate the same classes, which in this analysis are clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Using size of points to reflect counts</head><p>We further enhance the basic VRV visualization by reflecting the number of records at each point. In <ref type="figure" target="#fig_4">figure 5</ref>, the size of each point is proportional to the number of coincident records at each point. This is an important feature because there are only a finite number of possible locations where points may be drawn in a VRV display. This is because the value of each dimension is either zero or one. As a result, a point in the visualization could represent a large number of records. This feature removes the necessity of jittering to show the number of records at a point. Although there is still a chance of occlusion, the discrete nature of the dimensions tends to result in separated points. Sizing the points in <ref type="figure" target="#fig_4">Figure 5</ref> reveals that the points closest to the interior of the circle are smaller than the points on or near the circumference. Thus, the records that are in the least stable clusters represent a small portion of the total number of records in the dataset.</p><p>The largest circles are on, or very close to, the circumference. These points represent the records that are in stable clusters. This suggests that the three cluster sets are consistent with each other. <ref type="figure">Fig. 4</ref>. The class discrimination layout algorithm applied to the iris dataset VRV visualization with 3 cluster sets. Similar dimensions are grouped together using the KM1 cluster set as the basis with each sector is labeled with the KM1 cluster number. Records are more spread out and farther away from the center of the circle as compared to <ref type="figure">Figure 3</ref> providing more coordinate information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3.5</head><p>Drawing lines from each point to the dimensions A common practice with Radviz implementations is to draw lines from each record to the DAs in order to display the values of each dimension associated with that point. The thickness of the lines can be used to indicate the corresponding values. This tends to be a cluttered representation because each point in the display has a value associated with each dimension. Only the zero values would not have lines drawn to them. This is not a problem with VRV because the values for each dimension are either one or, in most cases, zero. Thus lines have to be drawn to only a subset of the dimensions, namely those with the value of one. In the case of multiple cluster analysis, the number of lines drawn from each point will equal the number of cluster sets.   <ref type="figure">6</ref> is the iris VRV visualization with lines added. Lines drawn from each point within the circle to each dimension with a value of one indicate which clusters the records associated with that point belong to. <ref type="figure">Fig. 6</ref>. Iris VRV visualization of the three cluster implementations with lines connecting points to their non-zero coordinates on the circumference. The records at points A, B, and C all belong to the fifth cluster of KM2 but to different clusters for KM1 and HC. This implies that the records in the fifth cluster of KM2 are unstable. Similarly records at point D belong to sectors 8 and 5.</p><p>These lines indicate important features about the dimensions they are connected to. If only one line is connected to a dimension, the cluster represented by that dimension corresponds to only one set of clusters generated by the other algorithms and is therefore very stable. If there are many lines connected to a dimension, this suggests an inconsistency with the other clustering algorithms. An example of this is the fifth cluster of KM2 which is enclosed in an orange box in <ref type="figure">Figure 6</ref>. There are three lines coming from points A, B, and C. But the KM1 and HC clusters associated with these three points are different. This implies the records in the fifth cluster of KM2 are not stable i.e. these records are not in the same clusters for the other two cluster sets, KM1 and HC.</p><p>The case where many lines point to one dimension and still have stable clusters is the case of KM1-6 described in section 3.3.3 <ref type="figure">(Figure 4)</ref>. Here there is one large cluster in one cluster set corresponding closely to multiple clusters in the other cluster sets. There are three clusters of KM2 (9, 1, 8, and 3) and three clusters of HC <ref type="bibr">(10, 7, and 8)</ref> in the same sector as the sixth sector of KM1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3.6</head><p>Moving the classification sectors</p><p>Up to this point, the classification cluster set, KM1, has been placed on the circumference in an arbitrary order, namely in increasing order in a counter clockwise direction. As explained in section 2.3, placing the clusters that are most like each other near each other on the circumference of the circle will tend to cluster points closer to the circumference. This allows for clearer interpretation of the visualization. <ref type="figure">Figure 7</ref> is the result of applying the algorithm in section 2.3 to reorient the classification sectors so that the most similar classification sectors are close to each other. Comparing the layout of the records in this figure to the layout of the records in <ref type="figure">Figure 6</ref>, the records are spread out further from the center of the circle. In particular, the location of records A and D in <ref type="figure">Figure 7</ref> lie closer to the circumference that those in <ref type="figure">Figure 6</ref> where they are much closer to the center.</p><p>The fact that the records in <ref type="figure">Figure 7</ref> are close to the circumference suggests that the three sets of clusters are relatively stable (i.e. records are grouped together consistently for each of the cluster sets). If a significant number of records were closer to the center further cluster analysis would be required. <ref type="figure">Fig. 7</ref>. Iris VRV visualization of the three cluster sets with classification sectors moved so that similar clusters are closer to each other. This results in points closer to the circumference increasing coordinate information and decreasing some of the ambiguities. For example, points A and D are closer to the circumference than in <ref type="figure">Figure 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPLICATION TO NEWT MICROARRAY DATA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset Used</head><p>We then applied VRV to a gene expression data to study the regeneration of amputated limbs in the newt (N. viridescens) <ref type="bibr" target="#b28">[29]</ref>. The changes in expression levels represent the response of individual genes in tissue at the point of amputation of the forelimb in a newt. The expression levels were determined experimentally by RNA isolation from tissue at the amputation site and hybridization on a custom designed Agilent microarray <ref type="bibr" target="#b7">[8]</ref>. The dataset consisted of about 500 genes, selected for their likely involvement in tissue regeneration, with expression levels measured at one day, three days, five days, twelve days, and twenty one days post-amputation of the limb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cluster sets</head><p>Four clustering algorithms were applied to the microarray expression dataset: (1) K-means, (2) expectation maximization, (3) extended Kmeans, and (4) density based clustering built on K-means. Eleven clusters were generated using each of the algorithms.</p><p>In the visualizations that follow, each cluster is denoted by a three digit number. The first digit corresponds to which algorithm that was used to generate the cluster as listed above. The two remaining digits represent the number of the cluster. For example, 203 corresponds to the third cluster of the expectation maximization cluster set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>The VRV analysis described in section 3 above was applied to the newt microarray data. First, the cluster data was flattened. Since there were eleven clusters generated by each of the four algorithms, the four algorithms were transformed into 44 dimensions. The class discrimination layout algorithm was applied using the K-means cluster as the classification dimension. This process resulted in the association of clusters in the other algorithms to each of the K-means clusters as illustrated in <ref type="figure" target="#fig_6">Figure 8</ref>. The points on the circumference of the circle represent stable records. But the records near the center are more difficult to interpret. It is not clear from the visualization which combination of clusters each record represents. To alleviate this problem, the classification sectors were relocated using the algorithm described in section 2.3 above. As shown in <ref type="figure">Figure 9</ref>, this results in the points moved closer to the circumference of the circle. Points near the circumference of the circle represent records assigned to clusters for each algorithm that were similar to sets of clusters for other records. Therefore the points close to each other near the circumference represent records clustered in a similar manner. In fact, if the number of clusters were reduced, those points would likely fall into the same sets of clusters.</p><p>In addition, the points in <ref type="figure">Figure 9</ref> are sized in proportion to the number of records represented by each point. The fact that the points near the circumference are relatively large and the points in the interior are small indicates that the set of clusters are reasonably consistent. If there were many records in the center of the circle, this would suggest that the algorithms are producing inconsistent outputs. This situation would warrant further investigation, possibly resulting in a different number of clusters produced by each algorithm.</p><p>A detailed analysis of the points in the interior of the circle revealed the significance of such a location. The points in the interior of the circle represent records that do not fit very cleanly into the clusters. For example, consider the point labelled "A" in <ref type="figure">Figure  9</ref>. The lines emanating from that point indicate that it belongs to cluster 9 in the K-means cluster set (109). Two of the other clusters it belongs to, cluster 9 of the density based cluster set (409) and cluster 2 of expectation maximization cluster set (202), are grouped with cluster 9 of the K-means cluster set (109). The cluster that is significantly displaced from these three clusters is the cluster identified as cluster 7 by the extended K-means algorithm (307). This cluster is grouped with cluster 10 of the K-means cluster set (110).</p><p>The underlying cause for this discrepancy was revealed by comparing the microarray expression patterns of clusters 9 and 10 in the K-means cluster set. <ref type="figure" target="#fig_1">Figure 10</ref> shows the expression levels for cluster 9. The record in question was displaced below the other records in that cluster and was not consistent with the other members of the cluster. When we compared this record with the records in cluster 10, <ref type="figure" target="#fig_1">Figure 11</ref>, we saw that the anomalous record, the heavy red line, had the same basic characteristics as the genes in cluster 10. This analysis indicated that this record warranted further investigation, as would the other points near the center of the circle. <ref type="figure">Fig. 9</ref>. VRV visualization of the newt microarray data with classification sectors reordered. Point A for example now stands out as an anomalous point since it falls closer to the circle center highlighting its being pulled by (belonging to) some other cluster. The red lines indicate the cluster sets it belongs to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>VRV has been shown to be an effective tool for analysing multiple clustered datasets. It provides the ability to simultaneously visualize several important characteristics of multiple clustered datasets. VRV is effective because vectorizing, or flattening, datasets harnesses two major advantageous features of Radviz. Radviz is very effective at displaying highly dimensional datasets. So increasing the number of dimensions as VRV does can be easily accommodated within Radviz. And Radviz has the flexibility of placing dimensions anywhere on the circumference of the circle. This allows for the manipulation of individual values of a dimension. Thus VRV allows the analyst to manipulate the placements of dimension in terms of its individual values in a highly flexible manner. <ref type="figure" target="#fig_1">Fig. 11</ref>. Newt microarray expression levels over time with K-means cluster 10 highlighted in black. The red line corresponds to the record in <ref type="figure">Figure 9</ref> that is close to the circle center. <ref type="figure" target="#fig_1">Figure 10</ref> also highlighted its not fitting well into the cluster 9, the cluster it is assigned to. Here we see that this record has characteristics (for days 1-5 and a leveling off after day 12) similar to those in cluster 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">How VRV Can Be Used</head><p>VRV can be used by domain experts to evaluate the consistency of the cluster ensemble by viewing the extent to which the records are displayed near the circumference of the visualization. VRV has proven effective in our applications in displaying the following information on multiple clustered datasets: 1. Clusters from each algorithm that are most alike.</p><p>2. The number of records appearing in each possible combination of cluster sets. 3. Those clusters that are the most stable. 4. Those records that tend to be least consistently assigned to clusters of other records in each of the cluster sets. 5. Clusters in the cluster set used as the base classifier that are most alike.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Further Development of VRV Applied to Multiple Cluster Sets</head><p>Since each dimension is limited to values one and zero, there are a finite number of possible point locations in VRV. Unlike traditional Radviz displays where the dimensions typically are continuous and therefore can admit a wide range of point locations, VRV each displayed point can have a large number of associated records. For this implementation, we used point size to represent the number of records at that location. Additional information can be displayed by making each point a pie chart. Since there are a limited number of feasible points, occlusion is not as large a problem as with traditional Radviz.</p><p>The current implementation places the dimensions counter clockwise in decreasing order of the calculated t-Statistic within a classification sector. It may be more effective to place the dimension with the greatest t-Statistic at the center of each classification sector in order to achieve the most separation from adjacent classification sectors.</p><p>One of the clusters must be used as the base classifier for the other clusters. The classifier for this paper was arbitrarily chosen. It may be more effective to analyse all of the cluster sets in some way to arrive at a more effective classifier. For example, the cluster set most alike all of the other clusters may be more appropriate.</p><p>In this analysis, clusters were placed in order using a greedy algorithm based on Euclidean distances of the averages of each cluster. An algorithm based on the simultaneous evaluation of multiple possible orderings could be more effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Further Application of VRV</head><p>VRV can be used to visualize a wide variety of data sets in other applications. For example, it can be used to aid in the analysis of Bayesian decision trees. Each node can be represented by a vector and the decision to be analyzed can be used as the classifier. Applications to continuous data are also possible by binning the data, either into equally distributed or sized bins. This approach allows one to handle complex distributions and still harness VRV's strengths.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Radviz example. The coordinates represent the values of dimensions X1, X2, X3, and X4 for the indicated records.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>shows a Radviz visualization of the three cluster sets. The three DAs, KM1, KM2, and HC, represent the results of the three clustering algorithms. As explained in the introduction, the location of each record is drawn to each anchor in proportion to the record's cluster number. Each point in the display represents the records with the same combination of clusters in the cluster set. The records are colored by the KM1 cluster results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Radviz visualization of three cluster sets based on the iris dataset. The color indicates the KM2 cluster the corresponding record belongs to. The enclosed records belong to cluster number 10 under KM1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Resizing points in Iris dataset VRV visualization to reflect the number of records at each point. The larger circles representing the most number of points are on or near the circumference of the circle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure</head><label></label><figDesc>Figure 6 is the iris VRV visualization with lines added. Lines drawn from each point within the circle to each dimension with a value of one indicate which clusters the records associated with that point belong to.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>VRV visualization of the newt microarray data after the Class Discrimination Layout. The dimensions in each sector represent clusters that are similar to each other. Points are spread out over the interior of the circle thus calling for more intelligent reordering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Newt microarray expression levels over time with K-means cluster 9 highlighted in black. The lower line separated from the other three lines in the cluster corresponds to point A inFigure 9.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>= ___________________________ •</head><label>___________________________</label><figDesc>John Sharko is with the Department of Computer Science, University of Massachusetts Lowell, E-Mail: jsharko@cs.uml.edu.</figDesc><table /><note>• Georges Grinstein is with the Department of Computer Science, University of Massachusetts Lowell, E-Mail: grinstein@cs.uml.edu.• Kenneth A Marx is with the Department of Chemistry, University of Massachusetts Lowell, E-Mail: kenneth_marx@uml.edu Manuscript received 31 March 2008; accepted 1 August 2008; posted online 19 October 2008; mailed on 13 October 2008. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Example Dataset Used to Illustrate the Discrimination Layout Algorithm</figDesc><table><row><cell>Record</cell><cell>Class</cell><cell>X1</cell><cell>X2</cell><cell>X3</cell></row><row><cell>1</cell><cell>A</cell><cell>11</cell><cell>3</cell><cell>13</cell></row><row><cell>2</cell><cell>A</cell><cell>12</cell><cell>4</cell><cell>10</cell></row><row><cell>3</cell><cell>A</cell><cell>11</cell><cell>1</cell><cell>12</cell></row><row><cell>4</cell><cell>B</cell><cell>3</cell><cell>14</cell><cell>1</cell></row><row><cell>5</cell><cell>B</cell><cell>4</cell><cell>13</cell><cell>2</cell></row><row><cell>6</cell><cell>B</cell><cell>2</cell><cell>14</cell><cell>1</cell></row><row><cell>7</cell><cell>C</cell><cell>5</cell><cell>3</cell><cell>4</cell></row><row><cell>8</cell><cell>C</cell><cell>1</cell><cell>5</cell><cell>2</cell></row><row><cell>9</cell><cell>C</cell><cell>3</cell><cell>2</cell><cell>1</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors wish to thank the reviewers for their detailed comments and suggestions. The authors acknowledge funding from DARPA and the CFCI at the University of Massachusetts Lowell for the newt microarray data project. The authors also wish to thank Dr. Alex Gee for his reviews and Dr. Jianping Zhou for his assistance in generating the cluster sets.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Detecting the Number of Clusters Using a Support Vector Machine Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mogueraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martin-Merino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Neural Networks</title>
		<meeting>the International Conference on Artificial Neural Networks</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2415</biblScope>
			<biblScope unit="page" from="763" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Objective Criteria for the Evaluation of Clustering Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Cluster Analysis for Researchers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Romesburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>North Carolina, Lulu Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finding Consistent Clusters in Data Partitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fred</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Workshop on Multiple Classifier Systems</title>
		<meeting>the Second International Workshop on Multiple Classifier Systems</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Combining Multiple Clusterings Using Evidence Accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fred</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions On Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="835" to="850" />
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Applied Mathematics</title>
		<imprint>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="1987-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Information Visualization in Data Mining and Knowledge Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Fayyad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wierse</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Morgan-Kaufmann Publishers</publisher>
			<pubPlace>San Francisco, California; San Francisco, California</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Heat Map Visualizations Allow Comparison of Multiple Clustering Results and Evaluation of Dataset Quality: Application to Microarray Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sharko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Odelberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proceedings of the 11 th International Conference on Information Visualization</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="521" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">DNA Visual And Analytic Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visualization 1997 Conference</title>
		<meeting>the IEEE Visualization 1997 Conference</meeting>
		<imprint>
			<date type="published" when="1997-10" />
			<biblScope unit="page" from="437" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dimensional anchors: a graphic primitive for multidimensional multivariate information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pinkney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 Workshop on New Paradigms in information Visualization and Manipulation</title>
		<meeting>the 1999 Workshop on New Paradigms in information Visualization and Manipulation</meeting>
		<imprint>
			<date type="published" when="1999-11" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">VizStruct: exploratory visualization for gene expression profiling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ramanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="92" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Leban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bratko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Petrovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Curk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zupan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="413" to="414" />
			<date type="published" when="2005" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Universal Visualization Platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Smrtic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Cvek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Goodell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE-IS&amp;T Electronic Imaging</title>
		<meeting>SPIE-IS&amp;T Electronic Imaging</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">5669</biblScope>
			<biblScope unit="page" from="274" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">RVPlotter Class for Java</title>
		<imprint/>
	</monogr>
	<note>Rapid Miner. formerly Yale</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Visualizing Multi-Dimensional Clusters, Trends, and Outliers using Star Coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kandogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Special Interest Group on Knowledge Discovery and Data Mining</title>
		<meeting>ACM Special Interest Group on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="107" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">SphereViz -Data Exploration in a Virtual Reality Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soldati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Doulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Csillaghy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11 th International Conference Information Visualization</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="680" to="683" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SpringView: Cooperation of RV and Parallel Coordinates for View Optimization and Clutter Reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dell'aquila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Santucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third IEEE International Conference on Coordinated and Multiple Views in Exploratory Visualization</title>
		<meeting>the Third IEEE International Conference on Coordinated and Multiple Views in Exploratory Visualization</meeting>
		<imprint>
			<date type="published" when="2005-07" />
			<biblScope unit="page" from="22" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">FreeViz-An intelligent multivariate visualization approach to explorative analysis of biomedical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Demsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="page" from="661" to="671" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Applications of Machine Learning and High-Dimensional Visualization in Cancer Detection, Diagnosis, and Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Gee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Ujwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hotchkiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1020</biblScope>
			<biblScope unit="page" from="239" to="262" />
			<date type="published" when="2004-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">High-Dimensional Visualization Support for Data Mining Gene Expression Data&quot; in DNA Arrays, Technologies and Experimental Strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jessee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O'neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gee</surname></persName>
		</author>
		<editor>Elena V. Grigorenko</editor>
		<imprint>
			<date type="published" when="2002" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Machine Learning Approach to Pharmacological Profiling of the Quinone Scaffold in the NCI Database: Effective Against Melanoma and Leukemia Cell Lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Ujwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Marx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7 th IEEE Bioinformatics and BioEngineering Conference</title>
		<meeting>the 7 th IEEE Bioinformatics and BioEngineering Conference</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="131" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Info Navigator: A Visualization Tool for Document Searching and Browsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Heesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Ruger</surname></persName>
		</author>
		<ptr target="http://kmi.open.ac.uk/people/stefan/www-pub/dms-2003.pdf" />
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Distributed Multimedia Systems</title>
		<imprint>
			<date type="published" when="2003-09" />
			<biblScope unit="page" from="24" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Clutter Reduction in Multi-Dimensional Data Visualization Using Dimension Reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Rundensteiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization</title>
		<meeting><address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-10-10" />
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Similarity Clustering of Dimensions for an Enhanced Visualization of Multidimensional Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ankerst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Berchtold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization</title>
		<meeting>the IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="52" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Tutorial on Support Vector Machines for Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining and Discovery Knowledge</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Benchmark Development for the Evaluation of Visualization for Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Laskowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pickett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Morgan Kaufmann Publishers</publisher>
			<biblScope unit="page" from="129" to="176" />
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
	<note>Information Visualization in Data Mining and Knowledge Discovery</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asuncion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Newman</surname></persName>
		</author>
		<ptr target="http://www.ics.uci.edu/~mlearn/MLRepository.html" />
		<title level="m">UCI Machine Learning Repository</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>University of California Irvine, School of Information and Computer Science</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
		<ptr target="http://www.r-project.org/" />
	</analytic>
	<monogr>
		<title level="j">The R Project</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Evidence for Proximal to Distal Limb Amputation Site Effects from Global Gene Expression Correlations found in Newt Microarrays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sharko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Odelberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7 th IEEE BioInformatics and BioEngineering Conference</title>
		<meeting>the 7 th IEEE BioInformatics and BioEngineering Conference</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="456" to="463" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
