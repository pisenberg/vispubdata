<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Visual Cues of Contact to Improve Interactive Manipulation of Virtual Objects in Industrial Assembly/Maintenance Simulations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Sreng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatole</forename><surname>Lécuyer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Mégard</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claude</forename><surname>Andriot</surname></persName>
						</author>
						<title level="a" type="main">Using Visual Cues of Contact to Improve Interactive Manipulation of Virtual Objects in Industrial Assembly/Maintenance Simulations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>virtual prototyping</term>
					<term>assembly/maintenance simulation</term>
					<term>visual cues</term>
					<term>glyph</term>
					<term>light</term>
					<term>contact</term>
					<term>proximity</term>
					<term>force</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper describes a set of visual cues of contact designed to improve the interactive manipulation of virtual objects in industrial assembly/maintenance simulations. These visual cues display information of proximity, contact and effort between virtual objects when the user manipulates a part inside a digital mock-up. The set of visual cues encloses the apparition of glyphs (arrow, disk, or sphere) when the manipulated object is close or in contact with another part of the virtual environment. Light sources can also be added at the level of contact points. A filtering technique is proposed to decrease the number of glyphs displayed at the same time. Various effects-such as change in color, change in size, and deformation of shape-can be applied to the glyphs as a function of proximity with other objects or amplitude of the contact forces. A preliminary evaluation was conducted to gather the subjective preference of a group of participants during the simulation of an automotive assembly operation. The collected questionnaires showed that participants globally appreciated our visual cues of contact. The changes in color appeared to be preferred concerning the display of distances and proximity information. Size changes and deformation effects appeared to be preferred in terms of perception of contact forces between the parts. Last, light sources were selected to focus the attention of the user on the contact areas.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Nowadays virtual reality technologies are increasingly used in industrial processes. Virtual prototyping consists in replacing physical prototypes by virtual mock-ups in order to improve productivity and shorten design, development, engineering and training times on industrial products <ref type="bibr" target="#b6">[7]</ref>.</p><p>In virtual assembly/maintenance simulations, designers and maintenance engineers can verify if an industrial part can be assembled and/or disassembled in the virtual mock-up. Several techniques can be used to improve the interactivity of assembly/maintenance simulations. For instance, haptic (force) feedback can help the user to better perceive the contacts between the parts of the digital mock-up <ref type="bibr" target="#b13">[14]</ref>. Haptic feedback can warn precisely of a collision and can guide the user when manipulating an object along its theoretical assembly trajectory.</p><p>However, the geometry of industrial virtual mock-ups is generally very complex and the manipulation of objects during assembly/maintenance simulations may lead to situations of multiple contacts. In a situation of multiple contacts, the manipulation becomes very difficult since the manipulated object is stopped at the level of several contact points. In such case, the force feedback of a haptic device provides global information of force which can not be easily used to extract the multiple information of local contacts.</p><p>Therefore, in this paper, we propose a set of visual cues which are designed to display information of proximity, contact and effort between objects in virtual environments. It encloses the apparition of glyphs (arrow, disk, or sphere) when the manipulated object is close or in contact with another part of the virtual environment. Visual effects such as color change, size change, and shape deformation are applied to the glyphs, as a function of proximity (distance between objects) or amplitude of contact forces. Light sources are also added at the level of the contact points. These contact cues are expected to improve the interactive manipulation of objects in assembly and maintenance simulations, especially in situation of multiple contacts.</p><p>Thus, the following paper begins with an overview of related work in the field of assistance to assembly/maintenance simulations and manipulation of objects in virtual reality. Then, the paper describes the set of visual cues that we have implemented. Then it describes the results of a preliminary evaluation conducted to gather the subjective preference of a group of participants concerning the use of our visual cues during an industrial assembly task. The paper ends with a conclusion and a description of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The use of visual feedback to improve manipulation of objects was early demonstrated in teleoperation studies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b9">10]</ref>. For instance, Kitagawa et al. <ref type="bibr" target="#b9">[10]</ref> tested different types of visual and auditory feedback during a teleoperated surgical procedure. They showed that a visual feedback which provides continuous force information can improve performance during a complex surgical task. A more complex visual feedback was tested by Petzold et al. <ref type="bibr" target="#b22">[23]</ref>. They displayed a reconstructed virtual scene of the telemanipulated environment with a set of graphic bars that continuously displayed the contact forces between the objects <ref type="bibr" target="#b22">[23]</ref>. This visual feedback, together with haptic and auditory feedback, was found to greatly improve the user's manipulation and his/her feeling of immersion.</p><p>In virtual reality, several studies were focused on the use of visual aids to improve manipulation of virtual objects. Kitamura et al. <ref type="bibr" target="#b10">[11]</ref> developed the "ghost object" to compensate for the missing force feedback in their virtual prototyping platform. When the manipulated object collides another part of the virtual environment, it is visually split into two representations. A "frozen" 3D display of the object remains at the last valid (collision-free) position, while a second display of the object (in wireframe) follows the user's motion and may penetrate inside the objects of the virtual environment.</p><p>Visual feedback can also be used to display global information of contact in virtual environments. Edwards used a flashing visual effect which is applied on a colliding object <ref type="bibr" target="#b5">[6]</ref>. Lécuyer et al. <ref type="bibr" target="#b14">[15]</ref> developed a change in transparency of the manipulated object to better visualize the contact scene. Gomes de Sá and Zachmann <ref type="bibr" target="#b6">[7]</ref> used a color code applied to the colliding object, e.g. red for collision, green for free-motion.</p><p>In some studies a visual glyph can be used to display local information of contact <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b24">25]</ref>. During the insertion task of Lécuyer et al. <ref type="bibr" target="#b14">[15]</ref>, the contact between two objects is notified to the user using a virtual arrow, located at the level of the contact point. Furthermore, this glyph provides an indication concerning the reaction force as the length of the arrow grows as function of the penetration of the manipulated object inside the encountered one <ref type="bibr" target="#b14">[15]</ref>. Thanks to this visual cue of contact, the users were found to pay more attention to the collisions. However, in return, researchers noticed that the users achieved their task slightly more slowly <ref type="bibr" target="#b14">[15]</ref>. In another study, McNeely et al. <ref type="bibr" target="#b19">[20]</ref> developed a technique to display visually the proximity information. They proposed to modify the color of the vertices of the manipulated object according to the distance (proximity) to the other objects of the scene.</p><p>Visual cues can also be used to convey depth information and thus inform about imminent contact in a manipulation task <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b16">17]</ref>. Kjelldahl et al. <ref type="bibr" target="#b11">[12]</ref> studied the use of different types of depth cues. They found that illumination and object placement (vertical or horizontal) were the most efficient cues for conveying relative depth information <ref type="bibr" target="#b11">[12]</ref>. Wanger et al. <ref type="bibr" target="#b25">[26]</ref> also compared six different depth cues: the projection mode, shadows, object texture, ground texture, motion and elevation. They found that a different combination of depth cues was necessary for each of their experimental tasks.</p><p>Several visual techniques have also been developed to attract the sight of the user to the relevant contact area <ref type="bibr" target="#b21">[22]</ref>. In the case of punctual haptic interaction (only one contact at a time), Otaduy and Lin <ref type="bibr" target="#b21">[22]</ref> developed a camera motion that keeps the most relevant (occlusion-free) viewpoint on the contact area. Other visual effects can be used to focus on relevant areas of an image. Baudisch et al. <ref type="bibr" target="#b2">[3]</ref> presented saliency-based techniques, masking and shadowing effects to hide the less relevant parts of a picture.</p><p>Last, other sources of information such as haptic and audio feedback can be used to provide contact information in assembly/maintenance simulations <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b4">5]</ref>. As already mentioned, haptic feedback of collision and contact is used in many studies <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b13">14]</ref>. Concerning audio feedback, simple beeps <ref type="bibr" target="#b14">[15]</ref>, realistic collision sounds <ref type="bibr" target="#b5">[6]</ref> and even physically-simulated sounds <ref type="bibr" target="#b23">[24]</ref> were developed to improve contact rendering and collision warning. Thus, Lindeman <ref type="bibr" target="#b15">[16]</ref> stressed the importance of combining various visual, auditory and haptic cues, to provide the user with appropriate contact information in virtual environments <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LOCAL MINIMUM DISTANCES AND CONTACT INFORMATION</head><p>Our main objective is to display information of contact visually, in order to improve the interactive manipulation of virtual objects in industrial assembly/maintenance simulations.</p><p>We can identify two types of information that can be displayed in assembly/maintenance simulations: (1) local minimum distances, and (2) contact information. First, a Local Minimum Distance (LMD) is a couple of two points between two objects that corresponds to a potential future contact between the two objects ( <ref type="figure" target="#fig_0">Figure 1</ref>). As described by Johnson et al. <ref type="bibr" target="#b8">[9]</ref>: "Imagine two models that have just collided. This collision can be represented at a single point on each surface <ref type="bibr">[...]</ref>. If the models move apart, this pair of points tracks the local minimum distance and represents the potential future contacts between entire sections of these two models". The number of LMD between two objects depends on the cut-off distance and the number of polygons of each object. When the LMD decreases and gets null, the two points join together and become a contact point between the two objects.</p><p>Second, contact information encloses one position information (the location of the contact point) and one force information (the contact force, at the level of the contact point).</p><p>A LMD can be described by a set of six real numbers representing the coordinates of its two points (it could also be displayed by one point and one vector). A contact information can be defined by one position (3 real numbers), one orientation (2 real numbers) and one contact force vector (3 real numbers). To summarize, the different types of information to be displayed are the following:</p><p>• local minimum distance information (dimension = 6) first point <ref type="formula">3</ref>second point <ref type="formula">3</ref>• contact information <ref type="formula">8</ref>contact point &amp; orientation <ref type="formula">5</ref>contact force <ref type="formula">3</ref>These different types of information can be displayed using several graphical objects. Many different graphical objects can be used: current objects of the virtual environment, avatar of the device, additional glyphs, additional text, etc. Furthermore, each graphical object can be characterized by several parameters: its position, orientation, size, color, texture, shading, illumination, animation, etc. Therefore, each parameter of each graphical display can be bound with one or several (contact) information in order to create a visual cue of contact. The <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the high number of possibilities that exists when binding one piece of contact information with one parameter of a graphical object in the simulation. In the next section we will describe the choices made concerning the design of our visual cues of contact. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VISUAL CUES FOR PROXIMITY, CONTACT AND EFFORTS</head><p>Among the numerous binding possibilities, we have chosen to develop a limited number of visual cues for proximity, contact and effort information. We have focused our implementation on the use of two types of graphical objects: glyphs and lights. Thus, in this section, we will describe three types of visual glyph that we have developed: the proximity glyph, the effort glyph, and the hybrid glyph. Then, we will describe a fourth contact cue based on objects illumination (contact lights) which does not overload the graphical scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Visual glyph</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Proximity glyph</head><p>The first visual glyph is a "proximity glyph" which provides two types of information:</p><p>• Proximity (location of local minimum distance)</p><p>• Contact (location and direction of contact)</p><p>The proximity glyph is a coupling between distance information and the color and size of a 3D glyph. When two objects are getting close, a small 3D blue glyph appears on the manipulated object. The color and size of the glyph are modified according to the distance between the objects. When the distance decreases the size of the glyph increases and its color changes using a classical blue-green-yellow-red gradient (see <ref type="figure" target="#fig_3">Figure 3</ref>).</p><p>Let us detail hereafter, the binding made between the LMD information and the parameters of the proximity glyph. We use here a C-like syntax with which, for instance, a contact force can be written as "contact.force(3)" and its amplitude as "contact.force:magnitude(1)" (the number corresponds here to the dimension of the information): After preliminary testings, the f 1 and g 1 functions were set as defined by Equation 1, in which k 1 is a control gain set to 20 and s M the maximum LMD threshold set to 0.05. The second visual glyph is an "effort glyph" which provides two types of information:</p><formula xml:id="formula_0">∀x ∈ R, f 1 (x) = k 1 (1 − x s M ) g 1 (x) = 2π 3 ( x s M )<label>(1)</label></formula><p>• Contact (location and direction)</p><p>• Contact force (location and direction)</p><p>The effort glyph is a coupling between the contact force information and the color and size of the 3D glyph. Thus, the effort glyph uses the same visual effects as the proximity glyph, but to display another information (see <ref type="figure" target="#fig_3">Figure 3)</ref>. When two parts get in contact, a small blue glyph appears at the level of the contact point. Then, the size and color of the glyph are modified according to the amplitude of the contact force. If the amplitude increases, the size of the glyph increases and its color changes using the same color gradient as the proximity glyph. Thus, we use the following binding: In our implementation, we use a simplified force computation which does not include a friction model. In this case, the orientation of the contact force corresponds to the one of the contact normal. After preliminary testings, the f 2 and g 2 functions were set as defined by Equation 2, in which k 2 is a control gain set to 10 and f M the maximum force magnitude that can be applied set to 0.1.</p><formula xml:id="formula_1">∀x ∈ R, f 2 (x) = k 2 (1 − x f M ) g 2 (x) = 2π 3 ( x f M )<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Hybrid glyph</head><p>The hybrid glyph is a "all-in-one" glyph that provides in one graphical symbol three types of information:</p><p>• Proximity (location of local minimum distance)</p><p>• Contact (location and direction)</p><p>• Contact force (location and direction)</p><p>The hybrid glyph combines the use of the proximity glyph with another scheme for the display of contact forces based on the deformation of a spherical glyph (see <ref type="figure">Figure 4)</ref>. A small blue sphere appears when the two objects are getting close. The color and size of the sphere are modified according to the distance between the objects. When the distance gets null (which corresponds to a contact situation), the glyph is a large red sphere. If the user continues to push on the manipulated object, the red sphere flattens in the direction of the contact force as if the user was pressing a rubber ball. When the sphere flattens, one radius is decreased (according to the force applied by the user) while the two other radii are increased so to keep the ball with a constant volume. The implementation of the hybrid glyph corresponds to the following pseudo-code: After preliminary testing, the f 3 , g 3 and h functions were set as defined by Equation 3 in which k 1 is a control gain set to 20, s M is the maximum LMD threshold set to 0.05, f M is the maximum force magnitude that can be applied set to 0.1 and k F is a force control gain set to 10. </p><formula xml:id="formula_2">∀x ∈ R,    f 3 (x) = f 1 (x) = k 1 (1 − x s M ) g 3 (x) = g 1 (x) = 2π 3 ( x s M ) h(x) = 1 + k F . x f M (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Shape of glyphs</head><p>The <ref type="figure" target="#fig_7">Figure 6</ref> displays three different possible shapes for the visual glyphs: arrow, disk and sphere. The sphere glyph does not provide any orientation information. However, this glyph is easy to understand and to localize. The arrow glyph provides straight orientation information: its main axis. The arrow glyph is highly informative, but if the number of displayed glyphs increases, the multiple arrows can quickly overload the visual feedback. The disk glyph provides an implicit orientation information as its symmetry axis is perpendicular to its surface. Furthermore, the disk glyph is less intrusive than the arrow since multiple disks tend to overlap at the surface of a virtual object, like colored stickers. However disks are sometimes less visible and their centre (i.e. the exact position of the contact point) can sometimes be difficult to perceive. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Glyph filtering</head><p>In situations of multiple contacts, numerous glyphs could be displayed at the same time. This could strongly overload the visual feedback. In order to decrease this visual load, we have developed a filtering method that selects some glyphs and hides the less relevant glyphs. At each time step, this filter hides the glyphs which do not correspond to a contact that constrains the motion of the manipulated object (see <ref type="figure" target="#fig_8">Figure 7</ref>). This is done by comparing for each glyph the orientation vector of the glyph, (i.e. orientation of the contact force d) with the direction of its velocity (i.e. the velocity of the object at the level of the contact point v). If the directions of these two vectors are close, the associated contact actually constrains the motion of the object and the glyph is considered as relevant. The hiding of the glyph is made by changing (increasing) its level of transparency, i.e. its alpha (α) color channel. The level of transparency of each glyph is set using Equation 4. Furthermore, if the user does not move the manipulated object for more than five seconds, all the hidden glyphs reappear, and the user has an access to all the contact and LMD information. The fourth visual cue that we propose corresponds to the addition of light sources at the level of the contact points (see <ref type="figure" target="#fig_9">Figure 8</ref>). This visual cue does not introduce additional graphical objects but is based on the illumination of the current objects of the virtual scene. Light sources make it possible to display contact information hidden by the object's geometry. They can be easily combined with the visual glyphs (see <ref type="figure" target="#fig_10">Figure 9</ref>).</p><formula xml:id="formula_3">α = 1 2|| d|||| v|| (| d. v| − d. v)<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Contact lights</head><p>Two types of contact light were implemented (see <ref type="figure" target="#fig_0">Figure 10</ref>): • Spherical light: a non directional light is positioned at the level of the contact point. All the objects close to the contact point are illuminated (see <ref type="figure" target="#fig_9">Figure 8</ref>).</p><p>• Conical light: a conical light is positioned at the level of the contact point and oriented in the opposite direction of the contact normal (see <ref type="figure" target="#fig_0">Figure 10)</ref>. The contact area is more focused since only the objects located inside the light cone are illuminated.</p><p>Using our C-like notation, the two different types of light source are defined as follows. For the spherical contact light: In our implementation, d is an elevation factor which is set to 5% of the length of the manipulated object. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">PRELIMINARY EVALUATION</head><p>The main objective of this preliminary evaluation was to collect data about the users' preference concerning the different visual cues and visual effects which we designed to display information of proximity, contact and effort during an industrial assembly operation.</p><p>An informal experiment was thus conducted in which participants were asked to perform an industrial assembly operation in a virtual environment with and without our visual cues of contact. After testing successively all the different visual effects, the participants were asked to fill in a subjective questionnaire.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setup</head><p>The virtual environment used corresponded to the simulation of an automotive assembly scenario. The virtual scene was made of two parts of an industrial digital mock-up: a windshield wiper motor, and the part of the firewall in which the wiper motor must be inserted (see <ref type="figure" target="#fig_10">Figure 9</ref>).</p><p>The software simulation engine used to compute LMD, to detect collisions and to render contacts between the parts was the GVM software of CEA <ref type="bibr" target="#b20">[21]</ref>. The visualisation software used was VTK 4.4 <ref type="bibr" target="#b1">[2]</ref>. The experimental setup used a 2.4Ghz Pentium 4 PC, together with a NVidia Quadro 4 graphic card. The frame rate of the visual feedback was then of 30 frames per second. The manipulation of the virtual object (windshield wiper motor) was made through the SpacePilot TM input device of 3DConnexion <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Participants</head><p>18 participants, aged from 21 to 43 took part in this experiments (m = 26.8, σ = 5.1) (m it the mean and σ the standard deviation). There were 16 men and 2 women. They had no known perception disorders. Among them, one man was left handed. The participants were all naive to the purpose of the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental procedure</head><p>The participants sat 60 cm in front of a 15" computer screen. The participants used their dominant hand to manipulate the SpacePilot TM .</p><p>During a learning phase, participants had first to read a text explaining the experimental setup and the different phases of the experiment. Then, they were trained to the use of the SpacePilot TM device. To do so, they had to achieve a series of 8 assembly tasks with a simplified virtual industrial model.</p><p>During the testing phase, all the different visual cues (and their associated visual effects, i.e. deformation, color code, etc) were introduced. The participants were asked to complete the virtual assembly task (from one given initial position to one given final position), in order to test successively the different visual effects. They could activate successively the contact lights and all the visual glyphs (proximity glyph, effort glyph, hybrid glyph), with their different shapes (disk, sphere, arrow), with and without the filtering technique. They could test the different conditions as long as they wanted. After testing all the possibilities once, they could freely test again all the different cues.</p><p>At the end of the testing phase, the participants had to fill in a subjective questionnaire. The total time for this experiment (including learning phase, breaks and questionnaire) was of 45 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Collected data</head><p>In the questionnaire, each participant had first to rank 5 different visual effects according to 4 preference criteria. The 5 visual effects were: the apparition of a light source (Light), the apparition of a glyph (Glyph), the change in color of glyphs (Colour), the change in size of glyphs (Size), the deformation of glyphs (Deformation). The 4 subjective criteria were: (1) Understanding of the blocking situation (Understanding), (2) Perception of distances between the objects (Distances), (3) Perception of the contact forces applied between the objects (Forces), and (4) Focus on the contact areas (Focus). They had to rank the different visual effects from 1 to 5 (1 = best effect for the criterion, 5 = worst effect).</p><p>Then, the participants were asked their preference concerning two properties of the visual glyphs' appearance: first the different shapes of glyph (disk, sphere, and arrow), second the activation (or not) of the filtering technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Participants' preference concerning the visual effects</head><p>The ranks given by the participants for each visual effect and each criterion are reported in <ref type="table" target="#tab_1">Table 1</ref>. <ref type="table" target="#tab_1">Table 1</ref> displays all the occurrences, i.e. all the number of times each visual effect is ranked in each place for each criterion. For instance, the apparition of glyphs (Glyph) was ranked 5 times in position 1 (i.e. best rank) concerning the Understanding criterion (better understanding of the blocking situations).</p><p>We have performed two types of analysis on the results: a χ 2 test on the ordinal rank, and a 1-way between subjects parametric ANOVA on the rank number used as a value. The main results are given hereafter.</p><p>Preference in terms of understanding of the blocking situations. The deformation of glyphs seems to be preferred concerning a better understanding of the contact situations, since it was more often selected in first position. Indeed, 10 participants ranked deformation in first place. However, the χ 2 test on the ranks was not significant (χ 2 = 23.8, do f = 16, p = 0.09) and the parametric ANOVA was also not significant (F(4, 85) = 0.82, p = 0.51).</p><p>Preference in terms of perception of distances between the objects. The change in color of the glyph seems to be preferred by the participants concerning the perception of distances between the virtual objects since 8 participants ranked color in first place. The deformation effect applied on the glyph and the contact lights were obviously not appreciated in terms of perception of distance (deformation was ranked 13 times in fifth place, and lights 10 times at fifth place). The statistical test on ordinal ranks was found to be significant here (χ 2 = 49.85,V Cramer = 0.37, do f = 16, p &lt; 0.0001). When considering the mean values of the ranking, the scheme is slightly different since the best visual effect appears to be the change in size, followed by the change in color. The ANOVA statistical test was also found significant here (F(4, 85) = 6.07, p &lt; 0.0003).</p><p>Preference in terms of perception of the contact forces between the objects. The deformation of the glyphs seems to be preferred concerning the perception of contact forces between the manipulated object and the other parts of the virtual environment. Indeed, the deformation effect was ranked in first place by a majority of participants (12 times). Contact lights were found irrelevant for this criterion (lights were ranked 13 times in last place). The statistical test was significant (χ 2 = 71.5,V Cramer = 0.44, do f = 16, p &lt; 0.00001). Considering the mean values, the mean rank obtained by the size changes was slightly better than the one of the deformation effect. The ANOVA test was also significant here (F(4, 85) = 21.74, p &lt; 0.00001).</p><p>Preference in terms of focus on the contact areas. The contact lights were very appreciated by the participants concerning the focus of the attention of the user on contact areas, as 11 participants put lights at first rank. Statistical test on rankings was significant (χ 2 = 37.17,V Cramer = 0.32, do f = 16, p &lt; 0.002). The computation of mean values showed a best evaluation of lights and size changes as well. The ANOVA statistical test was here also significant (F(4, 85) = 3.06, p &lt; 0.02).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Participants' preference concerning the appearance of</head><p>visual glyphs Shape of glyphs. Participants best ranked disk shape in 50% of the cases, sphere shape in 44% and arrow shape in 28% (see <ref type="table">Table 2</ref>). However, the χ 2 test on the ranks of the different shapes of glyph was not found significant (χ 2 = 2.56,V Cramer = 0.15, do f = 4, p = 0.6).</p><p>Ranks (m, σ ) Shape 1 2 3 ( m , σ ) Arrow 5 7 6 (2.1, 0.8) Disk 9 5 4 (1.7, 0.8) Sphere 8 4 6 (1.9, 0.9) <ref type="table">Table 2</ref>. Preferences concerning the shape of glyphs Filtering. The activation of the glyph filtering was preferred and selected by 72% of the participants (13 participants). The statistical test was found significant (χ 2 = 7.11, do f = 1, p &lt; 0.02).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Discussion</head><p>The analysis of the answers collected in the subjective questionnaire indicated clear preferences of the participants among the different visual cues. The participants were able to associate the various effects included in our visual cues with different types of contact information.</p><p>The contact lights were highly preferred to the glyphs' effects in terms of attraction and focus of the attention of the user on the contact  areas. The contact light effect could be compared here to the efficient masking effect described by Baudisch et al. <ref type="bibr" target="#b2">[3]</ref> in order to hide the irrelevant parts of a 2D picture and to focus the visual attention. For some participants, the illumination generated by the contact lights was also helpful to evaluate the distances between the parts. This advantage is comparable to the effect described by Kjelldahl et al. <ref type="bibr" target="#b11">[12]</ref> in another context. Numerous participants reported orally that such contact lights decreased the workload and kept the visual scene free of extra graphical objects. One participant reported that light sources "provided a better view of the static part". Another participant found the lights to be an efficient way to "give the location of the contact points, even if they are not directly visible". Thus, the light sources are non-intrusive visual objects which were globally very well appreciated. However, several participants reported a preference for the apparition of glyphs (as compared to lights), when they had to achieve precise manipulations. The change in color of the glyphs appeared to be preferred by the participants to display information of distance between the virtual parts. This suggests that the classical color gradient that we used was easy to understand by the participants to extract local proximity information. The change in size of the glyphs was globally well appreciated among the participants for all criteria. Indeed this effect was almost always ranked in second place, and it was rarely ranked in the last (fifth) place.</p><p>The deformation effect was preferred by a majority of participants for a better understanding of the blocking situations (even though statistical tests did not show significant effect). Furthermore, deformation of glyphs appeared also to be preferred to the size and color changes in terms of perception of the contact forces. When manipulating the virtual object through the use of an elastic input device such as the SpacePilot TM , the deformation of the hybrid glyph in situation of contact could meet up the technique of pseudo-haptic feedback described by Lécuyer et al. <ref type="bibr" target="#b12">[13]</ref>. Pseudo-haptic feedback was initially obtained by combining the use of a passive input device with a visual feedback <ref type="bibr" target="#b12">[13]</ref>. It has been shown and used to simulate haptic properties such as stiffness or friction <ref type="bibr" target="#b12">[13]</ref>. The deformation of the hybrid glyph could thus give here a pseudo-haptic feeling of the contact force, which could be naturally perceived and thus more appreciated by the participants. But future work would be necessary to investigate this issue and to develop contact glyphs based on pseudo-haptic feedback.</p><p>Besides, some participants suggested other useful effects and functionalities in their questionnaire. They asked for the possibility to "adapt the point of view automatically" or to have multiple windows and "several points of view on the parts", to "use a magnifying effect on the contacts" or a "transparency code on virtual objects when they are hidden by others". Last, numerous participants asked to change and adapt the visual cues in some specific cases, instead of having always the same kind of visual feedback for the whole task. This suggests that the user should keep the possibility to modify at any moment the properties of his/her visual cues of contact, and/or those contextual visual cues should be developed to match automatically various contact situations.</p><p>In a nutshell, the collected questionnaire showed that participants globally appreciated our visual cues of contact. The changes in color appeared to be preferred concerning the display of distances and proximity information. Size changes and deformation effects appeared to be globally preferred in terms of perception of contact forces between the parts. Last, light sources were selected to focus the attention of the user on the contact areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We have proposed the use of visual cues of contact to improve interactive manipulation of virtual objects in industrial assembly/maintenance simulations. Our set of visual cues encloses light sources and visual glyphs (e.g. arrow, disk, or sphere) when the manipulated object is close or in contact with another part of the virtual environment. Visual effects can be applied to the glyphs such as color change, size change or deformation effect.</p><p>A preliminary evaluation has been performed in which participants could give their preference concerning the different visual aids. This informal evaluation suggested that the visual glyphs and their associated visual effects seemed useful to inform about distances (proximity between parts) and contact forces, while light sources seemed appreciated to focus the attention of the user on the contact areas.</p><p>Future work. Future work will first deal with a formal study dedicated to the quantitative evaluation of our visual cues of contact in an industrial context, with several assembly/maintenance scenarios. This evaluation could compare the use of our visual cues of contact with the use of other contact cues such as with audio or haptic feedback. We would also like to develop the concept of contextual visual cues of contact, which would adapt to the multiple situations that can be faced in an assembly/maintenance simulation. Last, complementary interaction techniques could be investigated such as camera motions, i.e. changes in the user's viewpoint, in order to focus the attention of the user on the main contact areas.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Contact points and Local Minimum Distances</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Example of bindings between information (LMD and/or contact) and visual cues</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>glyph.position(3) = LMD:leftpoint(3) glyph.transf:orientation(2) = LMD:orientation(2) glyph.transf:size(1) = f1(LMD:size(1)) glyph.color:hue(1) = g1(LMD:size(1))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Use of arrow glyphs in situation of multiple contacts when manipulating a semi-transparent knob 4.1.2 Effort glyph</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>glyph.position(3) = contact.point:position(3) glyph.transf:orientation(2) = contact.force:orientation(2) glyph.transf:size(1) = f2(contact.force:magnitude(1)) glyph.color:hue(1) = g2(contact.force:magnitude(1))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>if LMD:size(1) is not null glyph.position(3) = LMD:leftpoint(3) glyph.transf:orientation(2) = LMD:orientation(2) glyph.transf:size(1) = f3(LMD:size(1)) glyph.color:hue(1) = g3(LMD:size(1)) else glyph.position(3) = contact.point:position(3) glyph.transf:orientation(2) = contact.force:orientation(2) glyph.transf:size_x(1) = 1/h(contact.force:magnitude(1))ˆ2 glyph.transf:size_y(1) = h(contact.force:magnitude(1)) glyph.transf:size_z(1) = h(contact.force:magnitude(1)) glyph.color:hue(1) = g3(0)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Visual glyphs Hybrid glyphs. (Left): situation of contact without a motion of the user. (Right): situation of contact with vertical motion and with contact forces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Arrow, disk and sphere glyphs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Glyph filtering based on the user's movement</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Use of spherical contact lights</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Combined use of light sources and visual glyphs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>spherelight.position(3) = contact.point:position(3) For the conical contact light: conelight.position(3) = contact.point:position(3) -d * contact.point:vector(3) conelight.trans:orientation(2) = contact.point:orientation(2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 10 .</head><label>10</label><figDesc>Spherical and conical contact lights</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>Jean Sreng is with CEA LSI and INRIA/IRISA, Bunraku Project. Address: 18 Route du Panorama, BP6 92265 Fontenay-aux-Roses, France. E-mail: jean.sreng@cea.fr. • Anatole Lécuyer is with INRIA/IRISA, Bunraku Project, Campus de Beaulieu, 35042 Rennes, France. E-mail: anatole.lecuyer@irisa.fr. • Christine Mégard is with CEA LSI, E-mail: christine.megard@cea.fr. • Claude Andriot is with CEA LSI, E-mail: claude.andriot@cea.fr. Manuscript received 31 March 2006; accepted 1 August 2006; posted online 6 November 2006. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Ranks of the visual effects</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors would like to thank all the participants who took part in this experiment for their kindness and their patience.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://www.3dconnexion.com" />
		<title level="m">3D connexion</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://www.vtk.org" />
		<title level="m">VTK</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Focusing on the essential: Considering attention in display design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baudisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decarlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Duchowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Geilser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="60" to="66" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The glad-in-art project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bergamasco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IMAGINA Conference</title>
		<meeting>IMAGINA Conference</meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Six degree-of-freedom haptic system for desktop virtual prototyping applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Workshop on Virtual Reality and Prototyping</title>
		<meeting>the First International Workshop on Virtual Reality and Prototyping</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="97" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Performance and usability of force feedback and auditory substitutions in a virtual environment manipulation task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Edwards</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-11" />
		</imprint>
	</monogr>
	<note>Master&apos;s thesis, Faculty of the Virginia Polytechnic Institute</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Virtual reality as a tool for verification of assembly and maintenance processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gomes De Sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zachmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="389" to="403" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual cues for imminent object contact in realistic virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Gooch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Smits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visualization Conference</title>
		<meeting>the IEEE Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="179" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Six degree-of-freedom haptic rendering of complex polygonal models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Willemsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems</title>
		<meeting>the 11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">229</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effect of sensory substitution on suture manipulation forces for surgical teleoperation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kitagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dokko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Okamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Bethea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Yuh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Annual Medicine Meets Virtual Reality Conference</title>
		<meeting>the 12th Annual Medicine Meets Virtual Reality Conference</meeting>
		<imprint>
			<date type="published" when="2004-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A sophisticated manipulation aid in a virtual environment using dynamic constraints among object faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kishino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Presence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="460" to="477" />
			<date type="published" when="1998-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A study on how depth perception is affected by different presentation methods of 3d objects on a 2d display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kjelldahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Prime</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="202" />
			<date type="published" when="1995-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pseudo-haptic feedback : Can isometric input devices simulate force feedback ?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lécuyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Coquillart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kheddar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Virtual Reality Conference</title>
		<meeting>the IEEE Virtual Reality Conference</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="83" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A haptic prototype for the simulations of aeronautics mounting/unmounting operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lécuyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kheddar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Coquillart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Graux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coiffet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Workshop on Robot-Human Interactive Communication</title>
		<meeting>the IEEE International Workshop on Robot-Human Interactive Communication</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The effect of haptic, visual and auditory feedback on an insertion task on a 2-screen workbench</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lécuyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mégard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Burkhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Coquillart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coiffet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Graux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Immersive Projection Technology Symposium</title>
		<meeting>the Immersive Projection Technology Symposium</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Virtual contact : the continuum from purely visual to purely physical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Lindeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th annual meeting of the human factor and ergonomics society</title>
		<meeting>the 47th annual meeting of the human factor and ergonomics society</meeting>
		<imprint>
			<date type="published" when="2003-10" />
			<biblScope unit="page" from="2103" to="2107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Use of interreflection and shadow for surface contact</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Madison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Smits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception and Psychophysics</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="194" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sensory substitution for force feedback in teleoperation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Massimino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Sheridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Presence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="344" to="352" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Six degree-of-freedom haptic rendering using voxel sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Mcneely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Puterbaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Troy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIG-GRAPH &apos;99</title>
		<meeting>the ACM SIG-GRAPH &apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Voxel-based 6-dof haptic rendering improvements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Mcneely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Puterbaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Troy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Haptics-e</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GVM/LMD++ physics engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Merlhiot</surname></persName>
		</author>
		<idno>DTSI/SCRI/LCI/05RT.011</idno>
	</analytic>
	<monogr>
		<title level="j">CEA</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">User-centric viewpoint computation for haptic exploration and manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Otaduy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visualization Conference</title>
		<meeting>the IEEE Visualization Conference</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A study on visual, auditory, and haptic feedback for assembly tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Petzold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Zaeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Faerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Deml</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Egermeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schilp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Presence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="16" to="21" />
			<date type="published" when="2004-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Symphony: Real-time physically-based sound synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Raghuvanshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Symposium on Interactive 3D Graphics and Games</title>
		<meeting>Symposium on Interactive 3D Graphics and Games</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Algorithms for interactive dynamics simulation of rigid bodies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Redon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002-10" />
		</imprint>
		<respStmt>
			<orgName>University of Evry</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Perceiving spatial relationships in computer-generated images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Wanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Ferwerda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="54" to="58" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
