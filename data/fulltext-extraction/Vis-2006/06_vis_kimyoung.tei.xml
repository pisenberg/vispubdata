<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Saliency-guided Enhancement for Volume Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngmin</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Amitabh</forename><surname>Varshney</surname></persName>
						</author>
						<title level="a" type="main">Saliency-guided Enhancement for Volume Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Saliency</term>
					<term>visual attention</term>
					<term>perceptual enhancement</term>
					<term>volume rendering</term>
					<term>non-photorealistic rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Recent research in visual saliency has established a computational measure of perceptual importance. In this paper we present a visual-saliency-based operator to enhance selected regions of a volume. We show how we use such an operator on a user-specified saliency field to compute an emphasis field. We further discuss how the emphasis field can be integrated into the visualization pipeline through its modifications of regional luminance and chrominance. Finally, we validate our work using an eyetracking-based user study and show that our new saliency enhancement operator is more effective at eliciting viewer attention than the traditional Gaussian enhancement operator.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Visually depicting large volume datasets in a comprehensible way has been a long-standing challenge. Transfer functions have been widely used to help visualize the features and details in volumes by assigning varying optical properties such as color and opacity to different densities of a volumetric scalar field. Significant advances have been made in the art and the science of devising transfer functions that successfully show the inherent structures within a given volume dataset. Despite these impressive advances the transfer functions remain a mapping of the physical appearance to the local geometric attributes such as the local density of the scalar field and its first and higher-order derivatives. Notwithstanding the pioneering work in dual-domain interactions by Kniss et al. <ref type="bibr" target="#b11">[12]</ref>, transfer functions by and large remain ill-suited to directly afford the appearance manipulation of selected regions of a volume. As the volume datasets have grown in complexity, so too has the need to emphasize and draw visual attention to appropriate regions in their visualization. This paper addresses the growing need for tools and techniques that can draw visual attention to userspecified regions in a direct volume rendering environment. Towards this goal we seek solutions based on multi-scale methods for visual saliency that can be used to guide visual attention based on varying perceptual importance.</p><p>In this paper, we introduce a new visualization enhancement operator that is inspired by the center-surround mechanism of visual saliency. Our goal is to enhance human perception of the volume data by guiding a viewer's attention to specific regions of interest. Since our method considers the influence of each voxel at multiple scales, it can emphasize volumetric features at an appropriate visual scale. Existing transfer functions, based on local geometry and its derivatives, would find it difficult to achieve a similar level of multi-scale emphasis. Our saliency-guided enhancement framework provides scientists and medical researchers a valuable tool to enable them to easily emphasize and de-emphasize regions of interests even in large volume datasets, successfully guiding user's visual attention to desired regions without sacrificing their local context. Saliency-guided emphasis is likely to find use in large-scale visual knowledge discovery applications where knowledge discovery modules could identify the regions satisfying a certain criteria and then present them visually with subtle variations to draw a user's attention to those regions in order of their importance.</p><p>The main contributions of this paper are:</p><p>• Youngmin Kim is with University of Maryland, College Park, E-mail: ymkim@cs.umd.edu.</p><p>• Amitabh Varshney is with University of Maryland, College Park, E-mail: varshney@cs.umd.edu.  • We present a new saliency-based enhancement operator to guide visual attention in volume visualization.</p><p>• We discuss augmenting the existing visualization pipeline by incorporating enhancement operators to increase the visual saliency of different regions of a volume dataset.</p><p>• We present an eye-tracking-based user study that shows that our saliency-enhancement operator is successful in eliciting viewer attention in volume visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Direct volume rendering models the attenuation of light in a volume composed of particles with varying densities and opacities <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref>. Volume rendering has evolved considerably over the past two decades and now engineers, scientists, medical researchers, and visual designers use a rich suite of tools and techniques to specify the visual appearance of a volume based on their needs. Transfer functions have played a crucial role in broad use of direct volume rendering. The design of transfer functions to generate informative visualizations has been a significant challenge that has been addressed by a number of researchers <ref type="bibr" target="#b21">[22]</ref>. A number of heuristics are used to guide the users in selecting appropriate transfer functions. For instance, Levoy <ref type="bibr" target="#b14">[15]</ref> suggested the use of the gradient magnitude to identify surfaces in volume data. Kindlmann and Durkin <ref type="bibr" target="#b9">[10]</ref> used the first and second derivatives along the gradient direction to calculate a boundary emphasis to be included in the opacity transfer function. In addition to the design of the opacity transfer function, general multi-dimensional transfer functions were studied to better convey the boundaries and features in volume data <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18]</ref>. Stylized rendering in volume visualization has attracted extensive research interest in the last few years. Treavett and Chen <ref type="bibr" target="#b27">[28]</ref> developed techniques for pen-and-ink illustrations of surfaces within volumes. Lu et al. <ref type="bibr" target="#b16">[17]</ref> used stippling techniques for interactively previewing large datasets. Burns et al. <ref type="bibr" target="#b2">[3]</ref> identified and depicted silhouettes and suggestive contours in volumes. Rheingans and Ebert <ref type="bibr" target="#b23">[24]</ref> developed a variety of volume illustration techniques. They used the scalar field gradient in addition to the local density to carry out a sophisticated set of perceptual enhancements that are view-and lightdependent. Interrante et al. explored the use of carefully oriented textures to convey surface shape in volumes <ref type="bibr" target="#b5">[6]</ref> and to convey 3D flows <ref type="bibr" target="#b6">[7]</ref>. With few exceptions, all of these enhance the important features based on the volume sample value or the local volume characteristics.</p><p>Viewers pay greater visual attention to regions that they find salient <ref type="bibr" target="#b19">[20]</ref>. Therefore, many models of visual attention and saliency in an image have been evaluated by their ability to predict eye movements <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b22">23]</ref>. Conversely, eye movements have been used to guide meaningful abstractions of photographs <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b24">25]</ref> and volume composition <ref type="bibr" target="#b15">[16]</ref>. Several computational models of visual saliency that model human attention have been developed. Itti et al. <ref type="bibr" target="#b7">[8]</ref> developed a computational model of visual attention based on the center-surround operators in an image. Recently, Lee et al. <ref type="bibr" target="#b13">[14]</ref> have proposed saliency for meshes based on a multi-scale center-surround mechanism that operates on local curvature.</p><p>Once saliency for a volume is computed either by using eyetracking data, or through computational models of human perception, or through feature extraction, it can be used to better inform the visualization process. Machiraju et al. <ref type="bibr" target="#b18">[19]</ref> used feature-based saliency to perform progressive visualization. They first project the volume data into a wavelet basis and identify features at multiple scales. Then, they use the ranked regions of interest in a priority scheduling scheme to progressively visualize the data. Rheingans and Ebert <ref type="bibr" target="#b23">[24]</ref> suggested the idea of importance-based regional enhancement for volume illustration. Their approach involves enhancing a region around a userspecified point of interest using a gradual fall-off function based on the view direction. Viola et al. <ref type="bibr" target="#b28">[29]</ref> developed an innovative importancedriven approach to emphasize features in volumes. Their approach modulates the opacity of a feature based upon its importance as well as the importance of the features that it occludes. This approach has been shown to be very valuable in simultaneously visualizing interior and exterior structures of a volume in clutter-free renderings that show the important regions while suppressing or eliminating the less important regions <ref type="bibr" target="#b1">[2]</ref>. Hauser <ref type="bibr" target="#b4">[5]</ref> suggested emphasizing regions in volumes using opacity, color, frequency (focus), and rendering styles.</p><p>A very interesting beginning in altering saliency to guide viewer attention has been made by Su et al. <ref type="bibr" target="#b26">[27]</ref>. They have developed an elegant post-processing technique to reduce the salience of distracting regions in an image. They alter regional saliency by reducing its texture variation through the use of steerable pyramids and validate their results with eye-tracking-based user studies.</p><p>In this paper we propose a new enhancement operator for emphasizing regions of volumes. Our enhancement operators are based on the idea of reversing the visual saliency computation at multiple scales and we show that they can be used to guide viewer attention. We integrate the application of our enhancement operator to the visualization pipeline through an emphasis field that could be used to modulate luminance and chrominance to enhance visual perception of volume data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW</head><p>Guiding user attention in volume visualization is an important component of the overall visual experience. Visual attention can be achieved by obtrusive methods such as very bright or flashing pixels in the desired region. However, such techniques distract the viewer from adequately exploring other regions of the volume data. Artists and illustrators have long used the principles of visual perception to gently guide viewer's attention to regions and objects that they wished to emphasize. In the preceding section we have provided a summary of several techniques used in volume visualization to emphasize regions. Most emphasis methods involve increasing the perceptual importance of a given region through a Gaussian fall-off function centered at the region of interest. Such Gaussian functions have been used to modulate opacity, luminance, chrominance, and texture detail. In this paper we present a novel saliency-guided enhancement operator based on computational models of visual saliency and show that it is better at drawing visual attention than a Gaussian. The various stages in our approach are shown in <ref type="figure" target="#fig_1">Figure 2</ref> and summarized below.</p><p>Saliency Field. We assume that a saliency value is assigned to each voxel of the volume data. This assignment could be based upon user specification (manual painting), eye-tracking data, or feature computation.</p><p>Enhancement Operator. We introduce a general class of saliencyguided enhancement operators that generate an emphasis field from a saliency field. These operators are based on the center-surround mechanisms at multiple scales and invert the process of the saliency computation at each scale.</p><p>Emphasis Field. Emphasis field is used to guide the modulation of the visual appearance by locally changing luminance or chrominance. Note that since the emphasis field operates independently of the transfer function, its effects on the overall visualization pipeline are complementary to those achieved by transfer functions alone.</p><p>Validation. We would like to have some objective evidence that our saliency-based enhancement operators elicit greater visual attention than the original volume visualization as well as the traditional Gaussian-based enhancement. We have conducted an eye-trackingbased user study to verify the impact of our enhancement operators and report the results of our method in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EMPHASIS FIELD COMPUTATION</head><p>The starting point for our approach is the generation of a saliency field S that defines a value of saliency for every voxel. We assume that the saliency field for each voxel defines its importance on a scale from 0 to 1. Such a saliency field could be specified through a number of methods. The first possibility is to acquire it by recording a user's eye movements when a given volume is shown <ref type="bibr" target="#b15">[16]</ref>. Another possibility is for an illustrator or a domain expert to specify the saliency for one or more voxels <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">29]</ref>. A third possibility is to procedurally detect and rank features in the order of their importance <ref type="bibr" target="#b18">[19]</ref>.</p><p>We would like to define an enhancement operator guided by the saliency field that is used to increase the perceptual importance. For this we start with a computational model of saliency. Itti et al. <ref type="bibr" target="#b7">[8]</ref> have defined saliency using the center-surround mechanism on the non-oriented properties such as intensity and color in an image at multiple scales. Lee et al. <ref type="bibr" target="#b13">[14]</ref> have recently defined mesh saliency using the center-surround mechanism on the mean curvature at each vertex at multiple scales. Since the overall volumetric appearance is a multivariate process, we use the above idea to compute the saliency field on a virtual emphasis field E . The emphasis field can then be used to logically decouple the processes of specifying multi-scale enhancement and achieving it through modulation of various volumetric appearance such as color and opacity. Let a voxel v i be the i-th voxel within a volume V . Then, let S (v i ) and E (v i ) be the saliency value and the emphasis value for a voxel v i , respectively. We define the saliency for a voxel v i using the center-surround mechanism L of the emphasis field E at scale, σ as:</p><formula xml:id="formula_0">S (v i ) = L(E , v i , σ )<label>(1)</label></formula><p>In general, there can be infinitely many solutions for an emphasis field E that will give us a desired value of saliency field S depending on the definition of the center-surround operator L. Let G(E , v i , σ ) be the Gaussian-weighted average of the emphasis field centered at a voxel v i :</p><formula xml:id="formula_1">G(E , v i , σ ) = ∑ v j ∈V E (v j )g(v i , v j , σ )<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">g(v i , v j , σ ) = exp[− v j −v i 2 /(2σ 2 )] ∑ v k ∈V exp[− v k −v i 2 /(2σ 2 )] .</formula><p>We define the center-surround operator at a voxel v i using the Laplacian of the Gaussian-weighted averages as:</p><formula xml:id="formula_3">L(E , v i , σ ) = w 1 G(E , v i , σ ) − w 2 G(E , v i , 2σ )<label>(3)</label></formula><p>where w 1 and w 2 indicate the weights of the Gaussian-weighted averages at a fine and a coarse scale, respectively. Positive weights w 1 and w 2 emphasize the center and de-emphasize the surrounding while negative weights achieve the opposite. In this paper, we have used positive weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Saliency-Enhancement Operator</head><p>Let us reformulate the saliency for a voxel v i using Equations 1-3:</p><formula xml:id="formula_4">S (v i ) = w 1 ∑ v j ∈V E (v j )g(v i , v j , σ ) − w 2 ∑ v j ∈V E (v j )g(v i , v j , 2σ ) = ∑ v j ∈V E (v j ) • c i, j</formula><p>where</p><formula xml:id="formula_5">c i, j = w 1 g(v i , v j , σ )−w 2 g(v i , v j , 2σ</formula><p>). We can express the above as the following system of simultaneous linear equations:</p><formula xml:id="formula_6">    c 1,1 c 1,2 . . . c 1,n c 2,1 c 2,2 . . . c 2,n . . . . . . . . . . . . c n,1 c n,2 . . . c n,n         E (v 1 ) E (v 2 ) . . . E (v n )     =     S (v 1 ) S (v 2 ) . . . S (v n )    </formula><p>This can be rewritten as CE = S which implies E = C −1 S . Thus, given a saliency field S , the enhancement operator C −1 will generate the emphasis field E . There are two parameters that govern the stability of the inversion of the matrix C. The first parameter is the relation between w 1 and w 2 . Using the same values (w 1 = w 2 ) makes the matrix C rank-deficient because the sum of each row is zero. To alleviate the rank-deficiency we use unequal weights: w 1 = 3/4 and w 2 = 1/4. The second parameter is the scale σ and we discuss its effect on the matrix C in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Emphasis Field</head><p>We have defined the enhancement operator C −1 which can generate an appropriate emphasis field for a given saliency field at a scale σ . Just as the saliency computation is based on the center-surround mechanisms at multiple scales, we would like to use enhancement operators at multiple scales σ i . Let E i be the emphasis field at scale σ i . We compute this by applying the enhancement operator C −1 i on the saliency field S . Then, the final emphasis field may be computed as the summation of E i . These steps are illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>For simplicity, we discuss the 1D binary case here. Consider the saliency field that is 1 over a desired emphasis region of length 2r and 0 everywhere else. This is shown in <ref type="figure" target="#fig_2">Figure 3(b)</ref>. We start by applying the enhancement operator C −1 1 at scale σ 1 = ( √ 2/8)r on the saliency field S . We consider a geometric sequence of scales σ</p><formula xml:id="formula_7">i = 2 i−1 • ( √ 2/8)r while σ i ≤ √ 2r</formula><p>. We have observed that the matrix C is well-conditioned for small values of σ that result in a diagonally dominant form. As the value of σ is increased, the matrix C ceases to remain diagonally dominant and in fact becomes close to singular. To address this, we sub-sample the saliency field by factors of r/4 (S 1 ), r/2 (S 2 ), r (S 3 ), etc. and construct the appropriate matrices C i . We then compute E i = C −1 i S i (shown in <ref type="figure" target="#fig_2">Figure 3</ref>(c)) and sum E i to get the overall emphasis field E = ∑ k i=1 E i as shown in <ref type="figure" target="#fig_2">Figure 3(d)</ref>. Note that we super-sample the subsampled fields so that the summation of all emphasis fields is carried out at the original scale.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Emphasis Field in Practice</head><p>A system of simultaneous linear equations in n variables may be solved in time varying from O(kn 2 ) for the Gauss-Seidel method where k is number of iterations to O(n 3 ) for the Gaussian elimination method. For our experiments we were interested in enhancing saliency over regions that ranged in size from n = 128 × 256 × 256 to n = 352 × 352 × 256. This clearly would have been computationally very expensive. To address this, we solve a 1D system of equations over n = 640 and assuming a spherical region of interest (ROI), interpret the results to be along the radial dimension. The 1D solution is shown in <ref type="figure" target="#fig_2">Figure 3(d)</ref> and by the green curve in <ref type="figure" target="#fig_4">Figure 4</ref>(b). Radial functions have been expressed using Gaussians, quadratic and higherdegree polynomials <ref type="bibr" target="#b0">[1]</ref>. Here we use piecewise polynomial radial functions inspired by Wendland <ref type="bibr" target="#b29">[30]</ref> to approximate the results. Our approximating function is shown in <ref type="figure" target="#fig_4">Figure 4</ref>(a) and by the blue curve in <ref type="figure" target="#fig_4">Figure 4(b)</ref>. <ref type="figure" target="#fig_4">Figure 4(c)</ref> shows the Gaussian fall-off function from the boundary of the specified region with σ = r/2. The enhancements generated by this Gaussian are used for the comparisons in Section 5 and 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VISUALIZATION ENHANCEMENT</head><p>Once we have computed the emphasis field we can use it to modulate the various visualization parameters. Here we first discuss changing just one of these parameters -the brightness of a voxel as determined by the Value parameter in the HSV color model. Brightness has been regarded as one of the most important components of color for drawing visual attention. Artists like Rembrandt and Caravaggio have skillfully used luminance contrast to emphasize key regions and characters in a painting. With our saliency-guide enhancement field E (v) at a voxel v, we can easily modulate its brightness value V as: where −λ − ≤ E (v) ≤ λ + . In the current implementation, we have used 0.4 ≤ λ + ≤ 0.6 and 0.15 ≤ λ − ≤ 0.35. <ref type="figure" target="#fig_5">Figure 5</ref> compares the enhancement by a traditional Gaussian operator and by our new saliencyguided enhancement operator on the Visible Male model. Notice that the original image has high brightness regions such as the nose. While the Gaussian operator increases the brightness of the user-specified regions, our saliency-enhancement operator additionally lowers the brightness in the neighborhood. This difference results in a much greater user attention to the desired regions, even with subtle changes to the overall brightness. <ref type="figure" target="#fig_6">Figure 6</ref> shows another comparison on the Engine Block model. Visual saliency can be increased by enhancing color saturation as well as the brightness. In cases where the brightness is already very high, it could be helpful to draw greater visual attention by enhancing color saturation. For instance in <ref type="figure" target="#fig_7">Figure 7</ref>(a) increasing the brightness any further will diminish the appearance of blood vessels at the center of the Sheep Heart. However a simple change in saturation can serve to draw visual attention as shown in <ref type="figure" target="#fig_7">Figure 7</ref>(b). Our technique can increase the overall color saturation in a way similar to what we have outlined above for brightness.</p><formula xml:id="formula_8">V new (v) = V (v) • (1 + E (v)) (a) (b) (c) (d) (e) (f)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">USER STUDY</head><p>We have carried out an eye-tracking-based user study to gather objective evidence of the effectiveness of our approach. Our goal in this user study is to validate our ability to draw a viewer's attention by subtle changes to the appearance of the volume data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Hypothesis</head><p>Our first hypothesis is that the eye fixations increase over the region of interest in a volume by the saliency-guided enhancement compared to the traditional volume visualization. Our second hypothesis is that the eye fixations increase over the region of interest in a volume by the saliency-guided enhancement compared to the Gaussian-based en- hancement. We would like to validate both of the above hypotheses with a visually subtle level of enhancement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Design</head><p>Eye-tracker and General Settings: We have used the ISCAN ETL-500 eye-tracker which can record eye movements continuously at 60 Hz. We carried out the study with 10 subjects that had normal or corrected-to-normal vision and who were not familiar with this work.</p><p>The study was carried out on a 17-inch LCD monitor with a resolution of 1280 × 1024, placed at a distance of 50cm from the subjects. The subjects had a chin rest to minimize head movements and to maintain calibration. Our experimental setup is shown in <ref type="figure" target="#fig_8">Figure 8</ref>.</p><p>Eye-tracker Calibration: The standard calibration of ETL-500 eye tracker was not sufficiently accurate for our purposes due to nonlinearities in the eye-tracker-calibrated screen space. Therefore we have used a two-step calibration process in which the first step is the standard calibration with 5 points on the screen and the second step involves a more densely-sampled calibration phase similar to <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref> with 13 additional points. Our calibration included asking the subjects to successively look at and to click on 13 points presented sequentially on the screen. This gave us an accurate correspondence between the eye-tracker space and the monitor space for that subject. We then triangulated the monitor's screen space using these 13 points and 4 corner points from the first phase calibration. Such a triangulation allowed us to accurately get a position on the monitor by interpolating inside the triangle where the subject was looking. After this we tested the accuracy of the calibration by asking the subjects to look at 16 randomly selected points on the screen. Of the 14 subjects who volunteered for this study, 10 were able to successfully calibrate to within the desired accuracy of 30 pixels for each of the 16 points. We proceeded with our study using these 10 subjects.</p><p>Duration: The user study had 12 trials (images). Each trial started with the subject seeing a blank screen with a cross at the center of the screen. The subject was asked to look at the cross before clicking the mouse to bring up the next image. This ensured that each trial started with the subject's eyes fixated at the center of the image. Each image was shown for 5 seconds. Each study took about 80 seconds. Subjects were told to freely view the images with no assigned goal and were informed in advance about the design of each trial including the duration each image would be shown and the total number of images.</p><p>Image Ordering: There were a total of 20 images used in all the experiments (they are in the supplemental materials for this paper). Each image set consists of one original image and four enhanced images in which one of two regions is enhanced by either a Gaussian or our saliency enhancement. We have used the volume datasets of the Engine Block, the Foot, the Visible Male, and the Sheep Heart model for our study. Each user saw 12 images out of these 20 images. When we ordered the images for each user, we considered differential carryover effects and the counter-balancing problem for the pairwise analysis on the results. First, we placed similar images far apart to alleviate differential carryover. At the same time, we did not place the similar images in perfectly regular manner so that a user could not guess what image will be shown next. Alleviating differential carryover effect had the highest priority in our ordering because a user is supposed to look at 3 similar images (original, enhancement on two different regions) for each model. Second, each user looked at two images where we enhanced different regions with different types of operators (Gaussian-based and Saliency-guided). Finally, we randomized the order of regions and the order of enhancement types (Gaussian and saliency-based) to counterbalance overall effects.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Data Analysis</head><p>The results of our study are shown in <ref type="figure" target="#fig_9">Figure 9</ref>. Each grouping of bars shows the percentage of fixations that fell in a desired region for the unaltered, Gaussian-enhanced, and Saliency-enhanced visualizations for a specific model and region on that model. First, we analyzed the effects of each enhancement technique on two different regions for each model. We have analyzed the differences in fixations between the first region and the second region of each model for the three cases -(a) unaltered, original visualization, (b) first region is enhanced, and (c) second region is enhanced. We carried out pairwise t-tests with the assumption that each region of interest occupies the same number of image pixels and has a similar percentage of fixations in the original model. This assumption did not hold for the Engine Block model since one region turned out to be brighter than the other. Also, it did not hold for the Sheep Heart model since one region was closer to the center and drew greater fixations <ref type="bibr" target="#b20">[21]</ref>. Therefore, we did not include these two in <ref type="table">Table 1</ref>. As the results show, we did not observe significant differences in the percentage of fixations when a region was enhanced by the Gaussian-based method in any of cases. However, we can clearly observe significant differences in all cases when a region is enhanced by the Saliencyguided method.</p><p>We next carried out a pairwise t-test on the percentage of fixations before and after we apply enhancement techniques for each model (this is the only condition in the test). <ref type="table">Table 2</ref> shows the results from all the models. We found a significant difference in the percentage of fixations when we applied saliency-guided enhancement for all the models. There was a difference for the percentage of fixations when we applied Gaussian-based enhancement for all the models other than the Visible Male model. When the results from each region alone in Visible Male and Sheep Heart were analyzed by pairwise t-tests with saliency-guided technique condition, there also was a significant effect, (t-value=-7.35, p=0.002 for Visible Male). However for the Engine Block and the Foot model, there was only a borderline significant effect by saliencyguided technique. We can only observe a significant effect when the results from each region alone in Sheep Heart were analyzed with Gaussian-based technique. We think that this is due to the small number of observations. We believe those results would also be significant if there were more participants because there was a clear trend show- ing an improvement on all models in <ref type="figure" target="#fig_9">Figure 9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS AND FUTURE WORK</head><p>We have proposed a saliency-based enhancement of volume visualization and successfully validated its ability to elicit viewer attention. Our model is inspired by the center-surround mechanisms of the human visual system. We have found that it is more successful at eliciting viewer attention than the traditional Gaussian regional enhancement approach. Saliency-guided enhancement for volume visualization can be helpful in several contexts. For instance, our approach could be used in helping users navigate through complex volumetric datasets and facilitating their understanding by guiding their attention to regions and objects selected by a domain expert. It will also be interesting to examine the applicability of this approach for exploratory visualization systems that rely on automated and fuzzy detection of features. Such systems could use saliency-based perceptual enhancement to generate a variable level of perceptual interest to the human observer. At present we have explored saliency-guided alteration of brightness and color saturation for volumes. In future we plan to also explore the implications of this framework for other appearance attributes such as opacity and texture detail. Our approach at this time has been validated only on static volumetric scalar field datasets. It will be interesting to generalize it further to be able to handle timevarying datasets with multiple superposed scalar and vector fields. Our current method has been validated on spherical regions of interest and binary-valued saliency field. Generating an emphasis field from an arbitrary-shaped region with general saliency values will be considered in the future. At this time we do not have any evidence if our approach can actually enhance the comprehensibility of the volume rendered images. We will like to further study this in the future. Visual saliency is very sensitive to scale. Identifying the appropriate scales and their relative importance is another valuable area for future research in guiding visual attention.</p><p>helped in improving the presentation of ideas in this paper. This work has been supported in part by the NSF grants: IIS 04-14699, CCF 04-29753, CNS 04-03313, and CCF 05-41120. <ref type="figure" target="#fig_0">Fig. 10</ref>. Parts of images used in the user study. The first column shows the saliency fields, the spherical regions of interest (ROI) marked in red. We also show the size of each volume dataset, the center of ROI, the radius of ROI, and each of weights, λ + and λ − used for enhancements above each saliency field image. The second column shows the traditional volume rendering. The third column shows the visualization with value enhancement in HSV color model based on the Gaussian-based enhancement while the fourth column shows the visualization with value enhancement based on our saliency-guided enhancement. All the images and their saliency fields used in the user study can be found in the supplemental material in the DVD-ROM and on the web site http://www.cs.umd.edu/gvil/projects/sevv.shtml.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Saliency-guided Enhancement for Volume Visualization: Image (a) shows the traditional volume visualization and image (b) shows the result of applying our saliency-guided enhancement operator to the mouth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>(a) The traditional visualization pipeline. (b) Saliency-enhanced visualization pipeline. The saliency field is modified by the enhancement operator to generate an emphasis field. The emphasis field is used to enhance the perception of features in volume by modulating appearance attributes such as luminance, chrominance, and texture detail.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Enhancement operator at scale σ i is denoted by C −1 i in (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure (b)shows an example of saliency field with a desired emphasis region of length 2r. The application of enhancement operator C −1 i on saliency field S gives an emphasis field E i in (c). Multi-scale summation of emphasis fields E i generates the overall emphasis field E in (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Saliency-guided emphasis field. Here r denotes the radius of the user-specified region. Figure (a) shows the emphasis field approximated by a piecewise polynomial function. Figure (b) shows the emphasis field generated by multi-scale summation of emphasis fields in green and the approximation of it in blue with λ + = 2.34 and λ − = 0.28 for comparison.Figure (c)shows the Gaussian that is used for enhancement for results inFigure 10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>The Visible Male model (128 × 256 × 256) is rendered by the traditional volume visualization in image (a). Images (b) and (c) show the visualization with regional enhancement by a Gaussian and our saliencyguided operator, respectively. User-specified spherical region of interest is shown in red in image (d) with a radius r = 20. Image (e) shows the Gaussian enhancement with σ = 10. Image (f) shows the emphasis field based on our method. The emphasis field value changes from λ + (= 0.4) to 0 to −λ − (= −0.15) are represented by the color changes from red to black to blue. The radii of the spherical regions affected by the Gaussian-based and our method are 40 and 60, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>The Engine Block model (256 × 256 × 256). Except for λ + = 0.55 and λ − = 0.35, the meanings of colors and the parameters are the same as inFigure 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>Saturation enhancement for the Sheep Heart and the Foot models. Images (a) and (c) show the tranditional volume visualization. Images (b) and (d) show the visualization with color saturation enhancement based on our saliency-guided enhancement operator applied on the blood vessels at the center and the fourth toe, respectively in each model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Our experimental setup for the user study with the ISCAN ETL-500 eye-tracker.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 9 .</head><label>9</label><figDesc>Fixation results for volume visualization enhancements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Pairwise t-tests on the 1st and the 2nd Areas of Interest. List of pairwise t-tests.</figDesc><table><row><cell cols="2">Model Condition</cell><cell cols="2">t-Value p-Value</cell></row><row><cell>Foot</cell><cell>No Change</cell><cell>0.312</cell><cell>0.762</cell></row><row><cell></cell><cell>Region1 enhanced by Gaussian</cell><cell>1.35</cell><cell>0.248</cell></row><row><cell></cell><cell>Region1 enhanced by Saliency</cell><cell>2.74</cell><cell>0.052</cell></row><row><cell cols="2">Region2 enhanced by Gaussian Region2 enhanced by Saliency Visible No Change</cell><cell>−0.68 −2.96 0.959</cell><cell>0.534 0.042 0.363</cell></row><row><cell>Male</cell><cell>Region1 enhanced by Gaussian</cell><cell>1.34</cell><cell>0.25</cell></row><row><cell></cell><cell>Region1 enhanced by Saliency</cell><cell>4.39</cell><cell>0.012</cell></row><row><cell></cell><cell>Region2 enhanced by Gaussian Region2 enhanced by Saliency</cell><cell>−0.57 −5.82</cell><cell>0.601 0.004</cell></row><row><cell cols="2">Model Condition: No Change vs.</cell><cell>t-Value</cell><cell>p-Value</cell></row><row><cell cols="2">Engine Gaussian-based enhancement Block Saliency-guided enhancement Foot Gaussian-based enhancement Saliency-guided enhancement Visible Gaussian-based enhancement Male Saliency-guided enhancement Sheep Gaussian-based enhancement Heart Saliency-guided enhancement</cell><cell>−2.36 −2.86 −2.67 −3.34 −0.661 −6.65 −3.86 −4.49</cell><cell>0.042 0.019 0.026 0.009 0.525 &lt; 0.001 0.005 0.002</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We would like to thank the anonymous referees for their exceptionally thorough reviews and valuable suggestions. We will thank Stefan Roettger and Dirk Bartz for providing us with volumetric datasets. We would also like to acknowledge David Jacobs and François Guimbretière for valuable discussions. Derek Juba and Robert Patro have</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Introduction to Implicit Surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bloomenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blinn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-P</forename><surname>Cani-Gascuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rockwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wyvill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wyvill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Illustrative contextpreserving volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EuroVis 2005</title>
		<meeting>EuroVis 2005</meeting>
		<imprint>
			<date type="published" when="2005-05" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Line drawings from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klawe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics (SIGGRAPH</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2005-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stylization and abstraction of photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decarlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="769" to="776" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalizing focus+context visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dagstuhl Conference on Scientific Visualization: Extracting Information and Knowledge from Scientific Datasets</title>
		<editor>G. M. N. G.-P. Bonneau, T. Ertl</editor>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="305" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Conveying the 3D shape of smoothly curving transparent surfaces via texture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="117" />
			<date type="published" when="1997-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Visualizing 3D flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grosch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="49" to="53" />
			<date type="published" when="1998-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A model of saliency-based visual attention for rapid scene analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Niebur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1254" to="1259" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>IEEE Society Press</publisher>
			<pubPlace>Los Alamitos, CA</pubPlace>
		</imprint>
	</monogr>
	<note>tutorial</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semi-automatic generation of transfer functions for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Durkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Volume Rendering Proceedings</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Curvaturebased transfer functions for direct volume rendering: Methods and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multidimensional transfer functions for interactive volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gaussian transfer functions for multi-field volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Premoze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ikits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Lefohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Praun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="497" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mesh saliency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics (Procs. ACM SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="659" to="666" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Volume composition using eye tracking data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics/IEEE VGTC Symposium on Visualization</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Nonphotorealistic volume rendering using stippling techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lighting transfer functions using gradient aligned sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evita: Efficient visualization and interrogation of tera-scale data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Soni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining for Scientific and Eng. Applications</title>
		<imprint>
			<biblScope unit="page" from="257" to="279" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Vision Science: Photons to Phenomenology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Modeling the role of salience in the allocation of overt visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parkhurst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Niebur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="123" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The transfer function bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="16" to="22" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Algorithms for defining visual regionsof-interest: Comparison with eye fixations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Privitera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Stark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intellignece</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="970" to="982" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Volume illustration: Nonphotorealistic rendering of volume models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="264" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual interest and NPR: an evaluation and manifesto</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NPAR</title>
		<meeting>NPAR</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="71" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Heuristic filtering and reliable calibration methods for videobased pupil tracking systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stampe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments and Computers</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="137" to="142" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">De-emphasis of distracting image regions using texture power maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Texture 2005: Procs. 4th IEEE International Workshop on Texture Analysis and Synthesis in conjunction with ICCV&apos;05</title>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="119" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pen-and-ink rendering in volume visualisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M F</forename><surname>Treavett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Visualization</title>
		<meeting>Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="203" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Importance-driven feature enhancement in volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="408" to="418" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Piecewise polynomial, positive definite and compactly supported radial functions of minimal degree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wendland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Computational Mathematics</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="389" to="396" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
