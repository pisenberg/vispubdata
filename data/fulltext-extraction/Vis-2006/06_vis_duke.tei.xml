<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fine-grained Visualization Pipelines and Lazy Functional Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duke</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><surname>Wallace</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Borgo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Runciman</surname></persName>
						</author>
						<title level="a" type="main">Fine-grained Visualization Pipelines and Lazy Functional Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>The pipeline model in visualization has evolved from a conceptual model of data processing into a widely used architecture for implementing visualization systems. In the process, a number of capabilities have been introduced, including streaming of data in chunks, distributed pipelines, and demand-driven processing. Visualization systems have invariably built on stateful programming technologies, and these capabilities have had to be implemented explicitly within the lower layers of a complex hierarchy of services. The good news for developers is that applications built on top of this hierarchy can access these capabilities without concern for how they are implemented. The bad news is that by freezing capabilities into low-level services expressive power and flexibility is lost. In this paper we express visualization systems in a programming language that more naturally supports this kind of processing model. Lazy functional languages support fine-grained demand-driven processing, a natural form of streaming, and pipeline-like function composition for assembling applications. The technology thus appears well suited to visualization applications. Using surface extraction algorithms as illustrative examples, and the lazy functional language Haskell, we argue the benefits of clear and concise expression combined with fine-grained, demand-driven computation. Just as visualization provides insight into data, functional abstraction provides new insight into visualization.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A number of architectures have been proposed and developed for data visualization, including spreadsheets <ref type="bibr" target="#b16">[17]</ref>, relational databases <ref type="bibr" target="#b22">[23]</ref>, spray-rendering <ref type="bibr" target="#b23">[24]</ref>, scene graphs <ref type="bibr" target="#b21">[22]</ref>, and pipelines <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b27">28]</ref>. They provide a layer of application-oriented services on which problemspecific visualization tools can be constructed. Of the approaches explored to date, the pipeline model has found the most widespread use. It underlies the implementation of well-known systems such as AVS <ref type="bibr" target="#b27">[28]</ref>, SCIRun <ref type="bibr" target="#b24">[25]</ref>, and VTK <ref type="bibr" target="#b25">[26]</ref>, and also serves as a conceptual model for visualization workflow <ref type="bibr" target="#b5">[6]</ref>.</p><p>Building layers of service abstraction is an approach that has served computing well in the past, giving developers reusable domainindependent blocks for building an application. For the pipeline model, services provide the capability to organize visualization operations within a dataflow-like network. Some pipelined systems extend the basic model with demand-driven evaluation and streaming of dataset chunks, again frozen into the service layer. However, this layered approach fixes design decisions associated with the services, without regard for the operations that are implemented in terms of those services. Pipeline services provide a lazy, dataflow-like model, but client operations are defined as a separate layer of stateful computation.</p><p>An alternative set out in this paper is to use a programming technology that naturally supports operations fundamental to pipelined visualization. Implementations of 'lazy' functional languages have advanced significantly over the last decade. They now have welldeveloped interfaces to low-level services such as graphics and I/O. In this paper we take surfacing as an archetypal visualization task, and reconstruct two fundamental algorithms. We illustrate how pipelining and demand-driven evaluation become naturally integrated within the expression of an algorithm. The result is a simplified presentation, generating fresh insight into how these algorithms are related. The resulting implementations have a pattern of space utilization quite different to their imperative counterparts, occupying an intermediate point between purely in-core and out-of-core approaches. Section 2 summarizes the main features of the pipeline model, in particular the capabilities that we seek to improve. Section 3 revisits the basic marching cubes algorithm for surface extraction, using the lazy functional language Haskell <ref type="bibr" target="#b13">[14]</ref>. Through a series of refinements, we show how pipelining and demand-driven evaluation allow the use of memoization to improve performance. An extension to resolve topological ambiguities <ref type="bibr" target="#b17">[18]</ref> in Section 4 shows how these finegrained abstractions can be reused. Section 5, on evaluation, gives particular attention to the space performance of our implementation. The lazy streaming approach set out here features low memory residency, even with larger datasets. Section 6 discusses related research. The work reported here is a first step in a much larger programme of work, and in Section 7 we set out a longer-term vision of how functional programming can contribute novel ways of solving the technical challenges of visualization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PIPELINES: PLUMBING FOR VISUALIZATION</head><p>Pipelines as a conceptual model for the visualization process were first proposed by Haber and McNabb <ref type="bibr" target="#b5">[6]</ref>. Their use for implementing visualization is usually traced to the work of Upson et.al. <ref type="bibr" target="#b27">[28]</ref> on AVS; they in turn cite the earlier work of Haeberli <ref type="bibr" target="#b6">[7]</ref> on the ConMan dataflow system for interactive graphics. All these models represent the visualization process as a directed graph. Nodes are processing elements; arcs represent data dependencies: an arc from component A to B means the output of A is required in order for B to execute. Importantly, this can also be expressed by saying that if B needs to execute, it must first ensure it has up-to-date data from A. In this way, a visualization application can be considered as a demand-driven dataflow system, with update demands on graphics windows at the end of the pipeline "pulling" the data through intermediate transformations. The pipeline originates at source components, typically interfaces to the external environment.</p><p>Pipelined systems often provide memoization: computed outputs are stored, and only regenerated when there is a change to some parameter of the component used to produce them. For each component there is usually a choice whether to retain its output or regenerate it each time it is required; the trade-off is between memory use and computation time. <ref type="figure">Figure 1</ref> shows a simple pipeline with four components, each retaining its output: a file reader, an isosurfacer, a filter to compute polygon normals, and a mapper which renders the polygons to a display. Three of the components have parameters. If any parameter is changed, some or all of the pipeline may need to re-execute. In the example, changes to the viewing parameters require only the mapper to re-execute, but if the user adjusts the isosurface threshold, the isosurfacer, normals filter and mapper all need to re-execute, in that order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Isosurfacing Pipeline</head><p>There are different approaches to managing pipeline execution. Systems such as IRIS Explorer employ a central executive to monitor the state of components and decide which to re-execute in response to a parameter change. VTK, in contrast, implements a decentralized model 1 where components and data are timestamped, and an update request at one part of the pipeline triggers 'upstream' components to execute only if their data needs to be regenerated. Relative merits of these schemes are discussed in <ref type="bibr" target="#b25">[26]</ref>.</p><p>Streaming <ref type="bibr" target="#b15">[16]</ref> is an enrichment to the basic model that allows a pipeline to pass datasets in chunks. For scientific data, such chunks are usually spatially contiguous subsets of the full extent. Some algorithms, for example Marching Cubes <ref type="bibr" target="#b18">[19]</ref>, can operate on individual chunks in isolation. Others require access to the full dataset, for example surface reconstruction: the dataset may be passed as a sequence of chunks, with downstream and upstream algorithms working on these sequences. In between the extremes of full-dataset versus arbitrary chunk are algorithms such as Gaussian smoothing which require only some overlap between adjacent chunks; this requirement is handled in VTK, for example, by the use of 'ghost' points within chunks.</p><p>While pipeline capabilities have advanced, both the services and the algorithms that use those services continue to be implemented using imperative languages, usually C or C++. The underlying computational model is call-by-value parameter-passing, yet the way to assemble applications from services is conceptually call-by-need. In contrast, non-strict functional languages such as Haskell <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b8">9]</ref> use a call-by-need evaluation strategy in which function arguments are only evaluated to the extent they are demanded (if at all). Apart from closely matching the pipeline model, this strategy also provides a 'new kind of glue' <ref type="bibr" target="#b9">[10]</ref> for assembling programs from components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MARCHING CUBES, FUNCTIONALLY</head><p>Without giving a full tutorial on Haskell, we need to introduce some key aspects of functional languages, for which we use the classic Marching Cubes algorithm as an exemplar. We first implement it in the standard fashion, iterating through an array of sample values, then refine the implementation into two lazily streaming variations. These illustrate two of the main benefits of laziness -on-demand processing (permitting fine-grained pipelining of input and output data), and automatic sharing of already-computed results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ordinary, array-based algorithm.</head><p>First, we explore a straightforward representation of the dataset as a three-dimensional array of sample values.</p><p>type XYZ = (Int,Int,Int) type Num a =&gt; Dataset a = Array XYZ a These type definitions declare synonyms for the actual array representation. Concrete type names are capitalised, for instance the Array index domain type is XYZ. The array is 0-based; its first element is at index (0,0,0). The type variable (lower-case a) in the range of the array indicates that the type of the samples themselves is generic (polymorphic). The predicate Num a constrains the polymorphism: samples must have arithmetic operations defined over them. Thus, we can reuse the algorithm with bytes, signed words, floats, complex numbers, and so on, without change.</p><p>isosurface ::</p><p>Num a =&gt; a -&gt; Dataset a -&gt; <ref type="bibr">[Triangle]</ref> This type declaration of the Marching Cubes isosurface function shows that it takes two arguments, a threshold value and the dataset, and computes from them a sequence of triangles approximating the surface. The triangles can be fed directly into e.g. OpenGL for rendering. The full pipeline shown in <ref type="figure">Figure 1</ref> can be written: 2 pipeline t = mapper view . normalize . isosurface t . reader</p><p>Here the dot . operator means pipelined composition of functions. The last function in the chain is applied to some input (a filename), and its results are fed back to the previous function, whose results are fed back, and so on. The backward direction is just convention -it is equally easy to write forward-composition in the style of unix shell pipes, just less common.</p><p>Now to the algorithm itself. We assume the classic table, either hard-coded or generated by the Haskell compiler from some specification. Full details of these tables are not vital to the presentation and are omitted; see <ref type="bibr" target="#b18">[19]</ref> for example.</p><formula xml:id="formula_0">mcCaseTable = { 0 |-&gt; [] , 1 |-&gt; [0,8,3] , 3 |-&gt; [1,8,3,9,8,1] ... , 254 |-&gt; [0,3,8] , 255 |-&gt; [] }</formula><p>Marching Cubes iterates through the dataset from the origin. At every cell it considers whether each of the eight vertices is below or above the threshold, treating this 8-tuple of Booleans as a byte-index into the case table. Having selected from the table which edges have the surface passing through them, we then interpolate the position of the cut point on each edge, and group these points into threes as triangles, adding in the absolute position of the cell on the underlying grid.</p><formula xml:id="formula_1">isosurface threshold sampleArray = concat [ mcube threshold lookup (i,j,k) | k &lt;-[1 .. ksz-1] , j &lt;-[1 .. jsz-1] , i &lt;-[1 .. isz-1] ] where</formula><p>(isz,jsz,ksz) = rangeSize sampleArray lookup xyz = eightFrom sampleArray xyz</p><p>In Haskell, application of a function to arguments is by juxtaposition -no parentheses are needed -so in the definition of isosurface, the arguments are threshold and sampleArray. The standard array function rangeSize extracts the maximum coordinates of the grid.</p><p>The larger expression in square brackets is a list comprehension 3 , and denotes the sequence of all applications of the function mcube to some arguments, where the variables (i,j,k) range over (or are drawn from) the given enumerations. The enumerators are separated from the main expression by a vertical bar, and the evaluation order causes the final variable i to vary most rapidly. This detail is of interest mainly to ensure good cache behaviour, if the array is stored with xdimension first. The comprehension can be viewed as equivalent to nested loops in imperative languages.</p><p>The result of computing mcube over any single cell is a sequence of triangles. These per-cube sequences are concatenated into a single global sequence, by the standard function concat.</p><p>Now we look more closely at the data structure representing an individual cell. For a regular cubic grid, this is just an 8-tuple of values from the full array.</p><p>type Cell a = (a,a,a,a,a,a,a,a) eightFrom :: Array XYZ a -&gt; XYZ -&gt; Cell a eightFrom arr (x,y,z) = ( arr!(x,y,z),</p><formula xml:id="formula_2">arr!(x+1,y,z) , arr!(x+1,y+1,z), arr!(x,y+1,z) , arr!(x,y,z+1), arr!(x+1,y,z+1) , arr!(x+1,y+1,z+1), arr!(x,y+1,z+1) )</formula><p>Next, we need to introduce higher-order functions. From the very name "functional language" one can surely guess that functions are important. Indeed, passing functions as arguments, and receiving functions as results, comes entirely naturally. A function that receives or returns a function is called higher-order. We have seen two examples thus far: mcube's second argument is the function lookup, but also, the composition operator . is just a higher-order function as well. Since this operator is the essence of the pipeline model, let's look briefly at its definition:</p><formula xml:id="formula_3">(.) :: (b-&gt;c) -&gt; (a-&gt;b) -&gt; a -&gt; c (f . g) x = f (g x)</formula><p>Dot takes two functions as arguments, with a third argument being the initial data. The result of applying the second function to the data is used as the argument to the first function. The type signature should help to make this clear -each type variable, a, b, and c, stands for any arbitrary (polymorphic) type, where for instance each occurrence of a must be the same, but a and b may be different. Longer chains of these compositions can be built up, as we have already seen in the earlier definition of pipeline.</p><p>Shortly, we will need another common higher-order function, map, which takes a function f and applies it to every element of a sequence: The cell of vertex sample values is found using the lookup function that has been passed in. We derive an 8-tuple of booleans by comparing each sample with the threshold (map8 is a higher-order function like map, only over a fixed-size tuple rather than an arbitrary sequence), then convert the 8 booleans to a byte (bools) to index into the classic case table (mcCaseTable).</p><p>The result of indexing the table is the sequence of edges cut by the surface. Using map, we perform the interpolation calculation for every one of those edges, and finally group those interpolated points into triples as the vertices of triangles to be rendered; group3 is used again in later steps, and hence is defined globally. The linear interpolation is standard: Although interpolate takes four arguments, it was initially applied to only three in mcube. This illustrates another important higher-order technique: a function of n arguments can be partially applied to its first k arguments; the result is a specialised function of n−k arguments, with the already-supplied values 'frozen in'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Observations.</head><p>The implementation outlined so far is naive in several respects: <ref type="bibr" target="#b0">(1)</ref> The entire dataset is needed in memory before we can begin any processing. (2) The work of comparing a vertex to the threshold value is repeated eight times, once for every cell it adjoins. (3) The work of interpolating along an edge is repeated if we revisit the same edge again within that cell. (4) The same interpolation calculation is repeated again when we visit the three neighbouring cells that share the same edge. The following sections address these issues in turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Streaming the dataset on-demand.</head><p>The monolithic array data structure implies that the entire dataset is in memory simultaneously, yet the algorithm only ever needs a small portion of the dataset. At any one moment, a single point and 7 of its neighbours suffices, making up a unit cube of sample values. If we compare this with a typical array or file storage format for regular grids (essentially a linear sequence of samples), then the unit cube is entirely contained within a "window" of the file, corresponding to exactly one plane + line + sample of the volume. The ideal solution is to slide this window over the file, constructing one unit cube on each iteration, and dropping the previous unit cube. <ref type="figure" target="#fig_3">Figure 2</ref> illustrates the idea. Haskell allows us to read data out of a file in this streamed fashion using lazy file I/O. The content of the file appears to the program as a sequence of bytes, extended on-demand one byte at a time. <ref type="bibr" target="#b3">4</ref> As for dropping data after it has been consumed, Haskell is a garbagecollected language, so when a datum is no longer referenced by the computation, the memory storing it is recycled automatically.</p><p>The datatype representing the dataset is now constructed from a lazy sequence of samples, stored along with the bounds of the grid:</p><p>data Num a =&gt; Dataset a = D XYZ [a]</p><p>Unlike the type definition, which only introduces a synonym, a data definition in Haskell can be thought of as a record, tagged with a constructor name (D) that can be used in pattern matching. <ref type="bibr" target="#b4">5</ref> The sliding window of eight point values (cell) is extracted from the lazy stream of samples as follows. We (conceptually) lay 8 copies of the datastream side-by-side, then repeatedly slice off one value from each of the 8 and glue them together into a cell. Each of the 8 copies of the stream is advanced on its predecessor by an offset representing the distance between the sample points in the original data stream. In Haskell, the zip family of functions (here, zip8) is used to turn a tuple-of-streams into a stream-of-tuples. <ref type="figure">(</ref> As written, mkStream generates 'phantom' cells that wrap around the boundaries of the dataset, at the end of each line and plane. Rather than trying to 'fix' mkStream, we insert another small function in the pipeline to eliminate the phantoms. The function disContinuities recursively copies items from its input stream to its output stream, but drops items whenever the counter reaches a boundary.</p><formula xml:id="formula_4">disContinuities :: XYZ -&gt; [b] -&gt; [b] disContinuities (isz,jsz,ksz) = step (0,0,0) where step (i,j,k) (x:xs) | i==(isz-1) = step (0,j+1,k) xs | j==(jsz-1) = step (0,0,k+1) (drop (isz-1) xs) | k==(ksz-1) = [] | otherwise = x : step (i+1,j,k) xs</formula><p>The vertical bars in this definition introduce guarded equations; given a function of the form f a | p = e, the call f v evaluates to e provided v matches the pattern a and the expression p evaluates to True. Multiple guards are tried from top to bottom until one succeeds.</p><p>By glueing the generating and pruning processes together with functional composition, we achieve our aim of transforming a lazy stream of samples from the file into a lazy stream of cells, also extended only on demand. The top-level function for isosurfacing becomes:</p><p>isosurfaceS thresh (D size samples) = concat (zipWith2 (mcubeS thresh) (cellStr samples) allXYZ ) where cellStr = disContinuities size . mkStream</p><formula xml:id="formula_5">allXYZ = [ (i,j,k) | k &lt;-[1 .. ksz-1] , j &lt;-[1 .. jsz-1] , i &lt;-[1 .. isz-1] ]</formula><p>The standard zipWith2 higher-order function is like map, but its function argument is iteratively applied to two items, pulled simultaneously from the front of its stream arguments. The zipWith family thus ensures that multiple streams are consumed at the same rate.</p><p>A feature of this example is the clean separation between generating a list of cells, and dealing with discontinuities. By separating these concerns, the individual functions are simplified. As they are smaller and more generic, they present more opportunity for reuse. The apparent inefficiency of computing 'phantom' cells only to discard them in the next step is eliminated through compiler optimization <ref type="bibr" target="#b26">[27]</ref>. Note that the new function mcubeS is now slightly different from the previous mcube. The advantage of call-by-need over call-by-name is that although the evaluation of an item might be delayed until it is needed, it is never repeated, no matter how often the value is used. If we want to share a computation between different parts of the program, we just arrange for the shared value to be constructed in one place, by one expression, rather than constructing it multiple times which leads to multiple evaluations.</p><p>In the streaming version of marching cubes presented so far, we can see that the reading of sample values from file is shared and performed only once. However, comparison against the threshold value (in mcubeS) is performed eight times for every sample, because on each occasion, the sample is at a different vertex position in the cell. To compute the comparison only once per sample, we just need to do the thresholding against the original byte stream, before it is tupled up into cells, rather than after. There are now three streams of incoming data to be consumed by mcubeT: the cells for interpolation, the indexes into the case table, and the co-ordinates. Note how the idxStream is itself built using smaller pipelines. The consumer mcubeT is now even simpler:</p><p>mcubeT :: a -&gt; Cell a -&gt; Byte -&gt; XYZ -&gt; [Triangle] mcubeT th cell index (x,y,z) = group3 (map (interpolate th cell (x,y,z)) (mcCaseTable ! index))</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Sharing the edge interpolation calculation.</head><p>Taking the notion of sharing-by-construction one step further, we now memoize the interpolation of edges. Recall that, in the result of the mcCaseTable, the sequence of edges through which the isosurface passes may have repeats, because the same edge belongs to more than one triangle of the approximated surface. But in general, an edge that is incident on the isosurface is also common to four separate cells, and we would like to share the interpolation calculation with those cells too. So, just as the threshold calculation was performed at an outer level, on the original datastream, we can do something similar here.</p><p>Instead of an 8-tuple of vertices, we build a 12-tuple of possible edges. Before looking up the case table in mcubeI, we cannot know which of those edges are actually incident on the surface. But that does not matter -we describe how to calculate the interpolation on all 12 edges, safe in the knowledge that each result will only be computed if that edge is actually needed! type CellEdge <ref type="figure">a = (a,a,a,a,a,a,a,a,a,a,a</ref> Here, the datastream is offset in each of the x, y, and z dimensions, zipped with the original copy, and the interpolation calculated pairwise in each dimension. The three dimensions are then zipped together, taking four edges from each, to make up each cell.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">UNAMBIGUOUS MARCHING CUBES</head><p>It is well-known that in the original marching cubes, ambiguous cases can occur, and the original method has been enhanced and generalized in various ways to assure topological correctness of the result. Chernyaev <ref type="bibr" target="#b3">[4]</ref> proposed a definitive classification of all the ambiguous cases. Lewiner et.al. <ref type="bibr" target="#b17">[18]</ref> completed the resolution of internal ambiguities, and defined a method, 'MC33', guaranteed to yield a manifold surface with no cracks between or within cubes. Although MC33 requires a more extensive set of test/case tables than the original algorithm, changes to the top level structure of the functional implementation are surprisingly small; at the top level, we have simply added, as a fourth stream, the original cells of samples (used to resolve ambiguities), to the streams of ready-interpolated edges, case- The mcubeU function differs from mcubeT in only two ways. (1) It uses a different two-stage case-table to look up the edges incident on the surface, of which the tiling stage occasionally needs the original sample cell to test for face-cracks. <ref type="formula">2</ref>The edges returned now include a distinguished marker to signal the need for tri-linear interpolation to resolve internal ambiguity. A simple auxiliary function detects the marker, or otherwise just picks the corresponding edge from the edge stream.  <ref type="figure">Figures 3 and 4</ref> show the 'fuel' and 'neghip' datasets, surfaced using our functional implementation. Triangles are coloured as a function of the point within the output stream at which they arrive, and the figures thus show how the streaming implementation progresses through the dataset (compare with <ref type="figure" target="#fig_3">Figure 2</ref>). In the remainder of this section the functional approach is evaluated against three criteria: time and space performance, requirements for data streaming <ref type="bibr" target="#b15">[16]</ref>, and the issue of clarity and economy of expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Time and Space Profiles</head><p>Performance numbers are given for the initial array-based version, and an optimised streaming version of marching cubes written in Haskell, over a range of sizes of dataset (all taken from volvis.org), and compared with VTK 5's marching cubes implementation in C++. The relevant characteristics of the datasets are summarised in <ref type="table" target="#tab_3">Table 1</ref>, where the streaming window size is calculated in bytes as one  plane+line+1, and the size of the extracted surface is measured in vertices. <ref type="table" target="#tab_4">Table 2</ref> gives the absolute time taken to compute an isosurface at threshold value 20 for every dataset, on a 2.3GHz Macintosh G5 with 2Gb of memory, compiled with the ghc compiler and -O2 optimization. We also normalise time against dataset size, giving the average number of microseconds expended per sample. <ref type="table" target="#tab_5">Table 3</ref> shows the peak live memory usage of each version of the algorithm, as determined by heap profiling. Again, we normalise the absolute numbers against the size of the dataset required in memory at any one time. For the VTK and array-based versions, this is the entire dataset, whilst for the streaming version, it is the (much smaller) window size.</p><p>The time performance in Haskell (both array-based and streaming versions) scales linearly with the size of dataset. It can also be seen that the memory performance is exactly proportional to the size of the input (array) or sliding window (streaming). In contrast, the VTK results, both time and memory, are more proportionally weighted to the size of the output surface, than the input.</p><p>Although for smaller datasets, our current speeds do not compare well with VTK, the clear and readable specification of the algorithms was our main aim. Elegant Haskell is not necessarily efficient Haskell! But, due to referential transparency and equational reasoning, it is possible to apply formal transformations that preserve the code's semantics whilst improving its runtime performance. Some improvement techniques that achieve speeds within 2-3× of C code, may currently be applied manually <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b1">2]</ref>, whilst research continues in generalizing similar transformations to be applied automatically during the optimization stage of the compiler <ref type="bibr" target="#b26">[27]</ref>. This approach promises (eventually) to allow elegance to co-exist with efficiency. Even without these possible performance improvements, it is clear that the ability to stream datasets in a natural fashion makes the functional approach much more scalable to larger problem sets. For instance, the streaming Haskell version is actually faster than VTK for the larger surfaces generated by skull and vertebra8. We speculate that where other toolkits might eventually need to swap to a different outof-core algorithm, the streaming approach will just continue to work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Visualization Criteria</head><p>Compare the properties of our fine-grained streaming approach with the requirements for data streaming set out in <ref type="bibr" target="#b15">[16]</ref>.</p><p>Caching is achieved by coupling streamed data access (sec 3.3) with memoization (sec 3.5) of results. Demand-Driven computation is a natural product of call-by-need evaluation (Section 3.4). Shared sub-expressions are evaluated at most once, e.g. the bi-linear interpolant of a given edge is computed only if needed (sec 3.4). Incoming data is transformed only to the extent that it contributes to the growing surface mesh, and grid memory that 'falls off' the back of the window is recycled automatically. By mem- Hardware architecture independence is supported in two ways. Through polymorphic types (sec 3.1) functions can be defined independent of the datatypes available on a specific architecture; type predicates (e.g. 'Num a') allow developers to set out the minimum requirements that particular types must satisfy. Beyond the scope of this paper, polytypism <ref type="bibr" target="#b12">[13]</ref>, also known as structural polymorphism on types, has the capability to abstract over data organisation and traversal, e.g. a polytypic marching cubes could be applied to other kinds of dataset organization like irregular grids. Component Based development, as highlighted throughout Section 3, is fundamental to functional programming <ref type="bibr" target="#b9">[10]</ref>. In <ref type="bibr" target="#b15">[16]</ref>, 'components' are coarse-grained modules encapsulating visualization algorithms; in this paper we have shown that component-based assembly can be much finer-grained. For example, the streaming operators would be just as applicable in the implementation of flow algorithms, generating streamlines. Functional building blocks, in the form of combinator libraries, have been developed for a range of problems, e.g. prettyprinting <ref type="bibr" target="#b10">[11]</ref>, XML transformation <ref type="bibr" target="#b28">[29]</ref>, and circuit layout <ref type="bibr" target="#b0">[1]</ref>. The rich type systems found in functional languages aid in program development; higher-order types exactly describe how components may be safely plugged together. The assembly of functional abstractions from smaller units has a similar feeling to pipeline assembly <ref type="bibr" target="#b25">[26]</ref>, but applies across all levels of abstraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Clarity</head><p>In the quest for faster, more space-efficient algorithms, other qualities required of visualization systems are easily overlooked. Law et.al. briefly discuss other software design properties like robustness and extensibility. But when pictures inform us on critical issues as diverse as surgical procedure, storm forecasting and long-term decision-making linked to climate change, we should add the over-riding criterion that algorithms must be evidently correct. Assurance of correctness is aided in functional programming by three means. (1) Strong static polymorphic type systems, and automatic memory management, eliminate entire classes of errors that are otherwise commonplace in imperative languages. (2) Conciseness of expression means that it is possible for a reader to understand more of the big picture at once. (This paper contains the majority of the marching cubes code -the complete program beyond the classic table is about 200 lines.) (3) As there are no 'side-effects', expressions can be manipulated using the kind of equational reasoning familiar from mathematics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head><p>While call-by-need is implicit in lazy functional languages, several efforts have explored more ad hoc provision of lazy evaluation in imperative implementations of visualization systems. Moran et al. <ref type="bibr" target="#b20">[21]</ref> exploit lazy evaluation for working with large time-series datasets in a visualization system based on the Demand Driven Visualizer (DDV) calculator paradigm for computation and visualization of large fields. In their system derived fields quantities are evaluated either on demand (lazy evaluation), as a whole field (eager evaluation), or via a cache of lazily evaluated results (lazy but thrifty evaluation).</p><p>Lazy evaluation has also been used in several visualization systems. The Unsteady Flow Analysis Toolkit (UFAT) <ref type="bibr" target="#b14">[15]</ref> allows users to compute field values on demand. Cox et.al. <ref type="bibr" target="#b4">[5]</ref> modified UFAT to support demand-driven loading of data into main memory, achieving good performance in the visualization of large computational fluid dynamics data sets. More generally, in the demand-driven ('pull-model') systems noted in Section 2, e.g. VTK <ref type="bibr" target="#b25">[26]</ref> and SCIRun <ref type="bibr" target="#b24">[25]</ref>, laziness underpins a streaming interface; modules can request just the data needed from upstreams modules within given spatial extents, and operations to produce these data are executed only on demand.</p><p>Isenburg et.al. <ref type="bibr" target="#b11">[12]</ref> propose a streaming mesh format for polygonal meshes and discuss techniques to construct streamed meshes. In this approach mesh elements (faces and vertices) appear interleaved in the stream, and finalization tags record when a vertex is last referenced. Finalized vertices are guaranteed not to be accessed further, and can thus be removed from main memory, an ad hoc form of the general garbage collection techniques provided by the Haskell runtime system. Laziness is achieved by introducing vertices only when needed, but at the cost of re-organizing the entire file data-structure to generate a proper data layout in terms of vertices and faces ordering. The authors propose an application of their streaming approach to isosurface extraction techniques, and show the benefits gained from streamed inputs; but the advantage is limited to cases where the volume data changes often and only few isosurface values are evaluated.</p><p>When data are generated by computationally intense simulations and multiple isosurfaces are generated to explore the dataset, the technique of Mascarenhas et.al. <ref type="bibr" target="#b19">[20]</ref> is more suitable. Adopting a contour following approach, their method uses sparse traversal to avoid computation at each grid location. Coupled with lazy evaluation of data based on a streamed format, performance is reported as faster than exemplar eager systems (as in <ref type="bibr" target="#b20">[21]</ref>). As shown by Chandrasekaran et.al. <ref type="bibr" target="#b2">[3]</ref> a lazy approach improves the throughput of an application: from a user's point of view, first results are returned quickly; from the application point of view, often only a portion of the result set is actually needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>The purely functional streaming implementation of marching cubes developed in this paper demonstrates significant space savings compared with an approach based on monolithic datasets. This is not in itself surprising, given prior work on streaming, but shows that elegance and clarity need not be sacrificed to meet certain performance criteria. Streaming within visualization occupies an important niche between fully in-core and fully out-of-core methods. A feature of the functional approach is that data is pulled off-disk as needed, without the programmer resorting to explicit control over buffering. Data is retained in memory only as long as required: in our case a sample is held while plane + line + 1 cells are processed, and discarded automatically.</p><p>Motivated by the demands of large-scale data, visualization researchers have explored techniques for lazy and demand-driven evaluation. But deployment of these techniques has been limited by the need to access these services from within an imperative programming system. We have shown how a programming technology based fundamentally on lazy evaluation allows the use of streaming, call-by-need, and memoization at a fine level of granularity. Functional forms for traversal and computation can be reused across different algorithms; in surface extraction for example, the sliding window used here is applicable to sweep-based seed-set generation. We are currently exploring use of generic programming techniques to extend the work to other types of grid (e.g. tetrahedral meshes and unstructured datasets), and to other surface extraction methods. The result should be a small set of combinators from which specific traversal and surfacing tools can be constructed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•</head><label></label><figDesc>Rita Borgo and David Duke are with the School of Computing, University of Leeds, UK, E-mail: {rborgo,djd}@comp.leeds.ac.uk. • Colin Runciman and Malcolm Wallace are with the Department of Computer Science, University of York, UK, E-mail: {Colin.Runciman,Malcolm.Wallace}@cs.york.ac.uk Manuscript received 31 March 2006; accepted 1 August 2006; posted online 6 November 2006. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>map :: (a-&gt;b) -&gt; [a] -&gt; [b] map f [] = [] map f (x:xs) = f x : map f xs This definition uses pattern-matching to distinguish the empty sequence [], from a non-empty sequence whose initial element is x, with the remainder of the sequence denoted by xs. Colon : is used both in pattern-matching, and to construct a new list. Finally, to the definition of mcube: mcube :: a -&gt; (XYZ-&gt;Cell a) -&gt; XYZ -&gt; [Triangle] mcube th lookup (x,y,z) = group3 (map (interpolate th cell (x,y,z)) (mcCaseTable ! bools)) where cell = lookup (x,y,z) bools = toByte (map8 (&gt;th) cell) group3 :: [a] -&gt; [(a,a,a)] group3 (x:y:z:ps) = (x,y,z):group3 ps group3 [] = []</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>interpolate :: Num a =&gt; a -&gt; Cell a -&gt; XYZ -&gt; Edge -&gt; TriangleVertex interpolate thresh cell (x,y,z) edge = case edge of 0 -&gt; (x+interp, y, z) 1 -&gt; (x+1, y+interp, z) ... 11 -&gt; (x, y+1, z+interp) where interp = (thresh -a) / (b -a) (a,b) = selectEdgeVertices edge cell</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Sliding a window over a grid</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>3 . 4</head><label>34</label><figDesc>Instead of passing a lookup function as an argument, we directly pass a cell from the stream of incoming cells. Compare the old and new type signatures: mcube :: a -&gt; (XYZ-&gt;Cell a) -&gt; XYZ -&gt; [Triangle] mcubeS :: a -&gt; Cell a -&gt; XYZ -&gt; [Triangle] Sharing the threshold calculation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>. --as before cellStream = disContinuities size . mkStream idxStream = map toByte . cellStream . map (&gt;th)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>size . mkCellEdges th size ... --idxStream, allXYZ as before Finally, mcubeI does no interpolation itself, it merely selects already-interpolated values from the CellEdge structure and adds the absolute grid position.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>mcubeI :: CellEdge a -&gt; Byte -&gt; XYZ -&gt; [Triangle] mcubeI edges index (x,y,z) = group3 (map (selectEdge edges (x,y,z)) (mcCaseTable ! index))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>mcubeU :: a -&gt; CellEdge a -&gt; Byte -&gt; Cell a -&gt; XYZ -&gt; [Triangle] mcubeU thresh edges index cell (x,y,z) = group3 (map (select (x,y,z)) cases) where cases = mc33tiles cell (mc33CaseTable ! index) select idx 12 = triInterpolate idx cell thresh select idx _ = selectEdge edges idx</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Functionally surfaced dataset coloured to show age of triangles in stream. Streamed dataset, colour mapped to stream position.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Dataset Statistics.</figDesc><table><row><cell>dataset</cell><cell>size</cell><cell cols="3">input (b) window (b) surface (v)</cell></row><row><cell>silicium</cell><cell>(98,34,34)</cell><cell>113,288</cell><cell>3,431</cell><cell>103,020</cell></row><row><cell>neghip</cell><cell>(64,64,64)</cell><cell>262,144</cell><cell>4,161</cell><cell>131,634</cell></row><row><cell cols="3">hydrogen (128,128,128) 2,097,152</cell><cell>16,513</cell><cell>134,952</cell></row><row><cell>lobster</cell><cell cols="2">(301,324,56) 5,461,344</cell><cell cols="2">97,826 1,373,196</cell></row><row><cell>engine</cell><cell cols="2">(256,256,128) 8,388,608</cell><cell cols="2">65,793 1,785,720</cell></row><row><cell cols="3">statueLeg (341,341,93) 10,814,133</cell><cell>116,623</cell><cell>553,554</cell></row><row><cell cols="3">aneurism (256,256,256) 16,777,216</cell><cell cols="2">65,793 1,098,582</cell></row><row><cell>skull</cell><cell cols="2">(256,256,256) 16,777,216</cell><cell cols="2">65,793 18,415,053</cell></row><row><cell>stent8</cell><cell cols="2">(512,512,174) 45,613,056</cell><cell cols="2">262,657 8,082,312</cell></row><row><cell cols="3">vertebra8 (512,512,512) 134,217,728</cell><cell cols="2">262,657 197,497,908</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Time Performance</figDesc><table><row><cell></cell><cell></cell><cell>time (s)</cell><cell></cell><cell></cell><cell cols="2">(µs/sample)</cell></row><row><cell>dataset</cell><cell>array</cell><cell cols="2">stream VTK</cell><cell>arr</cell><cell>str</cell><cell>VTK</cell></row><row><cell>silicium</cell><cell cols="2">0.626 0.386</cell><cell cols="4">0.19 5.53 3.40 1.67</cell></row><row><cell>neghip</cell><cell cols="2">1.088 0.852</cell><cell cols="4">0.29 4.15 3.25 1.11</cell></row><row><cell>hydrogen</cell><cell cols="2">8.638 6.694</cell><cell cols="4">0.51 4.12 3.19 0.24</cell></row><row><cell>lobster</cell><cell cols="2">25.37 18.42</cell><cell cols="4">5.69 4.65 3.37 1.04</cell></row><row><cell>engine</cell><cell cols="2">44.51 28.06</cell><cell cols="4">5.29 5.31 3.35 0.63</cell></row><row><cell>statueLeg</cell><cell cols="2">48.78 34.54</cell><cell cols="4">2.78 4.51 3.19 0.25</cell></row><row><cell>aneurism</cell><cell cols="2">72.98 54.44</cell><cell cols="4">5.69 4.35 3.24 0.33</cell></row><row><cell>skull</cell><cell cols="2">79.50 57.19</cell><cell cols="4">79.03 4.74 3.41 4.71</cell></row><row><cell>stent8</cell><cell cols="2">287.5 154.9</cell><cell cols="4">33.17 6.30 3.40 0.73</cell></row><row><cell cols="3">vertebra8 703.0 517.1</cell><cell>755.0</cell><cell cols="3">5.24 3.85 5.62</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Memory Usage</figDesc><table><row><cell></cell><cell cols="3">memory (MB)</cell><cell cols="2">(bytes/residency)</cell></row><row><cell>dataset</cell><cell>array</cell><cell cols="4">stream VTK array stream VTK</cell></row><row><cell>silicium</cell><cell cols="2">0.120 0.120</cell><cell></cell><cell>1.1 1.06</cell><cell>35.0</cell><cell>9.71</cell></row><row><cell>neghip</cell><cell cols="2">0.270 0.142</cell><cell></cell><cell>1.4 1.03</cell><cell>34.1</cell><cell>5.34</cell></row><row><cell>hydrogen</cell><cell cols="2">2.10 0.550</cell><cell></cell><cell>3.0 1.00</cell><cell>33.3</cell><cell>1.43</cell></row><row><cell>lobster</cell><cell cols="2">5.45 3.10</cell><cell></cell><cell>19.5 1.00</cell><cell>31.7</cell><cell>3.57</cell></row><row><cell>engine</cell><cell cols="2">8.25 2.10</cell><cell></cell><cell>25.4 0.98</cell><cell>31.9</cell><cell>3.03</cell></row><row><cell>statueLeg</cell><cell cols="2">11.0 3.72</cell><cell></cell><cell>15.9 1.02</cell><cell>31.9</cell><cell>1.47</cell></row><row><cell>aneurism</cell><cell cols="2">17.0 2.10</cell><cell></cell><cell>28.1 1.01</cell><cell>31.9</cell><cell>1.67</cell></row><row><cell>skull</cell><cell cols="2">17.0 2.13</cell><cell></cell><cell>185.3 1.01</cell><cell>32.4</cell><cell>11.04</cell></row><row><cell>stent8</cell><cell cols="2">46.0 8.35</cell><cell></cell><cell>119.1 1.01</cell><cell>31.8</cell><cell>2.61</cell></row><row><cell cols="3">vertebra8 137.0 8.35</cell><cell cols="2">1,300.9 1.02</cell><cell>31.8</cell><cell>9.69</cell></row><row><cell cols="6">oization, we extend laziness to wider sharing of computations, e.g.</cell></row><row><cell cols="6">avoiding recomputing the edge interpolant for each neighbouring cell</cell></row><row><cell>(sec 3.5).</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Since VTK5.0, there is the capability to associate different executives with specific parts of the pipeline.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Our Haskell implementation is actually built directly on the HOpenGL binding, so the mapping phase is implemented slightly differently, via a function that is invoked as the GL display callback. This is the only place where the presentation departs from the executable implementation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">It bears similarities to Zermelo-Frankel (ZF) set comprehensions in mathematics.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">For efficiency, the underlying system may choose to hold variable-size buffers for the file, but crucially, that buffering can be tuned to match available resources of memory, disc, and processor.<ref type="bibr" target="#b4">5</ref> Constructor names are required because in general, a data definition may introduce several alternative constructors for a given type; for example, a type that allowed both regular and rectilinear grids might appear asDataset a = Reg XYZ [a] | Rect ([Float],[Float],[Float]) [a]. Different kinds of dataset are then distinguished by their constructor.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The work reported in this paper was funded by the UK Engineering and Physical Sciences Research Council.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Source Material: All programs used in the paper are available from: http://hackage.haskell.org/trac/PolyFunViz/</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Lava: Hardware design in haskell</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bjesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Claessen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sheeran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Functional Programming</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="174" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An approach to fast arrays in haskell</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture notes in Computer Science</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="27" to="58" />
		</imprint>
	</monogr>
	<note>Advanced Functional Programming</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PSoup: a system for streaming queries over streaming data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Franklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="140" to="156" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Marching cubes 33: Construction of topologically correct isosurfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chernyaev</surname></persName>
		</author>
		<idno>CERN CN 95-17</idno>
		<imprint>
			<date type="published" when="1995" />
			<publisher>CERN</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Application-controlled demand paging for outof-core visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ellsworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;97</title>
		<meeting>Visualization &apos;97</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page">235</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visualization idioms: A conceptual model for scientific visualization systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcnabb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization in Scientific Computing</title>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ConMan: a visual programming language for interactive graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeberli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH&apos;88</title>
		<meeting>SIGGRAPH&apos;88</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1988" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Benchmarking implementations of functional languages with pseudoknot, a float-intensive benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Hartel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Functional Programming</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="621" to="656" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haskell</surname></persName>
		</author>
		<ptr target="http://www.haskell.org" />
		<title level="m">A purely functional language</title>
		<imprint>
			<biblScope unit="page" from="27" to="30" />
		</imprint>
	</monogr>
	<note>Last vis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Why functional programming matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
		<ptr target="http://www.cs.chalmers.se/rjmh/Papers/whyfp.html" />
	</analytic>
	<monogr>
		<title level="j">Computer Journal</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="98" to="107" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The design of a pretty-printing library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Functional Programming</title>
		<editor>J. Jeuring and E. Meijer.</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">925</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Streaming meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lindstrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization&apos;05</title>
		<meeting>Visualization&apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Polytypic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeuring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tutorial Text 2nd Int. School on Advanced Functional Programming</title>
		<editor>J. Launchbury, E. Meijer, and T. Sheard</editor>
		<meeting><address><addrLine>Olympia, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1996-08-30" />
			<biblScope unit="volume">1129</biblScope>
			<biblScope unit="page" from="68" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Jones</surname></persName>
		</author>
		<title level="m">Haskell&apos;98 Language and Libraries: The Revised Report</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">UFAT: a particle tracer for time-dependent flow fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;94</title>
		<meeting>Visualization &apos;94</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A multi-threaded streaming pipeline architecture for large structured data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Temkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;99</title>
		<meeting>Visualization &apos;99</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Spreadsheets for images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH&apos;94</title>
		<meeting>SIGGRAPH&apos;94</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="139" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient implementation of marching cubes&apos; cases with topological guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lewiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tavares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Graphics Tools</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Marching cubes: A high resolution 3d surface construction algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH&apos;87</title>
		<meeting>SIGGRAPH&apos;87</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="163" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Encoding volumetric grids for streaming isosurface extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mascarenhas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoeyink</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="665" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Large field visualization with demand-driven calculation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Henze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization&apos;99</title>
		<meeting>Visualization&apos;99</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="27" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Volume scene graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nadeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Volume Visualization</title>
		<meeting>the Symposium on Volume Visualization</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Snap-together visualization: a user interface for coordinating visualizations via relational schemata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AVI&apos;00: Proceedings of Advanced Visual Interfaces</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="128" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Spray rendering: visualization using smart particles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization&apos;93</title>
		<editor>G. Nielson and R. Bergeron</editor>
		<meeting>Visualization&apos;93</meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="283" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The SCIRun computational steering software system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modern software tools for scientific computing</title>
		<imprint>
			<publisher>Birkhauser Boston Inc</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="5" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The Visualization Toolkit: An Object-Oriented Approach to 3D Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lorensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Shortcut fusion for accumulating parameters &amp; zip-like functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Svenningsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICFP &apos;02: Proc. of International Conference on Functional Programming</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="124" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The application visualization system: A computational environment for scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Upson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Faulhaber</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vroom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Haskell and XML: Generic combinators or type-based translation?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Runciman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth ACM SIGPLAN International Conference on Functional Programming (ICFP&apos;99)</title>
		<meeting>the Fourth ACM SIGPLAN International Conference on Functional Programming (ICFP&apos;99)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="148" to="159" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
