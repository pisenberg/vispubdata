<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Phonon Tracing for Auralization and Visualization of Sound</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Bertram</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ITWM Kaiserslautern Jevgenij Jegorovs ITWM</orgName>
								<address>
									<settlement>Kaiserslautern</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">U</forename><surname>Kaiserslautern</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ITWM Kaiserslautern Jevgenij Jegorovs ITWM</orgName>
								<address>
									<settlement>Kaiserslautern</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">ITWM Kaiserslautern Jevgenij Jegorovs ITWM</orgName>
								<address>
									<settlement>Kaiserslautern</settlement>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">ITWM Kaiserslautern Jevgenij Jegorovs ITWM</orgName>
								<address>
									<settlement>Kaiserslautern</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Mohring</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ITWM Kaiserslautern Jevgenij Jegorovs ITWM</orgName>
								<address>
									<settlement>Kaiserslautern</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Hagen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ITWM Kaiserslautern Jevgenij Jegorovs ITWM</orgName>
								<address>
									<settlement>Kaiserslautern</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Phonon Tracing for Auralization and Visualization of Sound</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Raytracing</term>
					<term>I.6.8 [Simulation and Modeling]: Types of Simulation-Monte Carlo</term>
					<term>J.2 [Computer Applications]: Physical Sciences and Engineering-Physics</term>
					<term>acoustics, auralization, raytracing, photon mapping</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present a new particle tracing approach for the simulation of mid-and high-frequency sound. Inspired by the photorealism obtained by methods like photon mapping, we develop a similar method for the physical simulation of sound within rooms. For given source and listener positions, our method computes a finiteresponse filter accounting for the different reflections at various surfaces with frequency-dependent absorption coefficients. Convoluting this filter with an anechoic input signal reproduces a realistic aural impression of the simulated room. We do not consider diffraction effects due to low frequencies, since these can be better computed by finite elements. Our method allows the visualization of a wavefront propagation using color-coded blobs traversing the paths of individual phonons.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Auralization is concerned with simulating and reproducing the acoustic properties of a scene. It can be considered as an auditive variant of visualization, providing insight into the "good" and "bad" acoustic properties of classrooms, theaters, congress rooms, churches, etc. In this work, we contribute a simple, yet powerful auralization method, providing a combination of acoustic simulation and visualization. Sound is hereby represented as particles called phonons, emanating from a sound source, being reflected at different surfaces and finally collected at a listener's position. <ref type="figure">Figure 1</ref> contains a visualization of this process showing the different frequency decompositions due to reflection at materials with versatile absorption properties. The spectral energy of phonons within low, mid and high-frequency bands is mapped onto the blue, green and red color components, respectively. * e-mail: bertram@informatik.uni-kl. <ref type="bibr">de</ref> The objective of our auralization is the optimization of acoustic properties based on virtual models, for example of class rooms. For a given sound source (or a set of sources) and multiple listener positions, our simulation computes a finite impulse response (FIR) filter for each listener position, such that convolution with an anechoic input signal will provide a realistic impression of the sound perceived at this position. The progress of the simulation can be visualized by sliding through time and rendering all phonons corresponding to a unit impulse (Dirac) sent out from the source at time zero. Due to distinct absorption of different frequency bands at the surfaces of a scene, the spectral energy distribution of the phonons is altered at each reflection.</p><p>From our visualization, the effect of different materials on the spectral energy distribution can be observed. The first few reflections already show whether certain frequency bands are rapidly absorbed. The absorbing materials can be identified and replaced in the virtual model, improving the overall acoustic quality of the simulated room. After a large time period, a large number of reflections has occurred, such that individual wave fronts cannot be identified, anymore. The color mix of the phonons, however, shows the overall acoustic quality. The darker the color of phonons gets, the more energy is absorbed by the different materials.</p><p>Applications of our work include (but are not limited to) the acoustic improvement during architecture, design, and equipment of class-and congress rooms. Compared to commercial products designed for home entertainment, our method is more precise for highly detailed scenes, since a much greater number of reflections can be considered for complex scenes. The limitations are low-frequency simulations where diffraction dominates the process. These are frequencies in the order f = c/λ ∼ c/l, where c is the speed of sound and l denotes the diameter of the simulated room. Since only linear propagation of sound is considered by our method, diffraction needs to be simulated by different methods, like finite elements. For acoustic qualities, such as clarity of sound, however, lowest frequencies can often be neglected.</p><p>The remainder of our paper is structured as follows: In section 2 we review related work and summarize the differences with respect to our approach. Section 3 describes our simulation, composed of phonon emission, phonon collection, filtering, and visualization. Numerical examples and a qualitative evaluation are provided in section 4, followed by a brief conclusion.</p><p>Please see supplementary material on conference DVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Visualization 2005</head><p>October 23-28, Minneapolis, MN, USA 0-7803-9462-3/05/$20.00 ©2005 IEEE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In the theory of acoustics there are two main approaches simulating the propagation of sound. The first approach is based on wave equations that are numerically solved, for example with use of finite element methods (FEM). The simulation results are very accurate, but the complexity increases drastically with the highest frequency considered, since a volume grid with O(n 3 ) cells needs to be constructed where n is proportional to the highest frequency. The time complexity for solving this is typically O(n 3 log n 3 ). Hence, the wave model is suitable for low frequencies only. The second approach, known as geometric acoustics, describes the sound propagation by sound particles moving along a directed ray. There exists a variety of such methods for simulating room acoustics. They are mostly based on optical fundamentals, and make use of approaches developed there. Two classical methods for acoustic simulation are the image-source method and the raytracing method.</p><p>The image-source method <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> models specular reflections by inserting additional sound sources obtained by mirroring the location of audio source over polygonal surfaces inside the scene. The key idea here is, that a sound ray from a sound source S reflected on a surface has the same acoustic effect as one from the mirrored source S', reduced by the absorbed energy part. In a rectangular box-shaped room it is easy to construct image sources up to a certain order of reflections. Following the image source calculations, for a receiver position P, each of the virtual sources must be considered to determine whether it can be heard in P. All sources visible from P are summed up, reproducing the acoustical impression at P, where in addition to energy the individual time delays are considered. The advantage of the image-source method is, that it is very accurate, but it becomes very complicated for non-box-shaped rooms and curved surfaces cannot be simulated, at all. The number of the mirrored sources increases exponentially with reflection order. Hence, this approach is suitable only for simple room geometry and low reflection orders.</p><p>In the raytracing method <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> several rays are traced from the sound source to receiver that is typically represented as a sphere. The reflections over the surfaces in the scene are simulated according to specular laws or Lambert's law of diffuse reflections. In addition to absorption properties of considered surfaces, timely delay and air absorption are taken in account. This approach is general and easy to implement, but it is very computation expensive and can cause aliasing artifacts due to discrete number of rays. When changing the receiver's position, the tracing of all rays needs to be performed, again.</p><p>Due to the shortcomings of the two classical approaches described above, continuative approaches have been developed in recent years. Mostly, they employ parts of the classical schemes or a combination of them. One approach that makes use of advantages of image-source method and raytracing is introduced in <ref type="bibr" target="#b20">[21]</ref>. Here the visibility check of the image-source algorithm are performed via raytracing. Beam-tracing methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b15">16]</ref> overcome the aliasing problem of classical raytracing by recursively tracing pyramidal beams, implying the need for highly complex geometric operations, still ignoring diffraction effects at low frequencies. An approach for calculation of edge diffraction in room acoustics is presented in <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b14">15]</ref>. To overcome the dependency of the simulation on the receiver position the radiosity method was extended to be used in room acoustics <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b10">11]</ref>. Due to the computation complexity these methods do not seem practical for large environments. Newer approaches try to cope with complexity by exploiting GPU hardware accelerating the simulation calculations <ref type="bibr" target="#b5">[6]</ref>.</p><p>The aim of audio simulation is the estimation of acoustic properties, such as reverberation time and the reproduction of acoustic benchmarks. Auralization is the process of producing audible impression of a room. Therefore an anechoic signal is convolved with the room impulse signal and displayed over a loudspeaker system or head phones, often using head related transfer function (HRTF) for directional tracking. A survey of existing auralization systems and explicit description of the DIVA auralization system is given in <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b13">14]</ref>. In the visualization context, only few approaches to acoustics have been described <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>Our method is inspired by a technique known as photon mapping <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref> used for rendering photo-realistic images. The idea of this method is to trace photons from a light source into a scene, where their path is reflected and refracted at specular / transparent surfaces and ends on surfaces (or in volumes) with a diffuse component. These photons, composed of color intensity and outgoing direction, are associated with the surfaces ending their paths. When rendering these surfaces, for example by raytracing, a photon map is evaluated by inserting the n closest photons into a bi-directional reflection distribution function (BRDF) determining the local light intensity.</p><p>In the present work, we contribute a novel simulation technique for auralization, also applicable to large scenes. Our method is coupled with an interactive visualization, showing the impact of certain materials on the frequency decomposition and intensity of reflected wave fronts. With few restrictions, it is possible to alter acoustic material properties at interactive rates, re-using the particle paths computed by the simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ALGORITHM</head><p>Photon mapping <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref> is often used for rendering photo-realistic images, supplementing uni-directional raytracing by a variety of visual effects, like color bleeding and caustics. We adopt a similar approach to the simulation of sound, where a couple of issues need to be re-considered. For example, the human ear is not capable of locating the origin of a sound source as precise, as the human eye is capable of locating the origin of light. In the case of high frequencies where diffraction is negligible, one can locate directional sound with a precision of about 30 degrees. Thus, a lower number of particles (phonons) may be sufficient for auralization.</p><p>Another difference is that the human ear can distinguish a lot more frequency bands than the eye. Since the eye has only three different receptors for red, green, and blue light, any continuous distribution within the visible spectrum between 400 and 700 µm of wavelength is mapped onto three variables. Consequently, only three wavelengths need to be considered for rendering images. The human ear, however, can distinguish frequencies in the spectrum Ω = [20Hz, 20000Hz] fairly precise. In addition, the spectrum of an audio signal is highly time-dependent in contrast to most illumination problems that require only a static solution.</p><p>Problem specification. Our algorithm requires the following input:</p><p>• • an energy threshold ε e for terminating the phonon paths. Examples for absorption functions provided by CARA 1 are illustrated in figure 2. The output of our method is a FIR filter f i for each listener's position l i corresponding to the pulse response with respect to the sound source and a visualization of the simulation process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Phonon Tracing</head><p>Every phonon p emitted from the sound source carries the following information:</p><p>• an energy spectrum e p : Ω → R +</p><p>• the distance d p traversed from the source</p><formula xml:id="formula_0">• the phonon's current position p p • its outgoing direction v p .</formula><p>Additional information, such as the number of reflections and the material index of the last reflection may also be attached for visualization purposes.</p><p>Our absorption and energy functions α j are represented by n e = 10 coefficients associated with the frequencies 40, 80, 160, ..., 20480 Hz. The corresponding basis functions for the energy spectrum are wavelets ψ i (i = 1, ..., n e ) adding up to a unit impulse (discretized Dirac). We will define these wavelets later. For now, we assume that every phonon is composed of different frequencies, which is much more efficient than tracing a single phonon for each individual frequency band.</p><p>Phonons are emitted from the source s according to the emission probability distribution E. In the case of a sound source with equally distributed emission over the unit sphere, we use three independent random variables x, y, z with normal (gaussian) distribution using the probability function</p><formula xml:id="formula_1">P(x) = 2 √ π exp(−x 2 ).<label>(1)</label></formula><p>This is obtained by inserting a random variable ξ equally distributed on [0, 1] into x = Φ −1 (ξ ), where Φ is the normal distribution function</p><formula xml:id="formula_2">Φ(x) = 2 √ π x 0 exp(−t 2 ) dt = er f (x).<label>(2)</label></formula><p>Since the variable (x, y, z) T forms a rotationally symmetric gaussian distribution, its normalized direction is equally distributed on the unit sphere <ref type="bibr" target="#b2">[3]</ref> and can be used to emit phonons at a spherical sound source.</p><p>Our phonons are started at the source with a (discretized) unit energy spectrum e p,i = 1 (i = 1, ..., n e ). At the first intersection of the phonon ray with the scene, the phonon direction d p is reflected with respect to the local surface normal and the absorbed energy is subtracted according to the local material m j ,</p><formula xml:id="formula_3">e p,i := (1 − α j,i ) e p,i ,<label>(3)</label></formula><p>and the distance d p is set to the traversed distance. The phonon is fixed at the intersection point, contributing to a global phonon map (whose evaluation is discussed later). For efficient computation of ray-surface intersection, we use an octree-based partitioning of the scene.</p><p>If the maximal energy of the phonon exceeds the energy threshold, i.e. max{e p,i } n e i=1 &gt; ε e , the next phonon re-uses the path and energy of the preceding one, saving computation time. It is started at the current position with respect to the outgoing direction d p and contributes to the phonon map at the next surface intersection. If the threshold ε e is not exceeded and a minimum number of reflections have been computed, then a new phonon is started from the sound source s. After a prescribed number n p of phonons have contributed to the global phonon map, the tracing is terminated.  The approach can be extended by considering bi-directional reflection distribution functions (BRDF's), for example when modeling corrugated materials by plain surfaces. A BRDF provides the reflection factor for a pair of incoming and outgoing directions. For any fixed incoming direction, it can be used as probability function for a random variable determining the reflection vector. We note that the material's corrugation must be very coarse to justify this approach, since the wave lengths of sound are much wider than those of light. Due to the strong dependency of the wavelengths and reflection distribution, individual BRDF's may be defined for several bandwidths, making it necessary to trace multiple succeeding phonons in different directions, carrying distinct parts of the energy spectrum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Phonon Collection and Filtering</head><p>The remaining task of our method is collecting the phonons' contribution to a FIR filter f for every listener's position l. This filter f corresponds to the pulse response from the source, recorded at l, such that convolution with an anechoic source signal g s reproduces the perceived signal g l , where</p><formula xml:id="formula_4">g l = g s * f = R g s (τ) f (• − τ) dτ.<label>(4)</label></formula><p>In the case of uniform absorption for all frequencies, the contribution of a phonon visible from the listener is simply a scaled, translated Dirac (unit impulse),</p><formula xml:id="formula_5">δ p,l,i (t) = exp(−k h 2 pl ) e p,i δ t − (d p + d pl )/c ,<label>(5)</label></formula><p>where k is a constant, h pl denotes the shortest distance of the continued phonon path p p + tv p and the listener l, e p,i denotes the phonon's energy (at frequency ω i ), d pl denotes the distance between phonon p p and listener l, and c is the speed of sound. The term (d p + d pl )/c corresponds to the time elapsed between emission and reception of a phonon. The Dirac δ is shifted by this time interval and scaled by the phonon's energy e p,i , multiplied by a gaussian weighting the distance of the ray to the listener. In classical acoustic raytracing <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>, a sphere is used to collect rays at a listener's position. Using a gaussian, however, provides much smoother filters, since more phonon rays contribute to the filter, weighted by their shortest distance. The constant k determines the radius of this gaussian and can be compared with the shininess in the specular term of the Phong illumination model. For now, we use k = 200m −2 , keeping in mind that this constant needs to be adapted to the phonon density.</p><p>In the more general case of frequency-dependent absorption, the Dirac is subdivided into wavelets ψ i representing the individual frequency bands,</p><formula xml:id="formula_6">δ (t) = n e ∑ i=1 ψ i (t).<label>(6)</label></formula><p>With the different energy coefficients e p,i , the filter becomes</p><formula xml:id="formula_7">f (t) = ∑ p exp(−k h 2 pl ) n e ∑ i=1 e p,i ψ i t − (d p + d pl )/c)<label>(7)</label></formula><p>For a large number of phonons, it is more efficient to precompute n e different filters, one for each bandwidth, based on equation <ref type="bibr" target="#b4">(5)</ref>. Their convolutions with the individual wavelets are then efficiently computed employing the Fast Fourier Transform (FFT). By the convolution theorem, equation <ref type="formula" target="#formula_7">7</ref>is equivalent to</p><formula xml:id="formula_8">f (t) = n e ∑ i=1 ψ i * ∑ p δ p,l,i (t),<label>(8)</label></formula><p>where the convolution translates and scales the wavelets properly for each individual phonon. Filter design. Our band-pass filters b i = ψ i are constructed as follows. To obtain quickly decaying wavelets, the filters need to be smooth in the spectral domain. Therefore, we use the shape of cosine functions,</p><formula xml:id="formula_9">c i (x) := 1 2 + 1 2 cos(π(x − i)) i f x ∈ [i − 1, i + 1]; 0 else.<label>(9)</label></formula><p>With the re-definition c 1 (x) := 1 for x &lt; 1 and c n e (x) := 1 for x &gt; n e , we obtain the property ∑ n e i=1 c i (x) = 1, everywhere. In our implementation, we use n e = 10 and absorption coefficients for the frequencies ω i = 20 2 i Hz (i = 1, ..., 10), covering the range from 40 to 20480 Hz. On the logarithmic scale, our filters are defined as</p><formula xml:id="formula_10">b i (ω) =      c i (log 2 (ω/ω 0 )) i f ω &gt; 0; δ i1 i f ω = 0; c i (log 2 (ω 0 / − ω)) i f ω &lt; 0,<label>(10)</label></formula><p>where ω 0 = 20 Hz and δ i1 denotes the Kronecker delta. The wavelets ψ i are obtained by the inverse Fourier Transform. b 0 and b 10 are low-and highpass filters, respectively, whereas the remaining b i are bandpass filters with support [ω i−1 , ω i+1 ], see <ref type="figure" target="#fig_3">figure 3</ref>. Our filters have the following properties:</p><p>• compact support in Ω</p><p>• symmetry and smoothness in both domains</p><p>• their sum is one in Ω and a Dirac in the time domain. Discretization. The response filters produced by our implementation are sampled at a rate of 48 KHz. For generating the filter bank, we used 2 14 samples, employing the inverse FFT for computing the discretized wavelets. Due to the uncertainty principle, the pulse response may become non-causal. To limit this effect, we combine the widest filters for 40, 80, 160, and 320 Hz into one (decaying much faster) and cut off all filters after 314 samples (corresponding to 6.5 msec) in both directions. Hence, the low-frequency portions of an echo, filtered due to different absorption coefficients, may be received up to 6.5 msec in advance of the main peak, which in fact cannot be recognized by the human ear. In the case of uniform absorption, the discretized wavelets still form a partition of the unit impulse, providing perfect echos.</p><p>Once, the response filter f has been computed, it needs to be normalized with respect to the number of phonons used and the radius of the gaussian located at the listener. Therefore, we normalize the filter such that the signal's intensity at 1m distance from the source s (without any reflections) corresponds to the intensity of the anechoic source signal. The normalization factor is simply one over the sum of all gaussian terms collected from the outgoing phonon paths in 1m distance from the source.</p><p>An additional extension we did not consider here is the absorption of air,</p><formula xml:id="formula_11">1 − exp(−α air d),<label>(11)</label></formula><p>where α air is the absorption coefficient (depending on air humidity and temperature) and d is the traversed distance. This term is extremely small, compared to the absorption of materials, such that it is not considered in our simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Visualization</head><p>The computationally most expensive part of our method is the computation of ray intersections for phonon tracing and the visibility determination in the collection phase. Once the phonon map composed of phonon paths with instances at each reflection has been computed, it can be used for interactive visualization. When dropping the visibility check in the collection phase (or substituting a crude approximation), the filters for a varying listener position can be estimated at nearly interactive rates. Our visualization focuses on the spacial propagation of a pulse response from the sound source. The corresponding wave front traverses the room and is reflected at surfaces, altering its intensity and energy spectrum. We visualize this wave front by rendering a small sphere for every phonon path with color coded spectral energy. Therefore, we use the RGB components, such that blue corresponds to the average of e p,1 , ..., e p,4 (40, 80, 160, 320 Hz), green corresponds to e p,5 , ..., e p,7 (640, 1280, 2560 Hz), and red to e p,8 , ..., e p,10 (5120, 10240, 20480 Hz).</p><p>When sliding through time, the spheres follow the phonon paths. At small time values, the reflected wave fronts are clearly visible. When the number of reflections increases, however, it becomes more difficult to recognize individual fronts. In order to tackle this problem, we integrated the following function into our interactive visualization system:</p><p>• varying the percentage of phonons to be rendered</p><p>• rendering only the phonons reflected from a selected material</p><p>• exchanging selected materials</p><p>• varying time / traversed distance.</p><p>The data structure supporting this visualization is an array of phonons carrying their energy spectrum e p , the traversed distance d p , the phonon's position p p at a reflection point, and its outgoing direction v p , according to section 3.1. In addition, we record the number of reflections r p and the material m p at the current reflection.</p><p>Since all phonons sharing the same path are listed consecutively in the array, it is simple, for example, to select all consecutive pairs p i , p i+1 where the current time t satisfies t p i ≤ t &lt; t p i+1 and to draw a sphere on the line segment p p i , p p i+1 , corresponding to a phonon's location at time t. In addition, certain predicates can be used, for example selecting all phonon whose path was reflected at the first (or at any) reflection on a selected material.</p><p>The exchange of a certain material requires only the phonons' energy to be re-evaluated, where the phonon paths remain fixed. To allow the exchange, it is necessary to enforce a minimum number of reflections for every path in advance, since otherwise materials with high absorption coefficients cannot be replaced. An application scenario of this kind is provided in the next section.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Visualization Application</head><p>Our visualization was used to examine the acoustic properties of a virtual reality (VR) laboratory that is also used for auralization purposes. <ref type="figure">Figure 1</ref> shows the wave front propagation based on 1M phonons (33043 paths), at a traversed distance of 1.5, 4.5, and 10 m. At small distances / traversal times, the individual wave fronts can be recognized, whereas large distances provide insight into the frequency decomposition of the various reflections. We observe a shift  towards lower frequencies, since the phonons' color is dominated by the blue component after a number of reflections.</p><p>To identify the reason for the frequency shift, we look at phonons reflected by a selected material (at least once) in their earlier paths. <ref type="figure" target="#fig_5">Figure 4</ref> shows these phonons for reflections from walls, bottom, and canvas, respectively, at a distance of 4.5 m where the front direction can still be recognized. We observe that phonons reflected from walls carry mostly a yellowish color, despite of their potential reflection from additional materials. Hence, the energy of these phonons is shifted towards the mid and high frequencies. The bottom and the canvas reduce high frequencies. Reflections from the canvas affect mostly the right side of the room, whereas the impact of the carpet is much greater, see <ref type="figure" target="#fig_5">figure 4b</ref>. While a potential frequency shift can already be seen in a material's absorption coefficients, their impact on room acoustics can be studied much better with the aid of our visualization.</p><p>In <ref type="figure" target="#fig_7">figure 5</ref> we replaced the carpet by a material with similar absorption as the walls. When comparing figures 5b and 5c, it becomes evident that this change is sufficient for increasing the intensities of mid and high frequencies. The acoustic properties of this room are significantly improved by this modification, since low frequencies are also propagated by diffraction and thus do not depend on linear reflections that much. While the acoustics of the laboratory are not much of importance, it may have a greater impact on the design of larger classrooms. Optimizing the acoustics of such larger rooms may, for example, eliminate the need of using a mi-  crophone or improve the auditive quality of concerts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Simulation</head><p>We have applied our simulation and visualization method to the virtual models of three different rooms, a closet, the VR-laboratory, and a medium sized classroom. The computation times for tracing 1M phonons on a 2.4GHz Processor are listed in table 1. Due to the large number of reflections, the number of different paths is much smaller than the number of phonons. The times for collecting phonons and filtering are about the same as the tracing times, due to the visibility test. If the latter is dropped, the filters can be constructed at nearly interactive rates. The table shows that the time complexity of our method does not depend very much on the complexity of the scene, due to octree partitioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head><p>In order to validate our simulation results, illustrated in figures 9 and 10, we compared them to measurements and simulations obtained by a commercial room-acoustics program CARA       The sound field was produced by a single loudspeaker (blue box) and measurements were taken at five positions, see <ref type="figure" target="#fig_8">figure 6</ref>. The box was fed with sinusoidal signals of different frequencies ranging from 46.9 Hz to 24000 Hz. Each signal was displayed long enough (0.75 sec) to damp out other frequencies. The same input signal was convolved with the impulse responses simulated with both CARA and our algorithm. <ref type="figure" target="#fig_15">Figure 11</ref> shows a comparison of the measured and simulated pressures at a frequency of 750 Hz. At frequencies lower than 400 Hz, the results of both simulations differ significantly from our measurement, which may be due to diffraction effects and errors in the absorption coefficients (used by both simulations). At medium and high frequencies, our simulated pressures were mostly closer to the measured pressures than those obtained by CARA, due to the greater number of computed reflections. We note, however, that these measurements were very sen- sitive with respect to the microphone position, particularly in the high-frequency range.</p><p>In addition, we compare the descent of the residual energy, calculated from the impulse response simulated with both CARA and our algorithm. The residual energy descent is illustrated in <ref type="figure">figure</ref> 12. Ideally, the descent is exponentially, implying a constant slope in the logarithmic figure. Due to the limited number of reflections considered by CARA, their reverberation is cut off after a short time period, whereas the (logartihmic) decay in our solution is nearly linear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>We presented a new particle tracing method for the auralization and visualization of room acoustics. The results obtained by our simulation compare favorably to existing methods. Our interactive visualization helps to optimize acoustic properties of class-and concert rooms. It is particularly useful for determining the impact of certain materials, allowing their interactive exchange. Future work will be directed at the integration of our method into a unified virtualreality framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>position of sound source s • emission distribution E of sound source • one or more listener positions l i • a triangulated scene with tagged materials m j • an absorption function α j : Ω → (0, 1] for each material • an acoustic BRDF for each material (if applicable)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Absorption functions α i for different materials, provided by CARA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Bandpass filter, (a) in spectral domain; (b) in time domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Selecting wave fronts by material reflection. (a) Phonons reflected at least once by a wall; (b) phonons reflected from bottom; (c) phonons reflected from canvas (behind viewpoint).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Changing material of bottom. (a) all phonons at d = 1.5m; (b) phonons at d = 4.5m; (c) same as (b) with old material.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Geometry of closet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Geometry of the VR-laboratory.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Geometry of the classroom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 :</head><label>9</label><figDesc>Room impulse response and convolution with the anechoic signal of the three simulated rooms. (a+d) closet; (b+e) laboratory; (c+f) classroom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 10 :</head><label>10</label><figDesc>Anechoic signal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>(</head><label></label><figDesc>www.cara.de) based on the image-source method. All signals have a sampling rate of 48 kHz. To keep modeling errors low we chose a simple box-shaped closet room (1.9m × 1.61m × 2.49m, see figure 6) with a small number of faces and different absorption coefficients according to figure 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 11 :</head><label>11</label><figDesc>Comparison of the recorded amplitude at 750Hz (red) with results from phonon tracing (blue) and CARA (green).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 12 :</head><label>12</label><figDesc>Comparison of residual energy descent in db. (a) phonon tracing; (b) CARA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Computation times for constructing the phonon map based on one million phonons.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">www.cara.de</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the Stiftung Rheinland Pfalz für Innovation under contract no. 15202-386261/644. We thank Lars Kurandt and Norbert Siedow for their helpful comments and discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image method for efficiently simulating small-room acoustics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berkeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. So. Amer</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="943" to="950" />
			<date type="published" when="1979-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Extension of the image model to arbitrary polyhedra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Borish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. So. Amer</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1827" to="1836" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Non uniform random variate generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devroye</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A beam tracing approach to acoustic modeling for interactive virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Carlbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Elko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sondhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH 98)</title>
		<meeting><address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-07" />
			<biblScope unit="page" from="21" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Real-time acoustic modeling for distributed virtual environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Carlbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIG-GRAPH 99)</title>
		<meeting><address><addrLine>Los Angeles</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-08" />
			<biblScope unit="page" from="365" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Computation of room acoustics using programable video hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jedrzejewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marasek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision and Graphics ICCVG</title>
		<meeting><address><addrLine>Warsaw, Poland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-09-22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Global illumination using photon maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rendering Techniques &apos;96 (Proceedings of the 7th Eurographics Workshop on Rendering)</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient simulation of light transport in scene with participating media using photon maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH 98)</title>
		<imprint>
			<date type="published" when="1998-07" />
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient importance sampling techniques for the photon map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Wald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision, Modelling and Visualization</title>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Volumetric visualization of acoustic fields in cnmat&apos;s sound spatialization theatre</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khoury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Freed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wessel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;98</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">562</biblScope>
			<biblScope unit="page" from="439" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Acoustic simulation of rooms with boundaries of partially specular reflectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Korany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Alim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Acoustics</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="875" to="887" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Calculating the acoustical room response by the use of a ray tracing technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Krockstadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sound and Vibrations</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">18</biblScope>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Algorithmic representation of the ray tracing technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kulowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Acoustics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="449" to="469" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Physically-based Auralization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Helsinki University of Technology</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An efficient auralization of edge diffraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Savioja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Audio Engineering Society, 21th International Conference</title>
		<meeting><address><addrLine>St. Petersburg, Russia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-06" />
			<biblScope unit="page" from="166" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Acoustic simulation and visualization using a new unified beam tracing and image source approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dorsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convention of the Audio Engineering Society</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Acoustic rendering of buildings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rabenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Schips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stenger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Int. IBPSA Conference Building Simulation</title>
		<meeting><address><addrLine>Prag, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Auralization applying the parametric room acoustic modeling technique -the diva auralization system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Savioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huopaniemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Auditory Display</title>
		<meeting><address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-05" />
			<biblScope unit="page" from="219" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Computer graphics visualization for acoustic simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stettner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Graphics and Interactive Techniques</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1989" />
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Edge diffraction in room acoustics computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">P</forename><surname>Svensson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kleiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EAA Symposium on Architectural Acoustics</title>
		<meeting><address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simulation of the transient and steady-state sound propagation in rooms using a new combined ray-tracing/image-source algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vorländer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoust. So. Amer</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="172" to="178" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
