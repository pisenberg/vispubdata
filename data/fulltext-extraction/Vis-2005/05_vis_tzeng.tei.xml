<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Opening the Black Box -Data Driven Visualization of Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan-Yin</forename><surname>Tzeng</surname></persName>
							<email>tzengf@cs.ucdavis.edu</email>
							<affiliation key="aff1">
								<orgName type="department">IDAV &amp; Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>One Shields Avenue</addrLine>
									<postCode>95616</postCode>
									<settlement>Davis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwan-Liu</forename><surname>Ma</surname></persName>
							<email>ma@cs.ucdavis.edu</email>
							<affiliation key="aff1">
								<orgName type="department">IDAV &amp; Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>One Shields Avenue</addrLine>
									<postCode>95616</postCode>
									<settlement>Davis</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California at Davis</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Opening the Black Box -Data Driven Visualization of Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Artificial Neural Network</term>
					<term>Information Visualization</term>
					<term>Visualization Application</term>
					<term>Classification</term>
					<term>Machine Learning</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Artificial neural networks are computer software or hardware models inspired by the structure and behavior of neurons in the human nervous system. As a powerful learning tool, increasingly neural networks have been adopted by many large-scale information processing applications but there is no a set of well defined criteria for choosing a neural network. The user mostly treats a neural network as a black box and cannot explain how learning from input data was done nor how performance can be consistently ensured. We have experimented with several information visualization designs aiming to open the black box to possibly uncover underlying dependencies between the input data and the output data of a neural network. In this paper, we present our designs and show that the visualizations not only help us design more efficient neural networks, but also assist us in the process of using neural networks for problem solving such as performing a classification task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In a human brain, a massively parallel information processing system is formed by about ten billion nerve cells (neurons) and their synapses. Artificial neural networks (ANN) <ref type="bibr" target="#b29">[30]</ref> are a class of techniques that mimic the processes found in biological neural networks and well established in the machine learning community for predicting and learning from a given set of data. There are over 50 different types of ANN in use today. ANNs and other learning tools such as Support Vector Machines <ref type="bibr" target="#b2">[3]</ref> have gained increased use in a variety of application areas, which should help dispel the misconceptions of Artificial Intelligence (and ANN).</p><p>ANNs are based on the combination of neurons, connections and transfer functions with various learning algorithms and layout methods for the neurons and their connections. After learning, an ANN represents a high-dimensional non-linear function.</p><p>A common problem in using ANN is that they act essentially as a black box <ref type="bibr" target="#b24">[25]</ref> that performs the assigned tasks for the user. The information stored in a neural network is a set of numerical weights and connections that provides no direct clues as to how the task is performed or what the relationship is between inputs and outputs. This limits the usage and acceptance of ANN since in many applications in science and engineering it is demanded to use techniques based on analytical functions that can be understood and validated. Further complicating the use of neural networks is the tedious process of parameter selection. Even when performing very similar tasks, the proper choice of network parameters can vary widely. These parameters, which include neural network structure, error bound, learning rate, training algorithm, hidden layer size, and the data vector used, are often chosen in a trial-and-error process.</p><p>We believe visualization, which proves to help illustrate and understand the behaviors of complex systems, can also help us understand ANNs and design better ANNs. Previous attempts in using visualization to gain understanding into ANNs, as discussed in Section 3, mainly studied the weights and connections of a neural network and analyzed neural networks in isolation; the data used by the neural network were mostly not looked at.</p><p>We therefore take a data-driven approach to the problem of visualizing ANN since gaining insights into a neural network requires the study of not only the network but also how it responds to the input data that it was designed to process. The methods we present enable the interactive exploration of both the input data and the neural network so as to gain more complete picture of how the neural network performs its task. The visualizations can also assist in the selection of network structure and other parameters for an assigned task, with the objectives to achieve better results and minimize the cost in terms of both space and time. Equally important is that the user can apply our visualization methods to study how neural networks use data, and gain further understanding into the potentially complex data relationships. In our work, we have applied visualization techniques to feed-forward neural networks trained with the back-propagation training algorithm <ref type="bibr" target="#b22">[23]</ref>, which is one of the most popular neural networks used for classification. Our designs and findings have helped us develop better intelligent visualization systems, and should also help others gain both understanding and confidence in using ANNs. <ref type="figure" target="#fig_0">Figure 1</ref> shows the structure of a three-layer artificial neural network. Each node in a layer is connected to all nodes (neurons) in the adjacent layer. Each connection between neurons has a weight, with the weights modulating the value across the connection. If the nodes in the input layer are represented by I 1 , I 2 , I 3 , ... ,I m , the nodes in the hidden layer are H 1 , H 2 , H 3 , ... , H n , and W i j is the weight on the connection between I i and H j , the value of a node in the hidden layer can be shown as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ARTIFICIAL NEURAL NETWORKS</head><formula xml:id="formula_0">H j = T F( n ∑ i=1 W i j × I i ).</formula><p>Likewise, an output node O k of the neural network can be shown as</p><formula xml:id="formula_1">O k = T F( m ∑ i=1 W jk × H j ).</formula><p>In order for a neural network to model non-linear relationships between inputs and outputs, a non-linear transformation is required. T F(x) is the non-linear transfer function shown in the right side of the nodes in <ref type="figure" target="#fig_0">Figure 1</ref>. In our work we use the standard sigmoid function which can be expressed as f (x) = 1/ 1 + e −x , and is the most commonly used transfer function for classification tasks in neural networks. When calculating the value of an output node, the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Visualization 2005</head><p>October 23-28, Minneapolis, MN, USA 0-7803-9462-3/05/$20.00 ©2005 IEEE. same transfer function is applied after summing up the results from the previous layer. This transfer function can convert the neural network from a linear to a non-linear system. A training process is required to activate the neural network. To train a network, a set of training inputs and desired outputs are required. At the beginning, the weights are set at random, and are iteratively modified to obtain a network which minimizes the error at the output for the training data. Once training has occurred, the network can be applied to data that was not part of the training set.</p><p>After training, that is, when the error between neural network outputs and the desired outputs is lower than a threshold, the neural network can be used to process data similar to the training samples by taking the new set of data as input, and calculating the output value O k using the same formula above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORKS</head><p>To better understand the underlying behavior of a neural network, there has been some research devoted in visualizing the neural networks. Craven and Shavlik <ref type="bibr" target="#b4">[5]</ref> surveyed a number of visualization techniques for understanding the learning and decision-making processes of neural networks, including Hinton diagrams, bond diagrams, hyperplane diagrams, response-function plots, and trajectory diagrams. A Hinton diagram uses a data matrix to represent nodes with showing the topological information of the neural network. A Bond diagram shows the neural network topology and applies triangles with different sizes to show the weights. These techniques are used to illustrate the idea of neural networks but are not practical due to the difficulty of showing a large network clearly. Streeter et al. <ref type="bibr" target="#b25">[26]</ref> described an interactive visualization tool for feed-forward neural networks. Tree/graph based visualization is used in their work. They display network topology and connection weights as well as the evolutionary adaptation process when the user is allowed to interactively adjust training parameters during adaptation. The weights are used directly without taking the weight in the next levels into account when a large weight does not necessarily indicate the importance of an input. A small weight in the next layer can cancel the influence of the previous weight. They also demonstrated that a larger network can be handled, but when a large number of weights are used, the visualization can become too complex and difficult to understand. In our work, we not only visualize the weights along with the selected data, but convert the weight information and the statistics of the selected data into color and size representations for the input nodes. More recently, Duch <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> introduced a new projection on a lattice of hypercube nodes to visualize the hidden and output node activities in a high dimensional space. This method can be applied to any type of neural networks. However, only the nodes are shown when the connections might also provide valuable information.</p><p>In addition to visualization of the neural network, rule extraction and numerical methods are also applied to study the contribution of variables in a neural network <ref type="bibr" target="#b13">[14]</ref>. Rule extraction was first mentioned by Gallant <ref type="bibr" target="#b10">[11]</ref> to describe the neural networks with a more understandable representation. Andrews et al. <ref type="bibr" target="#b1">[2]</ref> and Tickle et al. <ref type="bibr" target="#b27">[28]</ref> survey the rule extraction methods and divide them into categories. Garson <ref type="bibr" target="#b11">[12]</ref> and Goh <ref type="bibr" target="#b14">[15]</ref> multiply the weights between layers to obtain the relative importance of the input variables. Since the absolute values of the weights are used, the result does not provide the direction of the relationship. Olden and Jackson <ref type="bibr" target="#b20">[21]</ref> introduce a randomization approach to statistically analyze the input importance based on Garson's method <ref type="bibr" target="#b11">[12]</ref>. Dimopoulos et al. <ref type="bibr" target="#b5">[6]</ref> compute the partial derivatives of the neural network's output according to the inputs. The results can be positive or negative. If the partial derivative is negative, it indicates that the output of the neural network increases when the studied input variable decreases. A SSD (Sum of Square Derivatives) value can also be calculated which indicates the importance of each input variable. Scardi and Harding <ref type="bibr" target="#b23">[24]</ref> modify only one of the input variables at a time and the corresponding output is used to determine the influence of each input variable. The stepwise methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b26">27]</ref> add or reject one input variable at a time and the MSE (mean square error) of the output is used to identify the most important variables. Both the Scardi and Harding's and the stepwise methods are computational expensive since the network needs to be re-calculated a lot of times to obtain results corresponding to different input conditions.</p><p>We modify Garson's method for defining node importance in our data-driven neural network visualization, and provide a more convenient way for the user to interpret the results. In addition to node importance, the uncertainty and errors are also visualized and discussed to help both the designer and the user of a neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ANN VISUALIZATION</head><p>Our work focuses on the application of visualizing neural networks. In order to study this application, we apply our techniques in using neural networks to solve two specific problems, volume classification and spam classification.</p><p>Neural networks have been used for higher-dimensional classification in biomedical imaging <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b21">22]</ref> and volume visualization <ref type="bibr" target="#b28">[29]</ref> to identify and show features more precisely. In our work, we use the volume classification framework described in our previous research <ref type="bibr" target="#b28">[29]</ref>. The neural network is first trained by a small set of input data including the corresponding class IDs provided by the user. The input vector of a training data includes the voxel's scalar value, gradient magnitude, its six neighbors' scalar values, and its position. For example, the user provides sample data from regions of the volume they would like to visualize, and the network can learn to classify the entire volume.</p><p>The second application of our work is spam classification. With the wide usage of email, spam has become a problem that limits the effectiveness of email as a communication media. In early approaches, classification rules were defined by hand, but were costly and impractical since the spammer also learns and adapts their messages. Therefore, machine learning techniques are becoming more and more popular for learning and performing text classification <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b30">31]</ref>.</p><p>Neural network is employed in our spam classification work. The neural network is trained by a set of pre-classified spam and non-spam email where words or phrases in an email form the input vectors. The trained network can recognize the pattern of spam and filter new incoming messages. The user can then select a para-graph, an email, or a set of email as the input data when visualizing the network.</p><p>The information of a neural network is stored in its weights. However, the weights are difficult to interpret and represent only through mathematical formula or numerical analysis methods. We show the neural network analysis through visualization since understanding of the data-driven neural network requires interactivity to explore different sets of selected data, and visualization allows the user to perceive and process large amounts of information rapidly and make effective comparisons. The visualization methods include dual-domain interactive weight visualization, which allows the user to probe into the data domain and visualize the corresponding network, errors, and uncertainty visualization to help both the designer and the user of a neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Visualizing Weights -with single data</head><p>In our system, the user is provided with a probe to select data of interest in the data domain and visualize the neural network as data are passing through the network. That is, the user is able to look at local properties of the data selected through the dual-domain interaction.</p><p>To highlight the information in a neural network, we color the input and output nodes based on a selected voxel's value, where low value maps to blue, middle value maps to yellow, and high value maps to pink. The data is then multiplied by the weights and added together at the nodes as described in Section 2. When visualizing the weights in a neural network, we focus on the inputhidden layer so that the results can be mapped to the input data domain, which the user is more familiar with. A more important connection has higher weights on it, and its connected nodes have a higher impact to the output result, which is also valuable information about the data. We set the connection's width based on how important this connection is. However, a large weight between the input-hidden layer might connect to a small weight between the hidden-output layer and the effect will be canceled. That is, the resulting visualization could be misleading if the weights were used directly. Therefore, we propagate all the layer's influence by multiplying each weight between the input-hidden layer and the weight between the hidden-output layer which connect to the same hidden node. <ref type="figure" target="#fig_1">Figure 2</ref> shows the result of visualizing a neural network which performs volume classification to classify the brain material from an MRI head data set. The neural network is first trained by examples of brain and non-brain materials provided by the user. A voxel is then selected to perform the classification. When a voxel at the lower left of the slice is selected, the color of the output node shows that this data is not in the classified material. In addition, the connections indicate that the position and data value are the main factors of the selected voxel's classified result. In the right image, another neural network is shown where the user selected a voxel within the brain, and almost all inputs except the gradient magnitude are used for classifying this voxel to the brain material.</p><p>Although the trained network is the same, different behaviors occur when different inputs are selected, and can help the user to better understand the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Visualizing Weights -with a set of data</head><p>In addition to selecting a single piece of data, our system also allows the user to select a region of data or even an entire data set, and visualize the neural network with the selected data.</p><p>The to the final result. The user can then remove nodes that are not necessary using the computed node importance as a reference.</p><p>To estimate the importance of each input variable, we adapt Garson's method to our approach which considers the selected region of data. In Garson's method <ref type="bibr" target="#b11">[12]</ref>, the contribution of input node i to the output o through a hidden node j is computed by multiplying the input-hidden weight strength and the hidden-output weight strength.</p><formula xml:id="formula_2">c i jo = w i j × w jo</formula><p>The relative contribution from each input node k to a hidden node j can be represented as</p><formula xml:id="formula_3">r i jo = |C i jo | ∑ m k=1 |C k jo |</formula><p>, and the total contribution from an input node i is</p><formula xml:id="formula_4">S i = n ∑ j=1 r i jo .</formula><p>Finally, we can calculate the relative importance of an input node as</p><formula xml:id="formula_5">RI i = (S i / m ∑ k=1 S k ).</formula><p>The relative contribution is used to show the width of the connections between input and hidden layers. For two input variables which have the same influence on the results, the weights connected to them can be very different since the classification process includes the multiplication of input variables and weights. For example, if an input variable is small, the connections through this input node need to be larger to bring the input variable to the same level of importance as other nodes which have higher values. However, when only interpreting the network, this property is ignored.</p><p>Instead of using the network's weights directly, for selected data we divide the weights between the input-hidden layer by the mean, which is the average of all the data. This can make the node importance evaluation more accurate and specific to the data used. The use of mean is based on the assumption that the selected data have similar properties so that the input values are close to their mean. To compensate the estimation of using mean to represent a set of data, we also show the standard deviation (std) on the nodes to indicate data spread. The standard deviation can be represented as</p><formula xml:id="formula_6">S = 1 n − 1 n ∑ i=1 (X i − M) 2 ,</formula><p>where n is the number of all the data, X i is the value of the ith data, and M is the mean.</p><p>The colors of input nodes are assigned based on the similarity of the mean and standard deviation using the table in <ref type="figure" target="#fig_2">Figure 3</ref>. The color's red (R) component increases when the mean increases, green (G) increases when the standard deviation decreases, and blue (B) remains constant. From an input node's color, the user can obtain information about what the selected data's distribution is.</p><p>In addition to the input nodes, hidden nodes can also provide valuable information. For hidden node j, a value H j is calculated by passing the mean value of the selected data to the neural network.</p><formula xml:id="formula_7">H j = Sigmoid( n ∑ i=0 W i j × Mean i ),</formula><p>where n is the number of input nodes and W i j is the weight on the connection between input node i and hidden node j. The sum of all hidden nodes is equal to the output of the neural network after applying a sigmoid function. The percentage of H j to the sum of all hidden nodes can thus be used to represent the relative contribution of H j to the output, and used to assign the size of hidden node j. In <ref type="figure" target="#fig_3">Figure 4</ref>, two neural networks are shown. The lower left image is a neural network used to classify the head material and the rest of the MRI head using five properties as inputs, and all the training data assigned to the head class are used as the selected data for visualization with the neural network. A thicker connection from the input layer shows the corresponding input node is more important to the final result, and there is a threshold that hides the connections that are less important. As shown in <ref type="figure" target="#fig_3">Figure 4</ref>, scalar value is the most important feature to classify the data when the gradient and position have only minor impacts on the result. This matches the fact that the head can be easily separated with a traditional 1-D transfer function, which maps data value to opacity directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mean increase std decrease</head><p>The right image in <ref type="figure" target="#fig_3">Figure 4</ref> shows the result of classifying the boundaries, which are the regions with high gradient magnitude. In this example, the gradient magnitude and neighbors play a more important role in the classification, and the scalar value and position do not contribute significantly to the final result. Based on the size of hidden nodes, we remove four less important hidden nodes (the 1st, 10th, 13th, and 14th from the bottom) from the neural network after it is trained. The cost of classification is reduced by 15% when the result is only about 0.5% different from the original result. The most direct way to measure the performance of a neural network is to look at the error between the training results and the desired outputs over time. This error shows how well the neural network learned to perform classification, and also provides information about convergence. To validate our method and results obtained so far, we calculate the mean square error for different parameter combination, and compare the results with our visualization of neural networks. <ref type="figure" target="#fig_5">Figure 5</ref> presents an example of visualizing both the weights and the errors together using 20 hidden nodes and 11 input nodes. In the top image, scalar and gradient information are shown to be unimportant because the weights are smaller than the threshold and the connections are not shown. This can be validated by visualizing the errors in the bottom image. When only using scalar and gradient as inputs, the mean square errors are high and converge at the end. This indicates that even if more training time is given, the neural network cannot improve further. With additional neighboring information, the neural network can learn better but still with relatively high errors compared to the case of using scalar, gradient, neighbors, and position. The orange and blue curves show the results of removing scalar and gradient from the input dimensions. These two input combinations obtain results similar to when using all input dimensions.</p><p>With this system, we discovered that when the hidden layer size is small, scalar and gradient information are more important than the neighboring information because the network is not able to learn the complex relationship and direct criteria for classification such as scalar value and gradient are more helpful. When a larger network is used, it is able to learn indirect relationships such as texture, gradient, and local data range from the neighbors. This makes the scalar and gradient information, which can be derived from the neighbors, less important.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Spam Classifier</head><p>To demonstrate our methods with a larger network, we choose the application of spam classification using a data set that contains 400 email in the training set with 117 spam and 283 non-spam messages, and 200 email messages in the testing set where 61 of them are spam email.</p><p>Neural networks are powerful because of their ability to process high-dimensional data and to learn the non-linear relationships between inputs. Therefore, in most neural network applications such as text classification, the inputs are high-dimensional. Dimension reduction techniques are common and often required in the field of neural networks since large networks lead to slow performance. The selection of important input variables and the removal of unimportant ones can help to improve performance when maintaining the classification or clustering ability <ref type="bibr" target="#b18">[19]</ref>. <ref type="figure">Figure 6</ref> shows a spam-classifier neural network using 82 input nodes and 100 hidden nodes. The input, hidden, and output layers are shown from bottom to top. The network is trained to assign the email into two classes, spam and not spam. The data feeding through the network is a subset of the spam in the training set.</p><p>From the visualization of input nodes, we can identify important terms for classifying spam based on the nodes' visual properties. In <ref type="figure">Figure 6</ref>, the nodes for "free" and "need" are large, which indicate that they are two important words to distinguish spam and not spam in the data set. "Http" occurs in almost all the spam, which is indicated by the red color of the node since red represents high mean and low standard deviation. High mean and low standard deviation are obtained when the elements in the data have similarly high values, and a high value is assigned when the word is in spam. However, "http" is also a commonly used term in normal email, so the node size is not as big as "free" and "need". In <ref type="figure">Figure 6</ref>, the node represents "information" is very small since "information" is used in both spam and not spam with similar frequency, and not a useful criterion for classifying spam. "Problem" is a medium size node shown in green in the network. Green is assigned to nodes with low mean, that is, the data does not exist in most spam.</p><p>When more nodes and connections are used in a neural network, the visualization becomes more cluttered and difficult to study. <ref type="figure" target="#fig_6">Figure 7</ref> shows the result of ordering the input nodes onto a panel according to the statistics information where the colors and sizes of each node in <ref type="figure">Figure 6</ref> and <ref type="figure" target="#fig_6">Figure 7</ref> are the same. From left to right are the input nodes with increasing frequency of appearing in spam. This simplifies the visualization and provides a more organized view of the input nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Visualizing Uncertainty</head><p>During classification, the neural network outputs a value representing the uncertainty of the classification. High and low values indicate the input belongs to the two user-specified classes with low uncertainty, and middle values indicate high uncertainty where the data is difficult for the neural network to classify. Parallel coordinate <ref type="bibr" target="#b17">[18]</ref> is a method to represent multi-dimensional data and is a well-known technique for information visualization <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17]</ref>. In our work, parallel coordinates are used to show the inputs and outputs when training or classifying using a neural network. <ref type="figure" target="#fig_7">Figure 8</ref> shows the result of using parallel coordinates when the task is to classify volume data into brain and all the other materials. The input vector includes each voxel's scalar value, gradient magnitude, six neighbors' scalar values, and the position. The last dimension of the parallel coordinate system is the output (or desired output for training), and the other dimensions are used for the input vectors. <ref type="figure" target="#fig_7">Figure 8</ref> shows the training samples with the desired outputs on the left, and the classification results on the right. In the left image, the desired outputs are binary, and the material of interest is mapped to red when the others are mapped to light blue. In the right image, outputs are the results of applying the trained neural network to the whole data set. Dark blue lines are used to highlight the data that are difficult for the system to classify.</p><p>When looking at the dark blue data, more understanding of the classification can be obtained. For example, the training data (left image) only contains data with low values for position z, and in the right image, the dark blue data always have high values for position z. That is, the training set includes insufficient number of examples with high z value for the neural network to learn this case. The user can then provide more training samples that consider high z values. This provides immediate understanding of the types of data that are well-classified and not well-classified.</p><p>An additional application designed specifically for volume data is to visualize the uncertainty of the classification result in the original volume data space. The left image in <ref type="figure">Figure 9</ref> is a slice of the volume data with colors showing the classification result. When a voxel is mapped to pink or blue, it shows that this voxel is well classified to one of the classes. Colors in the middle of the colorbar, for example, yellow and green, are used when the data are not well-classified by the neural network. This gives the user a better understanding of the data in the spatial domain. However, the green-to-yellow colors not only represent data that are difficult to classify, but also the boundaries between the brain and other materials due to the interpolation during rendering. Therefore, when rendering the uncertainty information of the entire volume, a thin green-to-yellow layer will cover the whole brain. This can cause misunderstanding of the classification results as shown in the middle image of <ref type="figure">Figure 9</ref>.</p><p>To remove the uncertainty caused by interpolation, we modify the coloring method as shown in <ref type="figure" target="#fig_0">Figure 10</ref>. In the left is a curved surface representing the boundary of the classification. Two adjacent voxels in the direction of the surface normal are assigned to http information need free problem <ref type="figure">Figure 6</ref>: A spam classifier with 82 input nodes and 100 hidden nodes. From bottom to top: Input layer, hidden layer, and output layer. The network is trained to classify email into spam and not spam where each input is a term in the email, and the data feeding through the network is a subset of the spam in the training set. pink and blue based on the user defined color map. During rendering, the opacity of a voxel is obtained by looking up a transfer function with the interpolated data value, and case 1 shows the segment between the two voxels with the interpolated color. After being multiplied by the interpolated opacity, the color on the classification boundary becomes yellow, which is not desired. Case 2 is the desired color assignment. There is a binary color assignment between the two voxels. Our method is shown in Case 3. For a voxel p 2 , the opacity is assigned based on the interpolated result, and the voxel p 1 , which is one voxel away from p 2 in the opposite direction of the surface normal, is used to look up the color assigned to p 2 . The result is shown in the right image of <ref type="figure">Figure 9</ref>. The colors are assigned by the neighboring voxel along the opposite direction of the normal so that only the classification uncertainty is shown. This image can help the user to identify regions that are not well classified in the 3D volume and guide the user to provide more training samples or add classification criteria to the current neural network.  The desired color assignment. The color changes at the boundary of two materials where no blending region exists. Case 3: Assign a voxel's color based on the value of the neighboring voxel along the opposite normal direction. After applying the interpolated opacity, the same color as in Case 2 can be obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High mean Low mean</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Machine learning is gaining widespread use in a variety of application areas. Methods such as artificial neural networks prove to be powerful in performing certain tasks and would become even more widely employed if they can be better understood by the users. Generally, users need to know how a decision is made and how cost/performance can be better managed. We have shown that properly designed visualizations can give us a sense of the behaviors of the network, how input data are used in the decision, and the level of uncertainty. In particular, we show that it is advantageous to couple visualization of network with visualization of the data. While the visualization cannot explain the learning, it effectively provides pointers to the user for refining their problem solving strategies using machine learning. Future work includes studying different neural networks and other machine learning methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A three-layered artificial neural network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>connections of a neural network are shown with width representing the weight strength. Input node size is assigned based on the node importance, and input nodes are colored based on their statistical information. A hidden node's size shows its contribution Dual-domain interaction between the data and neural network. In the input layer, s is the scalar value, g is the gradient magnitude, n is the neighboring information, and p is the x, y, and z position of the voxel. When a different voxel is probed, the visualization of the data-driven neural network would change. The left image shows the importance of position to assign the selected voxel on the left to a class, and the right image indicates that classifying the brain relies on all dimensions except the gradient magnitude.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>A table for assigning an input node's color based on its mean and standard deviation. A green node indicates the inputs have low mean and high standard deviation, and a red node represents high mean and low standard deviation distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>The left image shows a neural network which is trained for classifying the entire head from the data set. The scalar value is the main criterion considered in this classification. The right image is the result of classifying the boundaries. In this case, neighbors and gradient magnitude are shown to be more important. The classification result is shown at the upper right of each network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>The neural network for classifying the brain material is shown on the right. Scalar and gradient magnitude are unimportant compared to the neighboring information and position, and this can be verified by visualizing errors shown at the bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Result of ordering the input nodes onto a panel according to the statistics information where the colors and sizes of each node are the same as those inFigure 6. This provides a simple view of the input nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Parallel coordinates showing the classification uncertainty. The red and light blue lines represent two different classes, and the dark blue lines represent the data that is not well-classified. The left image shows the training data where data with high z values is missing, and the right image is the result of classification where the blue data also have high values for position z. This suggests that the training set is not wide enough and more samples with high z values are needed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :Figure 10 :</head><label>910</label><figDesc>Classification uncertainty shown in the volume data domain. The colorbar is used for color mapping to different uncertainty values. The left image is a slice classified by a trained neural network. The middle image the result of rendering the uncertainty directly as a volume, where a thin layer of green material is introduced by the interpolation during rendering. The right image shows the result of color assignment using our method as presented in Figure 10. = P2.position -N P2.color = P1.color * * Three different methods for assigning a interpolated color for classification uncertainty. Case 1: Assign color based on the interpolate value by looking up the color map. This will cause a thin layer of wrong color because of the interpolation. Case 2:</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work has been sponsored in part by the U.S. National Science Foundation under contracts ACI 9983641 (PECASE), ACI 0222991, and ANI 0220147 (ITR), ACI 0325934 (ITR), and the U.S. Department of Energy under Lawrence Livermore National Laboratory Agreement No. B537770, No. 548210 and No. 550194. The authors would like to thank members of the UCD visualization and graphics group for the valuable discussion and providing the test data sets.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Text categorization: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kjersti</forename><surname>Aas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Line</forename><surname>Eikvil</surname></persName>
		</author>
		<idno>941</idno>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Norwegian Computing Center</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A survey and critique of techniques for extracting rules from trained artificial neural networks. Knowledge Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Diederich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">B</forename><surname>Tickle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="373" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comparison of neural network and fuzzy clustering techniques in segmenting magnetic resonance images of the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><forename type="middle">M</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth annual workshop on Computational learning theory</title>
		<meeting>the fifth annual workshop on Computational learning theory</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Context-sensitive learning methods for text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="173" />
			<date type="published" when="1999" />
			<publisher>TOIS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Visualizing learning and computation in artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jude</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Artificial Intelligence Tools</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="425" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural network models to study relationships between lead concentration in grasses and permanent urban descriptors in athens city (greece)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ioannis Dimopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aikaterini</forename><surname>Chronopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sovan</forename><surname>Chronopoulou-Sereli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="157" to="165" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Support vector machines for spam categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1048" to="1054" />
			<date type="published" when="1999-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visualization of hidden node activity in neural networks: I. visualization methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wlodzislaw</forename><surname>Duch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Soft Computing</title>
		<meeting>the International Conference on Artificial Intelligence and Soft Computing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="38" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Visualization of hidden node activity in neural networks: Ii. application to rbf networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wlodzislaw</forename><surname>Duch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Soft Computing</title>
		<meeting>the International Conference on Artificial Intelligence and Soft Computing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="44" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchical parallel coordinates for exploration of large datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying-Huey</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elke</forename><forename type="middle">A</forename><surname>Rundensteiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization 1999 Proceedings</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Connectionist expert systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">I</forename><surname>Gallant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="152" to="169" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interpreting neural-network connection weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Garson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI. Expert</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="47" to="51" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Neural networks for volumetric MR imaging of the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erol</forename><surname>Gelenbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutao</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ranga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krishnan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>August</publisher>
			<biblScope unit="page" from="194" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Review and comparison of methods to study the contribution of variables in artificial neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muriel</forename><surname>Gevrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Dimopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sovan</forename><surname>Lek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="249" to="264" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Back-propagation neural networks for modeling complex systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T C</forename><surname>Goh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence in Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="143" to="151" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A comparison of neural network and fuzzy clustering techniques in segmenting magnetic resonance images of the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amine</forename><forename type="middle">M</forename><surname>Bensaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><forename type="middle">P</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Velthuizen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">S</forename><surname>Silbiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks</title>
		<imprint>
			<date type="published" when="1992-09" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="672" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Angular brushing of extended parallel coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helwig</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Ledermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Doleisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Information Visualization</title>
		<meeting>IEEE Symposium on Information Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="127" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The plane with parallel coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Inselberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="69" to="92" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Feature reduction for neural network based text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Y</forename><surname>Savio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dik</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lun Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Database Systems for Advanced Applications (DASFAA)</title>
		<meeting>the Sixth International Conference on Database Systems for Advanced Applications (DASFAA)</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Use of artificial neural networks for modelling cyanobacteria anabaena spp. in the river murray, south australia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Holger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><forename type="middle">C</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Dandy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="257" to="272" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Illuminating the&quot;black box&quot; a randomization approach for understanding variable contributions in artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><forename type="middle">D</forename><surname>Olden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">A</forename><surname>Jackson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="135" to="150" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Neural Networks and Intellect: Using Model-Based Concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><forename type="middle">I</forename><surname>Perlovsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning representations by backpropagation error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Developing an empirical model of phytoplankton primary production: a neural network case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Scardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">W</forename><surname>Harding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecological Modelling</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="220" to="233" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nonlinear black-box modeling in system identification: a unified overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Sjberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lennart</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Benveniste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Delyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Yves</forename><surname>Glorennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hkan</forename><surname>Hjalmarsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoli</forename><surname>Juditsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica (Journal of IFAC)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1691" to="1724" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Nvis: An interactive visualization tool for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Streeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE Symposium on Visual Data Exploration and Analysis VII</title>
		<meeting>SPIE Symposium on Visual Data Exploration and Analysis VII</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ranking importance of input parameters of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="405" to="411" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The truth will come to light: Directions and challenges in extracting the knowledge embedded within trained artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">B</forename><surname>Tickle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostefa</forename><surname>Golea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Diederich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1057" to="1068" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An intelligent system approach to higher-dimensional classification of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan-Yin</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwan-Liu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Werbos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974" />
		</imprint>
		<respStmt>
			<orgName>Department of Applied Mathematics, Harvard University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A neural network approach to topic spotting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Wiener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">O</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">S</forename><surname>Weigend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SDAIR &apos;95</title>
		<meeting>SDAIR &apos;95</meeting>
		<imprint>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Annual Symposium on Document Analysis and Information Retrieval</title>
		<imprint>
			<biblScope unit="page" from="317" to="332" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
