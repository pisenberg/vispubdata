<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Magic Volume Lens: An Interactive Focus+Context Technique for Volume Rendering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lujin</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Visual Computing</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Visual Computing</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Mueller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Visual Computing</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Kaufman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Visual Computing</orgName>
								<orgName type="department" key="dep2">Computer Science</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Magic Volume Lens: An Interactive Focus+Context Technique for Volume Rendering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation-Viewing algorithms; I.3.3 [Computer Graphics]: Picture/Image Generation-Display algorithms I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Color</term>
					<term>shading</term>
					<term>shadowing</term>
					<term>and texture Focus+Context Techniques</term>
					<term>Lens</term>
					<term>Volume Rendering</term>
					<term>Hardware-assisted Volume Rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Figure 1: Magic volume lens results. (a) magnifying inside features in an arbitrary-shaped area on an engine, (b) applying sampling-rate-based lens on a foot, (c) enlarging area of interest on an aneurism, (d) magnifying the duodenum of a segmented frog dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent years have seen a dramatic growth in our ability to compute, acquire, and assemble datasets of increasingly large magnitudes and * e-mail: {lujin|yezhao|mueller|ari}@cs.sunysb.edu resolutions. Great advances have also been made in screen technology, bringing high-resolution displays to the desktop at affordable prices, as well as offering sophisticated CAVE environments. The one device that has consistently resisted participation in this spiral of growth is the human eye and the cortical visual processing abilities. In fact, there is a natural limit on the screen pixel density, as a function of distance, which the human eye can resolve, and there is also a natural falloff of retinal receptor density towards the foveal periphery. Finally, there is also a bound on the information the human brain can visually process at any given time, but this is probably an ability that can be trained the most. In view of these natural limitations, which are bound to stay, we must devise ways to make the best use of the available retinal surface and cerebral potential, in light of the growing amount of visual information ready to be presented. These efforts have commonly been labelled focus+context techniques, where the resolution of the visual information presented is highest in the foveal center and then falls off towards the periphery in some smooth fashion, without performing any clipping of the viewed large object. Multi-resolution techniques, or even semantic zooms, can be employed to navigate across the resolutions in visual space, and a great number of techniques to control these have been described in the past, including various forms of lenses, warps, and distortions. On the other hand, there have also been a number of methods and metaphors to aid the user in the perceptional navigation of a dataset or object, such as stylized highlighting of features, cut-away views, and folding.</p><p>Interactive operability is the prime key to a successful user experience and his/her exploration and immersion in the data, and the GPU has provided an attractive platform to achieve these goals. Our work embraces this technology to provide a novel focus+context tool that unifies and extends a variety of existing methods in this area. Our techniques are primarily designed for volumetric objects, which have received the least amount of attention so far. Our framework provides a free-form volumetric lens function that can be feature-adaptive or user-configurable for a high-quality, anti-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>367</head><p>Please see supplementary material on conference DVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Visualization 2005</head><p>October 23-28, Minneapolis, MN, USA 0-7803-9462-3/05/$20.00 ©2005 IEEE.</p><p>aliased, and interactive display with smooth transitions from highto low-resolution areas. It is somewhat related to the importancedriven visualization system, recently described by Viola et al. <ref type="bibr" target="#b21">[22]</ref>, but our method allows users not only to highlight and expose an object, but also to non-linearly magnify the object for closer inspection in its spatial and semantic context.</p><p>Our paper is structured as follows. We first present an overview of previous work on this subject, in Section 2, and then describe our volumetric lens, in Section 3 and GPU implementation in Section 4. Finally, we present results, in Section 5, and end with conclusions, in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>Focus+Context Visualization Many techniques have been developed in this area. Zhou et al. <ref type="bibr" target="#b24">[25]</ref> devised focus-region based volume rendering for volume feature enhancement. Volume data inside and outside the focus region are rendered in different styles, and the distance to the focal point is further included to control the optical properties of volume features in the context region <ref type="bibr" target="#b23">[24]</ref>. Gaze-directed volume rendering <ref type="bibr" target="#b16">[17]</ref> takes the observer's viewing focus into account to increase the rendering performance. The volume dataset is rendered at different resolutions, with the focal region represented at full resolution and the other parts at a lower resolution. Importance-driven volume rendering <ref type="bibr" target="#b21">[22]</ref> is a viewdependent model for automatic focus+context volume visualization. The object importance is added as a new dimension to the traditional volume rendering pipeline in order to maximize the visual information. This technique removes or suppresses less important parts of a scene to reveal more important underlying information.</p><p>Cut-Away Views and Extensions Cut-away viewing, also known as volume cutting <ref type="bibr" target="#b19">[20]</ref>, is another way to display volumetric objects. Various cut-away techniques can be achieved automatically <ref type="bibr" target="#b6">[7]</ref>, and many improvements have been made. Instead of disposing cut-away volume parts, McGuffin et al. <ref type="bibr" target="#b17">[18]</ref> use deformations for browsing volumetric data. Tory et al. <ref type="bibr" target="#b20">[21]</ref> provide a framework, called ExoVis, for simultaneously viewing detail and context in volumetric data sets. It allows users to view multiple slices of a volume at arbitrary orientations, along with multiple subvolumes rendered in different styles. All slices and subvolumes are outside or surrounding a 3D overview of the dataset.</p><p>Lenses and Distortion Lenses in real world can be quite complicated <ref type="bibr" target="#b12">[13]</ref>. However, simple lenses and magnifications are still very useful and have been thoroughly studied for text, image and information visualizations <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>. Bier et al. <ref type="bibr" target="#b0">[1]</ref> introduced Toolglass and Magic Lenses as a see-through interface to modify the visual appearance of application objects, enhance data of interest or suppress distracting information. Viewpointdependent distortion of 3D data, see <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> for example, highlights regions of interest by dedicating more space to them. On the other hand, relatively little work has been done on lenses in the domain of volume visualization. Cignoni et al. <ref type="bibr" target="#b4">[5]</ref> provided the Magicsphere metaphor to visualize 3D data with a MultiRes filter. LaMar et al. <ref type="bibr" target="#b14">[15]</ref> integrated a 3D magnification lens with a hardware-texture based volume renderer. Zooming is accomplished by modifying texture coordinates, and the 2D perspective correct textures technique is extended to 3D in order to obtain the correct texture coordinates for the lens border. Multiple segments on the border are needed to generate more natural circular lenses. Wei et al. <ref type="bibr" target="#b22">[23]</ref> applied fisheye views to magnify particle track volume data using nonlinear magnification functions. Cohen and Brodlie <ref type="bibr" target="#b5">[6]</ref> magnify volume data by generating a new volume using inverse distortion functions, however, this method is slow and is memory-intensive. Further research is clearly needed to design better lenses and find efficient implementations for volume data.</p><p>GPU-based Volume Rendering GPU-accelerated volume rendering can be based on textures <ref type="bibr" target="#b7">[8]</ref> or ray casting <ref type="bibr" target="#b13">[14]</ref>. Here we will not list all the papers on GPU-based Volume Rendering. Since our volume lenses are designed based on changes in ray direction or ray sampling rate, it is straightforward to implement, as well as extend, them using a ray casting approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VOLUMETRIC LENSES</head><p>In this section we describe several volumetric lenses which are based on geometric optics and conform to sampling theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Magnifier</head><p>The magnification lens, called magnifier in this paper, is based on the magnification model in optical physics. It provides users a method for close inspection of regions of interest in volumetric objects. <ref type="figure" target="#fig_0">Figure 2</ref> illustrates the principle of a magnifier. The blue line segment represents a magnifier lens positioned on the image plane by the user. LC is the center point of the lens and F is the virtual focal point. When orthogonal incident rays hit the image plane, in the region of the magnifier, then the ray directions are modified and go through the focal point F. Therefore, a ray cone is formed between the lens and F. The objects within this cone are rendered in a larger area on the image plane than their original size, while the other objects retain their original size. Consequently, the objects in the region of interest are magnified. In the basic scenario described above, objects located between the orthogonal rays and the focused rays will not be visible on the image plane. This causes a loss of spatial context for the observed objects and has to be compensated for by special treatments. Our solution is to add a transition region close to the border of the ray cone where the directions of rays are gradually changed from the focused direction to the orthogonal direction. In <ref type="figure" target="#fig_0">Figure 2</ref>, the transition region is represented by the red line segments on the image plane with a width lb, lr is the radius of the lens, and the magnification region of the lens is shown as the blue line segment. For a ray starting from a point P I in the transition region, the direction is computed according to the distance from P I to LC as follows: </p><formula xml:id="formula_0">|P F − F| lr = |P I − LC| − (lr − lb) lb ,<label>(1)</label></formula><formula xml:id="formula_1">(a) (b) (c) (d)</formula><formula xml:id="formula_2">P F = F + P I − LC |P I − LC| • |P F − F|,<label>(2)</label></formula><p>ray dir = P F − P I .</p><p>where P F is the point at which this ray passes through the virtual lens focus plane, which is parallel to the image plane and includes the focal point F.</p><p>As a result of the transition region approach, while the objects inside the center region of the lens are magnified, the objects in the transition region are compressed. Therefore, continuous observation of the objects is achieved and no artificial data loss is introduced.</p><p>Based on this method, we are able to design magnifiers with any arbitrary shape. Results obtained by using magnifiers in volume rendering are shown in <ref type="figure" target="#fig_1">Figure 3</ref>.  The magnification factor can be changed by modifying the focal point position. Moving virtual focal point F towards the image plane achieves a higher magnification factor and vice versa. The GPU acceleration makes it possible for users to choose this interactively. At the same time, the users can also change the size of the magnifier, for example, the radius of a circular lens, and the size of the transition region to generate the desired results.</p><p>Our volumetric lenses are based on ray casting and it can be easily detected whether a ray pass the feature, therefore the magnifier can be utilized to enlarge only features of interest in the observed (a) (b) volumetric object. The magnification method is straightforwardly applied to the segmented volumetric datasets. The ray modification method does not interfere with the composition of the voxels with different properties because of their segmentation. <ref type="figure" target="#fig_4">Figure 5</ref> shows the results of applying the magnifier to show the bone features of a segmented frog dataset. Since in the transition region, the ray sampling rate is relatively low, aliasing could occur. Although this is not always noticeable in practice, anti-aliasing techniques can be applied to generate better results. A solution is to use volume texture mip-mapping to adaptively choose the appropriate resolution of the volume data for rendering. A lower resolution volume is chosen for regions sampled at a lower rate, in order to eliminate aliasing. One can determine the required mip-map level by calculating the magnification factor m f</p><formula xml:id="formula_4">for point P R , m f = |P R − P RI | |F − LC| ( lb lr − 1) + 1.<label>(4)</label></formula><p>where P RI is the orthogonal projection of P R on the image plane. This factor will determine the mip-map level that needs to be used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature-based lens</head><p>Feature-driven volume visualization provides users a highlighting and exposition of the portions of interest in volume objects. This facilitates an accurate and differentiated understanding of the important features. Besides the traditional fixed-shaped lens used to magnify segmented datasets, our free-form magnifier can be employed to also achieve a feature-sensitive and feature-centric object enlargement. The difference is that the shape of the magnifier is defined dynamically by the shape of the features (represented by the segmentation information) in the dataset, within an arbitrary view port. This is illustrated in <ref type="figure" target="#fig_5">Figure 6</ref>. Whether an incident ray changes direction depends on the distribution of the feature and the current view port. Thus the direction of each ray has to be determined dynamically. Transition regions are also used here to retain the space context of the features. For each ray orthogonally incident upon the image plane, the new direction is computed as follows. Assuming all rays have changed directions to the focal point F,</p><p>• if a ray passes through the feature, then its new direction is pointing to F.</p><p>• if the ray does not pass through the feature but is inside the transition region on the image plane, the distance d (see <ref type="figure" target="#fig_5">Figure 6</ref>) from its entry point to the boundary of the featureprojected area is calculated. This distance is used to compute the new direction as in Equations1-3.</p><p>• otherwise, the ray continues along its original direction.</p><p>(a) (b) On the image plane, the distance from a pixel to the boundary of the feature-projected area has to be calculated for some rays. This requires knowledge of the position of such an area on the image plane in each different view port. Therefore, a two pass computation has to be used, where the first pass defines the feature-projected region and the second pass computes the distance from a pixel to this region. Different distance computation methods can be used during the second pass. To facilitate the GPU acceleration for this algorithm, it has to be implemented based on local operations where each pixel only utilizes the knowledge of its neighborhood. Our implementation is to use a searching circle for each pixel with the transition region width lb as its maximal radius (see <ref type="figure" target="#fig_6">Figure 7</ref> for an illustration). Inside this circle, we compute a neighbor that is a feature projected point and has the smallest distance to the pixel. This smallest distance is used as the distance value for this pixel. This method is implemented directly as a fragment program on GPU (see Section 4).</p><p>Our lens can be combined with any feature-based ray casting volume rendering method, for example, the two level volume rendering technique <ref type="bibr" target="#b8">[9]</ref> for segmented volume data. <ref type="figure" target="#fig_7">Figure 8</ref> shows some rendering results for a color volume dataset, in which a user selected feature is magnified and the other objects near that feature are compressed. <ref type="figure" target="#fig_7">Figure 8a</ref> shows the skin of the brain. <ref type="figure" target="#fig_7">Figure 8b</ref> shows an interior structure of the brain, without rendering other features which occlude this structure, while the magnified structures are shown in <ref type="figure" target="#fig_7">Figure 8c</ref> and 8d. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sampling-rate-based lens</head><p>We introduced two magnification lenses that modify the casted rays using geometric optics. They are implemented directly by changing ray directions from different areas of the image plane. The distribution of the areas can be user-defined or feature-based. In this section, we define a lens from another point of view. The rays casted towards the observed object may have varying densities in different portions of the object. This results in a varying sampling rate for the object. Therefore, this special lens is called sampling-ratebased lens. Various sampling functions could be adopted to define various volumetric lenses and to achieve different volume rendering results. we can use these lenses in conjunction with the mip-map volumes discussed in Section 3.1.  We illustrate the idea of this lens in 1D in <ref type="figure" target="#fig_9">Figure 9</ref>, where a sampling rate function is shown at the top and the corresponding rays are shown at the bottom. In the sampling rate function, lr is the lens radius, the vertical axis is the sampling rate and the horizontal axis represents the distance to the lens center. The sampling rate close to the lens center is the highest. It then decreases and becomes even smaller than the original normal sampling rate towards the boundary of the lens. At the bottom of <ref type="figure" target="#fig_9">Figure 9</ref>, we can see that the rays shot to the object are dense in the center region of the lens and become coarser towards the boundary. Note that the distribution of pixels on the image screen is uniform and that the original orthogonal rays are also distributed uniformly. To distribute the rays according to the sampling rate function, the start point of a ray is not from its original starting pixel but depends on its distance to the lens center and the sampling rate. Thus, we need to compute the correct start point for each ray. As usual, the transition region approach is applied to this lens. Here, the magnification region plus transi-tion region must be exactly equal to the lens region, which means the distance from the cutting point (where sampling rate returns to normal) to the lens center must be equal to the radius of the lens, lr. Define sr as the sampling rate and sd as the sampling distance function. Here, sr is inversely proportional to the distance between sampling rays. We first precompute a coefficient C satisfying the integral equation:</p><formula xml:id="formula_5">lr 0 C • sd(s)ds = lr,<label>(5)</label></formula><p>sd(s) = 1 sr .</p><p>Then for each ray j, the distance between its real start point and the lens center can be calculated using Equation 7, which is the discrete form of the distance integral.</p><formula xml:id="formula_7">distance( j) = steps ∑ i=0 C • sd(i).</formula><p>(7) <ref type="figure" target="#fig_8">Figure 10</ref> shows the results with the sampling-rate-based lenses, comparing it with the results obtained with no lens and with the magnifier. The toes of the foot are rendered with different magnification effects. The difference between <ref type="figure" target="#fig_8">Figure 10b</ref> and 10c is mainly caused by the different magnification factor distributions on the lenses. For the magnifier, the factors for points, which project into the magnification region and locate on the same plane parallel to the image plane, are the same. Therefore, objects with the same depth are magnified uniformly. However, for the lens with cubic sampling function, the factor is the highest on the lens center and decreases gradually towards the lens boundary. Objects with projections closer to the lens center are magnified with higher magnification factors. Along any ray, the factor remains the same for different depthes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Angular lens</head><p>A common widely used lens is the fisheye lens <ref type="bibr" target="#b1">[2]</ref>, and our GPU accelerated general volumetric lens framework supports this type of lens as well. The fisheye lens is a specially designed lens which achieves wider viewing angles. The original fisheye lenses were photometric lenses designed to take photos of the entire sky. There are two main idealized fisheye projections, the hemispherical and the angular fisheye, which are common in computer graphics rendering <ref type="bibr" target="#b1">[2]</ref>. The hemispherical fisheye is less used due to the distortion introduced. An angular fisheye projection can be used for angles up to 360 degrees and is defined such that the distance from the pixel P to the center of the image is proportional to the angle α of the viewing direction (see <ref type="figure" target="#fig_0">Figure 12a</ref>). The ray direction corresponding to any pixel on the image can be calculated by a special transform from pixel coordinates to 3D polar coordinates <ref type="bibr" target="#b1">[2]</ref>. Our framework is based on a ray casting volume rendering scheme. This allows us to walk into the interior of the object to see the augmented volume rendering results. By using an angular lens, larger view port angles can be achieved and more objects can be accommodated in the final image. This is helpful in many interior volume rendering scenarios. A good example is virtual colonoscopy <ref type="bibr" target="#b9">[10]</ref>. When navigating inside the colon, more areas can be viewed to achieve a more efficient observation. <ref type="figure" target="#fig_1">Figure 13</ref> shows the result of viewing a colon from a point on the centerline of the colon. Comparing this with a normal perspective view with 120 degrees, more information can be obtained when using a 180 degrees angular lens. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">HARDWARE ACCELERATION</head><p>To achieve interactive focus+context volume rendering, we have implemented all of our volumetric lenses on contemporary graphic hardware. In GPU-accelerated ray casting volume rendering <ref type="bibr" target="#b13">[14]</ref>, front faces and back faces of the volume bounding box are drawn using OpenGL in two fragment passes to get the start and end points for all the rays. However, this approach can not be used for our volumetric lens. Because ray directions are not always orthogonal or perspective, we have to calculate the start and end points of each ray for the various lens algorithms described earlier. Hence, we implemented our own ray casting rendering algorithms with lens effects on the GPU. At first, we calculate the ray directions using the appropriate lens rules. Then, the intersection points of each ray with the bounding box of the volumetric object are computed. Finally, a ray traversal algorithm is implemented for a given step size, with the volume data (density, gradient or color) stored in 3D textures. All these algorithms are translated into Cg fragment programs. The current GPUs (e.g., NVIDIA GeForce 6800) have the required features, such as loop, early termination and branches, making it possible to implement our ray traversal method efficiently. For our magnifier and angular lenses, we use four passes fragment programs as follows:</p><p>• Pass 1: RayDirection Calculate the ray direction for each fragment based on the view port and lens parameters. Also the information about whether a ray goes through the lens or hits the feature of interest, or the distance to the lens center can be obtained to achieve different rendering effects. • Pass 2: RayTfrontback Compute the intersections of each ray with the volume bounding box, and store the distances from the front and back intersection points to the ray start point, denoted as t front and t back, which will be used along with the ray direction and view port parameters to define the intersection points in the next pass. • Pass 3: RayCasting Cast the ray into the volume and composite the color based on the volume data and transfer function. Different traditional volume rendering modes can be easily added into this pass. • Pass 4: Rendering Output the rendering results to the frame buffer. For the feature-based lens, one more pass called Pass 1+: RayLensBorder, is added before Pass 2, to calculate the distance field for the lens transition region and change the ray directions based on the distance.</p><p>For sampling-rate-based lenses, ray directions are never changed, but the real ray start points need to be computed. We also use the four-pass fragment programs, but the first pass is changed to Pass 1*: RayStartPoints, which computes the ray start points used in later passes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>We have implemented our methods on a Pentium Xeon 2.4GHz CPU with 2.5GB memory and an NVIDIA GeForce 6800 Ultra GPU with 256MB memory. In <ref type="table" target="#tab_0">Table 1</ref>, we report the data size and the performance of our method with GPU-accelerated computation. For comparison, we also include the performance of a simple ray casting volume renderer (utilizing the front faces and back faces) with the same data sets on the same GPU. All the performances are tested with 512 × 512 images and with a 1.0 step size. Note that our method has not been optimized for the GPU, therefore, we compare it with the simple ray casting implementation, which is also unoptimized. Our volume lens methods only slightly increase the rendering time comparing to the general ray casting method. In the future, we will implement the standard optimization methods, such  as empty space skipping to improve the performance. For example, the speed for aneurism data can be dramatically accelerated with space skipping. As a ray casting based augmentation for volume rendering, our volumetric lenses can be combined with many volume rendering modes, for example, direct volume rendering (DVR), MIP and DVR with no shading, DVR with gradient magnitude modulation, XRay and the two level volume rendering method for segmented data. We show results with several rendering methods in <ref type="figure" target="#fig_3">Figure 14</ref>, <ref type="figure" target="#fig_4">Figure 15</ref> and <ref type="figure" target="#fig_5">Figure 16</ref>.</p><p>Our lenses can be used to interactively choose and magnify regions or features of interest to see small details more clearly while the context region remains. The size and shape of the lenses, and the magnification factor also can be changed interactively, which allows the user to adjust the lenses for desired results. Demo videos that show the interactive volume lens renderings can be obtained at http://www.cs.sunysb.edu/∼lujin/paper/vis05.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We have described a universal and general volumetric lens framework that has applications in many domains. It allows users to apply any well known lenses, such as a fisheye lens in the context of volumetric distortion, as well as design free-style and featureadaptive lenses for arbitrary magnified focus+context viewing. For example, coupled with a GPU-based interactive segmentation algorithm it can be used to magnify the segmentation result at great detail and aid in its refinement. The support for free-style lenses, created with our lens design interface, can help illustrators to designed more helpful and informative visualizations of volumetric objects, emphasizing an arbitrary shaped region of interest without losing the context of its surround. Finally, the GPU acceleration of our magic volume lens allows all of these to be done at interactive speeds, fostering both creative design and exploration. In future work, we would like to extend this free-style zooming capabilities to multi-resolution data and to semantic zooms, where the data appearing under magnification comes from a different data source, or even texture synthesis. It may also proof helpful to users to provide an option for superimposing a lens-distorted lattice on top of the lens area, to aid in the assessment of the non-linear magnification effects.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Magnifier illustration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Magnifier volume renderings with (a) No lens, (b) Circular lens, (c) Square lens, (d) Arbitrary-shaped lens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 3ais the original volume rendering result with no magnifier andFigure 3b-d are the results obtained by using circular magnifier, square magnifier and arbitrary-shaped magnifier, respectively.Figure 4shows the transition regions, magnification regions of three magnifiers, and the rendering effects on enlarged portions ofFigure 3b-d.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Transition region and its rendering effect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Magnifier volume renderings for the bone feature in a segmented frog dataset. (a) and (b) are renderings without and with magnification under circular lens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Feature-based lens illustration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Distance computation on the transition region of the feature-based lens. (a) Distance field on the transition region, (b) Searching circle for each pixel outside the feature-projected region is used for local computation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Feature-based lens volume renderings for a segmented human brain color volume dataset. (a) without specifying any feature of interest, (b) with a feature of interest, which is not magnified and appears too small to be seen clearly. From (c) to (d) the magnification factor increases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Comparing volume renderings with (a) No lens, (b) Magnifier, and Sampling-rate-based lenses (c) Cubic sampling function (maximal sampling rate/normal sampling rate = 3), and (d) An arbitrary sampling function shown inFigure 11.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Sampling-rate-based lens illustration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 11 :</head><label>11</label><figDesc>Another sampling rate function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12b shows an image of a 180 degrees view on a bonsai with an angular lens. Angular lens. (a) Angular fisheye lens with 180 degrees illustration, (b) 180 degrees view of a bonsai with an angular fisheye lens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 :</head><label>13</label><figDesc>Virtual tour of the colon. (a) Perspective view with angle 120 degrees, (b) 180 degrees view with an angular fisheye lens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 14 :</head><label>14</label><figDesc>Magnification results. (a) and (b) are DVR results without and with magnifier, (c) and (d) are DVR with gradient magnitude modulation results without and with magnifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 15 :</head><label>15</label><figDesc>Feature-based lens results. (a)-(b) Feature frog heart is magnified, rendered with two level volume rendering method. The bone and eye retia are rendered with MIP, all other features are rendered with DVR, with different transfer function for each feature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 16 :</head><label>16</label><figDesc>Feature magnification results with magnification factor increasing from (a) to (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>GPU performance for different volume datasets.</figDesc><table><row><cell></cell><cell></cell><cell>Volume lens method</cell><cell></cell><cell>Simple ray casting</cell><cell></cell></row><row><cell>Data</cell><cell>Data size</cell><cell cols="4">Rendering speed (ms) Frames/second Rendering speed (ms) Frames/second</cell></row><row><cell>lobster</cell><cell>128 × 128 × 128</cell><cell>70</cell><cell>14.2</cell><cell>61</cell><cell>16.4</cell></row><row><cell>engine</cell><cell>256 × 256 × 110</cell><cell>95</cell><cell>10.5</cell><cell>74</cell><cell>13.6</cell></row><row><cell>bonsai</cell><cell>256 × 256 × 128</cell><cell>110</cell><cell>9</cell><cell>95</cell><cell>10.5</cell></row><row><cell>foot</cell><cell>154 × 263 × 222</cell><cell>97</cell><cell>10.3</cell><cell>90</cell><cell>11.1</cell></row><row><cell cols="2">aneurism 256 × 256 × 256</cell><cell>186</cell><cell>5.4</cell><cell>158</cell><cell>6.3</cell></row><row><cell>frog</cell><cell>502 × 472 × 138</cell><cell>308</cell><cell>3.3</cell><cell>258</cell><cell>3.9</cell></row><row><cell>(a)</cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(c)</cell><cell></cell><cell>(d)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This work has been supported by NSF grants CCR-0306438 and ACI-0093157. The datasets are courtesy of GE, National Library of Medicine, Lawrence Berkeley National Laboratory, Philips Research, Hamburg, Germany, Stony Brook University Hospital, and HuminTec Inc., Korea. Special thanks to Wei Hong and Feng Qiu for their contributions and valuable discussions in GPU based ray casting implementation, Satprem Pamudurthy for proof reading the paper, and the anonymous reviewers for their thoughtful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Toolglass and magic lenses: The see-through interface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Bier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Derose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="73" to="80" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Computer generated angular fisheye projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bourke</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distortion viewing techniques for 3-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Symposium on Information Visualization &apos;96</title>
		<meeting>of IEEE Symposium on Information Visualization &apos;96</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="46" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extending distortion viewing from 2D to 3D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S T</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications: Special Issue on Information Visualization</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="42" to="51" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Magicsphere: an insight tool for 3d data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cignoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Montani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Scopigno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proc. of EUROGRAPHICS &apos;94)</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="317" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Focus and context for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Brodlie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Theory and Practice of Computer Graphics &apos;04</title>
		<meeting>of Theory and Practice of Computer Graphics &apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="32" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Interactive cutaway illustrations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diepstraten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EUROGRAPHICS &apos;03</title>
		<meeting>of EUROGRAPHICS &apos;03</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="523" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">High-quality two-level volume rendering of segmented data sets on consumer graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization &apos;03</title>
		<meeting>of IEEE Visualization &apos;03</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="40" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Two-level volume rendering-fusing mip and dvr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-I</forename><surname>Bischi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization &apos;00</title>
		<meeting>of IEEE Visualization &apos;00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="211" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Virtual voyage: Interactive navigation in the human colon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muraki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGGRAPH &apos;97</title>
		<meeting>of SIGGRAPH &apos;97</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="27" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Techniques for non-linear magnification transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Symposium on Information Visualization &apos;96</title>
		<meeting>of IEEE Symposium on Information Visualization &apos;96</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nonlinear magnification fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Symposium on Information Visualization &apos;97</title>
		<meeting>of IEEE Symposium on Information Visualization &apos;97</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A realistic camera model for computer graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kolb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22nd annual conference on Computer graphics and interactive techniques</title>
		<meeting>of the 22nd annual conference on Computer graphics and interactive techniques</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Acceleration techniques for GPU-based volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krüger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization &apos;03</title>
		<meeting>of IEEE Visualization &apos;03</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="287" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A magnification lens for interactive volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Ninth Pacific Conference on Computer Graphics and Applications</title>
		<meeting>of the Ninth Pacific Conference on Computer Graphics and Applications</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="223" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A review and taxonomy of distortion-oriented presentation techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Apperley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="126" to="160" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Gaze-directed volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Symposium on Interactive 3D Graphics &apos;90)</title>
		<meeting>of Symposium on Interactive 3D Graphics &apos;90)</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="217" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using deformations for browsing volumetric data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcguffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tancau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization &apos;03</title>
		<meeting>of IEEE Visualization &apos;03</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="401" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Light and color</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Perlman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
			<publisher>Golden Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Towards realistic visualization for surgery rehearsal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pflesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Tiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Höhne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Computer Vision</title>
		<meeting>of Computer Vision</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="487" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Comparing exovis, orientation icon, and in-place 3d visualization techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Swindells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Graphics Interface &apos;03</title>
		<meeting>of Graphics Interface &apos;03</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Importance-driven volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization &apos;04</title>
		<meeting>of IEEE Visualization &apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="139" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Case study: visualization of particle track data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Hallman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Visualization &apos;01</title>
		<meeting>of IEEE Visualization &apos;01</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="465" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distance based enhancement for focal region based volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Döring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Tönnies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Bildverarbeitung für die Medizin &apos;04</title>
		<meeting>of Bildverarbeitung für die Medizin &apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="199" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Focal region-guided featurebased volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Tönnies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of 1st International Symposium on 3D Data Processing Visualization and Transmission</title>
		<meeting>of 1st International Symposium on 3D Data essing Visualization and Transmission</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="87" to="90" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
