<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Feature-Driven Approach to Locating Optimal Viewpoints for Volume Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigeo</forename><surname>Takahashi</surname></persName>
							<email>takahashis@acm.org</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Fujishiro</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuriko</forename><surname>Takeshima</surname></persName>
							<email>takesima@vis.ifs.tohoku.ac.jp</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoyuki</forename><surname>Nishita</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Tohoku University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Tohoku University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<addrLine>0.305 0.988 0.675 0.740 0.013 0.524 0.535 0.738 0.000 0.309 0.687 1.000</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<addrLine>0.816 0.571 0.582 0.000 0.241 0.845 1.000 0.361 0.574 0.962 0.557 0.598</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Feature-Driven Approach to Locating Optimal Viewpoints for Volume Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.m [Computer Graphics]: Miscellaneous viewpoint selection</term>
					<term>viewpoint entropy</term>
					<term>direct volume rendering</term>
					<term>interval volumes</term>
					<term>level-set graphs</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Figure 1: Locating optimal viewpoints by individually estimating the visibility quality of each feature subvolume. The value under each image represents its corresponding estimate normalized to [0.0, 1.0].</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent advances in visualization hardware allow us to manage large-scale volume datasets with 3D complicated inner structures. When visualizing such 3D structures, however, they must be projected onto the 2D screen in ordinary computational environments. This requires careful selection of viewpoints because it considerably influences on the amount of information embedded into the 2D projected image. The viewpoint selection is also important in that psychological studies show that the first view leaves a strong impression of the target volume <ref type="bibr" target="#b18">[19]</ref>, although current GPU-based systems are available for real-time rotation and translation of the given volume.</p><p>Actually, such methods of locating optimal viewpoints have been proposed especially for 3D surfaces such as polygonal mesh representations. These methods basically try to find the best viewpoint by evaluating the visibility quality of the visible faces or silhouettes of a given 3D mesh, and thus provide a sound viewpoint that meets our visual preference. Nonetheless, they are still limited to surface shapes, and cannot be directly applied to solid objects such as volumes that involve their own characteristic inner structures.</p><p>This paper presents a new method of locating optimal viewpoints for volume visualization, by applying the existing method for 3D meshes. In this setting, the method finds the best viewpoint of the volume so that the corresponding projected image becomes optimal by direct volume rendering such as ray-casting. The main idea behind our method is to decompose the entire volume into several feature components by analyzing its topological structure, and then to apply the existing surface-based method for evaluating a locally optimal viewpoint of each component so that we can find a global compromise between them. (See <ref type="figure">Figure 1.</ref>) As the feature components, the method employs an interval volume (IV) <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14]</ref>, which is a generalized concept of an isosurface and is defined as a subvolume obtained by sweeping an isosurface component within some range of scalar field values.</p><p>Another advantage is that the method can assign a different</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Visualization 2005</head><p>October 23-28, Minneapolis, MN, USA 0-7803-9462-3/05/$20.00 ©2005 IEEE.</p><p>weight to each component according to the significance of its corresponding volume feature when calculating the optimal viewpoint. In the method, opacity transfer functions (TFs) are employed as a tool for controlling such weight assignment. Actually, emphasis on regions-of-interest (ROI) using an opacity TF enables naive users to locate an optimal viewpoint that reflects specific volume features clearly on the final projected image. The important strategy of the present method is to find the best arrangement of the feature components in an final projected image by avoiding their occlusions as many as possible. This is justified by the psychological studies of Blanz et al. <ref type="bibr" target="#b4">[5]</ref>, where they describe the following three conditions for the viewpoint optimality: significance of visible features, stability of the view (with respect to small transformations), and the number of occluded features. Our method directly takes into account the first and third conditions, while the second condition is compatible with the third one because viewpoint stability can usually be accomplished by minimizing occlusions among significant features in the projected image.</p><p>The remainder of this paper is organized as follows: Section 2 refers to previous work related to our method. Section 3 describes an existing formula called the viewpoint entropy, which will be used to evaluate the viewpoint quality for each feature component of the volume. In Section 4, isosurfaces are first used as the feature components to locate the optimal viewpoint, and relevant issues are addressed. Interval volumes and their combinations are then introduced in Section 5 as more sophisticated feature components to improve the quality of the viewpoint location. After providing several results associated with users' evaluation and discussion in Section 6, Section 7 concludes this paper and refers to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>One of the pioneering studies on viewpoint 1 evaluation is the aspect graph representation developed by Koenderink et al. <ref type="bibr" target="#b16">[17]</ref>. This representation classifies the regions of the viewing sphere that surrounds the object into aspects, by identifying equivalent views of the object edges in a topological sense. The node of the aspect graph represents an aspect of the target 3D object, and the link a visual transition between neighboring aspects. The aspect graph representation has been intensively studied as a tool for object recognition <ref type="bibr" target="#b8">[9]</ref>, while its automatic computation is still the subject of ongoing research <ref type="bibr" target="#b25">[26]</ref>. The aspect graph representation, however, can be applied only to rather simple polyhedra, and the associated resolution on the viewing sphere is not high enough to locate the optimal viewpoint precisely.</p><p>Locating such optimal viewpoints has been an important problem in computer vision research, including object recognition and reconstruction, and thus many methods have been developed for the purposes. However, in this setting, a set of viewpoints is selected as optimal viewpoints to provide an appropriate combination of camera positions that fully surrounds the whole surface of the target object. This problem of planning camera positions is referred to as the next best view (NBV) problem in computer vision literature.</p><p>For example, Gremban et al. <ref type="bibr" target="#b11">[12]</ref> found the combination of optimal viewpoints for object recognition by searching a tree structure that retains the collection of possible camera movements and their associated aspects. Tarbox et al. <ref type="bibr" target="#b30">[31]</ref> developed a method of planning the optimal arrangement of sensors so that they completely surround the object surface for its precise shape reconstruction. The NBV problem has been further tackled by identifying the equivalent class of object silhouettes seen from available viewpoints <ref type="bibr" target="#b0">[1]</ref>, and by optimally distributing the view volumes of the visible surface to candidate viewpoints <ref type="bibr" target="#b23">[24]</ref>. The configuration of such optimal viewpoints has been also investigated for acquiring a minimal set of textures in the image synthesis techniques such as image-based rendering <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15]</ref>. However, these methods cannot be applied to our case directly because their objective is to recover the 3D surface shapes of target objects only.</p><p>In the computer graphics applications, on the other hand, several methods have been proposed to locate the best viewpoint for 3D polyhedral meshes. For example, Kamada et al. <ref type="bibr" target="#b15">[16]</ref> defined an optimal viewpoint if it minimizes the number of degenerate faces under orthogonal projection, and Barrel et al. <ref type="bibr" target="#b3">[4]</ref> extended this scheme in order to manage perspective projections effectively. While these methods offer good viewpoints, their use is still limited to polygonal meshes with a small number of faces.</p><p>One solution for the case of general 3D meshes is the viewpoint entropy, which is formulated by Vázquez et al. <ref type="bibr" target="#b31">[32]</ref> to evaluate the balance of visible faces in 2D projected images. In this formulation, they consider the visibility of each face as its probability, and find the optimal viewpoint by maximizing the information of the probability distribution using the Shannon entropy. The viewpoint entropy works well and has been further applied to image-based rendering <ref type="bibr" target="#b32">[33]</ref> and camera path planning <ref type="bibr" target="#b1">[2]</ref>. Furthermore, Lee et al. <ref type="bibr" target="#b17">[18]</ref> have recently developed a new saliency-based method of finding the viewpoint that maximizes the sum of the saliency for the visible faces of 3D meshes. However, the targets of these methods are still limited to surfaces having zero thickness.</p><p>The idea of locating optimal viewpoints for volumes has also been explored simultaneously but independently by Bordoloi and Shen <ref type="bibr" target="#b5">[6]</ref>. Their method evaluates the balance between the contributions of voxels to pixels in the resultant image using the entropy function, and then finds stable viewpoints with respect to small transformations as good viewpoints. On the other hand, our method first decomposes an entire volume into feature subvolumes to find the best arrangement of the features in the resultant image. This comparison allows us to claim that our method evaluates the viewpoint optimality in 3D space, while their method does in 2D screen space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VIEWPOINT ENTROPY</head><p>The present method evaluates the viewpoint optimality of each decomposed feature subvolume using an existing surface-based method. As the surface-based method, we employ the viewpoint entropy formulated by Vázquez et al. <ref type="bibr" target="#b31">[32]</ref>, which searches for a well-balanced distribution of visible faces. This section explains the formulation of the viewpoint entropy and its actual calculation.</p><p>The original version of the viewpoint entropy evaluates the viewpoint quality under perspective projections. However, in this method, the formulation is extended to also handle orthogonal projections that are usually used for direct volume rendering. Suppose that the j-th face of a given 3D mesh has a visible projected area A j ( j = 1, . . . , m) on the 2D screen, while A 0 denotes the background area as shown in <ref type="figure" target="#fig_0">Figure 2</ref>(a). Thus, the total area of the 2D screen S can be calculated as S = ∑ m j=0 A j . If the visibility of the j-th face (A j /S) is considered as its information probability, the viewpoint entropy E that estimates the viewpoint quality for the given 3D mesh can be defined as</p><formula xml:id="formula_0">E = − m ∑ j=0 A j S log 2 A j S .<label>(1)</label></formula><p>Note that the definition comes from the formulation of the Shannon entropy, and thus Eq. (1) becomes larger as the corresponding viewpoint achieves more balanced distribution of face visibility. In the present method, the range of the viewpoint entropy is normalized to [0.0, 1.0] for later convenience. It is clear that Eq. <ref type="formula" target="#formula_0">1</ref>takes the maximum when all the faces have the same probabilities. This implies that, since the maximum of Eq. <ref type="formula" target="#formula_0">1</ref>is log 2 (m + 1), its normalized version can be obtained when dividing it with the maximum value as</p><formula xml:id="formula_1">E = − 1 log 2 (m + 1) m ∑ j=0 A j S log 2 A j S .<label>(2)</label></formula><p>The actual calculation of the viewpoint entropy Eq. (2) can be done with the help of graphics hardware in the same way as the method by Barral et al. <ref type="bibr" target="#b3">[4]</ref>. For a given viewpoint the projected area of each face can easily be obtained by counting the number of pixels that belong to the face when the target object is drawn into the frame buffer. To discriminate one face from the others, a different color is assigned to each face in order to establish oneto-one correspondence between the faces and colors, as shown in <ref type="figure" target="#fig_0">Figure 2</ref> (2) over the viewing sphere, and the associated best and worst views for a simple cube and a 3D horse model. For the cube model the best viewpoint offers its isometric projection while the worst one gives its Cartesian projection, and for the horse model the best viewpoint captures its silhouettes while the worst one cannot avoid their overlaps.</p><p>In finding the optimal viewpoints, we uniformly sample the viewing sphere that surrounds the target object and compare the corresponding viewpoint entropies, so as to identify the optimal viewpoint that achieves the maximum entropy. The viewpoint samples are generated by referring to the vertices of another reference mesh (in red) that covers the viewing sphere (in blue) as shown in <ref type="figure" target="#fig_0">Figure 2(d)</ref>. Actually, the reference mesh is constructed by subdividing an icosahedron twice using the Loop subdivision rule <ref type="bibr" target="#b19">[20]</ref>, and thus offers a uniform distribution of 162 viewpoint samples on the sphere. The top and bottom color-coded disks in <ref type="figure" target="#fig_0">Figures 2(b)</ref> and (c) are the projections of the viewpoint entropy distributions on the viewing sphere seen from the top (the North pole) and the bottom (the South pole), respectively. Here, each disk is color-coded by referring to the color legend where the color changes over blue, green, yellow, and red according to the increase in the entropy, and the black and white spots indicate the best and worst locations of the viewpoints, respectively. Note that this color-coded representation is used throughout the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LOCATING OPTIMAL VIEWPOINTS USING ISOSURFACES</head><p>Although the viewpoint entropy can evaluate the viewpoint optimality for 3D meshes, it cannot cope with volumes directly since the volumes have their own thickness. Recall that the formulation of the viewpoint entropy comes from the fact that a 3D mesh can be decomposed into faces each of which has a distinct contribution to the final projected image. This leads us to an idea of evaluating an individual contribution of each voxel in the final visualization image, for example, obtained using the ray-casting technique. Actually, Bordoloi and Shen <ref type="bibr" target="#b5">[6]</ref> implemented this idea by distributing the contribution of each voxel to pixels in the final projected image.</p><p>However, in actual process of direct volume rendering, all the voxels do not always have contributions to the final visualization result. Our experience suggests that we generally accentuate only specific volume features while disregarding the others to generate comprehensive visualization results. This scheme is achieved by the use of TFs, and thus the subjects to be accentuated in the rendering process should be isosurfaces because the TFs usually depend only on the scalar field value. This motivates us to extract a set of isosurfaces from the given volume, and then to apply the surface-based method of viewpoint evaluation to each of the extracted isosurfaces in order to pursue a globally optimal viewpoint. The remainder of this section is devoted to the formulation of viewpoint evaluation based on this idea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Formulation of the Viewpoint Entropy with Isosurfaces</head><p>The simplest way of introducing isosurfaces is to extract isosurfaces by uniformly sampling the entire range of the scalar field values, and then to take the average of viewpoint entropies for the extracted isosurfaces. Suppose that a set of scalar field values p i (i = 1, . . . , n) is obtained by uniformly sampling the entire range of the scalar field values. For the isosurface I i (i = 1, . . . , n) at the scalar field value p i , we denote the visible area of the j-th face on the 2D screen as A i j ( j = 1, . . . , m i ), while the background area is denoted by A i0 . Since the total area of the 2D screen S remains constant for all the isosurfaces, we can formulate the viewpoint entropy for the isosurface I i from Eq. <ref type="formula" target="#formula_1">2</ref>as</p><formula xml:id="formula_2">E iso i = − 1 log 2 (m i + 1) m i ∑ j=0 A i j S log 2 A i j S .<label>(3)</label></formula><p>The viewpoint entropy of the entire volume E iso is defined as an average of the above entropies, which is given by</p><formula xml:id="formula_3">E iso = 1 n n ∑ i=1 E iso i .<label>(4)</label></formula><p>The viewpoint obtained using the above formulation provides the rendered images as shown in <ref type="figure" target="#fig_2">Figure 3(a)</ref>, where the electron density distribution of the proton hydrogen-atom collision is simulated <ref type="bibr" target="#b10">[11]</ref>. In this case, 32 isosurfaces are uniformly sampled from the entire range of scalar field values. Although the calculated viewpoint allows us to identify the centers of the proton and hydrogenatom, it still offers an unsatisfactory view because the density distributions around the two centers, together with the electron charge transfer between them, have partial overlaps in the resultant image. Our experiments show that increasing the number of isosurfaces cannot fully locate the best viewpoint while it gradually improves the quality of viewpoint location at the cost of computation time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Weight Assignment for Isosurfaces Using Transfer Functions</head><p>Our strategy for improving the viewpoint positions is to assign different weights to the isosurfaces when averaging their viewpoint entropies in Eq. (4). In general, as described previously, we accentuate some specific features selectively in the process of volume rendering to generate images clear enough to meet our preference. For this purpose, Eq. (4) is modified by distributing a different weight λ i (i = 1, . . . , n) to the isosurface I i , as</p><formula xml:id="formula_4">E iso = n ∑ i=1 λ i L E iso i ,<label>(5)</label></formula><p>where L = ∑ n i=1 λ i . The remaining issue here is to decide the weight values λ i (i = 1, . . . , n) for the extracted isosurfaces I i . Here, opacity TFs are employed to assign different weight values to the isosurfaces since they play a primary role in rendering volume features selectively. Suppose that we denote the opacity transfer function of the scalar field value s by T (s). The weight value λ i for the isosurface I i is set to be T (p i ) in this formulation because the isosurface I i is extracted by sampling p i in the range of the scalar field values. <ref type="figure" target="#fig_2">Figure 3</ref>(b) shows resultant images when an opacity TF is used to assign different weights to the 32 extracted isosurfaces. Here, the opacity TF is designed so that it can emphasize the topological transitions of isosurfaces with respect to the scalar field. (See <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b33">34]</ref>.) While the result seems to be better than the previous one, it still suffers from small partial overlaps between the two territories of the proton and hydrogen-atom along with the charge transfer in the projected image. Such problems also arise in other volume datasets if we stick to isosurfaces in evaluating the viewpoint optimality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LOCATING OPTIMAL VIEWPOINTS USING INTERVAL VOLUMES</head><p>This section presents a new method of locating optimal viewpoints, which is the main contribution of this paper. In the method, an entire volume is disassembled into interval volumes each of which captures some specific feature in the volume.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Decomposition into Interval Volumes</head><p>The isosurface-based formulation of the viewpoint entropy cannot provide satisfactory results even when assigning different weight values to the isosurfaces using opacity TFs. There are three reasons for this. First, the isosurfaces are sampled uniformly over the range of scalar field values, and thus cannot precisely reflect the shapes of volume features we are interested in. Second, the previous approach cannot discriminate between the connected components of an isosurface at one scalar field value while we may want to put different emphases on them. Third, the isosurface-based approach neglects thickness of the volume while we are now tackling solid objects. This is more crucial if we introduce more sophisticated accentuation of volume features together with multi-dimensional TFs. We therefore introduce new geometric components called interval volumes (IVs) <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14]</ref> to enable the adaptive sampling of the 3D volume domain according to the arrangement of volume features. Actually, an IV is a generalized concept of an isosurface and is defined to be a subvolume obtained by integrating a connected component of an isosurface within some range of the scalar field values 2 . Here, our method takes advantage of an interface called an interval volume decomposer (IVD) <ref type="bibr" target="#b26">[27]</ref>, where each decomposed IV corresponds to a link of a level-set graph such as a contour tree <ref type="bibr" target="#b2">[3]</ref>, which is obtained by tracking the topological transitions of isosurfaces with respect to the scalar field.</p><p>The IVD constructs the level-set graph by detecting changes in the number of isosurface components <ref type="bibr" target="#b6">[7]</ref> and their associated topological types <ref type="bibr" target="#b21">[22]</ref> according to the scalar field from an adaptive interpolation of voxel samples <ref type="bibr" target="#b27">[28]</ref>. Note that the level-set graphs are usually too sensitive to noise especially in acquired datasets and thus need some simplification process <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b27">28]</ref> to delineate the global structure of the given volumes. <ref type="figure" target="#fig_3">Figure 4</ref> shows a set of decomposed IVs of the proton hydrogenatom collision dataset together with the simplified level-set graph. As shown in the figure, the IVD interface provides a systematic decomposition of the entire volume that reflects its involved topological structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Formulation of the Viewpoint Entropy with Interval Volumes</head><p>Having obtained the decomposed IVs for the viewpoint calculation, we apply the viewpoint entropy formulation Eq. (2) to the external surface of each decomposed IV for outlining its boundary. Denote the visible area of the j-th face on the exterior surface of the ith IV V i (i = 1, . . . , n) by A i j ( j = 1, . . . , m i ), while A i0 represents a background area also in this case. The viewpoint entropy for the decomposed IV V i can be formulated, in the same way for isosurfaces, as</p><formula xml:id="formula_5">E iv i = − 1 log 2 (m i + 1) m i ∑ j=0 A i j S log 2 A i j S ,<label>(6)</label></formula><p>where S again represents the total area of the screen. This gives the viewpoint entropy for the entire volume as</p><formula xml:id="formula_6">E iv = 1 n n ∑ i=1 E iv i .<label>(7)</label></formula><p>This new formulation locates a viewpoint that yields the visualization images as shown in <ref type="figure" target="#fig_2">Figure 3(c)</ref>. The result reveals that the IV decomposition scheme pinpoints the viewpoint location that captures the relative positions of the proton and hydrogen-atom accompanied with the charge transfer between them at right angles without occlusions between their territories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Weight Assignment for Interval Volumes Using Transfer Functions</head><p>Of course, similarly to the previous case, different weights can be assigned to the decomposed IVs according to the importance of their associated features when calculating the optimal viewpoint. Here, opacity TFs are again used to achieve such weight assignment. However, in this case, we have no need to restrict ourselves to single-dimensional TFs that depend only on the scalar field values; we can utilize multi-dimensional TFs to assign different weights to specific ROI because the IV-based formulation allows us to adaptively sample opacity values in the volume due to the level-set graph-based analysis. Our formulation defines the weight of the IV V i as the average of the opacity values associated with the voxels within that IV. Let us denote a voxel contained in the IV V i as v i j ( j = 1, . . . , a i ), and its associated opacity value as t i j ( j = 1, . . . , a i ). The weight value λ i (i = 1, . . . , n) to be assigned to V i can be defined as</p><formula xml:id="formula_7">λ i = 1 a i a i ∑ j=1 t i j ,<label>(8)</label></formula><p>where a i is the number of voxels contained in V i . Accordingly, the total viewpoint entropy is revised as</p><formula xml:id="formula_8">E iv = n ∑ i=1 λ i L E iv i ,<label>(9)</label></formula><p>where L = ∑ n i=1 λ i . The weight assignment to IVs provides the distribution of the viewpoint entropies and the resultant images as shown in <ref type="figure" target="#fig_2">Figure 3(d)</ref>, which are the same as <ref type="figure" target="#fig_2">Figure 3(c)</ref>. Here, the same opacity TF as <ref type="figure" target="#fig_2">Figure 3</ref>(b) is used to assign different weights to the decomposed IVs. This formulation also allows us to pinpoint the location of the best viewpoint in connection with the opacity TF design if we take into account the inner structures in the given volume.  shows such an example where the two-body probability distribution of a nucleon in O is simulated <ref type="bibr" target="#b20">[21]</ref>. Here, the visualization result together with the viewpoint location has been enhanced by replacing a simple single-dimensional opacity TF ( <ref type="figure" target="#fig_4">Figure 5(a)</ref>) with a multi-dimensional opacity TF that emphasizes the inner structures in the volume <ref type="bibr" target="#b29">[30]</ref>  <ref type="figure" target="#fig_4">(Figure 5(b)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Formulation of the Viewpoint Entropy with the Combinations of Neighboring Interval Volumes</head><p>As seen in the previous figures, the individual IVs serve as reasonable feature components for locating optimal viewpoints. Nonetheless, they incur another problem that we cannot take into account the relative positions of such IVs when locating optimal viewpoints. For example, we are likely to find a viewpoint that arranges two neighboring IVs side by side without any overlaps on the screen especially if they are in contact with each other. Finding such a viewpoint is difficult because we still estimate the visibility quality of each decomposed IV separately. We tackle this problem by identifying important combinations of neighboring IVs that should be projected on the screen side by side, and then evaluating the viewpoint quality together with their relative positions in 3D space. Such IV combinations definitely share an isosurface component where some topological isosurface transition, such as isosurface merging and splitting, is about to occur. Since each decomposed IV corresponds to a link of the level-set graph in our framework, we extract a combination of neighboring IVs if their corresponding links share the node of some specific type. Considering the isosurface transitions according to the scalar field together with the level-set graph, we identify such IV combinations as those depicted in <ref type="figure" target="#fig_6">Figure 6</ref> where the corresponding links are drawn in red. Note that the figure depicts subgraphs around nodes of the specific types in the level-set graph <ref type="bibr" target="#b2">3</ref> where the links are arranged from top to bottom with respect to the scalar field. Also note that a solid link corresponds to an isosurface that expands as the scalar field value decreases while a hollow link represents an isosurface that shrinks <ref type="bibr" target="#b28">[29]</ref>.</p><p>We are now ready to revise the IV-based formulation of viewpoint entropy that takes into account the relative positions of specific IV combinations. Suppose that the i-th IV V i is paired with the j-th IV V j in some specific combination in <ref type="figure" target="#fig_6">Figure 6</ref>. The viewpoint entropy for each IV in the combination can be calculated using Eq. (6) by identifying the visible faces of the IV. However, if the faces of V i are partially occluded by V j with some viewpoint as shown in <ref type="figure" target="#fig_7">Figure 7</ref> entropy by painting the occluded face regions in the background color, as shown in <ref type="figure" target="#fig_7">Figure 7</ref>(b). This special handling together with Eqs. (6), <ref type="bibr" target="#b7">(8)</ref> and <ref type="bibr" target="#b8">(9)</ref> obviously allows us to avoid undesirable occlusions between V i and V j in the combination. <ref type="figure">Figure 8</ref> reveals the effects of emphasizing the relative positions of neighboring IVs in the specific combination for the hydrogenatom dataset. <ref type="figure">Figure 8(a)</ref> shows the result obtained by individually estimating the decomposed IVs while <ref type="figure">Figure 8(b)</ref> shows that obtained by taking into account the relative positions of feature IV combinations. These results prove that the new formulation provides us with the more sophisticated view of the target volume by taking into account the arrangement of feature subvolumes in the final projected image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results of Viewpoint Calculations</head><p>This section exhibits several results of viewpoint calculation to demonstrate the feasibility of the present framework. <ref type="figure" target="#fig_2">Figure 3</ref> shows visualization results for the proton hydrogenatom collision dataset <ref type="bibr" target="#b10">[11]</ref>, where individual isosurfaces and individual IVs are used as feature components with uniform and nonuniform weight assignment. Note that each visualization result is accompanied with the color-coded distribution of the viewpoint entropies on the viewing sphere, where the sphere is seen both from the top (the north pole) and bottom (the south pole). The color legends in <ref type="figure" target="#fig_0">Figures 2(b)</ref> and (c) represent how to assign colors according to the amplitude of the viewpoint entropy. It is clear from the visualization results that we can pinpoint the optimal viewpoint location once we have introduced IVs as the feature components for the analysis of the volume. The computation time for the viewpoint analysis is approximately 10 seconds using a 3.0GHz Pentium IV PC with 2GB RAM in the cases of Figures 3(c) and (d). <ref type="figure" target="#fig_4">Figure 5</ref> presents visualization results for the simulated twobody probability distribution of a nucleon in <ref type="bibr" target="#b15">16</ref> O <ref type="bibr" target="#b20">[21]</ref>, where individual IVs are used as feature components together with weight assignments using single-and multi-dimensional opacity TFs. As seen from <ref type="figure" target="#fig_4">Figure 5</ref>, the multi-dimensional opacity TF can illuminate the multi-layered structures in the volume more clearly if it is designed to emphasize the inner structures <ref type="bibr" target="#b29">[30]</ref>. <ref type="figure">Figure 8</ref> demonstrates the effect of emphasizing the relative positions between important neighboring IVs for the hydrogen atom dataset. Actually, <ref type="figure">Figure 8</ref>(b) reveals a better view of the target volume rather than <ref type="figure">Figure 8</ref>(a) because the occlusion between paired IVs is minimized.</p><p>The viewpoint selection accompanied with the distributions of viewpoint entropies for other volumes are also provided in <ref type="figure">Figure 9</ref> where the combinations of IVs are employed as feature components. Here, <ref type="figure">Figures 9(a)</ref>, (b), (c) and (d) show visualization results of the foot dataset <ref type="bibr" target="#b20">[21]</ref>, a laser fusion implosion dataset <ref type="bibr" target="#b24">[25]</ref>, the tooth dataset <ref type="bibr" target="#b22">[23]</ref>, and the vortex dataset, respectively. Note that, for the cases in Figures 9(c) and (d), the same opacity TFs as in <ref type="bibr" target="#b5">[6]</ref> are used to assign different weights to the decomposed IVs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Users' Evaluation</head><p>To verify the present framework, we asked 32 graduate students majoring in computer graphics and visualization to evaluate visualization images taken from 42 multiple viewpoints that are uniformly spaced on the viewing sphere. The graduate students are informed of what is involved in the dataset, and requested to rate clearer images at higher marks by understanding the associated inner structures. <ref type="figure">Figure 10</ref> shows the color-coded distribution interpolated from such evaluated marks at 42 viewpoints for the cases in <ref type="figure" target="#fig_2">Figure 3</ref> and <ref type="figure">Figure 9</ref>(c). Both results show that our formulation can roughly simulate the users' preference in selecting optimal viewpoints. Note that in both cases we generated visualization images by suppressing the influence of specular illuminations so that we can avoid unexpected side effects of light illuminations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Discussion</head><p>As described in Section 1, our method searches for the viewpoint that satisfies the three conditions derived from psychological studies <ref type="bibr" target="#b4">[5]</ref>. For this purpose, our method partitions the entire volume into feature IVs by referring to the level-set graph that delineates the global topological structure of the volume. This implies that the feature analysis of our approach assumes that the given volume contains some characteristic global structure. Thus, our method usually provides more reasonable results for simulated datasets rather than acquired datasets that inevitably involve unstructured highfrequency noise. However, once the feature IVs have been successfully identified, our method provides satisfactory results even with any opacity TFs. Actually, the results in Figures 9(c) and (d) are obtained using opacity TFs that have been designed without referring to the corresponding level-set graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>This paper has presented a new method for locating the optimal viewpoint in rendering volumes by applying the existing method for 3D surface meshes. The main idea behind the method is to decompose the entire volume into feature IVs, and then calculate the locally optimal viewpoints for the decomposed IVs to find a global compromise between them. The method introduces opacity TFs to assign larger weights to specific feature IVs so that we can attain more effective viewpoint exploration. The relative positions of the feature IVs are also taken into account in order to formulate a more reliable function for evaluating the viewpoint quality. The proposed method can provide naive users with useful criteria for the Users Our method Users Our Method (a) (b) <ref type="figure">Figure 10</ref>: User-evaluated distribution of viewpoint optimality (a) for the proton hydrogen-atom collision dataset and (b) tooth dataset. Each distribution is compared with that of our method.</p><p>optimal viewpoint that effectively illuminates the volume features using direct volume rendering such as ray-casting. For future research new camera path planning using the proposed criteria will be interesting when we quickly investigate inner structures of static and time-varying volume datasets. We can also incorporate entropy-based light planning phase <ref type="bibr" target="#b12">[13]</ref> into the method so that we can integrate the arrangement of features with light source placement. Relationships of our formulation with human psychological preference in viewpoint selection should be investigated more in detail. Software/hardware accelerated computation of optimal viewpoints for volumes is also an interesting theme for future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>(a) Assignment of different colors to visible faces on the 2D screen. The viewpoint entropy distributions and the associated best and worst views (b) for a cube model and (c) a horse model. (d) A reference mesh (in red) on the viewing sphere (in blue) for 162 viewpoint samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a). Figures 2(b) and (c) show the distributions of the viewpoint entropies Eq.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Viewpoint entropy distributions and the associated best and worst views for the proton hydrogen-atom collision dataset: Results obtained by using (a) isosurfaces, (b) weighted isosurfaces, (c) interval volumes, and (d) weighted interval volumes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Level-set graph and its associated interval volume decomposition of the proton hydrogen-atom collision dataset. Four interval volumes are subjects to the calculation of the viewpoint entropy. The nodes of the graph are arranged from top to bottom according to their scalar field values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Viewpoint entropy distributions and the associated best and worst views for the simulated two-body probability distribution of a nucleon in<ref type="bibr" target="#b15">16</ref> O: Results obtained by using (a) weighted interval volumes with a single-dimensional opacity TF, and (b) weighted interval volumes with a multi-dimensional opacity TF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5</head><label>5</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Neighboring IVs to be emphasized and their associated links in level-set graphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>(a), we calculate the corresponding viewpoint =⇒ (a) Neighboring IVs having overlaps. (b) The occluded region will be painted in the background color when evaluating the viewpoint quality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Viewpoint entropy distributions and the associated best and worst views for the dataset of the simulated electron density distribution in a hydrogen atom: Results obtained by using (a) weighted interval volumes, and (b) weighted combinations of interval volumes. Results of optimal viewpoint calculation: (a) the human foot medical dataset, (b) a simulated dataset of implosion in laser fusion, (c) the tooth dataset, and (d) the vortex dataset. All the calculations are conducted by using weighted combinations of interval volumes.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">View directions for orthogonal projections are also referred to as viewpoints in this paper.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The IV is originally defined as a subvolume obtained by sweeping an entire isosurface, not by sweeping its individual connected component.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This figure only shows non-degenerate topological transitions but we can similarly handle degenerate cases where three or more isosurface components are involved in the transition.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments The vortex dataset is available from the Time-Varying Volume Data Repository maintained by Kwan-Lu Ma (http://www.cs.ucdavis.edu/˜ma/ITR/tvdr.html). The opacity transfer functions for the tooth and vortex datasets are courtesy of Udeepta D. Bordoloi and Han-Wei Shen. The viewpoint evaluation was conducted in cooperation with graduate students in Tohoku University and Wakayama University. The authors also would like to thank the anonymous reviewers for their helpful comments. This work has been partially supported by Japan Society of the Promotion of Science under Grants-in-Aid for Young Scientists (B) No. 17700092, and the Ohkawa Foundation for Information and Telecommunications.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic view selection in multi-view object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Abbasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mokhtarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int. Conference on Pattern Recognition</title>
		<meeting>of Int. Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="13" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Way-finder: Guided tours through complex walkthrough models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Andújar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fairén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="499" to="508" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The contour spectrum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Schikore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Vis&apos;97</title>
		<meeting>of IEEE Vis&apos;97</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="167" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scene understanding techniques using a virtual camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dorme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Plemenos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Eurographics &apos;00 Short Presentations</title>
		<meeting>of Eurographics &apos;00 Short Presentations</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What object attributes determine canonical views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Tarr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Bülthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="575" to="600" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">View selection for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">D</forename><surname>Bordoloi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Vis2005</title>
		<meeting>of IEEE Vis2005</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computing contour trees in all dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoeyink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Axen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="75" to="94" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Simplifying flexible isosurfaces using local geometric measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoeyink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van De Panne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Vis2004</title>
		<meeting>of IEEE Vis2004</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="497" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">3D object recognition using shape similarity-based aspect graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Cyr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Kimia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int. Conference on Computer Vision</title>
		<meeting>of Int. Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="254" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic camera placement for image-based modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fleishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Volumetric data exploration using interval volume</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="144" to="155" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Planning multiple observations for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Gremban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="137" to="172" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Maximum entropy light source placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gumhold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Vis2002</title>
		<meeting>of IEEE Vis2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="275" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interval set: A volume rendering technique generalizing isosurface extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Vis&apos;95</title>
		<meeting>of IEEE Vis&apos;95</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">PC-based real-time texture painting on real world objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Iwakiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kaneko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="105" to="113" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A simple method for computing general position in displaying three-dimensional objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kawai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The singularities of the visual mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Van Doorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="211" to="216" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mesh saliency. ACM Trans. on Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="659" to="666" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Failure to detect changes to attended objects in motion pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Simons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="501" to="506" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Smooth Subdivision Surfaces Based on Triangles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>University of Utah, Department of Mathematics</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meißner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Page</surname></persName>
		</author>
		<ptr target="http://www.volvis.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient computation of the topology of level sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cole-Mclaughlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Vis2002</title>
		<meeting>of IEEE Vis2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="187" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The transfer function bake-off</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="16" to="22" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A solution to the next best view problem for automated surface aquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. of Pattern Analysis and Maching Intelligence</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1016" to="1030" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">9 tflops threedimensional fluid simulation for fusion science with HPF on the earth simulator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sakagami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Murai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yokokawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM/IEEE SC2002</title>
		<meeting>of ACM/IEEE SC2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Finite-resolution aspect graphs of polyhedral objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shimshoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="315" to="327" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Interval volume decomposer: A topological approach to volume traversal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SPIE Conference on Visualization and Data Analysis</title>
		<meeting>of SPIE Conference on Visualization and Data Analysis</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">5669</biblScope>
			<biblScope unit="page" from="103" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Topological volume skeletonization using adaptive tetrahedralization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Nielson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Geometric Modeling and Processing</title>
		<meeting>of Geometric Modeling and essing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Topological volume skeletonization and its application to transfer function design. Graphical Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="22" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Introducing topological attributes for objective-based visualization of simulated datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Nielson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Volume Graphics</title>
		<meeting>of Volume Graphics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">236</biblScope>
			<biblScope unit="page" from="137" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Planning for complete sensor coverage in inspection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Tarbox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Gottschlich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="84" to="111" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Viewpoint selection using view entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-P</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Vision Modeling and Visualization Conference (VMV01)</title>
		<meeting>of Vision Modeling and Visualization Conference (VMV01)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="273" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automatic view selection using viewpoint entropy and its application to image-based rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-P</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="page" from="689" to="700" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automating transfer function design based on topology analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Scheuermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Geometric Modeling for Scientific Visualization</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="293" to="306" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
