<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualizing Data with Motion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Huber</surname></persName>
							<email>dan.huber@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
							<email>healey@csc.ncsu.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<settlement>Northrop Grumman</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">North Carolina State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Visualizing Data with Motion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.1.2 [Models and Principles]: User/Machine Systems-Human factors, human information processing</term>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation-Display algorithms</term>
					<term>I.3.6 [Computer Graphics]: Methodology and Techniques-Interaction techniques direction, flicker, motion, multidimensional, perception, velocity, visualization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper describes an experimental study of three perceptual properties of motion: flicker, direction, and velocity. Our goal is to understand how to apply these properties to represent data in a visualization environment. Results from our experiments show that all three properties can encode multiple data values, but that minimum visual differences are needed to ensure rapid and accurate target detection: flicker must be coherent and must have a cycle length of 120 milliseconds or greater, direction must differ by at least 20 • , and velocity must differ by at least 0.43 • of subtended visual angle. We conclude with an overview of how we are applying our results to real-world data, then discuss future work we plan to pursue.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Visualization converts information into images that can be used to explore, discover, and analyze. The amount of data being collected and recorded has grown rapidly in recent years. Unfortunately, our ability to understand this data has improved more slowly. Building images that allow viewers to analyze their data offers one promising approach to increasing the amount of information we can manage effectively.</p><p>Our interests in this paper focus on multidimensional datasets. Such a dataset D stores information about multiple data attributes A = (A1, . . . , An) via numerous sample points or data elements ei. Specifically, D = {e1, . . . , em} and ei = (ai,1, . . . , ai,n), ai,j ∈ Aj. The goal of visualization in this context is to convert the dataset into images that allow viewers to rapidly and accurately complete their analysis tasks.</p><p>One way to build effective visualizations is to construct data to visual feature mappings based on guidelines from human perception. The low-level human visual system can identify certain visual properties in a scene or an image very rapidly, often in 200 milliseconds (msec) or less <ref type="bibr" target="#b12">[12]</ref>. When combined properly, these properties can be used to represent information in ways that allow viewers to perform high-level analysis tasks like locating target elements and spatial boundaries, enumerating, or tracking groups of elements as they move and change over time. The ability to complete these tasks quickly on large, multi-element displays allows analysis to occur in real-time, dramatically increasing the amount of information a viewer can process.</p><p>Past research has documented how colour and texture can be decomposed into perceptually salient visual features like hue, luminance, and saturation, or size, orientation, density, and regularity of placement <ref type="bibr" target="#b5">[5]</ref>. One method for visualizing multidimensional data is to attach a unique visual feature to each data attribute, for example, to use hue to represent the first attribute, orientation to represent the second attribute, and so on. How we map the data to the different visual features depends critically on three constraints: (1) the capabilities of each visual feature; (2) the makeup of the data; and (3) the analysis tasks the viewer needs to perform.</p><p>Each visual feature has a certain information carrying capacity, representing its ability to encode data in isolation. Different features can also interact with one another in various ways when they are displayed together in a common image. For example, colour properties like hue and luminance initially dominate texture properties, forcing colour patterns to be seen first by the low-level visual system. These types of issues must be considered when we design a visualization's data-feature mapping.</p><p>A third visual feature we would like to use is motion. Experimental results from psychophysics show that properties of motion are detected by the low-level visual system. Motion occurs, both implicitly and explicitly, in numerous visualization techniques. However, the detailed knowledge needed to construct perceptual guidelines on the use of motion in visualization has not been documented. This paper describes a set of perceptual experiments we conducted to investigate the information carrying capacity of three perceptual dimensions of motion: flicker, direction, and velocity.</p><p>The remainder of this paper is organized as follows. First, we provide an overview of previous work from psychophysics on motion, together with past research on the use of motion in visualization. Next, we discuss three experiments that studied the basic abilities of flicker, direction of motion, and velocity of motion to encode information. We describe our initial attempts to use our results to visualize real-world data. Finally, we conclude with a summary of our findings and a discussion of areas of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MOTION</head><p>Like colour and texture, motion is a visual feature that is known to be perceptually salient. Examples of motion in visualization include the animation of particles, dye, or glyphs to represent the direction and magnitude of a vector field (e.g., fluid flow visualization), or the implicit use of motion transients to highlight changes in a dataset across a user-selected data axis (e.g., over time for a temporal dataset, or along the scanning axis for CT or MRI slices).</p><p>Although properties of motion are commonly used in visualization, formal studies of the strengths and weaknesses of these properties are less numerous. As with colour and texture, our goal is to identify perceptual dimensions of motion and apply them in an effective manner. Three basic properties described in the perceptual literature were of particular interest to us: flicker, direction of motion, and velocity of motion.</p><p>Flicker refers to a repeating on-off pattern applied to an image or an object, and is normally measured as the frequency of repetition F in cycles per second (cps). A common use of flicker research in computer graphics is the critical flicker frequency (CFF), the rate at which images must be redrawn to appear continuous. Below the Please see supplementary material on conference DVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Visualization 2005</head><p>October 23-28, Minneapolis, MN, USA 0-7803-9462-3/05/$20.00 ©2005 IEEE.</p><p>CFF, individual clear-and-display operations can be perceived, producing the impression of a "flickering" image. Although F = 60 cps is an often-cited rule of thumb for the CFF, this number varies depending on the colour, brightness, or size of the object being displayed, and on its eccentricity, which measures the distance in visual angle from the viewer's current focal point to the object. Our interest is in flicker frequencies that are perceived as discrete flashes by the viewer, that is, frequencies below the CFF. Experiments by Mowbrey and Gebhard, later discussed by Brown, suggest that frequency must vary from 2 to 5% to produce a distinguishable difference in flicker (1.02 ≤ ∆F ≤ 1.05) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">9]</ref>. As objects move away from the focus of attention, however, ∆F increases dramatically, with differences of 100% or more needed for high F at large eccentricities. Separate findings describe how differences in luminance and size can affect ∆F .</p><p>Other vision scientists have studied both direction and velocity of motion. Tynan and Sekuler reported that a decrease in a target object's velocity or an increase in its eccentricity increased the time required to identify it <ref type="bibr" target="#b13">[13]</ref>, although in all cases viewers responded rapidly. Two hundred to 350 msec were needed to identify targets in the periphery, and 200 to 310 msec for targets in the center of focus. van Doorn and Koenderink confirmed that higher initial velocities produce a faster response to a change in the velocity <ref type="bibr" target="#b14">[14]</ref>. They claim this is due to the need for the target to traverse a "critical distance" before it can be detected. Follow-on work by Mateeff et al. <ref type="bibr" target="#b8">[8]</ref> showed that for a baseline velocity V1 and a target velocity V2 = 2V1, approximately 100 msec is needed to see the velocity change from V1 to V2 for slow V1 (1 • per second) and approximately 50 msec for faster V1 (2 • per second or higher). Recent results by Hohnsbein and Mateeff suggest that changes in the direction of motion may be detected based on the perceived velocity change they produce <ref type="bibr" target="#b6">[6]</ref>. Related work suggests at least 15 • of difference is needed to distinguish between static elements with different orientations <ref type="bibr" target="#b16">[16]</ref>.</p><p>Researchers in psychology have used properties of motion to extend a viewer's ability to perform basic exploration tasks. Nakayama and Silverman showed that coherent motion or stereoscopic depth can be used to perceptually group elements <ref type="bibr" target="#b10">[10]</ref>, allowing viewers to search each group independently and in parallel. Driver et al. showed that oscillation can also be used to separate elements into independent visual groups, but only if the oscillation pattern is coherent <ref type="bibr" target="#b4">[4]</ref>. More sophisticated motion patterns have also been analyzed, although with less success in terms of achieving high-speed search performance. Braddick and Holliday studied both divergence and deformation <ref type="bibr" target="#b1">[2]</ref>. Although the basic motion properties being shown can be rapidly identified in isolation, the combinations that produce deformation and divergence were not detected by the low-level visual system.</p><p>Properties of motion have been extended to visualization design. Animated motion is used in flow visualization to show the direction and speed of different flow patterns (e.g., in van Wijk <ref type="bibr" target="#b15">[15]</ref>). Kerlick proposed the use of animated glyphs to visualize 2D and 3D multidimensional datasets <ref type="bibr" target="#b7">[7]</ref>. He designed a set of "boids" to encode attribute values at specific locations in the dataset, for example, a sphere boid to query data values at a user-selected location, or pyramid and dart boids that animate over a vector field to visualize its shape. Bartram et al. studied the use of variations in colour, shape, and motion to "notify" viewers while they were engaged in a separate, attention-demanding task <ref type="bibr" target="#b0">[1]</ref>. Results showed that applying motion to a static glyph was significantly easier to recognize, compared to changing the glyph's colour or shape. This finding held both when the glyph was near the center of focus, and when it was located on the periphery of the viewer's gaze. Experiments were conducted to measure how distracting each secondary motion cue appeared to a viewer. Flicker was the least distracting, followed by oscillating motion, then divergence, and finally movement over long distances. The authors concluded by confirming that different motion paths can be used to perceptually group glyphs in a manner similar to the work of Nakayama and Silverman and Driver et al.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FLICKER EXPERIMENT</head><p>The flicker experiment studied a viewer's ability to distinguish the presence or absence of a small group of target elements that flicker at a rate different from the background elements. Each experiment trial contained a 20 × 20 regular grid of yellow squares on a black background that filled a 19-inch screen. For target present trials, a 3 × 3 group of elements was randomly selected to flicker at a target flicker rate ft different from the background flicker rate f b . For target absent trials, all the elements flickered at the same background flicker rate f b .</p><p>Observer accuracy and response time were used to measure viewer performance. The experiment was constructed to test three separate conditions:</p><p>1. Cycle length: the duration of the target elements' cycle ft in milliseconds. This allowed us to test whether different cycle lengths produced different viewer performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Cycle difference: the absolute difference between the target and background elements' cycle lengths</head><formula xml:id="formula_0">∆F = |ft − f b |.</formula><p>This allowed us to determine how much of a difference in cycle length is needed to generate a perceived difference in flicker rate. • ft = 360 msec: (360, 120) and (360, 600)</p><p>• ft = 480 msec: (480, 240) and (480, 720)</p><p>• ft = 600 msec: (600, 360) and (600, 840)</p><p>Target-background pairs for the other three ∆F were generated in an identical fashion. This resulted in 64 different trial types (two coherency types by four ∆F by four ft by two f b ). Each trial type was shown to a viewer six times during the experiment, for a total of 384 trials. Half the trials for a given trial type were randomly selected to contain a target group of elements flickering at the target flicker rate. The remaining trials contained no target, with all the elements flickering at the background flicker rate. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Procedure</head><p>Eight members of the Computer Science department (faculty, staff, and graduate students) volunteered to participate during the experiment. Viewers were naive to the purpose of the experiment, although some students had knowledge of related work conducted in our laboratory. All viewers had normal or corrected to normal vision. The experiment was run on a SunBlade 150 connected to a 19-inch Sun Microsystems LCD monitor. At the beginning of the experiment viewers were instructed to search each display for a small group of target elements flickering at a rate different from the background elements. Viewers were told to hit a key representing "present" if the target group was present, or a key representing "absent" if the target group was absent. Viewers were asked to answer as quickly as possible, while still maintaining a high level of accuracy. Feedback was provided for one second after each viewer response: a plus-sign for a correct answer, or a minus-sign for an incorrect answer. This allows viewers to gauge their performance, and to ensure they are entering their answers properly. The next trial followed immediately after the feedback display. Coherent and non-coherent experiment trials were separated into two parts. Viewers completed each part separately. Half the viewers started with the coherent trials. The other half started with the non-coherent trials. Trials within each part were presented in a random order.</p><p>Prior to starting an experiment part, viewers completed 32 practice trials. Sixteen practice trials were randomly selected to contain a target group. Each of the 16 possible (∆F, ft) pairs were shown once within these trials. The remaining 16 trials did not contain a target group. Viewers were allowed to repeat the practice session as often as they needed to become comfortable with the procedure and speed of the experiment. Viewers completed all 384 experiment trials plus the 64 practice trials (192 experiments trials plus 32 practice trials for both the coherent and non-coherent experiment parts) during a single one hour session. Viewers were offered an opportunity to rest after every 96 experiment trials. A viewer's present or absent response for each trial, together with the time taken to respond, were saved for later analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Two performance metrics were recorded during the experiment: mean viewer error rate e and mean viewer response time rt. Although e can be analyzed directly, rt may not provide a reliable direct measure for comparison, particularly for coherent trials across different ∆F . In order for a viewer to perceive a difference between the target and the background flicker rates, the target elements (or background elements) must complete at least half a cycle (i.e., either the target or the background must "turn off" while the other "stays on" at least once before a flicker difference is observable). The time required for half a cycle to complete is longer for larger ∆F . Therefore, we would expect rt to also be longer for larger ∆F .</p><p>To address this issue, we combined ∆F and rt to compute the number of visibility changes vc that occur before a response is made. vc tells us how many times the target (or background) turned on and off before a viewer responded. vc is calculated using the faster of the two cycle lengths, fvc = min(ft, f b ). Given rt and fvc, the number of visibility changes vc is:</p><formula xml:id="formula_1">vc = 2 rt fvc<label>(1)</label></formula><p>Trials were divided along the conditions of target present or absent, coherency, target cycle length ft, and cycle difference ∆F , with</p><p>vc and e for all viewers collapsed and averaged over the resulting categories. t-tests and analysis of variance (ANOVA) with a 95% confidence interval were use to identify statistically significant variations in performance. In summary, we found:</p><p>1. Coherent trials had significantly lower vc and e, compared to non-coherent trials.</p><p>2. In most cases, e for non-coherent trials approached the chance rate of 50% (i.e., viewer responses were no better than simply guessing whether the target was present or absent).</p><p>3. For coherent trials, there was no effect of either ∆F or ft on e.</p><p>4. For coherent trials, vc was significantly higher for smaller ∆F , particularly at ft = 120 msec. Since e approached the chance rate of 50% for non-coherent trials, we restrict our remaining analysis to coherent trials only. Target presence or absence during coherent trials had no effect on either vc or e, t(24) = 0.091, p = 0.928 and t(24) = 0.034, p = 0.973, respectively. For coherent target present trials, target cycle length ft had no effect on either vc or e, F (6, 9) = 1.469, p = 0.290 and F (6, 9) = 0.528, p = 0.775, respectively. Finally, for coherent target present trials, cycle difference ∆F had a significant effect on vc, but not on e, F (3, 12) = 56.391, p &lt; 0.0001 and F (3, 12) = 0.524, p = 0.674, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Interpretation</head><p>Our experiment results suggest that a difference in coherent flicker is easy to detect, at the cycle lengths we tested. Non-coherent flicker, however, is very difficult to see. When elements with the same cycle length flicker at different onsets, they normally cannot be grouped together by the visual system. The visual result is similar to a set of blinking Christmas lights: they seem to turn on and off randomly, and the fact that their cycle lengths may (or may not) be identical is no longer apparent. This is similar to Driver et al.'s finding that coherent oscillation is salient, but that non-coherent oscillation is difficult to detect <ref type="bibr" target="#b4">[4]</ref>.</p><p>For coherent trials, vc was stable across ∆F for a given ft. However, vc was significantly higher when ft = 120 msec, compared to other ft values <ref type="figure" target="#fig_1">(Fig. 1a)</ref>. During the experiment viewers needed time to formulate their answer, plus an additional 250 to 500 msec to react and enter their response. If ft falls below the minimum reaction rate viewers are penalized by some additional visibility changes, because they cannot react quickly enough to avoid the changes that happen as they enter their response. This explains why vc was higher for ft = 120 msec. Less extreme examples of this effect can be seen for ft = 240 and ft = 360 msec.</p><p>One case where non-coherent flicker differences were easy to detect occurred when fvc = 120 msec and ∆F ≥ 360 msec <ref type="figure" target="#fig_1">(Fig. 1b)</ref>. Here, either the target elements or the background elements (but not both) flickered very quickly. Visually, this looked like either a rapidly changing region within a relatively stable background, or a rapidly changing background with a relatively stable region inset within it. The slower-changing region needed a cycle length of 360 msec or more to appear stable. When fvc &gt; 120 msec, the high-speed region no longer had the rapidly changing, blurred appearance needed to trigger this phenomenon.</p><p>Non-coherent error rates were also lower for fvc ≥ 960 msec. Since the largest ft tested during target present trials was 840 msec, any fvc &gt; 840 msec implies ft = f b , a target absent trial. When non-coherent trials alone are tested, target presence or absence is significant, t(31) = 2.26, p = 0.031, with target absent trials (e = 0.352) more accurate than target present trials (e = 0.535). This explains the lower error rates for these non-coherent trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DIRECTION EXPERIMENT</head><p>The direction experiment studied a viewer's ability to distinguish the presence or absence of a small 3×3 group of target elements that move in a direction dt different from the background elements d b . The velocity v of both target and background elements was fixed to a constant rate. Trials were otherwise identical to the flicker experiment. Observer accuracy and response time were used to measure viewer performance. The experiment was constructed to test two separate conditions:</p><p>1. Motion direction: the direction of the target elements' motion dt measured in degrees rotated counterclockwise from the horizontal axis. This allowed us to test whether different directions produced different viewer performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Motion difference: the absolute difference between the target and background elements' directions of motion ∆D = |dt − d b |. This allowed us to determine how much of an angular difference is needed to generate a perceived difference in motion direction.</p><p>In order to simulate motion, elements "walked" within constantsize screen regions (or cells) centered about an element's starting position. Neighboring cells adjoined with one another, so there were no gaps between the cells. As an element reached the edge of its cell, it wrapped around to the opposite side. When adjacent elements have the same direction of motion d and velocity v, and the same relative starting position within their cell, the impression of a continuous stream of motion is created. Each element reaches the edge of its cell and wraps around simultaneously, with the space left empty by one element being immediately filled by its adjacent neighbor. Thus, there is no visible separation between neighboring cells. When a target group is present in the display, however, a discontinuity will occur at the boundary between target and background cells, since the elements within the cells have different directions of motion dt = d b . This introduces a potential problem, since viewers may identify a target group by looking for the boundary discontinuity, and not by searching for different directions of motion.</p><p>We investigated a number of solutions to this problem. The simplest approach is to do nothing. Unfortunately, this produces a noticeable "popping" effect when elements reach a target-background edge. We tracked the center of an element ei to determine when it should wrap around. When ei's center crosses a target-background edge, the entire element disappears from one side of the cell and reappears on the opposite side. Since there is no corresponding element to fill the space vacated by ei, a visual discontinuity appears in the display. We next tried gradually increasing ei's transparency as it approached a target-background edge, and gradually decreasing its transparency as it moved away from the edge. Although this removed the visual discontinuity, we worried that viewers might identify targets by searching for variations in luminance, rather than differences in direction of motion. Our final solution was to use the stencil buffer to mask the group of cells containing the target elements. As a target element ei passes over a target-background cell boundary, it is masked so that only the portion of ei within the the target cell region is drawn. The stencil also clips background elements as they pass into the target region. The visual effect is similar to placing an array of background elements on a plane with a hole cut through it, then drawing a second array of target elements underneath the plane. The target elements can be seen through the hole, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Procedure</head><p>Ten members of the Computer Science department (faculty, staff, and graduate students) volunteered to participate during the experiment. Experiment details were similar to the flicker experiment, except that viewers were instructed to search each display for a small group of target elements moving in a direction different from the background elements.</p><p>Prior to starting the experiment, viewers completed 36 practice trials. 18 trials contained a target group (with each of the 9 possible motion differences included twice), and 18 trials did not. Viewers were allowed to repeat the practice session as often as they needed to become comfortable with the procedure and speed of the experiment. Viewers then completed 540 experiment trials presented in a random order during a single one hour session. Present or absent response for each trial, together with the time taken to respond, were saved for later analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Two performance metrics were recorded during the experiment: mean viewer response time rt and mean viewer error rate e. Trials were divided along the conditions of target present or absent, motion direction, and motion difference, with rt and e for all viewers collapsed and averaged over the resulting categories. t-tests and ANOVAs with a 95% confidence interval were used to identify statistically significant variations in performance. In summary, we found:</p><p>1. rt was significantly longer for target absent trials, compared to target present trials.</p><p>2. Neither rt nor e varied significantly across motion direction dt.</p><p>3. Both rt and e varied significantly across motion difference ∆D.</p><p>rt varied significantly between target absent and target present trials, t(78) = 17.33, p &lt; 0.0001. The difference in e was not significant, however, t(78) = 1.41, p = 0.163. For target absent trials, rt= 2202 and e= 0.007. For target present trials, rt=914 and e= 0.065. For target present trials, neither rt nor e varied significantly over target motion direction dt, F (9, 60) = 0.176, p = 0.996 and F (9, 60) = 0.107, p &gt; 0.999, respectively Both rt and e did vary significantly over motion difference ∆D, however, F (8, 61) = 112.9, p &lt; 0.0001 and F (8, 61) = 95.9, p &lt; 0.0001, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Interpretation</head><p>Results showed that viewers had longer rt for target absent trials, compared to target present trials. This type of finding is not uncommon, and represents a viewer's attempt to confirm his or her answer. Viewers can respond as soon as they detect a target during target present trials. For target absent trials, they will often wait for a short period of time to confirm no target is present before responding. The lack of a significant difference in e across trial type shows that viewers did not have more difficulty answering correctly during target absent trials.</p><p>There was no significant difference in either rt or e for different target motion directions dt. Motion in certain directions (e.g., cardinal directions like 0 • or 90 • ) is no easier to detect. rt and e did vary significantly based on motion difference ∆D = |dt − d b |, however. <ref type="figure" target="#fig_2">Figs. 2c and 2d</ref> show that rt is high for ∆D ≤ 20 • , and that e is high for ∆D = 10 • . Both values drop significantly past these points. This finding is supported by previous research which shows that at least 15 • of rotation is needed to distinguish differences in glyph orientation in a static image <ref type="bibr" target="#b16">[16]</ref>. Our results suggest a similar difference in motion direction is needed to accurately distinguish between target and background elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">VELOCITY EXPERIMENT</head><p>The velocity experiment studied a viewer's ability to identify the presence or absence of a small 3 × 3 group of target elements that move at a speed vt different from the background elements v b . The direction of all elements d was identical for a given trial. Trials were otherwise identical to the previous two experiments. Observer accuracy and response time were used to measure viewer performance. The experiment was constructed to test three separate conditions:</p><p>1. Target velocity: the target elements' velocity vt. This allowed us to determine if a minimum target velocity was needed to generate perceptually distinguishable motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Velocity difference: the absolute difference between the target and background elements' velocities ∆V = |vt−v b |. This allowed us to determine how much of a difference in subtended visual angle is needed to generate a perceived difference in velocity.</p><p>3. Motion direction: the direction of the elements' motion d measured in degrees rotated counterclockwise from the horizontal axis. This allowed us to test whether different directions produced different viewer performance.</p><p>In order to simulate motion, elements "walked" within constantsize screen regions (or cells) centered about an element's starting position. Neighboring cells adjoined with one another, so there were no gaps between the cells. As in the direction experiment, we used the stencil buffer to eliminate visual artifacts at the targetbackground edge during target present trials. We tested four different velocities: 10, 18, 26, and 34 pixels per second. Given an average viewing distance of 24 inches, a screen width and height of 14.5 × 11.5 inches, and a screen resolution of 1280 × 1024 pixels, these velocities corresponded to subtended visual angles of approximately 0.27 • , 0.49 • , 0.70 • , and 0.92 • . Previous research showed that velocities of 1 • or greater are easily perceived <ref type="bibr" target="#b8">[8]</ref>. We therefore chose values below this ceiling to search for limitations on a viewer's ability to perceive velocity differences.</p><p>Every Velocity differences ∆V = |vt − v b | were either 8, 16, or 24 pixels per second for the target present trials. Trials with a given ∆V were shown 96 times, divided equally across each trial type. Each target absent trial type was shown 9 times. This produced 288 target present trials and 288 target absent trials, for a total of 576 trials during the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Procedure</head><p>Ten members of the Computer Science department (faculty, staff, and graduate students) volunteered to participate during the experiment. Experiment details were similar to the flicker experiment, except that viewers were instructed to search each display for a small group of target elements moving at a velocity different from the background elements.</p><p>Prior to starting the experiment, viewers completed 24 practice trials. 12 trials contained a target group (with each of the 12 possible (vt, v b ) pairs included once), and 12 trials did not. Viewers were allowed to repeat the practice session as often as they needed to become comfortable with the procedure and speed of the experiment. Viewers then completed 576 experiment trials presented in a random order during a single one hour session. Present or absent response for each trial, together with the time taken to respond, were saved for later analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Two performance metrics were recorded during the experiment: mean viewer response time rt and mean viewer error rate e. Trials were divided along the conditions of target present or absent, target velocity, velocity difference, and motion direction, with rt and e for all viewers collapsed and averaged over the resulting categories. t-tests and ANOVAs with a 95% confidence interval were used to identify statistically significant variations in performance. In summary, we found:</p><p>1. rt was significantly longer for target absent trials, compared to target present trials.</p><p>2. e was significantly higher for target present trials, compared to target absent trials.</p><p>3. Neither rt nor e varied significantly across target velocity vt or target motion direction d. <ref type="bibr" target="#b4">4</ref>. Both rt and e varied significant across motion difference ∆V .</p><p>rt varied significantly between target absent and target present trials, t(110) = 14.920, p &lt; 0.0001. The difference in e was smaller but also statistically significant, t(110) = 3.335, p = 0.0012. For target absent trials, rt= 1339 and e= 0.005. For target present trials, rt=901 and e= 0.043. For target present trials, neither rt nor e varied significantly over either target velocity vt or target motion direction dt. For target velocity, F (7, 72) = 0.3205, p = 0.9424 and F (7, 72) = 0.6803, p = 0.6881 for rt and e, respectively. For target motion direction, F (7, 72) = 1.2632, p = 0.2931 and F (7, 72) = 1.3971, p = 0.2502. Both rt and e did vary significantly over velocity difference ∆V , however, F (2, 77) = 370.68, p &lt; 0.0001 and F (2, 77) = 52.167, p &lt; 0.0001, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Interpretation</head><p>As in the direction experiments, rt was longer for target absent trials than for target present trials, suggesting that viewers again waited some period of time to confirm no target was present before responding. Interestingly, e was slightly higher for target present trials (e = 4.3%) compared to target absent trials (e = 0.5%). This error occurred almost entirely during trials with a velocity difference ∆V = 8 pixels per second. Viewers mistakenly responded that no target was present during some of these trials. There was no significant difference in either rt or e for different target velocities vt or target motion directions d. This suggests that even a 10 pixel per second velocity (0.27 • of subtended viewing angle) can be rapidly detected as visible motion. As well, motion in certain directions was no harder or easier to detect.</p><p>rt and e did vary significantly based on velocity difference ∆V = |vt − v b |. <ref type="figure" target="#fig_0">Figs. 3c and 3d</ref> show that rt and e are high for ∆V = 8 pixels per second. Both values fall quickly past this point. Our results suggest that a velocity difference of 0.22 • of subtended visual angle is not sufficient to differentiate target and background elements. At 0.43 • (16 pixels per second), however, viewers could rapidly and accurately locate the target group (rt of 1087 msec versus 801 msec and e of 10% versus 0.4% for 8 and 16 pixels per second, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">PRACTICAL APPLICATIONS</head><p>We were interested in applying our experimental results to real data. One collaboration in our laboratory involves astrophysics researchers who are investigating various aspects of supernovas. Part of this effort includes simulating how a supernova collapses. We were provided with a number of 2D slices through a 4D volume (x, y, z and t) generated by their simulation. We want to visualize this data in a way that is perceptually salient, and that also minimizes the amount of on-screen information used to represent flow directions and velocities. Our current technique carefully seeds a small number of dots throughout the flow field. The dot positions are selected using an algorithm proposed by psychologists that models how visual the system perceives local orientation around each dot <ref type="bibr" target="#b11">[11]</ref>. We start with a sparse regular grid of dots over a target flow field, then iteratively optimize the dot positions to converge to a solution that produces a perceived local orientation that matches the flow direction at each dot's position in the flow field. Level-of-detail hierarchies are built to display both a highlevel overview and increasing amounts of detail within each field.</p><p>In order to reinforce flow direction, and to visualize the corresponding flow velocities, we animate each dot. We are experimenting with different data representations. In one example, continuous flow directions are binned into 18 categories: 0 • , 20 • , . . . , 340 • , and flow velocities into six categories: 0, 10, 18, 26, 34, and 42 pixels per second. This guarantees perceptually noticeable differences between each category. We are also visualizing the continuous flow directions and velocities without discretizing. This allows viewers to see the exact direction and speed of the flow, and to distinguish between locations with differences at or above the thresholds of 20 • and 0.43 • of subtended visual angle. We move each dot along a line through its position, with a direction and velocity based on the underlying flow field values. The length of the line is fixed to keep it within the perceived local neighborhood of each dot. Dots fade in and out at the endpoints of their lines to avoid visual discontinuities (i.e., similar to the use of the stencil buffer during our experiments). The result is a smooth, continuous animation that displays flow direction and velocity throughout the flow field. <ref type="figure">Fig. 4</ref> shows an example of visualizing data around two vortices and a shear boundary, with dot patterns from a twenty-frame interval composited into a single image to highlight the paths that the dots traverse. The astrophysics researchers are using our technique together with existing tools (e.g., volume visualization, LIC, and animated movie sequences) to study different aspects of their  <ref type="figure">Figure 4</ref>: An example of a Stevens flow visualization, with four static snapshots over a one second interval, and the composite of 20 timesteps over the same one second interval (center image); longer streamlines (e.g., at the top of the composite image) show regions of higher velocity simulation data. They have expressed an appreciation for the hierarchical abilities of our technique, which allows them to rapidly identify high-level patterns, then conduct more in-depth analyses of the underlying flow details.</p><p>We have also applied our motion results to data without an inherent motion context, for example, to visualize temperature and pressure gradients and areas of high precipitation in a meteorological dataset. Although the use of flicker, direction, and velocity work as expected, there were interactions between the properties (e.g., some flicker frequencies interfered with the detection of direction or velocity patterns). The same type of visual interference exists between texture and colour properties <ref type="bibr" target="#b5">[5]</ref>. Further experiments are needed to classify these effects in a way that will allow us to minimize or avoid them when designing multidimensional visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>This paper describes an experimental study of the perceptual properties flicker, direction of motion, and velocity of motion. Results suggest that a coherent flicker difference of at least 120 msec, a direction difference of at least 20 • , and a velocity difference at least 0.43 • of subtended visual angle are needed to distinguish between different values of the three properties.</p><p>There are a number of additional issues we plan to address. We are designing follow-on experiments to investigate visual interference, first between individual motion properties, and next between motion, colour, and texture. This knowledge is needed to apply motion more effectively during visualization. Higher order motion properties like acceleration and non-linear motion paths may also hold the ability to encode certain types of data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3 .</head><label>3</label><figDesc>Coherency: whether elements with the same cycle length flicker in phase or not. When flicker is coherent, elements with the same cycle length turn on and off together. For example, given two elements e1 and e2 with cycle lengths of 120 msec, both e1 and e2 have an on-off pattern at timesteps t = 0, 60, 120, 180, . . . When flicker is non-coherent, elements with the same cycle length can turn on and off at different times. Given the same elements e1 and e2 with cycle lengths of 120 msec, e1 could have an on-off pattern of t = 0, 60, 120, 180 . . ., while e2 could have a different on-off pattern of t = 20, 80, 140, 200, . . . In other words, even though the length of the on-off cycle is the same 120 msec, the onset of each cycle can occur at different times. This allowed us to test for the effect of coherency on viewer performance.We tested four target-background cycle differences: ∆F = 120, 240, 360, and 480 msec. The experiment included four target cycle lengths for each ∆F : ft = ∆F , ∆F + 120, ∆F + 240, and ∆F + 360 msec. For each ft two different background cycle lengths f b = ft ± ∆F were selected, except when ft = ∆F , since f b = ft − ∆F = 0 in this situation. To avoid f b = 0 while still maintaining balance within the experiment, f b = ft +∆F was used twice when ft = ∆F . This produced eight (ft, f b ) pairs for each ∆F . For example, for ∆F = 240, we tested the following target-background pairs:• ft = 240 msec: (240, 480) and (240, 480)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Average viewer performance during the flicker experiments for coherent and non-coherent trials: (a) vc versus ft; (b) e versus ft; (c) vc versus ∆F during target present trials; (d) e versus ∆F during target present trials</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Average viewer performance during the direction experiments: (a) rt versus dt; (b) e versus dt; (c) rt versus ∆D during target present trials; (d) e versus ∆D during target present trials moving smoothly beneath the background elements. By making elements appear and disappear in this way, no popping or change in luminance was visible. This forced viewers to use changes in the direction of motion to identify the presence or absence of a target group.We studied ten different motion directions ranging from 0 • to 90 • rotated counterclockwise from the horizontal axis in 10 • steps. Every possible combination of motion directions (dt, d b ) was tested, producing 90 cases where dt = d b (target present trials) and 10 cases where dt = d b (target absent trials). Motion differences ∆D = |dt − d b | ranged from 10 • to 90 • during the target present trials. Each target present trial was shown three times, while each target absent trial was shown 27 times. This produced a total of 540 trials during the experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>possible combination of velocities (vt, v b ) was tested, producing 12 cases where vt = v b (target present trials) and 4 cases where vt = v b (target absent trials). Each (vt, v b ) pair was shown eight different times, with the elements moving in eight different directions d ranging from 0 • to 315 • counterclockwise about the horizontal axis in 45 • increments. This produced a total of 96 target present trial types, and 32 target absent trial types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Average viewer performance during the velocity experiments: (a) rt versus vt; (b) e versus vt; (c) rt versus ∆V during target present trials; (d) e versus ∆V during target present trials</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Moticons: Detection, distraction, and task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Calvert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="515" to="545" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Serial search for targets defined by divergence or deformation of optic flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">J</forename><surname>Braddick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">E</forename><surname>Holliday</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="345" to="354" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Flicker and intermittent stimulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<pubPlace>In Clarence H</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Graham</surname></persName>
		</author>
		<title level="m">Vision and Visual Perception</title>
		<meeting><address><addrLine>New York, New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<date type="published" when="1965" />
			<biblScope unit="page" from="251" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Motion coherence and conjunction search: Implications for guided search theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Driver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcleod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dienes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="85" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large datasets at a glance: Combining textures and colors in scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="167" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The time it takes to detect changes in speed and direction of visual motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hohnsbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mateeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="2569" to="2573" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Moving iconic objects in scientific visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Kerlick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Visualization &apos;90</title>
		<meeting>Visualization &apos;90<address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="124" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Temporal thresholds and reaction time to changes in velocity of visual motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mateeff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hohnsbein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="363" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Differential sensitivity of the eye to intermittent white light</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Mowbray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Gebhard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="137" to="175" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Serial and parallel processing of visual feature conjunctions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Silverman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="page" from="264" to="265" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computation of locally parallel structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="19" to="28" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Feature analysis in early vision: Evidence from search asymmetries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Triesman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gormican</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="48" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Motion processing in peripheral vision: Reaction time and perceived velocity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Tynan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sekuler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="68" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Temporal properties of the visual detectability of moving spatial white noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Van Doorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Brain Research</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="179" to="188" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image based flow visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 2002 Conference Proceedings</title>
		<editor>John Hughes</editor>
		<meeting><address><addrLine>San Antonio, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="745" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Oriented texture slivers: A technique for local value estimation of multiple scalar fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weigle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Emigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Enns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Healey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Graphics Interface</title>
		<meeting>Graphics Interface<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="163" to="170" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
