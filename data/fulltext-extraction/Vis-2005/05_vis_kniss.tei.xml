<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Statistically Quantitative Volume Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><forename type="middle">M</forename><surname>Kniss</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Van Uitert</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National Institutes of Health</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Stephens</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Shi</forename><surname>Li</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Hansen</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">University of Utah</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Statistically Quantitative Volume Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>volume visualization</term>
					<term>uncertainty</term>
					<term>classification</term>
					<term>risk analysis</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Visualization users are increasingly in need of techniques for assessing quantitative uncertainty and error in the images produced. Statistical segmentation algorithms compute these quantitative results, yet volume rendering tools typically produce only qualitative imagery via transfer functionbased classification. This paper presents a visualization technique that allows users to interactively explore the uncertainty, risk, and probabilistic decision of surface boundaries. Our approach makes it possible to directly visualize the combined &quot;fuzzy&quot; classification results from multiple segmentations by combining these data into a unified probabilistic data space. We represent this unified space, the combination of scalar volumes from numerous segmentations, using a novel graph-based dimensionality reduction scheme. The scheme both dramatically reduces the dataset size and is suitable for efficient, high quality, quantitative visualization. Lastly, we show that the statistical risk arising from overlapping segmentations is a robust measure for visualizing features and assigning optical properties.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>Introduction Volume visualization endeavors to provide meaningful images of features "embedded" in data. There has been a significant amount of research over the past 17 years on providing visualization of volume data <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19]</ref>. Interactive volume visualization strives to allow the user to highlight features of interest in the volume data, such as material boundaries or different tissue types. Such features are dependent on a number of factors: the kind of data, domain specific knowledge, and the user's semantics. Simultaneously, there has been progress towards classifying features from volumetric data <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b20">21]</ref>. While segmentation is not considered to be a solved problem, there exist many different methods for segmenting volume data <ref type="bibr" target="#b9">[10]</ref>.</p><p>The demand for more quantitative measures in visualization has grown both within the visualization community and with the users of visualization tools. In volume rendering applications, transfer functions have typically been used for both classification and assignment of optical properties. However, using transfer functions for classification limits the user's ability to change the type of classification that occurs and does not provide any quantifiable measure of uncertainty. Transfer functions also tend to be unintuitive to use and do not provide the user with a clear concept of how classification is being performed on the data.</p><p>Statistical classification and segmentation methods incorporate a probabilistic model of the data and feature behav-A) Transfer Function-based Classification B) Unsupervised Probabilistic Classification <ref type="figure">Figure 1</ref>: A comparison of transfer function-based classification versus data-specific probabilistic classification. Both images are based on T1 MRI scans of a human head and show fuzzy classified whitematter, gray-matter, and cerebro-spinal fluid. Subfigure A shows the results of classification using a carefully designed 2D transfer function based on data value and gradient magnitude. Subfigure B shows a visualization of the data classified using a fully automatic, atlasbased method that infers class statistics using minimum entropy, non-parametric density estimation <ref type="bibr" target="#b20">[21]</ref>.</p><p>iors, a sophisticated notion of spatial locality, as well as the ability for the user to input their expertise. Interaction with this kind of probabilistic data and decision rules can provide each user the ability to define what information is important to his/her particular task as part of the visualization. In this paper, we propose a system that provides the user access to the quantitative information computed during fuzzy segmentation. The decision making step of classification is deferred until render time, allowing the user finer control of the "importance" of each class. Unfortunately, postponing this decision result comes at the cost of increased memory consumption. To accomodate this memory use, we propose a data dimensionality reduction (DDR) scheme that is designed to accurately represent pre-classified or segmented data for visualization. This approach allows data to be classified using the most appropriate fuzzy segmentation method, while utilizing existing volume visualization techniques. We also show that statistical risk is a robust measure for visualizing features and assigning optical properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head><p>There has been an enormous number of publications on both volume visualization and classification/segmentation. A comprehensive overview is outside the scope of this paper. For an extensive overview of volume rendering, the reader is refered to an excellent survey by Kaufman and Mueller <ref type="bibr" target="#b12">[13]</ref>. The book by Duda et al. provides a solid introduction to the topic of statistical classification and segmentation <ref type="bibr" target="#b4">[5]</ref>. <ref type="bibr">Stalling et al.</ref> demonstrate the utility of fuzzy probabilistic classification for creating smooth, sub-voxel accurate models and visualization <ref type="bibr" target="#b19">[20]</ref>.</p><p>Using transfer functions for volume rendering involves</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>287</head><p>Please see supplementary material on conference DVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Visualization 2005</head><p>October 23-28, Minneapolis, MN, USA 0-7803-9462-3/05/$20.00 Â©2005 IEEE.</p><p>mapping data values to optical properties such as color and opacity <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b3">4]</ref>. Transfer function design is a difficult process, especially when features are indistinguishable based on data value alone. As such, researchers have investigated augmenting the domain of the transfer function with derivative information to better disambiguate homogeneous materials and the boundaries between them <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>. Laidlaw demonstrated the effectiveness of classification techniques that define an explicit material mixture model and incorporate a feature space that includes spatial neighborhood information <ref type="bibr" target="#b15">[16]</ref>. Recently, a number of visualization research efforts have begun to leverage high quality classification techniques to enhance the expressiveness of transfer function design. <ref type="bibr">Bajaj et al.</ref> show how statistical analysis can drive the creation of transfer function lookup tables <ref type="bibr" target="#b0">[1]</ref>. Tzeng et al. demonstrate two kinds of binary discriminant classifiers for transfer function specification using artificial neural networks and support vector machines <ref type="bibr" target="#b23">[24]</ref>. Their approach illustrates the benefits of a robust feature space including local spatial information. In later work, Tzeng et al. utilize a cluster-based discriminant and discuss the importance of fuzzy classification with respect to material boundaries <ref type="bibr" target="#b24">[25]</ref>.</p><p>Others take a different approach in dealing with the difficulties of transfer function-based classification and color mapping by separating classification from the transfer function entirely. Tiede et al. describe a technique for volume rendering attributed or tagged data that smoothes feature boundaries by analyzing the relationship between the tags and original scalar data <ref type="bibr" target="#b22">[23]</ref>. Hadwigger et al. and Viola et al. describe techniques for rendering tagged data that extends the approach of Tiede using a sophisticated hardware accelerated system and novel rendering modalities for preclassified or segmented data <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26]</ref>. Bonnell et al. describe a method for the geometric extraction of features represented in data with volume-fraction information <ref type="bibr" target="#b1">[2]</ref>.</p><p>There has been a recent call from within the visualization community for visualization techniques that provide a rigorous treatment of uncertainty and error in the images they produce <ref type="bibr" target="#b11">[12]</ref>. Grigoryan and Rheihgens present a pointbased approach for representing spatial uncertainty in segmented data <ref type="bibr" target="#b7">[8]</ref>. Whittenbrink et al. describe how geometric glyphs can be used to express uncertainty in vector valued data fields <ref type="bibr" target="#b26">[27]</ref>.</p><p>A number of dimensionality reduction techniques have been developed to either detect low-dimensional feature manifolds in a high dimensional data-space or reduce the dimensionality of the data-space while preserving relationships between data samples. Principal component analysis and independent component analysis are examples of linear dimensionality reduction <ref type="bibr" target="#b4">[5]</ref>. ISOMAP and Local Linear Embedding are examples of non-linear manifold learning techniques that attempt to "flatten out" a sparsely sampled manifold embedded in a higher dimensional space while preserving the geodesic distance between points <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>General Statistical Classification Classification of image data in either 2D or 3D is a special case of a more general data classification. Since nearly all image data share the characteristic that samples are spatially correlated, the "feature space" for image data classification includes not only data values, but also spatial relationships.</p><p>Rather than discussing a specific classification scheme for image data, we would like to focus on the more general statistical classification process and its application to visualization. There are five basic elements of the statistical classification process that need to be considered when designing a classifier: feature selection, classifier selection, parameter estimation, class conditional probability estimation, and decision and risk analysis. The remainder of this section covers a statistical framework for image data classification for use in visualization applications and describes each of these steps in further detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Feature Selection</head><p>The first step in classifying data is to decide what features should be identified and subsequently visualized. The features are the different classes that exist in the data, which we will identify as Ïi, representing physical items such as white matter and gray matter in MRI brain data, or more abstract phenomena like warm and cold air-masses in numerical weather simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classifier Selection</head><p>Before features can be classified, it is necessary to understand how they are represented by the raw image data. For scanned image data, e.g. MRI or CT, there are several assumptions commonly made with respect to features in the acquired signal. These assumptions can help guide the construction of a statistical feature model. One common assumption is that discrete materials tend to generate nearly constant scanned values, i.e. if two samples come from the same material, their signal intensities should be the same. It is assumed that data sample values are degraded or perturbed by an independent noise source due to thermal variation and electro-magnetic interference. If the noise model can be adequately characterized as a probabilistic distribution, it dictates the expected variation of data value for a locally homogeneous material. Because data is only available in a discrete form, it is also assumed that the signal is band limited and that the sample values are mixtures of discrete materials near that sample. This assumption of partial volume effects allows one to predict, or model, how data values for multiple classes mix near boundaries. If for no other reason, partial volume effects alone suggest that apriori, discrete class assignment of data samples is a poor choice for representing classified data. That is, partial volume effects indicate that the classification of data samples near feature boundaries is inherently fuzzy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Estimation</head><p>If the feature model is parametric the next step is the estimation of the model parameters. For instance, if materials are represented as Gaussian distributions, it is necessary to identify the mean and standard deviation for each of the materials to be classified.</p><p>Not all feature models are parametric however, i.e. there may not be an explicit, a-priori model for which to estimate parameters. For instance, consider an artificial neural network as a classifier. With this type of classifier, the model and its parameters are implicit, and must be inferred from a training set. The training set is a set of samples and the associated class memberships identified by a user, which are used to "teach" the classifier the relationships between feature vectors (data values) and classes. A training set might also be used as segmentation seed points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Class Probability Estimation</head><p>Once an appropriate feature model has been developed and parameters identified for each feature of interest, it is possible to compute the class conditional probabilities for each sample in the dataset. When these probabilities are calculated using only the global feature model, with respect to individual samples or feature vectors ( x), we call this the probabilistic likelihood P ( x|Ïi). What is wanted, however, is the posterior distribution P (Ïi| x), which weighs the likelihood against observed evidence and prior information. Bayes Rule provides the relationship between the posterior distribution and likelihood,</p><formula xml:id="formula_0">P (Ïi| x) = P ( x|Ïi)P (Ïi) C i=1 P ( x|Ïi)P (Ïi)</formula><p>where C is the number of classes, P (Ïi) is the prior probability of class Ïi, and the denominator is a normalization factor that insures that c i=1 P (Ïi| x) = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Decision and Risk Analysis</head><p>Conditional risk R(Ïi, x) describes the loss incurred for deciding that a sample x belongs to class Ïi based on multiple class conditional probabilities,</p><formula xml:id="formula_1">R(Ïi, x) = C j=1 Î»(Ïi, Ïj)P (Ïj| x)<label>( 2 )</label></formula><p>where C is the number of classes, Î»(Ïi, Ïj) is the risk weight, which expresses the cost associated with deciding Ïi when the true state of nature is Ïj. The optimal, discrete class assignment rule for some feature sample x is the Ïi that minimizes R(Ïi, x), and is commonly known as the Bayes Risk or Bayes Decision Rule.</p><p>The maximum a-posteriori discriminant, also known as the "0-1 risk" decision rule, is commonly used when building a tag volume from class conditional probabilities. It is a special case in which the minimum risk class decision is simply the class with the maximum conditional probability. The risk weights in this case are,</p><formula xml:id="formula_2">Î»(Ïi, Ïj) = 1 i = j 0 i = j The risk function becomes simply R(Ïi, x) = 1 â P (Ïi| x).</formula><p>Another constructive way of reasoning about risk is to consider what minimum value of Î»(Ïi, Ïj) with respect to x would be required to make class Ïi the minimum risk class. This can be expressed as</p><formula xml:id="formula_3">Î»(Ïi, x) = max j,i =j P (Ïj| x) P (Ïi| x)<label>(4)</label></formula><p>We call this the "risk-ratio". <ref type="figure">Figure 2</ref> shows the relationship between probabilities and their ratios for a 1D feature space (x) and two classes. For compactness we denote P1(x) â¡ P (Ï1|x) and P2(x) â¡ P (Ï2|x). Because it is often useful to work in "log-probability" space, <ref type="figure">Figure 2</ref> also plots the log probabilities and log probability ratios (log risk ratios). <ref type="figure">Figure 2A</ref> shows plots for a pair of non-normalized distributions. <ref type="figure">Figure 2B</ref> shows the plots for the normalized distributions based on P1(x) and P2(x) from <ref type="figure">Figure 2A</ref>. Notice that neither the probability ratio nor log probability ratio is changed by normalization. Also notice that the log risk-ratios have a zero-crossing at the "0-1" risk boundary, denoted by the vertical line labeled B. In the following section, we will leverage the behavior of the log risk ratio to design a continuous discriminant function suitable for visualizing the relationships between multiple class probabilities.</p><p>While specifying or manipulating the Î»(Ïi, Ïj) risk weight for each pair of classes is extremely useful for exploring uncertainty in the classification, we have found that in practice it is often tedious and cumbersome. Instead, it is preferable to specify a weight that describes the "importance" of a class. From this weight it is possible to derive the risk weight as</p><formula xml:id="formula_4">Î»(Ï i, Ïj) = Î¼j/Î¼i i = j 0 i = j<label>(5)</label></formula><p>where Î¼i is a user specified importance weight for class Ïi.</p><formula xml:id="formula_5">-2 -1 1 2 3 -2 -1.5 -1 -0.5 0.5 1 2 -2 -1 1 2 3 -2 -1.5 -1 -0.5 0.5 1 2 P1(x) P2(x) P1(x) P2(x) Ln( P1(x) ) Ln( P2(x) ) Ln( P2(x) ) Ln( P1(x) ) P1(x) P2(x) P1(x) P2(x) P2(x) P1(x) P2(x) P1(x) Ln( P2(x) ) Ln( P1(x) ) Ln( P1(x) ) Ln( P2(x) ) Ln( P1(x) ) Ln( P2(x) )</formula><p>Ln( P2(x) ) Ln( P1(x) ) B) Normalized probability A) Non-normalized probability B B <ref type="figure">Figure 2</ref>: A 1D example of probabilistic boundary behavior. The graphs plot the relationship between probability, log-probability, probability ratio, and log-probability ratio in multi-class uncertainty analysis. <ref type="figure">Figure B</ref> shows these quantities for normalized probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Visualizing Classified Data</head><p>Our approach for visualizing classified data advocates decoupling the first four primary stages of classification from the transfer function and deferring the final step, the decision, until a sample is rendered. This requires the fuzzy class probabilities to be included with the data used for rendering. The advantage of using the fuzzy probabilities is that they interpolate, unlike discrete class assignments, and allow the transfer function design to be greatly simplified. <ref type="figure" target="#fig_0">Figure 3</ref> shows a simple, synthetic 2D example that illustrates various approaches for color mapping based on class probabilities from a realistic classifier, iso-surfaces, and transfer function-based classification. The simulated raw data ( <ref type="figure" target="#fig_0">Figure 3B</ref>) was created by assigning a unique intensity value to each of the generated materials ( <ref type="figure" target="#fig_0">Figure 3A)</ref>, rasterizing the materials into a 256 2 image, blurring the image, and finally adding three percent normally distributed noise. <ref type="figure" target="#fig_0">Figure 3C</ref> shows four relevant iso-value thresholds (Taken at intervals between the class means) as subimages. The posterior class conditional probabilities were estimated using the known parameters <ref type="figure" target="#fig_0">(Figure 3 D)</ref>; mean data value, noise distribution, and a neighborhood size proportional to the blur kernel. <ref type="figure" target="#fig_0">Figure 3E</ref> shows the image color mapped based on the class with the maximum probability (0-1 risk decision), as is often done when generating "tagged data". <ref type="figure" target="#fig_0">Figure 3F</ref> shows a color mapping based on class probabilities greater than a threshold of 0.5 for all classes; all data values containing a probability less than 0.5 are shown as black. <ref type="figure" target="#fig_0">Figure 3G</ref> shows the image with colors weighted by the minimum reciprocal-risk-ratio, w i = 1/Î»(Ïi, x)). Notice that the boundaries are crisper than in the probability weighted example and that the variation in thickness for the loop (material e) is easier to see. <ref type="figure" target="#fig_0">Figure 3H</ref> shows a color mapping based on the 0-1 risk decision, with the addition of two importance weighted risk decisions for material e, where Î¼e = 1.15 and Î¼e = 1.5. The additional max risk-ratios were blended over the color map weighted by 1/Î¼e. Finally, <ref type="figure" target="#fig_0">Figure 3I</ref> shows a color mapping made using a carefully designed 2D transfer function, based on data value and gradient magnitude. Because gradient estimation is highly sensitive to noise, the 2D transfer function performed quite poorly with the raw data (top-right subfigure), even though the gradient was estimated using the derivative of a cubic b-spline kernel, which implicitly blurs the data. To accommodate for the noise, the data was pre-processed using a median filter with a width of five pixels before gradient computation ( <ref type="figure" target="#fig_0">Figure 3I</ref>, bottom-right subfigure). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Color Mapping Multi-Class Probabilities</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Risk-centric Transfer Functions</head><p>Instead of taking a D dimensional vector of raw-data values as input, a transfer function based on class conditional probabilities transforms a C dimensional vector into the optical properties needed for rendering, where C is the number of classes. While it may seem appropriate to use the class conditional probabilities as input to the transfer function, as described in Section 3.5, the relationships between the individual posterior probabilities are best expressed in terms of risk. A reasonable choice is the C dimensional risk vector,</p><formula xml:id="formula_6">Î( x) = [Î»0( x) . . . Î» C ( x)] T , where Î»i( x) = R(Ïi, x) from Equation 2.</formula><p>Unfortunately, this expression of risk does not provide much more information than the raw probabilities. Instead, it is preferable to use a discriminant function that we call the minimum decision boundary distance:</p><formula xml:id="formula_7">Î»i( x) = max j,j =i log Î»(Ïj, Ïi) Pj( x) Pi( x)<label>(6)</label></formula><p>where we are using the short-hand Pi( x) â¡ P (Ïi| x). This can be rewritten as</p><formula xml:id="formula_8">Î»i( x) = max j,j =i ( log(Î»(Ïj, Ïi)) + log(Pj( x)) â log(Pi( x)) )</formula><p>In terms of importance weights Î¼i, the minimum decision boundary distance is the maximum over all</p><formula xml:id="formula_9">j = i Î»i( x) = log(Î¼j) + log(Pj( x)) â log(Î¼i) â log(Pi( x)) (8)</formula><p>The benefit of this expression is that it places the decision boundary, with respect to class Ï i, at Î»i( x) = 0, with negative values indicating that class Ïi is the minimum risk class, and positive values indicating that it is not. It also has a more linear behavior than the probability ratio, and is invariant with respect to normalization (or any other uniform scaling) of the class conditional probabilities. For Gaussian distributions with the same standard deviation, this term is exactly the minimum decision boundary distance (in the feature space) scaled by 2 ci â cj , two times the distance between their means or centers. <ref type="figure" target="#fig_1">Figure 4</ref> illustrates the behavior of this term for three different class distributions in a 1D feature space (x), with a varying importance term for class 2. Notice that in <ref type="figure" target="#fig_1">Figure 4C</ref> a small increase in Î¼2 was able to make class 2 the minimum risk class, even though it would not have been using the maximum a-posteriori decision rule, used in <ref type="figure" target="#fig_1">Figure 4A</ref>. The arrows below the plots indicate the range over which each class is the minimum risk decision. In <ref type="figure" target="#fig_1">Figure 4B</ref> all three classes are the minimum risk at the origin.  Like iso-surfaces, risk surfaces, i.e. spatial decision boundaries, have a number of desirable properties; water tight, easy geometric extraction. Unlike iso-surfaces, risk surfaces can support interesting boundary configurations, nonmanifold 3-way and 4-way intersections, whereas iso-surfaces only support manifold 2-way interfaces.</p><formula xml:id="formula_10">-2 -1 1 2 -1 -0.5 0.5 1 -2 -1 1 2 -1 -0.5 0.5 1 -2 -1 1 2 -1 -0.5 0.5 1 P1(x) P3(x) P2(x) Î»2(x) Î»1(x) Î»3(x) A) Î¼2 = 1 B) Î¼2 = 1.1 C) Î¼2 = 1.4</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Reparameterization</head><p>The increased storage size required for representing multiple fuzzy classified features is an important issue for interactive rendering. Most hardware based rendering platforms place hard restrictions on dataset size. Increased data size also has a dramatic effect on data access bandwidth, a prime concern for rendering efficiency, which is arguably a more pressing issue than memory capacity limitations.</p><p>To address the problems associated with increased data set size, we need a data-space transformation T ( c â C ) â P with the following properties: 1) Reduces the dimensionality of the dataspace; P C. 2) Invertible with minimal error; c â T â1 (T ( c)) &lt; .</p><p>3) Encoded values can be interpolated prior to decode; 4) Decoding has minimal algorithmic complexity.</p><p>The criteria above describe a transformation, or encoding, of the data that effectively compresses the data, while allowing the conditional probabilities to be reconstructed after the data has been resampled during rendering. While dimensionality reduction (criterion 1) helps us solve the problem A B <ref type="figure">Figure 6</ref>: Slices of classified datasets reparameterized into a 3D dataspace, and their associated graphs. The color is generated by mapping the 3D data coordinates directly to RGB colors. Subfigure A shows a classified engine dataset, and Subfigure B shows the Brain-Web Phantom fuzzy classifed data <ref type="bibr" target="#b2">[3]</ref>.</p><p>of increased storage and bandwidth, the criterion of interpolation prior to decode (3) helps eliminate redundant computation during the resampling and gradient estimation stages of the rendering pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.1</head><p>Graph-based Dimensionality Reduction GDR Our approach models the transformation (T ( c)) as a graph layout problem, and is similar to work done independently by Iwata et al. <ref type="bibr" target="#b10">[11]</ref>. Nodes represent pure classes, P (Ïi| x) = 1, and edges represent mixtures of multiple classes. Once connectivity of the graph is known, it is laid out in a space with a dimension P of our choosing, optimizing the spacing between nodes so there is no overlap of edges. The node locations are then used as a sparse data interpolation system, which serves as the inverse mapping T â1 ( p). All data samples c are then mapped to this parameterization space by finding the position p that minimizes the difference between T â1 ( p) and c. <ref type="figure">Figure 6</ref> illustrates this method applied to 2 classified datasets using a 3D reparameterization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Graph Construction</head><p>Graph construction begins with identifying edge weights eij for each pair of class nodes Ni and Nj. Edge weight is the covariance of the class probabilities assuming a mean of 1 for each class,</p><formula xml:id="formula_11">eij = N k=1 P (Ïi|x k )P (Ïj|x k )</formula><p>where N is the number of samples in the dataset. In addition to the pair-wise class variance, we are interested in identifying higher order mixtures. To do this, an additional node is added to the system for any significant higher order mixtures. These nodes have an associated weight, n, that is the higher order variance for the mixture type it represents. For instance the three way mixture variance is</p><formula xml:id="formula_12">n ijk = N l=1 P (Ïi|x l )P (Ïj|x l )P (Ï k |x l )</formula><p>Note that for volume data these variance weights represent fuzzy boundaries between classified features. In general, most edge and higher order node weights are zero, i.e. the features/classes do not touch in the spatial domain; this is a property that our data parameterization method exploits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Graph Layout</head><p>Once the edge and higher order node weights are determined, they are normalized based on the maximum weight. These weights are then used to compute potentials for a force directed graph layout. Our solver treats edges as springs with a unit natural length, and nodes as charged particles, which repel one another. The solver seeks to minimize an energy function with respect to the class nodes, which are positions in a P dimensional space; </p><formula xml:id="formula_13">E( N2, . . . , N C ) = M i=1 M j=i+1 Ï Ni, Nj</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Sparse Data Interpolation and Encoding</head><p>Once we have laid out the graph in our target space, the class nodes serve as fiducials for a sparse data interpolation scheme. For this we choose Gaussian radial basis functions. This sparse data interpolation scheme defines a mapping, T â1 ( p), from our encoding space back to the C dimensional probability space. For some point p in the encoding space, the corresponding vector of conditional probabilities, c, is given by</p><formula xml:id="formula_14">c = C i=1 ci exp(â p â Ni 2 ) C i=1 exp(â p â Ni 2 )</formula><p>where ci is the conditional probability vector associated with node Ni, and the denominator expresses the fact that this equation is a "sum of unity" sparse data interpolation scheme. Since each node represents a pure class probability, all of the elements of its associated c i are 0 except the ith entry, which is 1. Therefore, the conditional probability for each element of c reduces to</p><formula xml:id="formula_15">c [i] = exp(â p â Ni 2 ) C j=1 exp(â p â Nj 2 )<label>(14)</label></formula><p>That is, the ith element of c is simply the normalized interpolation kernel weight associated with Ni. As suggested in Section 4.2, the minimum decision boundary distance discriminant (Equation 8) is perhaps a better quantity for transfer function color mapping. In this case, the denominator in Equation 14 cancels and the expression for the elements of Î( x) becomes the maximum over all j = i,</p><formula xml:id="formula_16">Î» i( x) = log(Î¼j) â p â Nj 2 â log(Î¼i) + p â Ni 2 (15)</formula><p>where p = T [P (Ï1| x), . . . , P (Ï C | x)] <ref type="bibr">T</ref> , and note that â p â Nj 2 â¡ log(P (Ïj| x)).</p><p>For each sample in our dataset, identified by its feature vector xi, the associated vector of class conditional probabilities, ci = [P (Ï1| xi), . . . , P (Ï C | xi)] T , is parameterized, or mapped under T ( c), into our new space as the point, pi, that minimizes</p><formula xml:id="formula_17">E( pi) = ci â T â1 ( pi)</formula><p>Unfortunately, since we are using non-compact basis functions, when a class probability approaches 1, the p vectors tend to infinity. This is due the fact that the Gaussian basis functions are never actually zero. To accommodate this we apply an affine transformation to the elements of T â1 ( pi) that ramps smoothly zero as the values approach some threshold . This epsilon value is the reciprocal of the maximum importance weight Î¼i that our system allows; empirically, a Î¼max = 200 is sufficient to make the minimization well behaved. The affine transformation has no effect on the placement of the decision boundaries, and tends to push error in the transformation out to the extremely low class probabilities, i.e. P (Ïi| x) &lt; â 0.</p><p>This mapping can alternatively be thought of a reparameterization of the data-space that allows us to trivially classify the data using normalized Gaussian distributions with means equal to the class node centers. That is, the data samples are arranged in the new space so they are, by construction, normally distributed based on the feature classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Implementation</head><p>Our implementation of this work found that decoupling classification and transfer function color mapping not only improved the flexibility of our visualization system, but also dramatically simplified its construction. Our system naturally breaks up into several components: slicing and probing, classification and segmentation, GDR encoding, and visualization. Whenever possible, we leveraged existing tools and libraries to speed the development and prototyping of application specific variants of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Slicing and Probing</head><p>The first step in the visualization of data using our system is the inspection of the raw data on a slice by slice basis. Our slicing tool's interface is modeled after a user interface commonly used for medical data. There are three slice views, one for each axis of the 3D data, and mouse clicks in one window automatically update the slice positions in the other two. This tool also provides window and level contrast settings as well as simplistic coloring of multi-variate data. The main function of this tool is to provide the ability to do feature/class selection and training set generation. This is done by probing locations in the data, on the slice views, where a class is present. These probe locations can then be used to estimate classification parameters, or as training data for non-parametric classifiers, or as seed points for segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Classification and Segmentation</head><p>While we have developed several specialized classification algorithms of our own, we rely heavily on a collaborative project aimed at the development of open source algorithms for image registration, classification, and segmentation called the Insight Toolkit (ITK) <ref type="bibr" target="#b9">[10]</ref>. The designers of this toolkit were careful to make a strong distinction between class conditional probability estimation and decision rules with respect to the statistical classifiers it supports, which makes the specialization of classification and segmentation algorithms for the purpose of visualizing class conditional probabilities very convenient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">GDR Encoding</head><p>The implementation of the Graph-based Dimensionality Reduction scheme represented the bulk of our development effort. Even so, the library only consists of approximately 300 lines of code. We developed the library to be generic with respect to dimension, so it naturally supports encodings with any target dimension. A force directed graph solver naturally lends itself to least-squared, implicit solutions. However, given the relatively low number of nodes that we need to layout (typically between ten and one hundred), we found that a time dependent explicit solver performs quite well. The advantage of using an explicit solver is in the simplicity of its implementation. The disadvantage is that explicit solvers can tend to get stuck in local minima, which can be resolved using simulated annealing randomization. Our solver is iterative, with an adaptive timestep proportional to the maximum force over all nodes. Our solver begins by initializing all class nodes to random positions. At each timestep the class node positions are updated by</p><formula xml:id="formula_18">Ni = Ni + Ît 1 + Î± max k N j=1 Ï( N k , Nj) N j=1 Ï( Ni, Nj)</formula><p>where Î± is a scale term, in our system we choose Ît = 1 and Î± = 10. All higher-order variance nodes are constrained to the average position of the class nodes whose variance they represent, therefore after each time step, we update the positions of these nodes accordingly. The iteration proceeds until the energy function E(N2, . . . , NC ) is no longer decreasing. We then record the graph configuration and the value of the energy function, and randomize several of the class node positions and minimize the new configuration. We perform this process of minimization and randomization several times, generally 10, and return the configuration with minimal energy. The encoding step, p = T ( c), is also expressed as a minimization. This too, can be implemented as an iterative solver. We accomplish this by first selecting an initial p as</p><formula xml:id="formula_19">p = C i=1 Ni c [i]</formula><p>The update step is</p><formula xml:id="formula_20">p = p + C i=1 Ni c [i] â A(T â1 ( p)[i]) s</formula><p>where A() is an affine transformation mapping the range [ , 1] â [0, 1], and s is a scale term proportional to the iteration number. Empirically, we have found that s = (1 + n)/2 gives excellent results, where n is the iteration number. Because our inverse mapping, T â1 , is smooth, this optimization converges quickly. Five iterations is generally enough to achieve an acceptable RMS error, ideally this error should be approximately . For instance, the 4D GDR encoding of the BrainWeb Phantom classified data achieves an RMS error of .0004, with an = .0003.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Visualization</head><p>Our rendering system is a simple single pass hardware ray caster. When the number of classes being visualized is five or less, we do not require a GDR encoding of the posterior probabilities. Since we know that P (Ï c| x) = 1 â Câ1 i=1 P (Ïi| x), we can simply use a 4D dataspace (RGBA texture) for four classes, and easily derive the fifth class's probability. When using GDR encoded data, the first step in rendering a sample is decoding. Recall that since we want the minimum decision boundary distance, Î( x), we do not need to actually decode the class conditional probabilities (see <ref type="bibr">Equation 15)</ref>. The algorithm for computing Î from GDR encoded data can be computed efficiently by looping over the classes twice. The first loop computes log(Î¼i) + log(P (Ïi| x)) and saves off the maximum and second maximum of these values. The second loop completes the computation of Î â¡ L by subtracting the respective log(Î¼i)+log(P (Ïi| x)) from the maximum of these values, unless this term is already the maximum, in which case we use the second maximum. This small optimization converts the computation of Î from an O(C 2 ) to an O(C) algorithm.</p><p>Once the Î( x) vector has been computed, the transfer function can be evaluated as C separable 1D opacity functions, or lookups. The domain of these 1D transfer functions is [â log(Î¼max), log(Î¼max)], where negative values indicate that the class is the minimum risk class and 0 is the decision boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results and Discussion</head><p>Color mapping based on the decision boundary distance term has a number of advantages. Unlike the raw class conditional probabilities, this term takes into account the relationships between the class probabilities for each sample and a user defined importance for each class. This means that the transfer function can be evaluated for each class independently, i.e. we need only design a simple 1D transfer function for each class. Furthermore, thanks to its welldefined behavior, we can define transfer functions based on decision boundary distance in advance, and apply them to classes as effects or profiles. For instance, if we desire a surface-like rendering, the opacity function for a particular class is simply a dirac delta centered at 0. This can be implemented robustly using a single preintegrated isosurface lookup table, which can be used for all classes that are to be rendered in this way. Alternatively, this can also be done by detecting a Î»i( x) zero-crossing between two adjacent samples along the viewing ray, an example of risk-surfaces rendered using this method can be seen in <ref type="figure">Figure 7</ref>. For two sided risk-surfaces, we need only move the delta function to a slightly negative Î» i( x) value, so that each class' risk-surface appears at a slightly different position than those who share that boundary. If we desire a more traditional fuzzy rendering, a suitable opacity function can be any monotonically decreasing function based on âÎ»i( x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Low</head><p>High Sensitivity wht csf skl skn m+s glial <ref type="figure">Figure 7</ref>: Selected risk-surfaces from the classified BrainWeb Phantom "fuzzy data", color mapped based on sensitivity (a measure of uncertainty in the decision boundary position). The data used for the renderings is a 4D GDR encoding of ten material classes.</p><p>Often, when probabilistic data is presented graphically, it is also shown with error bars indicating some confidence interval or sensitivity. We can create a kind of 3D analogue by displaying multiple risk-surfaces for a class at once, by varying Î¼i. These concentric risk-surfaces provide a visual indication of the sensitivity of the boundary test. That is, it shows how the boundary would change if some class Ïi was Î¼i times more likely. When the contours are packed closely together, we see that the decision boundary is well defined. When the contours are spread out, we see that the boundary is sensitive to small changes in class likelihoods, indicating that the exact placement of the decision boundary is less reliable. We can also derive a local measure of sensitivity that can be used for coloring the risk surfaces to highlight regions where the boundary placement is less certain. The measure we use is s( x) = 1/ âÎ»i( x) , larger values of s( x) indicate a higher sensitivity in the spatial boundary location with respect to small changes in Î¼i. Confidence intervals are another way of generating risk-boundary error bars. Confidence intervals can be measured in terms of the volume enclosed by a decision boundary with respect to Î¼i. We compute confidence intervals by generating a histogram for the range of Î¼i from <ref type="bibr">[1/Î¼max, Î¼max]</ref>, where each bin is simply the number of samples in the dataset with a negative Î»i( x) values given the corresponding Î¼i. The 95% confidence interval is the decision boundary for the Î¼i whose volume histogram count is 95% of the Î¼max histogram bin count. <ref type="figure" target="#fig_4">Figure 8</ref> shows examples of each of these methods as well as a more traditional approach to color and opacity specification. Notice that the fuzzy method ramps color to black as Î» approaches 0. This gives us yet another visual indication of uncertainty, when the black boundary is thick, the placement of the decision surface in this region is less certain.</p><p>Because the reparameterized dataspace is an encoding, transformations to the data, such as scaling and bias or quantizing, must also be applied to the node centers. We have found this to be quite easy if we simply encode the centers as part of the dataset, for instance appended to the end of the file or setting the first few samples to be the (parameterized) node centers. Of course, this technique is fragile with respect to spatial transformations, such as resampling and cropping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8</head><p>Conclusion and Future Work This paper describes a key way in which domain specific classification and segmentation can be integrated with state of the art volume visualization techniques. By decoupling classification and color mapping, classification can be accomplished independently of color mapping, allowing application specific solutions to evolve without concern for the current limitations of transfer function-based volume rendering. The transfer function interface also is dramatically simplified, not only is the feature space broken down into independent components, but these components have semantic meaning to the user. We show that deferring the decision step of the classification pipeline until render-time can provide the user with the ability to manipulate the decision making process and investigate uncertainty in the classification. We also address the increase in data set size, due to the need to store each class' probabilities independently, by developing a data dimensionality reduction technique specifically designed to accurately encode probabilistic image data and efficiently decode after resampling during the rendering phase of the visualization pipeline. insight in the development of this research, and Aaron Lefohn for early feedback and last minute writing. We would also like to thank David Laidlaw and Ross Whitaker for many helpful discussions relating to this work over the last several years, and Ryan White for help navigating the world of computer vision. This work has been supported by the DOE HPCS Graduate Fellowship, DOE-CSAFE, DOE-VIEWS, and DOE-ASC ASAP.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>A 2D example of probabilistic boundary behavior. A) The synthetic dataset, consisting of five materials. B) The raw dataset constructed from a blurred monochrome version of the synthetic dataset with noise added. C) The four most relevant iso-value thresholds of the raw data as subimages. D) An image colored based on the class conditional probabilities of the classified raw data. E) A "max-probability" tagged image. F) The data set color mapped based on a probability threshold of 0.5. G) An image colored based the probability ratios (risk curves). H) An image showing several risk contours for material "e". I) Data color mapped using a carefully hand tuned 2D transfer function, based on raw data value and the gradient magnitude of the median filtered raw data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Behavior of the decision boundary distance function with respect to a varying importance term (mu).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Effect of varying the importance term for white matter in a classified brain dataset visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>where C is the number of classes, M is the total number of nodes in the system including the higher order variance nodes, and Ï( Ni, Nj) is the force function. The first node, N1, is constrained to the origin of the ambient space.The nodes representing higher order variance, N C+1 . . . NM , are constrained to the average position of the class nodes whose variance they represent. The role of these nodes is to insure that class node placement does not interfere with spaces that represent important feature mixtures. The force function, Ï( Ni, Nj), for the charged particle and spring edge model is, Ï( Ni, Nj) = eij( d â 1) + ninj exp(â d 2 ) d where d = Ni â Nj, and ni is a higher order variance node weight or 1 if Ni is a class node. If either of the nodes represent a higher order variance, the edge weight eij is 0. This function returns the force vector with respect to node Ni. It is anti-symmetric with respect to the order of its parameters, i.e. Ï( Ni, Nj) = âÏ( Nj, Ni).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>A comparison of rendering profiles. Subfigure A shows a "fuzzy" volume rendering color-mapped based on lambda for white matter. Subfigure B shows the risk-surface (lambda equal 0) for white matter color-mapped based on sensitivity (change in boundary position per unit change in importance). Subfigure C shows confidence intervals based on percent change in importance. Subfigures D and E show various features classified/segmented in the engine dataset. D shows sensitivity color mapping applied to the valve guides. E shows the coolant chamber of the engine rendered using confidence intervals.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We wish to acknowledge Randal Frank, Mark Duchaineau, and Valerio Pascucci for providing substantial support and</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Contour Spectrum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schikore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="167" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Material interface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Bonnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Duchaineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schikore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hamann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics(TVCG)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="500" to="511" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Brainweb: Online interface to a 3d mri brain database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cocosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kollokian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Evens</surname></persName>
		</author>
		<ptr target="http://www.bic.mni.mcgill.ca/brainweb" />
	</analytic>
	<monogr>
		<title level="m">NeuroImage</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proceedings of SIGGRAPH 88)</title>
		<imprint>
			<date type="published" when="1988-08" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pattern Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">High-Quality Pre-Integrated Volume Rendering Using Hardware-Accelerated Pixel Shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics / SIGGRAPH Workshop on Graphics Hardware &apos;01, Annual Conference Series</title>
		<imprint>
			<publisher>Addison-Wesley Publishing Company, Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multilabel random walker image segmentation using prior models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2005</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Accepted</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Point-based probabilistic surfaces to show surface uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grigoryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TVCG</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="564" to="573" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">High-quality twolevel volume rendering of segmented data sets on consumer graphics hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The ITK Software Guide: The Insight Segmentation and Registration Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ibanez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cates</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Kitware, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Parametric embedding for class visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Iwata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ueda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Stromsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="617" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Top scientific visualization research problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="page" from="13" to="17" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The Visualization Handbook, chapter Overview of Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Semi-automatic generation of transfer functions for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multidimensional transfer functions for interactive volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2002-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Geometric Model Extraction from Magnetic Resonance Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laidlaw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A hybrid ray tracer for rendering polygon and volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="1990-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by local linear embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Volumetric ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Segmentation of 3d medical images with subvoxel accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stalling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zoeckler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Assisted Radiology and Surgery</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mri tissue classification with neighborhood statistics: A nonparametric, entropy-minimizing approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Awate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2005</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Accepted</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2000-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">High quality rendering of attributed volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Tiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schiemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Hohne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An intelligent system approach to higher dimensional classification of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="284" />
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A cluster-space visual interface for arbitrary dimensional classification of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE TCVG Symposium on Visualization</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Importance-driven volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>GrÃ¶ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization&apos;04</title>
		<meeting>IEEE Visualization&apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="139" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Glyphs for visualizing uncertainty in vector fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wittenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lodha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TVCG</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="266" to="279" />
			<date type="published" when="1996-09" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
