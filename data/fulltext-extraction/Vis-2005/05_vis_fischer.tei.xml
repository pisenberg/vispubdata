<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Illustrative Display of Hidden Iso-Surface Structures</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Fischer</surname></persName>
							<email>fischer@gris.uni-tuebingen.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Bartz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Straßer</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Visual Computing for Medicine WSI</orgName>
								<orgName type="institution">GRIS University of Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Visual Computing for Medicine WSI/GRIS</orgName>
								<orgName type="institution">University of Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">WSI/GRIS</orgName>
								<orgName type="institution">University of Tübingen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Illustrative Display of Hidden Iso-Surface Structures</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.3.3 [Computer Graphics]: Picture/Image Generation-Display algorithms</term>
					<term>I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Visible line/surface algorithms</term>
					<term>I.4.3 [Image Processing and Computer Vision]: Enhancement-Filtering illustrative rendering, non-photorealistic rendering, transparency, indirect volume rendering, hatching, shading language</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We describe the implementation of the algorithm, which exploits the programmability of state-of-the-art graphics processing units (GPUs). The algorithm described in this paper does not require any preprocessing of the input data or a manual defitinion of inner structures. Since the presented method works on iso-surfaces, which are stored as polygonal datasets, it can also be applied to other types of polygonal models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: Two images generated with our illustrative rendering algorithm. The shape of the front layer of the geometry is represented by black silhouettes and hatching. The second layer of the iso-surface is rendered as red silhouette lines. In <ref type="figure">Figure 1</ref>(b), a portion of the volume containing very large voxel values is shown as blue "secondary" geometry. The images were rendered in real-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABSTRACT</head><p>Indirect volume rendering is a widespread method for the display of volume datasets. It is based on the extraction of polygonal isosurfaces from volumetric data, which are then rendered using conventional rasterization methods. Whereas this rendering approach is fast and relatively easy to implement, it cannot easily provide an understandable display of structures occluded by the directly visible iso-surface. Simple approaches like alpha-blending for transparency when drawing the iso-surface often generate a visually complex output, which is difficult to interpret. Moreover, such methods can significantly increase the computational complexity of the rendering process.</p><p>In this paper, we therefore propose a new approach for the illustrative indirect rendering of volume data in real-time. This algorithm emphasizes the silhouette of objects represented by the iso-surface. Additionally, shading intensities on objects are reproduced with a monochrome hatching technique. Using a specially designed two-pass rendering process, structures behind the front layer of the iso-surface are automatically extracted with a depth peeling method. The shapes of these hidden structures are also displayed as silhouette outlines. As an additional option, the geometry of explicitly specified inner objects can be displayed with constant translucency. Although these inner objects always remain visible, a specific shading and depth attenuation method is used to convey the depth relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Volumetric datasets have become a widely used format for storing three-dimensional information in application areas like medicine and scientific visualization. The efficient display of such datasets has been a field of active research for many years. One very common method for rendering volume data is the use of polygonal isosurfaces, which represent boundary surfaces defined by a constant intensity value within the volume. The Marching Cubes algorithm proposed by Lorensen and Cline is a widespread method for the extraction of such iso-surfaces from a volume dataset <ref type="bibr" target="#b12">[13]</ref>. Standard polygon rasterization techniques are then used for displaying the iso-surfaces. This entire process is called indirect volume rendering.</p><p>Please see supplementary material on conference DVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IEEE Visualization 2005</head><p>October 23-28, Minneapolis, MN, USA 0-7803-9462-3/05/$20.00 ©2005 IEEE.</p><p>In conventional indirect volume rendering, only the front layer of the iso-surface geometry is visible to the user. Parts of the model which are at a greater depth in the eye coordinate system are suppressed by hidden-surface algorithms like the Z-Buffer. However, the shape of inner structures in a dataset is of great importance for many applications. For instance, inner organ structures or back walls of cavities often are of interest for a physician inspecting an anatomical dataset. In the case of a volume dataset containing a scanned engine block (see <ref type="figure">Fig. 1(a)</ref>), it might be useful to view hidden mechanical parts or structural weaknesses in non-destructive material testing.</p><p>The straightforward solution for displaying hidden structures of an iso-surface is to render the entire geometry with transparent polygons. Parts of the iso-surface geometry which cover the same screen space are combined using standard (alpha-)blending mechanisms. The drawback of this approach is that the entire polygonal model becomes visible. This can produce a visually complex and difficult to interpret graphical output, if too many structures are shown behind each other. Moreover, it is necessary to sort the graphical primitives according to their screen space depth, so that the blending computations yield correct results. This usually leads to a significantly increased computational complexity of the rendering process.</p><p>Direct volume rendering, which is not based on precisely defined iso-surfaces, also makes the display of interior structures of an observed dataset possible. However, the necessary definition of a useful transfer function is not trivial <ref type="bibr" target="#b19">[20]</ref>. The images generated by direct volume rendering often show many parts of the volume dataset simultaneously, which can make viewing the structures of interest difficult for the user.</p><p>In this paper, we therefore propose a novel way of displaying hidden structures of an iso-surface. Our new algorithm utilizes illustrative rendering methods, which have become an important research area during the last years (see <ref type="bibr" target="#b27">[28]</ref>). We have designed the new method to achieve the following advantages:</p><p>• By using illustrative visualization methods, an easily understandable graphical output is generated. Our algorithm uses silhouette outlines and monochrome hatching for conveying the shape of objects.</p><p>• The inner structures of the iso-surface are automatically extracted during the rendering process. In our approach, the first occluded layer of the iso-surface behind the front layer is displayed as hidden geometry in a distinctive silhouettebased style. No preprocessing or manual definition of objects is required.</p><p>• As an optional addition, the geometry of special inner structures of high interest can be manually specified by the user. This "secondary geometry" always remains visible and is displayed in a special solid style with depth attenuation.</p><p>• The algorithm is capable of generating real-time frame rates for most datasets and typical image resolutions.</p><p>The design of our algorithm exploits the programmability of modern graphics processing units. A specialized rendering pipeline has been developed, which integrates application-specific object space and image space processing stages. Two geometry rendering passes generate the data for the first and second layer of the iso-surface. In an optional third pass, the information required for displaying the "secondary geometry" is gathered. Finally, an image-space processing step combines all the data collected in the previous steps for achieving the desired graphical output. Our implementation uses the OpenGL Shading Language (GLSL) <ref type="bibr" target="#b23">[24]</ref> and can deliver real-time frame rates in most cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>As mentioned above, non-photorealistic rendering has been in the focus of active research for several years. Overviews of nonphotorealistic and artistic techniques have been given by Gooch and Gooch <ref type="bibr" target="#b8">[9]</ref> and Strothotte and Schlechtweg <ref type="bibr" target="#b27">[28]</ref>. The motivation for using non-photorealistic and illustrative rendering in scientific visualization is to emphasize visual information over physical realism. This principle has been described as "functional realism" by Ferwerda <ref type="bibr" target="#b4">[5]</ref>.</p><p>A very important basic principle employed by many nonphotorealistic techniques is the generation and processing of intermediate image-space buffers containing geometric properties of the observed scene. Depth values and transformed normal vectors, which are computed for each image pixel, are frequently used geometric properties. This basic principle was introduced as G-buffers by Saito and Takahashi <ref type="bibr" target="#b24">[25]</ref>. The algorithm presented in our paper is also partly based on such intermediate image-space data. Decaudin has described a method for the cartoon-like rendering of 3D objects using depth and normals buffers <ref type="bibr" target="#b1">[2]</ref>. Mitchell et al. have presented a GPU-based technique for the extraction of object outlines based on image-space information <ref type="bibr" target="#b15">[16]</ref>. Nienhaus and Doellner use G-buffers to create different non-photorealistic styles <ref type="bibr" target="#b16">[17]</ref>. A framework for mapping G-buffer concepts to modern graphics processing units was described by Eißele et al. <ref type="bibr" target="#b3">[4]</ref>.</p><p>Several researchers have proposed to use colors for conveying the shape of objects or their material properties. Examples include the work of Gooch et al. on non-photorealistic lighting for automatic illustration <ref type="bibr" target="#b7">[8]</ref>, as well as Lum and Ma's watercolor inspired method for rendering surfaces <ref type="bibr" target="#b14">[15]</ref>. Our new approach uses discrete, user-defined colors in order to distinguish the front layer of the iso-surface from the second layer and for highlighting the "secondary geometry".</p><p>Monochrome hatching and halftoning are often used in nonphotorealistic rendering. These methods map a continuous range of intensities to monochrome representations based on regular patterns or artistic drawing styles. Interrante et al. have discussed the use of a texture containing discrete strokes for conveying the shape of an iso-surface <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. Hertzmann and Zorin have described methods for the line-art rendering of smooth surfaces <ref type="bibr" target="#b9">[10]</ref>. Praun et al. have proposed tonal art maps as a primitive for generating an artistic monochrome hatching for 3D objects <ref type="bibr" target="#b20">[21]</ref>. An automatic generation of tonal art maps based on arbitrary input textures has been developed by Fung and Veryovka <ref type="bibr" target="#b6">[7]</ref>. The utilization of configurable and programmable graphics hardware for real-time hatching and halftoning has been addressed by several researchers <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b31">32]</ref>. Secord et al. have presented a method for the high-quality distribution of monochrome drawing primitives based on a probability density function derived from an input image <ref type="bibr" target="#b26">[27]</ref>. An application of hatching styles to 3D scans of real world enviroments was developed by Xu and Chen <ref type="bibr" target="#b32">[33]</ref>. Strothotte and Schlechtweg describe a method for procedural halftoning, which is used by the algorithm presented in this paper <ref type="bibr" target="#b27">[28]</ref>.</p><p>Some researchers have addressed the problem of visualizing hidden components of a graphical model. Nooruddin and Turk have described a preprocessing method for classifying interior and exterior parts of a polygonal dataset <ref type="bibr" target="#b18">[19]</ref>. Diepstraten et al. have presented an algorithm for displaying hidden structures in technical illustrations using transparency <ref type="bibr" target="#b2">[3]</ref>. An algorithm for the illustrative display of polygonal models using depth peeling has been described by Nienhaus and Döllner <ref type="bibr" target="#b17">[18]</ref>. However, their method extracts consecutive layers of geometry for the entire model, again introducing a certain degree of visual complexity. Moreover, their algorithm typically delivers less than interactive frame rates, whereas our new method can generate images in real-time for most datasets.</p><p>Non-photorealism has also been applied to direct volume rendering in order to emphasize structures of interest. Rheingans and Ebert have proposed the volume illustration approach for enhancing important features in a volume dataset <ref type="bibr" target="#b22">[23]</ref>. A technique that uses stippling for the visualization of volume data has been presented by Lu et al. <ref type="bibr" target="#b13">[14]</ref>. Viola et al. describe an automatic method for cutting away irrelevant parts of a volume which occlude significant structures <ref type="bibr" target="#b29">[30]</ref>. A method for the real-time generation of line drawings from volume data has recently been presented by Burns et al. <ref type="bibr" target="#b0">[1]</ref>.</p><p>The display of anatomical datasets is one of the most important applications for both direct and indirect volume rendering. An overview of techniques for non-photorealistic medical visualization is given by Preim et al. <ref type="bibr" target="#b21">[22]</ref>. Tietjen et al. have presented a combination of different rendering techniques for different parts of a patient dataset <ref type="bibr" target="#b28">[29]</ref>. Salah et al. have proposed a technique based on point-based silhouettes and halftoning for a comprehensible display of segmented anatomical data <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESCRIPTION OF THE ALGORITHM</head><p>Our new illustrative rendering algorithm consists of a pipeline of geometry drawing passes followed by an image-space processing step. At first, the polygonal geometry of the iso-surface is rendered twice in order to extract the first and second layers of the model. Subsequently, the optional secondary geometry is rendered, if it has been defined by the user. Finally, an image processing shader combines all data collected in the previous stages to achieve the desired illustrative output. This is the main step of our method. In the following, we denote the set of polygons comprising the iso-surface as P and the secondary geometry as S.  <ref type="figure" target="#fig_0">Figure 2</ref> shows an overview of our method. After each of the geometry rendering passes, generated image-space data like fragment depth, normal vectors, and computed intensity are gathered. Note that the second and third rendering step take information from previous passes into account for their own computations. This is necessary because the fragment depths of the polygons drawn by the preceding stages are required for correctly rendering the geometry data in subsequent passes.</p><p>In the remainder of this section, the two primary rendering passes (Sec. 3.1) and the step for the optional secondary geometry (Sec. 3.2) are described. Finally, the central image processing stage is discussed in detail in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Iso-Surface Rendering Passes</head><p>In the first pass of the algorithm, the polygons P of the iso-surface are rendered. The standard Z-Buffer test is applied, so that the final image contains the front layer of the iso-surface geometry. For the generation of the image, a special shader is used, which computes the interpolated and normalized normal vectors for each pixel instead of color values. The depth values depth P 1 and normal vectors normal P 1 are the image-space output of this pass and can be accessed by the following steps of the algorithm. <ref type="figure" target="#fig_2">Figure 3</ref> shows the output generated by the first rendering pass for a view of the Engine dataset.  In the next step of the rendering pipeline, the iso-surface polyons P are drawn once again. This time, we want to generate the image that results from removing the first layer of the geometry. The depth information from the first pass is used to achieve this effect using a technique called depth peeling <ref type="bibr" target="#b17">[18]</ref>. Each fragment rasterized in this rendering step has to pass two depth tests. In the first test, the depth of the currently regarded polygon fragment is compared to the depth of the first-pass geometry at the same location. The new fragment has to be at a greater depth than the value stored in depth P 1 , otherwise it is culled. The result of this test is that the first layer of the iso-surface geometry is suppressed, or "peeled away". Subsequently, each fragment has to pass the standard Z-Buffer test so that a coherent second-layer image is generated. This process is illustrated in the following piece of pseudocode: for all polygons p ∈ P do F := rasterize p; for all fragments f ∈ F do /* depth peeling test */ if ( f .depth &lt;= depth P 1 ( f .x, f .y)) then continue; endif /* standard Z-Buffer test */ if ( f .depth &gt; depth P 2 ( f .x, f .y)) then continue; endif depth P 2 ( f .x, f .y) := f .depth; normal P 2 ( f .x, f .y) := f .normal; done done</p><p>Only fragments which pass both tests contribute to the imagespace output of the second rendering stage. The diagram in <ref type="figure" target="#fig_3">Figure 4</ref> demonstrates the depth peeling technique. As shown here, the second rendering pass yields the first layer of geometry behind the directly visible polyons.</p><p>The output of the second rendering pass again consists of depth and normal information, depth P 2 and normal P 2 . <ref type="figure" target="#fig_4">Figure 5</ref> depicts the data computed for the second layer of the Engine volume dataset.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Optional Rendering of Secondary Geometry</head><p>If a polygonal dataset containing secondary geometry has been specified by the user, the optional third geometry rendering pass is performed. In contrast to the two iso-surface rendering steps, this pass generates an intensity texture. The computed intensities are later used by the image processing stage as brightness values for the secondary geometry pixels. All polygons in S are rasterized. Initially, the intensity of each fragment is calculated using diffuse reflection:</p><formula xml:id="formula_0">I 0 S (x, y) = max(normal S (x, y) • lightDir, 0)<label>(1)</label></formula><p>As shown in Equation 1, the initial intensity value I 0 S is the result of the dot product of the normal vector of the fragment, normal S (x, y), and the user-defined light direction lightDir. A special depth attenuation scheme is then applied to the fragment intensities. The aim of this process is to make the depth relationships in the generated image better understandable. Although the secondary geometry is supposed to remain always visible, we want the user to be able to comprehend its distance relative to iso-surface structures. Therefore, the fragment depth of the secondary geometry is compared to the depth values retrieved from the first two rendering passes.</p><formula xml:id="formula_1">I S (x, y) = I 0 S (x, y) • ⎧ ⎪ ⎨ ⎪ ⎩ 1, depth S (x,y) &lt; depth P 1 (x,y) α, depth P 1 (x,y) ≤ depth S (x,y) &lt; depth P 2 (x,y) β , depth P 2 (x,y) ≤ depth S (x,y) with 0 &lt; β &lt; α &lt; 1<label>(2)</label></formula><p>The depth of the secondary geometry fragments is denoted as depth S in Equation 2. Depth values computed during the primary rendering passes are contained in depth P 1 and depth P 2 , as described in Section 3.1. The following rule determines the attenuation of the initial fragment intensity I 0 S : Secondary geometry fragments which are directly visible, i.e. not behind any iso-surface layer, retain their full intensity. Fragments which would be occluded by the front layer are attenuated with factor α, those which are also behind the second iso-surface layer with factor β . These factors have to be in the interval [0; 1] and are parameters of our algorithm. This depth attenuation method helps the user understand the spatial relationship between the secondary geometry and the isosurface. <ref type="figure" target="#fig_5">Figure 6</ref> illustrates this effect. In the central part of the image detail, the secondary geometry is shown with less intensity because here it is occluded by two iso-surface layers. The output of the optional third rendering step is the final intensity value I S , which is accessed by the image processing stage. Moreover, the depth of the secondary geometry fragments, depth S , is also stored for use by the final step of the rendering pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Image Processing Stage</head><p>All of the aforementioned geometry rendering passes generate images with the full resolution of the OpenGL output window. The size of this OpenGL viewport is determined by the user. In the final stage of our algorithm, all the previously generated data are combined using an image processing step. This step is performed by drawing a textured rectangle, which again has the same size as the OpenGL window. The intermediate images generated by the geometry rendering passes are used as input textures for a special shader program. In this shader, a number of image processing tasks are performed, which eventually yield the desired output rendering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Silhouette Detection</head><p>As mentioned above, the display of silhouettes is a central feature of our illustrative rendering method. Silhouettes are detected in image-space for both the first and the second layer of the isosurface. Our silhouette detection method is similar to the approach described by Mitchell et al. <ref type="bibr" target="#b15">[16]</ref>. Discontinuities in the depth and normal vector images are the basis for computing the response of the silhouette detection filter.</p><p>The gradient magnitude is computed for the depth maps of both iso-surface layers, depth P 1 and depth P 2 . In order to determine the gradient magnitude, partial derivatives</p><formula xml:id="formula_2">∂ depth Pn ∂ x and ∂ depth Pn ∂ y</formula><p>(n ∈ {1, 2}) are obtained using the Sobel edge detection filter. The norms of the resulting gradient vectors, |∇depth P 1 | and |∇depth P 2 |, indicate discontinuities in the depth images. We determine a binary response for the depth discontinuity filter based on a user-defined threshold, depthT hresh, as shown in Equation 3.</p><formula xml:id="formula_3">depthResp P n (x, y) = 0, |∇depth Pn |(x,y) &lt; depthT hresh 1, |∇depth Pn |(x,y) ≥ depthT hresh<label>(3)</label></formula><p>For finding discontinuities in the normal images, the normal vector stored in each pixel is compared to its four direct neighbours. This comparison is computed as a dot product between the corresponding vectors. As shown in Equation 4, the four resulting dot products are added up in order to obtain a normal vector similarity value normalSim P n . These computations are performed for both layers of the iso-surface, yielding normalSim P 1 and normalSim P 2 , respectively. A smaller normal similarity value indicates a significant discontinuity.</p><formula xml:id="formula_4">normalSim P n (x, y) = normal P n (x, y) • normal P n (x + 1, y)+ normal P n (x, y) • normal P n (x − 1, y)+ normal P n (x, y) • normal P n (x, y + 1)+ normal P n (x, y) • normal P n (x, y − 1) (4) normalResp P n (x, y) = 0, normalSim Pn (x,y) ≥ normalT hresh 1, normalSim Pn (x,y) &lt; normalT hresh<label>(5)</label></formula><p>A binary normal discontinuity response is computed by comparing the similarity value to a user-defined threshold (see Equation 5). The greater the threshold value normalT hresh is, the more pixels contribute to normal map silhouettes. Finally, an overall silhouette detection response is determined for each iso-surface layer. Depth as well as normal discontinuities are taken into account by calculating the logical OR of both response types, i.e. silhouette P n (x, y) = depthResp P n (x, y) ∨ normalResp P n (x, y). The output of the silhouette detection process for both layers of the Engine dataset is shown in <ref type="figure" target="#fig_7">Figure 7</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Procedural Halftoning</head><p>In our illustrative rendering style, the shape of the front layer of the iso-surface is not only represented with silhouettes. In order to make a better understanding of the geometry of the iso-surface possible, and to achieve a clear distinction between first-layer and second-layer structures, diffuse reflection intensities are added to the graphical output. The intensity of each first-layer fragment is computed as the dot product of a user-defined light direction and the stored normal vector. As shown in Equation 6, we again use the aforementioned light direction vector lightDir for this calculation.</p><formula xml:id="formula_5">I P 1 (x, y) = max(normal P 1 (x, y) • lightDir, 0)<label>(6)</label></formula><p>The main aim of our rendering algorithm is the display of hidden structures behind the first iso-surface layer. We therefore want to show the diffuse reflection intensities with a method which allows second-layer silhouettes to remain visible. A monochrome halftoning method is used for recreating a black-and-white crosshatching style found in technical illustrations. We utilize the procedural screening approach described by Strothotte and Schlechtweg <ref type="bibr" target="#b27">[28]</ref>, which does not require additional input textures for describing the hatching pattern.</p><p>The coordinates of each fragment which is to be dithered are first mapped to dither coordinates (s,t). This is done using a mapping function M:</p><formula xml:id="formula_6">(x , y ) = R θ • (x, y) (s,t) = M(x , y ) = x mod n n , y mod n n (7)</formula><p>In Equation 7, the screen-space coordinates of the currently regarded fragment are denoted as (x, y). These coordinates are first rotated by the angle θ , which is selected by the user. This is done by computing the product of the rotation matrix R θ ∈ ℜ 2x2 and the input coordinate vector. Due to this multiplication, the resulting halftoning pattern will be rotated relative to the screen-space coordinate axes. This creates a more natural look of the black-and-white hatching image. Subsequently, the rotated fragment coordinates are mapped to the real number range [0; 1] using the mapping function M. The dither coordinates (s,t) are the basis for determining whether the fragment is displayed as an opaque black pixel or as translucent. The choice of the user-defined variable n in Equation 7 determines the size in pixels of the hatching pattern.</p><formula xml:id="formula_7">τ(s,t) = c cross • t s ≤ c cross (1 − c cross )s + c cross s &gt; c cross (8) I hatching (x, y) = 0, I P 1 (x, y) &lt; τ(s,t) 1, I P 1 (x, y) ≥ τ(s,t)<label>(9)</label></formula><p>For each pixel, a halftoning threshold τ is computed as a function of the dither coordinates (s,t). The calculation of τ depends on the parameter c cross (see <ref type="bibr">Equation 8)</ref>. c cross determines the minimum intensity necessary for generating perpendicular crosshatching strokes in addition to the parallel strokes which are the basis for the halftoning pattern. As described in Equation 9, the diffuse reflection intensity I P 1 (x, y) is then compared to the local threshold τ(s,t). If the intensity is large enough, the output value I hatching (x, y) will be one, otherwise zero. The black-and-white pattern computed by this halftoning method for the intensity range [0; 1] is depicted in <ref type="figure" target="#fig_8">Figure 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Display of Secondary Geometry</head><p>In the final output image, the secondary geometry is displayed as a solid polygonal object with a special color. The brightness of secondary geometry fragments is determined by the intensity value I S (x, y), which has been computed in the optional third geometry rendering pass (see Section 3.2). Before the final color for each pixel in the output image is computed, a specific depth test is performed for the secondary geometry. In places where second-layer silhouette pixels have been detected, only such secondary geometry fragments are to be displayed which are in front of the second layer of the iso-surface.</p><formula xml:id="formula_8">I S (x, y) = I S (x, y) • 0, silhouette P 2 (x,y) ∧ (depth P 2 (x,y)≤depth S (x,y))</formula><p>1, otherwise <ref type="bibr" target="#b9">(10)</ref> Equation 10 shows the additional depth test for secondary geometry pixels, which yields the final intensity value I S . Due to this test, the depth relationships between second-layer silhouettes and the secondary geometry are correctly represented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Computation of Final Pixel Color</head><p>In order to generate the final output image, all the data computed for each pixel so far are combined. The image is initialized with a userdefined background color called paperColor. We typically use a bright background color to create the look of a technical illustration on paper. The second-layer silhouettes are then drawn over the background. They are displayed with the color backLayerColor in all places where silhouette P 2 indicates a silhouette fragment. Subsequently, the secondary geometry is blended over the background according to its computed intensity I S . The color of the secondary geometry is also selected by the user and stored in the variable secGeomColor. Finally, the front-layer of the iso-surface is taken into account. Every pixel which has a first-layer silhouette response of one or a hatching intensity of zero is displayed black. In this paper, we always use black for the first-layer geometry, but it could easily be replaced with any other color. The following piece of pseudocode summarizes the process of determining the final pixel color. This code uses a terminology similar to the functionality of modern shading languages. vec3 pixelColor; pixelColor = mix(paperColor,backLayerColor,silhouette P 2 (x, y)); pixelColor = mix(pixelColor,secGeomColor,I S (x, y)); pixelColor *= (1.0 -silhouette P 1 (x, y)); pixelColor *= I hatching (x, y);</p><p>In this pseudocode, the variable pixelColor is an RGB color vector, which will store the final output color of the pixel at position (x, y). In the code, the linear blend of two colors is computed by the function mix, i.e., mix(c 1 ,c 2 ,α)=(1 − α)c 1 + αc 2 . The black color of the first-layer geometry is generated by multiplying the components of pixelColor with a scalar value of zero, indicated by an *= operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION DETAILS</head><p>The capability for achieving real-time frame rates has been one of the main objectives of the design and the implementation of our algorithm. Our method has been realized with the OpenGL Shading Language <ref type="bibr" target="#b23">[24]</ref>, which was used to implement all of the aforementioned shader programs. The entire approach is executed on the graphics processing unit (GPU) and does not require any preprocessing on the CPU.</p><p>Each type of intermediate image-space information (e.g., depth P n , normal P n , depth S etc.) is stored in a separate texture image in onboard memory. The normal and intensity images are generated as the components of standard RGBA textures, while depth P n and depth S have a special depth texture format provided by OpenGL. In each geometry rendering pass, the intermediate data are written into the framebuffer. Subsequently, they are copied into texture images which are accessed by later stages of the algorithm. This is done with the glCopyTexSubImage2D() 1 function.</p><p>In the final step of the algorithm, a rectangle covering the entire OpenGL window is drawn using the image processing shader. The image processing shader reads the intermediate data by accessing the corresponding texture images. In particular for the silhouette detection step, a large number of texture accesses is required. For each fragment, a neighborhood of five or nine texels has to be read for the normal and depth textures, respectively. In order to avoid a loss of performance due to the repeated calculation of texel addresses, we use a special precomputation scheme. This texel address precomputation method is similar to the one presented by Viola et al. <ref type="bibr" target="#b30">[31]</ref>.</p><p>One significant advantage of the design of our rendering pipeline (see <ref type="figure" target="#fig_0">Fig. 2</ref>) is the fact that all image processing tasks are performed in the same shader progam. This way, no redundant texture accesses are necessary. All the previously computed data relevant for the current pixel are loaded once from the intermediate textures and can be used for several computations. One example is the first-layer normal information, normal P 1 , which is needed for the silhouette detection and the calculation of the diffuse reflection intensity.</p><p>Many of the computations in our rendering pipeline use standard functions provided by the shading language. Examples include step(), which performs a boundary check, and mix(), which computes a linear blending of vectors. These functions are normally executed efficiently on the GPU. Due to the extensive use of these functions, our implementation requires almost no conditional branches and no loop statements on the GPU, which are notoriously slow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>We have tested the algorithm with a number of example datasets. Most of them are polygon meshes representing iso-surfaces generated from volume data. For some of the datasets, secondary geometry was created by extracting a second surface with a different isovalue. Example images rendered with our method are shown in <ref type="figure" target="#fig_0">Figures 1, 11 and 12</ref>. The Engine dataset <ref type="figure">(Fig. 1(a)</ref>) is a CT scan of two cylinders of an engine block. The result of a simulation of fuel injection into a combustion chamber is contained in the Fuel dataset ( <ref type="figure">Fig. 1(b)</ref>). In this case, high-intensity voxels are displayed as secondary geometry. The NegHip example <ref type="figure" target="#fig_0">(Fig. 12(a)</ref>) is a simulation of the spatial probability of the electrons in a protein molecule. It also contains secondary geometry extracted from high-intensity voxels. A scanned human colon is shown in the Colon example, and the Ventricle dataset is a scan of the ventricular system of a human brain <ref type="figure" target="#fig_0">(Fig. 12(b) and 12(c)</ref>). In addition to these iso-surfaces, we have also tested our algorithm with a manually created polygonal model. The Screwdriver dataset <ref type="figure" target="#fig_11">(Fig. 11)</ref> is the detailed mechanical design of an electric screwdriver, with some inner parts highlighted as secondary geometry.</p><p>The example images and the animations in the accompanying video show that our method can convey the shape of hidden structures of the iso-surface. This is also illustrated in <ref type="figure" target="#fig_9">Figure 9</ref>, which shows a detail of the colon dataset, where the shape of the back wall of the colon is suggested by second-layer silhouettes. In <ref type="figure">Figure</ref> 10, holes in the septum of the patient are visible in the Ventricle dataset. These are defects caused by a degenerative process, and are significant for medical diagnosis and treatment.  We have run a number of tests for measuring the frame rates achieved with our new method. These benchmarks were performed on a computer with a Pentium 4 processor running at 2.8 GHz using a graphics card with an NVidia GeForce FX 6600 GT chipset. Animation sequences with a length of at least 1000 frames were used to compute the average performance for each test run. <ref type="table" target="#tab_0">Table 1</ref> shows a comparison of frame rates measured with standard rendering and with our illustrative method for the Engine dataset. In <ref type="table" target="#tab_1">Table 2</ref>, rendering speeds achieved by our algorithm for the other five test datasets are listed. Benchmark runs were performed for different output resolutions. As illustrated in both benchmark tables, the performance of our method depends on two main factors. The first is the size of the iso-surface mesh. A large number of polygons slows down the image generation because of the multiple geometry rendering passes. Moreover, the frame rate is influenced strongly by the output resolution. A larger output window increases the size of the intermediate textures and the number of image processing operations, resulting in a reduced rendering speed. Still, our algorithm is capable of delivering real-time performance in most cases. Even for large datasets and image resolutions, frame rates of close to or above 20 fps have been measured.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We have presented a novel method for the illustrative rendering of iso-surfaces. Our algorithm utilizes depth peeling, silhouette extraction, and monochrome hatching and combines them in an efficient way in a single rendering pipeline. The generated images make a simultaneous inspection of the outer surface and inner structures possible. Due to the selected style of rendering, spatial relationships and the shape of hidden objects can easily be understood. One major advantage of our algorithm is the fact that no preprocessing of the input data is necessary. Any polygonal dataset can be loaded into the system and then be displayed in the new illustrative style. The depth peeling step automatically extracts the second-layer geometry. Since we always assume the second isosurface layer to contain the relevant hidden structures, difficulties can arise in the case of more complex datasets. If areas of interest are occluded by several layers of polygons, they have to be manually specified as secondary geometry in order to remain visible. However, the continual display of such secondary structures is integrated efficiently into our rendering pipeline.</p><p>Although the performance of our algorithm depends on the size of the displayed dataset and the image resolution, we have found it to achieve real-time frame rates in most cases. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Overview of our algorithm for the illustrative rendering of hidden iso-surface structures. Solid arrows indicate data that is fed into the geometry rendering passes, dotted arrows data for the image processing stage. P and S stand for the primary iso-surface and the secondary geometry, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) depth P 1 (b) normal P 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Image-space data generated for the first layer of the Engine dataset. The components of the normal vectors are represented as RGB-values inFig. 3(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Illustration of the depth peeling technique (adapted from<ref type="bibr" target="#b17">[18]</ref>). Thick black lines indicate polygons which are visible in the image generated by the respective rendering stage.(a) depth P 2 (b) normal P 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Image-space data generated for the second layer of the Engine dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Increasing attenuation of secondary geometry pixels which are behind one or two iso-surface layers, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a) silhouette P 1 (b) silhouette P 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Silhouette detection responses computed for the first and second layer of the Engine dataset iso-surface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Black-and-white pattern generated for the continuous intensity range [0; 1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Close-up of a section of the Colon dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>A significant detail in the Ventricle dataset displayed by our algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 :</head><label>11</label><figDesc>Detailed polygonal model of an electric screwdriver. Some inner parts are used as secondary geometry (see enlarged detail).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>(a ) Figure 12 :</head><label>)12</label><figDesc>NegHip dataset (b) Colon dataset (c) Ventricle dataset Example images generated with our illustrative rendering algorithm. (Parameters used for all images: α = 0.7, β = 0.21, normalT hresh = 3.98, depthT hresh = 0.001, θ = 20.0, n = 4.0, c cross = 0.9)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of frame rates for standard and illustrative rendering of the Engine dataset (311k vertices) at different resolutions.</figDesc><table><row><cell></cell><cell cols="3">1024x768 800x600 640x480</cell></row><row><cell>standard</cell><cell>96.01</cell><cell>99.05</cell><cell>100.85</cell></row><row><cell>illustrative</cell><cell>21.33</cell><cell>28.10</cell><cell>34.83</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Frame rates measured for the other five datasets.</figDesc><table><row><cell cols="5">Dataset #vertices 1024x768 800x600 640x480</cell></row><row><cell>Colon</cell><cell>1,076k</cell><cell>18.16</cell><cell>22.96</cell><cell>27.17</cell></row><row><cell>Screwdriver</cell><cell>487k</cell><cell>26.65</cell><cell>40.69</cell><cell>58.07</cell></row><row><cell>Ventricle</cell><cell>201k</cell><cell>31.00</cell><cell>45.94</cell><cell>61.98</cell></row><row><cell>NegHip</cell><cell>17k</cell><cell>30.96</cell><cell>50.41</cell><cell>76.78</cell></row><row><cell>Fuel</cell><cell>6.4k</cell><cell>32.29</cell><cell>52.30</cell><cell>81.49</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">An alternative to using glCopyTexSubImage2D() is the direct rendering of intermediate images into texture memory. We have implemented a modification of our algorithm with render-to-texture using the OpenGL framebuffer object extension (EXT framebuffer object). However, we have found the resulting performance gains to be only marginal, due to the relatively limited amount of image-space data which needs to be copied. The performance measurments in this paper are based on the original approach with explicit texture copying.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We would like to thankÁngel del Río for providing the iso-surface extraction software used for generating our example datasets from volume data. Most of the volume datasets used in our experiments were downloaded from the VolVis website (www.volvis.org). This work has been supported by project VIRTUE in the focus program on "Medical Navigation and Robotics" (SPP 1124) of the German Research Foundation (DFG).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Line Drawings from Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klawe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>De-Carlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Cartoon-Looking Rendering of 3D-Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Decaudin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996-06" />
		</imprint>
	</monogr>
	<note>Research Report 2919, INRIA</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Transparency in Interactive Technical Illustrations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diepstraten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurographics</title>
		<meeting>Eurographics</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The G2-Buffer Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eißele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Simulation and Visualization</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="287" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Three Varieties of Realism in Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Ferwerda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings SPIE Human Vision and Electronic Imaging</title>
		<meeting>SPIE Human Vision and Electronic Imaging</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="290" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-Time Halftoning: A Primitive for Non-Photorealistic Shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freudenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Masuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Strothotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rendering Techniques 2002: Proceedings of the 13th Eurographics Workshop on Rendering</title>
		<imprint>
			<date type="published" when="2002-06" />
			<biblScope unit="page" from="227" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pen-and-ink Textures for Real-Time Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veryovka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface</title>
		<meeting>Graphics Interface</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Non-Photorealistic Lighting Model For Automatic Technical Illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gooch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gooch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Non-Photorealistic Rendering. A K Peters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gooch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gooch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Illustrating Smooth Surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zorin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Conveying the 3D Shape of Smoothly Curving Transparent Surfaces via Texture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="98" to="117" />
			<date type="published" when="1997-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Conveying Shape with Texture: experimental investigations of texture&apos;s effects on shape categorization judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagh-Shenas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="483" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Marching Cubes: A High Resolution 3D Surface Construction Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIG-GRAPH</title>
		<meeting>ACM SIG-GRAPH</meeting>
		<imprint>
			<date type="published" when="1987-07" />
			<biblScope unit="page" from="163" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Non-Photorealistic Volume Rendering Using Stippling Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Non-Photorealistic Rendering Using Watercolor Inspired Textures and Illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth Pacific Conference on Computer Graphics and Applications</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page">322</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Real-Time Image Space Outlining for Non-Photorealistic Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 2002 Conference Abstracts and Applications</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">239</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Edge-Enhancement -An Algorithm for Real-Time Non-Photorealistic Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nienhaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Döllner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSCG</title>
		<meeting>WSCG</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="346" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Blueprints -Illustrating Architecture and Technical Parts using Hardware-Accelerated Non-Photorealistic Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nienhaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Döllner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface</title>
		<meeting>Graphics Interface</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interior/Exterior Classification of Polygonal Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Nooruddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Turk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="415" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Transfer Function Bake-off</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="16" to="22" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Real-Time Hatching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Praun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page">581</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Focussing and Emphasis in Medical Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tietjen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doerge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Npr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Simulation und Visualisierung</title>
		<meeting>Simulation und Visualisierung</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Volume Illustration: Nonphotorealistic Rendering of Volume Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="264" />
			<date type="published" when="2001-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">OpenGL Shading Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Rost</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Addison-Wesley Publishing Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Comprehensible Rendering of 3-D Shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Takahashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGGRAPH</title>
		<meeting>ACM SIGGRAPH</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Illustrative Rendering of Segmented Anatomical Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Salah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Straßer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Simulation und Visualisierung</title>
		<meeting>Simulation und Visualisierung</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fast Primitive Distribution for Illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Secord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Streit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurographics Workshop on Rendering</title>
		<meeting>Eurographics Workshop on Rendering</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Non-Photorealistic Computer Graphics -Modelling, Rendering, and Animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Strothotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schlechtweg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Morgan Kaufmann Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Combining Silhouettes, Surface, and Volume Rendering for Surgery Education and Planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tietjen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Preim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE/Eurographics Symposium on Visualization</title>
		<meeting>IEEE/Eurographics Symposium on Visualization</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Importance-Driven Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="139" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hardware-Based Nonlinear Filtering and Segmentation using High-Level Shading Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="309" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fine Tone Control in Hardware Hatching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Praun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International Symposium on Non Photorealistic Rendering</title>
		<imprint>
			<date type="published" when="2002-06" />
			<biblScope unit="page" from="53" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Stylized Rendering of 3D Scanned Real World Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Symposium on Non-photorealistic Animation and Rendering</title>
		<meeting>the 3rd International Symposium on Non-photorealistic Animation and Rendering</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="34" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
