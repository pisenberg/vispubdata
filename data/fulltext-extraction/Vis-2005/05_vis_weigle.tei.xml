<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualizing intersecting surfaces with nested-surface techniques</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Weigle</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><forename type="middle">M</forename><surname>Taylor</surname><genName>II</genName></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Visualizing intersecting surfaces with nested-surface techniques</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>perception</term>
					<term>user study</term>
					<term>transparent surfaces</term>
					<term>nested surfaces</term>
					<term>intersecting surfaces</term>
					<term>two-surface visualization</term>
					<term>scientific visualization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper describes the adaptation and evaluation of existing nestedsurface visualization techniques for the problem of displaying intersecting surfaces. For this work, we collaborated with a neurosurgeon who is comparing multiple tumor segmentations with the goal of increasing the segmentation accuracy and reliability. A second collaborator, a physicist, aims to validate geometric models of specimens against atomic-force microscope images of actual specimens. These collaborators are interested in comparing both surface shape and inter-surface distances. Many commonly employed techniques for visually comparing multiple surfaces (side-by-side, wireframe, colormaps, uniform translucence) do not simultaneously convey inter-surface distance and the shapes of two or more surfaces. This paper describes a simple geometric partitioning of intersecting surfaces that enables the application of existing nested-surface techniques, such as texturemodulated translucent rendering of exteriors, to a broader range of visualization problems. Three user studies investigate the performance of existing techniques and a new shadow-casting glyph technique. The results of the first user study show that texture glyphs on partitioned, intersecting surfaces can convey inter-surface distance better than directly mapping distance to a red-gray-blue color scale on a single surface. The results of the second study show similar results for conveying local surface orientation. The results of the third user study show that adding cast shadows to texture glyphs can increase the understanding of inter-surface distance in static images, but can be overpowered by the shape cues from a simple rocking motion.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The surfaces of real-world objects almost never intersect, and the human visual system seems ill-prepared to deal with this rare case. However, the comparison of two similar models or approximations of the same surface can require simultaneous global estimation of each individual shape and local comparisons between the two surfaces. This paper presents visualization techniques designed for two users, a physicist and a neurosurgeon, who have these simultaneous goals. This paper also presents performance evaluation of the techniques, with tasks designed around the users' goals.</p><p>Michael Falvo, a physicist, compares real atomic-force microscope (AFM) scans with simulations. His goal is to validate geometric models of the specimen's structure. An AFM collects 2D height data by scanning a sharp tip across the surface of the specimen, effectively computing a dilation of the true specimen. A simulated AFM performs a similar dilation of a model specimen by a model tip. Understanding the differences between the real and simulated scans can help determine what changes need to be made to the specimen model. For instance, if peak heights are not significantly different between the two surfaces but the slopes are different, the most likely explanation is that the tip model is the wrong shape.</p><p>Elizabeth Bullitt, a neurosurgeon, investigates methods for automatic image segmentation of tumors from magnetic-resonance imaging (MRI). Her goal is to produce image segmentation algorithms at least as accurate and reliable as expert humans, so that other surgeons will trust the segmentations for treatment planning. Understanding the differences between automatic segmentations and radiologist segmentations can help determine how to tune the automatic algorithms. For instance, if the automatically-generated surface consistently overestimates the height and depth of similar small protrusions and divots compared to the expert, it is likely that the parameters controlling the contribution of small-scale features in the data are too large.</p><p>We are particularly interested in visualization techniques that enable scientists to perform multiple comparisons between surfaces, where the comparisons are intimately related to their research questions. A common difficulty in introducing new visualization techniques to a scientist's workflow is convincing the scientist to invest the time in learning the new technique. Typically, the scientist has already grown accustomed to some display method and is reluctant to accept that an unfamiliar technique will yield better or faster understanding of data. Therefore, we undertook user studies to indicate how well a given visualization conveys the metrics in which they are interested. As discussed previously, our collaborators want to understand shape and inter-surface distance. For this reason, the first two studies involve tasks to evaluate how well the intersectingsurface visualization techniques convey both.</p><p>Many techniques for nested surfaces solve the occlusion problem by displaying the outer layers with texture-modulated translucency <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b27">28]</ref>. This allows regions of the inner surfaces to be seen through regions of the outer surfaces. Intersecting surfaces pose a more difficult problem because no one intersecting surface can be said to inside or outside the others. This paper describes a simple partitioning of the surface geometries at the intersections that enables the application of existing nested-surface techniques to intersecting surfaces. The first two user studies evaluate a simple but effective intersecting surface visualization technique in the mold of Interrante's curvature-directed strokes <ref type="bibr" target="#b14">[15]</ref> and find that it conveys inter-surface distance and local shape better than directly mapping inter-surface distance to a red-gray-blue color scale on a single surface. A third user study evaluates the effectiveness of cast shadows at enhancing the perception of inter-surface distance and find that although it is effective in static images, it is overpowered and made superfluous by simple animation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>The following two sections discuss previous work in perception and visualization that relate to the display of intersecting surfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Displaying a Single Surface</head><p>Much work in visual perception has explored the perception of shape from shading <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b26">27]</ref>. Specifically, the human visual system interprets shape with a built-in bias toward scenes that are diffusely lit from overhead <ref type="bibr" target="#b11">[12]</ref>, though sufficient cues from IEEE Visualization 2005 October 23-28, Minneapolis, MN, USA 0-7803-9462-3/05/$20.00 ©2005 IEEE.</p><p>other perceptual channels can influence this bias. Perception research suggests a variety of other visual cues that also elicit the perception of shape, such as texture <ref type="bibr" target="#b5">[6]</ref>, specular highlights <ref type="bibr" target="#b0">[1]</ref>, shadows <ref type="bibr" target="#b9">[10]</ref>, and object boundaries <ref type="bibr" target="#b26">[27]</ref>.</p><p>The most common illumination model used in computer graphics, the empirical Phong lighting model, may convey shape cues in a manner similar to certain real objects under natural illumination. The Phong lighting model approximates diffuse and specular lighting according to Lambert's cosine law and Fresnel's laws of reflection, respectively <ref type="bibr" target="#b25">[26]</ref>. Under the appropriate conditions, Phong illumination has been shown to convey shape and depth <ref type="bibr" target="#b15">[16]</ref>.</p><p>Research into the perception of attached shadows finds they are perceived similarly to occlusion contours <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24]</ref>. Most significantly, attached shadow boundaries reveal the global structure of surfaces, providing evidence of the presence of bumps, dimples, and other features. Cavanagh and Leclerc report that cast shadows help disambiguate light direction and help place objects in space, but do not appear to strongly suggest shape <ref type="bibr" target="#b2">[3]</ref>. Mamassian et al. report that even when available visual information suggests otherwise, shadows in motion are interpreted as if the light source were fixed <ref type="bibr" target="#b22">[23]</ref>. Other assumptions and biases can be overridden by shadow motion as well, such as constant object size, linear object motion, and assumed viewpoint.</p><p>Texture has long been known to be an excellent shape cue. Gibson shows that the slant of a textured plane extending to the horizon could be perceived, though typically underestimated <ref type="bibr" target="#b11">[12]</ref>. Here Gibson uses slant to refer to the degree of rotation the surface out of the image plane toward the horizon. Cumming et al. describe the three shape cues due to apparent variation in texture on a uniformly textured surface: compression -due to surface orientation relative to the image plane, density -due to distance and obliqueness of view, and perspective -due to distance from the view point <ref type="bibr" target="#b4">[5]</ref>. Of these, texture compression has been shown to be the most significant for surface shape perception under stereo viewing.</p><p>A number of studies have found that certain directional components of surface texture seem to enable better shape and depth perception than some other directions <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b29">30]</ref>. Li and Zaidi find that (sinusoidal) surface shape is best perceived when noiselike textures project significant energy along the first principal curvature direction <ref type="bibr" target="#b21">[22]</ref>, which is the direction of highest local curvature. Interrante et al. found that brush strokes laid along the first principal curvature direction, through well spaced points on the surface, also convey surface shape <ref type="bibr" target="#b14">[15]</ref>. Some cautions against using first principal curvature alone have been put forth <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b29">30]</ref> concerning the poor shape cues present in principal-direction textures under non-generic views where the view direction follows the curvature direction. Viewing a ridge transversely is one such non-generic view. However, using both principal curvature directions can convey shape better than either one alone <ref type="bibr" target="#b16">[17]</ref>, and additional nonprincipal directions can further improve the recognition of some shapes <ref type="bibr" target="#b17">[18]</ref>. Because the two principal directions are orthogonal, textures using both directions address concerns about non-generic views. We adopt Interrante's curvature-directed strokes by replacing unidirectional strokes with curvature glyphs that indicate both curvature directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Displaying Nested Surfaces</head><p>Techniques have been specifically developed to enable the visualization of nested surfaces <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b27">28]</ref>. These non-photorealistic techniques attempt to remove regions of the exterior surface geometry that occlude the interior surfaces.</p><p>Diepstraten et al. describe a technique for view-dependent transparency, which aims to automatically produce translucent surfaces similar to technical illustrations <ref type="bibr" target="#b7">[8]</ref>. In a later work, Diepstraten et al. describe techniques for automatically producing breakaway and cutaway illustrations of nested surfaces <ref type="bibr" target="#b8">[9]</ref>. These illustrations remove regions of geometry that occlude the interior surfaces as opposed to rendering those regions as a translucent material.</p><p>Some successful techniques render an opaque interior surface surrounded by textured, translucent exterior surfaces <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b27">28]</ref>. The texture patterns modulate local translucency, providing better illumination and texture cues to enhance exterior surface shape perception as compared to uniform translucency. Interrante places first principal curvature direction strokes along outer surfaces <ref type="bibr" target="#b14">[15]</ref>. Rheingans retiled surfaces so that uniform circle or hexagon textures could be applied around vertices <ref type="bibr" target="#b27">[28]</ref>. Interrante provides an excellent summary of relevant perceptual issues for using translucency in visualizations <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DISPLAYING INTERSECTING SURFACES</head><p>We present a geometric refactoring that enables the use of existing and new techniques for nested-surface display on pairs of surfaces that have multiple intersections. For a pair of nested surfaces, the exterior surface always occludes the interior surface. An algorithm for ameliorating the nested-surface occlusion problem need treat only the exterior surface. For a pair of intersecting surfaces, the surfaces swap interior/exterior roles at each intersection curve. For most interesting surfaces, each surface occludes the other in different regions of a single view. The basic approach to ameliorating the intersecting-surface occlusion problem is to refactor the two intersecting surfaces into an interior, nested surface and an exterior, surrounding surface. Considering two closed, intersecting surfaces A and B enclosing the respective, overlapping volume regions A and B, the boundary of volume A ∩ B is the desired interior surface and the boundary of volume A ∪ B is the desired exterior surface.</p><p>To more generally apply nested-surface techniques to intersecting surfaces, including open surface patches, an interior/exterior classification must be made. This is naturally accomplished by partitioning the surfaces at their intersection curves. Classifying partitioned surface regions as interior or exterior can be accomplished in many ways. Geometric algorithms provide methods to precompute the classification for a fixed scene. Image-based algorithms provide solutions which require no precomputation and can handle scene changes interactively (as long as the view-dependent depth complexity remains sufficiently low). A variety of image-based techniques exist that can perform such a classification <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25]</ref> and can do so on the graphics processor.</p><p>Once partitioned and classified, we render the surface regions with different shape perception cues as per nested-surface techniques. The perceptual cues should convey interior/exterior classification and source data set for each region. This has also been independently suggested by Robinson and Robbins <ref type="bibr" target="#b28">[29]</ref>. The following discussion of the first two user studies includes a description of our chosen perceptual cues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT 1</head><p>This section describes the first intersecting-surface perception experiment, consisting of two of our three user studies. The two studies evaluated the relative effectiveness of color mapping versus curvature glyphs for comparing inter-surface distance and for local shape estimation. The studies were run simultaneously using the same trial data and visualization conditions but requiring participants to perform different tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>The surfaces generated for the user study were limited to height fields. The geometry for all surfaces was computed on a 100x100 grid. Inter-surface distances were computed at ten times that resolution. Each surface was constructed from eight Gaussian bumps. The bumps have random centers, maxima, and sigmas, and may overlap. Noise is also included in each surface; the noise is significantly smaller in scale than the bumps. <ref type="figure" target="#fig_0">Figure 1</ref> shows several examples. Although this set of surfaces does not at first appear representative of real-world data, it should be noted that typical shape features are present (bumps, saddles, ridges, valleys, etc).</p><p>Limiting the investigation to height fields is not uncommon when studying surface shape. For our study, this greatly simplifies the demands on the participants and allows renderings to be precomputed. The inclusion of closed surfaces in our evaluation of the perceptual effects of shadows would require participants to have interactive control of the light source or the objects (or both). If surfaces were closed, some glyph elements on the exterior might cast shadows that never fall on the interior surface.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Viewing Parameters</head><p>Surfaces are pre-rendered from a vantage point 45 degrees above the plane of the grid (rotation about the horizontal axis). The initial renderings are over-sampled, filtered, and re-sampled at the final display resolution (750x750 pixels) to reduce aliasing artifacts. Participants were seated such that the distance from eye to monitor was approximately 53 cm. At the center of view, the surfaces extend horizontally just beyond the viewport. The viewport is 22 cm square and subtends 24 degrees visual angle. These view parameters display the surfaces such that the grid units of the surface geometry are approximately 2.5 mm.</p><p>Illumination is from an infinite point source with a direction vector</p><formula xml:id="formula_0">( 2 3 , 1 3 , 2</formula><p>3 ), effectively over the viewer's right shoulder. Per-pixel Phong illumination is employed.</p><p>When surfaces are first presented, they rock five degrees to either side of center around the vertical axis. The motion is that of a torsion pendulum with a period of two seconds, slowing to rest before changing direction. The apparent light source remains fixed. Participants may also repeat the rocking animation as they desire during trials. The inclusion of surface rocking turned out to be a critical decision which weighed heavily on the results of the first two user studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Tasks</head><p>The shape tasks included in the user studies were chosen in consultation with our collaborators. We had three goals in selecting tasks for the evaluation:</p><p>1. to satisfy the scientists that the study tasks related to their research questions, 2. to use shape tasks commonly employed in the literature (adapted as necessary for two simultaneous surfaces), 3. and to facilitate fast, simple judgments from the participants.</p><p>Because our collaborators are interested in inter-surface distance and shape, the tasks performed in the first experiment ask participants to estimate inter-surface distance and to compare local surface orientations. Typically, either task would be considered sufficient to evaluate shape perception of a visualization technique <ref type="bibr" target="#b0">1</ref> . We evaluated performance for both tasks to directly address our collaborators concerns.</p><p>Because displays represent two surfaces, the metrics estimated should involve both surfaces. Inter-surface distance readily satisfied this constraint. To make estimating local surface orientation involve both surfaces, participants were asked to estimate the difference in orientation between the two surfaces. Instead of asking participants to manipulate some measurement widget once for each of the two surfaces represented by the display (like the orientation probe developed by Koenderink and van Doorn <ref type="bibr" target="#b19">[20]</ref>), we used forced choice between two labeled regions. Because one of the visualization conditions included in the studies renders only one surface, forced choice also avoids the problem of indicating where on the invisible surface the participant should estimate orientation. For inter-surface distance, participants would indicate which of the two regions contained the closest approach between the two surfaces. For local orientation, participants would indicate which of the two regions had the smallest orientation difference between the two surfaces (in other words, in which region were the two surfaces most parallel to each other). Regions were labeled by overlaying unfilled circles with a radius of 15 pixels, one in solid cyan and the other in dashed yellow. The labels were hidden during the rocking animation, and could also be temporarily hidden by participants. With these tasks, participants could perform many trials in a relatively short amount of time (compared to manipulating widgets). However, these tasks yield only binary responses instead of metric errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Conditions: Visualization Techniques</head><p>The following sections describe the three visualization conditions included in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Color mapping</head><p>The first condition displays the geometry of one of the two intersecting surfaces. That surface's color is mapped to the signed shortest distance between the two intersecting surfaces <ref type="figure" target="#fig_1">(Figure 2</ref>). A double-ended saturation scale, blue through gray to red, classifies inside, touching, and outside (hue) while also encoding distance (saturation). This scale is suggested by Ware as a possible scale for conveying ratio data, though Ware also notes that conveying ratio data in color is "a tall order" <ref type="bibr" target="#b32">[33]</ref>. Additionally, a regular-grid texture appears on the surfaces for stronger shape cues. The color scale is normalized, so the maximum inter-surface difference maps to the appropriate end of the scale. This maximizes the available perceptual precision in the saturation scale and would be expected practice if such a scale were applied to real data.</p><p>Color mapping is a frequently-used visualization technique for conveying scalar parameters on surfaces -a task for which it is well suited when used appropriately <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32]</ref>. Applying a color scale to a surface can be quite effective for classification or metric estimation, but is not a good perceptual technique for carrying alternate shape information. A color mapping technique is a typically employed approach for comparing two surfaces. It should be noted that color is not included as a recommendable solution, but to form a baseline for performance. Though it conveys no perceptual shape information about one of the surfaces, the color scale directly encodes one of the task metrics (inter-surface distance), and the gradient of the color scale encodes the other (the larger the local color gradient, the larger the local difference in orientation between the two surfaces).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Curvature glyphs</head><p>The second visualization condition is an adaptation of existing nested surface techniques. It is based on Interrante's curvaturedirected strokes <ref type="bibr" target="#b14">[15]</ref>. The technique employs texture glyphs which conform to both principal curvature directions and modulate translucency as suggested by Kim et al. <ref type="bibr" target="#b16">[17]</ref>  <ref type="figure">(Figure 3)</ref>. The glyph is a simple elongated plus -the long axis indicates an estimate of the first principal curvature direction at the glyph center. Recall that the data includes noise, so principal directions are defined everywhere on the surfaces -though one could replace the anisotropic glyph with an isotropic glyph in regions where the prin- <ref type="figure">Figure 3</ref>: This is an example of the curvature glyph condition. The two surfaces on top are used to produce the visualization on the bottom, and appear in the same colors. Regions of the surfaces labeled interior appear colored by the exterior, but are rendered as a neutral gray material with a regular-grid texture. Regions of the surfaces labeled exterior appear as principal-curvature glyphs textured onto a translucent surface.</p><p>cipal directions actually were undefined.</p><p>Red and blue are used to denote ownership of the exterior surface regions. Red regions belong to surface A, and blue regions belong to surface B. Though the apparent color is modified by the translucent exterior regions, the interior regions are rendered as a light gray material. We chose light gray to minimize differences between this condition and the next, where we felt it important that the interior coloring provide better contrast than the red and blue color coding would. The interior is also textured with a regular grid to enhance shape perception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Shadow-casting curvature glyphs</head><p>The third visualization condition adds cast shadows to the curvature glyphs <ref type="figure">(Figure 4</ref>). Again, red and blue denote ownership of the exterior regions of the two surfaces, while the interior is a light gray material colored by the translucent exterior. Light gray provides better contrast for the cast shadows than would red or blue, helping the glyph shadows to stand out from the interior and to be perceptually separable from the glyphs. The interior is also textured with a regular grid to enhance shape perception. Recall that the light <ref type="figure">Figure 4</ref>: This is an example of the shadow-casting curvature glyph condition. The two surfaces on top are used to produce the visualization on the bottom, and appear in the same colors. Regions of the surfaces labeled interior appear colored by the exterior, but are rendered as a neutral gray material with a regular-grid texture. Regions of the surfaces labeled exterior appear as principal-curvature glyphs textured onto a translucent surface. All opaque surface elements cast shadows.</p><p>source is fixed, thus when the surfaces undergo the rocking motion, the shadows move appropriately. We expected the cast shadows to enhance the ability to perceive inter-surface distance because cast shadows have been reported to help fix the frame of reference between caster and receiver <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Training</head><p>Each session began with a short training exercise. Participants were introduced to each visualization condition and to the manner of marking regions for comparison. Participants were then shown 6 example trials, 2 for each visualization condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Questionnaire</head><p>As part of the first two user studies, participants completed a short questionnaire. The questionnaire consisted of two questions, one asking about clarity of display and the other about preference:</p><p>• On a scale of 1 to 9, how clearly did each display technique convey the information you needed to complete the task?</p><p>• If you were to perform this task again using these display techniques, what would be your order of preference?</p><p>These are essentially both preference questions, though the second more explicitly so than the first. We expected responses to the two questions to be correlated, with the display scoring highest for clarity also being most preferred. We intended the clarity question to allow some flexibility in the participants' responses while the preference question would force a strict ordering (breaking ties in scoring for clarity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Evaluation</head><p>This section describes the tasks evaluated in the two user studies and analyzes the results of each.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.1">User Study 1: Inter-Surface Distance</head><p>Six undergraduate and graduate students performed the intersurface distance task. Each participant viewed 60 unique, random surface pairs per visualization condition, for a total of 180 trials. Participants estimated how closely the two surfaces approached each other within each indicated region and reported the region containing the closest approach (the smallest inter-surface distance). The region locations were precomputed. Regions were selected to guarantee that bumps were present in both surfaces (instead of the background noise) and that the intersections themselves were avoided. The regions were also selected such that differences in closest approach were uniformly distributed between 0 and 5.5 grid units (approximately 0 mm to 14 mm). Region locations were otherwise random. Trials were randomly ordered for each participant.</p><p>We expected the accuracy of participant responses to depend on the magnitude of the difference between the inter-surface distances and on the visualization condition. We expected participants would be able to compare inter-surface distance accurately with the color mapping condition, because it directly encodes the necessary information. We expected the cast shadows to enhance the perception of separation between surfaces, yielding better task performance than for the glyph condition without shadows.   ANOVA analysis finds significant main effects for the distance difference between marked regions (p &lt; .01), the visualization condition (p &lt; .001), the participant (p &lt; .001), and participant response time (p &lt; .001). <ref type="figure" target="#fig_3">Figure 5</ref> shows the overall accuracies and 95% confidence intervals by visualization condition; the figure also shows that the performance of the participants is better than chance. A Tukey's Honestly Separable Difference (HSD) test finds that the two glyph routines are separable from direct color mapping (a statistically significant difference was found, and a task performance ranking can be found), but are not separable from each other (the differences are not found to be statistically different).</p><p>Responses to the questionnaire show that the average participant found color mapping and glyphs with cast shadows to show intersurface distance with equal clarity and with greater clarity than glyphs alone. However, the average participant preferred glyphs with shadows over the other two techniques. This is an interesting result, as it shows the participants' judgment of the strength of the techniques does not match the study findings. The results did not show the expected improvement in perception due to cast shadows for the glyph technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.3">User Study 2: Local Orientation</head><p>Seven undergraduate and graduate students performed the local orientation task. None of the participants took part in User Study 1. Each participant viewed 180 trials, as in Experiment 1. Participants estimated the orientation of each surface within the regions and reported the region containing the smallest orientation difference (the smaller angle difference). The region locations were selected such that the angle differences were uniformly distributed between 0 and 45 degrees. The region locations were otherwise determined as before. Trials were randomly ordered for each participant.</p><p>We expected the accuracy of participant responses to depend on the angle difference between the two regions and on the visualization condition. We expected participants would be able to estimate orientation differences accurately in the color mapping condition by comparing color gradients in the marked regions. Because the distance between the two surfaces changes where the two surfaces have different orientations, the color changes there also. We expected cast shadows to enhance the perception of shape, especially on the interior surface. We expected the glyph techniques to enable better performance than the color mapping technique, because they present geometry of both surfaces.</p><p>One might question why color still represents inter-surface distance in this task. Mapping an estimate of the angle difference in orientation would seem more effective. However, our goal is to find a single visualization that can be used effectively for both tasks. Estimating the orientation difference from the color gradient seems much easier than estimating distances from angle information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.4">Results of User Study 2</head><p>ANOVA analysis finds significant main effects for the angle difference between marked regions (p &lt; .001), the visualization condition (p &lt; .01), the participant (p &lt; .01) and participant response time (p &lt; .01). <ref type="figure">Figure 6</ref> shows the overall accuracies and 95% confidence intervals by visualization condition; the figure also shows that the performance of participants is better than chance. A Tukey's HSD test finds that the two glyph routines are separable from direct color mapping, but are not separable from each other.</p><p>Responses to the questionnaire show that the average participant found glyphs with shadows marginally clearer than color, and either clearer than glyphs alone. No preference was reported between color or glyphs with shadows, but either were preferred over glyphs alone. As in the inter-surface distance task, participants' judgment  <ref type="figure">Figure 6</ref>: This figure shows the overall accuracies and their 95% confidence intervals for the local orientation task. Tukey's HSD test finds that the two glyph techniques are statistically different from the color mapping techniques, but not from each other.</p><p>of the strength of the techniques does not match the study findings. Also, the results did not show the expected improvement in perception due to cast shadows for the two glyph techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Discussion</head><p>The user study results show the glyph techniques enabled better comparison of both inter-surface distance and local shape than directly mapping distance to color. It should be noted that these results do not reveal the precision with which a single estimation of distance or orientation could be made, only that the relative magnitudes of each can be effectively compared. Although the accuracies for color mapping and glyphs are statistically significant, the glyph techniques may not provide meaningful improvement for the intersurface distance task, because participants were 89% accurate with color mapping and 95% and 97% accurate with glyphs. That the glyph techniques are better at all for inter-surface distance is important to note, because the color mapping visualization directly encodes that information while the glyph techniques present two shapes from which the distances must be inferred. Glyphs clearly enable better performance for the orientation task. The combination of statistically better performance for both tasks suggests that a glyph technique would be a better overall visualization for our collaborators.</p><p>An reasonable question is whether another color scale would have enabled better performance than the red-gray-blue scale. We believe that this is quite probable, and we would not be surprised if the best performing color scale enabled better metric estimation on these surfaces than the glyph techniques enable shape perception. However, no color scale will enable perception of the shape hidden surface. That the glyph techniques are comparable to some direct encoding of the shape metrics suggests that they are better techniques for exploratory visualization. Although a color-mapped surface can be used to encode shape metric information about the difference between two surfaces, it can not be said to convey the shape of two surfaces.</p><p>An interesting result of these experiments comes from the questionnaires. Subjective preference does not reflect objective performance. Participants expressed a preference for color mapping or glyphs with shadows over glyphs without shadows for both tasks, and a preference for color mapping over glyphs with shadows for the inter-surface distance task. Neither of these preferences can be supported by the performance results. In particular, it is interest-ing that participants preferred direct encoding of the metric to be estimated over a technique which enabled better task performance.</p><p>There are a number of possible reasons why adding cast shadows to the glyph technique does not have a measurable effect. One reason may be that shadows make no difference. Another reason may be a lack of statistical power -it may require many more participants to statistically differentiate the two conditions. A related reason may be that the techniques do not enable participants to perceive the estimated metrics with sufficient precision to find differences between them. We hypothesize that, in fact, the rocking animation reveals too much of the shape for the shadows to have any effect. The static images of the two glyph techniques certainly seem to suggest that shadows do have some effect, and they theoretically should help ground the location of the glyphs above the interior surfaces. We designed a second experiment to test the theory that allowing participants to rock the surfaces masked the benefits of cast shadows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENT 2</head><p>The second experiment consisted of one user study designed to test whether adding cast shadows to the glyph technique had any benefit and whether allowing limited animation (surface rocking) in the first experiment masked that benefit. The data sets from Experiment 1 were re-used for this experiment. The rendering and view parameters were also the same as Experiment 1. Training was similar to Experiment 1, except for the number of visualization conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Conditions</head><p>The glyph technique was the basis for all conditions in this experiment. We used a two-by-two factorial design for the display condition, with the presence of cast shadows and the availability of rocking as the two factors. When rocking was part of the condition, participants were allowed to initiate the torsion-pendulum animation at will, after its initial occurrence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Task</head><p>For this experiment we considered only the inter-surface distance task. It was presented in exactly the same manner as in Experiment 1 (with allowances for rocking). The range of difference between inter-surface distances was shortened to 0.5 grid units through 3 grid units (approximately 1mm through 8mm). The analysis of Experiment 1 found that at the short-distance end participants performed near chance and at the long-distance end participants made relatively few errors (this is true for the color mapping condition as well). Because this experiment involved four visualization conditions, this also helped control the number of responses required from each participant.</p><p>Including only one task deviates from our previous decision to accommodate our collaborators and perform two shape perception evaluations. The inter-surface distance task is the one for which we expected glyphs to realize the most benefit from cast shadows. It was also more expedient to run only the one study in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">User Study 3: Rocking versus Shadows</head><p>Seven undergraduate and graduate students performed the intersurface distance task. Two participants also took part in User Study 2. Each participant viewed 132 trials. Other aspects of each session were as in Experiment 1.</p><p>We expected shadows without rocking to enable better task performance than glyphs with no shadows and no rocking. We expected rocking to provide more benefit than shadows, thus explaining why Experiment 1 showed no benefit for shadows.  <ref type="figure">Figure 7</ref>: This figure shows the overall accuracies and their 95% confidence intervals for the inter-surface distance task while comparing the effects of rocking and shadows applied to the glyph technique. Tukey's HSD test finds that introducing shadows or rocking to the glyph technique conveys inter-surface shape better the glyphs alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>Two-way ANOVA analysis finds significant main effects for rocking in the visualization condition (p &lt; .001) and the participant response time (p &lt; .01). Rocking can be said to have an overall impact on task performance, but the same can not be said for shadows. A significant interaction effect was also found between shadows and rocking (p &lt; .001). The interaction can not be interpreted without a post hoc test. <ref type="figure">Figure 7</ref> shows the overall accuracies and 95% confidence intervals by visualization condition; the figure also shows that the performance of participants is better than chance. A Tukey's HSD test finds that:</p><p>• using any combination of rocking and shadows is separable from using neither,</p><p>• combining shadows and rocking is not separable from using either alone,</p><p>• and using only shadows is separable from using only rocking.</p><p>Given the post hoc Tukey's HSD test, it can be said that shadows provide a benefit in the absence of rocking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Discussion</head><p>Experiment 2 appears to support our claim that including a rocking animation in the first experiment masked any benefit shadows would have provided. Further, it can be said that adding shadows to the glyph technique is beneficial for comparing inter-surface distances in static images (like those intended for print publication). We can not say whether shadows are beneficial for interactive medium. However, if prioritizing between animation and shadows, animation should be added to the visualization first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SUMMARY</head><p>We have described a simple partitioning of intersecting surfaces that enables existing nested surface techniques to be applied to a new visualization problem. By partitioning geometry at the intersection curves, regions of the intersecting surfaces can be categorized into interior and exterior. The regions can then be displayed as nested surfaces.</p><p>A first user study showed that a curvature glyph technique can convey inter-surface distance better than a direct encoding of that distance into a color scale. A second user study showed that the glyph techniques conveyed local surface orientation better than the color mapping technique. Neither of the first two studies showed an advantage to combining cast shadows with the glyph technique. A third user study showed that the rocking animation included in the first two studies masked the benefits of cast shadows for the inter-surface distance task. We find that our collaborators would be better served by one of the glyph techniques than by directly mapping distance to color when they want to compare both shape and inter-surface distance in their data. Due to the necessity of hiding one surface, we believe that no color scale, applied as we have done, is capable of enabling the level of shape perception possible when displaying both surfaces in their intersecting configuration. We also find that a glyph technique should include cast shadows for publication (or similar static media) to better convey inter-surface distance.</p><p>Participants subjectively rated direct color mapping a better technique than the glyph technique without shadows, but objective performance evaluation did not match those ratings. One possible explanation for this incongruity is that participants preferred visualizations that could be interpreted quickly regardless of precision. This is especially likely in a user study setting where participants are asked to evaluate hundreds of trials. This finding is a reminder that user studies are a valuable tool for determining the relative task performance of visualization techniques on problems scientists care about.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Six examples of the random surfaces created for the user studies. Each surface is comprised of Gaussian bumps and noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>This is an example of the color mapping condition. The two surfaces on top are used to produce the visualization on the bottom. The top left image is used as geometry, and the top right image is used to compute the distances for the color scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>This figure shows the overall accuracies and their 95% confidence intervals for the inter-surface distance task. Tukey's HSD test finds that the two glyph techniques are statistically different from the color mapping techniques, but not from each other.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>4. 7 . 2</head><label>72</label><figDesc>Results of User Study 1</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Langer and Bülthoff list the most commonly used shape tasks and weigh their advantages and disadvantages<ref type="bibr" target="#b20">[21]</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGMENTS</head><p>The authors and Michael Falvo's collaboration were supported by NIH-NIBIB P41 EB002025-21 RS/RMT. Elizabeth Bullitt's collaboration was supported by R01 EB000219 NIH-NIBIB. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Does the brain know the physics of specular reflection?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bülthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">343</biblScope>
			<biblScope unit="page" from="165" to="168" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Implicit processing of shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Castiello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="2305" to="2309" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Journal of Experimental Psychology: Human Perception and Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cavanagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Leclerc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3" to="27" />
		</imprint>
	</monogr>
	<note>Shape from shadows</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Light source dependence in shape from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Christou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1441" to="1449" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Effects of different texture cues on curved surfaces viewed stereoscopically</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cumming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5/6</biblScope>
			<biblScope unit="page" from="827" to="838" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The effect of illuminant position on perceived curvature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Johnston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1399" to="1410" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shape from shaded random surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>De Haan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G F</forename><surname>Erens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Noest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="2985" to="3001" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transparency in interactive technical illustration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diepstraten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interactive cutaway illustrations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diepstraten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="523" to="532" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Perception of local shape from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Erens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kappers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Koenderink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception and Psychphysics</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="145" to="147" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Interactive order-independant transparency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Everitt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<pubPlace>Nvidia</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The perception of the visual world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Houghton Mifflin</title>
		<imprint>
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Near real-time CSG rendering using tree normalization and geometric pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldfeather</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Molnar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="20" to="28" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Choosing effective colours for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Healey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;96</title>
		<meeting>Visualization &apos;96</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Conveying the 3d shape of smoothly curving transparent surfaces via texture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="98" to="117" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Investigating shape-from-shading illusions using solid objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="2827" to="2835" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Showing shape with texture: two directions seem better than one</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagh-Shenas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Vision and Electronic Imaging VIII</title>
		<imprint>
			<publisher>SPIE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="332" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Conveying shape with texture: experimental investigations of texture&apos;s effects on shape categorization judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hagh-Shenas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Interrante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="483" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Geometry of shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Knill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of Ameriaca</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3216" to="3232" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Relief: pictoral and otherwise. Image and Vision Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Koenderink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Doorn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="321" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Measuring visual shape using computer graphics psychophysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Bülthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurographics Workshop on Rendering Techniques</title>
		<meeting>Eurographics Workshop on Rendering Techniques</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Perception of three-dimensional shape from texture is based on patterns of oriented energy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zaidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="217" to="242" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Illumination, shading and the perception of local orientation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="2351" to="2367" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The perception of cast shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mamassian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Knill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="288" to="295" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Interior/exterior classification of polygonal models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nooruddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Turk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;00</title>
		<meeting>IEEE Visualization &apos;00</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="415" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Illumination for computer generated pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Phong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="311" to="317" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Perceiving shape from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramachandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific American</title>
		<imprint>
			<biblScope unit="volume">259</biblScope>
			<biblScope unit="page" from="58" to="65" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Opacity-modulating triangular textures for irregular surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rheingans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;96</title>
		<meeting>Visualization &apos;96</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="219" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards perceptual enhancement of multiple intersecting surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization and Data Analysis</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="339" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">View direction, surface orientation and texture orientation for perception of surface shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sweet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface</title>
		<meeting>Graphics Interface</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generic and non-generic conditions for the perception of surface shape from texture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Oomes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="837" to="850" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Color sequences for univariate maps: Theory, experiments and principles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="page" from="41" to="49" />
			<date type="published" when="1988-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Information visualization: Perception for design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd Edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
