<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Generalized Detail-In-Context Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Alan</forename><surname>Keahey</surname></persName>
							<email>keahey@lanl.gov</email>
							<affiliation key="aff0">
								<orgName type="institution">Los Alamos National Laboratory</orgName>
								<address>
									<postCode>MS B287, 87545</postCode>
									<settlement>Los Alamos</settlement>
									<region>NM</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Generalized Detail-In-Context Problem</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>This paper describes a general formulation of the &quot;detail-in-context&quot; problem, which is a central issue of fundamental importance to a wide variety of nonlinear magnification systems. A number of tools are described for dealing with this problem effectively. These tools can be applied to any continuous nonlinear magnification system, and are not tied to specific implementation features of the system that produced the original transformation. Of particular interest is the development of &quot;seamless multi-level views&quot;, which allow multiple global views of an information space (each having different information content) to be integrated into a single view without discontinuity.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Many approaches have been described in the literature for stretching and distorting spaces to produce effective visualizations of data. Such techniques have been called polyfocal projection <ref type="bibr" target="#b7">[8]</ref>, fisheye views <ref type="bibr" target="#b6">[7]</ref>, distortionoriented presentation <ref type="bibr" target="#b14">[15]</ref>, focus + context <ref type="bibr" target="#b13">[14]</ref> and many other terms <ref type="bibr" target="#b9">[10]</ref>. In <ref type="bibr" target="#b11">[12]</ref> we introduced the term nonlinear magnification to describe the effects common to all of these systems. The basic characteristics of nonlinear magnification are non-occluding in-place magnification which preserves a view of the global context. In this paper we will define the detail-in-context problem as a general issue of significance to all nonlinear magnification systems, and then describe a collection of methods for dealing with the problem. Both the statement of the problem, and the methods for dealing with it are very general-purpose in nature, and can be readily applied to existing nonlinear magnification systems.</p><p>In overview: after first defining the problem, we will provide a brief review of the nonlinear magnification fields which are of central importance to the techniques described later. Following this we will examine specific methods for addressing the detail-in-context problem, concentrating first on the case for discrete objects, and then considering the task of seamlessly integrating different global views of the information space. We finish with a brief discussion on consistent visual cues for magnification, followed by related work and conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">The Detail-In-Context Problem</head><p>The detail-in-context problem for visualization with nonlinear magnification systems can be stated briefly as:</p><p>How can we effectively utilize the additional space made available by any nonlinear magnification transformation to enhance the visualization of the data or objects located within that space? <ref type="figure">Figure 1</ref> shows a diagram of the problem. Detail can be seen as an additional axis that is orthogonal to the transformational axes. The interpretation of this detail axis is highly task-dependent. It can refer to something as simple as object size, or as complex as semantic levels of information content. One goal of this paper is to provide a single, unifying method for defining the detail levels implicit in a nonlinear magnification system, so that more sophisticated treatment of the detail axis can then be based on those defined values.</p><p>x y detail</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. The Detail-In-Context Problem</head><p>The formulation of this problem is similar to a number of approaches already taken in the literature. The Perspective Wall <ref type="bibr" target="#b16">[17]</ref> was an effort to provide "detail and context smoothly integrated". Researchers at Xerox PARC using a 2D hyperbolic transformation for display of graphs referred to their technique as a "focus+context" technique <ref type="bibr" target="#b13">[14]</ref>. Similar terminology is scattered through much of the literature since that time. Our definition of the problem has significant differences from these specific approaches however, which we will now outline.</p><p>Many focus+context techniques are designed to create "focus" by enlarging spaces, and reduced "context" by compressing the surrounding spaces. This addresses only half of the detail-in-context problem as it has been defined here; it creates the space needed for additional detail, but does not by itself provide a means for placing more detail within that space. Although many of these systems also provide enhanced detail within regions of magnification <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18]</ref>; the techniques that we will describe in this paper are of a more general nature, these methods effectively synchronize detail functions with any continuous nonlinear magnification transformation. Although most of the transformations in this paper were generated using the nonlinear magnification transformations described in <ref type="bibr" target="#b11">[12]</ref>, the techniques which we will explore here are independent of the actual mechanism used to produce the original nonlinear transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Nonlinear Magnification Fields</head><p>Leung and Apperley <ref type="bibr" target="#b14">[15]</ref> first established the mathematical relationship between magnification and transformation functions for nonlinear magnification or "distortionoriented" systems. For the one-dimensional case they define the magnification function as the derivative of the transformation function. This relationship was extended to higherdimensional nonlinear transformations in <ref type="bibr" target="#b12">[13]</ref>, resulting in the nonlinear magnification field (described in greater detail in <ref type="bibr" target="#b8">[9]</ref>). Methods were provided for converting back and forth between 2D nonlinear transformation functions and their associated magnification functions. It was shown that every continuous, order-preserving, nonlinear transformation has an implicit magnification field which is a field of scalar values reflecting the magnificational effect of that transformation. Implicit magnification fields are very inexpensive to compute, provide a consistent measurement of the effect of transformations, and can be computed on any continuous nonlinear magnification transformation, regardless of what type of system was used to produce that transformation (an example shown in <ref type="bibr" target="#b12">[13]</ref> illustrates the implicit magnification field of the Perspective Wall <ref type="bibr" target="#b16">[17]</ref> system). These magnification fields play a central role in the methods described in this paper; their implementation-independent nature provides a general-purpose method for quantifying the effects of specific nonlinear magnification transformations, thus providing a rigorous mathematical measure on which to synchronize our detail-rendering methods. <ref type="figure" target="#fig_0">Figure  2</ref> shows two examples of nonlinear transformations along with their associated implicit magnification fields. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Putting Detail In Context</head><p>In this section we will examine the problem of how to provide suitable detail within magnified regions of a nonlinearly transformed domain. First we will consider the case where our information is composed of discrete objects within the coordinate space, and then we will consider the problem of seamlessly integrating different global views of the information space (each view having a different information content). Throughout the section we will use an "interactive travel atlas" as an application to demonstrate the concepts involved. As regions of the atlas are expanded with nonlinear magnification by a user, points of interest within those regions can be displayed accordingly. For this specific example we will use an atlas of Scotland, with major points of interest (castles, whisky distilleries, etc.) as the discrete data objects within the map. Each atlas example is illustrated both in the paper and in Colour Plate A. These examples make extensive use of texture mapping techniques <ref type="bibr" target="#b2">[3]</ref> to place the images on the screen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Discrete Objects</head><p>The first general detail-in-context task that we will examine involves rendering discrete objects within a nonlinearly transformed space. The problem is to determine how to render these discrete objects in a manner that is consistent with the underlying spatial transformation. There are several ways in which this can be approached, ranging from simple object-size calculations to "embedding" objects within the underlying space. We will now examine these methods individually, and also show different ways in which they can be combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Object Size</head><p>The simplest method for increasing detail of objects involves only increasing their size. This method is commonly used for single-foci systems such as <ref type="bibr" target="#b21">[22]</ref>, where object size can be based on simple Euclidean proximity to the center of magnification. However the task becomes more difficult when complex transformations with multiple foci and/or constrained domains are used; simple Euclidean distance is no longer effective as a measure on which to base object size in such cases. A recent article <ref type="bibr" target="#b5">[6]</ref> describes the separation of transformation ("displacement") and magnification (a conceptual distinction describing node size) functions, however the authors do not address the issue of how to ensure that these functions are reasonably synchronized. All of the examples shown in that work involve either a very simple single-focus transformation function or else a very simple magnification function; for such cases there is no complex interaction of transformation and magnification to account for, and thus simple proximity-based approaches can be used for determining detail.</p><p>The implicit magnification fields developed in <ref type="bibr" target="#b12">[13]</ref> are very well suited for the task of synchronizing transformation and magnification functions when complex transformations are involved. By computing the implicit magnification field for the transformation we can find the magnification for any object within the transformation domain, and render the object with a size proportional to that magnification. This method is general-purpose in nature, and does not require any special knowledge about foci-location or other facts that are internal to the specific transformation technique used to produce the transformation. In addition, since the implicit magnification field is C 0 continuous and well defined over the entire domain it does not leave any gaps where the magnification is undefined, as is the case for some of the other approaches for graph visualization that only define magnification locally at the nodes of the graph <ref type="bibr" target="#b18">[19]</ref>. <ref type="figure" target="#fig_1">Figure 3</ref> shows several examples of how object size can be coupled effectively with implicit magnification values. <ref type="bibr" target="#b0">1</ref> 1 Uniform scaling is used in these examples, although non-uniform aspect ratios are also possible. This was illustrated for simple cases in <ref type="bibr" target="#b5">[6]</ref>, and can be implemented for complex cases via the nonlinear magnification vectors described in <ref type="bibr" target="#b8">[9]</ref>.  <ref type="figure" target="#fig_2">Figure 4</ref> shows how object-size rendering might work for our interactive atlas; each point of interest is rendered as an image which is uniformly magnified proportionally to the implicit magnification of the transformation. Although this example illustrates effective synchronization of detail and transformation functions, it also shows how object size alone is not always sufficient to guarantee that the objects do not overlap each other. In this example we sort the images by the implicit magnification level of the transformation, so that the highest-magnified image will always be completely visible. This sorting can be performed analytically, or on a per-pixel basis using z-buffer rendering. A more sophisticated approach to this problem which uses embedded objects will also be described in Section 2.1.3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Level of Detail</head><p>We can extend the object-size methods by incorporating level of detail (LOD) for the rendering of the objects. Level of detail is a common technique in 3D graphics. It is typically used to suppress details in the polygonal representation of objects when the object is far away from the view-point, since the detail would not be visible at the pixel level anyway.</p><p>The LOD notion can be generalized to tasks other than polygonal simplification however, and can incorporate concepts such as semantic levels of detail. Using our interactive atlas example, we might want to represent each castle in the atlas with three levels of detail. At level 0 we can represent the castle by a picture of it, at level 1 we use an iconic representation of a castle (which is shared by all castles), and at level 2 we simply represent the castle by a coloured square. <ref type="figure">Figure 5</ref> shows a schematic representation of these levels of detail.</p><p>level 0 level 2 level 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5. Castle Levels of Detail</head><p>We can easily drive the LOD rendering of objects simply by making the level of detail proportional to the implicit magnification produced by the transformation. <ref type="figure" target="#fig_3">Figure 6</ref> shows an example of our interactive atlas using both LOD and object size based on implicit magnification. This is but one simple example of how LOD rendering can be incorporated into nonlinearly magnified spaces, many other approaches are possible; for example the Pad++ [2] WWW navigation system uses page thumbnails with a LOD function so that the node at the focus of the transformation becomes an actual web page which the user can interact with, other systems for visualization of graph structures expand and collapse subgraphs as their root nodes are magnified or demagnified <ref type="bibr" target="#b18">[19]</ref>.</p><p>At this point we are still left with the problem that simple linear scaling of objects proportionally to the implicit magnification of the transformation can result in overlapping objects. In addition, this method leads to the perception of the objects as "floating" above the transformed space. Therefore while this method binds the dimensions of detail and context effectively, it does not reflect more complex aspects of the transformation itself within the objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3.">Embedded Objects</head><p>An alternative to the simple object-size approach is to embed the objects within the transformed coordinate space. This goes beyond simply placing the centers of objects appropriately within the transformed space, and involves mapping the boundaries of the objects to the transformed spatial coordinates. Embedding objects in this way produces what could be called a coherent information space, where the objects obey the same "transformational physics" as the underlying space. The result is a visualization that has a more tangible aspect to it; the magnification produced by the transformation can now be perceived consistently on three different levels: on the underlying space, between objects, and within individual objects. Prominent examples of this type of embedded object are found in the Perspective Wall <ref type="bibr" target="#b16">[17]</ref> and the Document Lens <ref type="bibr" target="#b20">[21]</ref>. <ref type="figure" target="#fig_4">Figure 7</ref> shows an example of using embedded objects for our interactive atlas. There are a number of problems with embedded objects however. The first problem is that magnification level for the objects is directly proportional to the implicit magnification of the underlying transformation, and is therefore not as flexible and responsive as using object size alone, where possibilities such as making object size proportional to the square of the implicit magnification allow for a greater dynamic scaling range for the objects. Another problem with embedded objects is that layout of the objects within the original untransformed space becomes more of a challenge if we want to ensure that the objects do not overlap at any point along their boundaries, since we need to ensure that the objects do not overlap in the original untransformed space. This difficulty is by no means insurmountable, but does produce constraints on the size and location of objects within the original coordinate space. A final problem with embedded objects is that they may introduce distortion within the objects being magnified. This problem can be dealt with by using transformations with linear regions of magnification to provide uniform scaling within the magnified regions, as shown in <ref type="figure" target="#fig_5">Figure 8</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4.">Embedded Objects with Size and Level of Detail</head><p>We can combine all of the previous techniques within a single visualization system so that we get the advantages of each technique. We linearly scale the objects in the original layout based on their implicit magnification value in the transformed space (clamping the scale factor so that they do not scale beyond the boundaries defined in the initial layout). Then LOD filtering can be applied, and finally the boundaries of the scaled, filtered object are mapped to the transformed coordinates to embed the object within the transformed space. <ref type="figure" target="#fig_6">Figure 9</ref> shows an example of this with our interactive atlas. Note that the maximum size of the objects is still bounded with this system, we can remove this restriction by allowing the objects to scale beyond the initial layout boundaries, using sorting based on magnification (either on a per-object or per-pixel basis) to manage the overlapping objects. This damages the coherency of the information space somewhat, but the extra benefits of allowing larger objects may make this worthwhile. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Seamless Multi-Level Views</head><p>Another level on which the detail-in-context problem can be addressed involves integrating different global "views" of the information space. The term "view" in this context does not refer to a different physical viewpoint, but rather a different visual representation of the information space. In the specific examples described here, each view is represented by a discrete image. This does not represent a fundamental limitation on the types of views or data that can be used, since any data can always be rendered to an offscreen buffer and then used as an image (although this may introduce implementation considerations).</p><p>Since we will be dealing with views as images, it is illustrative to look first at the example of nonlinear magnification of a single image. <ref type="figure" target="#fig_7">Figure 10</ref> shows a simple 8 8 checkerboard image alongside a nonlinearly magnified version of the image. Because the data content is static between normal and magnified versions, no additional information is obtained through the nonlinear magnification, and the only thing that changes is the size (and shape) of the original 88 squares. Some filtering techniques which are commonly used in texture mapping may also allow interpolated values between the data squares, however this does not provide any new information to the user, but rather just a smoother transition between normal and magnified squares. For cases where the original image is larger than the available screen pixels, similar filtering techniques can be used to downsample the image so that the low frequency content of the entire image is still visible. Magnification of these downsampled regions may reveal a clearer view of the actual image pixels, however the underlying image content does not change, only the sampling frequency of that image. Nonlinear magnification of individual images was illustrated in <ref type="bibr" target="#b3">[4]</ref>; details of nonlinear image magnification and the differences between discrete and continuous domains were described extensively in <ref type="bibr" target="#b10">[11]</ref>, and later mentioned in <ref type="bibr" target="#b4">[5]</ref>. We can extend this idea of image magnification to account for multiple levels of images (i.e. multiple views), where each view can now represent distinct semantic or graphical representations of the overall information space (this idea was first mentioned in <ref type="bibr" target="#b10">[11]</ref>). An example application where this might be useful involves combining state, county and city maps within a single magnified view. At the top level the user is looking at a state map; as the user magnifies some region of the map, the county map is "pulled in" to the magnified area to provide that detail within the state map. Further magnification would also pull in additional detail from the city map.</p><p>We will first examine a simple example of multi-level image magnification to illustrate the issues that are involved. Consider two independent views of an information space, the first view is an 8 8 grid, and the second view is a 16 16 grid (the grid sizes here are deliberately chosen to illustrate the effectiveness of integrating the two views, in practice any other grid sizes could be used). Conceptually, we can think of this process as looking straight-on at the centers of the images, with the 8 8 image in front of the 16 16 image, and filling the entire window. As we apply nonlinear magnification, we effectively "punch a hole" through the 8 8 grid and pull in the view of the <ref type="bibr">16 16</ref> grid so that the two views are seamlessly integrated. <ref type="figure" target="#fig_8">Figure 11</ref> shows an example of this operation; notice how each square of the 8 8 is perfectly aligned with the corresponding 4 squares from the 16 16 grid, and note also how the two images are blended together around the region of magnification to provide a smooth transition between images. This technique differs significantly from single image magnification in that we are now dynamically incorporating additional detail within the context provided by our nonlinear magnification transformation. <ref type="figure" target="#fig_0">Figure 12</ref> shows an example of this using two different maps from the Xerox PARC Map Server <ref type="bibr" target="#b19">[20]</ref>. Two views of the California Bay Area are provided, with the larger map showing more detail (roads, railway tracks etc.) than the smaller one. As the smaller, simple view is magnified, additional information is pulled in from the detailed view. Note  The implementation of multi-level image magnification can be greatly facilitated by the use of MIP-mapping <ref type="bibr" target="#b24">[25]</ref>, which is a common technique within the graphics community for dealing with texture mapping, and is supported by hardware acceleration on most workstations and PCs with hardware graphics capabilities. MIP-mapping is a method for storing different resolution versions of a texture map, so that the most appropriate resolution level can be used for the patch that the texture is being applied to. For example, an n n texture will be stored at the original resolution at level 0, along with a filtered n=2 n=2 version at level 1, and a n=4 n=4 at level 2 and so on down to a 1 1 version at level log 2 n . <ref type="figure" target="#fig_1">Figure 13</ref> shows a schematic representation of this for a single channel of an RGB texture. image (256 256), we will see only that image; as we magnify portions of the level 1 image, the level 0 image will be pulled into the context of the level 1 image. Although this method works very efficiently on hardware accelerated machines, some hardware implementations also place limits on the size of images that are allowed. This can be a limitation on the maximum size of image (typically somewhere between 512 512 and 2048 2048 pixels), or on the scale factor between levels (some graphics library implementations restrict this to a factor of 2). Although workarounds can usually be found for these constraints, an area for further research is to develop a more general formalism for describing multi-level image magnification outside of the constrained hardware-accelerated environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Consistent Visual Cues</head><p>A final issue involved with the detail-in-context problem is the need to provide consistent visual cues to the user as to what regions are being magnified or demagnified by a given transformation. This need was addressed in an implementation-specific manner for the 3DPS system <ref type="bibr" target="#b3">[4]</ref>, through the combination of an additional NURB surface and a computationally expensive lighting model to produce shading of regions of distortion. More generally, suitable shading for any given transformation can also be produced in an implementation-independent fashion through the use of implicit magnification fields. These provide a consistent quantification for the degree of magnification implicit in a given transformation, making our task simply to render the information in a way that reflects this quantification (the 3DPS system does not provide a mechanism for quantifying the effects of a given transformation, and has an inconsistent relationship between elevation and magnification <ref type="bibr" target="#b12">[13]</ref>). We have already seen examples in Section 1.2 where the implicit magnification values are mapped into a 1D colour ramp to provide consistent visual cues for a single surface; the situation is somewhat more complicated for textured or multiple surfaces however. One possibility is to use multipass rendering and modulate all of the surfaces with the appropriate colour ramp values during one of the passes. Another simpler method involves mapping the surfaces onto a composite mesh (defined in <ref type="bibr" target="#b8">[9]</ref>, each node in the composite mesh has the fx; yg coordinates of the transformation grid, and the z value of the implicit magnification mesh of the transformation). The mesh is then viewed from above with an orthographic transformation, and fog is used to gradually fade out the regions of lower magnification. The fog colour can be set to any RGB values, depending on what colour works best for a particular application. This technique is illustrated for both a single textured surface and a multilevel view in <ref type="figure" target="#fig_2">Figure 14</ref> and Colour Plate C. The fog-based approach to providing visual cues has the benefit of allowing for very simple implementation (most current graphics libraries provide ready support for this), and is also very inexpensive computationally (having hardware support on many platforms). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head><p>Lieberman <ref type="bibr" target="#b15">[16]</ref> takes a different approach to integrating global views of an information space. The primary technique used there relies on overlapping layers of varying translucency, so that the different global views are visible simultaneously. In contrast, the seamless multi-level views described here do not introduce the clutter of overlapping images; in general each pixel will be associated with a single view, except at the transition zone between two different views, where it will be a blended value from between those two views. Another fundamental difference is that Lieberman's method leaves sharp spatial discontinuities between the levels of information. Although these discontinuities help to facilitate large degrees of magnification, they also place the method outside the scope of the traditional nonlinear magnification techniques which seek a smoother transition between the magnified and compressed regions in the spatial plane. In contrast, the seamless multi-level views presented here provide smooth transitions that are free of discontinuities.</p><p>Magic Lens <ref type="bibr" target="#b23">[24]</ref> filters provide many different methods for changing the visual representation of information as the filters pass over the workspace. Filters are available for increasing or decreasing detail, as well as for altering semantic representation and other effects. A key difference between these filters and the methods described here is that the filters are implemented as distinct objects with discrete boundaries, and do not create the nonlinear spatial transformations which expand and compress the space to allow more or less detail. The tools described in this paper differ in that their effects are all defined by the intrinsic properties of a given nonlinear transformation, in effect allowing the nonlinear transformation to drive the filtering process in a well-synchronized fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper we have defined a general statement of the "detail-in-context" problem common to many nonlinear magnification systems. By defining the general case for this problem, we allow for the analysis and construction of techniques for dealing with the problem that are not tied to the specific implementation details of the system that is producing the original nonlinear magnification transformation.</p><p>We have explored several different techniques for handling the detail-in-context problem. Some of these techniques are primarily a generalization of methods that have been described elsewhere in the literature, whereas other techniques (such as seamless multi-level views) offer a completely novel functionality. All of these methods are based on our low-level implicit magnification field method for defining well-synchronized detail values for a given nonlinear transformation. Through combinations of the techniques developed here, we can define general-purpose methods for enriching the visualization of information spaces that have been transformed via the nonlinear magnification paradigm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Transformations and their Implicit Magnification Fields</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Synchronizing Object Size and Implicit Magnification</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Interactive Atlas with Variable Object Sizing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Interactive Atlas with LOD and Variable Object Sizing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Interactive Atlas with Embedded Objects</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Interactive Atlas with Embedded Objects and Linear Magnification (compare the linear scaling of the castle in focus with the distortion of the same object inFigure 7)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Interactive Atlas with Variable Size, LOD and Embedded Objects</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 .</head><label>10</label><figDesc>Single Image Magnification</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 .</head><label>11</label><figDesc>Multi-Level Image Magnificationthat the integration of the two views is seamless, and that all of the map lines are perfectly aligned at the intersection of the simple and detailed views. Colour Plate B shows our two examples of seamless multi-level views.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 12 .</head><label>12</label><figDesc>Multi-Level Map Magnification</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 13 .</head><label>13</label><figDesc>We can bypass the normal filtering construction of MIPmap levels and load any image into the different levels of the MIP-map, as long as the image has the same number of pixel rows and columns as are required for that level. Using our previous example, we can load the 256 256 pixel image of the 8 8 grid into level 1, and the 512 512 pixel image of the 16 16 grid into level 0. If we size our view-port to the same number of pixels as the level 1 MIP-Mapping for a Single Channel</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 14 .</head><label>14</label><figDesc>Using Fog to Indicate Magnification</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The continuous zoom: A constrained fisheye technique for viewing and navigating large information spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bartram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Henigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User Interface Software and Technology</title>
		<meeting>the ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="1995-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pad++: A zoomable graphical sketchpad for exploring alternate interface physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Hollan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Perlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Furnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages and Computing</title>
		<imprint>
			<biblScope unit="page" from="3" to="31" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Texture and reflection in computer generated images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Blinn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="542" to="546" />
			<date type="published" when="1976-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">3D pliable surfaces: For the effective presentation of visual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User Interface Software and Technology</title>
		<meeting>the ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multiscale viewing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Visual Proceedings</title>
		<imprint>
			<date type="published" when="1996-08" />
			<biblScope unit="page">149</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Technical Sketch</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extending distortion viewing from 2D to 3D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carpendale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cowperthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fracchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="42" to="51" />
			<date type="published" when="1997-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<title level="m">Generalized fisheye views. Human Factors in Computing Systems, CHI &apos;86</title>
		<imprint>
			<date type="published" when="1986-04" />
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A polyfocal projection for statistical surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kadmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shlomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Cartographic Journal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="41" />
			<date type="published" when="1978-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Nonlinear Magnification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Keahey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-12" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Indiana University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">the Nonlinear Magnification Home Page. A WWW resource devoted to all aspects of nonlinear magnification available at: www</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Keahey</surname></persName>
		</author>
		<ptr target=".cs.indiana.edu/hyplan/tkeahey/research/nlm/nlm.html" />
		<imprint>
			<date type="published" when="1997-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Non-linear image magnification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Robertson</surname></persName>
		</author>
		<idno>460</idno>
		<imprint>
			<date type="published" when="1996-04" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Indiana University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Techniques for non-linear magnification transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization</title>
		<meeting>the IEEE Symposium on Information Visualization, IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1996-10" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nonlinear magnification fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Keahey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization</title>
		<meeting>the IEEE Symposium on Information Visualization, IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1997-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A focus+context technique based on hyperbolic geometry for visualizing large hierarchies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lamping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer Human Interaction</title>
		<meeting>the ACM Conference on Computer Human Interaction</meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A review and taxonomy of distortion-oriented presentation techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Apperley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="126" to="160" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Powers of ten thousand</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lieberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User Interface Software and Technology</title>
		<meeting>the ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="1994-11" />
			<biblScope unit="page" from="15" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The perspective wall: Detail and context smoothly integrated</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mackinlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Card</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer Human Interaction</title>
		<meeting>the ACM Conference on Computer Human Interaction</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="173" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">H3: Laying out large directed graphs in 3D hyperbolic space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization, IEEE Visualization</title>
		<meeting>the IEEE Symposium on Information Visualization, IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="1997-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploring large hyperdocuments: Fisheye views of nested networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Noik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Hypertext</title>
		<meeting>the ACM Conference on Hypertext</meeting>
		<imprint>
			<date type="published" when="1993-11" />
			<biblScope unit="page" from="192" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Xerox PARC map viewer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Putz</surname></persName>
		</author>
		<ptr target="www.parc.xerox.com/istl/projects/mapdocs/" />
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The document lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mackinlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User Interface Software and Technology</title>
		<meeting>the ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Graphical fisheye views of graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer Human Interaction</title>
		<meeting>the ACM Conference on Computer Human Interaction</meeting>
		<imprint>
			<date type="published" when="1992-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Stretching the rubber sheet: A metaphor for visualizing large layouts on small screens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Snibbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Reiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Symposium on User Interface Software and Technology</title>
		<meeting>the ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The movable filter as a user interface tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Bier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Computer Human Interaction</title>
		<meeting>the ACM Conference on Computer Human Interaction</meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pyramidal parametrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
