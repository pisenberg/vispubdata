<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Subspace Search and Visualization to Make Sense of Alternative Clusterings in High-Dimensional Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrada</forename><surname>Tatu</surname></persName>
							<email>tatu@inf.uni-konstanz.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Maaß</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Färber</surname></persName>
							<email>faerber@cs.rwth-aachen.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Bertini</surname></persName>
							<email>bertini@inf.uni-konstanz.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Schreck</surname></persName>
							<email>tobias.schreck@uni-konstanz.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Seidl</surname></persName>
							<email>seidl@cs.rwth-aachen.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keim</surname></persName>
							<email>keim@inf.uni-konstanz.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">RWTH</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country>University Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="institution">RWTH</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country>University Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Subspace Search and Visualization to Make Sense of Alternative Clusterings in High-Dimensional Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.2.8 [Database Applications]: Data mining</term>
					<term>H.3.3 [Information Search and Retrieval]: Selection process</term>
					<term>I.3.3 [Picture/Image Generation]: Display algorithms</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The analysis of high-dimensional (HD) data is an ubiquitously relevant, yet notoriously difficult problem. Problems exist both in automatic data analysis and in the visualization of this kind of data. On the visual-interactive side, a limited number of available visual variables and limited short-term memory of human analysts make it difficult to effectively visualize data in high numbers of dimensions. For automatic pattern detection, a typically employed paradigm is the one of clustering, which identifies groups of objects based on their mutual similarity. Unlike traditional clustering methods, for the mentioned HD data considering all features simultaneously is not effective anymore due to the so-called curse of dimensionality <ref type="bibr" target="#b2">[3]</ref>. As dimensionality increases, the distances between any two objects become less discriminative. Moreover, the probability of many dimensions being irrelevant for the underlying cluster structure increases.</p><p>Global dimensionality reduction or feature selection methods do not solve this problem as clusters may be located in different subspace projections of the feature space, i.e., projections obtained by considering subsets of the original dimensions. For such scenarios the clustering structure tends to be obfuscated in the original feature space and traditional clustering algorithms as well as visual analysis based on the full-space may fail. For large feature spaces, interesting patterns may often be located only in subspace projections of the data. As insights may not be hidden in only one single subspace, relevant analysis should consider also multiple subspaces and their interrelations. Especially, for HD data we can expect to have different views on the same data <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b20">21]</ref>, i.e., the same objects might group differently given different subspace perspectives (see <ref type="figure" target="#fig_0">Figure 1</ref> for an illustration). The existence of alternative relevant subspaces may stem from the data description process, when during preprocessing, features (dimensions) which describe different semantic properties of the data, are combined. For instance, in demographic analysis, households are often described by an array of many variables, combinations of which constitute different conceptual domains, such as wealth, mobility, or health. Likewise, it may be the combination of otherwise not semantically related dimensions, which by their combination give rise to interesting patterns. In the Data Mining community, a class of so-called Subspace Analysis algorithms has been proposed to cope with the problem of identifying interesting subspaces and clusters from a HD data set. To date, however, there has been a very limited focus on the presentation and interpretation of the generated output. Furthermore, subspace analysis often produces highly redundant results that need to be further manipulated in order to get meaningful results <ref type="bibr" target="#b18">[19]</ref>.</p><p>We propose an initial step towards the use of Visual Analytics as a way to explore alternative views generated by subspace analysis algorithms. We define an analytical pipeline made of algorithmic and visual components that permits to single out and explore alternative views in the data. After being analyzed by a subspace search algorithm, the data is structured and further processed in an interactive visualization environment to reduce redundancy.</p><p>The main contribution of this paper is the operative definition and implementation of this multistep pipeline which permits to sift through an exponential number of subspace candidates and to reduce the problem to a handful of relevant views. More specifically, we (1) introduce a mechanism to deal with subspace redundancy by defining topological and dimensional subspace similarity and by allowing flexible and interactive subspace aggregation; <ref type="bibr" target="#b1">(2)</ref> we provide a well-reasoned interactive visualization environment that permits to compare and assess alternative views by visually comparing topological and dimensional similarities and strike a balance between visual complexity and level of detail.</p><p>We evaluate our method through two case studies. The first is based on synthetic data to check whether the tool does what it is supposed to do. The second is based on real-world data to demonstrate how the tool can help finding and interpreting alternative views in HD data. We believe these results show the potential of Visual Analytics in the context of automated mining algorithms. It furthermore shows how the use of Visual Analytics can enhance the understanding of the results of automated data analysis methods, and lead to new questions concerning more effective or more efficient algorithms.  <ref type="bibr" target="#b19">[20]</ref> in two different subspaces of a larger HD data space (domain here: demographic data analysis). Our proposed visual analysis method integrates the notion of alternative subspaces into the analysis process and links it to the task of comparative cluster analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">SUBSPACE ANALYSIS</head><p>In this section, we discuss the challenges for visual subspace analysis in more detail and explain how we tackle these with our new interactive, explorative framework supported by subspace search algorithms.</p><p>As is commonly known in subspace clustering, dealing with HD data in its subspace projections faces two main challenges. The first, serious challenge is a reasonable scalability w.r.t. the dimensionality of the data set. As for a d-dimensional data set the number of possible subspaces S ⊆ {1,...,d} is ∑ d k=1 d k = 2 d − 1, many subspace clustering approaches do not scale well for very HD data. Every algorithm has to employ some strategy and heuristics to cope with such an exponential search space. The second, closely related challenge is dealing with high redundancy, that stems from the high similarity of the exponentially many subspaces. If two subspaces share a high proportion of dimensions, they are likely to exhibit a very similar clustering structure <ref type="bibr" target="#b10">[11]</ref>. A large search result with high redundancy is, however, not beneficial for the user as it masks the complete information and is hard to interpret.</p><p>A core task in analysis of HD data is to apply a clustering method to reduce data complexity and identify groups of data for comparison. Different clustering algorithms follow different clustering notions, e.g., there exist density-(e.g., DBSCAN <ref type="bibr" target="#b8">[9]</ref>) or compactnessbased (e.g., k-Means) clustering methods, and their outcomes often depend crucially on non-intuitive parameter settings. Usually several clustering attempts are required until the user has a usable result. It is obvious that high runtimes of subspace clustering processes (see Section 6.3) are not tolerable for such a workflow. Consequently, we decided to start the visual data exploration one step before the actual clustering process and decouple subspace search and the actual clustering. Dedicated subspace search algorithms <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b14">15]</ref> have been designed to efficiently filter and rank the possible subspaces according to specific quality criteria (or interesting-ness measures, see also below). After subspace search has taken place, an arbitrary clustering approach can be used to cluster in the identified subspaces.</p><p>The use of subspace search for our purposes has several advantages: (1) It helps to effectively filter out those subspaces that based on low interestingness do not need to be considered by the user. (2) Subspace search approaches are designed to reduce the search space efficiently and they do not need to compute clusters. And (3) although, subspace search approaches themselves also rely on certain assumptions of what makes a subspace interesting, these assumptions do not necessarily lead to very different subspaces among different approaches. Therefore, the results are not as biased as they are for different clustering algorithms, which enables the user to already obtain valuable results with one subspace search approach. For example, the quality assessment based on the k-NN distance <ref type="bibr" target="#b1">[2]</ref>, favors neither the DBSCAN nor the k-Means clustering notion. And (4), integrating the subspace search into the HD analysis offers the user the opportunity to obtain a visual, intuitive overview of the clustering structure before even starting the actual clustering. Thus, the user can assess the potential of the data to deliver valuable clustering results at all; decide which subspaces are to be clustered; decide which clustering notion to follow in each subspace (since the notion does not need to be the same for all); more easily determine meaningful parameter settings for clustering approaches.</p><p>Subspace search methods guide their search process by specific interestingness scores that are defined heuristically. For example, the method proposed in <ref type="bibr" target="#b6">[7]</ref> considers as interestingness score the variation of the density of objects across a regular cell-based partitioning of a given subspace. The underlying assumption is, that higher variation of density provides higher probability that the subspace shows meaningful structure. As another example, the SURF-ING method <ref type="bibr" target="#b1">[2]</ref> relies on the histogram of the k-nearest neighbor distances for all objects in a given subspace. It considers subspaces with non-uniform distance distributions more interesting (as they are an indication of the presence of strong clusterings). The underlying assumption is that for subspaces that show meaningful structures (e.g., clusters), different k-NN distances will occur. These and other measures aim at identifying subspaces that show a high "contrast" with respect to the distribution of objects, allowing to spot meaningful structure in the subspaces.</p><p>Subspace search methods also typically contain heuristic approaches for early abandoning uninteresting subspaces, as exhaustive search would be prohibitively expensive. SURFING for example is based on a bottom-up strategy for searching subspaces by increasing dimensionality. It is based on testing additional dimensions for subspaces already known to be interesting. The list of currently interesting subspaces is continuously pruned to keep only the most interesting subspaces and speed up the search. SURFING has no dimensionality bias, assumes no specific clustering structure and in practice, it is parameter free. Due to these properties, we rely on this method in our proposed approach, using the implementation provided to us by the original authors, but other subspace search algorithms could be easily used as well.</p><p>Overall, using the results of a subspace search algorithm as a starting point for our visualization has many advantages. Subspace search methods such as SURFING employ efficient search strategies tackling the efficiency challenge of subspace analysis. However, they typically do not solve the challenge of high redundancy. This is exactly where our proposed visual analytical workflow introduced next, starts from.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED ANALYTICAL WORKFLOW</head><p>We propose a carefully designed visual-analytics workflow for subspace-based exploration of HD data, making use of algorithmic subspace search in combination with visual-interactive representations for user-based filtering and exploration. Our approach starts  <ref type="figure">Figure 2</ref>: Our proposed analysis pipeline. A subspace selection algorithm is applied to automatically identify a candidate set of interesting subspaces. A filtering step reduces the potentially large and redundant set of automatically obtained subspaces to a user-selectable number of representing subspaces. Visual-interactive user exploration then proceeds on the subspace representations. Subspace analysis is also supported by comparative cluster views, allowing users to identify meaningful similar, complementary or even conflicting clustering structures in the set of subspaces.</p><p>(1) with an automatic subspace search step, where a large number of interesting subspaces is selected by a subspace search algorithm. Current subspace search methods provide an algorithmic handling of the problem of finding interesting subspaces, yet they often produce too many subspaces that may also be redundant and thereby overwhelm the interactive analysis (see also Section 2). We therefore employ similarity-based grouping of subspaces <ref type="bibr" target="#b1">(2)</ref> and perform the interactive exploration of interesting subspaces based on a few group representatives. Appropriate visual representations and interactions support the visual interactive analysis (3) for better understanding the subspace search results, including the support for comparative cluster analysis. <ref type="figure">Figure 2</ref> depicts our proposed analytical workflow. We next detail the technical design decisions made for each of the analysis steps, including discussion of alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Generation of interesting subspace candidates</head><p>The advantages for choosing subspace search, and in particular SURFING, have been already discussed in detail in Section 2. We observe that typically subspace search algorithms output a huge number of subspaces. Since the examination of all subspaces is infeasible, a common approach is to filter the subspaces based on a certain threshold. This, however, ignores the fact, that the first ranked subspaces might be only slight variations (i.e., high overlap of dimension sets) of the same subspace and therefore are redundant to each other. Yet, interesting subspaces with substantially different dimension sets, as compared to the top ranked results, could be found at much later ranking positions, and run the risk to be neglected from the analysis. Therefore, we apply a grouping step based on an appropriately defined notion of subspace similarity, as described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Similarity-based subspace grouping and filtering</head><p>Given a large number of candidate subspaces, we apply hierarchical grouping and filtering to yield a smaller set of mutually sufficiently different, yet individually interesting groups of subspaces for interactive analysis. Our filtering and grouping operation is based on a custom similarity function defined on pairs of subspaces according to two main criteria: (1) overlap of the sets of dimensions that constitute the respective subspaces, and (2) resemblance in the data topology given in the respective subspaces.</p><p>(1) Similarity based on dimension overlap: Subspaces can be similar regarding their constituent dimensions. We use the Tanimoto Similarity <ref type="bibr" target="#b22">[23]</ref> on bit vectors indicating the contained (active) dimensions in a respective subspace (1 denotes an active dimension, 0 the converse). The Tanimoto Similarity is then computed as the fraction of dimensions contained in both subspaces (AND-ing of the bit vectors), among the total number of different dimensions occurring in the subspaces (OR-ing of the bit vectors).</p><p>(2) Similarity based on data topology: We also compare subspaces with regard to their data distribution. Specifically, we consider the similarity of k-NN relationships in the respective subspaces. For efficiency reasons, we compute the k-nearest neighborhood (k = 20) lists for a sample of 5% of the contained data points. The similarity between two subspaces is then evaluated as the average percentage of agreement of k-NN lists in the subspaces. This score measures the similarity of the k-NN topology of the data, where k is a parameter and can be adapted to the data sets at hand by the user. Note that also other similarity measures are in principle possible. For instance, the data could be clustered and the similarity between subspaces evaluated according to the resemblance of obtained clusterings by an appropriate measure such as the RandIndex <ref type="bibr" target="#b21">[22]</ref>.</p><p>These two distance functions are the basis for the subspace grouping step in our analytical workflow as follows:</p><p>(1) Subspace grouping: We apply hierarchical agglomerative grouping of subspaces based on the topologic distance function using Ward's minimum variance method <ref type="bibr" target="#b29">[30]</ref>. Based on the dendrogram representation of the obtained hierarchical grouping, the user chooses the hierarchy depth level to select a number of groups. This way the user can easily decide how many clusters are desired for the analysis.</p><p>(2) Subspace filtering: Based on the previously achieved grouping of subspaces, we filter one subspace from each group as representative: For each group we consider the subspaces with the lowest dimensionality and choose the one which exhibits the highest interestingness score. We note that other rules for filtering representatives are possible, but find that this rule is robust and effective for users, as it tries to keep the dimensionality as low as possible.</p><p>These steps together with both distance functions take us further towards our goal of understanding the different kinds of relationships between subspaces. They can complement, confirm, or contradict each other and being aware of these relations can be crucial for further mining tasks.  Four basic cases can be identified, each of which might be relevant for a given subspace analysis task: (1) Subspaces that are similar in both, their contained dimension sets and their data topology (truly redundant subspaces); (2) Subspaces that are dissimilar in both, their contained dimensions and their data topology (truly complementary subspaces); (3) Subspaces that are similar w.r.t. data topology but dissimilar regarding their contained dimensions (confirmatory subspaces: we confirm the same data relationships in different subspaces); and (4) Subspaces that are similar w.r.t. their contained dimensions, but dissimilar regarding topology (this is generally not expected but could indicate the existence of one or a few dimensions which are by their nature very dominant for the data topology). <ref type="figure" target="#fig_2">Figure 3</ref> illustrates these four basic filtering cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Visual-interactive design</head><p>After hierarchical aggregation and/or filtering of the potentially redundant set of subspaces have taken place, we apply a set of analytical views for exploring and comparing the subspaces. Our displays are based on (1) scatterplot-oriented representations of individual subspaces or groups of subspaces, (2) similarity-based or linear list layouts for sets of subspaces, and (3) additional informative views (parallel coordinates and color-coding for comparison of groups in data).</p><p>The proposed design is the result of several iterations of alternative solutions in which we explored and compared several representations. Two design choices are worth discussing here: (1) the design of a visual representative for subspaces and (2) their layout. We decided to represent subspaces with scatter plots because they allow for the identification and comparison of groups in the data. More abstract representations (like simple colored marks) would require less space but would not allow the rich topological comparison provided by the scatter plots. In contrast, representations that are more complex like, e.g., parallel coordinates would provide a direct representation of the dimensions included in the subspace but would make their representation much more cluttered. As for the layout, we tried several tree and graph layouts to make the relationship between the subspaces and their shared dimensions explicit but we found that this rarely provides interesting insights and makes the visualization too cluttered to be of any use.</p><p>Scatter plots for subspaces can be generated by any appropriate projection technique such as PCA <ref type="bibr" target="#b13">[14]</ref>, MDS <ref type="bibr" target="#b7">[8]</ref> or t-SNE <ref type="bibr" target="#b28">[29]</ref>, to name a few. We currently use MDS, but we experimented with others and any other technique could be used as an alternative. For a group of subspaces, one representative subspace is chosen (see below). To convey the involved dimensions, we also add an index glyph to the respective scatter plot (see <ref type="figure" target="#fig_3">Figure 4</ref>). The analytical views are combined and linked in an application that consists of the following components:</p><p>Linearly sorted view of subspaces. To obtain a first overview of the output of the subspace search algorithm, we present all the subspaces in a linear view. The MDS scatter plots representing the individual subspaces are sorted left-to-right and top-down according to the interestingness index provided by the subspace search method. This view is exclusively used as a detail view for groups of topologically similar subspaces. <ref type="figure">Figure 5</ref>(1) illustrates the subspaces of the synthetic data set, which is described also later in Subsection 4.1.</p><p>Subspace group view. In this view, groups of subspaces that have been formed by hierarchical agglomerative grouping are shown. Each group is represented by one selected subspace from that group, using the filtering method as described in the previous Subsection.</p><p>The representative subspaces are each visualized by an MDS plot, and shown side-by-side <ref type="figure">(Figure 6</ref>(1) illustrates). A dimension histogram on top of it indicates the distribution of dimensions contained by the subspaces in the group, where the length of the bar encodes the frequency of the respective dimension. The last bar encodes the percentage of subspaces contained in this group. It is colored in orange to be easily distinguished from the others. Each group of subspaces from the preceding view can be expanded and its member subspaces can be seen and compared in detail (as <ref type="figure">Figure 6(5)</ref> illustrates). This allows a better understanding of the current similarity threshold, and allows to expand or further collapse the group structure based on visually perceived similarity between subspaces. The user can investigate how similar the distribution of dimensions is among different groups of subspaces. To this end, a click on the dimension histogram icon of one particular group will cross-highlight the dimensions of the selected group that are also contained by other clusters. In summary, the subspace group view allows a global comparison of non-redundant subspaces and their similarities concerning the contained data topology.</p><p>Dimension-based subspace similarity view. We also support the comparative analysis of all subspaces based on their similarity regarding the set of active dimensions. To this end, a global MDS layout, based on the Tanimoto distances between the subspaces, as described in Section 3.2, is generated. <ref type="figure">Figure 6</ref>(4) illustrates the subspace similarity view. For a high number of subspaces, this view can only provide an impression of the similarity relationships but by zooming more details become visible. The subspace group view (based on data topology distance) and dimension-similarity view (based on Tanimoto distance) are linked by color-coding (outer frame coloring). Thereby, we can compare the similarity of subspaces by their topological and dimension-overlap-based similarity.</p><p>Additional views and cluster comparison support. We also integrated details-on-demand for each subspace by a parallel coordinates view <ref type="figure" target="#fig_2">(Figures 5(3)</ref> and 6(3) illustrate). Highlighting contained dimensions helps to understand the difference of the subspaces in more detail. Furthermore, interactive exploration of the subspaces is enhanced by a single subspace view, providing an enlarged view of a selected subspace scatter plot (Figures 5(2) and 6(2) illustrate this). This view also allows to manually select clusters of objects by a lasso tool. Cross-coloring of the selected points among the other subspaces and within the parallel coordinates plot thus allows comparative exploration of grouping structures -a core problem in making effective use of alternative subspaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPLICATION</head><p>We now demonstrate the analytical capabilities of our proposed approach. First, we use synthetic data as a proof of concept and exemplify the suggested workflow. We show how that relevant subspaces can conveniently be identified. Then, we describe an explorative setting in which interesting findings in alternative subspaces of a real world data set are obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Application Scenario 1: Synthetic Data</head><p>We used a 750 record sample of the first 12D synthetic data set presented in <ref type="bibr" target="#b9">[10]</ref> (data set No. 2). This data set consists of four 3D Gaussian clusters and two 6D Gaussian clusters. The remaining dimensions contain uniformly distributed random noise. The first step of our approach is to determine the interesting subspaces of the high-dimensional data set, by running automatic subspace search using SURFING (see Section 3). This subspace search returns a total of 296 subspaces identified as interesting, out of the 4095 possible subspaces. To get a first impression of these subspaces, we use the linearly sorted view of subspaces shown in <ref type="figure">Figure 5</ref>, relying on MDS representations of the data in the subspaces, and sorted by the interestingness score in decreasing order. The view shows the diversity of subspaces identified during the automatic step. The first elements in the first row of the view are very similar in terms of the point distribution (showing mostly scattered and spherical point distributions). However, at later positions, we also see other varieties of point distributions, including parallel stripe patterns, and stripes mixed with spherical patterns. In a normal (non-visual) analysis case, relying just on the subspaces ranked top by the interestingness score, the analyst might miss some of these different characteristics of the subspaces.</p><p>The overview also confirms that the subspace search did return a lot of redundant subspaces, judging by the shape of the MDS projection representations. The next step is therefore to group the subspaces according to their similarity, allowing the user to abstract to a smaller number of relevant subspaces to compare them in detail. We used our similarity function based on the data topology, creating a hierarchal agglomerative clustering. <ref type="figure">Figure 6</ref>(1) shows that the number of subspaces can be reduced considerably in a meaningful way by the user. The navigation buttons, as shown in <ref type="figure">Figure 6(6)</ref>, allow the user to move through each dendrogram level and to find the desired level of redundancy. Here the dendrogram was cut at 0.73, very close to the root. As a result, six groups are found and visualized by their representatives. The number of groups can be variated, and the user can also investigate different levels in the dendrogram hierarchy. In this data we quickly found that six groups is the right level of detail for our further investigation.</p><p>We investigate the components of each group of subspaces in more detail. <ref type="figure">Figure 6</ref>(5) shows the group detail view of the orange, green, and purple subspace groups as framed in <ref type="figure">Figure 6</ref>(1). Topo-logically similar subspaces are grouped together. In this way, the analyst is given an overview of the existing groups and, if needed, can further compare individual group components.</p><p>On top of the scatterplots a dimension histogram is indicating the distribution of dimensions for each group. The last bar of the histogram is marked in orange and represents the percentage of subspaces contained in this group. It is scaled logarithmically, so that this bar is also visible for groups with few elements. A click on the dimension histogram of one group representative highlights its dimensions in all the other representatives. In <ref type="figure">Figure 6</ref>(1) the green group was clicked. To understand why the green-and gray-framed groups are split, we can consult the additional view in <ref type="figure">Figure 6</ref>(4). It shows an MDS layout of all interesting subspaces based on the dimension overlap (Tanimoto) similarity. In this view closeness of two subspaces corresponds to dimension similarity. We see that the green-and gray-framed cluster groups are located on the far left side in the plot. This shows us that the subspaces are similar in terms of dimensions, but being in different groups, they must show different topological similarity according to our similarity measure. This can be explained as all the subspaces of the gray-framed group contain dimension d12, while none of the subspaces in the greenframed group contain this dimension. This is visible by the bars in the dimension histogram of the gray-framed group. As it is not highlighted, it is not contained in the marked green-framed group. This dimension is obviously responsible for a different data distribution.</p><p>We can also go one step further in detailed comparison of subspaces by cross-color-coding clusters of points in the MDS representation. Our lasso tool allows the user to manually mark clusters of points in the MDS subspace representation, which allows to cross-compare the groupings among different subspaces. For example, we manually marked six separate clusters of points in the pink-framed subspace group (group number two in <ref type="figure">Figure 6</ref>(1)) and assigned distinct colors. By analyzing the distribution of colors among subspace group representatives, we see that other subspaces merge some of these clusters and spread others. This is also true for the purple framed group representative. The dark blue and pink point cluster (the upper most in the original colored subspace) are clustered in the purple subspace but some of their points also became noise in this subspace. Summing up, we can see how our visual analytics workflow helps to deal with the extensive number of possibly interesting subspaces in a natural overview-first based visual analytics workflow. In a first step, the SURFING approach reduced the number of subspaces of the 12 dimensional data set from 4095 to 296 interesting ones. Since this set of subspaces still showed a high redundancy, in our next step we grouped them using our topological similarity measure. Based on the grouped subspaces, further investigations coud take place for comparing the relations and distributions among points of data within the subspaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Application Scenario 2: Exploration/discovery</head><p>We will now demonstrate the exploratory functionalities of our proposed approach based on a real data set. We analyze the USDA Food Composition Data Set (http://www.ars.usda.gov/), a full collection of raw and processed foods characterized by their composition in terms of nutrients. The database contains more than 7000 records and 44 dimensions. After removing missing values and outliers, as well as normalization 722 records (foods) remained for which we selected 18 dimensions of the data set that where interpretable to us.</p><p>From this input data set, application of the SURFING algorithm returned 216 interesting subspaces for further exploration. To get a first impression of this data, we investigated the linearly sorted view (see <ref type="figure">Figure 8</ref> for a cut-out). Many subspaces, in particular those ranked with a high interestingness index, show a rather skewed dis- tribution of points in our projection representation, concentrating along the edges of the diagrams. Only later in the ranking, we start to see the projections forming out more structure, that could be meaningful. The red color framed subspace in <ref type="figure">Figure 8</ref> seems to be very interesting, forming long, clear stripes. With the help of the single subspace view, we further investigated this subspace (Iron, Maganase,Vit D ) by coloring each stripe with a different color and compared the formation of these clusters across the other subspaces. Most of them seemed to be overspread by the cyan class (see <ref type="figure">Figure 8 right)</ref>.</p><p>At the same time, it is clear that a high level of redundancy is still present, and a further grouping is deemed necessary. Therefore, we continued with our next analytical step, the subspace grouping by agglomerative hierarchical clustering. We obtained different groups of subspaces and found out that these clearly striped clusters only appear in subspaces containing Vit D .</p><p>We therefore reset the coloring and started a new interactive analysis step, beginning with this stage of our workflow. After testing different filtering thresholds and comparing the topological-and the dimension-based similarity relations, we obtained a number of 12 groups, and considered this suitable for subsequent analysis.</p><p>From the reduced number of representative subspaces, one particular subspace stood out to us (see <ref type="figure" target="#fig_0">Fig 9(1)</ref> for the group representatives and <ref type="figure" target="#fig_6">Fig. 7(A)</ref> for the interesting spotted one). This subspace shows the most structure and allows to discern two point clusters (pink and blue). We selected this specific subspace group (framed brown in <ref type="figure">Figure 9</ref>) for further analysis. Cross-coloring is used to highlight its group components, that are shown at the bottom of the figure. It is visible that the group of subspaces are topologically similar, consequently this subspace is a valid representative.</p><p>In addition, we observe that there are some subspaces in this group where the clustering is changing. One example is shown in <ref type="figure" target="#fig_6">Figure 7</ref>(B). We assigned the green color to the outstanding points on the left side, as they seem to form a different structure. In the group view (see <ref type="figure">Fig. 9</ref>(1)) we can see that this green cluster overspreads on five of the 12 subspace group representatives. After a closer look to the components of the orange subspace group, we spotted a sharply defined green cluster (see <ref type="figure" target="#fig_6">Fig. 7</ref>(D) and highlighted in <ref type="figure">Fig. 9</ref>(2)). By highlighting the dimensions of the orange group, we can see that the brown group has a dominant dimension (Protein) that is not contained by any subspace of the orange group. We can therefore assume that this dimension is decisive for the clustering of the points. In the dimension-based similarity view (MDS Layout in <ref type="figure" target="#fig_2">Fig. 9(3)</ref>) the subspaces of the brown and orange groups are far apart from each other, which supports our finding that the groups contain different dimensions. Likewise we can see that the group components of the brown group are scattered across the MDS layout. This is due to the fact that the group subspaces are dissimilar in terms of their dimensions, but their topological similarity is dominated by the shared dimension (Protein).</p><p>Summing up, we demonstrated how our interactive, exploratory workflow can be applied to real data. Compared to the previous scenario, the information about the clusters is not known in real data sets, meaning that several interactive attempts are needed to investigate the vast number of interesting subspaces provided by the subspace search algorithm. With the help of the topological similarity functionalities, we could group the redundant clusters and have a closer look in their topological change. Using the different linked views of our approach helped us to identify different subspaces that present alternative clusterings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION AND POSSIBLE EXTENSIONS</head><p>We will now summarize the main goal of our system, and discuss limitations and possible extensions next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Summarizing the Main Goals of our Approach</head><p>Our presented approach supports visual-interactive analysis of HD data from multiple perspectives based on the notion of automatic subspace search. The core assumption for our approach is that useful information could be extracted in a comparative way from several different subspaces residing in a larger HD data space. This assumption is the key driving force behind subspace search and subspace clustering algorithms developed in the Data Mining community over the past few years. We exploit algorithmic subspace search in an encompassing visual-interactive system. Our approach is designed around Shneiderman's Visual Information-Seeking Mantra <ref type="bibr" target="#b26">[27]</ref>, applied to the problem of analyzing potentially large sets of subspaces. Modern subspace search methods such as SURFING efficiently identify candidate subspaces that are expected to exhibit informative structure without restricting on a specific nature of the structure. Specifically, interactively detecting and understanding relevant structures in subspaces is an explicit goal of our system. Our interactive support allows users to condense and compare subspaces, and even groups in data. Thereby, we close the analytical loop from algorithmic search of subspaces to sense-making by the user. Subspace search algorithms are very useful as a starting point. Since the identification based on interestingness is done heuristically, the search methods alone cannot solve the analytical problems at hand. To this end, capable visualanalytic systems need to be designed based on the output of the subspace search algorithm. We therefore designed, implemented, and applied an encompassing system design based on a subspace search method (exemplarily we used SURFING). It allows to explore HD data taking into account the curse of dimensionality and the possibility to find alternative clusters in different subspaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Limitations and Possible Extensions</head><p>We identify the following limitations and improvement opportunities for our approach.</p><p>Computational scalability. We designed and tested our system around data sets of moderate high-dimensionality of tens of dimensions. For higher-dimensional data, we will have to deal with scalability issues in (1) computational complexity of the subspace search and (2) scalability of the visual representation of subspaces. Regarding (1), the search space increases exponentially with dimensionality. Subspace search algorithms probably need more aggressive filtering mechanisms to keep the number of searched subspaces tractable. A dynamically adjustable threshold could be useful here. However, we still need to ensure that no relevant results are excluded. To this end, sensitivity analysis is needed.</p><p>Visual scalability. Regarding (2), also scalable visual representations are needed for higher-dimensional data. We need to scale with the number of subspaces and the representation of each subspace. Hierarchical grouping of subspaces is already included in our system to scale with the number of subspaces. The linearly sorted view per se does not scale with many subspaces, yet it can be restricted to the representative subspaces obtained from hierarchical grouping. Visual representation of subspaces takes place by projection to show the data points and an index view to show contained dimensions. In particular, the latter will only scale for a limited number of dimensions. How to design set-oriented views to compare many sets of dimensions is a challenging problem that if solved, would improve our tool.</p><p>Projection-based subspace representation. We currently represent the subspaces by MDS projections of the data residing in respective subspaces. However, projection typically induces loss in information, that could be incorporated in our visualization, e.g., by showing the stress values in an overlay visualization <ref type="bibr" target="#b23">[24]</ref>. In our experiments, MDS performed very well compared to using PCA. Yet, it would be interesting to test other projections. Also, other subspace representations besides scatterplots could be thought of, in essence similar to Value-and-Relation displays <ref type="bibr" target="#b32">[33]</ref>. Likewise, many different, useful similarity notions to group and compare subspaces, such as notions based on stress measures, implicit clustering structures, relations to outliers, Scagnostics features <ref type="bibr" target="#b31">[32]</ref>, etc. could be employed. Testing them in different application domains is considered valuable future work. We note that our analytical ap-proach can easily accommodate alternative subspace search algorithms, representations, and filtering options.</p><p>Interpretable Dimensions. To relate subspaces and data groups in subspaces, it is important for the analyst to be aware of the meaning of the dimensions of the respective subspace. Our index-based glyph does not convey information about the type of dimension. More semantically meaningful dimension representations would be useful. Detail-on-demand functions could be added to help the user interpret the involved dimensions and properties of the data points more efficiently.</p><p>Definition of interestingness and sensitivity to noise. Subspace search algorithms heuristically identify subspaces as interesting based on certain properties of object relations. Based on the user and application, additional interestingness formulations are possible and should be supported. Following best practices in data analysis, we have applied a data cleaning step (outlier and missing value removal) to our tested data before we fed it into our system. The SURFING algorithm is not robust with respect to missing values, whereas it seems to be robust with respect to outliers. The original paper does not discuss this aspect and we did not further investigate it. The projections used to represent data distributions in subspaces are sensitive to outliers and may generate clamped distributions if not pre-processed. We postpone the analysis of this problem to future work.</p><p>Automatic support for cluster comparison. Adding automatic clustering of data points in subspaces would be useful as a postprocessing step. Equipped with automatic clustering, we can colorcode the found clusters. This could lead to new visual-oriented interestingness measures useful for selecting interesting subspaces in the future. User interaction with the subspace search output could be a useful analytical feature for refinement. Allowing expert users to split or merge subspaces, or construct new subspaces by adding or removing dimensions, would be one option.</p><p>Usability and user adoption. Our current system design targets users with expertise in data mining. End-user applications, e.g., in Market Segment analysis, could benefit from subspace analysis. Yet we recognize that for end-users, the interface of our system would need to be customized, possibly. Our experience in collaborating with data mining experts showed that the tool can be useful not only for data exploration but also as an evaluation tool to assess the output generated by subspace analysis algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Visualization and Clustering of HD Data</head><p>Visualization of HD data is a long-standing research topic. Classic approaches include parallel coordinates, scatter plot matrices, glyph-based and pixel-oriented techniques <ref type="bibr" target="#b30">[31]</ref>. By an appropriate sorting of dimensions and mapping them to visual variables, these methods allow to overview and relate high-dimensional input data, however we may run into scalability problems for large numbers of dimensions or records. Dimension reduction methods such as PCA <ref type="bibr" target="#b13">[14]</ref> or MDS <ref type="bibr" target="#b7">[8]</ref> can be used to reduce the data to a smaller number of dimensions for subsequent visualization.</p><p>Identification and relation of groups of data is a key explorative data analysis task. Often, user interaction is needed to identify and revise the number and characteristics of data clusters found by automatic search methods. To this end, visual-interactive approaches are useful. Although, many methods have been proposed, we can only highlight few of them in an exemplary manner. In <ref type="bibr" target="#b24">[25]</ref>, interactive exploration of hierarchically clustered data along a dendrogram data structure is proposed to help users find the right level of clusters for their tasks. In <ref type="bibr" target="#b33">[34]</ref>, the parallel coordinates approach serves as a basic display to show data clustering results allowing to compare clusters along their high-dimensional data space. Also, 2D projections, possibly in conjunction with glyph-based representation of clusters, are widely employed, a recent example is <ref type="bibr" target="#b5">[6]</ref>.</p><p>These approaches to visualization and clustering in HD data spaces all have in common that they are based on a given full (or reduced) dimensionality of the input data set. Thereby, they show only a singular perspective of the usually multi-faceted HD data, that might not be the most relevant one. As we show in this paper, it is also useful to explore HD data for patterns in subsets of its full HD input space to increase potential data insight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Automatic and Visual-Interactive Feature Selection</head><p>In Machine Learning, feature selection is the problem of selecting from a large space of input features (or dimensions) a smaller number of features that optimize a measurable criterion, e.g., the accuracy of a classifier <ref type="bibr" target="#b17">[18]</ref>. Most automatic feature selection methods rely on supervised information (e.g., labeled data) to perform the selection. Therefore, they are not directly applicable to the explorative analysis problem. In existing works involving visual-interactive selections or comparison of features, the Rankby-Feature Framework <ref type="bibr" target="#b25">[26]</ref> provides a sorted visual overview of the correlation among pairs of features. In <ref type="bibr" target="#b12">[13]</ref>, the selection of input features was supported by a measure of the interestingness of the visual view provided by candidate features. An interactive dimensionality reduction workflow was presented in <ref type="bibr" target="#b11">[12]</ref>, relying on visual approaches to guide users in selecting features.</p><p>In <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b4">[5]</ref>, interactive visual comparison was proposed to relate data described in different given feature spaces based on 2D mappings and tree structures extracted from the different data spaces. Furthermore, in <ref type="bibr" target="#b16">[17]</ref> a visual design based on network and heat map visualization was proposed to relate clusterings in different subsets of dimensions. In <ref type="bibr" target="#b33">[34]</ref>, dimensions are hierarchically clustered based on a simple value-oriented similarity measure. Based on this structure, user navigation can take place to identify interesting subspaces. In a recent work <ref type="bibr" target="#b34">[35]</ref>, the output of this simple search method was visualized by tree-and matrixbased views, where each dimension combination was represented by a single MDS plot.</p><p>In summary, many of these methods are applicable to compare data regarding different criteria. However, most of them assume the feature selection to be performed globally and do not take the subspace search problem directly into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Subspace cluster analysis and visualization</head><p>As traditional full-space clustering is often not effective for revealing a meaningful clustering structure for HD data, in the emerging research field of subspace clustering <ref type="bibr" target="#b15">[16]</ref> several approaches aim at discovering meaningful clusters in locally relevant subspaces. The problem of finding clusters in HD data can be divided into two subproblems: subspace search and cluster search. The first one aims at finding the subspaces where clusters exist, the second one at finding the actual clusters. The large majority of existing algorithms considers the two problems simultaneously and produces a set of clusters, where each cluster is typically represented by a pair (O, D) with O being the set of clustered objects (rows of the original data table) and D being the subset of relevant dimensions (columns of the original data table). Several methods have been proposed, that differ to the clustering search strategy and constraints with respect to the overlap of clusters and dimensions <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref>.</p><p>Only few works to date have considered visualization support for subspace clustering. The VISA <ref type="bibr" target="#b0">[1]</ref> system uses visualization to help in interpreting the subspace clustering result. A global view shows the similarity between clusters in terms of the number of records and dimensions, and a detail view shows properties of individual clusters. A disadvantage of this approach is that no visualization or comparison for the data distribution in respective subspaces is supported. Heidi Matrix <ref type="bibr" target="#b27">[28]</ref> uses a complex arrangement of subspaces on a matrix representation based on the computation of the kNN in each subspace. The complex visual mapping scheme may not be easy to use and its effectiveness to the best of our knowledge has not been evaluated yet. <ref type="bibr" target="#b9">[10]</ref> proposes an approach for finding and visualizing interesting subspaces in astronomical data. Candidate subspaces are found from the data and ranked by a quality metric based on density estimation and morphological operators.</p><p>We note that if we apply one of these subspace clustering visualizations, we immediately inherit two main challenges of this paradigm that is still considered an open research issues, namely: the efficiency challenge (relating to subspace cluster search) and the redundancy challenge (relating to the typical redundancy of the outputs generated).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>We presented an encompassing visual-interactive system for subspace-based analysis in HD data. Subspace-based analysis can constitute a new paradigm for HD data analysis since informative structures in the data can be found and compared in different subspaces of a larger HD input space. We defined, implemented, and demonstrated an analytical workflow based on automatic subspace search. A larger set of automatically identified interesting subspaces is grouped for interactive exploration by the user. A custom subspace similarity function allows for comparing subspaces. Our approach is able to effectively pin down several interesting views and helps to come up with specific findings regarding similarities of groups in data. We discussed a set of possible extensions of the system, which could be addressed as future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Alternative data distributions and groupings</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Filtering cases that can be supported by our two defined subspace similarity functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Subspace representation by 2D scatterplots with dimension glyph. We can see two 5D subspaces (left) and one 4D subspace (right) in the visual representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 2 3 Figure 5 : ( 1 )</head><label>1351</label><figDesc>Linearly sorted view of subspaces for the 12D synthetical data set from<ref type="bibr" target="#b9">[10]</ref> showing the full result of SURFING, consisting of 296 subspaces. The selected subspace in this view is shown in a (2) single subspace view to enable interaction and in (3) a parallel coordinates view with the subspace dimensions as the first axes (highlighted), and all the other data dimension as the last axes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 : ( 1 )</head><label>61</label><figDesc>Subspace group view for the 12D synthetic data set with six subspace groups. (2) Single subspace view showing the representative subspace for the first group. (3) Details-on-demand in the parallel coordinates view for the selected subspace. (4) The MDS layout of the subspace search results based on their dimension similarity. (5) Group detail view for the three (orange, green, purple) subspace groups. (6) Hierarchical navigation buttons.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>(A) Interesting spotted subspace (Carbohydrat, Fibre) presenting two clusters. (B) Subspace (Carbohydarte, Lipid, Protein) in the same cluster group of (A) where the cluster structure changes. (C) Green marked third cluster in subspace from (B). (D) Subspace (Fiber, Protein,Vit D ) of orange color-framed subspace group, where the alternative clustering of points is visible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 : ( 1 )</head><label>81</label><figDesc>Linearly sorted view cut-out of subspaces for the 18D USDA Food Composition Data Set. The full result of SURFING, consisting of 216 subspaces. We see a rather high level of redundancy. Subspaces exhibiting more structure are found in particular at the mid and end positions in the ranking. Relying only on the numerically top ranked results, we would have omitted such interesting cases from the analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1 2 3 Figure 9 : ( 1 )</head><label>1391</label><figDesc>Grouped view of subspaces for the 18D USDA Food Composition Data Set with 12 group representatives. (2) The brown and orange group components are shown in the components view. (3) MDS Layout of the total number of subspaces with cross-colored group representatives.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The research leading to these results has received funding from the "SteerSCiVA: Steerable Subspace Clustering for Visual Analytics" DFG-664/11 project. We thank our colleagues Miloš Krstajić, Svenja Simon, and Leishi Zhang for their helpful comments on this project. We are thankful to Bilkis Ferdosi and Peer Kröger for sharing their subspace search implementations with us. The reviewers' comments were most helpful in improving this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visa: visual subspace clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="5" to="12" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Subspace selection for clustering high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kailing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth IEEE Conference on Data Mining (ICDM)</title>
		<meeting>the Fourth IEEE Conference on Data Mining (ICDM)</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">When is &quot;nearest neighbor&quot; meaningful?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Shaft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Database Theory (ICDT)</title>
		<meeting>the 7th International Conference on Database Theory (ICDT)</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="217" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Assisted descriptor selection based on visual comparative data analysis. Computer Graphics Forum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bremm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Landesberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="891" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Interactive visual comparison of multiple trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bremm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Landesberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heß</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Weil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hamacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST)</title>
		<meeting>IEEE Symposium on Visual Analytics Science and Technology (VAST)</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dicon: Interactive visual analysis of multidimensional clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2581" to="2590" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Entropy-based subspace clustering for mining numerical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="84" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Multidimensional Scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Chapman &amp; Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the Second ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Finding and visualizing relevant subspaces for clustering high-dimensional astronomical data using connected morphological operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Ferdosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Buddelmeijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Trager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H F</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B T M</forename><surname>Roerdink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST)</title>
		<meeting>IEEE Symposium on Visual Analytics Science and Technology (VAST)</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detection of orthogonal concepts in subspaces of high dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management (CIKM)</title>
		<meeting>the 18th ACM conference on Information and knowledge management (CIKM)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1317" to="1326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">DimStiller: Workflows for dimensional analysis and reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bergner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST)</title>
		<meeting>IEEE Symposium on Visual Analytics Science and Technology (VAST)</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Interactive dimensionality reduction through user-defined combinations of quality metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="993" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Principal Components Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ranking interesting subspaces for clustering high dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kailing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wanka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)</title>
		<meeting>the 7th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="241" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Clustering high-dimensional data: A survey on subspace clustering, pattern-based clustering, and correlation clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kröger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zimek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Knowledge Discovery from Data (TKDD)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="58" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparative analysis of multidimensional, quantitative data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Partl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1027" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Computational Methods of Feature Selection (Chapman &amp; Hall/Crc Data Mining and Knowledge Discovery Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Motoda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Chapman &amp; Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Relevant subspace clustering: Mining the most interesting non-redundant concepts in high dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the IEEE International Conference on Data Mining (ICDM)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="377" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discovering multiple clustering solutions: Grouping objects in different views of the data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th IEEE Conference on Data Mining (ICDM)</title>
		<meeting>the 10th IEEE Conference on Data Mining (ICDM)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1220</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiple non-redundant spectral clustering views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Dy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="831" to="838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Objective criteria for the evaluation of clustering methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">336</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Computer Program for Classifying Plants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">T</forename><surname>Tanimoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="issue">3434</biblScope>
			<biblScope unit="page" from="1115" to="1118" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Techniques for precision-based visual analysis of projected data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Landesberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bremm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Palgrave Macmillan Information Visualization</publisher>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="181" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Interactively exploring hierarchical clustering results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="80" to="86" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A rank-by-feature framework for unsupervised multidimensional data exploration using low dimensional projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Information Visualization (InfoVis)</title>
		<meeting>IEEE Symposium on Information Visualization (InfoVis)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Visual Languages (VL)</title>
		<meeting>the IEEE Symposium on Visual Languages (VL)</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Heidi matrix: nearest neighbor driven high-dimensional data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vadapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Karlapalem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery (VAKD)</title>
		<meeting>the ACM SIGKDD Workshop on Visual Analytics and Knowledge Discovery (VAKD)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">85</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hierarchical grouping to optimize an objective function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="236" to="244" />
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Interactive Data Visualization: Foundations, Techniques, and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Grinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Taylor &amp; Francis</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Graph-theoretic scagnostics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization (InfoVis)</title>
		<meeting>the IEEE Symposium on Information Visualization (InfoVis)</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="157" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Rundensteiner. Value and relation display for interactive exploration of high dimensional datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Information Visualization (InfoVis)</title>
		<meeting>IEEE Symposium on Information Visualization (InfoVis)</meeting>
		<imprint>
			<publisher>IEEE CS Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Visual hierarchical dimension reduction for exploration of high dimensional datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Rundensteiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Symposium on Data Visualization (VIS-SYM)</title>
		<meeting>the Symposium on Data Visualization (VIS-SYM)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Mds-tree and mds-matrix for high dimensional data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Symposium on Information Visualization (InfoVis)</title>
		<meeting>IEEE Symposium on Information Visualization (InfoVis)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Poster abstract</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
