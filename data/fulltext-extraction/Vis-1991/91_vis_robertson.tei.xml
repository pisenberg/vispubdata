<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distributed Visualization Using Workstations, Supercomputers, and High Speed Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Robertson</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lawrence Berkeley Laboratory</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Van</forename><forename type="middle">L</forename><surname>Jacobson</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lawrence Berkeley Laboratory</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">E</forename><surname>Johnston</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lawrence Berkeley Laboratory</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stewart</forename><forename type="middle">C</forename><surname>Loken</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lawrence Berkeley Laboratory</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">H</forename><surname>Theil</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lawrence Berkeley Laboratory</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">L</forename><surname>Tiemey</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lawrence Berkeley Laboratory</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distributed Visualization Using Workstations, Supercomputers, and High Speed Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Access to supercomputers via the high speed wide area networks being developed will enable sophisticated, interactive visualization on local workstations. As an experiment, Lawrence Berkeley Laboratory and the Pittsburgh Supercomputer Center collaborated to demonstrate the possibilities for such distributed applications. The test case was visualization of 3 0 magnetic resonance imaging (MRI) data, with a Cray performing surface reconstruction to generate a set of triangles. The resulting geometric data was sent to a local workstation to be rendered, with minor enhancements to current network protocols enabling effective utilization of the 45 megabit bandwidth of a T3 based network.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There is a class of scientific and research medical imaging problems that is currently done poorly or not at all due to limitations in computer networking, computational capacity, and the scientific software environment. This research imaging environment is characterized by three elements that are typically geographically dispersed. These elements (illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>) are:</p><p>1) the imaging device, and its associated control system. The data generated by such a device for a single time frame can be quite large, on the order of tens to thousands of megabytes. a supercomputer, necessary for processing speed and/or large memory, in order to interpret the data. a local workstation to perform the visualization necessary to understand the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>3)</p><p>highly complex imagery, to guide the operation of the imaging device, and directly for medical study, diagnosis, and treatment planning. Currently, the sources of data are either isolated from the supercomputers, or communicate over low speed networks; the supercomputers are at best connected to the graphics and analysis workstations via low to medium speed networks; and adequate graphics workstations are just becoming available.</p><p>NSFNet is in the process of upgrading its backbones from T1 (1 megabit per second) to T3 (45 megabits per second) lines. A sample medical application was devised to capitalize on the improved bandwidth that will be available over NSFNet, and to identify the bottlenecks that will still remain in the way of achieving the above scenario for scientific imaging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Application</head><p>The test case chosen, which utilizes items 2 and 3 from the list above, was visualization of a 3D MRI data set of the brain. The graphics workstation was located in Washington, D.C. during the Net '91 conference, and was connected to the Cray Y-MP at the Pittsburgh Supercomputer Center by a T3 line (see <ref type="figure">Figure 2</ref>).</p><p>A surface reconstruction method, Marching Cubes [ll, was used to generate polygonal data sets from the MRI grid. This is a compute-intensive algorithm, and was performed on the Cray. (The MRI data set resided at the same site.) The Cray acted as a compute server, generating triangles at various isosurface values on request by the client graphics workstation, which then rendered the triangles. A graphical interface on the   workstation allowed a user to interactively explore the geometry of the brain, sending new parameters to the Cray for re-rendering as the exploration proceeded. Even though this process was not real time, it would not have been practical at all over a lowbandwidth wide area network timing considerations are considered in the sections below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>USE OF A GIGABIT NETWORK FOR RESEARCH MEDICAL IMAGING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Enhancements to Network Protocol</head><p>As network speeds increase, throughput becomes limited by the speed-of-light propagation time between the communicating computers. The standard Jntemet data transfer protocol, TCP/IP, can send at most 64-of data per round-trip-time (twice the propagation time) and, in practice, the sustained throughput will be at most half this theoretical maximum. The measured round-trip-time between the Net '91 show floor and PSC was 36ms so the maximum possible network throughput for standard TCPD was 15Mb/s, less than 1/3 of the 45Mb/s NSFNet capacity, and the expected throughput was 7Mb/s, less than the capacity of the show's local Ethemet (Note: Mb == Megabit; MB == MegaByte).</p><p>Working closely with Cray Research and Sun Microsystems, we implemented the TCP/IP extensions defined in <ref type="bibr">RFC1072 [21 and</ref><ref type="bibr">RFC1185 [3]</ref>. These extensions remove the 64KB per round-trip-time limit and allow TCP/IP to run at the full speed of the underlying network, independent of the end-to-end propagation time. Our network throughput was limited, unfortunately, by the lOMb/s bandwidth of the show Ethemet but the extended TCP/IP (and the T3 NSFNet) performed flawlessly, completely saturating the local Ethemet during transmission of the triangle data from PSC to Washington D.C. With the extensions, the 1000 mile separation between the PSC Cray and and the local Sun workstation ceased to be a consideration and the performance was limited solely by the reconstruction speed on the YMP and the rendering speed on the workstation. (Detailed network traffic traces showed that while we would send 1MB bursts of data (1MB was the network buffer size on the Cray &amp; Sun) at a sustained lOMb/s, these would be followed by long pauses while the triangles in the buffer were rendered. This bottleneck in the reconstruction / rendering reduced the long-term average network throughput to a mere 3.5Mb/s -slightly more than twice the total capacity of the T1 NSFNet.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Analysis</head><p>The improved bandwidth of wide-area networks and performance of network protocols was taken advantage of in this test case.</p><p>Other bottlenecks emerged, which require providing faster processing through both improved computer architecture and software algorithms.</p><p>The main bottleneck was the speed of the particular graphics workstation used in rendering mangles; a speed of around 10,000 triangles per second was typical. Considering that the surface reconstruction implementation used on the MRI data yielded 100,000 to 200,000 triangles per isovalue, this is clearly insufficient for this application. Workstations now exist that have the rendering speed necessary, but are still out of the price range of most researchers.</p><p>Once fast enough workstations are available, the performance of the supercomputer will be the bottleneck for this application, and for volumetric applications as well.</p><p>A typical speed of 6 seconds was achieved by the Cray in generating the number of triangles mentioned above. We believe the performance could be improved with further work on the algorithm implementation. However, massively parallel architectures are necessary to achieve real-time analysis of the large amounts of data involved. For example, the particular data set used for the demonstration was 80x80~80; it was smoothed down from 256x256~124 to make the application feasible. Software for the above applications is beginning to be written for massively parallel architectures 143.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This example application demonstrated that wide-area networks are no longer the bottleneck to the type of distributed imaging applications envisioned above. Of the many scientific imaging scenarios that require the described architecture, medical research can provide a clear and immediate focus to drive and justify the computing development, and demonstrate the utility and importance of an integrated, distributed, high speed computing environment. High speed network testbeds and associated prototype applications are the first step in the process of enabling this technology.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2</figDesc></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Marching Cubes: A High Resolution 3D Surface Construction Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="163" to="169" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Braden</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
