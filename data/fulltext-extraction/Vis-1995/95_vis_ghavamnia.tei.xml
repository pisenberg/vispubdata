<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Direct Rendering of Laplacian Pyramid Compressed Volume</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">H</forename><surname>Ghavamnia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Regina Regina</orgName>
								<address>
									<postCode>S4S OA2</postCode>
									<settlement>Saskatchewan</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Direct Rendering of Laplacian Pyramid Compressed Volume</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Volume rendering generates 2D images by ray tracing 30 volume data. This technique imposes considerable demands on storage space as the data set grows in size. In this paper we describe a method to render compressed volume data directly to reduce the memory requirements of the rendering process. The volume data was compressed by a technique called Laplacian pyramid. A compression ratio of 10:l was achieved by uniform quantization over the Laplacian pyramid. The quality of the images obtained by this technique is virtually indistinguishable from that of the images generated from the uncompressed volume data. A significant improvement in computational performance was achieved by using a cache algorithm to temporarily retain the reconstructed voxels to be used by the adjacent rays.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Volume rendering is a technique for visualizing sampled scalar functions or vector fields of three spatial dimensions without fitting geometric primitives to the data. Early research focused mainly on the problems of color and opacity assignments to voxels and the 2D projection of the resulting colored semi-transparent volume <ref type="bibr" target="#b6">[7]</ref>. Rendering time grows linearly with the size of the volume data. Several later works addressed the rendering efficiency problem. Levoy <ref type="bibr" target="#b7">[8]</ref> employed a pyramid of binary volumes to encode spatial coherence present in the data and to render volume data in a front-to-back order. <ref type="bibr">Laur and Hanrahan [6]</ref> presented a hierarchical splatting method for volume rendering with a progressive refinement capability. Wilhelms [13] studied a back-to-front projection method which allows the polygon rendering power available in most modern graphics workstations to be utilized. More recently, a new algorithm was presented for vol-Xue D. Yang</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Department of Computer Science</head><p>University of Regina Regina, Saskatchewan S4S OA2</p><p>ume rendering that reduced the time of rendering close to real time <ref type="bibr">[5]</ref>. Three dimensional volume data, such as computed tomography (CT), are very space consuming. For example, a CT data typically consists of 256 slices of 256 x 256 gray level images with an 8-bit quantized voxel value. The total size of such an image is 16 megabytes (MB). Rendering algorithms, such as <ref type="bibr" target="#b6">[7]</ref>, construct a shaded color volume of the same size during the rendering process. Hence, the space requirement is essentially doubled. Thus, space efficiency is an important issue in volume rendering.</p><p>While rendering performance has been constantly improving, little attention has been paid to the problem of space efficiency. This problem was addressed in <ref type="bibr">[ll]</ref> by using vector quantization to compress volume data. Since this technique [ll] is very lossy, the quality of the images is the main drawback. <ref type="bibr">Muraki's algorithm [lo]</ref> using wavelet transforms takes more than ten minutes to create images for edge detection. Volume data compression can also be achieved by using Fourier transforms [9, 121. However, it has an inherent problem of composing shaded color values along the depth in the frequency domain.</p><p>In this article, we are focusing on facilitating the direct rendering of compressed volume data. The Laplacian pyramid compression technique was chosen due to its simple hierarchical computational structure and its capability to fulfill following criteria.</p><p>A fairly good compression ratio of volume data can be achieved. Each voxel value can be reconstructed on the fly during the rendering process to avoid reconstruction of the whole volume data. The standard spatial domain shading models can be supported by the new representation in the rendering process. Also, progressive rendering can be supported.</p><p>With such a representation the compressed volume data can be efficiently transmitted across the network, and stored externally (on disks), as well as internally (in main memory). The second criteria is particularly attractive because it will allow higher resolution volume data of much larger sizes to be handled on the current workstations.</p><p>It also opens the possibility of doing volume data visualization on popular personal computers, making the volume rendering technology accessible to a much wider range of users.</p><p>The paper is organized as follows. The compression of 3D volume data by the Laplacian pyramid is described in Section 2. The method for the direct rendering of Laplacian pyramid compressed volume data as well as the cache algorithm for performance improvement are presented in Section 3. The implementation and the experimental results along with a discussion of progressive rendering are presented in Section 4. Finally, the summary and conclusions are given in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Laplacian pyramid</head><p>The Laplacian pyramid [2] is a compression technique to remove image correlation known as interpixel redundancy.</p><p>Although it is not the most advanced image compression technique available today, it has a unique important position in the development of compression techniques from the first generation to the second generation [3, 41. Our particular interest in this technique is based on the match between a number of properties of this model and the needs of our volume rendering task. A brief review of the original Laplacian pyramid model for 2D image compression is presented along with a discussion of its extension to 3D volume data.</p><p>Given an original image, go, of dimension N x N a low-pass filtered image, gi, of dimension T x T can be generated by using a Gaussian low-pass filter called REDUCE(). This is done by convolotion of go with a 5 x 5 Gaussian low-pass kernel:</p><formula xml:id="formula_0">Sl(i,d = 2 w(m,n).go(2i+ m,2j+n) (1) m=-2 n=-2</formula><p>where w(m, n) is the Gaussian low-pass kernel, and ;, j = 0, 1, . . . . $! -1. In general, the Gaussian pyramids are generated by successively application of the Gaussian low-pass filter:</p><formula xml:id="formula_1">gk = REDtJCE(gk-1)<label>(2)</label></formula><p>If gi is considered to be an approximation (or prediction) of go, the error, lo, of dimension N x N is defined to be go-EXPAND(gl),</p><p>where the function EX-PAND() expands the dimension of gi to the same dimension as go before the subtraction. EXPAND() is essentially the reverse process of the above low-pass computation, generating a gb of dimension N x N:</p><formula xml:id="formula_2">gh(i,j) = 4 2 2 uJ(",n).gl (T,T) m=-2 ?I=-2 for i,j = 0, 1, . . . . N-l.<label>(3)</label></formula><p>The gi can be low-pass filtered again, producing gz of dimension $ x $. Similarly, 11 of dimension g x + can also be computed by gl-EXPAND(g2) (in general, lp = g,-EXPAND(gp+l)).</p><p>By repeating the above process le times, two series of successively half-sized images are generated:</p><formula xml:id="formula_3">gO,gl,...,gk<label>(4)</label></formula><p>called a Gaussian pyramid, and</p><formula xml:id="formula_4">lO,ll,.. .,lk<label>(5)</label></formula><p>called a Laplacian pyramid. This process is illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. The technique of subtracting a predicted value from each image pixel, as in the Laplacian pyramid, removes much of the interpixel correlation.</p><p>Decorrelation also results in a concentration of pixel values around zero in li, and therefore, in the reduction of variance and entropy (see [2] for a detailed description). This suggests that the average number of bits/pixel for encoding li can be significantly reduced by information coding theory <ref type="bibr">[2]</ref>. By using variable length coding, maximum compression of li can be achieved. A drawback of doing this is the high computational costs in both the encoding and decoding processes. <ref type="bibr">Burt [2]</ref> suggested an approximate compression method which uniformly quantizes the pixel values in each level of the Laplacian pyramid. This introduces quantization errors, but with the proper choice of the number and distribution of quantization levels, the degradation can be made very small (5 1%). Th e compression ratio achievable by this technique is around 1O:l.</p><p>Given a Laplacian pyramid (lo, Ii, . . . , lk), the original image TO can be reconstructed by the reversed process of the above computation. By definition rk = lk andforeachi= k-l,k-2,...,0therg</p><p>iscalculated by T; = l;+ EXPAND(?'i+l). The encoding and decoding are shown in <ref type="figure">Fig</ref> The above Laplacian pyramid compression technique for 2D image can be extended easily to 3D volume data. The previous 5 x 5 Gaussian low-pass filter in 2D is replaced by a 5 x 5 x 5 Gaussian low-pass filter in 3D. By convolotion of a 3D volume data with such a 3D low-pass filter, a low-pass filtered volume data with half-sized dimensions can be generated. A compression ratio of 1O:l was achieved with uniform quantization for the testing CT volume data in our experiment with a root mean square error of 1.3.</p><p>It is noted [14] that the 5 x 5 x 5 operator is separable, i.e., it can be decomposed into products of three 1D operators. Thus, the low-pass filtering process can be done by using a 1D operator in three passes along the x, y, and z dimensions, respectively. The result is a constant speed up in the reconstruction process by roughly a factor of 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Rendering of compressed volume data</head><p>Due to the huge amount of memory space used in volume rendering, conventional techniques which are run on ordinary systems are limited by data size. This problem motivated us to develop a new technique to reduce the memory space requirement. Instead of hav-ing all the volume data available during the run time, we reconstruct each voxel value on the fly from the Laplacian pyramid compressed volume data.</p><p>The volume rendering algorithm used in this article is adapted from Levoy's method <ref type="bibr" target="#b6">[7]</ref> which is briefly described as follows:</p><p>1. Cast rays from a viewpoint (perspective projection) through the pixels on to the view plane. Each ray is represented by a parametric line equation, with parameter t = 0 at the viewpoint.</p><p>2. Compute the intersection points between the ray and the volume boundary, denoted by tl and t2, if any.</p><p>3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Ray trace the volume data from the entry point (tl) to the exit point (ta), while computing density (cri) and color (ci) a.t a fixed sampling step size along the ray. The density of each point (t) is computed by the trilinear interpolation of its neighbors and the color of each voxel is computed by using the Phong shading model <ref type="bibr">[l]</ref>.</p><p>Compute the final color value of each pixel on the view plane by composing the densities and colors along the ray with the following iterative formula:</p><formula xml:id="formula_5">f-d(i + 1) = f-d(i) + aici(l -a-d(i)) (6) a-d(i + 1) = cl!i + (1 -a-d(i))<label>(7)</label></formula><p>where f-d is final density and a-d is accumulated density.</p><p>3.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reconstruction of the voxel value on the fly</head><p>In step 3 of the above algorithm, the rendering process accesses the voxel value by reconstructing it on the fly in the following manner:</p><p>Assume a Laplacian pyramid (lo, 11, . . . . lk), with k + 1 levels, is given and a voxel (~0~~0 ,zo) is to be reconstructed. According to Equation (2), the 5 x 5 x 5 neighbors of (~o,yo,zo) at the next level are needed. Recursively, these voxels can be reconstructed in turn from the next level. When the top level of the pyramid is reached, the needed voxel value is directly available from rk.</p><p>The main part of the computation is to reconstruct the small cubic volume data that contains the desired voxel <ref type="bibr">(ZO,YO,ZO)</ref>.</p><p>To do this the following steps are required:  It is easy to see <ref type="figure" target="#fig_2">(Fig. 3)</ref> that Xk, y,+ I and Zk can be computed by simply dividing $0, ye, and z. by 2".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EXPAND(2k,yk,Zk)</head><p>is combined with the corresponding subvolume in lk-i, to give the subvolume of 2 x 2 x 2 of (Xk</p><formula xml:id="formula_6">-1,&amp;-1,&amp;-i) in Q-1.</formula><p>3. Repeat step 2 until the bottom level is reached. It is a subvolume of size 2" x 2k x 2" containing the desired voxel (xs,ye,zs).</p><p>Step two and three are illustrated in <ref type="figure">Fig. 4</ref>.</p><p>The top level volume rendering algorithm used in our experiment is adapted from Levoy's method <ref type="bibr" target="#b6">[7]</ref>. Two modifications have been done in that algorithm. Each voxel value is reconstructed from the Laplacian pyramid, instead of a simple 3D matrix access. The shaded color value at each voxel is also computed on the fly rather than by accessing a pre-computed color volume. <ref type="figure">Fig. 5</ref> shows two images resulting from the rendering a volume data (CThead).</p><p>This CThead volume data is from the Chapel Hill Volume Rendering Test Data set, the courtesy of the University of North Carolina.</p><p>It consists of 113 slices of 256 x 256 Xray CT images. Image <ref type="figure">Fig. 5(a)</ref> is generated by the level k</p><formula xml:id="formula_7">level k -1 level k -2 level k -3 l l l level 0 2k x 2k x 2"</formula><p>Figure 4.</p><p>Step two and three of reconstruction operation.</p><p>conventional algorithm ( <ref type="bibr" target="#b6">[7]</ref>) with the original volume data. Image <ref type="figure">Fig. 5(b)</ref> is generated by the new algorithm with Laplacian pyramid compressed volume data. The time for generating image (b) on a Silicon Graphics Indigo machine is tens of hours while image (a) takes around one minute running on the same machine. This performance is a completely unacceptable. However, this extremely poor performance is not surprising because there is a huge overhead due to the reconstruction of each voxel several times. To improve the performance, a caching method was developed to maintain the reconstructed voxels during the ray tracing process to be used by the adjacent rays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cache data structure</head><p>The voxel values reconstructed along one projection ray are very likely to be used for adjacent rays. This observation motivated us to reduce the number of reconstruction for adjacent rays by using cache memory to keep reconstructed voxels. In fact the main goal of using cache memory is to reduce the reconstruction overhead which is a bottleneck in a direct rendering algorithm.</p><p>For this reason, after a subvolume of voxels is reconstructed, it is temporarily buffered in a cache memory, instead of being discarded right away. When the tracing of one projection ray is completed, a sequence of subvolumes will be temporarily maintained in the cache memory in a sorted structure along the depth, while the boundaries of the reconstructed subvolumes are saved in an array called buffered-subvolume. For the adjacent projection ray, any desired voxel is tested first against the buffered-subvolume array. Then, if the requested voxel is within the existing boundaries of the array, the voxel value can be retrieved from the cache. Otherwise, the reconstruction procedure is invoked. The newly reconstructed subvolume will be buffered.</p><p>It should be noted that a basic assumption in the current research is that a limited size of main memory is available during the volume rendering. Thus, the free memory space that can be used for caching reconstructed subvolumes will be limited. The question that should be addressed is the proper size of the cache. In the following, the structure of the cache is presented and the size requirement is explained.</p><p>In a pyramid with k + 1 levels (0, 1, . . , k), the size of each reconstructed subvolume is 2" x 2k x 2", as explained in the previous section. If there are 2" voxels in the depth of the volume data, we have 2"-k subvolumes to be buffered in cache. It is obvious that for the next adjacent ray many voxel values are available from the cache. Therefore, the number of reconstruction call is reduced dramatically.</p><p>In general, the number of subvolume reconstructions across the current row is 2m-k x 2n-k assuming that there are 2n voxels along the row.</p><p>If we keep all the reconstructed subvolumes in the first row (2m-k x 2n-k ) along the depth, the reconstruction procedure will not be called for the rendering of the next 2" -1 rows, on the average. To keep all the reconstructed subvolumes along the depth of a row, the size of cache memory should be 2'+" x 2n-k subvolumes.</p><p>Ideally speaking, by using this caching method, we may reduce the number of reconstruction calls by a factor of 2" x 2" x 2k. In this case we do not have any redundant reconstruction.</p><p>Therefore reconstruction is called 2m-k x 2n-k x 2pmk times instead of 2m x 2" x 21, times for a volume data of size 2" x 2" x 2P. For example, a volume data of size 2* x 2* x 2* (16 MB) compressed by the Laplacian pyramid with 6 levels (IT: = 5) needs 23 x 23 subvolumes of size 25 x 25 x 25 bytes (2 MB) as the cache memory. If the ideal required cache size is not available, the performance of the rendering algorithm will be degraded due to redundant reconstruction.</p><p>Since the cache memory is capable of keeping 2m-k x 2n-k subvolumes of size 2" x 2" x 2") the size of the buffered-subvolume array should be 2"-" x 2n-k bytes to hold the boundaries of the reconstructed subvolumes stored in the cache memory. For any desired voxel to be reconstructed, it is first tested against this array to see if the existing reconstructed subvolumes contain this voxel. If the requested voxel exists, a cache hit will occur and no new reconstruction will be needed. Otherwise, a cache miss will occur and a new subvolume containing the desired voxel will be reconstructed.</p><p>The oldest subvolume will be substituted by the new subvolume in the cache memory and the buffered-subvolume array will be updated as well. As a result of this cache method, the CPU time for producing <ref type="figure">Fig. 5(b)</ref> has been reduced from tens of hours to less than two minutes while the quality did not change. The generality of the cache algorithm used in this paper was tested by choosing arbitrary viewpoints for the rendering algorithm. Their performance is presented in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation and results</head><p>The Laplacian pyramid compression technique was applied to a volume data (CThead) with 113 slices of 256 x 256 X-ray CT images. Uniform quantization was used for the Laplacian pyramid (Ic = 5 levels) such that the bin size of 32, 16, . . ., and 1 were chosen for lo, 11, "., and 1s respectively; that is, there are 8 gray levels at IO, 16 gray levels at Ii, . . ., and 256 gray levels at 2s. The resulting entropy was 0.464 bits/per pixel with the root mean square error of 1.3. Then, the Laplacian pyramid volume data was rendered by the new rendering algorithm.</p><p>In the ray tracing process (perspective projection), the projection ray was swept across the viewing plane. Voxel values were reconstructed on the fly from the Laplacian pyramid compressed volume data and temporarily maintained in a cache. In the next two subsections a set of experimental results is presented along with the discussion of progressive rendering based on the Laplacian pyramid technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head><p>To show the generality of the cache algorithm, we applied the volume rendering technique to the compressed volume data from four different viewpoints as shown in <ref type="figure">Fig. 6</ref>. The performance of the algorithm is summarized in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>The second column of the table shows the net CPU time in seconds for generating the corresponding images. It should be noticed that this time includes the reconstruction overhead, the calculation of the density and the shading of voxels on the fly, and the color integration. The third column shows the portion of the time in seconds that was spent on voxel reconstruction. The fourth column shows the average number of times that each individual voxel is reconstructed. It is obvious that not all voxels will be accessed during the ray tracing. For example, when the accumulated opacities exceeds a pre-specified threshold then the ray tracing stops. Therefore voxels beyond the stop point are not required. An accurate measurement of the average is the total number of reconstructed voxels divided by the number of distinctive voxels actually participating in the rendering process. This average indicates the number of cache misses that occurred during the rendering process. As it is shown, each voxel was reconstructed approximately once in our experiments which is almost an optimal performance. a way that if the size of volume data doubles in each dimension, the size of cache will be doubled in just depth and width. For example, we need eight MB for the cache when the size of the volume data is 512 x 512 x 512 (128 MB).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Progressive rendering</head><p>One of the advantages of the Laplacian pyramid or multiresolution compression techniques is the capability to support progressive rendering which is very useful for interactive visualization.</p><p>Suppose we want to render only the first three top levels of the Laplacian pyramid (out of six). This means that 15, 14, and 13 are participating in the reconstruction procedure.</p><p>The sizes of 15, 14, and 1s are 8 x 8 x 4, 16 x 16 x 8, and 32 x 32 x 16 respectively. The size of the final reconstructed volume data is 32 x 32 x 16. The image generated from this volume is shown in <ref type="figure" target="#fig_5">Fig. 7(a)</ref>.</p><p>Greater numbers of Laplacian pyramid levels, participating in rendering process, requires more cache memory and longer processing time. <ref type="figure" target="#fig_5">Fig. 7</ref>(b) to <ref type="figure" target="#fig_5">Fig. 7(d)</ref> show the images generated from participation of 4, 5, and 6 levels of the Laplacian pyramid respectively. The performance of the rendering of different levels of a compressed volume data is summarized  in <ref type="table" target="#tab_2">Table 2</ref>. For example, when four levels are used, the total rendering time (including reconstruction) is only about 1.5 seconds and the image <ref type="figure" target="#fig_5">(Fig. 7(b)</ref>) gives coarse 3D shapes at a reasonable level. However, when the number of levels is too small the generated image may be blurred <ref type="figure" target="#fig_5">(Fig. 7(a)</ref>). For interactive applications, coarse images can be generated during motion. The Laplacian pyramid is particularly suitable for this purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Summary and conclusions</head><p>Since volume data visualization deals with huge amounts of data, the efficiencies in both space and time are the key issues in this technique. While the rendering efficiency in time is constantly improving [5], little attention has been paid to the problem of space efficiency. This motivated us to find an efficient algorithm that uses much less space than is used normally while at the same time reducing the overhead cost (time) of reconstructing voxels on the fly.</p><p>In this paper, a compression technique called Laplacian pyramid is modified and used to compress a 3D volume data (CThead). Then the rendering algorithm is applied to the compressed volume data directly. Voxel values are reconstructed on the fly. An efficient cache algorithm was developed to temporarily maintain the reconstructed subvolumes to reduce redundant reconstruction.</p><p>As is shown in previous sections, the quality of the images generated by this algorithm using the compressed volume data is virtually indistinguishable from that of the images rendered by the conventional algorithm using uncompressed volume data, while the space requirement for the new algorithm is about l/10 of the original.</p><p>It is a trade off between space and time in our algorithm. While we can save a significant amount of space, especially for a large volume data set, reconstruction of voxel values introduces overhead.</p><p>Two recent papers [lo, 111 have addressed similar issues. <ref type="bibr">Ning [ll]</ref> used a vector quantization technique to compress the scalar samples and the recomputed surface normal field (for shading). The rendered images are visibly different from the original ones and the time required for rendering a 1283 volume data is around 55 seconds. <ref type="bibr">Muraki [lo]</ref> compressed volume data by wavelet transforms. His algorithm took more than 10 minutes on a HP9000/735 workstation, while we need 10 seconds to render a compressed volume data of size 128 x 128 x 64 as it is shown in <ref type="table" target="#tab_2">Table 2.</ref> In summary, the new volume rendering algorithm satisfies the criteria proposed in the introduction section.</p><p>It may be used in several applications such as: visualization of large volume data sets on current workstations, visualization of CT data on personal computers, and interactive visualization.</p><p>At the current stage, we have not used any auxiliary structures used in the other previous work, such as: pre-computed shading color volume [5] and octree structure <ref type="bibr">[B]</ref>. Further study might include auxiliary structures, which may further improve the performance of our technique. Also, due to the similar computational structure between Laplacian pyramid and wavelet transforms, we are planning to do a more comprehensive comparison and fine analysis of the two models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Processes of generating lo.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2. A summary of the steps of encoding and decoding in Laplacian pyramid.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Step one of reconstruction operation, 1. Find the voxel (cube of size 1 x 1 x 1) from the top level, T,+, whose Laplacian reconstruction contains the voxel (ze,ye,ze). To find this, we map the indices 20, ~0, and zs from the bottom level, TO, to indices xk, &amp;, and .&amp; in the top level, rk.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 5. Volume rendering of CThead of size 256x256~113.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7</head><label>7</label><figDesc>Figure 7. Volume rendering of different levels (out of 6) of compressed data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(cl</cell><cell>(4</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Figure</cell><cell>6. Rendering</cell><cell>of 3D compressed</cell><cell>data</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">from different</cell><cell>viewpoints.</cell></row><row><cell></cell><cell>. Performance</cell><cell>of rendering</cell><cell>algorithm</cell></row><row><cell>shown</cell><cell>in Fig. 6.</cell><cell></cell><cell></cell></row><row><cell cols="4">In our example, we used a cache memory of size</cell></row><row><cell cols="4">23 x 23 x 25 x 25 x 25 (2 MB). The Laplacian pyramid</cell></row><row><cell cols="4">needs one MB. The cache structure is designed in such</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">. Performance</cell><cell></cell><cell cols="2">of rendering</cell><cell cols="2">algorithm</cell></row><row><cell>shown</cell><cell cols="2">in Fig. 7.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Size</cell><cell>Total</cell><cell>(s)</cell><cell>Reconst.</cell><cell>(s)</cell><cell>Avg.</cell><cell>MB</cell></row><row><cell cols="2">32 x 32 x 16</cell><cell>0.51</cell><cell></cell><cell>0.23</cell><cell></cell><cell>1.044</cell><cell>0.05</cell></row><row><cell cols="2">64 x 64 x 32</cell><cell>1.3</cell><cell></cell><cell>0.7</cell><cell></cell><cell>1.065</cell><cell>0.1</cell></row><row><cell cols="2">128 x 128 x 64</cell><cell>10</cell><cell></cell><cell>5</cell><cell></cell><cell>1.061</cell><cell>0.8</cell></row><row><cell cols="2">256 x 256 x 128</cell><cell>110</cell><cell></cell><cell>51</cell><cell></cell><cell>1.062</cell><cell>3</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)1070-2385/95 $10.00 Â© 1995 IEEE</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported in part by NSERC Research Grant OGP0105708, Canada, and by the Ministry of Culture and Higher Education of Iran.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Illumination for Computer Generated Pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bui Tuong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>CACM</publisher>
			<biblScope unit="page" from="311" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Laplacian Pyramid as a Compact Image Code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Burt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Communications</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="532" to="540" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image Data Compression: a Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1981" />
			<biblScope unit="page" from="349" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Second Generation Image Coding Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ilonomopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE</title>
		<meeting>IEEE</meeting>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="page" from="285" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering Using a Shear-Warp Factorization of the Viewing Transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH &apos;94</title>
		<meeting>SIGGRAPH &apos;94</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical Splatting: A Progressive Refinement Algorithm for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ham&amp;an</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="285" to="288" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Display of Surface from Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Efficient Ray Tracing of Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="261" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fourier Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">A CM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="250" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multiscale 3D Edge Representation of Volume Data by a DOG Wavelet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muraki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of Symposium on Volume Visualization &apos;94</title>
		<meeting>eeding of Symposium on Volume Visualization &apos;94</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering of Compressed Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hesselink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization &apos;93</title>
		<meeting>IEEE Visualization &apos;93</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Frequency Domain Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tots&amp;a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRA PH &apos;93</title>
		<meeting>SIGGRA PH &apos;93</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Coherent Projection Approach for Direct Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="284" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Comparative Study of Multi-Resolution Image Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghavamnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Wescanex &apos;95</title>
		<meeting>IEEE Wescanex &apos;95<address><addrLine>Winnipeg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
