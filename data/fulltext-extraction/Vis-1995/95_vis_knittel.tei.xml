<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">High-Speed Volume Rendering Using Redundant Block Compression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giinter</forename><surname>Knittel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">WSI I GRIS t University of Tiibingen</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">High-Speed Volume Rendering Using Redundant Block Compression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>We present a novel volume rendering method which ojfers high rendering speed on standard workstations. It is based on a lossy data compression scheme which drastically reduces the memory bandwidth and computing requirements of perspective raycasting. Starting from classified and shaded data sets, we use Block Truncation Coding or Color Cell Compression to compress a block of 12 voxels into 32 bits. All blocks of the data set are processed redundantly, yielding a data structure which avoids multiple memory accesses per raypoint. As a side effect, the tri-linear interpolation of data coded in such a way is very much simplified. These techniques allow us to perform walkthroughs at interactive frame rates. Furthermore, the algorithm provides depth-cueing and the semi-transparent display of different materials. The algorithm achieves a sustained frame generation rate of about 2Hz for large data sets (-2od) at an acceptable image quality on an SGI Indy workstation. A number of examples are shown.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A volume visualization system, be it software or hardware, should provide support for both of the two basic functionalities of volume visualization: the segmentation, or classification of structures of interest, and their meaningful display on the output device. In the ideal case, the user is placed in a closed loop with the system, which directly responds to changes in visualization parameters. This is especially important in case the contents of the data sets are unknown a priori (e.g., in scientific visualization).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>t Universitit Tiibingen</head><p>Wilhelm-Schickard-Institut ftir Informatik -Graphisch-Interaktive Systeme (?%%I / GRIS) Auf der Morgenstelle 10, C9 D-72076 Tiibingen, Germany Phone: ..49 7071 29 5461 FAX: ..49 7071 29 5466 email: knittel@gris.informatik.uni-tuebingen.de www: http://greco.gris.infonuatik.uni-tuebingen.de/ Therefore, our previous work in this area was directed towards an integrated volume exploration system <ref type="bibr">[lo]</ref>.</p><p>However, there are a large number of applications where the kind of data is well known and always the same, as well as the structures of interest. Then the segmentation can be done once in a preprocessing step by optimized algorithms. In critical applications, where automatic classification is not reliable enough (e.g., in medical diagnosis), classification is even performed by human specialists in a time-consuming process. These applications thus require only a convenient and fast rendering tool.</p><p>In this work we introduce a new method to speed up the display of classified and shaded data sets, allowing for 0 walk-through examinations, 0 perspective projections, 0 depth-cueing, 0 the semi-transparent display of different materials and 0 interactive rendering speed even on low-cost workstations. For the design of a high-speed volume rendering system we must exploit the strengths and circumvent the weaknesses of the current computing machines. Considering the evolution in the workstation area, we can see a very dominant trend: 0 the CPU performance, the main memory capacity and the background storage (harddisk) capacity have increased dramatically, but Cl the memory bandwidth is stagnating on a low level. Thus, the design task is to reduce the data traffic between the CPU and the main memory, and to carefully evaluate the gains and losses of precomputation in terms of table access time vs. on-line computing time.</p><p>Our approach to fit the volume rendering process to the technological capabilities is based on a very simple data encoding scheme, which is discussed in detail in section 3. In section 2, we give a short overview of related work in this area and explain why we still felt that improvements ,were necessary. Image quality and rendering speed are illustrated with two examples from medical imaging in section 4.</p><p>Vector Quantization is the compression scheme proposed in <ref type="bibr">[15]</ref>. A vector in this context consists of the function values, the gradients and the gradient magnitudes of voxels in a certain block, for example a 2~2x2 subcube. The data set is transformed into vectors in a space filling manner, similar to the redundant coding scheme described here (see section 3.1). All vectors are then quantized into a small set of appropriately designed vectors, called a codebook, and each block is represented by an index into that codebook. For accelerated raycasting, the voxels of each entry in the codebook are shaded, and each codebook entry is individually raytraced to yield a pixmap for all occurrences of this codebook entry in the data set. For the raycasting itself, only the volume traversal and the compositing consume computing time.</p><p>However, the accelerated raycasting method works only for parallel projections, and the reported rendering times are still outside the interactive range.</p><p>Transforming the data set into the frequency domain is the basic idea in [16], adopted from <ref type="bibr">[14]</ref>. The energy of most signals is represented by a small number of low frequency components, a fact commonly exploited to reduce computing times and storage requirements. The projection slice theorem further reduces the costs of a projection to a 2D inverse Fourier transform. Using the derivative theorem (to obtain the gradient) and a view-dependent interpolation filter, all shading operations including depth-cueing are performed in the frequency domain. The rendering time is 2 seconds for a 2563 data set on a 5OMHz R4000 processor.</p><p>The authors themselves state that a major drawback of this method is the lack of occlusion, which removes the most important depth information.</p><p>In <ref type="bibr">[ll]</ref>, truly interactive rendering times are reported for parallel projections. In contrast to our approach, the authors use an object-order algorithm, where voxels are projected on the image plane rather than sending rays through the data. Prior to rendering, the data is aligned to the major axis of the view direction via a shear transformation. The resulting distorted image is then corrected using a 2D warp. Since the grid of voxels is aligned to the grid of pixels, the data set can be traversed in scanline-order. The authors use a run-length encoding of both the volume data set and the image, where the runs in the volume data set refer to transparent voxels and the runs in the image refer to opaque pixels. While processing the data set slice by slice in scanline-order, only visible, non-transparent voxels are visited, thereby effectively avoiding work in empty regions.</p><p>An advantage of this algorithm is that it includes fast shading and, as an option, fast classification. Thus, render-ing parameters can be adapted interactively. It achieves a frame rate of about 1Hz for large data sets on an SGI Indigo. For perspective projections, however, the proposed algorithm does not operate at such high speeds. The reported rendering times are above 3 seconds, a rate at which the user gets lost in the data set during a walkthrough.</p><p>Skipping regions of no interest in order to accelerate the rendering process can also be accomplished by the use of hierarchical data representations, e.g., octrees [3], <ref type="bibr">[13]</ref>, <ref type="bibr">[17]</ref>. However, the traversal through a hierarchical data structure is substantially more expensive than regular volume traversal. Depending on the data structure, this can considerably reduce the increase in rendering speed.</p><p>To avoid this disadvantage, a non-hierarchical distance coding is used in <ref type="bibr">[19]</ref>. In a second data set, each entry holds a pseudo-Euclidean distance to the next interesting voxel, which is zero in case the location is inside an interesting structure. Besides increased memory requirements, the drawback of this method is that rays are slowed down in the vicinity of an interesting structure, although they might never enter this region.</p><p>Other approaches reduce the number of steps a ray initially takes before entering an interesting region. PARC uses a set of polygons to better approximate the bounding volume of the data set <ref type="bibr">[l]</ref>, and a consecutively transformed C-Buffer holds the coordinates of the first intersection point of all rays with the objects in <ref type="bibr">[18]</ref>. However, these methods do not apply to the interior of hollow objects, e.g., the bone structure of a human skull.</p><p>We will now discuss our rendering method, which includes an advantageous coding scheme (section 3.1), a simplified tri-linear interpolation (section 3.2) and a special way of distance coding (section 3.3), which shows a number of advantages over the methods discussed above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithm</head><p>Processing starts with the classification of the data set. The voxels are grouped and tagged according to the material they belong to (e.g., bone and tissue, see <ref type="bibr">[5]</ref>). Each material is shaded separately according to whether only its surface should be displayed or its entire region [ 121. Thus, we use one opacity transfer function for each material having an upper bound equal to 1. Then the data is passed to the compression stage as explained in section 3.1.</p><p>The coded data set is then visualized using the raycasting algorithm. As stated earlier, our method offers arbitrary perspective projections and even walk&amp;roughs. Consequently, the raypoints do not coincide with the grid points and the data set is therefore tri-linearly interpolated at the resample locations. The visual appearance is further improved by performing depth-cueing, i.e., the mypoint intensity is attenuated according to a linear depth-cueing function. The material tags in conjunction with user-supplied transparency parameters allow us to display a given structure exclusively or to blend different materials during the rendering process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Compression and redundant Coding</head><p>The compression algorithms are borrowed from 2D image processing [2],[4] and are briefly reviewed for completeness.</p><p>Given an g-bit grey scale picture, the image is divided into 4x4 pixel blocks in which the pixels are grouped according to whether their greyvalue is above (or equal to) or below the average greyvalue q of the entire block. The result of this operation is a 16 bit decision vector D for each block. For each group of "lower" and "upper" pixels new greyvalues a and b are computed such that the block mean rl and the variance a2 are preserved. Given 9 and p as the number of pixels above and below the block mean, respectively, a and b are computed by: <ref type="formula">1</ref>The new values a and b are appended to the 16 bit decision vector to form the code element for one 4x4 pixel block. Using 8 bits for both a and b, this scheme achieves a reduction to 2 bits per pixel. The example demonstrated above is a variant of the block truncation coding (BTC) algorithm <ref type="bibr">[4]</ref>. Variations of block size, threshold value and computation scheme for a and b may produce better results depending on the specific application <ref type="bibr">[LX]</ref>.</p><p>Note that the decompression is particularly inexpensive: for each pixel in the image to be created, examine the corresponding decision bit and write either a or b.</p><p>The reduction to 2 bits per pixel can be maintained for 24-bit RGB pictures using the color cell compression (CCC) technique <ref type="bibr">[2]</ref>. The decision criterion now is the mean luminance % where Y = 0.3~R+0.59~G+O.11~B</p><p>(2)</p><p>The mean values R,, G, and B,, computed from the color components of the upper pixels, are assigned to the upper group. The same is done for the lower pixels. At this time, a 64 bit word DR,GtBtR, G,B, represents a 16 pixel block. In the next step, a set of 256 colors is constructed which best represents the set of colors present in the code elements, for example, by using the median cut algorithm <ref type="bibr">[9]</ref>. Each RGB-triple is then replaced by a pointer P into that look-up table, so that finally a 4x4 pixel block is compressed into a 32 bit code element DP, P, . Optionally, two separate color look-up tables could be used for the upper and lower colors.</p><p>The decompression expenses for CCC are slightly increased, since two table look-ups must be performed additionally for each pixel block.</p><p>The application of these compression techniques to volume data sets is straightforward. Since most workstations can handle 32 bit words conveniently, we chose to pack 12 voxels into one 32 bit code element, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>.  The decision vector occupies 12 bits in any given code element. Thus we can spend 10 bits to characterize the upper and the lower group. The actual contents of these bit fields depend on the kind of data set and the visualization method used. For example: 0 Blood vessels are commonly visualized from MR data sets using a maximum projection. The resolution of the scanning devices is typically 12 bits. Since only the maximum value along a ray is displayed, one can discard all voxels below a certain threshold during compression without losing relevant information. The remaining voxel values are then quantized in 10 bits, e.g., by a histogram equalization 171. 0 For grey-level gradient shading, the upper and lower bit fields hold the emitted light intensity in up to 10 bit resolution. 0 For colored gradient shading, pointers into 1K entry color look-up tables can be used. P, = 0 denotes an empty code element, i.e., all voxel values are zero. 0 If only 8-bit greyvalues or pointers are used, the remaining bits can be used to group the voxels into different materials. For each code element, the bits are set according to the material tag which occurs the most often, Consequently, each volume rendering method requires its own coding scheme. For each of the examples presented later, we will give some details about the coding process.</p><p>Considering just a single code element, we can see the first major advantage of this method: after performing a single memory access, all voxels needed for &amp;i-linear interpolation are available. To make this true for the entire data set, we have to compress and code all voxels redundantly, as shown in <ref type="figure">Figure 2</ref>. As a'consequence, all voxels   <ref type="figure" target="#fig_0">Figure 1</ref> are represented 8 times, and the voxels at position 4, 5,6 and 7 are stored 4 times in the coded data set. Thus, for original data sets of 16 bit voxels, the coded data set has just the same size. To be precise, if the original data set dimensions were xxyxz, the coded data set occupies 2xxxyxz bytes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">T&amp;Linear Interpolation revisited</head><formula xml:id="formula_0">Y b X</formula><p>The second major advantage of this coding scheme is that the t&amp;linear interpolation is simplified to the largest extent. Let's consider a volume cell with the eight greyvalues C,..C, at the corners as shown in <ref type="figure" target="#fig_3">Figure 3</ref>. </p><p>If all a, p and y have 4 bit precision, which is sufficient in most practical cases, then any given distribution of upper and lower values in (5) can give 4096 possible values for Ok. All in all, of depends on an 8 bit decision vector and three 4 bit offsets, giving a total of IM = 220 different configurations. Thus we can easily precompute the weightfactors for each possible configuration and store them in a table. Furthermore, as implied by (6), we do not store C, and C, in the code elements, but instead C,, and (C,-CL).</p><p>Then, a complete tri-linear interpolation is performed by Q assembling the weightfactor address from the decision vector and the offsets, For colored data sets, the code elements hold the color indexes P, and P,, which refer to R,G,,B, and R,GIBl, respectively, instead of the gmyvalues. Assuming 8 bits for both P,, and Pl and limiting the precision of u.+ to 5 bits, 2M = 221 different resulting colors exist. So, starting from intermediate, 256 entry color look-up tables for the upper and the lower colors of the data set, we precompute the weighted color look-up table and store it along with every coded data set. Thus, the costs of performing a @i-linear interpolation in a colored cell are: 0 the construction of the weightfactor address from the decision vector and the offsets, 0 one table look-up for the weight, 0 the construction of the weighted color address from the weightfactor and the color indexes and 0 one table look-up for the final color of the resample location. Thus, the processing of one resample location requires only one (in case P,;C, = 0), two or three memory accesses, and only a small amount of computation. The size of the tables presents no problem either: IMByte for the weights (if coded into 8 bits) for grey-level shading, and 8MByte for colored data sets (2M entries of 32 bits each, 8 bits for each component of the weighted colors, and remaining 8 bits are used for the weights).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Distance Coding</head><p>Classified and shaded data sets contain a high percentage of empty voxel blocks, for which P,;C,, = 0. In this case, the remaining bits of the code element are redefined. We define 8 overlapping neighborhood octants (corresponding to the 8 possible orientations of a ray in terms of the sign of its components) and count for each octant the number of raypoints which can be skipped safely due to an empty neighborhood (assuming the distance of two raypoints is smaller than 1). See <ref type="figure">Figure 5</ref> for an explanation in 2D. The largest step can be 8 resample locations if C,, or P, have 8 bits, or 4 raypoints if 10 bits are used for these quantities.</p><p>The advantage of this technique is that no separate acceleration data structure (e.g., an octree) is needed, and thus, skipping empty space requires neither additional memory capacity nor bandwidth. The spatial arrangement of objects in the neighborhood of an empty block is described more precisely as in [ 191, so that an unnecessary reduction of the stepsize in the vicinity of objects that will not be hit occurs less often.</p><p>The maximum stepsize of 8 (in grid units) is usually satisfactory except for the regions outside the bounding volume of the objects. Thus, techniques like PARC [l] can very well complement our method, and will be implemented in a later version.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Rendering</head><p>The frame generation routine consists of 3 nested loops, of which we'll discuss only the inner loop:</p><p>For each Line do . . . For each Pixel do . . .</p><p>For each Raypoint do . . .</p><p>We enter the inner loop with the coordinates X.a, I!p, 2.y of the first resample point (the intersection point with the bounding volume), the vector to the next raypoint A x,A y,A z, the number of raypoints, the orientation of the ray, the initial attenuation factor h and its increment A$ Linear depth-cueing [6],[16] is performed according to the nearest and the farthest point of the volume, as depicted in <ref type="figure">Figure 6</ref>: 0 i I <ref type="figure">Figure 6</ref>: Linear Depth-Cueing</p><p>We give the inner loop in pseudo-code with the example of the maximum projection (see <ref type="figure" target="#fig_6">Figure 7</ref>). Since the inner loop is very short, but dominates the pro- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance and Image Quality</head><p>Two examples from medical imaging are given: a MR study of the blood vessels of a brain, and a CT data set from a human skull, which has a hole due to an accident. The performance was measured on an SGI Indy with a 1OOMHz R4600 processor (32 KByte on-chip cache), no secondary cache and 80MByte main memory. Images were created by sending 128x128 or 256x256 rays through the data. In any case, the image was bi-linearly interpolated to 512x512 pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">MR Data Set: Blood Vessels of a Brain</head><p>The data set size is 256x256~162. The original voxels were given as 16 bit unsigned integers. All voxels having values below 20% of the maximum value in the original data set were set to zero. The data set was visualized using a maximum projection, where only the maximum value along a ray is displayed. The maximum projection in our implementation can be considered to be the worst case in performance, since each and every my must be followed until volume exit. A ray could be terminated if a value close to the largest possible number occurred, but the additional conditional branch in the inner loop didn't pay off. <ref type="figure">Figure 8a</ref> shows the back view of the head at a 128x128 sampling resolution. The front view in <ref type="figure">Figure 8b</ref> was generated by 256x256 rays. Comparing the two figures, we can see the helpful effect of depth-cueing and perspective as the only depth information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">CT Data Set: Skull with Fracture</head><p>The data set size is 256x256~216. Again the original voxels were 16 bit integers in the range from 0 (air) to 4095 (fillings in the teeth, from which the artifacts stem). The data set was divided into two separate materials, tissue (values in-between 200 and 1100) and bone (1170 to 3100). Each material was assigned a separate opacity transfer function, both strengthening the region boundaries. The bone surface, however, needs a stronger gradient to be visible. The material was given a "pleasing" color and shaded using six light sources at infinity. The occupied color space was very narrow, so that the color quantization losses were minimal.</p><p>For <ref type="figure">Figures 8c and 8d</ref>, the renderer was instructed to discard all voxels belonging to tissue. The bone was detected by a special threshold operator. After having found a user-defined threshold value, the operator proceeds through a small number of raypoints (typically 8) and returns the maximum value found within that distance.</p><p>For <ref type="figure">Figures 8e and 8f</ref>, practically the same was done to the tissue to display the skin only. <ref type="figure">Figures 8g and 8h</ref> were created by integrating the color intensities of the tissue and applying the threshold operator mentioned above to bone. The accumulated value of the tissue region was then blended with the returned value of the threshold operator according to a user-defined blending coefficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance</head><p>Rendering times are listed in <ref type="table" target="#tab_3">Table 1</ref>. Average frame rates refer to a round-trip around the z-axis.  We have presented a data encoding scheme which offers interactive rendering speed on today's workstations and real-time operation on tomorrow's. Image quality is still high, as can be seen in the color prints. The users are offered a large degree of freedom, since they can explore the data set by walking right through it. A disadvantage of this method is that the illumination is static, and does not change when the observer moves. The preprocessing step, especially the distance coding, requires further work. In the actual (unoptimized) implementation, preprocessing takes between 5 and 15 minutes, depending on the size of the neighborhood of each code element which is tested for being empty. Interactive preprocessing could be provided by faster algorithms, and by considering only a significant, but small subvolume of the data set to determine the final visualization parameters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Voxel Block and Decision Vector 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>:</head><label></label><figDesc>ode Element n+dim-x*dlm-y Code Element n+dim-x'dimredundant operation applies for y-direction as well</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure</head><label></label><figDesc>Figure 2: Redundant Block Compression at positions 0, 1,2,3, 8,9, 10 and 11 in Figure 1 are represented 8 times, and the voxels at position 4, 5,6 and 7 are stored 4 times in the coded data set. Thus, for original data sets of 16 bit voxels, the coded data set has just the same size. To be precise, if the original data set dimensions were xxyxz, the coded data set occupies 2xxxyxz bytes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>c3Figure 3 :</head><label>3</label><figDesc>Tri-Linear Interpolation IThe desired greyvalue C at the offset (a,P,y) within the cell is given by : only two different greyvalues C, and C, in any given volume cell, we can factor out (4) in 256 possible ways: c = c; (w,+wb+'..+w,)+cf.(wd+we+...+wf)(5)The weightfactors o, can be considered as the contents of the subvolumes shown inFigure 4sum up to 1. If wf is the compound weight for C,, then c = c; (l-w,) +c,*w, = q-w,. (q-c,)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>0</head><label></label><figDesc>one table look-up and 0 one multiplication and one subtraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure</head><label></label><figDesc>Figure 5: Distance Coding</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Pseudo-Code of the Inner Loop gram execution time, it is reasonable to optimize it on assembly language level. An assembler implementation was made for the MIPS R4000 processor family, which consists of exactly 112 machine instructions in the case of the maximum projection. All performance figures refer to this optimized assembly language version.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Rendering Times 5 Conclusion and Future Work</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)1070-2385/95 $10.00 Â© 1995 IEEE</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgments</head><p>This work was done for the research project SFB 328, funded by the German Science Foundation DFG, and was supervised by Prof. Stral3er. Thanks to Andreas Schilling for many fruitful discussions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards a Comprehensive Volume Ksualization System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Visualization &apos;92 Conference</title>
		<meeting>the IEEE Visualization &apos;92 Conference<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="13" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Defanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frederiksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Joyce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Leske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Sandin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">live Bit/ Pixel Full Color Encoding</title>
		<imprint>
			<date type="published" when="1986-08" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">215223</biblScope>
		</imprint>
	</monogr>
	<note>SIGGRAPH &apos;86 Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast Algorithms for Volume Ray Tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Danskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanraban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1992 Workshop on Volume Visualization</title>
		<meeting>the 1992 Workshop on Volume Visualization<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992-10" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Image Compression Using Block Truncation Coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Delp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">R A</forename><surname>Mitchell ; R</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH &apos;88 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1979-08" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
	<note>Computer Graphics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Hughes</surname></persName>
		</author>
		<title level="m">Computer Graphics: Pn&apos;nciples and Practice</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="727" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wintz</surname></persName>
		</author>
		<title level="m">Digital Image Processing</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the Implementation of a Block Truncation Coding Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Halverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Communications</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2482" to="2484" />
			<date type="published" when="1982-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Color Image Quantization for Frame Buffer Dispiay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Heckbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH &apos;82 Proceedings</title>
		<imprint>
			<date type="published" when="1982-08" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="297" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Compact Volume Rendering Accelerator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Straber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE 1994 Symposium on Volume Visualization</title>
		<meeting>the ACM/IEEE 1994 Symposium on Volume Visualization<address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering Using a Shear-Warp Factorization of the Viewing Transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH &apos;94 Proceedings</title>
		<imprint>
			<date type="published" when="1994-07" />
			<biblScope unit="page" from="451" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Display of Surfaces from Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="31" />
			<date type="published" when="1988-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficient Ray Tracing of Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="261" />
			<date type="published" when="1990-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fourier Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="250" />
			<date type="published" when="1993-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering of Compressed Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hesselink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Visualization &apos;93 Conference</title>
		<meeting>the Visualization &apos;93 Conference<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Frequency Domain Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Totsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH &apos;93 Conference Proceedings</title>
		<imprint>
			<date type="published" when="1993-08" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Octrees for Faster Isosurface Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Withelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="227" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Accelerating Volume Animation by Space-Leaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE &apos;93 Visualization Conference</title>
		<meeting>the IEEE &apos;93 Visualization Conference<address><addrLine>San Jose, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="62" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Acceleration of Ray-Casting Using 30 Distance Transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Zuiderveld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H J</forename><surname>Koning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization in Biomedical Computing</title>
		<meeting>Visualization in Biomedical Computing<address><addrLine>Chapel Hill, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page">335</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
