<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Hardware Acceleration Method for Volumetric Ray Tracing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">M</forename><surname>Sobierajski</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">GE Corporate Research &amp; Development Schenectady</orgName>
								<address>
									<postCode>12345</postCode>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><forename type="middle">S</forename><surname>Avila</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">GE Corporate Research &amp; Development Schenectady</orgName>
								<address>
									<postCode>12345</postCode>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Hardware Acceleration Method for Volumetric Ray Tracing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>In this paper we present an acceleration method for volumetric ray tracing which utilizes standard graphics hardware without compromising image accuracy. The graphics hardware is employed to ident@ those segments of each ray that could possibly contribute to the jinal image. A volumetric ray tracing algorithm is then used to compute the$nal image, traversing only the identi$ed segments of the rays. This technique can be used to render volumetric isosurfaces as well as translucent volumes. In addition, this method can accelerate the traversal of shadow rays when performing recursive ray tracing.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The ability to render large volumetric data sets quickly is an essential requirement in many engineering and scientific applications. This is a challenging demand, since the scientific user is typically unwilling to sacrifice the accuracy of the final image in order to decrease projection times.</p><p>One way to improve rendering performance is to take advantage of the graphics hardware supported by most workstations. Current workstations typically offer hardware methods for rendering geometric primitives, with depth buffering employed for hidden surface removal. This hardware can be used directly to render a set of geometric primitives that approximate the volume. Although there are many rendering algorithms that directly employ graphics hardware, none of these methods can be used to generate accurate images of both volumetric isosurfaces and translucent volumetric data. The marching cubes technique <ref type="bibr" target="#b7">[8]</ref> can be used effectively to render volumetric isosurfaces, but cannot adequately represent an amorphous object. A cell projection method <ref type="bibr" target="#b12">[13]</ref> or a polygonal splatting technique <ref type="bibr" target="#b5">[6]</ref> can be used to capture translucent volumetric data, but the resulting images are often unacceptable when sharp deta,ils are desired.</p><p>In contrast to hardware projection algorithms, a volumetric ray tracing algorithm is generally slower, but much more accurate and flexible <ref type="bibr" target="#b8">[9]</ref>. For example, the value returned by a ray-volume intersection may represent an isosurface intersection location, an accumulated color and opacity value, or the maximum value encountered along the ray. In addition, a ray tracing algorithm can be used to include global effects such as shadows and reflections in the final image.</p><p>The rendering method presented in this paper employs graphics hardware to accelerate volumetric ray tracing. An approximation of the volumetric data is projected using the graphics hardware, and the information stored in the color and depth buffers is used to reduce the amount of time required for a ray-volume intersection calculation. These rendering improvements are obtained by avoiding intersection calculations in regions of the volume that could not contribute to the final image. A classification of volume regions is given in Section 2. An algorithm that accelerates ray tracing with a depth buffer projection is described in Section 3. In Section 4, a color buffer version of this algorithm that improves rendering times for translucent projections is presented. These acceleration methods can also be used to reduce the time required to cast shadow rays in a ray tracing algorithm, as described in Section 5. The results of this technique are given in Section 6. Finally, some conclusions and future work are discussed in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Cell Classification</head><p>A volume is a 3D rectilinear array of scalar values that define some property, such as density or temperature, at discrete grid locations. An interpolation function is employed to define scalar values between grid locations in order to produce a scalar field. We have chosen to use trilinear interpolation for the work presented in this paper. However, the acceleration algorithms readily extend to handle other interpolation functions such as zero-order (nearest-neighbor) interpolation or tricubic interpolation.</p><p>Consider the example ray in <ref type="figure">Figure 1</ref> where a ray is cast through a volume and ray-isosurface intersection calculations are being performed along the ray. The cells encountered along the ray are shown as small cubes where the data samples that the define the scalar field within the (See color plates, page CP-5) cube are located at the eight vertices. The isosurface threshold value can be used to classify all cells in the volume as either "empty" cells, or "possibly contributing" cells. An empty cell is one where all eight vertices are either above or below the isosurface value, and therefore the surface does not pass through this cell. A possibly contributing cell is one that does contain the surface. For a specific ray, as shown in <ref type="figure">Figure 1</ref>, the possibly contributing cells can be further classified as either "non-contributing" or "contributing". The non-contributing cells, shown in light grey, indicate that a surface does pass through the cell, but the ray does not actually intersect that surface. The contributing cells, shown in dark grey, contain a surface that the ray does intersect. These cell classifications are also valid for volume rendering techniques where, for example, an accumulated color and opacity value is calculated instead of an isosurface intersection value. In this case, the empty cells contain only scalar values with zero opacity according to the opacity transfer function, while the possibly contributing cells contain scalar values with non-zero opacity. For a given ray, the contributing cells are those in which the ray encounters scalar values with non-zero opacity. The noncontributing cells are those which contain non-zero opacity values, but the ray does not encounter these values.</p><p>either contrihu empty Cj).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>tion of cells along a ray as non-contributing (a), or</head><p>The standard ray casting method considers all cells along a ray when searching for an isostiace intersection or accumulating color and opacity. The ideal ray caster would look only at the contributing cells to determine the final ray value. Unfortunately, the determination of whether a cell is contributing is dependent on the scalar values, the isosurface threshold value or opacity transfer functions, and the ray. Since the ray is typically different for every ray cast, it is difficult to know for a given ray which cells are contributing.</p><p>Alternatively, the determination of whether a cell is possibly contributing is independent of the ray direction.</p><p>Considering only the possibly contributing cells is equivalent to skipping the empty cells. There are various algorithms for quickly stepping through the empty cells. A hierarchical representation of the data could be constructed <ref type="bibr" target="#b5">[6]</ref>, and a ray traversal algorithm could be used to step through the cells at various levels. Unfortunately, for noisy data such as that acquired from confocal microscopy, the time required to move between levels in the hierarchy is sometimes greater than the time saved by the larger steps taken at the higher levels of the hierarchy. Another possibility is to construct a distance volume, where each cell contains the distance to the nearest possibly contributing cell [lo, 141. This method requires a significant amount of additional memory to store distance values, and the time required to build the distance volume may be prohibitively slow for interactively modifying the isosurface threshold value or opacity transfer functions. Algorithms that employ an object-order technique [4, 61 can compress the volume to remove empty cells, but cannot easily produce an accurate rendering of multiple overlapping volumes.</p><p>The goal of the work presented in this paper was to develop an algorithm that reduces the time required to cast a ray by avoiding empty cells. This algorithm can render volumetric isosurfaces as well as translucent volume data with no loss in image quality over standard ray casting. In addition, multiple overlapping volumes can be easily rendered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Depth Buffer PARC</head><p>In Polygon Assisted Ray Casting, known as PARC, graphics hardware is used to determine the distance to the closest and farthest possibly contributing cell along each ray <ref type="bibr">[l]</ref>. These distance values can be quickly obtained by projecting a simple polygonal model of the possibly contributing cells into standard zbuffer hardware.</p><p>The polygonal model consists of the rectangular polygons representing the "outer" faces of the possibly contributing cells. The outer faces are those that are shared beiween a possibly contributing cell and an empty cell. The polygonal model is projected first into a "near" zbuffer using the standard "less than" operator to capture the closest distance information, and then into a "far" zbuffer using a "greater than" operator to capture the farthest distance information. If a greater than operator is unavailable for zbuffering, the viewing matrix can be modified to produce inverted depth values.</p><p>Once the nearest and farthest distances have been computed for a ray, a cell stepping algorithm is used to evaluate the contribution of each cell between the bounding distances, as in the 2D example of an isosurface intersection shown in <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Far Distance 4</head><p>Viewing/Ray Nei Distance lso&amp;face <ref type="figure">Figure 2</ref>: The near and far zbuffers contain the closest and farthest distance to a possibly contributing cell along a viewing ray.</p><p>Isosurface intersection calculations are done on a cellby-cell basis along the ray, while samples are taken at uniform intervals along the ray for accumulation techniques. Early ray termination is possible, for example, when an isosurface intersection is detected, or the opacity along the ray reaches unity. If early ray termination does not occur, ray traversal ends at the far distance. In the special case where the eye point is located within a possibly contributing cell, the stepping algorithm must start from the viewing plane and can terminate at the farthest distance. The PARC ray tracing method is summarized in the algorithm shown in <ref type="figure" target="#fig_0">Figure 3</ref> Decoupling the ray casting and the shading processes allows for multiple overlapping volumes, even if the volumes require different ray casting functions <ref type="bibr" target="#b8">[9]</ref>. For example, a volumetric isosurface could intersect with a translucent volume. A standard ray tracing illumination equation is used for surface intersections <ref type="bibr" target="#b11">[12]</ref>, while a transport theory model is employed for rendering translucent data <ref type="bibr" target="#b2">[3]</ref>.</p><p>For large volumetric data sets, the number of geometric primitives in the simple polygon model often produces high hardware projection times that eliminate the savings gained during ray stepping. To reduce the number of polygons in the model, an m X y1 X p group of neighboring cells can be considered one "supercell". The interpolation function can be employed to generate supercells with noninteger m, 12, and p. A supercell is possibly contributing if it contains any possibly contributing cells, otherwise it is considered to be empty. The polygonal model is then created for the possibly contributing supercells, resulting in fewer geometric primitives, but generally longer ray segments between the near and far distances. <ref type="figure">Figure 4</ref> shows the same example as in <ref type="figure">Figure 2</ref>, except that a supercell size of 3 X 2 was employed.</p><p>Far Distance</p><p>Viewing/Ray Ne&amp; Distance lso&amp;face <ref type="figure">Figure 4</ref>: A 3 x 2 supercell is used to determine the near and far distances, resulting in less geometric primitives but longer ray segments than the example shown in <ref type="figure">Figure 2</ref>.</p><p>For small volumetric data sets, "subcells" can be created by sub-sampling the volume. This results in more geometric primitives and generally shorter ray segments. In general, the closer the polygonal model comes to accurately representing the possibly contributing regions of the volume, the higher the ratio of contributing to non-contributing segments along the ray, as can be noted by comparing <ref type="figure">Figure 2</ref> with <ref type="figure">Figure 4</ref>. Therefore a reduction in ray casting speed can typically be obtained at the cost of higher polygon projection times. The optimal number of geometric primitives mainly depends on the relative performance of hardware polygon projection versus software cell processing.</p><p>In theory, the PARC algorithm as described above will produce images identical to those produced by standard ray casting. In practice, allowances must be made for the inaccuracies found in hardware polygon scan-conversion to achieve the identical image. This can be accomplished by small changes to the position and size of the polygon to ensure that: ZS I Zi for all near buffer pixels, and zS 2 Zi for all far buffer pixels, where ZS is the scan-converted depth value, and zi is the ideal depth value for a pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Color Buffer PARC</head><p>The depth buffer PARC algorithm described in the previous section can be used to skip over the initial empty cells when performing volume rendering. This technique works well when rendering a volumetric isosurface, since the contributing cell with the actual intersection location is typically encountered at, or shortly after, the first possibly contributing cell. However, when performing a color and opacity accumulation method along the ray, the opacity does not typically reach unity at the first contributing cell. In fact, all contributing cells along the ray are often considered when computing the final ray accumulation value. This is also true of other ray-object intersection functions such as maximum value and average value calculations. Therefore, volumetric ray tracing would often benefit from the ability to skip over the empty cells that occur between the first and last possibly contributing cell. This capability can be achieved by making a modification to the PARC algorithm.</p><p>Instead of projecting the outer faces of the possibly contributing cells into a zbuffer, a polygonal model for the possibly contributing cells is projected into me color buffer. Rendering is performed so that the resulting bits for each pixel in the color buffer represent segments along the ray passing through that pixel. The value of each bit determines whether the corresponding ray segment encounters any possibly contributing cells. Using this information, intersection or sampling calculations can be avoided on the empty segments of the ray.</p><p>In order to obtain this color buffer, the possibly contributing cells are assigned color values according to their distance along the major viewing axis, as shown in <ref type="figure">Figure  5</ref>. The major viewing axis is the positive or negative axis of the volume that is most closely aligned with the viewing direction. For each plane i, 0 S i &lt; N, along the major viewing direction, the color value of the possibly contributing cells in that plane is 2' . To reduce the number of color values required, the first plane along the major viewing direction that contains at least one possibly contributing cell is considered plane 0.</p><p>The outer faces of the possibly contributing cells, and the faces that are shared by two possibly contributing cells of different color values, are projected without shading or depth buffering according to the currently defined viewing <ref type="figure">Figure 5</ref>: The color of a cell is determined by its distance along the major direction. The example colors given here are valid when 2 is the major axis. matrix. During projection, a bitwise OR operation is employed on the value currently stored in a pixel and the value being written to the pixel to determine the final pixel value. Only P planes of cells can be projected at once, where P is the number of color bits available for display on a workstation. After each set of P planes has been projected, the bits from the color buffer are saved. When all cells have been projected, the bits that are set in each pixel indicate the possibly contributing cells encountered along the ray that passes through that pixel, as shown in <ref type="figure">Figure   6</ref>.</p><p>Each bit in a color buffer pixel represents the segment of the ray passing through the corresponding plane of cells. The ray may pass through either one or two cells in a plane, and the corresponding bit is set to 1 if either cell is possibly contributing, otherwise the bit is set to 0. The ray stepping algorithm is modified to avoid sampling the planes that have a bit value of 0. Additional speedups are achieved by considering the pixel value one byte at a time, and examining the actual bits only for non-zero bytes.</p><p>When supercells are projected to obtain the color buffer values, this method is analogous to a hierarchical method with three levels. The lowest level is the original data, the middle level is represented by the pixel bits, and the highest level is represented by the bytes. This hardware acceleration method provides an approximate list of elements pierced by the ray at the two higher levels of the hierarchy. The list is approximate since two pierced supercells in one plane are represented by one value in the list. The time spent acquiring samples in empty cells in the traversal list is overshadowed by the time saved due to the hardware generation of the list.</p><p>As in the depth buffer PARC algorithm, special considerations must be made when the eye point is inside a possibly contributing cell. In this case, each viewing ray must start at the viewing plane. After the ray steps beyond the plane containing this initial cell, the algorithm utilizes the projected color bits to step along the ray as before. Binary: 00111110010100 <ref type="figure">Figure 6</ref>: The color buffer values for a pixel represent the possibly contributing cells encountered along the ray passing through that pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Shadow Rays</head><p>The depth buffer PARC method described in Section 3, and the color buffer version described in Section 4 can also be employed to accelerate shadow rays in a volumetric ray tracing method. For each point light source in the scene, the light position is treated as an eye point, and either a color buffer, or near and far zbuffers are created for each object using a perspective viewing matrix. The viewing direction is defined by the vector from the light source to the center of the object. Eight vectors are defined that point from the light source to the eight vertices of the bounding box of the object, and the field of view for the perspective projection is twice the maximum angle between the viewing ray and each of the eight vectors. If a field of view is computed to be greater than 90 degrees, then multiple projections are taken, each with a field of view that is less than or equal to 90 degrees. In the worst case the light source is located within the object, and six projections are required. <ref type="figure" target="#fig_3">Figure 7</ref> shows an example of the buffers created for a point light source and an object using depth buffer PARC. For each directional light source in the scene, the light direction is considered the viewing direction, and a parallel viewing matrix is employed to generate the PARC buffers for each object. The position, width, and height of the viewing plane used for rendering is determined by the projected locations of the eight bounding vertices of the object onto the viewing plane.</p><p>In this shadow ray method, the width and height in pixels of the PARC buffers is arbitrary. All buffers could be set to a constant size, or the size of the buffers could vary depending upon the size of the object and distance to the light source.  When a shadow ray is cast to a light during ray tracing, the information stored in the PARC buffers for that light is employed in a manner similar to the PARC buffers for primary rays. The difference is that a shadow ray is not necessarily represented exactly by a pixel in the light PARC buffers. Therefore, the intersection of the ray with each of the PARC buffers for that light is determined. For each intersection, the values stored at the four neighboring pixels are merged to form one PARC value. For depth buffer PARC, this requires selecting the minimum near value, and the maximum far value found in the four pixels. For color buffer PARC, this involves applying a bitwise OR operation to the values found in the four pixels. In addition, the values found in the PARC buffers for a light source must be inverted to account for the fact that the shadow rays are cast in the opposite direction of the viewing rays used to create the buffers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head><p>The algorithms described in this paper were implemented within the VolVis volume visualization system [l, 21. Great care was taken to ensure that these algorithms support multiple overlapping volumes, perspective and parallel projections, analytic intersection calculations, and many other VolVis capabilities. As a result, some of the possible rendering speedups have been sacrificed in order to retain high functionality.</p><p>The results were obtained on a Silicon Graphics Indigo2 Extreme with a 2OOMHz R4400 processor, 24 bit color buffer, 24 bit zbuffer, and 64MB of RAM. Since a double buffered visual was employed for the rendering window, color buffer information was captured eight bits at a time. The timing information is in seconds of wall time.   <ref type="figure" target="#fig_4">Figure 8</ref> shows an example data set where color buffer PARC performs better than depth buffer PARC for images generated using a color and opacity accumulation method. This lateral geniculate nucleus (LGN) data was obtained at a resolution of 384x256x195 using a confocal microscope. After applying the opacity transfer function, 93.5% of the cells were empty. The standard ray tracing method required 110.33 seconds to generate a 300x300 image. The depth buffer PARC method reduced this time to 60.64 seconds. The polygonal model used to generate the depth buffers is shown in <ref type="figure" target="#fig_5">Figure 9</ref>. This model contains approximately 38,000 polygons. The color buffer PARC method reduced the image time to 23.88 seconds, using a color buffer with 8 bytes. The color buffer shown in <ref type="figure" target="#fig_6">Figure 10</ref> is 3 bytes deep for illustration purposes. The additional reduction in rendering time over the depth buffer PARC method was gained by skipping empty segments between samples.</p><p>Statistics for the images shown in <ref type="figure" target="#fig_0">Figures 11-13</ref> are given in <ref type="table">Tables I-3</ref>. The image represented by the data in the fourth row of each table is the image shown in the cor- responding <ref type="figure">Figure,</ref> although except for pixel size, all four images in each table are identical. Statistics for the data sets are given in <ref type="table">Table 4</ref>. This information includes the number of data samples and the size of the volume in units. Also given are the size of the supercells in data samples, and the percentage of supercells that were classified as possibly contributing. <ref type="figure" target="#fig_7">Figure 11</ref> contains a CT scan of a frozen human foot from the Visible Human Project [5] which was rendered using an opacity and color accumulation method. In <ref type="table" target="#tab_0">Table  1</ref>, the PARC version is given in the first column, where "None" indicates standard ray tracing. The image size is indicated in the second column. Two different image resolutions were used to show that both standard ray tracing and PARC scale according to image size. The third column contains the number of samples taken along all rays, while the fourth column indicates the time to take these samples. This time includes the time required to project the polygonal model for the PARC methods. Samples were takes every 0.25 units, where the unit size of the data set was 144~247.9~220, as shown in <ref type="table">Table 4</ref>. Finally, the fifth column indicates the total image generation time. This is essentially the ray casting time plus the ray shading time. The color buffer PARC algorithm performed almost 9 times better than the standard ray tracing algorithm. <ref type="figure" target="#fig_8">Figure 12</ref> contains two data sets obtained from simulation, representing the positive and negative wave function values in a high potential iron protein. The positive wave function values are rendered as a volumetric isosurface while the negative wave function values are rendered using a color and opacity accumulation method. The depth buffer PARC method was used to accelerate the isosurface, while the color buffer PARC method was used to accelerate the translucent data. The statistics for this image are shown in <ref type="table" target="#tab_1">Table 2</ref>, where the first two columns again indicate the PARC method and the image resolution. The third column indicates the number of cells that were considered for intersection calculations, while the fourth column contains the number of samples taken during the accumulation method. Again, samples were takes at 0.25 unit intervals. The fifth column contains the time required to cast all rays, while the sixth column indicates the total time for a shaded image. In this case, the combined color and depth buffer PARC performed more than 5.6 times faster than the standard ray tracing method. <ref type="figure" target="#fig_0">Figure 13</ref> shows a hippocampal pyramidal neuron casting two shadows on a volumetric floor. The cell was obtained using confocal microscopy, while the floor was voxelized from a geometric description <ref type="bibr">[ll]</ref>. Depth buffer PARC was used to accelerate both the primary rays and the shadow rays. The statistics for the image are given in <ref type="table">Table 3</ref>, where the first two columns indicate PARC version and image size. The third column contains the number of cells considered for intersection during primary ray calculations, the fourth column indicates the time required to cast the primary rays, and the fifth column shows the time required to generate a shaded image with only primary rays. In the sixth column, the number of cells considered for intersection during shadow ray casting is given, while the seventh column indicates the time required for the shaded image with shadows. For primary rays, a 3.5 times increase in rendering performance is obtained, while shadow ray generation times are improved by about a factor of 2.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>We have developed two projection algorithms that utilize standard graphics hardware to significantly reduce volumetric rendering times. The depth buffer version of PARC is well suited for rendering volumetric isosurfaces whereas the color buffer version of PARC is better suited for volume rendering. Both algorithms achieve high speedups without compromising image accuracy. The algorithms are general, supporting both parallel and perspective projections. In addition, the algorithms can be used to accelerate shadow rays.</p><p>In the future, we intend to investigate several enhancements to these algorithms. Requiring all elements (cells, supercells, or subcells) to have the same voxel dimensions leads to a compact data structure for storing the elements, but may not lead to an optimal polygonal model. We are investigating the ability to group variously sized regions of the volume in order to more closely approximate the possibly contributing cells with fewer polygons. In the color buffer PARC method, we are considering projecting several resolutions of polygonal models, enabling us to perform a hierarchical ray traversal. Finally, we are exploring the possibility of projecting additional information for each possibly contributing cell. For example, we could also indicate if a cell is homogeneous which may accelerate the rendering of translucent data.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>. o Create a set of near and far buffers for each visible volume o For each pixel in the image do: o For each visible volume do: O Obtain near and far distances for the ray from the set of buffers for that volume O If near value is less than far value: O Cast the ray segment O If any contributing cells are encountered along any ray segments: O Shade the ray segments to get pixel color I I The PARC ray tracing algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Near and far PARC buffers are created by viewing the volume from the light source.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>A volume rendered image of an LGN cell using a color and opacity accumulation method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>A polygonal model used to obtain depth buffers for the LGN cell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>A color buffer used to accelerate volume rendering of the LGN cell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 :</head><label>11</label><figDesc>A translucent rendering of a human foot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>A combined isosurface and translucent rendering of a high potential iron protein.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 13 :</head><label>13</label><figDesc>A ray traced image of a hippocampal cell casting two shadows on a volumetric floor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results forFigure 11</figDesc><table><row><cell>PARC Version</cell><cell cols="5">Image Samples Casting Total Size (pixels2) Time Time (x 103) 6) 6)</cell></row><row><cell>None</cell><cell>300</cell><cell></cell><cell>47250</cell><cell cols="2">149.12 168.43</cell></row><row><cell cols="2">Color 1 300</cell><cell>1</cell><cell cols="3">3318 1 12.70 1 19.16</cell></row><row><cell>None</cell><cell>600</cell><cell></cell><cell>189741</cell><cell cols="2">598.50 673.95</cell></row><row><cell>Color</cell><cell>600</cell><cell></cell><cell>13285</cell><cell>49.70</cell><cell>75.90</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results forFigure 12</figDesc><table><row><cell></cell><cell>I</cell><cell>I</cell><cell>I</cell><cell>,</cell><cell>I</cell></row><row><cell>None</cell><cell>1 300</cell><cell cols="5">I 5123 1 15094 1 61.01 1 68.95</cell></row><row><cell>Color/Depth</cell><cell>300</cell><cell></cell><cell>183</cell><cell>881</cell><cell>8.19</cell><cell>12.12</cell></row><row><cell>None</cell><cell>600</cell><cell></cell><cell>20508</cell><cell>60436</cell><cell cols="2">242.92 276.02</cell></row><row><cell cols="2">Color/Depth ( 600</cell><cell>1</cell><cell>735 I</cell><cell cols="3">3341 I 31.99 1 43.55</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1070">-2385/95 $4.00 0 1995 IEEE Proceedings of the 6th IEEE Visualization Conference (VISUALIZATION '95) 1070-2385/95 $10.00 © 1995 IEEE</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)1070-2385/95 $10.00 © 1995 IEEE</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head> <ref type="figure">Figure 12</ref> <p>is courtesy of Scripps Clinic, La Jolla, CA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards a Comprehensive Volume Visualization System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Rx Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;92 Proceedings</title>
		<imprint>
			<date type="published" when="1992-10" />
			<biblScope unit="page" from="13" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">VolVis: A Diversified Volume Visualization System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;94 Proceedings</title>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Application of Transport Theory to Visualization of 3D Scalar Data Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Krueger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Physics</title>
		<imprint>
			<biblScope unit="page" from="397" to="406" />
			<date type="published" when="1991-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering Using a Shear-Warp Factorization of the Viewing Transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<date type="published" when="1994-07" />
			<biblScope unit="page" from="451" to="457" />
		</imprint>
	</monogr>
	<note>3: Results for Figure 13</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Marching Through the Visible Man</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;95 Proceedings</title>
		<imprint>
			<date type="published" when="1995-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical Splatting: A Progressive Refinement Algorithm for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<date type="published" when="1991-07" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="285" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Display of Surfaces from Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Marching Cubes: A High Resolution 3D Surface Construction Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="163" to="169" />
			<date type="published" when="1987-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Volumetric Ray Tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1994 Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast Surface Rendering from Raster Data by Voxel Traversal Using Chessboard Distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sramek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;94 Proceedings</title>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="188" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Volume Sampled Voxelization of Geometric Primitives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization &apos;93 Proceedings</title>
		<imprint>
			<date type="published" when="1993-10" />
			<biblScope unit="page" from="78" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An Improved Illumination Model for Shaded Display</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Whitted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="343" to="349" />
			<date type="published" when="1980-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Coherent Projection Approach for Direct Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<date type="published" when="1991-07" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="275" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Acceleration of Ray-Casting Using 3D Distance Transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Zuiderveld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H J</forename><surname>Koning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visualization and Biomedical Computing Proceedings</title>
		<imprint>
			<date type="published" when="1992-10" />
			<biblScope unit="page" from="324" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Data Set Statistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
