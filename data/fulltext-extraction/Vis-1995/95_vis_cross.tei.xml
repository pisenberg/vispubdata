<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Realism for Visualization Using Ray Tracing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Cross</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Naval Research Laboratory &apos;</orgName>
								<address>
									<addrLine>4555 Overlook Avenue SW Washington</addrLine>
									<postCode>20375</postCode>
									<region>DC</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Interactive Realism for Visualization Using Ray Tracing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Visual realism is necessary for many virtual reality applications. In order to convince the user that the virtual environment is real, the scene presented should faithfully model the expected actual environment. A highly accurate, fully modeled, interactive environment is thus seen as &quot;virtually real.&quot; This paper addresses the problem of interactive visual realism and discusses a possible solution: a hybrid rendering paradigm that ties distributed graphics hardware and ray tracing systems together for use in interactive, high visual realism applications. This new paradigm is examined in the context of a working rendering system. This system is capable of producing images of higher fidelity than possible through the use of graphics hardware alone, able both to render images at speeds useful for interactive systems and to progressively refine static, high quality snapshots.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Virtual reality is a demanding computer science technology, immersing the user in a 3D interactive virtual world. The three primary requirements of a virtual reality system are immersion, interaction and visual realism. Immersion requires physically involving the user, both by capturing exclusive visual attention and transparently responding to three dimensional input (e.g., through a head-tracker, 3D mouse or wand)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PI.</head><p>The user of a virtual reality system interacts through the three dimensional control devices to investigate the virtual environment. The displayed view of the environment must be updated quickly (at least ten frames per second while the input devices must 0.1 seconds) <ref type="bibr">[l]</ref>. 2 be tracked smoothly requiring control lag less than Virtual reality also requires visual realism: accurate representation and presentation of visual cues and information about the virtual environment.</p><p>As in real environments, visual cues provide intuitive information about the virtual scene <ref type="bibr">[2]</ref>. This research attacks problems faced in real-time visually realistic systems OMuch of the work on this project took place at the Department of Computer Science, Indiana University, Bloomington,</p><p>which attempt to maintain both high quality rendering and interaction.</p><p>2 Motivation for Visual Realism A VR system faces the demanding problem of convincing the user that the simulated environment' is "virtually real." The user will expect large amounts of visual information; e.g., small lights produce hard shadows and small specularities while area sources produce soft shadows and broad specularities. While the entertainment industry offers texture mapped polygon graphics in movies, arcade and home computer games, these rely on the "suspension of disbelief" of the users and viewers. This is unsuitable for real applications such as training, design and telepresence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rendering</head><p>Problems Simulation of natural environments faces computer graphics problems including accurate modeling of luminaires, shadows, and surface material properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Luminaires.</head><p>Accurate modeling of light sources, or luminaires, is important for visual realism. A user would not expect diffuse fluorescent office lighting to be treated as point sources; likewise, stars in the night sky are too distant to be reasonably treated as area sources (see <ref type="figure">Figure 1</ref>). Physical modeling of the luminaire's spectral response is also important. For example, in theater lighting design, specific luminaires are chosen for their visual impression; a design prototyping system thus requires correct spectra.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shadows.</head><p>Shadows are important to human perception. They add intuitive three dimensional visual cues to the flat images on a CRT display. Static perception is also enhanced by soft shadows (with gradually darkening edges are known as penumbra); such shadows are cast by objects occluding light from area sources (see <ref type="figure">Figure 1</ref>). The softness of the shadow provides a visual measure of relative distance; a nearby area source casts soft shadows while at greater distances the shadows tend to be more hard-edged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optics and Material Types.</head><p>A surface's optical properties can be modeled with a bidirectional IWhile this paper assumes natural environments (e.g., architectural scenes), the results presented here apply equally to real-time interaction with other complex artificial environments.</p><p>(See color plates, page CP-4)  <ref type="figure">Figure 1</ref>: Light from point sources produces point specularities; area sources produce broader specularities. Point sources cast hard shadows; area sources cast soft shadows. reflectance distribution function (BRDF) which measures reflected energy as a function of the light vector and the viewing direction (and often the light's wavelength). A mirror-like surface reflects the most energy along a single vector, scattering little light in other directions. A diffuse surface scatters energy equally in all directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2</head><p>Approximate Realism True optical realism is complex.</p><p>For other than the simplest scenes, real-time computation of a full model for the optical physics of a dynamic virtual environment is currently infeasible. A VR system must present the best model possible within the restrictions imposed by user interaction.</p><p>Many contemporary virtual reality systems use dedicated scan conversion graphics hardware (e.g., Bryson's Virtual Wind tunnel). However, the fundamental paradigm of such hardware limits its rendering ability; it is difficult to produce realistic visual features at all, much less at high speed. In contrast, a ray tracing system can produce realistic static images of complex environments.</p><p>However, the computational expense of such methods restricts rendering speeds to rates much too slow for use in a VR system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>Scan Conversion Graphics Hardware Many contemporary interactive visualization and VR systems use scan conversion graphics hardware; these virtual environments are composed exclusively of simple primitives (e.g., polygons or streamlines). The Silicon Graphics RealityEngine is an example of a popular, powerful system; all examples of graphics hardware presented here will assume its capabilities2 as a standard measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.1</head><p>Graphics Hardware Assets The graphics hardware has powerful rendering assets; the z-buffer is the most important for the prototype system presented here.</p><p>The z-buffer is used for visibility and distance testing. During scan conversion, distance values are calculated for the extreme points of triangles. These distances are then bilinearly interpolated across the scan </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2</head><p>Graphics Hardware Limitations Though capable of rendering many texture mapped triangles per second, the graphics hardware faces severe limitations which restrict the real-time realism potential of a purely graphics hardware-based rendering system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lighting</head><p>Model.</p><p>The model used by the graphics hardware is more simplistic than Phong shading. The Phong intensity function is evaluated at the extreme vertices and these values are bilinearly interpolated. As a result, visual quality is low except for small triangles, failing to produce proper specular behavior except near the vertices. <ref type="figure" target="#fig_1">Figure 2</ref> gives an example of tessellated spheres rendered using this approximation; note the artifacts near the vertices and along the edges. Higher image quality requires an artificial inflation, introducing many small triangles to refine the tessellation.</p><p>However, regardless.of the size of the triangles, the Phong model is not physically based so it cannot be used to model realistic material effects (e.g., shallow angle glare or rough surfaces).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rendering</head><p>Frustum.</p><p>The scan conversion rendering frustum is a truncated pyramid extending from the viewpoint, specifying the visible volume. This structure is the foundation of the z-buffer algorithm.</p><p>Unfortunately, the rendering frustum obfuscates other mathematics, including vector interpolation and optical reflection. As illustrated in <ref type="figure" target="#fig_0">Figure 3</ref>, planar reflection of a viewing frustum can be imitated by imagining a virtual viewpoint on the opposite side of a mirror. However, no hardware-based mechanism exists to properly treat more complex reflections; although the hardware's environment mapping approximates infinite-range effects, the bilinear interpolation of texture vertices results in stretched and distorted  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Texture</head><p>Projection.</p><p>Hardware supported texture projection [4, 51 is an extension to simple texture mapping: the image is projected into the environment like a spotlight. This method can be used to approximate luminaire distributions or in support of hardware shadows.</p><p>Shadows are a difficult problem for scan conversion rendering. The hardware-supported shadow method [4, 51 uses texture projection and a complete z-buffer from each light source. For each luminaire, the resulting z-values are retrieved from the frame buffer, redefined as a texture map and then projected into the environment.</p><p>These values indicate the surface closest to a particular luminaire so any surface more distant must be in shadow. This process produces a "stencil" image which is multiplied against an image of the luminaire's lighting distribution projected into the environment.</p><p>The result of this image multiplication is a view of the environment with one source casting shadows. This algorithm must be repeated for scenes with more than one luminaire, adding the lit images together to produce the final scene.</p><p>Texture projection produces distortion; pixels are enlarged and smeared onto oblique surfaces; inverse mappings are only accurate for short distances and near-perpendicular angles. The limitations of texture projection appear in the aliased shadows resulting from this method, which may be coarse, ragged or even striped [6] (see <ref type="figure" target="#fig_3">Figure 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Component</head><p>Image Composition.</p><p>The shadow algorithm requires the composition of several images to produce a single view of the scene. This is a common costly requirement of the hardware-based algorithms developed for visual realism (e.g., <ref type="bibr">[4]</ref>). The hardware's pixel fill speed is a finite resource, consumed by each image transfer As these algorithms require many such operations, a scan conversion system must choose between high resolution images at the expense of speed, or reduced image quality to preserve interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3</head><p>Graphics Hardware Is Too Limited These limitations prevent contemporary scan conversion graphics hardware from producing optically complex visual realism at interactive rates. The hardware was designed for high-speed rendering of Zbuffered, texture mapped triangles [3]; its limitations discourage pursuit of a pure graphics hardware-based realistic rendering paradigm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Photorealistic</head><p>Ray Tracing Photorealism is characterized by extremely meticulous depiction of detail. Important issues for computer graphics include precise modeling and attention to photometric accuracy. Ray tracing determines the visibility of surfaces by tracing backwards along imaginary rays of light from the viewpoint through the pixels of the image to objects in the scene <ref type="bibr">[6]</ref>. If such a ray intersects an object in the environment, the object's color becomes the color of the corresponding screen pixel. If the object is reflective, a reflected viewing ray may be shot into the environment; this process proceeds recursively in a highly reflective environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.1</head><p>Advantages of Ray Tracing Ray tracing is a more powerful rendering paradigm than scan conversion. The ray model is more intuitive and physically plausible. <ref type="figure" target="#fig_0">Figure 3</ref> shows the simplicity of ray reflection; rays can be reflected from any object. In contrast, reflected viewing frusta are distorted to uselessness for non-trivial cases.</p><p>Unlike scan conversion, ray tracing is accurate at the pixel level. Realistic BRDFs evaluated at each pixel give a much better impression than the hardware's Gouraud-shaded model. These functions model of complex surface material types (such as brushed metal or polished wood).</p><p>In contrast, the hardware cannot even place specularities within large polygons. The intuitive rendering power of the ray tracing method motivates the development of a real-time ray tracing-based renderer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2</head><p>Speed Limitations of Ray Tracing Unfortunately, classical ray tracing is computationally expensive. The primary visual ray and shadow tests consume much of the available computing resources. The visual ray shot through each pixel must test for intersection against many objects. The classic shadow method requires a shadow ray from each intersection point to all light sources, searching for occlusions (see <ref type="figure" target="#fig_3">Figure 4)</ref>. The cost per pixel grows rapidly with the complexity of the environment. Though analytic methods exist that directly compute occlusions and penumbra, such methods are much too slow for dynamic environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>A Hybrid Rendering Paradigm This section examines a solution to the problem of high-speed visual realism: the combination of the speed of graphics hardware with the power of software ray tracing. A fast network allows the computational components to be distributed over several machines. The result is a hybrid rendering paradigm able to render approximate images at speeds useful for interactive systems and to progressively refine static, high quality snapshots.3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.1</head><p>The Item Buffer Each primary ray test answers two rendering questions: "Which object is visible through this pixel?" and "Given an intersection, what color does this ray contribute?".</p><p>The graphics hardware z-buffer can quickly answer the first question. <ref type="bibr">Weghorst et al. [8]</ref> introduce the concept of an item bufler, assigning a unique identifier to each object; as the z-buffer identifies visible surfaces, the resulting image is a set of identifiers, specifying which object is visible through each pixel. Given this knowledge, the ray passing through each pixel can be specifically targeted towards the visible object (see <ref type="figure">Figure 5)</ref>.</p><p>Limitations. While the item buffer accelerates the visibility test, it is an approximation.</p><p>It is limited to single pixel resolution and requires tessellation of all objects into triangles (the only primitives acceptable to the hardware z-buffer). Thus, the visible periphery of a smooth object will also be tessellated. However, this does not affect the appearance of the rest of the surface. For example, the front of a sphere looks round, though the edge may appear jagged. 3This paper presents an outline of the hybrid paradigm; see <ref type="bibr">Cross [7]</ref> for a a more detailed discussion. <ref type="figure">Figure 5</ref>: The item buffer acceleration method identifies the closest object visible through a pixel, allowing rays to be shot directly to a specific target.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Advantages.</head><p>The item buffer is a fast visibility approximation.</p><p>It provides simple boolean visibility methods for surfaces of arbitrary complexity without a specific ray-object intersection test. In addition, the answer to the visibility question may also simplify surface rendering. For example, given a visible polygon, there is no need to compute a ray-plane intersection point and clip by the polygon edges. Instead, the rayplane intersection operation is sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Frameless Rendering</head><p>The pixel-oriented nature of ray tracing, as opposed to the double buffered frames of scan conversion, is better suited to frameless rendering (introduced by <ref type="bibr">Bishop et al. [9]</ref>). This method computes pixel colors in randomized order, displaying the new values immediately upon completion. This gives the impression of constant, simultaneous update. In addition, this provides direct control over pixel accuracy and rendering priority. Most important for virtual reality, frameless rendering reduces visual control lag. Each pixel is computed based on the latest control inputs and immediately displayed (rather than waiting for a complete frame). Thus, the user is better able to control the system effectively [lo].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.3</head><p>Approximate Realism The hybrid rendering system is intended to provide visual realism at interactive rates. In difficult scenes, frameless rendering makes the user more tolerant of changes in rendering speed; speed increments are measured in pixels per second rather than frames, (much finer gradations).</p><p>However, as complexity increases, the system must reduce fidelity in order to maintain rendering speed. Section 6 describes the algorithms developed to provide these levels of approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.4</head><p>Distributed Computing Asynchronous transfer mode (ATM) networks are characterized by high data rate transfer with low latency. Experimental ATM networks are approaching 1 gigabyte bandwidths while common, less expensive networks exceed 100 megabits per second on common hardware. Networks of such high bandwidths allow complex real-time calculations to be distributed over several chassis.</p><p>Since the rays of a ray tracer are largely independent, such a renderer parallelizes well. Given a fast network and local copies of the environment data, the  rendering process can also be distributed between machines. These remote processes then pass their partial solutions back to a central process for display. 5.5 Summary of the Hybrid Design The hybrid rendering system uses both general purpose and graphics hardware linked through a fast network into a rendering pipeline.</p><p>The graphics hardware provides pre-processing, including a fast visibility computation.</p><p>This information is then passed to a distributed ray tracing system for rendering. The resulting pixels are transferred to the display process and composed into a final image. The front-end transmits control information back to the visibility and rendering systems. The final distributed design of the hybrid rendering system appears in <ref type="figure">Figure 6</ref>  Complex environments may preclude rendering at maximum fidelity; the system requires approximate realism within the time available. 6.1 Realistic BRDFs As the hybrid system uses ray tracing, it is not limited by the vector interpolation problems of scan conversion. The hybrid system uses Ward's Gaussianbased model [Ill as an approximation to more complex BRDFs, allowing it to render isotropic and nonisotropic surfaces at interactive rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.2</head><p>Complex Object Descriptions The hybrid system uses the item buffer to calculate visibility information, thus requiring complex objects to be tessellated before rendering. However, the ray tracer models objects at full resolution.</p><p>Also, given that a ray must hit a particular object, rendering its surface may be greatly simplified; e.g., the ray tracer can replace a ray-polygon calculation with a simple ray-plane test. The final image of the complex object may still appear tessellated about its periphery. However, its interior pixels are rendered at full resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.3</head><p>Pixel Accuracy &amp; Dynamic Range Floating point pixel calculations provide greater accuracy and dynamic range (useful for complex features such as dark adaption). Therefore, the ray tracing processes perform image calculations using floating point mathematics.</p><p>Ward's RGBE algorithm [12] compresses the three floating point components (red, green and blue) into a 32 bit word. The resolution of the RGBE values gives the hybrid system an effective dynamic range of [0,2"' = 1.7 x 1O38] per color component. In contrast, an &amp;bit frame buffer is limited to [0,255].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.4</head><p>Graceful Degradation The hybrid system has detailed control over performance. Speed changes are measured in pixels per second, so small changes are less obvious to the user. It can designate screen areas as important, updating those pixels more often and with higher fidelity than less important areas. In order to render a high quality image, performance restrictions may be relaxed, allowing the system to produce a wider spectrum of visual quality. 6.5</p><p>Opacity Grid The hybrid system uses an opacity grid: an axisaligned grid that replaces the original geometry of the shadow ray test with a probability estimation. Initialization of the opacity grid divides the environment into cells. These cells are randomly sampled for possible occlusions, computing cell opacity from the ratio of occlusions to the total number of samples. This opacity is the probability that a ray passing through a cell would be occluded. Probabilities are interpolated for directions between the sampled axes.</p><p>Example opacity cells occluded <ref type="figure">Figure 7</ref>: A grid-based approximation for use in shadow calculations. This section examines the computational components and visual results of a working hybrid rendering system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.1</head><p>Computational Performance The current version is a three machine design. The item buffer machine is a 200 MHz R4400 Indigo2 that passes its visibility information through the OC3 SONET ATM line to the ray tracing machine. This is an Onyx with four 150 MHz R4400 processors that renders individual pixels in randomized order. Each pixel is compressed into a 32-bit RGBE composite <ref type="bibr">[12]</ref> and sent to the display machine, a 150 MHz R4400 Crimson that translates the RGBE pixels back into frame buffer pixels. The overall performance is summarized in <ref type="table" target="#tab_2">Table 1</ref> (bottlenecks are indicated in boldface). <ref type="figure">Figure 9</ref> shows an overhead view of the virtual environment. As in <ref type="figure">Figure 8</ref>, the system has refined this image for approximately two seconds. These images illustrate the ability to render high quality images containing complex objects (spheres and cylinders appear here) composed of realistic materials at useful speeds.</p><p>The ray tracer is the bottleneck.</p><p>The Onyx cannot fully consume the visibility information.</p><p>The net throughput is limited to 400 kilopixels per second; the equivalent of a 200 x 200 display, updated ten times per second. In comparison, an NTSC television screen is 640 x 480, while workstation monitors commonly exceed 1280 x 1024. Fortunately, the ray tracing processes need not be limited to a single chassis. They could be distributed across several platforms without major changes to the pipeline design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.2</head><p>Visual Performance <ref type="figure">Figure 10</ref> illustrates the problems of the basic opacity grid implementation (these problems are much less apparent in the more distant view of <ref type="figure">Figure 11)</ref>. In constructing the opacity grid, the virtual environment is sampled at a coarse level; "interesting" cells are identified by sharp variations in the sampled opacity. A sufficiently interesting cell is partitioned into sub-grids and resampled. In both figures, it is clear that this implementation failed to refine the large cell including the chair and end of the table. A more sophisticated method for sub-sampling is obviously necessary.</p><p>The shadow aliasing of the opacity grid is also clear. The opacity grid's structure is apparent in the false shadows and false illumination.</p><p>These artifacts are due to both the limited resolution of the grid and the key assumption of the opacity grid: the grid cells must be small relative to their distance from the test objects.</p><p>In this case, some shadow rays are slipping through cracks between nearby grid cells. Similarly, some shadow rays are self-intersecting with cells lying directly on the surface. <ref type="figure">Figure 8</ref> shows a static view of the virtual envi-In spite of these limitations, the opacity grid proronment that emphasizes the different surface mate-vides a fast, effective approximation for longer range rial types with multiple area light sources. The red shadow effects. The nested grid structure allows for sphere is similar to the table surface, a specular, rough, implicit construction of levels of detail. In interactive plastic surface. The green sphere is equally specu-situations, shadow rays test only the coarse high-level lar but is much rougher; the specularities are broader cells; during the refinement of static images, the renand blurred. Finally, the blue sphere is a much more derer can use finer resolution of the sub-grids. The specular metallic surface. terns could use approximate shadows in interactive situations as well as high resolution rendering in static situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8</head><p>Future Work This work has great potential for extension. Future virtual reality systems will surpass these results and with great potential for interactive visual realism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8.1</head><p>Graphics Hardware Features The current hybrid system uses only the graphics hardware z-buffer; the RealityEngine has other powerful features. For example, a separate pre-process, similar to the item buffer, could provide high-speed texture mapping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8.2</head><p>Expanded Rendering Ability The ability of ray tracing to implement convex lens camera models, dynamic range and grid-based approximations will greatly increase the visual realism of future systems. The lens model will provide interactive depth of field, directing or following users' attention, indicating the important points by directly focusing upon them. The dynamic range available from floating point pixels will enable complex effects such as dark or glare adaption. Volume graphics and volume rendering research encourages further development of grid-based approximations methods. Their ability to automatically generate approximate environments reduces the modeling workload. This type of approximation may also attack problems such as automatic clustering of light sources and geometry in extremely complex scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9</head><p>Conclusion While the performance results described in Section 7 are below the requirements for a virtual reality system, they do illustrate important aspects of the rendering power of the hybrid paradigm:</p><p>Realism: The realism of the images is greater than current scan-conversion VR systems modeling similar environments.</p><p>Extension: Software ray tracing allows intuitive extension (e.g., geometric models, optical and physical properties, etc.).</p><p>Expansion: A hybrid system is not architecturespecific. The pipeline design permits expansion as new equipment is connected to the fast network. Unlike esoteric research systems with specific equipment requirements, the hybrid system runs on common hardware and networks.</p><p>These contributions will facilitate the design of future high visual realism systems. The current system already exhibits better visual performance than texture-mapped polygon virtual reality systems. Future work will extend its rendering power, working towards the ultimate goal of truly realistic virtual reality:</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>The graphics hardware scan conversion rendering frustum can model simple planar reflectors; more complex reflectors are infeasible. The ray model permits reflection from arbitrary surfaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Artifacts produced by the graphics hardware's approximation to Phong shading: tessellated spheres (85 triangles per sphere). reflection artifacts [4].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>The hardware shadow method: the depth map is used to determine which pixels are visible to the light; others are in shadow. Ray traced shadows look better but are computationally expensive.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>. j_ . . . . . . . . . . . . . . . . . . . . . ., . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ...! j Display &amp; I / front end I I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure</head><label></label><figDesc>Figure 6: The hybrid rendering pipeline 6 Algorithms for Approximate Realism The hybrid system must adapt to the requirements of interaction. Complex environments may preclude rendering at maximum fidelity; the system requires approximate realism within the time available. 6.1 Realistic BRDFs As the hybrid system uses ray tracing, it is not limited by the vector interpolation problems of scan</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>: Theoretical throughput</cell><cell>of current system</cell></row><row><cell cols="2">compared to actual performance, with bottlenecks in-</cell></row><row><cell cols="2">dicated in bold; figures assume best measured perfor-</cell></row><row><cell>mance.</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1070">-2385/95 $4.00 0 1995 IEEE Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)1070-2385/95 $10.00 © 1995 IEEE</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)1070-2385/95 $10.00 © 1995 IEEE</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments Much of the research for this project took place at the Department of Computer Science, Indiana University, Bloomington, IN 47405. Hardware support was provided by NSF grants CDA-92-23008, CDA-93-03189 and IRI-91-06389.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real-time exploratory scientific visualization and virtual reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Bryson ; L</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosenblum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scientific Visualization: Advances and Challenges</title>
		<imprint>
			<publisher>Academic Press, Inc., 1994. E. B. Goldstein, Sensation and Perception</publisher>
			<biblScope unit="page" from="65" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">RealityEngine graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Akeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;93 Proceedings</title>
		<editor>J. T. Kajiya</editor>
		<imprint>
			<date type="published" when="1993-08" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Texture mapping as a fundamental drawing primitive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeberli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Segal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fourth Eurographits Worlcshop on Rendering</title>
		<editor>M. F. Cohen, C. Puech, and F. Sillion</editor>
		<imprint>
			<date type="published" when="1993-06" />
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast shadows and lighting effects using texture mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Korobkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Widenfelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Haeberli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;92 Proceedings</title>
		<editor>E. E. Catmull</editor>
		<imprint>
			<date type="published" when="1992-07" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="249" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Advanced Animation and Rendering Techniques: Theory and Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Watt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Watt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Addison-Wesley Publishing Company</publisher>
			<pubPlace>New York, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Interactive Visual Realism Using Distributed Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Cross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995-05" />
		</imprint>
		<respStmt>
			<orgName>Indiana University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improved computational methods for ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Weghorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM fiansactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="52" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Frameless rendering: Double buffering considered harmful</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;94 Proceedings</title>
		<editor>A. S. Glassner</editor>
		<imprint>
			<date type="published" when="1994-07" />
			<biblScope unit="page" from="175" to="176" />
		</imprint>
	</monogr>
	<note>Scher Zagier</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Target acquisition in fish tank VR: The effects of lag and frame rate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ware</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Graphics Interface &apos;94</title>
		<meeting>Graphics Interface &apos;94</meeting>
		<imprint>
			<publisher>Canadian Information Processing Society</publisher>
			<date type="published" when="1994-05" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Measuring and modeling anisotropic reflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics (SIGGRAPH &apos;92</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Real pixels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics Gems II</title>
		<editor>J. Arvo</editor>
		<imprint>
			<publisher>Academic Press, Inc</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="80" to="83" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
