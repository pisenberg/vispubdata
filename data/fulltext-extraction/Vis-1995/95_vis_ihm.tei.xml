<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Enhancing the Speed of Splatting with Indexing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Insung</forename><surname>Ihm</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Sogang University Seoul</orgName>
								<address>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rae</forename><forename type="middle">Kyoung</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Sogang University Seoul</orgName>
								<address>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Enhancing the Speed of Splatting with Indexing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Splatting is an object-space direct volume rendering algorithm that produces images of high quality, but is computationally expensive like many other volume rendering algorithms. This paper presents a new technique that enhances the speed of splatting without trading of image quality. This new method reduces rendering time by employing a simple indexing mechanism which allows to visit and splat only the voxels of interest. It is shown that this algorithm is suitable for the dynamic situation in which viewing parameters and opacity transfer functions change interactively. We report experimental results on several test data sets of useful size and complexity, and discuss the cost/beneJit trade-off of our method.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scientific visualization is a fast growing area which is concerned with various techniques that help scientists and engineers to extract meaningful and visual information from the results of simulations and experimentations <ref type="bibr" target="#b1">[2]</ref>. One of the most actively researched subfields of scientific visualization is volume rendering that deals with scalar and vector data defined on three (or higher) dimensional grids. In this relatively new field several rendering techniques have emerged to analyze, understand, and render objects that are contained in volume data.</p><p>Some of the most commonly used direct volume rendering algorithms are ray casting <ref type="bibr">[5, 8, lo]</ref>, splatting <ref type="bibr">[ll]</ref>, and volume shearing <ref type="bibr">[l, 33.</ref> Splatting is an object-order traversal algorithm where voxels are properly splatted into an image plane. In this algorithm, the voxels are sorted slice by slice in the frontt-back or back-t-front order. Each voxel, traversed in the order, is classified and shaded by given opac-ity and color transfer functions.</p><p>Then, the voxel is projected into an image plane, and its contribution is accumulated to an image buffer using a projected reconstruction kernel called footprint. In this way, successive slices are composited to produce the final image. Splatting is, like many other direct volume rendering algorithms, computationally expensive due to the large size of volume data although it is known to be more efficient than ray casting or volume shearing.</p><p>Since the original splatting algorithm traverses all the voxels in some proper order, the computational cost is linearly proportional to the size of the volumetric data set, regardless of its contents. Often, only small portions of volumetric data sets contain objects to be rendered. For example, a large portion of typical CT or MRI data contains air which is seldom rendered. Hence, it is quite likely that computing time can be saved by splatting only those voxels that correspond to objects which are being rendered. It has been reported that volume data with 70-90% of uninteresting voxel points are not uncommon <ref type="bibr" target="#b5">[6,</ref><ref type="bibr">131</ref>. Spatial data structures like octrees and pyramids were used in encoding volume data so that unnecessary computation in transparent regions can be avoided <ref type="bibr">[S, 9, 13, 1,4,7]</ref>.</p><p>Unlike ray tracing or other rendering algorithms, little has been done to reduce rendering time of the splatting method on a uniprocessor while a few algorithms are known for parallel processors <ref type="bibr" target="#b12">[12]</ref>. In <ref type="bibr" target="#b3">[4]</ref>, a pyramidal volume representation was used to improve the speed of splatting. Given transfer functions and view-independent shading functions, an octree is constructed in which each node contains the average RGBA value of all its children and a value indicating the average error associated with the average. Then, the octree is traversed in a viewing order to splat the voxels, depending on the given allowable error that determines the refinement of rendered images. This algorithm reduces rendering costs, but trades off im-(See color plates, page CP-10) age quality for speed.</p><p>This paper presents a new technique that enhances the speed of splatting without sacrificing image quality. In this algorithm, a simple indexing mechanism is employed so that only the voxels of interest are examined and splatted. The data structure used in our algorithm is simpler than octrees, and the traversal order of voxels is basically the same as the traditional splatting algorithm, hence any improvement techniques, such as early termination of composition process, can be easily applied.</p><p>Observe that the order in which voxels are stored in an array for raw volume data is determined by their positions which, in general, have nothing to do with their density values, that is, the materials which exist at the corresponding grid points. On the other hand, most rendering algorithms use opacity transfer functions for classification, which decide the range of densities of interesting voxels. Hence, the volume data must be stored or at least be accessible efficiently depending on the density values rather than being stored in terms of voxel's positions. In our algorithm, we preprocess the volume data to extract indexing information which enables efficient access to voxels having arbitrary density values. The extracted indexing information is both view-independent and transferfunction-independent. This means that it is built only once in the preprocessing step, and splatting is done efficiently with dynamically changing viewing parameters and transfer functions.</p><p>In Section 2, we propose a new way of splatting that enhances the speed of rendering. In Section 3, we show how viewing transformations are performed efficiently in our algorithm. Experimental results are reported in Section 4, and we discuss some of the implication of our algorithm in Section 5. Then, an additional data structure, that performs the function of indexing, are precomputed as follows : for each principal axis of the volume data (without loss of generality, consider the A axis.), imagine the series of slices, perpendicular to the axis. For each slice, a sequence of pointers corresponding to the density values dh that appear in the slice, is enumerated in the increasing order of density values (See <ref type="figure">Figure 1.</ref>). The pointer associated with density dh is to a data block that keeps the list of the (i, j) indices to the voxels in the slice which have the density value dh. (In Section 2.3, we describe how these indices are encoded in our implementation.) Building this data structure for indexing can be viewed as reorganizing the given volume data based on the density values, not the positions of voxels. In most volume rendering algorithms, objects of interest to be rendered are classified in terms of opacity transfer functions. Our new data structure enables us to easily access only those voxels that fall in the ranges of interest which are specified in terms of the opacity transfer functions.</p><p>To make the splatting process view-independent, three sets of such a data structure are built in the preprocessing step, one for each principal axis. Given arbitrary viewing parameters (that is, the view reference point, the view-up vector, and the view plane normal), the proper viewing direction is selected so voxels are visited slice by slice in the proper front-to-back order.</p><p>l Splatting time is saved by accessing only the necessary voxels.</p><p>l</p><p>The opacity transfer functions can change interactively without building the indexing data structure again.</p><p>The viewing and shading parameters can be modified dynamically without building the indexing data structure again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Details on the Indexing Data Structures</head><p>The indexed splatting algorithm saves the rendering</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Algorithm</head><p>Now, our new splatting algorithm works as follows : assume that we want to render some objects whose density values range from dlow to d,,.</p><p>First, the principal axis for the viewing direction is determined among the i, -i, j, -j, k, and -k axes. (Again, without loss of generality, let's assume the viewing direction is the k axis.) Once the viewing direction is decided, each slice perpendicular to the viewing direction is traversed in the front-toback order as the original splatting algorithm does. For each slice, we first find the actual lower and the upper bounds quickly, using the binary search, of density values that are between the interval [dl OW, dup], then, follow the pointers in between to visit only the voxels with values of interest. The remaining steps such as shading, projection, and color blending are the same as the traditional splatting algorithm.</p><p>Note that the traversal order of voxels in splatting is basically the same as the traditional splatting algorithm, hence any enhancement techniques, such as early termination of composition process, can be easily applied. The resulting algorithm inherits the merits of the original splatting algorithm as well as it has the following additional characteristics : time 'by traversing only the voxel points of interest. However, extra memory is necessary to store the information on indexing. It could lead to an enormous memory requirement if inefficient data structures were used to store indexing information. On the other hand, any space-saving encoding method to store the information efhciently should not be complicated enough to waste the time that is saved by indexing. In our current implementation that permits volume data of size up to 256 x 256 x 256, the following simple encoding method for indexing is used. For the k-th slice, and for the density value d, the memory block, that contains the indices (i, j) of (i, j, k) whose density is d, is organized as follows : first, each voxel (i,j) is associated with an index value indij that is defined as indg = i + j * nz. Then consider the enumeration of voxel points in the scan-line order. Rather than store the i and j pair for each voxel (i, j) consuming two bytes, we store the offset value off that is the displacement from the predecessor. One byte is used for the offset, which means that distance at most 255 is possible. When the offset is greater than 255, one byte containing zero (null value) is put, and followed by two bytes for the i and j index of the next voxel. Hence, one byte is necessary when the next voxel with density d is within 255 voxel off, or three bytes are required. We observe that due to the property of spatial coherence of volume data this encoding technique results in saving the total number of bytes for the index information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Efficient</head><p>Viewing Tkansformat ions</p><p>Viewing transformation is the process in which a grid point (2, y, Z) in the voxel-space is mapped to a point (u, w) in the image-space. Efficient computation of the transformation is essential since a huge number of voxels are usually projected into an image plane. To probe objects in volume data interactively, we often change viewing parameters dynamically. Hence, the viewing transformation for arbitrary viewing parameters must be calculated efficiently as well as each voxel is projected quickly.</p><p>In our indexed splatting algorithm, the voxel points are not visited in a regular manner as in the original splatting method (for example, either i, j, or k direction fastest, one of the remaining two directions second fastest, and the last remaining direction slowest .) . Note that we visit only the voxels with densities between ranges of interest. Since the traversing order is rather arbitrary, the viewing transformation can not be done incrementally as proposed in <ref type="bibr" target="#b12">[12]</ref>.</p><p>In this section, we are concerned with efficient computations of two tasks : one is to compute the viewing transformation given arbitrary viewing parameters, and the other is to actually project each voxel into the image plane once the viewing transformation is set. Remind that computing the transformation and projecting a voxel correspond to building a 4 x 4 transformation matrix, and multiplying it by a 4-vector, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Orthographic Projections</head><p>In <ref type="figure">Figure 2</ref>, it is illustrated how orthographic projections of an arbitrary voxel point (i, j, k) into the image plane are carried out. In our viewing transformation scheme, we assume that the volume data can exist anywhere with arbitrary orientations, and the image plane can be defined by arbitrary viewing parameters. This assumption is well-suited to the dynamical situation in which both camera and objects move freely in the world coordinates (z,~, 2). First, the image-space (u, V, w) is specified by a point p = (pa, pv, pd)*, and three orthonormal vectors u = (% ay, %)*, v = (G, 5, Q)*, ad w = (WE, q, w#. Notice that p is the view reference point, and v and w are the view-up vector and view plane normal, respectively. Secondly, the voxel points are expressed with respect to the volume space (i, j, k) defined by a Point q = b, 6, qzY and three orthonormal vectors i = (is, i,, ia)t, .i = (h, ig,jz)', ad k = (b, k,, b)'. Now what we would like to do is to orthographically map a voxel point (i, j, k) into the corresponding point (u, w) on the image plane. The voxel point is, in fact, q + i . i + j . j + k . k in the world space, which is also expressed as p + u . u + w . v + we w for the unknowns a, w and w. Equating these two expressions, we are led to where o is the inner product of two vectors. Now imagine the Iendering process : when a user set the viewing parameters before starting splatting, are added to u and w for the initial k (k could be zero or nk -1.). Under the assumption that the viewing direction is the k axis, the slices perpendicular to this axis is examined one by one in the front-to-back order. For each slice k, , k is fixed, so k, . (u o k) and k, -(v o k) are calculated once per slice. Note that since k is uniformly increased or decreased, these values can be computed incrementally in two additions. Then, for each varying (i, j) of (i, j, k,), (11, w) is computed using 4 additions and 4 multiplications. Thus we see that the total cost of the viewing transformation for each rendering is 6+2nk+4nVOzez additions and 24+4n,,,,l multiplications, where nuoCcl is the number of voxels that are actually projected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Perspective Projections</head><p>While most volume rendering techniques assume orthographic projections due to their simplicity, perspective projections are also useful particularly because they provide depth-cue information. In this subsection, we show that computations for perspective transformations are slightly more expensive than orthographic transformations, but can be done in a similar way. For perspective projections, another viewing parameter e = (e,, ey , e,)t is specified corresponding to the projection reference point (See <ref type="figure">Figure 3.</ref>). The Again, when a user set the viewing parameters before starting rendering, u o (q -e), u o i, u o j, u o k, uo(p-,e),vo(q-e),voi,voj,vok,vo(p-e), w o (q --e), w o i, w o j, w ok, and w o (p -e) are computed once. For each slice ka, three incremental additions are necessary for the denominator of to, II, and v. For each varying (i, j) of (i, j, k,), to is computed using two additions, two multiplications, and one division, and then p1 and w are computed in two additions, one subtraction, and three multiplications, respectively.</p><p>In case of perspective projections, the depth information of the voxel point being projected is often important. In the splatting algorithm, this information could be used to select the proper size of footprint tables adaptively. When the projection reference point e is on the w axis, the value w = wo(q-p)+i.(woi)+j.(woj)+k.(wok) from orthographic projections will be a good choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>Both original and indexed splatting algorithms have been implemented, and added to our SGVR (SoGang Volume Rendering) scientific visualization system <ref type="figure" target="#fig_3">(Figure 4)</ref>. The performance results for the two algorithms are summarized in <ref type="figure" target="#fig_5">Figure 5</ref>. We have experimented with five data sets to generate RGB images of size 256 x 256 using orthographic projections. The test cases Hl (head) and H2 (head with a cutting plane) are from the "UNC head" data set that is 256 x 256 x 225 CT scan of a human head <ref type="figure">(Figure 6 (a)</ref> and (b)), and the case Bl (brain) is from the "UNC brain" data set which is 256 x 256 x 167 MRI scan of a human head <ref type="figure">(Figure 7(b)</ref>). HD (decimated head) and BD (d ecimated brain) are tested using the decimated versions of the head and the brain data sets with the resolutions 128 x 128 x 113 and 128 x 128 x 84, respectively. Two more cases El (engine block) and E2 (engine part) were tested with the 256 x 256 x 110 "engine block" data set <ref type="figure">(Figure 8</ref>    with a 150MHz R4400 CPU and 96 Mbytes of memory, and the timing results are given for both algorithms along with the memory requirements. Also given are the spatial ratios of the number of voxels that were actually visited to the whole number of voxels in the data sets. These ratios indicate how much space objects of interest, that is, objects we want to render, take with respect to the whole volume space, and is the major factor in the performance of the indexed splatting algorithm. In our implementation, four bytes are used to store one voxel : one for density, two for encoded normal, and one for gradient size. Precomputation of the encoded normal vectors and gradient sizes allows us to perform fast classification and shading. For the 256 x 256 x 225 head data (Hl), the number of voxels is about 14.1 millions, and hence about 56.3 Mbytes of memory are necessary for splatting without indexing. On the other hand, about 62.7 Mbytes of memory is needed, so we see that roughly 6.4 Mbytes of additional memory are consumed for the indexing data structure. We have to mention that the amount of re quired memory for indexing depends on the materials residing in data sets. In the test with Hl, only the bones and muscles were loaded for indexing. When skins were loaded, about 20 Mbytes of memory were used. In the simpler data set El, only 5.5 Mbytes of memory were required in loading the whole indices. We are now focusing on the development of a better scheme that encodes data blocks for (i, J') indices efficiently without harming the timing performance of indexing too much.</p><p>The indexing algorithm produces 57.8 -95.7% of time reduction, which obviously depends on the test data. In the best (E2) and worst (El) cases, the indexing method improved rendering speed by factors of about 23.1 and 2.4, respectively. In case of perspective projection, it took roughly 1.2 times longer than orthographic projection, although it also relies on the data sets. Notice the somewhat exaggerated 82.3% 82.4% 67.4% 74.3% 60.7% 57.8% 95.7% effect of perspective projection for the head data in <ref type="figure">Figure 7</ref> (a).</p><p>The timing results reveal several interesting facts about our enhanced algorithm. First, we see that the spatial ratio, that actually decides how many voxels are visited, is somewhat small, and that the speedup tends to be better as the ratio gets smaller (Compare El and E2 to see this.). This observation is clearly understood since the new splatting algorithm was designed to visit the rendered objects only.</p><p>Secondly, the spatial ratio is not the only factor that affects the performance. That is, the reduction in rendering time obtained by indexing is highly dependent on the scenes. Consider Bl and El that demonstrate the effect of semitransparent objects on the performance of our algorithm. Although they have almost the same spatial ratios, the timings for the two data sets are somewhat different. The main factor that made differences is the opacity transfer functions. Since a large portion of engine block (El) is semitransparent, almost all voxels are processed. In case of Bl, lots of the voxels in the behind are blocked by ones in the front without being splatted, resulting in fast rendering.</p><p>Consider how the original splatting algorithm spends rendering time. It first visits all the voxels in a volume data set one by one, doing classification of each voxel. It is shaded, and projected if it turns out to be one of the voxels of interest. Then, resampling is performed using a footprint table. The reduction in splatting time of our algorithm is made possible by not visiting unnecessary voxels using the indexing mechanism. Although just visiting and classifying each voxel takes very little time compared to the shading and resampling precesses, it is found out that accumulation of such a small effect for the whole volume data makes a prominent difference.</p><p>We have proposed a new technique that enhances the speed of splatting without trading off image quality. This new method saves rendering time by employing a simple indexing mechanism so that only voxels of interest are processed in splatting. We observe that the proposed data structure for indexing is suitable for the dynamic situation in which viewing parameters and opacity transfer functions change interactively. Tests with several data sets of useful sizes and complexities showed 57.8 -95.7% of time reduction at the reasonable cost of additional memory for indexing.</p><p>Currently, we are applying the data structure for indexing to volume ray tracing, and the preliminary results indicate a significant rendering time reduction. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 2: Orthographic Transformations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>we can get the (u, w) point on the image plane after the orthographic projection as follows : u = uo(q-p)+i.(uoi)+j.(uoj)+k.(uok) W = ve(q-p)+i.(voi)+j.(voj)+k.(vok)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(q-p)ou, (q-p)ov, uoi, uoj, uok, voi, voj, and vok are computed only once, and k . (u o k) and k -(v o k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>iFigure 4 :</head><label>4</label><figDesc>An Example SGVR Session Figure 3: Perspective Transformations projector connecting e and a voxel (i, j, k) can be expressed parametrically as L(t) -e-(1-t)+(q+i.i+ j. j+k.k).t = (q-e+i.i+j.j+k.k)*t+e. Then, for the parameter value to corresponding to the intersection of the projector with the image plane, (L(to)-p)ow = 0, and solving it for to results in to = -w 0 (P -4 wo(q-e)+i.(woi)+j.(woj)+k.(wok) As in orthographic projections, the intersection point can be expressed for the unknowns u, V, and w as p$-U~U+W.v+w.w = {(q-e)+i.i+j.j +k*k}.to+e From this, we can show that the mapped point (u, w) (w must be zero.) is computed as follows : u = {uo(q-e)+i.(uoi)+j.(uoj) +k+(uok)}-to-uo(p-e) W = (vo(q-e)+i.(voi)+ j.(voj) +k.(vok)}.to-vo(p-e)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) and (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Comparisons of Two Algorithms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Perspective CT Head and MFkI Human Brain (a) engine block (b) part of engine Engine Block</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1070">-2385/95$4.00@1995IEEEProceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)1070-2385/95 $10.00 © 1995 IEEE</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)1070-2385/95 $10.00 © 1995 IEEE</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">'74Proceedings of the 6th IEEE Visualization Conference(VISUALIZATION '95)1070-2385/95 $10.00 © 1995 IEEE</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to Mr. Philippe Lacroute who helped get the test data sets.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast algorithms for volume ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Danskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1992 Workshop on Volume Visualization</title>
		<meeting>the 1992 Workshop on Volume Visualization<address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="91" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Introduction to Volume Visualization</title>
		<editor>A. Kaufman</editor>
		<imprint>
			<date type="published" when="1991" />
			<publisher>IEEE Computer Society Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast volume rendering using a shear-warp factorization of the viewing transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="458" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hierarchical splattings : A progressive refinement algorithm for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanraban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="285" to="288" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Display of suirface from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Efficient ray tracing of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">ACM Zkansactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="261" />
			<date type="published" when="1990-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient synthetic image generation of arbitrary 3-d objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meagher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Pattern Recognition and Image Processing</title>
		<meeting>the IEEE Conference on Pattern Recognition and Image Processing</meeting>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="page">473478</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A rendering algorithm for 3d scalar fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sabella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Applying space subdivision techniques to volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Subramaanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fussell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;90</title>
		<meeting>Visualization &apos;90<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="150" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">V-buffer: Visible volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Upson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keeler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="59" to="64" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Footprint evaluation for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="367" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Splatting -A parallel, feed-forward volume rendering algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991-07" />
		</imprint>
		<respStmt>
			<orgName>Dept. of Computer Science, Univ. of North Carolina at Chapel Hill</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Octrees for faster isosurface generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM lFansactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="227" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
