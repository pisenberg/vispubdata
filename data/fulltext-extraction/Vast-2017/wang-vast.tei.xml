<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Causality Analysis Made Practical</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
							<email>junwang2@cs.stonybrook.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Mueller</surname></persName>
							<email>mueller@cs.stonybrook.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="laboratory">Visual Analytics and Imaging Lab</orgName>
								<orgName type="institution">Stony Brook University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">IEEE Conference on Visual Analytics Science and Technology (VAST)</orgName>
								<address>
									<addrLine>October 1-6, Phoenix</addrLine>
									<postCode>2017</postCode>
									<region>Arizona</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Visual Causality Analysis Made Practical</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visual knowledge discovery</term>
					<term>Causality</term>
					<term>Hypothesis testing</term>
					<term>Visual evidence</term>
					<term>High-dimensional data</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Deriving the exact casual model that governs the relations between variables in a multidimensional dataset is difficult in practice. It is because causal inference algorithms by themselves typically cannot encode an adequate amount of domain knowledge to break all ties. Visual analytic approaches are considered a feasible alternative to fully automated methods. However, their application in real-world scenarios can be tedious. This paper focuses on these practical aspects of visual causality analysis. The most imperative of these aspects is posed by Simpson&apos; Paradox. It implies the existence of multiple causal models differing in both structure and parameter depending on how the data is subdivided. We propose a comprehensive interface that engages human experts in identifying these subdivisions and allowing them to establish the corresponding causal models via a rich set of interactive facilities. Other features of our interface include: (1) a new causal network visualization that emphasizes the flow of causal dependencies, (2) a model scoring mechanism with visual hints for interactive model refinement, and (3) flexible approaches for handling heterogeneous data. Various real-world data examples are given.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The urge to find the causal explanations behind one or more observed phenomena is an inherent trait of human nature, and the massive growth of data can help satisfy this innate curiosity. While correlation has been widely used as evidence of causation, relations derived in this way can be ambiguous and often even spurious (A great many of such examples can be found at the website of spurious-correlations <ref type="bibr" target="#b0">[1]</ref>). What is needed is a dedicated causality framework capable of measuring the dependency between two variables in the context of another set of controlled variables. While a number of algorithms have been devised for identifying causal relation in multivariate data, these algorithms typically cannot encode existing domain knowledge, or even common sense, to guide their analyses. This, in turn, leads them to hold strong assumptions on data distributions which can rarely be satisfied in practice. A remedy to overcome this significant shortcoming is to insert a human into the casual inference loop as a synergist partner.</p><p>This realization has led to efforts that use a visual analytics approach to casual inference, called visual causality analysis. It allows human experts endowed with domain knowledge and intuition to refute or propose causal links. We proposed a prototype of such an interface in an earlier paper <ref type="bibr" target="#b1">[2]</ref>, called the Visual Causality Analyst. It utilizes a 2D graph visualization of causal networks and a set of interactive tools that users can employ to examine the derived relations. While effective, this interface is nevertheless relatively simple and can only provide very basic functions of operating on a single model. Real world scenarios, however, incur many practical difficulties that such a simple tool cannot handle. The greatest practical challenge is posed by Simpson's Paradox <ref type="bibr" target="#b2">[3]</ref> which states that a relation held in the general population may be altered in data sub-groups given proper partitions. A widelyused example for this phenomenon is the 1973 discovery of an apparent gender bias favoring male applicants in the graduate school admissions at UC Berkeley <ref type="bibr" target="#b3">[4]</ref>. However, in fact, the gender bias was reversed when each department was considered separately -6/85 departments appeared to favor females while only 4/85 appeared to favor males. This discrepancy was not deliberating but explainable by unrelated admission facts. For causality analysis, Simpson's paradox implies that possibly multiple causal models underlie a dataset, each for a certain subrange of the data across the factors. We propose a new set of tools to help analysts recognize where such decompositions might be appropriate and allow them to subdivide the data along certain dimensions or into clusters. In addition, we also provide facilities that allows analysts to compare between and extract credible relations from the derived multiple causal models via a pooling process that can either occur at the causal link level or at the model level.</p><p>Another challenge is that real-world problems often have a mix of numerical and categorical (ordinal, nominal) data. This stands at odds with current causality algorithms which can only handle either numerical or categorical variable, but not both. To make the data homogeneous, we can either bin all numeric variables into categorical ones, or use our method <ref type="bibr" target="#b1">[2]</ref> which transformed the categorical variables into numerical ones using a global re-spacing and re-ordering scheme. The problem with this scheme was that the distribution of the levels remains to be sparse which adds complexity to the casual inferencing. We propose a novel levelenrichment scheme that absolves this problem, and along with it, we also devise a set of generalized inference algorithms with flexible options for handling heterogeneous data.</p><p>Finally, causal models are often drawn in form of general directed networks and graphs in which flows of causal dependencies are hard to recognize. This also impedes the practical use of causality analysis as an analytics platform for general use. We have devised a new and more appropriate visualization of causal networks in form of path diagrams laid out using spanning trees. We find that these path diagrams give causal flows an effective narrative structure.</p><p>In general, the major contributions of this paper include:  A new visualization of causal networks that better exposes the flow of causal sequences;  A scoring function along with corresponding visual hints that can be used to compare alternative causal models;  An improved method for handling heterogeneous data in causal inference along with their experimental evaluation; </p><p>Interactive facilities that allow users to explore data subdivisions from which different models can be inferred;  Mechanisms for diagnosing (or pooling) all derived models to recognize valuable causal relations and patterns. And all of these techniques have been implemented into a novel visual interface we call the Causal Structure Investigator (CSI). The teaser image in <ref type="figure" target="#fig_0">Fig. 1</ref> shows its individual components.</p><p>Our paper is structured as follows. Section 2 discusses related work. Section 3 briefly introduces the interface components and then presents detailed techniques used in the CSI framework for visual analysis of a single model. Section 4 discusses the impact of data partition on causal inference. Then two case studies, respectively, are presented in Section 5. Finally, Section 6 ends with conclusions and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Following the seminal work of Pearl <ref type="bibr" target="#b8">[5]</ref> <ref type="bibr" target="#b9">[6]</ref> and Spirtes <ref type="bibr" target="#b10">[7]</ref>, theories of causation modeling and discovery on multivariate datasets have been widely studied. Visual causality analysis has also become a popular topic in the field of visual analytics (VA) in recent years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Causality Modeling and Inference</head><p>The set of causal relations between variables of a multidimensional dataset is usually depicted as a Directed Acyclic Graph (DAG) where variables are nodes and a directed edge between two nodes means the first causes the second. Algorithms learning the structure of such DAGs can be roughly classified into two categories -scorebased algorithms and constraint-based algorithms. The former typically associate a DAG with a score function, e.g. the Bayesian Information Criterion (BIC) <ref type="bibr" target="#b11">[8]</ref> <ref type="bibr" target="#b12">[9]</ref>, and performs, for instance, a greedy search in the space of all possible DAGs. Examples are the GES algorithm <ref type="bibr" target="#b13">[10]</ref> and the K2 algorithm <ref type="bibr" target="#b14">[11]</ref>. Since the number of possible structures is super-exponential in the number of variables, such algorithms usually suffer from high search cost. In contrast, the constraint-based algorithms build causal networks according to the constraints of dependencies and conditional dependencies in the data. Some well-known algorithms are SGS <ref type="bibr" target="#b10">[7]</ref>, PC <ref type="bibr" target="#b10">[7]</ref> <ref type="bibr" target="#b15">[12]</ref>, IC <ref type="bibr" target="#b16">[13]</ref>, Total Conditioning <ref type="bibr" target="#b17">[14]</ref>, and others. These constraints are usually learned with conditional independence (CI) tests via partial correlation <ref type="bibr" target="#b18">[15]</ref>, G 2 statistics <ref type="bibr" target="#b19">[16]</ref>, or other techniques <ref type="bibr" target="#b20">[17]</ref> <ref type="bibr" target="#b21">[18]</ref>. It is important to note that such algorithms are commonly based on several strong assumptions of data distributions which are rarely satisfied by real-world data. As a consequence, none can guarantee an exact model, especially when there are latent or nonlinearly related variables.</p><p>Several causal modeling methods can be used to parameterize the learned DAG. The two most common choices are Bayesian Networks (BN) <ref type="bibr" target="#b8">[5]</ref> <ref type="bibr" target="#b22">[19]</ref> and Structural Causal Models (SCM) <ref type="bibr" target="#b9">[6]</ref> <ref type="bibr" target="#b23">[20]</ref>. The former quantifies causal relations with conditional probability tables, and the latter with linear functions plus Gaussian noise, e.g. linear regression and logistic regressions. As the knowledge of data distribution required in BN is usually hard to acquire in practice, we will use the algorithm of Total conditioning and PC in this paper to infer causal structures and then parameterize them as SCM models. <ref type="figure" target="#fig_1">Fig. 2</ref> pictures the workflow of visual causality analysis proposed by Chen et al. <ref type="bibr" target="#b24">[21]</ref>, aiming to provide decision support in a typical organization and aid hypothesis generation and evaluation in a scientific investigation. One of the earliest attempts of such a system is the Growing-polygons <ref type="bibr" target="#b25">[22]</ref> scheme which captures causation at the process level, i.e. as a sequence of causal events. It uses animated polygon colors and sizes to signify causal semantics. The work of Vigueras and Botia <ref type="bibr" target="#b26">[23]</ref> considers ordered events in a distributed system as causations and visualizes their dependencies as causal graphs. Focusing on the upstream-downstream relations of variables, ReactFlow <ref type="bibr" target="#b27">[24]</ref> visualizes causal relations as pairwise pathways connecting duplicated variables in two columns. Some other efforts in the visual mining of causation include OutFlow <ref type="bibr" target="#b28">[25]</ref> and EventFlow <ref type="bibr" target="#b29">[26]</ref>. Both visualize temporal event sequences as alternative pathways and use event chains to explore embedded patterns. Liu et al. <ref type="bibr" target="#b30">[27]</ref> visualize event streams as flows aligned by event types. However, none of these above systems leverages automated algorithms for causal discovery, and so they require significant user input to acquire such knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Causality Analysis</head><p>The first visual interface with the capability of automatic causal inference was proposed by us in previous work <ref type="bibr" target="#b1">[2]</ref>. It visualizes causal networks as color-coded 2D graphs with force-directed layouts and offers a set of interactive tools for the user to examine the derived relations. The graph visualization we employed in this previous work has also been widely used in visualizing Bayesian belief networks <ref type="bibr" target="#b31">[28]</ref>, correlation networks <ref type="bibr" target="#b32">[29]</ref>, uncertainty networks <ref type="bibr" target="#b33">[30]</ref>, and many other graph-based analytic models <ref type="bibr" target="#b34">[31]</ref> <ref type="bibr" target="#b35">[32]</ref>. The work in this paper is inspired by these methods but will provide a much-improved visualization and more comprehensive analytic capabilities that can handle many practical difficulties in real-world causality analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VISUAL INFERENCE OF SINGLE CAUSAL MODEL</head><p>The design of the CSI interface ( <ref type="figure" target="#fig_0">Fig. 1</ref>) fulfills the requirements of a causality VA system proposed by Chen et al. <ref type="bibr" target="#b24">[21]</ref>  <ref type="figure" target="#fig_1">(Fig. 2)</ref>. More specifically, the parallel coordinates view <ref type="figure" target="#fig_0">(Fig. 1c</ref>) serves as the component for data visualization. Users have the option to start from either a causality model or a correlation graph <ref type="figure" target="#fig_0">(Fig. 1a)</ref>. The path diagram view ( <ref type="figure" target="#fig_0">Fig. 1b</ref>) and the regression analysis view <ref type="figure" target="#fig_0">(Fig.  1d</ref>) then allow the visual analysis of both causation and correlation. The analytics on local causation models are achieved through the data subdivision view ( <ref type="figure" target="#fig_0">Fig. 1e</ref>) and the model heatmap ( <ref type="figure" target="#fig_0">Fig. 1f)</ref>, with which user can visually examine each model derived from a data subdivision as well as the pooled models, getting full support for decision making and hypothesis evaluation.</p><p>In this section, we will describe the various features of our framework in terms of a single model, which serves two major purposes: (1) communicate the automatically derived relations for the causal network and (2) allow users to examine their own proposed causal links as well as ones derived by algorithms. The next section will then expand it to analyze multiple models arising from data subdivisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Causal networks visualization</head><p>As mentioned, although force-directed graphs could be a feasible choice for demonstrating the overall structure of the network, they often suffer from a dense and unpredictable layout. With such layouts, local structures in causal sequences can become difficult to observe especially when they are part of more complex networks. However, these local structures can often be of great interest to domain users. For instance, Dang et al. <ref type="bibr" target="#b27">[24]</ref> show that recognizing the upstream and downstream causal relation of variables is commonly required by biologists when examining relations between proteins and biochemical reactions. While their work succeeds in visualizing local causal relations as pairwise pathways, it is less successful in conveying global structures of the network.</p><p>We aimed to create a framework that would convey both local causal sequences as well as the overall network structure. For this, we devised a new approach that visualizes causal networks as path diagrams. In a causal path diagram, a causal relation is visualized as a straight or curved path from the cause to the effect variable denoted by named nodes. Such design is inspired by previous works using pathways to represent relation or event flows <ref type="bibr" target="#b27">[24]</ref> <ref type="bibr" target="#b28">[25]</ref>. The arrow mark in the middle of a path signals the direction of the relation. To remit the clutter of local structures, i.e. sequences of causal relations, the path diagram is laid out using spanning trees of the network built with Breadth-first Search. More specifically, we first layout the nodes of the spanning trees to fit the canvas in a left-to-right manner regarding their parent-child relations, and then add back all edges during rendering. Variables not related to others shall be isolated at the bottom. By such, most paths of causal sequences will connect and direct from left to right, intuitively forming causal stories. Finally, although the generated diagrams are usually clear enough for demonstrating the causal paths, users are also allowed to adjust it manually by dragging each node.</p><p>Besides the directional structure, parameterized relations also come with a set of statistical coefficients quantitatively measuring their strengths and significances. In our interface, the width of a path signifies the strength of the relation measured by linear (targeting numeric variables) or logistic (targeting categorical variables) regression coefficients. Using the color code for causal semantics we proposed in <ref type="bibr" target="#b1">[2]</ref>, green paths denote positive causal influence and red paths denote a negative influence. Compound relations between levels of categorical variables and other variables are colored yellow. Node colors indicate variable type -blue for numeric and yellow for categorical. A node's border thickness suggests the goodness of fit of the variable's regression model measured by r-squared (for linear regression) or McFadden's pseudo r-squared (for logistic regression) coefficients <ref type="bibr" target="#b36">[33]</ref>, both have a value range of 0 to 1. <ref type="figure" target="#fig_2">Fig. 3a</ref> shows a first application, using the causal network learned from the AutoMPG dataset <ref type="bibr" target="#b37">[34]</ref>. We can observe that nodes are mostly positioned left to right in topological order following their dependencies. The flow of causations, especially those with strong relations, become even clearer after weak relations (narrow paths) have been filtered out (which is a function included in the CSI interface). For example, <ref type="figure" target="#fig_2">Fig. 3b</ref> shows the same network with a coefficient (path width) threshold of 0.3. Here we can observe several causal paths flowing from left to right. One of them is Cylinder→Displacement→ Weight→MPG, which indicates that it is weight rather than the size of the engine that is directly affecting a car's gas mileage. This can be a useful finding for a car company which now knows that it can counter-balance the adverse effect a big engine has on mpg by designing a car with a lighter chassis but designed for increased structural stability. The force-directed graph used in our earlier work <ref type="bibr" target="#b1">[2]</ref> is shown in <ref type="figure" target="#fig_2">Fig. 3c</ref> and an example for an orthogonal graph is shown in <ref type="figure" target="#fig_2">Fig. 3d</ref> where nodes are connected by orthogonal edges. Both demonstrate the AutoMPG network to facilitate a fair comparison. Compared to these two methods, we believe that our new path diagram exposes flow of causal sequences embedded in the network in a much more prominent way than the two competing methods. Future work will compare the three methods in a formal setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visual Model Refinement with Model Scoring</head><p>According to <ref type="figure" target="#fig_1">Fig. 2</ref>, one of the major tasks of visual causality analysis is to provide visual evidence supporting a user's decision on refuting or accepting causal relations. This can be achieved by scoring each relation as well as the overall network with proper metrics. Although common statistics calculated from regression residuals, e.g. F-statistics and r-squared, are capable of measuring the model goodness of fit, they usually do not take model complexity into consideration. This implies that just by adding more relations into the model these statistics will mostly improve. However, this can potentially lead to overfitting, which means that the model is an extremely good fit for the dataset from which it was learned, but generates huge errors on any other dataset recorded from the same source. Hence, based on William of Occam's parsimony principle, models should be kept as simple as possible. The idea is that by adding new relations to a causal model we obtain an improvement in its fit to the data to some degree, but at the same time the model also becomes "worse" because it is harder to fit new data. So, the question is how complex should the model be for a given dataset.</p><p>The Bayesian Information Criterion (BIC) <ref type="bibr" target="#b11">[8]</ref>[9], applicable to both linear and logistic regressions, serves well in answering this question. It rewards the improvement in fit but also punishes for increasing model complexity. For a single regression model, it is formulated as</p><formula xml:id="formula_0">BIC = −2 ln̂+ ln( )<label>(1)</label></formula><p>where ̂ is the likelihood of the model, is the number of independent variables, and is the number of data points. The BIC of a linear regression can be computed from residuals following</p><formula xml:id="formula_1">BIC = ln / + ln( )<label>(2)</label></formula><p>where the residual sum of squares = ∑( −̂) <ref type="bibr" target="#b1">2</ref> , in which ̂ is the predicted value of the dependent variable given values of independent variables in a regression equation, and is the actual observed value of the dependent variable. The likelihood of logistic regressions can be computed directly using logistic functions. Eq. 2 also suggests that a smaller BIC score with small residuals and less parameters implies a better regression model.</p><p>For each variable in a causal network, in Eq. 2 is the number of incoming directed edges. Variables with no observed cause can be fitted with a null model (with only the error term, thus = 0). As such, a causal edge is preferable only when it reduces the error term of the first part of Eq. 2 more than it increases the complexity term of the second part of the equation, i.e. it reduces the regression's BIC. Further, as suggested by Kass and Raftery <ref type="bibr" target="#b38">[35]</ref>, the difference of a regression's BIC with and without a certain independent variable can be interpreted qualitatively following <ref type="table" target="#tab_0">Table 1</ref>. According to the table, if adding a causal edge causes the BIC of the regression model to be reduced by more than 10 points, the resulting model can be deemed as "very strongly" better and the edge should be favored. Based on this fact, an automated analysis process can be applied whenever the DAG is parameterized by regressions. Since each node implies a variable regressed on its causes linked by all the incoming edges, we assign each edge a level of importance by calculating the regression's BIC change when the edge is removed while keeping all other causes. If the BIC score goes up after removing it, the edge should be recognized as valid and a green plus glyph is attached to it in the path diagram ( <ref type="figure">Fig. 4)</ref>. Otherwise, it is considered doubtful and a red minus glyph is placed. The size of the glyph encodes how much the score would change such that bigger glyphs indicate larger score changes. However, since changes larger than 10 points can all be classified into the "very strong" category, the maximum glyph size can be correspondingly fixed. As such, good causal relations, as well as false ones suggested by the data, can be visually recognized.</p><p>The sum of all the BIC calculated from these regressions can be used as the score of the overall causal network , which is</p><formula xml:id="formula_2">( ) = ∑ (3)</formula><p>where BIC is the BIC of the regression model on variable . Such a scoring strategy has also been adopted by many score-based inference algorithms to score potential causal structures <ref type="bibr" target="#b13">[10]</ref> <ref type="bibr" target="#b14">[11]</ref>. Based on the model score, a colored bar is rendered whenever the user modifies the network, showing the impact of the modification on the overall model. A red bar means the overall model score is rising and a green bar stands for a score decreasing. The length of the bar encodes by how much the score has changed. With these visual hints, users can be intimately aware if they have made a good move in their quest of refining the model under study. <ref type="figure">Fig. 4</ref> illustrates an example where we added a path from Displacement to MPG to the causal network of <ref type="figure" target="#fig_2">Fig. 3a</ref>. While most relations are valid according to the green plus glyphs, the red minus next to the newly added edge indicates that it is increasing the BIC score of the regression of MPG, thus increasing the total model <ref type="figure">Fig. 4</ref> The path diagram with model scores visualizing the AutoMPG network. A new relation from Displacement to MPG is added. However, the red minus glyph next to it and the red score bar on the right show that the relation is not valid and so should be removed.</p><p>score. The score bar shows the model score changed about 2 points ("Positive" according to <ref type="table" target="#tab_0">Table 1</ref>), so it is suggested to be removed.</p><p>It is worth noting that the Akaike information criterion (AIC) <ref type="bibr" target="#b11">[8]</ref>, which is defined very similar to BIC but with a less stringent punishment for model complexity, is also a widely applied scoring strategy used in model selection. While the AIC can work exactly the same function as BIC and might be preferred in some circumstances, we choose BIC in our implementation as it is more often adopted in causality studies and emphasis more on solving the issue of overfitting <ref type="bibr" target="#b39">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Working with Heterogeneous Data</head><p>As mentioned, heterogeneous data containing both numeric and categorical variables are problematic when learning the structure of a causal DAG. It requires a CI test method capable of testing and conditioning on variables of arbitrary distributions. However, typical CI tests using partial correlation or the 2 test can only handle either numeric or categorical data, and none can handle both. Simply binning all numeric variables and applying the 2 test can be a plausible solution but it comes at the potential price of a significant information loss. With this approach, not only is there a loss in value scales, but also the order of bins will be ignored in the 2 tests, both of which can introduce error relations in the result.</p><p>Another recently proposed solution is the Global Mapping (GM) strategy (see our earlier paper <ref type="bibr" target="#b1">[2]</ref>), which re-orders and respaces categorical variables' levels so that Pearson's correlations involving categorical variables are generally maximized with respect to all numeric variables in the dataset. This allows the CI test via partial correlation to be applied to all, which also means a faster inference process since the 2 test usually takes much longer. More specifically, the GM strategy assigns values to level of categorical variable according to the following formula:</p><formula xml:id="formula_3">( ) ∝ ∑ ( ( )) =1<label>(4)</label></formula><p>where By such, categorical variables can be simulated to be continuous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Experimental Evaluation</head><p>We evaluate the effectiveness of the GM with and without UB via three runs of experiments, comparing them to the strategy of equalwidth binning of all numeric data. We use 100 randomly generated DAGs in each run as ground truth. A DAG has 10 nodes in the first run and 15 nodes in the second and third runs. A node in a DAG has a 0.2 probability to connect to any other nodes. Coefficients of graph edges are uniformly distributed within the range [0.1, 1], based on which 10000 data points are sampled for each DAG in the first two runs and 25000 in the third run. Some randomly selected variables are then converted into categorical ones in each run with equal-width binning. The three aforementioned strategies applied with the PC-stable algorithm <ref type="bibr" target="#b15">[12]</ref> are tested under each setting, trying to reconstruct simulated DAGs from the sampled mixed-type data. All experiments were done with the R package pcalg <ref type="bibr" target="#b40">[37]</ref>.</p><p>The charts in each row of <ref type="figure" target="#fig_4">Fig.5</ref> show the results of each run. The charts in the left most column of <ref type="figure" target="#fig_4">Fig. 5 (a, e, and i)</ref> visualize the Structure Hamming Distance (SHD) error of the causal models inferred with binning all variables into 2 to 7 levels, respectively. The SHD is defined as the minimum number of edge insertions, deletions, directions, and reversions needed to transform the estimated graph into the ground truth. In SHD, the deletion or the direction of an undirected edge is each counted as one error, while it counts as two errors if a directed edge needs to be reversed. In each of the three charts, we observe that the SHD increases both when there are too few levels (equivalent to a loss of value scale) as well as when there too many (ignorance of bin order). We also </p><formula xml:id="formula_4">(c) (d) (e) (f) (g) (h) (i) (j) (k) (l)</formula><p>observe that the error increases when reconstructing a larger network (comparing <ref type="figure" target="#fig_4">Fig. 5a and e</ref>), but it drops when more data is available ( <ref type="figure" target="#fig_4">Fig. 5e and i)</ref>. The charts in the second column of <ref type="figure" target="#fig_4">Fig. 5</ref> (b, f, j) demonstrate the SHD from GM (red boxes) and GM+UB (blue boxes) under the situation that at most 50% of variables are categorical. While the error increases when more categorical variables are introduced, both of the two strategies outperform the best case from binning in all three runs (compare <ref type="figure" target="#fig_4">Fig. 5a, e, and i)</ref>. A deeper inspection is offered when looking at charts in the right two columns of <ref type="figure" target="#fig_4">Fig. 5  (c, d, g, h, k, and l)</ref>, which shows the average True Positive Rate (TPR, the number of correct edges out of ground truth edges) and True Discovery Rate (TDR, the number of correct edges out of all found edges) of the results. Edge directions are omitted here. We learn from <ref type="figure" target="#fig_4">Fig. 5c</ref>, g, and k that GM+UB (blue line) generally shows a better TPR than GM (green line), which means more correct relations are discovered. However, when looking at <ref type="figure" target="#fig_4">Fig. 5d</ref>, h, and l, the TDR from GM+UB drops much faster than the pure GM when there are more than 4 categorical variables in the first two runs and 5 in the third run, which means many error relations are falsely linked too. Also, both GM strategies tend to introduce more spurious relations than binning with more categorical variables in the dataset. We suspect that when the ratio of categorical variables is too large, the global re-ordering and respacing can no longer preserve the fidelity of the data.</p><p>Taking all of the experiment results into consideration, we suggest users take the GM strategy whenever no more than 30% of the variables in a dataset are categorical, while UB can further boost the inference accuracy. When there are more categorical variables, binning numeric variables could be a more plausible choice. Finally, we would like to stress that the strategy is only applied when learning the structure of causal networks. Conversely, in the subsequent parameterization, the original levels of the categorical variables are used as they can be well handled by logistic regressions. Our GUI allows users to choose any of the three methods when working with heterogeneous datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CAUSALITY ANALYSIS WITH MULTIPLE MODELS</head><p>As mentioned, our framework also supports the visual investigation of multiple causal models underlying a dataset. We now present details of this mechanism, along with illustrative examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Causal Inference on Data Subdivisions</head><p>According to Simpson's Paradox, a relation found in the overall data may not hold in certain data subdivisions, and conflicting relations buried in some specific data ranges may cancel each other so that none can be observed in the general population. Such effect has often been observed in correlation analysis <ref type="bibr" target="#b32">[29]</ref>. For example, by bracketing the price of a product to lower ranges one may see positive correlations with sales, while negative correlations come with a higher price range. What's more, causal relations with opposite directions may also exist as feedback loops. For instance, the price of a product will affect sales when sales are low, but a large number of sales can also reduce the cost and so lower the price. As a result, it is often the case that multiple causal models differing in both structure and regression parameters can arise from data partitions. Ignoring such facts and always learning the model using the whole dataset will potentially lead to faulty relations returned by inference algorithms. Without data partitioning, the regression model constructed will probably contain considerable large residuals. Seeing that the BIC of a model is computed from such residuals (Eq. 2), refining these miscalculated causal models based on their score change can also be difficult in this situation.</p><p>To eliminate or at least reduce such disturbances and reveal the different causal models hiding in the data, an interactive parallel coordinates interface <ref type="figure" target="#fig_0">(Fig. 1c)</ref> is employed in our CSI framework. Via the parallel coordinates, users can directly observe potentially attractive data subdivisions and partition the data by adjusting the brushed value range of variables. Conversely, data partitions can also be detected automatedly based on unique values of some variables or as data clusters recognized by clustering algorithms, using the interactive facilities shown in <ref type="figure" target="#fig_0">Fig. 1e</ref>.</p><p>These interactive facilities also allow users to manage the recognized partitions. Users can save a partition as a tag, recall it in the parallel coordinates by clicking the tag, or fit it to a causal structure by hitting the "Fit Model" button. Most importantly, they can learn a causal model from each such data subdivision and refine it with the visual approaches introduced in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Illustrative Example</head><p>We now demonstrate how to discover different causal models from data with the CSI interface through an illustrative example, leveraging the Sales Campaign dataset. This dataset contains 10 numerical variables and 600 records describing several important factors in sales marketing and their effects on a company's financials. Each sample in the dataset represents a sales person's sales behaviors. Three data clusters have been recognized by kmeans clustering <ref type="bibr" target="#b41">[38]</ref> and are colored blue, yellow and red, respectively (with interactive facilities shown in <ref type="figure" target="#fig_0">Fig. 1e</ref>). It is worth noting here that while we have implemented the k-means in the current version of the CSI interface for illustration, the proper choice of clustering algorithms may vary depending on the data. When constructing the causal model, we assume the following background knowledge. A sales pipeline starts with a lead generator developing prospective customers called Leads. When some leads return positive feedback, they become WonLeads and an increased sales pitch at cost of CostPerWL is invested in each of them, so that they might be further developed into real customers called Opportunities. The TotalCost reports the actual cost of each sales person. The goal of the entire efforts is to increase the expected return on investment (ExpectROI) and ultimately maximize the pipeline revenue (PipeRevn).</p><p>In our earlier work <ref type="bibr" target="#b1">[2]</ref> we found several meaningful relations but these were conjunctive over the entire population of sales people in the dataset. However, when looking at the three clusters in the parallel coordinates in <ref type="figure" target="#fig_5">Fig. 6a</ref> it seems more meaningful to consider the three groups of sales people separately, as it is obvious that they are behaving very differently. It is likely that by doing so specific sales plans can be strategized for each of them. Hence, we click the "Infer on Each" button in <ref type="figure" target="#fig_0">Fig. 1e</ref> and three causality graphs are generated (see <ref type="figure" target="#fig_5">Fig. 6b, c, and d)</ref>. They allow specified prescriptive analytics to be made for each sales group.</p><p>First, it is interesting to note that the three causality graphs have some structures that are similar, which is consistent with the background knowledge that there must be some marketing model guiding the sales behaviors. From the three graphs, one can see that CompRate, PlanROI, and PlanRevn are not related in the pattern and thus adjusting any of these variables will likely not affect revenue. A relation observed in all three graphs is that ExpectROI is directly affecting PipeRevn in a positive manner. This implies that the company's revenue prediction model seems to work well. TotalCost is consistently caused by CostPerWL, which is reasonable as investing in each customer represents the major costs in the pipeline. Further sound business facts realized by all groups are: (1) higher TotalCost will reduce ExpectROI, and (2) more Leads will require a reduction of CostPerWL (which is natural when the budget is fixed).</p><p>However, the pathway CostPerWL→Opportunity→ExpectROI is somehow different for each model, implying distinct patterns in each group's sales behaviors. In the causality graph of the blue cluster ( <ref type="figure" target="#fig_5">Fig. 6b)</ref>, it is striking to see that more investment on each won lead is not bringing them more "opportunities" (referring to the negative effect of CostPerWL on Opportunities), i.e. they might have invested too much on each customer and probably inappropriately. But, the opportunities they get with their approach are profitably increasing ExpectROI and revenue, and so overall, they are successful. In contrast, the sales people in the yellow group <ref type="figure" target="#fig_5">(Fig. 6c</ref>) are gaining more opportunities from their investments (referring to the positive relation from CostPerWL to Opportunities), however, this is not bringing them more revenue, as Opportunities is not positively related to ExpectROI. Thus, they should work on increasing the profit of each closed deal. Finally, the sales group of the red cluster converts much less ExpectROI into PipeRevn, as indicated by the thinner green arrow between these two in <ref type="figure" target="#fig_5">Fig. 6d</ref>. Based on the negative causal relation from Opportunities to ExpectROI, this may have similar reasons than for the yellow cluster that their deals are not profiting, although their generous investment in CostPerWL does bring them many opportunities. They might better reduce the cost of each won lead and focus on increasing the profit.</p><p>Based on the different causal patterns observed, the analyst team may have many suggestions for each sales group. While discussing these specific strategies is beyond the scope of our research we believe that the case study presented here has shown that causality analysis with data partitioning can indeed reveal different causal facts hidden in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Causal Model Visual Diagnostics</head><p>While causal inference on data subdivisions can result in multiple models revealing different causal patterns, diagnosing these models by investigating their similarities can often reveal interesting knowledge, especially when the data is bracketed into a large number of subsets and a corresponding number of models are learned. Meanwhile, doing so also brings the issue that the number of data points available to learn each model will be heavily reduced with more partitions added. This may potentially lower the statistical saliency of causal relations so that they may often be missed. Reducing p-value thresholds in CI tests could be a solution, however, it also results in more false relations and thus in less credible models.</p><p>To uncover the common causal patterns and extract reliable relations from all learned models, we propose a visual pooling process that can either occur at the causal link level or at the model level. In the following, we shall present the specific visual pooling strategies leveraging a real-world dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Pooling at the Causal Model Level</head><p>The purpose of pooling at the causal model level is to recognize the possible grouping of causal models so that common causal relations can be summarized from models in the same group and different causal trends can be compared between models in different groups. To achieve this, we represent each causal graph as an adjacency matrix. Since a causal model features both its structure and parameters, we use the regression coefficient of each edge as the corresponding element in the matrix. Then, we can pool at the causal model level by clustering these adjacency matrices to uncover the different causal mechanisms embedded in them.</p><p>To demonstrate this method, we utilize the Ocean Chlorophyll dataset. The dataset was merged from several satellite data sources <ref type="bibr" target="#b42">[39]</ref>[40][41] <ref type="bibr" target="#b46">[42]</ref>, monitoring the area of S22° ~ S25°, E50° ~ E53° (located at the south Madagascar sea). Each data source contains a particular physical property -ocean surface temperature, surface currents speed, wind speed, thermal radiation, precipitation rate, and water mixed layer depth, or a biological propertyphotosynthesis radiation activation and chlorophyll concentration. These satellite data come in different horizontal resolutions and were recoded into a 0.25-by-0.25-degree resolution in longitude and latitude. At each of the 169 geolocations, the time series spans 12 years (from 1998 to 2009) and were averaged in months (thus 144 data points). Partitioning data by each geolocation, 169 causal models are learned. <ref type="figure" target="#fig_0">Fig. 1f</ref> contains the heatmap of these models, where a darker tile denotes a model with a lower model score (thus better goodness) following the criterion in Section 3.2. <ref type="figure" target="#fig_0">Fig. 1b</ref> is the causal model denoted by the highlighted tile (that is colored in orange) in <ref type="figure" target="#fig_0">Fig. 1f</ref>.</p><p>To find possible groupings of the 169 models derived from the dataset, we apply k-medoids clustering <ref type="bibr" target="#b47">[43]</ref>, which is good at finding the representative objects among all. Here, by setting = 3 with the controls in <ref type="figure" target="#fig_0">Fig. 1f</ref>, a new heatmap is generated in <ref type="figure" target="#fig_6">Fig.  7a</ref>. The three tiles marked with numbers denote the medoid models found by the clustering algorithm, i.e. the most representative model in each cluster. These three medoid causal models are visualized in <ref type="figure" target="#fig_6">Fig. 7b (blue cluster)</ref>, c (red cluster), and d (green cluster). Here we place the nodes at the same location for each model to make comparisons easy for the analyst. As he has been trying to use this dataset to relate the unique cycle of the chlorophyll concentration variation with other variables, the most attractive difference for him could be that the ChlrConc is associated with other variables differently in the three representative models. Users can also examine other models by clicking on tiles of the heatmap. Also, we can cluster models into more groups with controls shown in <ref type="figure" target="#fig_0">Fig. 1f</ref>, although we observe there are indeed three dense areas in the t-SNE layout <ref type="bibr" target="#b48">[44]</ref> of these models' adjacency matrices in <ref type="figure" target="#fig_6">Fig. 7e</ref>. The t-SNE layout is not included in the current CSI interface but can be easily incorporated in future extension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Pooling at the Causal Links Level</head><p>To summarize the common and credible relations from models in each cluster, we need to conduct pooling at the causal links level. The simplest pooling strategy that occurs at the causal link level is to count the frequency of each possible causal relation observed in all models. Then by setting thresholds on such statistics, only causal relations observed more than a certain number of times are returned, resulting in a combined model. A shortcoming of such strategy is that it equally considers all observed causal models, while they may actually have different levels of credibility. This might be fine for datasets in which all bracketed subsets enclose a sufficient number of records. But for other scenarios where the dataset is bracketed into a large number of subdivisions each containing only limited data samples, pooling by frequency may potentially enlarge the impact of the false relations found in low credibility models. When a group of models is following similar causal processes, it is reasonable to infer that those true causal relations will be observed frequently in models with higher credibility so that they should be emphasized in pooling; while models with lower credibility can be considered random noise and thus should have a small weight. When a dataset is evenly partitioned (this is important as BIC is sensitive to sample numbers in Eq. 2), the credibility of causal models learned from each data subset can be measured by their model scores. Then, as all possible causal relations form a complete graph, we assign each edge of the graph a normalized score calculated by summing up the credibility of all models in which the relation is observed. Specifically, the credibility score ( ) for edge is calculated as is the score of model , while and are the largest and the smallest score of all models. By such, we consider edges with larger ( ) are with higher credibility. Users can then work with a slider control to filter out edges with small scores, leaving only reliable relations.</p><formula xml:id="formula_5">( ) = ∑ ( − ) ( − )<label>(5)</label></formula><p>We illustrate the effect of such pooling strategy by continuing the example of the Ocean Chlorophyll dataset. After clustering the causal models into three clusters, three combined models are pooled and shown in <ref type="figure" target="#fig_6">Fig. 7f, g</ref>, and h respectively. Here a credibility threshold of 0.5 is applied so that only strong credible causal relations are retrieved. Looking at the three models, there are seemingly some causal loops between environmental and biological variables in the whole area as causal relations with opposite directions between the same pair of variables are observed in different models. But one direction of the loop could be more dominating than the other in some sub-areas. For example, MaxLayrDepth is a good predictor of PhotActiRadi in the pooled models of the blue and the red clusters but the relation is reversed in the green cluster's model. Similarly, MaxLayrDepth is he only variable strongly associated with ChlrConc but the causal mechanisms are different in the three models. The scientific implication behind these findings could be rich but explaining them goes beyond the purpose of this paper. But the presented example has demonstrated the effectiveness of our pooling methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CASE STUDIES</head><p>In this section, we further demonstrate the use of the CSI interface by analyzing two real-world datasets with all the techniques proposed in previous sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Case Study -Presidential Election Dataset</head><p>Donald Trump's unexpected triumph in the 2016 US Presidential Election has gathered worldwide attention and sparked extensive discussion. Since most polls and political analyses before the election failed to predict the win, there has been strong interest in finding the causes of what led to it. In an attempt to gain insight into this question, we have used our framework to conduct a causality analysis on the Presidential Election dataset. The dataset contains variables of the county-level election results and of each county's selected geographical features, i.e. population, vote rate, race ratios, income level, the level of education, etc., which are extracted from a more inclusive Kaggle data archive <ref type="bibr" target="#b49">[45]</ref>. To analyze the dataset using our CSI interface, we first load the data and then select variable types (categorical or numeric) as well as data preparation method (GM with UB or equal-width binning) via the pop-up window shown in <ref type="figure" target="#fig_7">Fig. 8a</ref>. Then the data is visualized in the parallel coordinates as shown in <ref type="figure" target="#fig_7">Fig. 8b</ref>. Here data points corresponding to counties of the 11 swing states (according to the website Politico <ref type="bibr" target="#b50">[46]</ref>) are brushed, as the election results in these areas are more decisive and Trump won in most of them. Then by clicking "Go Causality!" the causal network of <ref type="figure" target="#fig_7">Fig. 8c</ref> is returned.</p><p>We can observe many interesting causal relations in <ref type="figure" target="#fig_7">Fig. 8c</ref>. For example, Age65Plus and White (population percentage of those aged 65 or plus and those identified as White) are positively causing TrumpSupport, which is the supporting rate of candidate Trump in the county. This means that older people and Whites are mostly supportive for Trump. What's more, both of these two variables are positively causing VoteRate via different causal paths, implying Trump supporters are voting actively. On the other hand, those who were not preferring Trump are the immigrants and people with high education level, referring to the negative relation from ForeignBorn and BachelorDegree to TrumpSupport. However, the negative causal path ForeignBorn→ BachelorDegree→ Age65Plus→ VoteRate says that more immigrants and more people with Bachelor degree may indirectly hurt voting rate. Besides, when looking at the parallel coordinates, values on the axes of ForeignBorn and BachelorDegree are generally much smaller than values on axes of Age65Plus and White, suggesting the latter two are much bigger groups.</p><p>There are many more causal patterns we can observe that may entail various social facts. We cannot list them all here. While the presented analytics has explained the major reasons behind Trump's victory, we believe the causality analysis can also be applied to other political datasets, e.g. poll data, in a similar manner, which can potentially improve prediction accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">The ACT Dataset</head><p>The original ACT dataset <ref type="bibr" target="#b51">[47]</ref> was used to study why high school graduates change majors at college and has been modified so that its variables are more suited in a causality context. There are about 230,000 data points each represents a participated student. A student would report his/her college major three times in total -the expected one at the senior year of high school (T1) and the actual major at the first and second year of college (T2 and T3). Majors are categorized into 18 fields. A test was also conducted at each point in time quantifying the student's fitness for his choice (Fit_T1/T2/T3). Other factors considered include a student's gender, ACT score, attended college type (2 or 4 years), and transfer between colleges.</p><p>Since there are two times at which a student may change majors (T1 to T2 and T2 to T3), we arrange the variables into two different but overlapping groups, each corresponds to a sub-dataset. We then further subdivide the first sub-dataset based on students' major at T1 and the second based on major at T2, so that students selecting different fields are studied separately, avoiding possible disturbances by Simpson's Paradox. Conditioning on these subdivisions, 36 causal networks (18 majors ×2 sub-datasets) are inferred and refined with our CSI framework. Some are visualized in <ref type="figure">Fig. 9</ref>. Again, we place the nodes at the same location for each model from the same sub-dataset to facilitate comparison. <ref type="figure">Fig. 9a, b</ref>, and c are the causal models learned correspondingly from students who claimed at T1 that they would take Computer Science and Math, Health Science, and Business in college. Here Changed_T2 indicates whether the student entered a different major in the first year of college. There are some interesting observations when comparing the three figures. For example, in <ref type="figure">Fig. 9a</ref>, we see there is a gender bias indicated by the positive edge Gender → Changed_T2. As males are valued 1 in the binary variable Gender, this implies that they are more likely than females to major differently from what they expected earlier. Meanwhile, ACTScore is also playing as a positive motivation. However, the two relations become just the opposite in <ref type="figure">Fig. 9b</ref>, implying that a low ACT score would very likely make a girl, who initially wanted to take Health Science, attend another major. It also appears that students who wanted to enter Business schools are the only group among the three who considered their fitness to the major (referring to Fit_T1 → Changed_T2 in <ref type="figure" target="#fig_7">Fig. 8c</ref>), even though they usually didn't get to change to a better fitting one (the negative edge Changed_T2 → Fit_T2). As each data subdivision has a sufficient but different number of data points, the strategy of pooling by frequency is then applied. <ref type="figure">Fig. 9d</ref> shows the causal relations pooled from the 18 models with a frequency threshold of 0.5. We see that a student's decision for college major is generally affected by his ACT score and the type of college he had been admitted to, while the fitness score is seemingly irrelevant in most cases.</p><p>To see the motivation behind the major switch of a college student actually taking the above three majors at T2, the second data-subset variables are analyzed. <ref type="figure">Fig. 9e</ref>, f, and g are the corresponding causal networks and <ref type="figure">Fig. 9h</ref> is the pooled model with the frequency threshold of 0.5. From these visualizations, we can see that the transfer of college now becomes the most common reason for a student to change major, regarding the edge Transferred → Changed_T3 in the three models as well as in the pooled model, while gender bias can only be observed in very few fields, e.g. the edge Gender →Changed_T3 observed in <ref type="figure">Fig. 9f</ref> but not in <ref type="figure">Fig. 9e and 9g</ref>. Again, the fitness score is generally shown to be irrelevant.</p><p>Due to space limitations, we cannot list all inferred models here, but examining them comparably can surely lead to many more interesting findings. Nevertheless, the case study on the ACT dataset has demonstrated that different models underlying data subdivisions can be effectively uncovered with our CSI framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We have presented several new VA techniques for making visual causality analysis more practical for real-world applications. All of these new visual analytical methods were implemented in our CSI (Causal Structure Investigator) interface. They are general and applicable to a wide set of real world cases as demonstrated by examples and case studies presented in this paper.</p><p>In future work, we would like to compare different causal network visualizations with user studies, such that the most receptive one can be chosen accordingly. Further, we also plan to visualize the differential network so that two or more causal models can be compared visually in a single visualization.</p><p>A present limitation of our framework is that it does not support causality analysis on time series data, which would have many popular applications, such as finance, health, etc. A possible solution is to utilize the theory of logic-based causality, which can be capable of learning causes of certain events within time series. Another future work we like to explore is to gain the ability to build causal models utilizing data from different measurements and sources but generated by the same causal mechanism, which is called the data fusion problem <ref type="bibr" target="#b52">[48]</ref> or integrative causal analysis <ref type="bibr" target="#b53">[49]</ref>. A visual interface supporting such analytics would allow users to study scientific systems over a series of data collections.</p><p>Finally, as illustrated in this paper, causality analysis can serve as a starting point for prescriptive analytics. Automatic generation of such analytics is also a promising extension to our work, where specific actions could be recommended given a user's request.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>The Causal Structure Investigator interface (a) Control panel for reading in data and setting inference parameters. (b) Interactive path diagrams for causal network visualization. (c) Parallel coordinates view for exploring data partitions. (d) Statistic coefficients tables of regressions associated with the causal model. (e) Data subdivision control, where a subdivision can be saved as a clickable tag. (f) Model diagnostic controls and the model heatmap, where users can examine learned models by clicking each tile colored by model scores.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2</head><label>2</label><figDesc>The workflow of visual causality analysis by Chen et al.<ref type="bibr" target="#b24">[21]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3</head><label>3</label><figDesc>Visualization of the causal network derived from the AutoMPG dataset [34]. (a) The path diagram visualization of the network. (b) The path diagram after setting an edge coefficient threshold of 0.3. (c) Visualization of the network as a force-directed graph from our earlier work [2]. (d) An orthogonal graph visualization of the network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>( ( )) is the average of numeric variable corresponding to level of , is the maximized Pearson's correlation between and , and decides the sign of by comparing the level orders of regarding and regarding the numeric variable most correlated with , supposing there are numeric variables in total. A shortcoming of GM is that the mapped values are still discrete while CI tests via partial correlation assume they are continuous. To ease this issue, we add an un-binning (UB) process after GM in which mapped levels are converted to value ranges separated by the middle point of two levels. For example, if a three-level variable is mapped to values {0, 0.4, 1}, the converted ranges shall be {[-0.2, 0.2], [0.2, 0.7], [0.7, 1.3]}. Then data points are randomly assigned with values in the according range based on a Gaussian distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5</head><label>5</label><figDesc>Experimental evaluation of the impact of GM with/without UB in the causal inference of heterogeneous data, comparing to the strategy of simply binning. Charts in each row are from experiments running on the same simulated dataset. Charts in each column visualize the same metric. (a), (e) and (i) are the SHDs of rebuilt causal networks by binning numeric variables with different levels. (b), (f), and (j) are the SHDs from GM and GM+UB with different numbers of categorical variables included in the dataset. (c), (g), and (k) show the average TPR and (d), (h) and (l) show the average TDR of the reconstructed networks with the three strategies under different numbers of categorical variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6</head><label>6</label><figDesc>Causality analysis on the Sales Campaign dataset containing three sales groups. (a) The parallel coordinates view of the CSI interface displaying the three clusters of the dataset. (b), (c), (d) The path diagrams of causal networks generated from the corresponding sales groups. Both the structure and parameters of the three networks are somehow different, which implies different facts in sales behaviors. (b) Blue Cluster (c) Yellow Cluster (d) Red Cluster (a)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7</head><label>7</label><figDesc>Diagnostic of causal models learned from the Ocean Chlorophyll dataset by conditioning on each geolocation. (a) Heatmap of all models clustering into three clusters. (b), (c), and (d) are the representative models for the three clusters corresponding to the numbered tiles in(a). (e) is the t-SNE layout of these models' adjacency matrices in which we observe there are indeed three clusters. (f), (g), and (h) are pooled causal relations from the three clusters accordingly, with a credibility coefficient threshold of 0.5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8</head><label>8</label><figDesc>Analyzing the Presidential Election dataset with the CSI framework. (a) The pop-up window where the user can select variable types and data preparation method. (b) The parallel coordinates visualizing the dataset. Counties of the 11 swing states are brushed as the election results in these areas are more decisive. (c) The derived causal network which uncovers many interesting facts behind the election results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Qualitative interpretation of BIC score difference. Here is a regression model with one extra independent variable added to .</figDesc><table><row><cell>|</cell><cell>−</cell><cell>|</cell><cell>Evidence Against Model</cell></row><row><cell></cell><cell>0 to 2</cell><cell></cell><cell>Not worth more than a bare mention</cell></row><row><cell></cell><cell>2 to 6</cell><cell></cell><cell>Positive</cell></row><row><cell></cell><cell>6 to 10</cell><cell></cell><cell>Strong</cell></row><row><cell></cell><cell>&gt;10</cell><cell></cell><cell>Very Strong</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>This research was partially supported by NSF grant IIS 1527200 and the Ministry of Science, ICT and Future Planning, Korea, under the "IT Consilience Creative Program (ITCCP)" supervised by NIPA. Partial support was also provided by the US Department of Energy (DOE) Office of Science, Office of Basic Energy Sciences, Division of Chemical Sciences, Geosciences, and Biosciences. Some of this research was performed in the Environmental Molecular Sciences Laboratory, a national scientific user facility sponsored by the DOE's OBER at Pacific Northwest National Laboratory (PNNL). PNNL is operated by the US DOE by Battelle Memorial Institute under contract No. DE-AC06-76RL0.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Spurious Correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vigen</surname></persName>
		</author>
		<ptr target="http://www.tylervigen.com/spurious-correlations" />
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Visual Causality Analyst: An Interactive Interface for Causal Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="230" to="239" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Interpretation of Interaction in Contingency Tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Simpson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Source J. R. Stat. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="241" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sex bias in graduate admissions: data from berkeley</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Hammel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="issue">4175</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m">T1-T2 Comp. Sci. &amp; Math (b)T1-T2 Health Sci. &amp; Techno (c)T1-T2 Business</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<idno>Threshold=0.5</idno>
		<title level="m">T2-T3 Comp. Sci. &amp; Math (f)T2-T3 Health Sci. &amp; Techno (d)T1-T2 Pooled</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<idno>Threshold=0.5</idno>
		<title level="m">T1-T2 Business (h)T1-T2 Pooled</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">and (c) are causal networks explaining why students changed to other majors when entering college. (d) The model pooled from the first group of 18 models learned from data subdivisions. (e), (f), and (g) are causal networks explaining why students changed major in the first two years in college. (d) The model pooled from the second group of 18 models</title>
	</analytic>
	<monogr>
		<title level="m">Causal models inferred from the ACT dataset</title>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="398" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<title level="m">Causality: Models, Reasoning, and Inference</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An Introduction to Causal Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Biostat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="62" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Causation, Prediction, and Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Springer</publisher>
			<pubPlace>New York, NY; New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multimodel Inference: Understanding AIC and BIC in Model Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Burnham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociol. Methods Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="304" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Estimating the Dimension of a Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Stat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="461" to="464" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimal structure identification with greedy search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="507" to="554" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A Bayesian Method for the Induction of Probabilistic Networks from Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Herskovits</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">347</biblScope>
			<biblScope unit="page" from="309" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Order-independent constraintbased causal structure learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Maathuis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3741" to="3782" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A theory of inferred causation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stud. Log. Found. Math</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="789" to="811" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Using Markov Blankets for Causal Structure Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Pellet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1295" to="1342" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Partial correlation and conditional correlation as measures of conditional independence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sibuya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Aust. New Zeal. J. Stat</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="657" to="664" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Chapter 10.3.1,&quot; in Learning Bayesian Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Neapolitan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Pearson</publisher>
			<biblScope unit="page" from="600" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nonparametric testing of conditional independence by means of the partial copula</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bergsma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Arxiv Prepr. arXiv11014607</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Kernel-based Conditional Independence Test and Application in Causal Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th Conf. Uncertain. Artif. Intell. (UAI 2011)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="804" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Being Bayesian about network structure. A Bayesian approach to structure discovery in Bayesian networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="95" to="125" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<title level="m">Structural Causal Models: Cycles, Marginalizations, Exogenous Reparametrizations and Reductions</title>
		<imprint>
			<date type="published" when="2016-11" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">From Data Analysis and Visualization to Causality Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="84" to="87" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Animated visualization of causal relations through growing 2D geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tsigas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Vis</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="154" to="172" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Tracking Causality by Visualization of Multi-Agent Interactions Using Causality Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vigueras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Botia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="190" to="204" />
			<pubPlace>Berlin, Heidelberg; Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">in Programming Multi-Agent Systems</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ReactionFlow: an interactive visualization tool for causality analysis in biological pathways</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aurisano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Forbes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Symposium on Biological Data Visualization: Part 2</title>
		<meeting>the 5th Symposium on Biological Data Visualization: Part 2</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
	<note>Suppl 6</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Exploring flow, factors, and outcomes of temporal event sequences with the outflow visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2659" to="2668" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Temporal event sequence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2227" to="2236" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="321" to="330" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Visualization of Bayesian Belief Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zapata-Rivera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Neufeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Greer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="6" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visual Correlation Analysis of Numerical and Categorical Data on the Correlation Map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zadok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="289" to="303" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Probabilistic Graph Layout for Uncertain Network Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nocaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goertler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Deussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Brandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="531" to="540" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Glueck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Breslav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="261" to="270" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">AmbiguityVis: Visualization of Ambiguity in Graph Layouts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="359" to="368" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Conditional logit analysis of qualitative choice behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcfadden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Econometrics</title>
		<imprint>
			<biblScope unit="page" from="105" to="142" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">UCI Machine Learning Repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>University of California, Irvine, School of Information</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bayes Factor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">430</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Sensitivity and specificity of information criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Dziak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Coffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Lanza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Runze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Causal Inference Using Graphical Models with the R Package pcalg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kalisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Machler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Maathuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buhlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Softw</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An efficient k-means clustering algorithm: analysis and implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanungo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Mount</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Netanyahu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Piatko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="881" to="892" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">SeaWiFS Project</title>
		<ptr target="https://oceancolor.gsfc.nasa.gov/SeaWiFS/" />
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">1</biblScope>
		</imprint>
		<respStmt>
			<orgName>NASA</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">"</forename><surname>Nasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Modis</surname></persName>
		</author>
		<ptr target="https://modis.gsfc.nasa.gov/" />
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">European Centre for Medium-Range Weather</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<ptr target="http://www.ecmwf.int/" />
		<title level="m">Available</title>
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Precipitation Measurement Missions</title>
		<ptr target="https://pmm.nasa.gov/TRMM" />
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">1</biblScope>
		</imprint>
		<respStmt>
			<orgName>NASA</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A simple and fast algorithm for K-medoids clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Jun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3336" to="3341" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>PART 2</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Visualizing highdimensional data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J P</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">2012 and 2016 Presidential Elections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilson</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/joelwilson/2012-2016-presidential-elections" />
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
	<note>Kaggle</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Battleground States Polling Average</title>
		<ptr target="http://www.politico.com/2016-election/swing-states" />
	</analytic>
	<monogr>
		<title level="j">POLITICO</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">IEEE VGTC VPG International Data-Visualization Contest</title>
		<ptr target="http://vacommunity.org/ieeevpg/viscontest/2015/index.html" />
		<imprint>
			<date type="published" when="2017-03" />
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Causal inference and the data-fusion problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Pnas</publisher>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="7345" to="7352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Advances in Integrative Causal Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsamardinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the UAI 2015 Conference on Advances in Causal Inference</title>
		<meeting>the UAI 2015 Conference on Advances in Causal Inference</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="90" to="91" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
