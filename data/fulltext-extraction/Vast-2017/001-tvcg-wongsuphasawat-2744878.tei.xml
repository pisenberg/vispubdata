<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kanit</forename><surname>Wongsuphasawat</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Smilkov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Wexler</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimbo</forename><surname>Wilson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Mané</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Fritz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><forename type="middle">B</forename><surname>Viégas</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
						</author>
						<title level="a" type="main">Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2017.2744878</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Neural Network</term>
					<term>Graph Visualization</term>
					<term>Dataflow Graph</term>
					<term>Clustered Graph</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Main Graph Auxiliary Nodes Fig. 1. The TensorFlow Graph Visualizer shows a convolutional network for classifying images (tf cifar). (a) An overview displays a dataflow between groups of operations, with auxiliary nodes extracted to the side. (b) Expanding a group shows its nested structure.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent years have seen a series of breakthroughs in machine learning, with a technique known as deep learning bringing dramatic results on standard benchmarks <ref type="bibr" target="#b35">[37]</ref>. A hallmark of deep learning methods is their multi-layered networks of calculations. The complexity of these networks, which often include dozens of layers and millions of parameters, can lead to difficulties in implementation. Modern deep learning platforms including TensorFlow <ref type="bibr" target="#b4">[6]</ref>, Theano <ref type="bibr">[11]</ref>, and Torch <ref type="bibr" target="#b16">[18]</ref> provide high-level APIs to lower these difficulties. With these APIs, developers can write an abstract program to generate a low-level dataflow graph that supports a variety of learning algorithms, distributed computation, and different kinds of devices.</p><p>These APIs and their dataflow models simplify the creation of neural networks for deep learning. Yet developers still have to read code and manually build a mental map of a model to understand its complicated structure. A visualization of the model can help developers inspect its structure directly. However, these dataflow graphs typically contain thousands of heterogeneous, low-level operations; some of which are high-degree nodes that connect to many parts of the graphs. As a result, standard layout techniques such as flow layout <ref type="bibr" target="#b48">[49]</ref> and force-directed layout generally produce tangled diagrams.</p><p>In response, we present the TensorFlow Graph Visualizer, a component of in the TensorFlow machine intelligence platform, to help developers understand and inspect the structure of their TensorFlow models. Given a low-level directed dataflow graph of a model as input, the visualizer produces an interactive visualization that shows the high-level structure of the model, akin to diagrams that deep learning experts typically draw to explain their models, and enables users to explore its nested structure on demand.</p><p>This paper describes our design process and the design of the visualizer. We present a set of graph transformations and visual encodings that enables standard flow layout techniques <ref type="bibr" target="#b49">[50]</ref> to produce a legible interactive diagram from a dataflow graph of a machine learning model. To provide an overview, we build a clustered graph by grouping nodes based on their hierarchical namespaces that developers can provide. To support exploration, we introduce a novel application of edge bundling to enable stable and responsive expansion of clustered flow layout. To declutter the graph, we apply heuristics to extract noncritical nodes, and introduce new visual encodings that decouple the extracted nodes from the layout. We also detect and highlight repeated structures to help users recognize modular composition in the models. Finally, we overlay the graph with additional quantitative information to help developers inspect their models.</p><p>To demonstrate the utility of the visualizer, we describe usage scenarios for exploring deep learning models. We also report feedback from users who use the tool to examine structures of deep learning models, and discuss usage patterns we have observed in the wild. Overall, developers find the visualization useful for understanding, debugging, and sharing the structures of their models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK 2.1 Dataflow Graph Applications</head><p>Dataflow graphs arise in diverse domains: distributed systems <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b40">42]</ref>, databases <ref type="bibr" target="#b39">[41]</ref>, user-interface development <ref type="bibr" target="#b18">[20]</ref>, visualization <ref type="bibr">[14,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b51">52]</ref> and engineering <ref type="bibr">[4]</ref>.</p><p>Some dataflow systems (e.g., <ref type="bibr">[4,</ref><ref type="bibr">14,</ref><ref type="bibr" target="#b51">52]</ref>) use visualizations as authoring tools and allow users to directly edit the graph to modify the dataflow. Since dataflows in these systems represent high-level components that are manually added one-by-one, their graphs are typically much smaller compared to dataflow graphs of deep neural networks.</p><p>One important application domain for dataflow models is largescale distributed systems, which automatically create dataflow structures from a program to enable distributed computation <ref type="bibr" target="#b13">[15,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b40">42]</ref>. To help users diagnose performance of distributed databases, Perfopticon <ref type="bibr" target="#b39">[41]</ref> includes a collapsible dataflow graph of query execution plans. However, its design does not scale to large dataflow graphs.</p><p>Our goal is to help users understand large, complex dataflow programs with a visualization that scales, provides a legible overview, and supports detailed exploration on demand. While our design targets TensorFlow, our strategy to decouple non-critical nodes from the layout can be applicable for heterogeneous graphs in other domains. Clustered flow graphs in other domains can apply edge bundling to facilitate responsive and stable graph expansion as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visualization for Neural Networks</head><p>Visualization plays many important roles in machine learning. Practitioners and researchers often use visualization to monitor learned parameters and output metrics to help them train and optimize their models. Besides the Graph Visualizer, TensorBoard, TensorFlow's dashboard component, also includes modules for monitoring scalar values, distribution of tensors, images, and audio. We briefly describe these modules in supplementary material.</p><p>For neural networks, the lack of understanding of how the models work often makes model optimization difficult. Visualizations can improve the transparency and interpretability of the models and help open these "black boxes" <ref type="bibr" target="#b32">[34,</ref><ref type="bibr" target="#b53">54]</ref>. Some projects present visualizations for specific types of neural networks such as convolutional network <ref type="bibr" target="#b37">[39]</ref> and recurrent networks <ref type="bibr" target="#b0">[2,</ref><ref type="bibr" target="#b47">48]</ref>. Besides supporting expert's analysis, recent projects, such as Olah's interactive essays <ref type="bibr" target="#b57">[1]</ref>, ConvNetJS <ref type="bibr" target="#b0">[2]</ref>, and TensorFlow Playground <ref type="bibr" target="#b46">[47]</ref>, provide interactive visualizations to teach novices how neural networks work. Unlike prior projects that focus on visualizing learned parameters and output values, or specific kinds of networks, our primary goal is to help users understand the structure of dataflow graphs that represent arbitrary neural networks.</p><p>Similar to our work, some high-level deep learning toolkits such as Keras <ref type="bibr" target="#b1">[3]</ref> and MXNet <ref type="bibr" target="#b14">[16]</ref> leverage GraphViz <ref type="bibr" target="#b26">[28]</ref> to provide tools for visualizing model structure. However, their graph representations are higher-level than TensorFlow and do not contain information about nested low-level operations. For other toolkits that use more complex and lower-level dataflow graphs <ref type="bibr">[11,</ref><ref type="bibr" target="#b16">18]</ref>, standard tools like GraphViz generally produce illegible layouts. Without a better tool, developers have to read the code and manually build a mental map of the structure to understand a model. Our visualizer aims to help developers understand and inspect low-level dataflow graphs of neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph Visualization Techniques</head><p>Visualizing dataflow graphs can be generalized as drawing directed graphs. A common way to draw directed graph is the flow layout, which uses one axis to convey overall direction. A standard flow layout algorithm, introduced by Sugiyama et al. <ref type="bibr" target="#b49">[50]</ref> and widely extended <ref type="bibr" target="#b11">[13,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b31">33]</ref>, assigns x-and y-coordinates separately in multiple stages that optimize different objectives. An alternative approach by Dwyer et al. applies constraint optimization to compute both coordinates for a flow layout simultaneously <ref type="bibr">[22,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b22">24]</ref>. The separation constraints <ref type="bibr" target="#b22">[24]</ref> introduced by this approach are also used in other types of layouts <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b56">57]</ref>. Since directionality is critical for understanding the dataflow of neural networks, we use a flow layout as a basis of our layout algorithm and augment it with additional transformations to simplify the graph. Our implementation uses a Sugiyama-style algorithm due to the availability of stable libraries and high-quality documentation. However, our additional transformations are also applicable for a constraint-based flow layout.</p><p>To simplify large graphs, a common technique is to build hierarchical clustered graphs that provide an overview and support cluster expansion to explore details <ref type="bibr" target="#b5">[7,</ref><ref type="bibr">8,</ref><ref type="bibr">9,</ref><ref type="bibr" target="#b28">30]</ref>. Following this approach, we leverage hierarchical namespaces that developers provide to create a clustered flow layout. To help users maintain mental maps during exploration <ref type="bibr" target="#b38">[40]</ref>, a clustered graph must also be responsive and stable. For undirected graphs, some systems use static layouts <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b54">55]</ref> while others draw the graph interactively <ref type="bibr" target="#b5">[7,</ref><ref type="bibr">8,</ref><ref type="bibr" target="#b54">55]</ref>. For directed graphs, constraint-based approaches <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b24">26]</ref> and an online technique <ref type="bibr" target="#b41">[43]</ref> can speed up the calculation and preserve the topology of the flow layout during interactions. However, drawing edges directly between all visible nodes still clutters expanded graphs. To both declutter the view and support interactive expansion, we bundle and route edges between groups such that edges only connect nodes that are siblings in the hierarchy <ref type="bibr" target="#b8">[10]</ref>. This approach allows us to compute the layout of each cluster's subgraph separately and update only relevant subgraphs when users expand nodes. As a result, we can create responsive and stable interactive graph with a standard Sugiyama-style algorithm for clustered graph <ref type="bibr" target="#b25">[27,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b43">45,</ref><ref type="bibr" target="#b48">49]</ref>, without the need to implement complex constraints or online algorithms. To the best of our knowledge, none of the prior work documents the application of edge bundling to enable interactive expansion of a clustered flow layout.</p><p>Graph clustering and edge bundling simplify our layout, but still leave intertwining edges in many cases due to the presence of noncritical, high-degree nodes. Another group of graph simplification techniques extracts nodes and edges, or replaces them with special visual encodings. Dunne and Shneiderman substitute common nodes and links with compact glyphs that represent common patterns <ref type="bibr" target="#b19">[21]</ref>. Van Ham &amp; Wattenberg remove edges based on a centrality measure to show graph clusters in force-directed layout <ref type="bibr" target="#b55">[56]</ref>. Inspired by these strategies, we apply heuristics based on domain knowledge, semantic metadata, and distribution of node degrees to extract non-critical nodes from the layout, and re-encode them with new visual encodings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BACKGROUND: TENSORFLOW</head><p>TensorFlow <ref type="bibr" target="#b4">[6]</ref> is Google's system for the implementation and deployment of large-scale machine learning models. Although deep learning is a central application, TensorFlow also supports a broad range of models including other types of learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Structure of a TensorFlow Model</head><p>A TensorFlow model is a dataflow graph that represents a computation. Nodes in the graph represent various operations. These include mathematical functions such as addition and matrix multiplication; constant, sequence, and random operations for initializing tensor values; summary operations for producing log events for debugging; and variable operations for storing model parameters.</p><p>Edges in TensorFlow graphs serve three different purposes. Data dependency edges represent tensors, or multidimensional arrays, that are input and output data of the operations. Reference edges, or outputs of variable operations, represent pointers to the variable rather than its value, allowing dependent operations (e.g., Assign) to mutate the referenced variable. Finally, control dependency edges do not represent any data but indicate that their source operations must execute before their tail operations can start.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Building a TensorFlow Model</head><p>The TensorFlow API provides high-level methods for producing low-level operations in the dataflow graph. Some, such as tf.train.GradientDescentOptimizer, generate dozens of lowlevel operations. Thus a small amount of code, such as the definition of the tf mnist simple model in <ref type="figure">Figure 4</ref> (see supplementary material), can produce about a hundred operations in the graph. Real-world networks can be even more complex. For instance, an implementation of the well-known Inception network <ref type="bibr" target="#b50">[51]</ref> has over 36,000 nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Operation Names</head><p>For clarity, operations in TensorFlow graphs have unique names, which are partly generated by the API and partly specified by users. Slashes in operation names define hierarchies akin to Unix paths (like/this/example). By default, the API uses operation types as names and appends integer suffixes to make names unique (e.g., "Add 1"). To provide a meaningful structure, users can group operations with a namespace prefix (e.g., "weights/"). Complex methods such as tf.train.GradientDescentOptimizer also automatically group their underlying operations into subnamespaces (e.g., "gradients" and "GradientDescent"). As discussed later in §5.2, we apply these namespaces to build a clustered graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">MOTIVATION &amp; DESIGN PROCESS</head><p>The motivation for the TensorFlow Graph Visualizer came from our conversations with deep learning experts, including one of the authors. When experts discuss their models, they frequently use diagrams (e.g., <ref type="figure" target="#fig_0">Figure 2</ref>) to depict high-level structure. When working with a new model, they often read the code and draw a diagram to help them build a mental map of the model's architecture. Since diagrams are critical for their work, machine learning experts desire a tool that can automatically visualize the model structures.</p><p>Motivated by an apparent need for a visualization tool, we worked with potential users to understand the key tasks for such a visualization. We also examined the model data that a visualization would have to portray. The purpose of these investigations was to match user needs with what would be possible given real-world data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task Analysis</head><p>Our overarching design goal is to help developers understand and communicate the structures of TensorFlow models, which can be useful in many scenarios. Based on conversations with potential users, we identified a set of key scenarios for a model visualization. Beginners often learn how to use TensorFlow based on example networks in the tutorials. Even experts usually build new models based on existing networks. Therefore, they can use the visualization to help them understand existing models. When modifying the code that generates models, developers can use the visualization to observe the changes they make. Finally, developers typically work in teams and share their models with their co-workers; they can use the visualization to help explain the structures of their models.</p><p>As discussed earlier, researchers often manually create diagrams to explain their models and build mental maps. These diagrams were an important inspiration for our design. As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, they usually show a high-level view of the model architecture and feature relatively few nodes. Low-level implementation details such as cost function calculation or parameter update mechanism are generally excluded from these diagrams. When a network features repeated modules, the modules are usually drawn in a way that viewers can tell they are the same. These diagrams also often annotate quantitative information such as the layer dimensions in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>In model development, developers also need to understand the model beyond the high-level structure. For example, when a developer modifies a part of the code and sees an unexpected result, the reason may lie either in the model itself or in the code that created the model. It can be hard to know whether the program is actually building the intended model. In such case, the developer may desire to inspect a specific part of the model to debug their code.</p><p>From conversations with experts about potential usage scenarios and our observation from these hand-drawn diagrams, we identify a set of main tasks that the visualization should support: T1: Understand an overview of the high-level components of the model and their relationships, similar to schematic diagrams that developers manually draw to explain their model structure. T2: Recognize similarities and differences between components in the graph. Knowing that two high-level components have identical structure helps users build a mental model of a network; noticing differences between components that should be identical can help them detect a bug. T3: Examine the nested structure of a high-level component, in terms of low-level operations. This is especially important when a complex nested structure has been created automatically from a single API call. T4: Inspect details of individual operations. Developers should not have to refer back to the code to see lists of attributes, inputs, and outputs, for instance. T5: View quantitative data in the context of the graph. For example, users often want to know tensor sizes, distribution of computation between devices, and compute time for each operation.</p><p>These tasks do not include standard monitoring apparatus, such as plots of loss functions (i.e. optimization objectives) over time. Such tools are important, but beyond the scope of this paper since they do not relate directly to the structure of the dataflow graph; we briefly discuss how TensorFlow handles these issues in supplementary material.</p><p>This task analysis guided our work, as we engaged in a usercentered design process. Throughout the project, we worked closely with several TensorFlow developers and beta users and iterated on the design. We met with beta users and members of the developer team for at least an hour a week (sometimes for much longer) for about 20 weeks. After the release, we continued to seek feedback from both internal and public users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data Characteristic Analysis</head><p>Our design process also included an investigation into the particular properties of dataflow graphs that define TensorFlow models. An immediate concern was that early experiments with standard layout tools (e.g. flow layout in GraphViz <ref type="bibr" target="#b26">[28]</ref>, as well as force-directed layouts from D3) had produced poor results. We wanted to understand, more generally, the scale of real-world model data, and whether it would be possible for an automatic visualization to support key user tasks.</p><p>We initially performed rapid prototyping to investigate the reasons that TensorFlow graphs caused problems for standard layouts. We visualized several example computation model graphs in multiple ways. After a few trials, we quickly abandoned experiments with forcedirected layouts as they created illegible hairballs. Attempts to use a standard flow layout <ref type="bibr" target="#b49">[50]</ref> for example models yielded illegible results. For example, <ref type="figure">Figure 4</ref>-a shows a flow layout of a simple network for classifying handwritten digits (tf mnist simple). Building clustered flow layouts allows us to produce more legible views. However, these layouts were still cluttered and often change dramatically after expanding a node.</p><p>These experiments pointed to several challenges that make Tensor-Flow model graphs problematic for standard techniques.</p><p>C1: Mismatch between graph topology and semantics. One might hope that meaningful structures would emerge naturally from the graph topology. Unfortunately, it is hard to observe clear boundaries between groups of operations that perform different functions such as declaring and initializing variables, or calculating gradients. Moreover, randomized algorithms produce visually different layouts for topologically identical subgraphs. A good layout should show similarities between identical subgraphs. C2: Graph heterogeneity. Some operations and connections are less important for understanding the graph than others. For example, developers often consider constants and variables simply as parameters for other operators. Similarly, summary operations serve as bookkeepers that save their input to log files for inspection, but have no effect on the computation. Treating all nodes equivalently clutters the layout with non-critical details. C3: Interconnected nodes. While most nodes in TensorFlow graphs have low-degree (one to four), most graphs also contain some interconnected high-degree nodes that couple different parts of the graphs. For example, the summary writer operation <ref type="figure">(Figure 4</ref>-a) connects with all summary operations. These high-degree nodes present a major problem for visualizations, forcing a choice between tight clustering and visual clutter. In force-directed layouts, connections between these nodes reduce distances between nodes that are otherwise distant, leading to illegibly dense groupings. In flow layouts, these connections produce long edges along of the flow of the layout and clutter the views.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DESIGN OF THE TENSORFLOW GRAPH VISUALIZER</head><p>We now describe the design of TensorFlow Graph Visualizer that aims to help users with the tasks in §4.1. First, we explain the basic layout and visual encodings. We then describe a sequence of graph transformations that target the challenges in §4.2. We also report how we identify and highlight repeated structure, and overlay the graph with other quantitative information. We finally discuss our implementation. For simplicity, we will use a simple softmax regression model for image classification (tf mnist simple) to illustrate how we transform an illegible graph into a high-level diagram <ref type="figure">(Figure 4</ref>). As shown in the final diagram <ref type="figure">(Figure 4-d)</ref>, the model calculates weighted sum (Wx b) of the input x-data. The parameters (weights and bias) are placed on the side. With Wx b and the y-input labels, the model computes the test metrics and cross-entropy (xent), which is in turn used to train and update the parameters. Besides this simple model, we describe scenarios for exploring more complex neural networks in §6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Basic Encoding and Interaction</head><p>As in <ref type="figure" target="#fig_7">Figures 1 and 4</ref>-d, the visualizer initially fits the whole graph to the screen. We draw the directed graph of the dataflow with a flow layout <ref type="bibr" target="#b49">[50]</ref> from the bottom to the top, following a common convention in the deep learning literature. Although both horizontal and vertical layouts are common in the literature, we use a vertical layout since it produces a better aspect ratio for models with a large number of layers.</p><p>Horizontal ellipse nodes represent individual operations. Compared to a circle, this shape provides extra room for input edges on the bottom and output edges on the top. Edge styles distinguish different kinds of dependencies (T2). Solid lines represent data that flow along data dependency edges. Dotted lines indicate that data does not flow along control dependency edges (e.g., bias→init in <ref type="figure">Figure 4</ref>-c). Reference edges, such as weight→weight/Assign in <ref type="figure" target="#fig_1">Figure 3</ref>-a, have arrows pointing back to the variables to suggest that the tail operations can mutate the incoming tensors.</p><p>Since users are often interested in the shape of tensors edges (T5), we label the edges with the tensor shape <ref type="figure" target="#fig_1">(Figure 3-a)</ref>. We also compute the total tensor size (i.e. the number of entries, or the product of each dimension size) and map it to the edge's stroke width (via a power scale due to the large range of possible tensor sizes). If the input graph does not specify dimension sizes for a tensor, the lowest possible tensor size determines the width.</p><p>Users can pan and zoom to navigate the graph by dragging and scrolling. When the graph is zoomed, a mini-map appears on the bottom right corner to help users track the current viewpoint <ref type="figure" target="#fig_7">(Figure 1-b)</ref>. To reset the navigation, users can click the "Fit to screen" button on the top-left. To inspect details of a node (T4), users can select a node to open an information card widget ( <ref type="figure" target="#fig_7">Figure 1</ref>-b, top-right), which lists the node's type, attributes, as well as its inputs and outputs. The widget itself is interactive: users can select the node's input or output listed on the graph. If necessary, the viewpoint automatically pans so the selected node is visible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Graph Transformation</head><p>The key challenge for visualizing TensorFlow graphs is overcoming the layout problems described in §4.2. We apply a sequence of transformations ( <ref type="figure">Figure 4</ref>) that enables standard layout techniques to overcome these challenges. To provide an overview that matches the semantics of the model (C1), we cluster nodes based on their namespaces <ref type="bibr">[8]</ref>. In addition to clustering, we also bundle edges to enable stable and responsive layout when users expand clusters. Moreover, as non-critical (C2) and interconnected nodes (C3) often clutter the layout of clustered graphs, we extract these nodes from the graphs and introduce new visual encodings that decouple them from the layout.</p><p>Step 1. Extract Non-Critical Operations TensorFlow graphs are large and contain heterogeneuous operations (C2), many of which are less important when developers inspect a model. To declutter and shrink the graph, we de-emphasize these noncritical operations by extracting these nodes from the layout and encoding them as small icons on the side of their neighbors.</p><p>We extract two kinds of operations, constants and summaries. Both are loosely connected: extracting them does not change any paths between other nodes. A constant node always serves as an input to another operation and thus has only one output edge and no input edge. A summary node always has one input edge from a logged operation and one output edge to the summary writer node, which is the global sink node that takes all summary nodes as inputs and write log data to the log file. Since the summary writer behaves identically in every Tensor-Flow graph, it is negligible for distinguishing different models and can be removed. With the summary writer removed, both summaries and constants have degree 1. Thus, we can extract them without changing any connections between the rest of the graph.   <ref type="figure">Fig. 4</ref>. Transforming the graph of a simple model for classifying handwritten digits (tf mnist simple). (a) A dataflow graph, which is large and wide and has many intertwining connections. The zoomed part of the raw graph highlights how the summary writer operation (red) is interconnected to logged operations in many different parts of the graph (green) via summary operations (blue). (b) The dataflow graph with summary and constant operations extracted. Logged operations (green) are now less intertwined. (c) An overview of the graph, which shows only toplevel group nodes in the hierarchy. (d) An overview with auxiliary nodes extracted to the side of the graph. Selecting an extracted node highlights proxy icons attached to its graph neighbors.</p><p>We encode the extracted constants and summaries as embedded inputs and outputs of their neighbor operations, or small icons on the left and right of the node they connect to <ref type="figure" target="#fig_1">(Figure 3)</ref>. A small circle represents a constant while a bar chart icon represents a summary operation. Edges of the embedded nodes have arrows to indicate the flow direction. We place embedded nodes on the side of their neighbor nodes to make the overall layout more compact and avoid occlusion with other edges that connect with the node on the top and bottom.</p><p>As shown in <ref type="figure">Figure 4</ref> (a-b), this transformation declutters the view in two ways. First, removing the interconnected summary writer (red) frees logged operations (green) from being tied together (C3). Moreover, constants and summaries together account for a large fraction of nodes (approximately 30% in a typical network). Extracting them can significantly reduce the graph size, making it less packed. Reduced size also expedites subsequent transformation and layout calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Step 2. Build a Clustered Graph with Bundled Edges</head><p>To reflect semantic structure of the model (C1), we build a hierarchical clustered graph by grouping operations based on their namespaces. We also bundle edges between groups to help simplify the layout and make the clustered flow layout responsive and stable when users expand nodes. With these transformations, we can provide an overview (T1) that shows only the top-level groups in the hierarchy as the initial view, while allowing users to expand these groups to examine their nested structure (T3). <ref type="figure">Figure 4</ref>-c shows an example overview produced from this step. Each rounded rectangle represents a group node. To distinguish groups of different size (T2), each rectangle's height encodes the number of operations inside the group. Users can expand these groups to examine their nested structure, as shown in <ref type="figure" target="#fig_3">Figure 5</ref>-c.</p><p>Building a hierarchy. We build a hierarchy based on operation names by creating a group node for each unique namespace (or, in the Unix path analogy, directory). If a node's name conflicts with a namespace (analogy: a file having the same name as a directory in Unix) we put the node inside the group node and add parentheses around its name. For example, <ref type="figure" target="#fig_3">Figure 5</ref>-a shows a hierarchy, which groups three nodes in <ref type="figure" target="#fig_1">Figure 3</ref>-b under weights. The original weights operation becomes the (weights) operation inside the weights group.</p><p>Although namespace groupings are optional, they are a good choice for defining a hierarchy for a few reasons. First, TensorFlow graphs typically have informative namespaces as developers also use these namespaces to understand non-visual output in the debugging tools. Moreover, inferring the semantic hierarchy from the graph topology alone is ineffective; even incomplete namespace information better corresponds to the mental model of the network's developer. Most importantly, adding names to models is relatively low effort for developers; we predicted that they would add namespaces to their models to produce hierarchical groupings in the visualization if necessary. As described later in §7, user feedback confirms this prediction.</p><p>To prevent operations without proper namespace prefixes (e.g., "Add 1", "Add 2", ...) from cluttering the view, we also group operations of the same name under the same namespace into a special series node. To avoid aggressive series grouping, by default we only group these operations if there are at least five of them.</p><p>Bundling edges to enable stable and responsive expansion. After grouping nodes to build a hierarchy, we draw group edges, or edges between groups. We avoid drawing edges between all visible nodes directly for a few reasons. First, it usually produces cluttered layouts. More importantly, it may require complete layout re-calculation and cause major layout changes every time the user expands a node. Instead, we bundle edges and route them along the hierarchy to make the layout responsive, stable, and legible.</p><p>To do so, we create group edges only between nodes within the same subgraphs of the group nodes. Within a subgraph, we create group edges between group nodes and operation nodes as well as group edges between pairs of group nodes. A group node and an operation are dependent if there is at least one edge between a descendant operation of the group node and the operation. Similarly, two group nodes are dependent if there is at least one depen- dency edge between a pair of their descendant operations. If there is more than one such edge, the corresponding group edge can bundle multiple dependency edges. For example, we create a group edge from weights to train in <ref type="figure" target="#fig_3">Figure 5</ref>-b. This group edge actually bundles two dependency edges: weights/read → train/gradients and weights/(weights) → train/GradientDescent. When group nodes are expanded, we route edges along the hierarchy instead of directly drawing edges between all visible nodes <ref type="bibr" target="#b8">[10]</ref>. We only directly draw edges between nodes that are siblings in the hierarchy. For an edge between non-sibling nodes, we split the edge into segments that are routed through their siblings ancestors. For example, in <ref type="figure" target="#fig_3">Figure 5</ref>-c, both weights/read → train/gradients and weights/(weights) → train/GradientDescent are routed through weights and train. Routed edge bundling provides multiple benefits:</p><p>1. Responsiveness. With edge routing, we can compute the layout of each group node's subgraph separately because edges do not cross the boundary of each group node. Since layered graph layout has super-linear time complexity, dividing the layout calculation into smaller subproblems can provide significant speed-up. Moreover, when a group node is expanded or collapsed, we only need to re-compute the layout for the ancestors of the group node instead of recomputing the whole layout since other nodes are unaffected. In contrast, if we directly draw edges between all visible nodes even though they are not a part of the same group node's subgraph, the layout must be computed all at once. The whole layout also has to be recomputed every time a node is expanded or collapsed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Stability. With edge routing, the topology of each group node's subgraph remains constant after an expansion. Therefore, expanding a node only enlarges the node and its ancestors without causing major changes to the layout. This helps users maintain their mental model of the graph when they interactively expand the graph. We chose not to directly draw edges between all visible nodes, since in that case an expansion could vastly change the graph's topology and produce a totally different layout.</p><p>3. Legibility. Edge routing decreases the number of edges in each group's subgraph and thus declutters the layout by reducing edge crossings. Drawing edges directly can tangle the view with many crossing curves, especially when many nodes are expanded.</p><p>One possible drawback of edge routing is that it can be harder to trace where an edge goes when it is bundled. We address this with interaction by providing a list of inputs and outputs in the information card to help them track a particular input and output edge.</p><p>Step 3. Extract Auxiliary Nodes from the Clustered Graph Building a clustered graph simplifies the layout and provides a highlevel overview. However, high-degree nodes with connections across the graph continue to present a challenge, causing intertwining edges that clutter the visualization (C3). Ironically, when we showed these diagrams to experts, they commented that many problematic nodes such as variables and bookkeeping operations are actually not important for understanding the model structure.</p><p>Akin to Step 1, we address these issues by extracting non-critical nodes, but from each subgraph in the clustered graph instead of the raw input graph. We place extracted nodes on the right of the layout (labeled as "auxiliary nodes") as shown in <ref type="figure" target="#fig_7">Figures 1-a and 4-d</ref>. To represent the extracted connections, we add small proxy icons for them as embedded inputs and outputs besides their neighbor nodes. Each proxy icon has a shape like its node (rectangles for groups and ellipses for operations) and has a dashed border to indicate that it serves as a proxy for its full representation on the side. When an extracted node or one of its proxies is selected or hovered, we highlight both the node and all of its proxies to help users locate the node and its neighbors. This extraction strategy enables us to simplify the graph, while retaining connectivity information from the original graph. The key challenge here is to determine non-critical nodes to extract. We use a set of heuristics to extract two kinds of auxiliary nodes for each subgraph. First, we extract auxiliary nodes with specific and consistent subgraph patterns. These include groups for declaring and initializing variables, which experts consider as parameters rather than core operations, and NoOp nodes, which serve as control dependency hubs that perform no computation.</p><p>We then extract auxiliary nodes that do not have specific subgraph patterns, but connect to many parts of the graph. For example, groups that compute statistics for measuring performance often connect to multiple layers in a network. Due to their high-degree, these auxiliary nodes are mainly the cause of the intertwining connections (C3). Meanwhile, core computations in TensorFlow are typically mathematical operations that are binary or ternary operators. Thus most core nodes have lower degree than auxiliary nodes, except the ones that connect to many auxiliary nodes. Most of these auxiliary nodes are also sink-like, appearing at or near the end of the graph, and thus have high in-degree. Since extracting nodes affects the degrees of their neighbors, we extract high in-degree nodes before high out-degree nodes so core nodes that connect to many sinklike auxiliary nodes no longer have high out-degree.</p><p>To extract high in-degree nodes, we first calculate the quartiles of in-degrees for a subgraph, ignoring edges of extracted nodes. We apply Tukey's method <ref type="bibr" target="#b52">[53]</ref> to detect outlier nodes with in-degrees higher than Q3 + k * (Q3 − Q1), where k = 1 (a slightly aggressive threshold). To avoid extracting nodes in low-degree graphs, we only extract the outliers if they have in-degrees higher than a minimum threshold of 4. (To demonstrate our transformations with a simplified example, we disable this threshold in <ref type="figure">Figure 4</ref>.) After extracting high in-degree nodes, we repeat the same procedure to extract out-degree nodes, but use a conservative threshold (k = 4) to avoid extracting core nodes.</p><p>Another subtlety for calculating in-and out-degree in TensorFlow is that data dependency edges are considered more important than control dependency edges. If a node contains only a few data edges but many control edges, the node is likely a core operation. On the other hand, if a node contains only control edges, the node is likely auxiliary. Thus, if a node has a data edge, we determine the node's degree by only the number of data edges. If it has only control edges, we determine its degree by the number of control edges. As a result, we can further distinguish between core and auxiliary nodes.</p><p>As shown in <ref type="figure" target="#fig_7">Figures 1 and 4-d</ref>, extracting auxiliary nodes declutters clustered graphs and provides a layout that shows core structures of the models. Since we use heuristics to extract nodes, we also allow users to override the heuristics; users can use the "Remove from / Add to the main graph" button in the information card ( <ref type="figure" target="#fig_7">Figure 1-b, right)</ref> to manually extract a node or re-attach a node back to the main layout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Identify and Highlight Repeated Structure</head><p>The use of repeated modules is a characteristic feature of deep learning networks. For example, many image classification systems <ref type="bibr" target="#b50">[51]</ref> have a series of identical convolutional layers. The structure view (our default view, as shown in <ref type="figure" target="#fig_7">Figures 1 and 4-d)</ref> helps users understand a complex dataflow by highlighting group nodes with identical structure with the same color (T2). Uniquely structured group nodes are otherwise gray.</p><p>The challenge in creating this view is that, a priori, there is no explicit marker for identical structures. In theory one could modify the APIs to include structural annotations along with node names. However, keeping structural annotations in sync with the actual structure would require error-prone manual effort during changes to the APIs.</p><p>Instead, the TensorFlow Graph Visualizer automatically looks for repeated substructures in the graph. Since detecting isomorphic subgraphs is an NP-complete problem <ref type="bibr" target="#b17">[19]</ref>, we use a heuristic approach. Although this strategy is not guaranteed to find arbitrary repeated structures, it performs well and is effective in practice.</p><p>Detecting structural templates from group nodes. We restrict our search to subgraphs that are defined by single group nodes. This restriction is reasonable in practice, since repeated modules are frequently created by calling a given function multiple times, creating groups with similar nested structures. We detect similar group nodes using a two-step approach inspired by the blocking technique for duplication detection in databases <ref type="bibr" target="#b15">[17]</ref>. This technique reduces the number of record pairs to be compared by splitting the entities into blocks such that only entities in the same block need to be compared. Here, we first create a hashmap to store clusters of nodes with the same blocking key based on metadata that we compute while building the hierarchy ( §5.2). The key consists of the number of nodes and edges, and a histogram counting types of operation nodes inside the group node's subgraph. Two identical subgraphs will have the same key since all of these properties are isomorphism invariants.</p><p>Next, we examine each cluster in the hashmap to find templates of repeated modules, starting from clusters that contain fewer operations. For each cluster c, we first initialize a set of templates to an empty set T c = {}. For each group node g in the cluster, we compare it with each existing template t ∈ T c . For each template t, we compare g with a node g t that belongs to t using a subgraph similarity checking method described in the next paragraph. If g and g t are similar, we assign g to the template t. Otherwise, we continue checking with other templates. If g does not match any existing templates, we add a new template with g as a member to the set T c . After visiting all nodes in the cluster, we add all templates t ∈ T c that have more than one member to the global template set T , which is used for assigning colors.</p><p>Checking subgraph similarity. We determine if two group nodes g 1 and g 2 are similar with the following steps. If their subgraphs s 1 and s 2 do not have the same degree sequence, they are dissimilar. Otherwise, we use a heuristic graph traversal procedure that determines graph similarity with nodes' signature. We define a node's signature as a tuple of (1) the node's type, which can be an operation type for an operation node or its template unique identifier 1 for a group node, (2) the node's in-degree, and (3) the node's out-degree. We traverse through both graphs using breadth first search. First, we add the source nodes of the subgraphs s 1 and s 2 to their queues q 1 and q 2 respectively. If there are multiple sources for each subgraph, we sort them by their signatures before adding to the queue. We then traverse by dequeueing a pair of nodes, one from each queue. For each pair of visited nodes (n 1 , n 2 ), we compare their signatures. If they are different, we can terminate the process and decide that the group nodes are dissimilar.</p><p>Otherwise, we add all direct successors of n 1 and n 2 to q 1 and q 2 respectively. If there are multiple successors, we again sort them by their signatures. We keep traversing by removing nodes from the queue and perform the same process. If the parallel traversal completes successfully, the two group nodes are considered similar.</p><p>Time complexity. For the blocking step, we insert each group node to the cluster hash map based on its key, which is already included in the hierarchy. Since insertion in a hash map takes O(1) time on average, the blocking step takes O(N) time if the model has N group nodes. For comparing group nodes in each cluster, checking similarity for two subgraphs with V nodes and E edges takes O(V + E) time. Comparing many group nodes can be expensive. However, from our experiment with sample models, dissimilar group nodes never have the same blocking key. Therefore, in practice, we only need to perform subgraph similarity just to verify that a pair of group nodes are similar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Overlaying Additional Quantitative Data</head><p>In addition to structural similarity, users can use color to encode other quantitative information (T5). The device distribution view helps users understand how computation is distributed across multiple devices. As shown on the right, this view colors each operation according to the device it is allocated to run on. A group node is colored proportionally to the use of different devices for the operations inside it.</p><p>The compute time and memory views enables users to find and detect memory and computation bottleneck in their models. These views color nodes using a single-hue color ramp: nodes with higher compute time or memory usage have more saturation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Implementation</head><p>TensorFlow Graph Visualizer is an open-source, web-based visualization. The source code is available in TensorBoard's repository <ref type="bibr">[5]</ref>.</p><p>We generate the layout by recursively computing (depth first) the flow layout for each expanded group's subgraph. For example, in <ref type="figure" target="#fig_3">Figure 5</ref>-c, the layout for the subgraphs inside train and weights are calculated first. The layout for the root node's subgraphs are then computed. To include embedded inputs and output, we compute the bounding box of each node, including all of its embeddings, and then calculate the layout for these bounding boxes. Next, we adjust the anchor points of the edges so that they all connect directly to the node's shape. Finally, we render the graph in SVG and animate the graph during expansion using D3.js <ref type="bibr" target="#b10">[12]</ref>.</p><p>We use Dagre, a Javascript library for a Sugiyama-style flow layout <ref type="bibr" target="#b49">[50]</ref>, to compute a layout for each subgraph. Although Dagre sometimes produces unnecessary edge crossings, the library enables us to build clustered graphs and apply our graph extraction strategy to produce layouts that are overall legible. We consider the reduction of edge crossings in each subgraph beyond the scope of this work. However, prior edge crossing reduction techniques <ref type="bibr">[22,</ref><ref type="bibr" target="#b22">24,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b31">33]</ref> can be directly applied to improve the layout of each subgraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">NEURAL NETWORK EXPLORATION SCENARIOS</head><p>This section describes example scenarios for using the TensorFlow Graph Visualizer to explore neural networks in TensorFlow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scenario 1: Exploring a Convolutional Network</head><p>A user wants to learn about tf cifar, an example convolutional neural network for classifying images from the CIFAR-10 benchmark dataset <ref type="bibr" target="#b34">[36]</ref>. Since the model is based on roughly seven hundreds line of code (included in supplementary material), the user looks at the visualizer along with the code to understand the model structure. <ref type="figure" target="#fig_7">Figure 1</ref>-a shows an overview of the graph (T1). The main graph primarily includes input processing operations and layers of calculation networks for making inference. On the side, the auxiliary nodes include non-critical nodes that are extracted to declutter the layout since they connect to many layers in the model. Consider the main graph, the model first reads input images. To increase the training dataset size, the model applies randomized image processing (process image) such as adjusting brightness and contrast to produce additional data. It then shuffles the images and divides them into batches for training (shuffle batch). The middle part of the graph shows how the model makes inferences. In this part, the model first stacks two sets of convolution layers <ref type="bibr" target="#b36">[38]</ref>, which efficiently use shared parameters to produce higher-level features from the input. As the convolution layers have identical nested structure, their nodes share the same color (T2). Following each of the convolution layers, the model includes a max-pooling operation (pool1-2) to downsample the representation size and make the model invariant to low-level transformations, as well as a local response normalization operation <ref type="bibr" target="#b34">[36]</ref> (norm1-2) to reduce overfitting. The final part of the inference network contains fully connected layers (fully3-4), similar to layers in traditional neural networks, for performing high-level reasoning based on the produced features. After the fully connected layers, the model uses the softmax (multinomial logistic regression) module to calculate the probability distribution between different classification categories. Finally, the model computes the cross entropy between the prediction output and the labels of the input images as its loss function.</p><p>Expanding the conv1 module <ref type="figure" target="#fig_7">(Figure 1-b)</ref> to see its nested structure (T3), the user observes that the module composes a Conv2D operation with weights and biases variables, and forwards the output to a node named conv1. Curious about the conv1 node, the user selects it to inspect details in the information card (T4). The node is a rectified linear unit (Relu), an activation function that enables convolutional networks to make breakthroughs in recognition tasks <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b35">37]</ref>. From the weights, the module also computes L2Loss and passes the output to multiple auxiliary nodes including total loss and train.</p><p>Glancing at the auxiliary nodes, the user sees several groups that connect to all convolution and fully connected layers (conv1-2 and fully3-4). These include groups for state saving (save), error reporting (report uninitialized variables), model initialization, training and total loss function calculation. The model also contains auxiliary nodes (e.g., group deps and init) in which all edges are control dependencies to manage execution order in the dataflow.</p><p>After understanding the model structure, the user trains the model. During the training, she uses the memory and compute views to examine parts of the graphs that take a lot of memory and compute time during the training (T5). The user also uses the names of the nodes in the graph to select summary plots in TensorBoard. As the user experiments and modifies the model, she uses the visualizer to inspect modifed parts in the graph to verify her changes in the code. <ref type="figure">Figure 8</ref> shows an implementation of Inception <ref type="bibr" target="#b50">[51]</ref> (tf inception), a deep network architecture that had the top classification result in the ImageNet 2014. Due to space limitation, we show a version of the model that excludes training and bookkeeping operations. From the overview in <ref type="figure">Figure 8</ref>-a (T1), the user sees that the model contains about twenty top-level layers. The bottom part contains input processing operations. The topmost node is the softmax module for determining classification output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scenario 2: Exploring a Very Deep Network</head><p>From the overview, the user recognizes that some nodes share the same colors and thus have identical nested structure (T2). The lower part of the model contains the same convolution module (e.g., conv1-4), with identical max-pooling layers occasionally interleaving in the middle. The upper part contains the inception mixed modules <ref type="bibr" target="#b50">[51]</ref> that combine convolutional and pooling layers. Two groups of these mixed modules (mixed and mixed 1-2, and mixed 4-7) are identical, while other mixed modules shown in grey (mixed 3 and mixed 8-10) have unique structures.</p><p>The user can expand particular modules to explore their nested structure (T3). ure 8-c shows that all of these towers contain identical convolutional modules (conv). As these modules are blue, the user realizes that they are also identical to other blue convolutional modules in the lower layers (in <ref type="figure">Figure 8-a)</ref>. Finally, expanding a convolutional module <ref type="figure">(Figure 8-c, left)</ref> shows individual operations that form the module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">QUALITATIVE FEEDBACK</head><p>We gathered feedback from real-world users of the visualizer in many ways. Within our company, we sent out a structured questionnaire for feedback; we also observed and talked directly with developers who have used the tool. In addition, since the tool has been released publicly, we also collect feedback and comments from online forums.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Internal feedback</head><p>Here we report on internal feedback that was collected from: (1) formal questionnaire and (2) observations of usage "in the wild".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structured questionnaire</head><p>After the launch of TensorFlow, we followed up with 8 internal users of the Graph Visualizer to better understand why they used the visualization and what, if any, value they derived from it. We sent a structured questionnaire to ask them about their goals, usage, and problems.</p><p>Of our respondents, 5 were researchers (experimenting with and developing models) and 3 were engineers (applying existing models to products). None of them were the beta users that met with us weekly during the design process. Before using our visualization, three users said they had built their own tools to look at model architecture but had not been satisfied. The overall response was positive, with a good measure of the excitement resting on the interactive nature of the graph:</p><p>"It's great -visually appealing and the structure exploration seems very effective." "This is absolutely amazing! I especially love the ability to define custom collapsible units by using the / symbol -it does wonders in cleaning up my graph. "</p><p>When asked about the types of tasks they tried to accomplish, their answers ranged from checking model architecture, to inspecting what hardware different parts of the network were running on, to debugging model structure. Here are quotes that speak to user goals:</p><p>"Understanding what my code actually produced. We had layers of functions and configs and arguments and it's good to verify we got what we intended" "Find the name of a tensor so that I could do further exploration (like sampling that tensor over different inputs or seeing the evolution of a particular input)" "I needed to find out which device was running what, and I did." "Sanity-checking some specific part of the graph to make sure things are as expected"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Observed usage</head><p>Besides the questionnaire, we informally observed how the visualizer was being used "in the wild". Without our intervention, we take note of conversations in internal mailing lists and look at graphs made by users. From this examination, we discover a number of usage patterns.</p><p>Many users deliberately add namespaces to their models to ensure graph legibility. They iteratively modify namespaces until the visualization became a reasonable match to the mental model they had of their system, especially if they have to share their models with others. Our belief that users would annotate the graph to ensure visual legibility was not a foregone conclusion. These observations validate our decision to exploit user-specified namespaces to build a clustered graph. Moreover, they indicate that the visualizer is useful for users.</p><p>Many users also create screenshots of the graphs (or their parts) to communicate about deep learning systems. Sometimes this involves sharing "before and after" screenshots that show the graph as it changed during debugging. Other times the images are used simply as a visual reference to a particular piece of the system. Images of different graphs also regularly show up in the official TensorFlow tutorials and third-party articles, attesting to their value as didactic illustrations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Public feedback</head><p>To gather public feedback outside our company, we also searched online for user reactions to the Graph Visualizer. Unlike with internal users, where demand characteristics <ref type="bibr" target="#b42">[44]</ref> can be an issue, external users have no incentive to "be nice" about the diagrams the Graph Visualizer creates. We found that online reviews of TensorFlow have repeatedly called out the Graph Visualizer as differentiating the system from other deep learning platforms. Some typical examples: "I think there are two main differences at the moment, comparing it to the more mainstream libraries: 1: The visualization module (Ten-sorBoard): One of the main lacking areas of almost all open source Machine Learning packages, was the ability to visualize model and follow the computation pipeline." <ref type="bibr">[Quora]</ref> "We believe visualization is really fundamental to the creative process and our ability to develop better models. So, visualization tools like TensorBoard are a great step in the right direction." <ref type="bibr">[Indico]</ref> All of the comments we found have positive tone; we did not see users complaining about the tool. One reason may be that having any visualization at all is an improvement over the norm. The warm reception suggests that this is a design problem worth solving, and (as one commenter says) our tool is a least a "step in the right direction."</p><p>In addition to explicit feedback, we found many examples where people use screenshots of the Graph Visualizer to describe specific applications or explain intricacies of a particular type of model they built. These cases show that users find the visualizer helpful for communicating their ideas. Many users have also created tutorials that explain how to author namespaces to help the visualizer produce hierarchical clusters that matches the semantics of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND FUTURE WORK</head><p>Deep learning models are becoming increasingly important in many applications. Understanding and debugging these models, however, remains a major issue. This paper describes a design study of a visualization tool that tackles one aspect of this challenge: interactive exploration of the dataflow architecture behind machine learning models.</p><p>Our design process emphasizes understanding of both users and data: we describe a task analysis for developers of deep learning models, and outline the layout challenges presented by model structures. We then present a series of graph transformation to address these challenges, and demonstrate usage scenarios. Finally, we discuss user reactions, which indicate that the visualizer addresses users' need.</p><p>In the context of TensorFlow, there are many natural next steps. Some users have asked for "two-way" visualizations that allow direct editing of a graph. Direct manipulation capabilities in the graph could ease the creation and modification of machine learning models. Features for comparing multiple models could be helpful as well.</p><p>Another lesson may be applicable to other systems that visualize graphs with similar structures. The strategy of extracting non-critical nodes seems successful: viewers apparently understand the overall structure of the graph despite the lack of direct edges. While our heuristics to determine non-critical nodes are application-specific, the strategy of extracting non-critical nodes may be applicable for heterogeneous graphs in other domains.</p><p>An intriguing finding is that developers were willing to change their own code in the interest of improving the visualization, manually adding metadata to their graph in order to clarify the layout. For one thing, this behavior shows that users derived significant value from the visualizations. More importantly, it suggests that in other contexts, designers need not feel bound by the data at hand; with the right visualization, and a tight feedback loop between artifact visualization and creation, users may be willing to add critical pieces of metadata. This is a welcome sign for visualization creators.</p><p>Finally, developer reactions also suggest a heartfelt desire for better ways to understand machine learning. This is an area in which data is central, but the tools have not matured, and users often feel they operate in the dark. Visualization may have an important role to play.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VISUALIZING DATAFLOW GRAPHS OF DEEP LEARNING MOD-ELS IN TENSORFLOW: SUPPLEMENTARY MATERIAL A TENSORBOARD</head><p>TensorBoard is Tensorflow's dashboard tool, which allows users to visualize their TensorFlow models, plot quantitative metrics about their execution, and show additional data like images that pass through the models. The TensorFlow Graph Visualizer is included as the Graph View in TensorBoard. Besides the Graph Visualizer, TensorBoard provides others views <ref type="figure" target="#fig_7">(Figure S-1)</ref> for inspecting scalar, histogram, images, and audio data. To log data in the models, users can add summary operations that takes operation they desire to log as inputs. To visualize the graphs, user can include dataflow information for the Graph Visualizer in the log data. Users can also optionally include additional metadata about runtime statistics including total memory usage, total compute time, and tensor shapes.</p><p>For specific information about how to setup and run TensorBoard, please refer to TensorFlow tutorials 1 . 1 https://www.tensorflow.org/get started/summaries and tensorboard B EXAMPLE CODE tf mnist simple The Listing 1 below shows an example Python code snippet that declares a simple model for classifying handwritten digits, derived from TensorFlow's "MNIST For ML Beginners" getting started tutorial <ref type="bibr" target="#b0">2</ref> .</p><p>The code first defines a placeholder for the input and initializes variables for model parameters (Lines 1-5). It then calculates y = so f tmax(W x + b) (Lines 6-7), which produces a probability distribution for each of the ten digits (0-9), and trains the model by minimizing cross entropy using a gradient descent optimizer <ref type="figure" target="#fig_5">(Lines 11-17)</ref>. Finally, it evaluates the model by comparing the digit with highest probability for each data point with the correct label and calculating the ratio between correct predictions and the number of all data points (Lines 18-22). Namespaces are provided for operations via the name parameter of operation constructor methods (Lines 2-5), and the tf.name scope method (Lines 6, 12, 15, and 19), which wraps operations with a common namespace. Certain operations are also logged with summary operations for debugging (Lines 8-10,14,22).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Whiteboard drawing by a computer vision expert: a convolutional network for image classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Extract non-critical operations. (a) A raw subgraph for the weights variable and its summary. (b) The subgraph with summary and constant operations extracted from the flow layout and re-encoded as embedded input and output on the side of their neighbors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Build a hierarchical clustered graph. (a) A hierarchy showing only train and weights namespaces from tf mnist simple in Figure 4. (b) A high-level diagram showing dependency between train and weights. Hovering over the train namespace shows a button for expansion. (c) A diagram with train and weights expanded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Before extracting auxiliary nodes, the links between groups clutter the overview of tf cifar inFigure 1-a.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Nodes in the device distribution view.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 -Fig. 8 .</head><label>88</label><figDesc>b shows the expanded state of mixed 4 and mixed 5, confirming that they share the same structure. The user observes that each of these inception modules produces high-level features using 4 parallel pathways (conv, tower, tower 1, and tower 2) that are later concatenated (join). Expanding each tower unit inFig-Exploring an implementation of Inception (tf inception) [51], a deep network architecture that won the ImageNet 2014 competiton. (a) The overview shows identical modules with the same colors. (b) Expanding two identical modules (mixed 4-5) displays similar substructures. (c) Drilling down, mixed 4 is composed of multiple conv modules identical to the conv modules in the top-level graph. Expanding the conv module on the left reveals nested operations that form the module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. S- 1 .</head><label>1</label><figDesc>Summary log viewers in TensorBoard, TensorFlow's dashboard. (a) The events view showing plots of accuracy over time for the tf mnist simple model. (b) The histogram view showing distribution of the weights variable's tensor values over time. (c) The image view showing a handwritten digit image input.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• Kanit Wongsuphasawat is with Paul G. Allen School of Computer Science &amp; Engineering, University of Washington. E-mail: kanitw@uw.edu. • Daniel Smilkov, James Wexler, Jimbo Wilson, Dandelion Mané, Doug Fritz,</figDesc><table /><note>Dilip Krishnan, Fernanda B. Viégas, and Martin Wattenberg are with Google Research. E-mail: {smilkov, jwexler, jimbo, dougfritz, dilipkay, viegas, wattenberg}@google.com</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Since we detect templates in smaller group nodes first, each child of the examined group node always already has a template identifier assigned.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.tensorflow.org/get started/mnist/beginners 3 https://github.com/tensorflow/models</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank our colleagues at Google for advice and feedback during the design process: Greg Corrado, Jeff Dean, Matthieu Devin, Chris Olah, Koray Kavukcuoglu, Jon Shlens, Michael Terry, as well as our early users. We also thank UW Interactive Data Lab members and Supasorn Suwajanakorn for their comments on this manuscript.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>tf cifar</head><p>The source code is in cifar10.zip in the supplementary material zip file. See cifar10 train.py for the training code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>tf inception</head><p>The code can be found online in the inception directory in the tensorflow/models repository on GitHub 3 .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="http://cs.stanford.edu/people/karpathy/convnetjs/" />
		<title level="m">ConvNetJS</title>
		<imprint>
			<biblScope unit="page" from="2017" to="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Keras: Deep learning library for theano and tensorflow</title>
		<ptr target="https://keras.io/" />
		<imprint>
			<biblScope unit="page" from="2017" to="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Labview</surname></persName>
		</author>
		<ptr target="http://www.ni.com/labview/" />
		<imprint>
			<biblScope unit="page" from="2016" to="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<ptr target="http://github.com/tensorflow/tensorboard" />
		<title level="m">The TensorBoard repository on GitHub</title>
		<imprint>
			<biblScope unit="page" from="2017" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Software available from tensorflow.org</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ASK-Graphview: A large scale graph visualization system. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Abello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">Van</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="669" to="676" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Grouseflocks: Steerable exploration of graph hierarchy space. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Archambault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Auber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="900" to="913" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The readability of pathpreserving clusterings of graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Archambault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Purchase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pinaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1173" to="1182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Level-of-detail visualization of clustered graph layouts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Deussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Asia-Pacific Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="133" to="140" />
		</imprint>
	</monogr>
	<note>Visualization</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Theano: a CPU and GPU math expression compiler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Breuleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python for scientific computing conference (SciPy)</title>
		<meeting>the Python for scientific computing conference (SciPy)<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">D 3 data-driven documents. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bostock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ogievetsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2301" to="2309" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast and simple horizontal coordinate assignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Brandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Köpf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="31" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">VisTrails: visualization meets data management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2006 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="745" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Flumejava: easy, efficient data-parallel pipelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raniwala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bradshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weizenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Sigplan Notices</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="363" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">MXNet: A flexible and efficient machine learning library for heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.01274</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A survey of indexing techniques for scalable record linkage and deduplication. Knowledge and Data Engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1537" to="1555" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Torch: a modular machine learning software library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mariéthoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IDIAP</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The complexity of theorem-proving procedures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Annual ACM Symposium on Theory of Computing</title>
		<meeting>the Third Annual ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1971" />
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Elm: Concurrent frp for functional guis. Senior thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Czaplicki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Motif simplification: improving network visualization readability with fan, connector, and clique glyphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dunne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3247" to="3256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dig-CoLa: directed graph layout through constrained energy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2005. INFO-VIS 2005. IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Drawing directed graphs using quadratic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="536" to="548" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">IPSep-CoLa: An incremental procedure for separation constraint layout of graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="821" to="828" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Constrained graph layout by stress majorization and gradient projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Mathematics</title>
		<imprint>
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1895" to="1908" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Topology preserving constrained graph layout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wybrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Graph Drawing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="230" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Straight-line drawing algorithms for hierarchical graphs and clustered graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="113" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Graphviz and dynagraph-static and dynamic graph drawing tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ellson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Gansner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Koutsofios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Woodhull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing Software</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="127" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Applying crossing reduction strategies to layered compound graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Forster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="276" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Topological fisheye views for visualizing large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Gansner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="457" to="468" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A technique for drawing directed graphs. Software Engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Gansner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Koutsofios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="214" to="230" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dryad: distributed data-parallel programs from sequential building blocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Budiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fetterly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM SIGOPS Operating Systems Review</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="59" to="72" />
			<date type="published" when="2007" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Exact and heuristic algorithms for 2-layer straightline crossing minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jünger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mutzel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Springer Berlin Heidelberg</publisher>
			<biblScope unit="page" from="337" to="348" />
			<pubPlace>Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02078</idno>
		<title level="m">Visualizing and understanding recurrent networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Hola: Human-like orthogonal network layout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kieffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wybrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="349" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Towards better analysis of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="100" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Layout adjustment and the mental map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Misue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages &amp; Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="210" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Perfopticon: Visual query analysis for distributed databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Halperin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="71" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Ciel: a universal execution engine for distributed data-flow computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwarzkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Smowton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madhavapeddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 8th ACM/USENIX Symposium on Networked Systems Design and Implementation</title>
		<meeting>8th ACM/USENIX Symposium on Networked Systems Design and Implementation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="113" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Online hierarchical graph drawing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Woodhull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Graph Drawing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="232" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Demand characteristics and the concept of quasi-controls. Artifacts in Behavioral Research: Robert Rosenthal and Ralph L. Rosnow&apos;s Classic Books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Orne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">110</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Layout of compound directed graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Postfach</title>
		<imprint>
			<biblScope unit="volume">151141</biblScope>
			<biblScope unit="page">66041</biblScope>
		</imprint>
		<respStmt>
			<orgName>Saarlandische Universitat und Landesbibliothek</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saarbracken</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Declarative interaction design for data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Satyanarayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th annual ACM symposium on User interface software and technology</title>
		<meeting>the 27th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="669" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Direct manipulation visualization of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Smilkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Visualization for Deep Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.07461</idno>
		<title level="m">Visual analysis of hidden state dynamics in recurrent neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Visualization of structural information: Automatic drawing of compound digraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Misue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="876" to="892" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Methods for visual understanding of hierarchical system structures. Systems, Man and Cybernetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Toda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="125" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">OpenDX: paths to visualization; materials used for learning OpenDX the open source derivative of IBM&apos;s visualization Data Explorer. Visualization and Imagery Solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Exploratory data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Opening the black box -data driven visualization of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">Y</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIS 05. IEEE Visualization</title>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="383" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Interactive visualization of small world graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Visualization, 2004. INFOVIS 2004. IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="199" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Centrality based visualization of small world graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="975" to="982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">High-quality ultra-compact grid layout of grouped networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Yoghourdjian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kieffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marriott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="339" to="348" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Input</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>summary log 2 x = tf.placeholder(tf.float32, [None, 784], name= x-input</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>W = Tf</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Variable(tf.zeros([784, 10]), name= weights</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<idno>b = tf.Variable(tf.zeros</idno>
		<title level="m">name= bias ) 6 with tf.name_scope( Wx_b ): 7 y = tf.nn.softmax(tf.matmul(x, W) + b)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m">tf.histogram_summary( weights , W)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m">tf.histogram_summary( biases , b) 10 tf.histogram_summary( y , y)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main"># Define loss and optimizer 12 with tf.name_scope( xent ): 13 cross_entropy = -tf.reduce_sum(y_ * tf</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">scalar_summary( cross entropy , cross_entropy) 15 with tf.name_scope( train ): 16 train_step = tf.train.GradientDescentOptimizer( 17 FLAGS.learning_rate).minimize(cross_entropy)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">scalar_summary( accuracy , accuracy) tf.train.SummaryWriter(FLAGS.summaries_dir, 26 sess</title>
		<imprint/>
	</monogr>
	<note>graph.as_graph_def(add_shapes=True</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Listing 1. A example Python snippet that declares a simple model for classifying handwritten digits in the MNIST dataset with softmax regression</title>
		<imprint/>
	</monogr>
	<note>tf mnist simple</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
