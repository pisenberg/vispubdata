<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Comparing Visual-Interactive Labeling with Active Learning: An Experimental Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Bernard</surname></persName>
							<email>juergen.bernard@gris.tu-darmstadt.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Hutter</surname></persName>
							<email>marco.hutter@gris.tu-darmstadt.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zeppelzauer</surname></persName>
							<email>matthias.zeppelzauer@fhstp.ac.at</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fellner</surname></persName>
							<email>dieter.fellner@gris.tu-darmstadt.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sedlmair</surname></persName>
							<email>michael.sedlmair@univie.ac.at</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Technische Universität Darmstadt</orgName>
								<address>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Technische Universität Darmstadt</orgName>
								<address>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">St. Pölten University of Applied Sciences</orgName>
								<address>
									<settlement>St. Pölten</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Fraunhofer IGD</orgName>
								<address>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">University of Vienna</orgName>
								<address>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Comparing Visual-Interactive Labeling with Active Learning: An Experimental Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2017.2744818</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Labeling</term>
					<term>Visual-Interactive Labeling</term>
					<term>Information Visualization</term>
					<term>Visual Analytics</term>
					<term>Active Learning</term>
					<term>Machine Learning</term>
					<term>Classification</term>
					<term>Evaluation</term>
					<term>Experiment</term>
					<term>Dimensionality Reduction</term>
				</keywords>
			</textClass>
			<abstract>
				<p>(a) 2D Colormap (b) Class Coloring (c) Convex Hulls (d) Butterfly Plot Fig. 1: Evaluation of four visualization techniques (a)-(d) that support the visual-interactive labeling process. Our study reveals that Class Coloring (b) and Convex Hull (c) are the most useful techniques. Both capture characteristics of the input data and the classification model in an intuitive way. Our study shows that they can compete with and even outperform active learning strategies.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Labeling follows the principle of attaching information to some object. In data-centered disciplines labeling is often associated with querying knowledge of users about data objects. As such, the labeling process represents an essential prerequisite for algorithmic support in data mining, machine learning, and visual analytics. Two goals of almost any labeling process are being accurate and fast, i.e., effective and efficient.</p><p>In the machine learning community, labeling traditionally represents the basis for the creation of large ground truth data sets. Ground truth is necessary to enable autonomous supervised learning. The most recent and powerful supervised machine learning approaches, such as deep neural networks require large amounts of such labeled data to learn successfully. The generation of such datasets is, however, expensive and often requires extensive efforts from the users (e.g. crowdsourcing <ref type="bibr" target="#b27">[28]</ref>). Active learning (AL) is one promising approach to reduce the labeling effort. The basic principle of AL is to query an oracle (the user) for labels about individual objects (instances) in the dataset. Thereby the active learner selects those candidates from which the classifier is expected to benefit most. Various AL strategies have been proposed and shown to improve over random sample selection <ref type="bibr" target="#b55">[56]</ref>.</p><p>One of the intrinsic characteristics of AL strategies is the modeldriven way to identify meaningful instances for labeling. A drawback of this principle is that users, with their ability to identify patterns very fast, have no influence on the candidate selection. Considering the efficiency, strategies asking users for a single or multiple labels in an iterative manner does not scale well for large data sets. Finally, a particular challenge for model-driven strategies is the cold start (bootstrap) problem, i.e., starting the learning with no labeled instances at all <ref type="bibr" target="#b36">[37]</ref>. The question arises whether or not classical AL approaches can benefit from visual interfaces that take the user into the loop, not only for labeling but particularly for selecting meaningful candidates <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>In the visual analytics community, interfaces for visual-interactive labeling (VIL) become increasingly popular since they enable users to express their information need. Additionally, visual analytics models can support the users' knowledge generation process by exploiting such label information. Approaches differ in the type of acquired labeling information ranging from interestingness scores, rules, similarity relations to assignments of class labels. One common ground of many approaches is the user-driven selection of instances provided with visual interfaces for the exploration and identification of interesting instances. The motivation of users for the selection of particular instances can be diverse. It may be task-dependent but also the context, application field, and more intrinsic backgrounds of users may motivate the instance selection. These different motivations may lead to biased selections of instances that result in suboptimally trained models. Following the principle of AL strategies, guiding users in the candidate identification may be beneficial to mitigate subjective or suboptimal instance selection.</p><p>Our research is motivated by observing the different strengths and weaknesses of the respective principles and the idea of a substantiated combination of mutual strengths in future approaches. Recent developments in machine learning and visual analytics indicate that the two fields are getting closer, see for example a recent survey that exposes the considerable overlap <ref type="bibr" target="#b42">[43]</ref>. Furthermore, there have been first initiatives to combine active learning and visual-interactive label selection <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b56">57]</ref>. We share the vision that the strengths of both principles can be seamlessly combined in visual-interactive labeling systems, raising the effectiveness and efficiency to new levels.</p><p>From our literature research, we conclude that the strengths and weaknesses of both principles have hardly been assessed in direct comparison. There is a lack in formalizations of AL and VIL strategies and more generally of labeling approaches in machine learning and visual analytics. Thus, reliable decisions on whether or not to choose one or the other approach are hardly feasible. A core driving question is whether or not visual interfaces can improve labeling tasks, or whether AL performs so well that they render visual interfaces redundant. In case that VIL is really helpful, other interesting questions arise: Do users have particular strategies for the identification of labeling candidates? How good are these strategies with respect to their performance? Under which circumstances does VIL help, and when not? How does VIL perform for differently complex tasks? And how much and what information about data and machine learning models should be represented in visual interfaces? These questions have not been answered yet and require a closer investigation.</p><p>To answer these questions and to provide a direct comparison of VIL and AL labeling strategies, we perform an experimental study. As a basis for the study, we develop a flexible evaluation toolkit that integrates 16 different established AL strategies, five classifiers, and four visualization techniques, i.e., VIL-support techniques (Sec. 3). Using this toolkit, we conducted an empirical study with 16 expert participants. Our study sheds light into (i) how VIL and AL techniques compare to each other, (ii) how the complexity of the labeling situation impacts them, and (iii) the differences between single-and multi-instance labeling approaches (Sec. 5.1-5.2). We also (iv) characterize a set of user strategies for selecting data to be labeled, that we found our participants applying in VIL conditions (Sec. 5.3). With these findings, we discuss lessons learned, insights gained, and potential future work (Sec. 6).</p><p>Our investigation shows that VIL achieves similar performance to AL and in some settings even outperforms AL. It further points out new connecting points where VIL and AL may benefit from each other. The presented investigation represents an important step towards a unified labeling process that combines the individual strengths of user-centered and model-centered strategies.</p><p>We present related work in the next section, followed by our baseline approaches in Section 3, used for our experimental study. In Section 4, we introduce the experiment design, and present the experiment results in Section 5. We discuss follow-up insights in Section 6, and conclude with a discussion on limitations and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Related work for our study comes from different domains. Thus we subdivide the presentation of related work into three sections: related work on active learning (Section 2.1), visual interactive labeling (Section 2.2) and previous studies on visual interactive labeling (Section 2.3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Active Learning</head><p>Active learning (AL) is a special type of semi-supervised machine learning which takes the user into the loop to query label information to improve the training performance of a classifier. AL techniques ask (query) an oracle (the user) for specific instances instead of, e.g., querying random instances. AL is especially useful in cases where large portions of the data are unlabeled, or where manual labeling is expensive. Thereby, the major goal of AL is to achieve high accuracy with a minimum of manual labeling effort. The core component of AL is the candidate selection strategy which aims at identifying those instances which would contribute most to the learning progress of the model. The different classes of AL strategies are described in several surveys in detail <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b67">68]</ref>. We partition AL strategies into four major classes: (i) uncertainty sampling, (ii) error reduction schemes, (iii) relevance-based selection, and (iv) purely data-centered strategies.</p><p>Uncertainty sampling aims at finding the instances that the learner is most uncertain or unsure about. A widely used strategy is to search for those samples near the decision boundary of margin-based classifiers <ref type="bibr" target="#b71">[72]</ref> also referred to as large-margin based AL <ref type="bibr" target="#b64">[65]</ref>. Other strategies measure the uncertainty of a committee of classifiers. In Query by Committee (QBC) <ref type="bibr" target="#b59">[60]</ref>, each classifier of the ensemble is asked for labelings. Instances are considered interesting when the committee disagrees with respect to their labeling <ref type="bibr" target="#b35">[36]</ref>.</p><p>Error reduction schemes focus on the selection of those instances which may change the underlying classification model most. Techniques focus either on the impact on the training error (expected model change) <ref type="bibr" target="#b58">[59]</ref> or on the reduction of the generalization error (risk reduction <ref type="bibr" target="#b41">[42]</ref> and variance reduction <ref type="bibr" target="#b23">[24]</ref>).</p><p>The third group of AL strategies focuses on relevance <ref type="bibr" target="#b66">[67]</ref>. Based on a relevance criterion, those instances are selected which have the highest probability to be relevant for a certain class. This strategy fosters the identification of positive examples for a class. This is particularly useful in systems that aim at ranking search results <ref type="bibr" target="#b67">[68]</ref>.</p><p>Finally, one of approaches is purely data-driven and independent of the learning model. Examples for such data-driven strategies are density-and diversity-based instance selection. The diversity criterion fosters the selection of dissimilar instances for labeling to increase the information gain for the learner <ref type="bibr" target="#b16">[17]</ref>. In density-based selection, the query candidates are selected from dense areas of the feature space because those instances are considered as most representative <ref type="bibr" target="#b71">[72]</ref>. Density-based selection of candidates is a promising strategy for initiating an AL process in the case when no labels are available at all (cold start problem).</p><p>In this work, we employ a heterogeneous set of 16 AL strategies to obtain a representative baseline for AL (see Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual-Interactive Labeling and Classification</head><p>Labeling is a frequently supported task in visual analytics. Depending on the given task and approach, different types of labels may be employed. A widely used label type are categorical labels which can be either binary or multi-valued. Binary labels enable simple user feedback, such as "yes/no" decisions or "relevant/not relevant" assessments. Multi-valued categorial labels enable for example the tagging of different classes of objects. Users can, e.g., label relevant textual documents <ref type="bibr" target="#b21">[22]</ref>, interesting time series patterns <ref type="bibr" target="#b46">[47]</ref>, or occurrences of objects in video streams <ref type="bibr" target="#b22">[23]</ref>. Another important label type are continuous labels, often used to assign more fine grained interestingness or relevance scores. Example applications include relevance feedback <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b53">54]</ref>, candidate assessment and evaluation <ref type="bibr" target="#b70">[71]</ref>, patient well-being scores <ref type="bibr" target="#b3">[4]</ref>, or distinguishing between relevant and irrelevant views <ref type="bibr" target="#b1">[2]</ref>. Aside from providing labels explicitly, another type of user feedback is to directly provide weights (of features or data attributes), e.g., to build, validate, or improve algorithmic models <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b69">70]</ref>. Another type of label are similarity relations between instances, explicitly assigned by users which are used, e.g., to learn distance functions to support the visual-interactive re-allocation of instances <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b34">35]</ref>.</p><p>Labeling is an upstream task for (visual-interactive) classification approaches. Some approaches directly combine AL-based with VIL-based instance identification and labeling <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b56">57]</ref>. Seifert and Granitzer <ref type="bibr" target="#b54">[55]</ref> elaborate on user-picking strategies similarly as we do in our experiment. In contrast, the baseline interface does not aim for a similarity-preserving representation of instances. Heimerl at al. <ref type="bibr" target="#b21">[22]</ref> and Höferlin et al. <ref type="bibr" target="#b22">[23]</ref> present visual analytics systems <ref type="figure">Fig. 2</ref>: Visual-interactive interface for labeling instances. Four dimensionality reduction techniques provide different perspectives on the data set (default: t-SNE). In the center instances can be selected for labeling. At the right, users can refine selections and label multiple instances at once (in TR 3 ). Four different VIL-support techniques can be included to ease the visual-interactive labeling process (see <ref type="figure" target="#fig_1">Figure 1</ref>). combining multiple views including VIL support, model visualization, and instance labeling. We build upon these approaches for the implementation of our study results. Unsupervised techniques can be employed to ease the task of user-based labeling. Several approaches provide visualizations of cluster results in 2D, in combination with interaction tools like a 'lasso' for multi-instance selection <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b37">38]</ref>. From clustering, we take up the idea to support users in labeling instances in dense areas that are most representative. In this context, we will also examine whether or not visual cluster structures and user expectations <ref type="bibr" target="#b37">[38]</ref> are beneficial for the labeling process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Previous Studies on Visual Interactive Labeling</head><p>The number of experiments and studies regarding the performance of VIL is scarce. At a glance, our experiment builds upon insights gained from studies on the identification of human labeling strategies, the comparison of labeling-support techniques, multi-instance labeling, as well as measures of class separability. Möhrmann et al. measured the applicability of SOM-based data clustering and visualization as a means to support the generation of ground truth for image data <ref type="bibr" target="#b37">[38]</ref>. Similar to one of the parts of our experiment, the authors assess the increase in efficiency when labeling multiple instances at once. However, the authors report accuracy values that remained constant with a slight tendency to deterioration. The experiment conducted by Settles measures the annotation time of users versus accuracy <ref type="bibr" target="#b56">[57]</ref>. We build upon the ideas to raise baseline random performance measures as well as an upper limit of performance to provide upper and lower bounds. In contrast to our experiment, the comparison is between learning from instances, with and without additionally learning from features. In their studies, Seifert and Granitzer <ref type="bibr" target="#b54">[55]</ref> simulated user-picking strategies for instance selection, allowing the automation of user-based selection in a laboratory study. The authors presented a VIL-support technique based on radially ordered axes of a classifier's a-posteriori output probabilities and claimed that their technique outperforms uncertainty based sampling (AL) <ref type="bibr" target="#b55">[56]</ref>.</p><p>In contrast to previous studies, we further focus on the comparison of model-based (AL) versus human-based (VIL) label selection strategies. In particular, we are interested in observing what drives users to select particular instances in a given labeling interface. One way for humans to enhance the labeling process is the ability to identify patterns such as dense areas of instances and class distributions. Our experiment builds upon the results of a study on visual cluster and class separability <ref type="bibr" target="#b52">[53]</ref>. With the evaluation of techniques supporting VIL, we further investigate the effect of well-separable class distributions on effective and efficient labeling. One inspiring side-aspect is entailed in an experiment comparing the results of cluster validity measures with user evaluations (experts and non-experts) <ref type="bibr" target="#b32">[33]</ref>. Building on the basic assumption that model-based and user-based strategies of candidate identification differ, we will adopt the idea to further observe user preferences in candidate selection. Finally, Lewis et al. <ref type="bibr" target="#b33">[34]</ref> conducted an experiment on whether humans are consistent in rating the quality of results of dimensionality reduction algorithms. Similarly, a motivating aspect for our user experiment is to investigate the consistency of user-based labeling strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">APPROACHES</head><p>The major goal of this work is to compare AL and VIL strategies for data labeling tasks. For this purpose we have developed a toolkit that allows for simulating AL experiments as well as performing visual interactive labeling of data by users (identification, selection, and labeling of instances). Section 3.1 provides more details. We integrate a number of AL techniques and classifiers into the toolkit which we summarize in Sections 3.3 and 3.2. The visualization techniques that we propose to support VIL strategies are described in Section 3.4. We refer to them as VIL-support techniques in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Visual-Interactive Labeling Toolkit</head><p>We present a visual-interactive toolkit that supports the visualization of high-dimensional datasets, the integration and (automated) evaluation of AL strategies, and the enrichment with VIL-support techniques to ease the labeling process. The interaction loop of the labeling process builds upon the visual-interactive labeling process presented by Bernard et al. <ref type="bibr" target="#b6">[7]</ref> which also contains a graphical representation of the process. The design of the visual-interactive labeling interface fulfills the following three primary requirements: First, the toolkit provides a visual representation of the entire data set in 2D in a structure-preserving way. Second, the interaction design facilitates the selection and labeling of single and/or multiple instances. A lasso-tool allows the selection of multiple instances, i.e., a range selection in the 2D data representation. Third, to enable the objective comparisons between AL and VIL, labeling interactions by users trigger the same mechanisms for model building and performance testing as automatically executed AL strategies.</p><p>The visual interface of the toolkit is presented in <ref type="figure">Figure 2</ref>. Inspired by experiments on dimensionality reduction, scatterplots, and measures of class separation <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b62">63]</ref>, our toolkit uses dimensionality reduction techniques to map high-dimensional data into 2D. A total of four techniques (PCA <ref type="bibr" target="#b26">[27]</ref>, non-metric MDS <ref type="bibr" target="#b29">[30]</ref>, Sammons Mapping <ref type="bibr" target="#b45">[46]</ref>, and t-SNE <ref type="bibr" target="#b65">[66]</ref>) are used in a small-multiples setting to provide different perspectives on the data. This mitigates weaknesses of individual techniques. An overview of dimensionality reduction techniques for visualization is provided by Sacha et al. <ref type="bibr" target="#b43">[44]</ref>, parameter values used for the four techniques are described in the supplemental material.</p><p>The three primary views of the labeling interface are as follows. In the left view, users can select one of the four dimensionality-reduced data representations (default: t-SNE). The selected mapping is subsequently presented in the center view. At the beginning, all data instances are represented with small crosses in the center view, indicating that they are unlabeled. Once users label individual instances, the instances are depicted with small visual representations, in our case thumbnail images. The right view allows the refinement of selected subsets and multi-instance labeling, triggered by the label buttons at the bottom. The labeling information is then fed back to the underlying machine learning models which are re-trained on the enriched training set. The interaction loop is closed as soon as the results of the learning model are finished. The new classifier predictions are propagated to the center view which is updated with the new results <ref type="bibr" target="#b6">[7]</ref>. Section 3.4 provides details about visualization techniques used to represent the classification output. Note that the same process is performed for AL strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classifiers and Classification Accuracy</head><p>We integrate five different classifiers into the toolkit (Support Vector Machine (SVM) <ref type="bibr" target="#b12">[13]</ref>, Random Forest (RF) <ref type="bibr" target="#b8">[9]</ref>, Naive Bayes <ref type="bibr" target="#b17">[18]</ref>, Multilayer Perceptron (MLP) <ref type="bibr" target="#b24">[25]</ref> and Simple Logistic <ref type="bibr" target="#b30">[31]</ref>). The classifiers are used for testing the performance of labeled sets of instances in combination with the learned models in our study. With the use of five different classifiers, we achieve robustness in the assessment of labeling performance. The computation of classification accuracy is always performed on a separate instance set for testing <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Active Learning Strategies</head><p>In active learning (AL) an algorithmic model proactively asks the user for feedback (labels) about selected samples <ref type="bibr" target="#b55">[56]</ref>. Basically, the algorithmic selection of unlabeled instances is based on the result of an included classification model in combination with a quality criterion (see Section 2.1 and the supplemental material for details about the operating principles of AL). We integrate 16 supervised AL strategies into the evaluation toolkit that build upon eight different AL techniques. Techniques include Smallest Margin <ref type="bibr" target="#b47">[48]</ref>, Entropy-Based Sampling <ref type="bibr" target="#b57">[58]</ref>, Least Significant Confidence <ref type="bibr" target="#b13">[14]</ref>, Simpson Diversity <ref type="bibr" target="#b61">[62]</ref>, Probability Distance, Vote Comparison, Vote Entropy <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b60">61]</ref>, and Average Kullback Leibler <ref type="bibr" target="#b36">[37]</ref>. The first four techniques are combined with the three classifiers (SVM, MLP, RF) each, yielding 12 different AL strategies. The latter four techniques are query-by-committee (QBC) approaches that use all three classifiers simultaneously and vote over their individual decisions. This adds up to a total of 16 AL strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">VIL-Support Techniques</head><p>Related work in visual classification approaches reveals a series of techniques that have the potential to support VIL. In this work, we define a VIL-support technique as a visualization that assists the user in the selection of candidates for labeling, i.e., VIL-support techniques may facilitate VIL strategies. We present four VIL-support techniques that we assume to be particularly interesting and beneficial for interactive labeling. Enlarged example figures of all four VIL-support techniques are provided in the supplemental materials. The labeling toolkit presented in <ref type="figure">Figure 2</ref> serves as the baseline for all techniques. We apply voting between the five classifiers included in the system to condense the information of multiple classification results to a single class prediction for every instance. Accordingly, this condensed information about the current state of the learning models is exploited with the VIL-support techniques.</p><p>2D Colormap Every data element is colored with respect to its 2D location in the projection shown in the center view. The colors are linked to the small multiples at the left to support the lookup of instances in other views and the comparison of different perspectives on the data. In this way, users can expose mapping distortions and thus make informed decisions when selecting data elements. We use a 2D colormap to represent position information with continuous and similarity-preserving colors <ref type="bibr" target="#b5">[6]</ref>  <ref type="figure" target="#fig_1">(Figure 1a</ref>). Compared to the remaining techniques, this VIL-support technique does not require any information about the underlying classification model.</p><p>Class Coloring Each class is assigned a separate color <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b62">63]</ref>. Coloring classes or clusters in scatterplots is a frequently applied ap-proach <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b63">64]</ref>. Here we evaluate if this technique is also beneficial to support VIL ( <ref type="figure" target="#fig_1">Figure 1b)</ref>.</p><p>Convex Hull The convex hull is a prominent technique for the visualization of class distributions and boundaries <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b63">64]</ref>. We employ convex hulls to visualize the boundaries of the classes <ref type="figure" target="#fig_1">(Figure 1c</ref>) and investigate its suitability for VIL.</p><p>Butterfly Plot The butterfly plot technique <ref type="bibr" target="#b49">[50]</ref> is an interesting refinement of convex hulls that additionally provides information about the center of gravity of class distributions <ref type="figure" target="#fig_1">(Figure 1d</ref>). While the butterfly plot tends to produce more complex shapes it better highlights outliers than convex hulls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL DESIGN</head><p>We conducted an experiment with three main distinctive parts: (PART 1-3 ). Each part focused on a specific set of questions. The major goal of our experiment was to examine the potential of VIL and how it compares to AL. We first describe the general setup of the experiment, before we provide details for each part (variables, setup, tasks, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Research Questions</head><p>We formulated six research questions for our experiment:</p><p>• </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline AL Strategies</head><p>To obtain a representative and robust baseline a broad range of existing state-of-the-art approaches is required. These approaches can be run for comparison automatically and do not need to be tested by users directly, so we are not restricted by the participants' time here. We thus selected 16 AL strategies as baseline conditions (cf. Section 3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Data Set</head><p>To keep the study complexity manageable, we use a single, easy-tounderstand reference data set in our study. After reviewing a number of data sets the decision was made for the MNIST data set representing classified handwritten digits <ref type="bibr" target="#b31">[32]</ref>. The database contains 60,000 instances for training and 10,000 instances for testing from 10 distinct classes (digits "0" to "9"). Each raw digit is represented by a 28x28 grayscale image yielding a 784 dimensional vector in the original space.</p><p>The grayscale values represent the luminance information of the digits, while black color encodes the background (see, e.g., <ref type="figure">Figure 2</ref> in the top-right corner). To reduce the dimensionality for faster classification, we extract a descriptor based on 11 horizontal, 11 vertical, and 20 diagonal slices carved out from the original grid. A detailed description of the feature extraction is provided in the supplemental materials. The final feature vector is applied as input for training and testing classifiers, executing AL strategies, and applying dimensionality reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Participants</head><p>We recruited 16 participants (2 female) in our lab. Each participant performed all three parts of the experiment. The age of the participants ranged from 26 to 58 (Median = 33.06, SD = 7.56). All participants had normal or corrected-to-normal vision. Each subject had at least a Bachelor's degree and expertise in visualization, data mining, machine learning, or combinations thereof. However, none of the participants has either worked with the particular data set in detail, or has in-depth experience in implementing classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Procedure</head><p>We prepared a workstation in a quiet lab with a color-calibrated monitor. The evaluation toolkit (cf. Section 3.1) was installed and prepared for the experiment. <ref type="figure">Figure 2</ref> gives an impression of the toolkit. By design, all unlabeled (unknown) instances are represented with x, labeled instances are depicted with the image of the handwritten digit. At the beginning, the participants were introduced to the topic and the goals of our experiment, accompanied by the possibility to ask questions. Our toolkit was introduced in a short demo session, including its interaction techniques and VIL-support techniques. In addition, the concept of (baseline) AL strategies was described, as well as the functionality of the classifiers to be trained in the course of each session.</p><p>The main part of our study consisted of three core parts then:</p><p>• PART 1 -Users were asked to label the data under the 4 different VIL conditions described in 3.4. Our goal was to learn about how VIL techniques compare among each other, as well as to the baseline AL strategies, and how they do so in differently complex situations. • PART 2 -The users had to engage in a single and a multipleinstance selection tasks, so we can compare single vs. multiple instance labeling strategies for AL and VIL. • PART 3 -We gathered qualitative and subjective feedback from the participants. During PART 1 and PART 2 , the participants were asked to think aloud in the course of the labeling process, e.g., when they identify special cases, difficulties, or interesting findings. We also observed them and took notes on interesting behaviors and user strategies. Both parts used a separate within-subject design, which will be described in more detail below.</p><p>The overall time to perform the three parts was estimated with 75 minutes, depending on the extent of the interview. Participants were allowed to take breaks between the three parts. We now describe the experimental design of each part in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">PART 1 : Performance Comparison VIL and AL</head><p>The first part of the experiment considered the question whether or not the four VIL-support techniques can compete with state-of-the-art AL strategies, how they compare among each other, and how they perform in three different levels of complexity <ref type="figure" target="#fig_0">(RQ 1-3</ref> ). To answer these questions, PART 1 was organized as a 4 × 3 within subject design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1">Independent Variables</head><p>We had two independent variables in PART 1 . VIL. Our main variable of interest were the 4 different VIL-support techniques as outlined in Section 3.4: 2D Colormap, Class Coloring, Convex Hulls, and Butterfly Plot (cf. <ref type="figure" target="#fig_1">Figure 1)</ref>. Complexity. The second variable was task complexity. Complexity of the labeling task at hand is a very important factor that can strongly influence AL and VIL performance. Task complexity in itself, however, is a multifaceted concept. It is influenced by model aspects such as the number of different classes, how many data points it is operating on, the chosen model type, etc. It also depends on the input data and the nature of the labeling tasks, for instance, labeling digits might be easier than labeling objects in video streams. No single study can investigate all of these factors at once. Based on our pilot study (see suppl. materials), we thus opted for a well-defined labeling task (labeling digits), and focus on three different levels of model complexity: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2">Task Description</head><p>We asked the participants to select data instances for labeling in a meaningful way based on their preference. Depending on the provided VIL-support technique additional information about data and/or classification result was shown that possibly supported the process of selecting instances for labeling. As a general rule, we asked the participants to exploit relevant information about patterns explored in the labeling interface, and use it for the selection (labeling) of instances. For every condition, users were informed about the set of labels existing in the data set (task complexity). The focus of PART 1 was on the selection of instances rather than the actual process of assigning a label to the selected instance. We thus setup our toolkit in a way that participants did not actually need to label the digits of selected instances to save time. They could simply select an instance by clicking on it. The label was then set automatically and the image was revealed to the user. The registration of the true label of for the selected instance was automatically triggered to the evaluation bench (see the interaction loop in Section 3.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.3">Setup</head><p>The independent variables of PART 1 lead to 4 × 3 = 12 different conditions. We decided for a within-subject design, so all 16 participants were asked to perform all 12 conditions. We decided not to randomize the order of VIL techniques as the conditions are building up on top of each other (the number of visual variables depicting model information was zero for 2D Colormap, one for Class Coloring, and two for Convex Hulls and Butterfly Plot). The three different complexities of the labeling task were always performed in the natural order from easy to difficult. The data instances used for training and testing were randomly chosen with a constant seed to achieve both comparability and reproducibility. All other choices were based on the pilot study that we describe in Appendix A in the supplemental materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.4">Dependent Variables</head><p>Accuracy. To assess the performance of the 12 tested conditions outlined above, a measure is needed that is expressive and easy to understand. To enable comparability, the measure should be applicable for the 12 conditions and the baseline AL strategies. Based on these requirements, we select classification accuracy as the sole dependent measure to compare how 'good' the different conditions are. We use the standard definition of classification accuracy, that is, the portion of correctly classified instances compared to ground truth labels <ref type="bibr" target="#b18">[19]</ref>. To achieve robust (classifier-independent) accuracy estimates, we compute the accuracy after every label operation for all five classifiers listed in Section 3.2 and average the results. This leads to robust performance estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">PART 2 : Labeling Single vs. Multiple Instances</head><p>In the second part of the experiment, we turn towards the assessment of efficiency of the labeling process. To this end, we allow labeling multiple instances with the same label in a single labeling iteration. We investigate whether or not VIL can facilitate the concept of labeling multiple instances at once to make the process more efficient (RQ 4 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.1">Independent Variables</head><p>Single vs. Multi Labeling. We were interested in the question of how many labels should be set at once in the labeling interface. There are essentially two options. Setting one label to a single instance, one after another, or assigning a label to multiple instances at once. VIL vs. AL Strategies. Assigning labels to multiple instances at once can be facilitated with AL and for VIL as well. As a result, and in contrast to PART 1 , AL now shifts from an automated baseline approach to an independent variable as the participants need to get active in these conditions as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.2">Task Description</head><p>In contrast to PART 1 , the users' task in PART 2 was to explicitly assign labels to instances. That is, users selected and labeled instances (in VIL conditions), or they labeled suggested instances (in the AL condition).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.3">Setup</head><p>Altogether, the two independent variables form four conditions. We refer, to these four different conditions as:</p><p>• AL single labeling: AL suggests one item, labeled by the user • AL multi labeling: AL suggests multiple items to be labeled by the user; the user can select a subset of the suggestions and label them with one class label, for example, all "1s". <ref type="figure">Fig. 4</ref>: The accuracy of labeling strategies depends on the complexity of the labeling task. The performance of all VIL results (orange) can at least compete with the performance of AL (blue), and RB (black). ULoP (green) substantially outperforms all remaining strategies. Dashed lines represent minimum and maximum performances, area dyed with decreased alpha is used to depict 25% and 75% quartiles.</p><p>• VIL single labeling: The user selects a single item and labels it.</p><p>• VIL multi labeling: The user can select multiple instances with a lasso and give a label to this selection after filtering false positives. We provide dedicated interfaces for these conditions. For the VIL conditions, we use the interface described in Section 3.1. For VIL single, the user can only click select single items; for VIL multiple, he can use the lasso as described in Section 3.1. The interface was based on the Convex Hull design option, and is shown at the right of <ref type="figure">Figure 2</ref>.</p><p>In case of AL multi-labeling, we introduce a list-based interface, which allows the user to see the AL-suggested instance(s) and label them. In the AL single case, only one instance at a time is shown. In the AL multiple, multiple instances are shown and the users can select the items they think being to a certain class, and label them. We chose Smallest Margin <ref type="bibr" target="#b47">[48]</ref> in combination with a Support Vector Machine (SVM) <ref type="bibr" target="#b12">[13]</ref> classifier from the set of 16 AL strategies (cf. Section 3.2), as it is well-known, easy to implement, and produced consistently robust results with accuracies above average. Screenshots of all interface conditions are in the supplemental material.</p><p>We decided again for a within-subject design, so every participant was asked to perform all four conditions. The order of the conditions was from simple to difficult regarding labeling single or multiple labels at once. The order of VIL and AL was randomized. The data instances used for training and testing were again randomly chosen with a constant seed to achieve both comparability and reproducibility. The difficult labeling task was chosen (cf. Section 4.6), thus, all labels from 0 to 9 were included in the data set. For each condition, participants were asked to label as many instances as possible in 5 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.4">Dependent Variables</head><p>Accuracy. The accuracy measure described in PART 1 is again used to assess the effectiveness of the labeling task. Number of Labeled Instances. In addition, we are interested in a performance measure assessing the efficiency. Thus, we also look at the number of instances labeled over time as a second dependent variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">PART 3 : User Strategies and Feedback</head><p>After the two main parts of the study, the moderator conducted a summative interview, including questions about preferences, informal feedback, and subjective estimates about the usefulness of VIL-support techniques. We also handed out a short questionnaire to gather additional subjective feedback, with 5-point Likert scales regarding the subjective preference on VIL-support techniques.</p><p>The rationale of this part (PART 3 ) was to answer RQ 5 and RQ 6 , that is, whether or not users developed strategies for the selection of meaningful instances in VIL, and how these potential strategies relate to VIL-support techniques and AL strategies. Inspired by the algorithmic formalization of AL strategies for the selection of instances, we sought for formalizations of strategies performed by users when selecting instances for labeling. This was further informed by the qualitative input we got from the think-aloud protocols and our qualitative observations <ref type="figure">Fig. 5</ref>: Performance comparison of four VIL-support techniques (orange) with AL strategies (blue), RB (black), and ULoP (green) for an easy labeling task (PART 1 ). The overall insight is that all VIL-support techniques outperform AL and RB. In many cases the accuracy was around 0.95% after only three labeled instances.</p><p>(see Section 4.5). All sessions were audio-recorded. We used a lightweight open/axial coding approach to analyze this qualitative data <ref type="bibr" target="#b10">[11]</ref>. The analysis was done by one of the authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Data Analysis</head><p>To analyze our data, we mostly leverage visual representations of the performance of the different VIL and AL strategies over the course of many iterations, that is, line charts. Variations in the performances of the 16 participants (and 16 AL strategies) are visually represented as a "bundle" with an emphasis on statistical information represented over time. The colored area around a mean curve represents the interquartile range of the measured results ([Q 0.25 − Q 0.75 ]), dyed with decreased alpha. Dashed line charts depict minimum and maximum performances. As a general rule, the color coding used to assess performance of curves is orange for VIL and blue for AL. We superimpose AL and VIL results to allow for an easy visual comparison (i.e., comparison of bundles).</p><p>We also wanted to contextualize our findings by providing upper and lower bounds in the experiment. We thus provide two additional pieces of information in the line charts: a random baseline (RB) shown in black, and an upper limit of performance (ULoP) shown in green. For RB we simply sample the items for labeling randomly. To achieve robustness, 50 RB trials are calculated for every evaluation. The expectation is that the remaining strategies should at least perform better than this RB. For a similar purpose, we provide ULoP, which simulates an optimal labeling strategy where always the "best" (most beneficial) item is selected in each iteration. The calculation is based on a Greedy search, simulating the accuracy of the next labeling step for all remaining candidate instances. <ref type="figure" target="#fig_0">Figure 3</ref> shows the results of the AL strategies compared to RB, and the ULoP line chart, and illustrates our approach of visual data analysis.</p><p>We furthermore use confidence intervals (CI) for our analysis, following APA's up-to-date recommendation for statistical analyses <ref type="bibr" target="#b0">[1]</ref>. In the following, we use M for the sample mean as well as CI for the confidence interval defined by M ± Z score * SD/ √ n <ref type="bibr" target="#b14">[15]</ref>. We define Z score = 1.96, representing the commonly used CI = 95%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>We report results for the visual-interactive user experiment structured in three different parts. In Section 5.1, we take the factors of varying complexities of labeling tasks and different VIL-support techniques into account (PART 1 ). Results of the comparison of single and multiple instance labeling tasks are presented in Section 5.2 (PART 2 ). Finally, in Section 5.3, we report insights gained from the observation of participants, summative interviews, and informal feedback (PART 3 ). Large figures of all results are provided assupplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">PART 1 : Performance Comparison VIL and AL</head><p>The questions answered in PART 1 are whether or not VIL is able to compete with state-of-the-art AL strategies in different conditions <ref type="figure">Fig. 6</ref>: Performance comparison of four VIL-support techniques (orange) with AL strategies (blue), RB (black), and ULoP (green) for a labeling task with medium difficulty (PART 1 ). All VIL-support techniques have accuracies at least as high as AL and RB in earlier phases of the process. Convex hulls can compete with the AL performance for the entire observed process. ULoP (green) substantially outperforms all remaining techniques. <ref type="figure" target="#fig_0">(RQ 1,2,3</ref> ). To that aim, we investigate the performance of four VILsupport techniques in combination with three different task complexities (details about PART 1 in Section 4.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Performance for Different Task Complexities</head><p>First, we assess the dependency of the labeling performance on the complexity of the labeling settings. Three different task complexities easy, medium, and difficult are evaluated and compared.</p><p>Results <ref type="figure">Figure 4</ref> shows the overall results of the performance comparison for easy (left), medium, and difficult (right) labeling tasks. In general, the performance of virtually any strategy increases in the course of the labeling process. Please note that the performances of the four VIL techniques are aggregated for every complexity level. The results show that from easy to difficult the accuracy decreases substantially for all strategies, i.e., we infer that the complexity level has an influence on the labeling performance. A more detailed analysis reveals that the performance of VIL is at least as good as AL for all three task complexities (RQ 1,2 ). For easy tasks VIL outperforms AL considerably. In early phases, the accuracy curve is very steep and converges at higher levels. Using iteration 20 as an example, M = 0.96 (CI = [0.95 -0.98]) for VIL whereas the performance of AL only reaches M = 0.85 (CI = [0.82 -0.88]). One explanation may be that VIL enables faster capturing instances of all classes. This can be seen as an indicator that human intuition (in combination with data visualization) may be useful to solve the cold start problem of AL approaches (AL even performs weaker than RB at start). The results of the performance comparison for medium and difficult task complexities are similar. VIL performs slightly better than AL, RB can compete with AL. In the difficult case after 20 iterations, VIL performs with M = 0.42 (CI = [0.38 -0.45]) in contrast to AL (M = 0.35, CI = [0.33 -0.38]). However, we ascertain that VIL shows higher variations <ref type="figure">(Figure 4</ref> center, right). We draw the conclusion that, with VIL, human control over the labeling process is beneficial, but may also lead to weaker performances for individuals. In general, we ascertain that VIL can compete with the remaining strategies (RQ 1 ), even for complex labeling settings (RQ 2 ). The comparison of all strategies with the results of the ULoP indicates remaining potential. Even for the difficult condition, ULoP still achieved outstanding performance (M = 0.70 at iteration 20).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Comparison of VIL-Support Techniques</head><p>The second factor in PART 1 was the comparison of the 4 VIL-support techniques. The core question is whether VIL-support techniques perform differently (RQ 3 ). According to the 4 × 3 experiment conditions, we compare VIL-support techniques for the easy, medium, and difficult complexity level, Section 4.6 provides additional details. <ref type="figure">Fig. 7</ref>: Performance comparison of four VIL-support techniques (orange) with AL strategies (blue), RB (black), and ULoP (green) for a difficult labeling task (PART 2 ). For difficult labeling tasks, the performance of AL and VIL is more similar, with VIL having slight advantages over AL. RB performs surprisingly well. All VIL-support techniques have a good starting performance. Convex Hulls and Butterfly Plots perform well over the entire labeling process.</p><p>Results In <ref type="figure">Figure 5</ref>, results of the four VIL-support techniques can be compared for the easy task. Thus, we now explicitly distinguish the performances of different VIL-support techniques. One finding that can be identified without effort is the substantially better performance of all four candidates compared to AL. Compared to results of more difficult tasks VIL strategies are closer to the ULoP. We assume that, given an easy task, a clear separation of classes in 2D eases the identification of instances, leading to high accuracies very quickly. We conclude that differences between the four VIL-support techniques are negligible. <ref type="figure">Figure 6</ref> shows the performances of the VIL-support techniques for the medium task complexity. Again, it becomes apparent that VILtechniques are able to compete with AL strategies (RQ 1 ), particularly at the start of the process. In early phases of the labeling process (e.g., iteration 10), we assess the best performance for the  <ref type="figure" target="#fig_0">(RQ 1,3 )</ref>. In turn, the 2D Colormap approach cannot compete with the remaining techniques (M = 0.82). Finally, the ULoP outperforms all remaining strategies substantially which shows that there is still room for improvements.</p><p>The situation is similar for the difficult labeling task (see <ref type="figure">Figure 7)</ref>. All VIL-support techniques perform comparatively well at the beginning. Here, the 2D Colormap (no model information provided) slightly outperforms the remaining techniques (RQ 3 ). In the course of the process, the two shape-based techniques (Convex Hull M=0. <ref type="bibr" target="#b60">61</ref> and Butterfly Plot M=0.60) achieve the highest accuracies. Overall, the VIL strategies perform at least as good as AL and RB, AL again seems to perform weaker than RB at first. One explanation is that AL has problems to capture representatives of all classes (cold start problem) which is may be more severe for a complex tasks. To further investigate the cold start problem, we refer the reader to <ref type="figure" target="#fig_0">Figure 3</ref> which compares the accuracy of AL and RB for substantially more iterations. Here, we identify a break-even point at approximately 50 instances where AL starts to outperform RB. The observation strengthens the rationale to combine the strengths of AL and VIL, using the latter for entirely unlabeled data. One final insight gathered from <ref type="figure">Figure 7</ref> is the again outstanding performance of ULoP.</p><p>In summary, we identified that VIL can compete with AL (RQ 1 ) especially in early phases of the process. In addition, we ascertain a slight tendency of VIL-support techniques with classifier visualization to outperform the 2D Colormap technique (RQ 3 ). <ref type="figure">Fig. 8</ref>: Comparison of AL with VIL in combination with labeling single and multiple instances at once (PART 2 ). The duration of the labeling process is mapped to the x-axis ([ms] -300k = 5 min). Left: AL achieves higher accuracies (y-axis) than VIL for both single and multi-instance labeling. Right: the number of labeled instances is mapped to the yaxis. Assigning a label for multiple instances at once works particularly fast for VIL. In 5 minutes users were able to label approximately 450 instances on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">PART 2 : Labeling Single vs. Multiple Instances</head><p>PART 2 considered the question of whether the process can be made more efficient when multiple instances are labeled at once. In particular, we were interested whether or not VIL can make the process more efficient (RQ 4 ). The four candidate interfaces for PART 2 are AL single labeling, AL multi labeling, VIL single labeling, and VIL multi labeling, Section 4.7 provides additional information about the experiment design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of Effectiveness</head><p>We analyze the progression of accuracy of the four candidates measured over time (see <ref type="figure">Figure 8</ref>, left). The duration (300,000 ms) of the labeling process is mapped to the x-axis. The analysis of the accuracy (mapped to the y-axis) provides three insights. First, in the beginning of the process the four candidates perform fairly balanced. Second, both AL strategies (blue colors) achieve higher accuracies in less time in the remaining phase of the process. Third, labeling multiple instances at once improves the efficiency. This accounts for AL as well as for VIL. Overall, with respect to the accuracy over time, VIL cannot compete with AL. One explanation of the lower accuracy values is associated with an observation we made several times in the study. Selecting and filtering a large number of identical instances requires a considerable portion of time. Thus, many participants did not label all of the classes (leading to weaker accuracies), as this was not subject of the task introduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of Efficiency</head><p>We analyze the number of labeled instances over time for all four candidates (see <ref type="figure">Figure 8</ref>, right). We make two observations. First, the efficiency of VIL multi labeling is considerably better than the three remaining candidates. Thus, labeling multiple instances at once with a VIL-based interface can substantially increase the efficiency of the labeling process (RQ 4 ). We observed that users partially labeled 50 or more instances at once leading to a massive increase of efficiency compared to the other interfaces. Even the minimum performance of all users is considerably better than the maximum performance of any user using the remaining interfaces. Second, both AL-based candidates outperform VIL single labeling. This can be explained with the overhead of VIL approaches requiring additional exploration, identification, and selection of single candidate instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">PART 3 User Strategies and User Feedback</head><p>In PART 3 , we focus on the question whether or not users develop strategies for the selection of instances in VIL (RQ 5 ) and if so, how these strategies relate to VIL-support techniques and AL strategies (RQ 6 ). The experimental setup of PART 3 follows the description in Section 4.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">User Strategies for Labeling Data</head><p>The observation of participants during PART 1-2 revealed a series of user strategies for selecting labeling candidates (RQ 5 ). We classified these strategies into data-centered and model-centered strategies in a joint discourse of the authors. Data-centered strategies focus on characteristics of data instances (elementary or synoptic level). Model-centered strategies are based on visual feedback of the current state of the classification model. Data-Centered Strategies Dense Areas First: Collections of instances that form dense clusters are preferred during the labeling process. This supports the classification performance by learning the information for many instances at once. Centroid First: Special type of Dense Areas First. Instances that are at the center of clusters are labeled first, in order to assign labels to instances that are representative for a cluster. Equal Spread: The user tries to assign labels to instances that are well distributed (in 2D), to make sure that there are no areas in the original (high-dimensional) space that do not contain labeled instances. Cluster Borders: Instances that are at the border between two clusters are labeled, in order to give the classifier information that helps to better separate the clusters. Outliers: Outliers of the data set are labeled explicitly, in order to allow the classifier to learn about the range of instances that belong to one class. Ideal Label: The user only assigns labels to the instances that are ideal candidates or representatives of the respective class. The motivation for some users applying this strategy was based on data-semantical reasons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-Centered Strategies Class Distribution Minimization:</head><p>The spread of a class in the 2D representation (e.g., represented with a convex hull) is to be minimized. Class Borders: The user tries to achieve clearly separated borders between classes based on the visual feedback on spatial class distribution (e.g. based on the size of the convex hull). Class Intersection: The labeling process aims at minimizing possible ambiguities in the intersection between classes (e.g. depicted with overlaps of convex hulls). Class Outliers: Users label those instances that are assigned to a class but are far away from the class center of gravity. Referring to the convex hull, this can be identified with a spike.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Subjective User Feedback</head><p>Finally, we report on the subjective feedback we received in the concluding interviews and questionnaire. <ref type="table" target="#tab_2">Table 1</ref> provides an overview of average scores (5-point Likert scale, with 5 being 'very good'). The subjectively preferred techniques are Convex Hulls and Class Colors (RQ 6 ). Overall, information about the state of the classification model (Class Color, Convex Hulls, Butterfly Plot) was welcomed by most participants. We identified a shift in the labeling strategies towards model-centered characteristics, such as class distributions and class outliers, provoked by the additional visual encodings. One potential drawback of the shift towards model-centered information is neglecting data-centered properties as revealed by dimensionality reduction in combination with scatterplots.</p><p>In the interviews, we also received rich user feedback on the usability of the different VIL-support techniques (RQ 6 ). 2D Colormap: Users remarked the disadvantage of missing model information. In turn, the simplicity of the interface was welcomed for the complex labeling task. Class Color: Users welcomed the direct feedback about the current state of the model by means of colors. For complex labeling tasks with many colors, users had problems in the distinction of some (categorical) colors. Convex Hulls: Many users liked the combination of color and shape-based information about the current state of the model. The distribution of classes in the 2D representation was easily comprehensible. However, overlays of many semi-transparent layers caused some problems in distinguishing classes.   Data-centered Model-centered VIL-support User Strategies <ref type="figure">Fig. 9</ref>: Usefulness of VIL-support techniques for ten identified user strategies for labeling data. The strategies can be partitioned into datacentered and model-centered strategies. User preference is depicted with color values from gray (low) to black (high).</p><p>depicted information about the model including an indication of class outliers and the class centers, as well as the more compact fill area compared to convex hulls. However, many users were confused by the non-regular shapes that distracted them from the underlying data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION AND FUTURE WORK</head><p>We conducted an experiment with three parts to assess the performance of VIL in comparison to AL. The results revealed several insights about the applicability of VIL-support techniques, but also shed light on current limitations. Based on the experiment parts, we experienced a series of user strategies for selecting data for labeling which provide interesting stimuli for future research. In the following, we highlight lessons learned from the experiment, discuss insights from the interviews, and point out future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Dimensionality Reduction</head><p>The interviews revealed that every user decided to conduct large parts of PART 1 and PART 2 with t-SNE as dimensionality reduction technique. Virtually all participants only used the remaining techniques for validation purposes, to have a second perspective. By design, t-SNE was the default technique and we cannot completely exclude that this may have caused a bias. Still, we can confirm that users unanimously argued that they sought for a technique that separates cluster structures best, according to the study conducted by Lewis et al. <ref type="bibr" target="#b33">[34]</ref> showing that users think seeing a cluster is a sign of quality of the method. One drawback of the unanimous vote is that we cannot make statements about the performance of alternative techniques for dimensionality reduction. A systematic study on the benefit of different dimensionality reduction techniques on the labeling process is an open topic and subject of future work. Another point of discussion is class separability which became more difficult for complex labeling tasks in PART 1 . For strongly overlapping classes dimensionality reduction may not be the best choice, as the individual classes may not separate well in the resulting 2D mapping. One reason for this is that dimensionality reduction techniques do not consider class information. An alternative solution may be the use of Linear Discriminant Analysis (LDA) <ref type="bibr" target="#b19">[20]</ref> or other supervised methods <ref type="bibr" target="#b68">[69]</ref> for dimensionality reduction. These approaches take class information into account and thus may enable a more appropriate dimensionality reduction and visualization of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Analytical Guidance</head><p>Our work fundamentally deals with the question on how to guide users, an important research challenge in visualization <ref type="bibr" target="#b25">[26]</ref>. Considering data or model-centered perspectives, guidance can be achieved by different strategies coming either from AL (e.g. highlighting instances near decision boundaries) or VIL (e.g. visualizing cluster centroids). Designing optimal guidance models, however, is a challenging direction for future research. Summarizing PART 3 , we have identified three promising approaches for guidance that we plan to implement and evaluate in the future: (i) providing instant feedback on the (estimated) benefit of labeling a certain instance, plus the visualization of the development of accuracy over time; (ii) guiding the user in a way that the distribution of labels across classes becomes balanced to avoid biasing the learning algorithm towards a certain class; (iii) leveraging analytical class separability measures (e.g. Sips et al. <ref type="bibr" target="#b62">[63]</ref>) to adaptively select a suitable visualization or to continuously select the best dimensionality reduction technique for the given dataset during the labeling process (i.e. the one which maximizes the class separability). A final issue of discussion is the study design with conditions building up on each other. While we observed a positive effect towards user guidance, we cannot preclude a certain bias from the VIL strategies in predefined order. An investigation of this potential bias is a subject of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">User-based Labeling Strategies vs. Active Learning</head><p>One goal of our experiment was the identification of 10 VIL strategies (cf. Section 5.3.1) (RQ 5 ). A question that arises in this context is which similarities and differences between VIL and AL strategies exist and whether one approach can learn from the other. We observe for example that many VIL strategies have a direct counter part in AL, e.g. "Density First" corresponds to density-based sampling and "class intersection" is a variant of uncertainty sampling. Other strategies, however, are special to VIL, e.g., "Equal Spread" and "Outliers". Learning about VIL strategies developed by users may be a valuable source of information for novel AL strategies. Conversely, AL strategies may inspire novel visual guidance approaches for VIL. Furthermore, the list of VIL strategies may extend in future investigations and represents a topic for further investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Upper Limit of Performance</head><p>The ULoP was much better than the AL and VIL strategies in all results. This shows that in both domains there is still potential for improvements which justifies future research. One exception was the easy labeling task examined in PART 1 where some users achieved similar performance values for some early iterations (cf. Section 5.1). This leads to the question which guidance strategy best approximates the upper limit.</p><p>In this context, it may be interesting to compare concrete candidate suggestions proposed by the upper limit of performance, those of AL strategies, and those of users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Visual Instance Representation</head><p>In this study, we have employed handwritten digits data which is easy to visualize and self-explanatory as well. In general, proper visual representations of instances are needed to enable users grasp the data characteristics <ref type="bibr" target="#b6">[7]</ref>. Promising classes of techniques addressing this challenge are visual identifiers like images of soccer players <ref type="bibr" target="#b2">[3]</ref>, glyph designs <ref type="bibr" target="#b7">[8]</ref>, visualizations showing the feature space <ref type="bibr" target="#b28">[29]</ref>, or visualinteractive solutions allowing to grasp detailed information about data on demand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We examined the performance of visual-interactive labeling (VIL) strategies in comparison to active learning (AL) and random sampling. The overall objective was to assess whether or not VIL can compete with AL. We conducted an experiment with three parts, each with focus on a different aspect. First, we examined four VIL-support visualization techniques for three different task complexities and identified that convex hulls depicting the current model state are particularly suitable to support users in labeling data instances. In addition, we ascertained that all tested VIL-support techniques can compete with the performance of AL labeling strategies, at least in the examined first 50 labeling iterations where the cold start problem of AL is most severe. Furthermore, we identified that VIL outperforms AL for easy tasks and can keep up for more difficult labeling tasks. Second, we assessed the positive effect of VIL for assigning labels to multiple instances at once. While AL outperforms VIL with respect to effectiveness, VIL leads to a substantial increase in efficiency. Third, a reflection of the experiment including observation and interviews of participants revealed ten user-based data selection strategies that may form a promising basis for future VIL and AL approaches, e.g., to incorporate analytical guidance in the labeling process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 :</head><label>3</label><figDesc>Accuracy of performance baseline strategies developing over 150 labeled instances (x-axis). The performance of 50 baseline random sampling trials (black) is compared with 16 variants of AL strategies (blue). Dashed lines represent the minimum and maximum performance, filled areas depict 25% and 75% quartiles. In the result, we identify a frequently observed pattern: AL strategies start poor (cold start problem), but outperform the random baseline in later phases. The upper limit of performance (green) performs exceptionally well.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 .</head><label>1</label><figDesc>Easy: 2 classes (0,1), 100 instances each class 2. Medium: 5 classes (0,1,2,3,4), 100 instances each class 3. Difficult: 10 classes (0,1,...,9), 100 instances each class</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Class Colors technique (M = 0.73, CI = [0.71 -0.75] in contrast to the 2D Colormap (M = 0.68, CI = [0.64 -0.73]), Convex Hull (M = 0.70, CI = [0.65 -0.74]), and the Butterfly Plot (M = 0.70, CI = [0.66 -0.73]). Another insight for late iterations is the good performance of the three techniques displaying classifier information (Class Colors M = 0.83, Convex Hull M = 0.85 and Butterfly Plot M = 0.84), the Convex Hull approach performs best and keeps track with AL (M = 0.85)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>t r o i d s F i r s t E q u a l S p r e a d C l u s t e r B o r d e r s O u t l i e r s I d e a l L a b e l s C l a s s D i v e r s i t y C l a s s B o r d e r s C l a s s I n t e r s e c t . C l a s s O u t l .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>RQ 1 -Is VIL, facilitated with VIL-support techniques, able to compete with state-of-the-art AL strategies? • RQ 2 -Is VIL effective even in complex labeling settings? • RQ 3 -Do VIL-support techniques perform differently? • RQ 4 -Can VIL facilitate the concept of labeling multiple instances at once, to make the process more efficient? • RQ 5 -Do users develop strategies for the selection of meaningful instances in VIL? • RQ 6 -How do these potential strategies relate to VIL-support techniques and AL strategies?</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Butterfly Plots: The Butterfly plot obtained the most user feedback. Positive aspects are the</figDesc><table><row><cell></cell><cell>2D</cell><cell>Col-</cell><cell>Class Col-</cell><cell>Convex</cell><cell>Butterfly</cell></row><row><cell></cell><cell>ormap</cell><cell></cell><cell>ors</cell><cell>Hulls</cell><cell>Plot</cell></row><row><cell>Score</cell><cell>1.7</cell><cell></cell><cell>4.3</cell><cell>4.4</cell><cell>3,7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>User preferences on VIL-support techniques in PART 1 and PART 2 . Convex Hulls achieved the highest scores, followed by Class Colors.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Publication manual of the American psychological association</title>
		<imprint>
			<date type="published" when="2010" />
			<publisher>American Psychological Association Washington</publisher>
		</imprint>
	</monogr>
	<note>6th edition</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Feedback-driven interactive exploration of large multidimensional data supported by visual classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Korkmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2014.7042480</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visual-interactive similarity search for complex objects by example of soccer player analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeppelzauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohlhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fellner</surname></persName>
		</author>
		<idno type="DOI">10.5220/0006116400750087</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. of IVAPP, VISIGRAPP</title>
		<meeting>of IVAPP, VISIGRAPP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="75" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A visual active learning system for the assessment of patient well-being in prostate cancer research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bannach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohlhammer</surname></persName>
		</author>
		<idno type="DOI">10.1145/2836034.2836035</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE VIS Workshop on Visual Analytics in Healthcare (VAHC)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">User-based visual-interactive similarity definition for mixed data objectsconcept and first implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ruppert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuijper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohlhammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In WSCG</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2014" />
			<publisher>Eurographics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey and task-based quality assessment of static 2d colormaps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mittelstädt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kohlhammer</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.2079841</idno>
	</analytic>
	<monogr>
		<title level="m">Electronic Imaging, SPIE Conference on Visualization and Data Analysis</title>
		<imprint>
			<publisher>SPIE Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">9397</biblScope>
			<biblScope unit="page" from="93970" to="93970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Unified Process for Visual-Interactive Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeppelzauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Aigner</surname></persName>
		</author>
		<idno type="DOI">10.2312/eurova.20171123</idno>
	</analytic>
	<monogr>
		<title level="m">EuroVis Workshop on Visual Analytics (EuroVA). The Eurographics Association</title>
		<editor>M. Sedlmair and C. Tominski</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Glyph-based visualization: Foundations, design guidelines, techniques and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Borgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kehrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Maguire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.2312/conf/EG2013/stars/039-063</idno>
	</analytic>
	<monogr>
		<title level="m">Eurographics State of the Art Reports</title>
		<imprint>
			<publisher>EG STARs</publisher>
			<date type="published" when="2013-05" />
			<biblScope unit="page" from="39" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Random forests. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dis-function: Learning distance functions interactively</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2012.6400486</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Constructing grounded theory. Sage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Charmaz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Clustermap: Labeling clusters in large datasets via visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1031171.1031233</idno>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Information and Knowledge Management (CIKM)</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="285" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reducing labeling effort for structured prediction tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inference by eye: confidence intervals and how to read pictures of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Finch</surname></persName>
		</author>
		<idno>doi: 10. 1002/sim.3471</idno>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">170</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Committee-based sampling for training probabilistic classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Engelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Machine Learning (ICML)</title>
		<imprint>
			<publisher>Morgan Kaufmann Pub</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="150" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Leveraging active learning for relevance feedback using an information theoretic diversity measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Dagli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1007/1178803413</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Image and Video Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="123" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern classification</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1973" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An experimental comparison of performance measures for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ferri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hernández-Orallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Modroiu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patrec.2008.08.010</idno>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="38" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The use of multiple measurements in taxonomic problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-1809.1936.tb02137.x</idno>
	</analytic>
	<monogr>
		<title level="j">Annals of Eugenics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="188" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A visual analytics approach to model learning. na</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2010.5652484</idno>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Visual classifier training for text document retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heimerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2012.277</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2839" to="2848" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Inter-active learning of ad-hoc classifiers for video visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Höferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Netzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Höferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heidemann</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2012.6400492</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Large-scale text categorization by batch mode active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="DOI">10.1145/1135777.1135870</idno>
	</analytic>
	<monogr>
		<title level="m">World Wide Web</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="633" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multilayer feedforward networks are universal approximators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stinchcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>White</surname></persName>
		</author>
		<idno type="DOI">10.1016/0893-6080(89)90020-8</idno>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="359" to="366" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dimstiller: Workflows for dimensional analysis and reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bergner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<idno type="DOI">10.1109/VAST.2010.5652392</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Visual Analytics Science and Technology (VAST)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Principal Component Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T</forename><surname>Jolliffe</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-4757-1904-87</idno>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Crowdsourcing user studies with mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kittur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<idno type="DOI">10.1145/1357054.1357127</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;08</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems, CHI &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="453" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Infuse: Interactive feature selection for predictive modeling of high dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bertini</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.2346482</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans on Vis. &amp; Comp. Graph</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1614" to="1623" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
		<idno>doi: 10. 1007/BF02289565</idno>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Logistic model trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Landwehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10994-005-0466-3</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="161" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<idno type="DOI">10.1109/5.726791</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Human cluster evaluation and formal quality measures: A comparative study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ackerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>De Sa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Cognitive Science Society (CogSci)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1870" to="1875" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A behavioral investigation of dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>De Sa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Cognitive Science Society (CogSci)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Userdriven feature space transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Mamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Fatore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Nonato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
		<idno>doi: 10. 1111/cgf.12116</idno>
	</analytic>
	<monogr>
		<title level="m">CGF</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="291" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Query learning strategies using boosting and bagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A H</forename><surname>Mamitsuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Machine Learning (ICML)</title>
		<imprint>
			<publisher>Morgan Kaufmann Pub</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Employing em and pool-based active learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Machine Learning (ICML)</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Pub</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="350" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improving the usability of interfaces for the interactive semi-automatic labeling of large image data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Möhrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heidemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Computer Interaction. Design and Development Approaches</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="618" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A literature survey of active machine learning in the context of natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Olsson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Weightlifter: Visual weight space exploration for multicriteria decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pajer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Torsney-Weir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Spechtenhauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2598589</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="611" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The projection explorer: A flexible tool for projection-based multidimensional visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">V</forename><surname>Paulovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C F</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Minghim</surname></persName>
		</author>
		<idno>doi: 10. 1109/SIBGRAPI.2007.21</idno>
	</analytic>
	<monogr>
		<title level="m">Symposium on Computer Graphics and Image Processing (SIBGRAPI)</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="27" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Two-dimensional multilabel active learning with an efficient online adaptation model for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2008.218</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1880" to="1897" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Human-Centered Machine Learning Through Interactive Visualization: Review and Open Challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symp. on Artificial Neural Networks, Computational Intelligence and Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peltonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>North</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2016.2598495</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="241" to="250" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Improving retrieval performance by relevance feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<idno>doi: 10.1002/ (SICI)1097-4571(199006)41:4&lt;288::AID-ASI8&gt;3.0.CO</idno>
	</analytic>
	<monogr>
		<title level="j">Readings in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A nonlinear mapping for data structure analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Sammon</surname></persName>
		</author>
		<idno type="DOI">10.1109/T-C.1969.222678</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="401" to="409" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Visual discovery and model-driven explanation of time series patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jamnik</surname></persName>
		</author>
		<idno type="DOI">10.1109/VLHCC.2016.7739668</idno>
	</analytic>
	<monogr>
		<title level="m">Visual Languages and Human-Centric Computing (VL/HCC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Active hidden markov models for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Scheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Decomain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wrobel</surname></persName>
		</author>
		<idno type="DOI">10.1007/3-540-44816-031</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Advances in Intelligent Data Analysis (IDA)</title>
		<meeting><address><addrLine>London, UK, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A new metaphor for projection-based visual analysis and data exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Panse</surname></persName>
		</author>
		<idno type="DOI">10.1117/12.697879</idno>
	</analytic>
	<monogr>
		<title level="m">Visualization and Data Analysis</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="64950" to="64950" />
		</imprint>
	</monogr>
	<note>SPIE Proceedings</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Butterfly plots for visual analysis of large point cloud data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zeilfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Worm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSCG</title>
		<meeting><address><addrLine>Plzen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
		<respStmt>
			<orgName>University of West Bohemia</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Techniques for precisionbased visual analysis of projected data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Landesberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bremm</surname></persName>
		</author>
		<idno type="DOI">10.1057/ivs.2010.2</idno>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="193" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Empirical guidance on scatterplot and dimension reduction technique choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.153</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2634" to="2643" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A taxonomy of visual cluster separation factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tatu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2012.03125.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3pt4</biblScope>
			<biblScope unit="page" from="1335" to="1344" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Patent Retrieval: A Multi-Modal Visual Analytics Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Seebacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Janetzko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<idno>doi: 10. 2312/eurova.20161118</idno>
	</analytic>
	<monogr>
		<title level="m">EuroVis Workshop on Visual Analytics (EuroVA)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="13" to="017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">User-based active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
		<idno>doi: 10. 1109/ICDMW.2010</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Data Mining Workshops (ICDMW)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">181</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<idno>1648</idno>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Univ. of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Report</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Closing the loop: Fast, interactive semi-supervised annotation with queries on features and instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1467" to="1478" />
		</imprint>
	</monogr>
	<note>Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">An analysis of active learning strategies for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1070" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Multiple-instance active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1289" to="1296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Query by committee</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Opper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sompolinsky</surname></persName>
		</author>
		<idno type="DOI">10.1145/130385.130417</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 5th Ann. Worksh. on Comput. Learning Theory, COLT &apos;92</title>
		<meeting>of the 5th Ann. Worksh. on Comput. Learning Theory, COLT &apos;92<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="287" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">A mathematical theory of communication. Bell system technical journal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shannon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1948" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Measurement of diversity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Simpson</surname></persName>
		</author>
		<idno type="DOI">:10.1038/163688a0</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="issue">4148</biblScope>
			<biblScope unit="page" from="688" to="688" />
			<date type="published" when="1949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Selecting good views of high-dimensional data using class consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-8659.2009.01467.x</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="831" to="838" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Probing projections: Interaction techniques for interpreting arrangements and errors of dimensionality reductions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stahnke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Drk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thom</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2015.2467717</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics (TVCG)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="629" to="638" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A survey of active learning algorithms for supervised remote sensing image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Copa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kanevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Munoz-Mari</surname></persName>
		</author>
		<idno>doi: 10. 1109/JSTSP.2011.2139193</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Selected Topics in Signal Proc</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="606" to="617" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Visualizing high-dimensional data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Trec feature extraction by active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vendrig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Patras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hartog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Raaijmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Rest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Van Leeuwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Active learning in multimedia annotation and retrieval: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<idno type="DOI">10.1145/1899412.1899414</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A Perception-Driven Approach to Supervised Dimensionality Reduction for Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiaowei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2017.2701829</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Interactive machine learning: letting users build classifiers. Human-Computer Studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ware</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<idno type="DOI">10.1006/ijhc.2001.0499</idno>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="281" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Rapid, Detail-Preserving Image Downscaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Waechter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Amend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guthe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goesele</surname></persName>
		</author>
		<idno type="DOI">10.1145/2980179.2980239</idno>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Sampling strategies for active learning in personal photo retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kozintsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Bouguet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dulong</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICME.2006.262442</idno>
	</analytic>
	<monogr>
		<title level="m">Multimedia and Expo, 2006 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="529" to="532" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
