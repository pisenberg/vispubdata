<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bring it to the Pitch: Combining Video and Movement Data to Enhance Team Sport Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Stein</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Halldor</forename><surname>Janetzko</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Lamprecht</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Breitkreutz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Zimmermann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Goldl√ºcke</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Tobias</forename><surname>Schreck</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gennady</forename><surname>Andrienko</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Michael</forename><surname>Grossniklaus</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
						</author>
						<title level="a" type="main">Bring it to the Pitch: Combining Video and Movement Data to Enhance Team Sport Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2017.2745181</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>visual analytics</term>
					<term>sport analytics</term>
					<term>immersive analytics</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1: Our system integrates analytical visualizations of soccer player movement data extracted from video into the same video, relying on appropriate computer vision techniques. Movement visualization techniques like interaction spaces (left) and free spaces (right) allow to analyze and explore soccer movement data in context of the original video. As our studies conducted with expert soccer analysts show, the combination of video and abstract visualization supports effective contextualized analysis and can foster user trust regarding data and analytical visualization. Abstract-Analysts in professional team sport regularly perform analysis to gain strategic and tactical insights into player and team behavior. Goals of team sport analysis regularly include identification of weaknesses of opposing teams, or assessing performance and improvement potential of a coached team. Current analysis workflows are typically based on the analysis of team videos. Also, analysts can rely on techniques from Information Visualization, to depict e.g., player or ball trajectories. However, video analysis is typically a time-consuming process, where the analyst needs to memorize and annotate scenes. In contrast, visualization typically relies on an abstract data model, often using abstract visual mappings, and is not directly linked to the observed movement context anymore. We propose a visual analytics system that tightly integrates team sport video recordings with abstract visualization of underlying trajectory data. We apply appropriate computer vision techniques to extract trajectory data from video input. Furthermore, we apply advanced trajectory and movement analysis techniques to derive relevant team sport analytic measures for region, event and player analysis in the case of soccer analysis. Our system seamlessly integrates video and visualization modalities, enabling analysts to draw on the advantages of both analysis forms. Several expert studies conducted with team sport analysts indicate the effectiveness of our integrated approach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Over the last years, the interest in analysis of team sport data has grown rapidly in research and practice. Among many team sport disciplines, soccer is one of the most widely practiced and also, commercially relevant kinds of team sports. The analysis of soccer match data has received much attention in the recent years by fields including sports and behavioral science, biomedicine, and others. Computer science-based solutions help to capture soccer data, process and analyze it. Recently, several works introduced visual analysis techniques for soccer data. Soccer is a match of two opposing teams that engage in competitive and cooperative movement patterns among and between teams in space and time. Among the key goals of soccer analysis is to support understanding of patterns in this movement space on the player and team level. Also, the analysis of derived performance measures for players and teams, including predictive analysis, is of high relevance in this domain. In practice, two analysis modalities often occur. First, analysis can be done based on captured movement data, applying techniques from movement analysis. These often are used in combination with abstract movement visualization techniques. Second, in interactive video analysis, video recordings of matches are interactively inspected and annotated by experts, yielding reports and video presentations to coach players and inform coaches. Video analysts are typically used to work with video recordings and not with abstract data representations.</p><p>Several previous works investigated the usage of visually-supported methods in the soccer analysis domain. For example, the Soccer-Stories <ref type="bibr" target="#b35">[37]</ref> system presented several custom-designed information visualization techniques to present and comprehend soccer match data We detect players on the soccer pitch (A) and, simultaneously, generate a panoramic view of the pitch (B). Afterwards, each frame gets projected into the panoramic view to extract correct player positions from a moving camera (C). The extracted player positions then can get projected into a normalized pitch (D). Based on this projection, we realize the integration of visualizations on the pitch for the video (E).</p><p>using abstract visual representations. Other works make use of trajectory visualization, hetamap-based techniques, of movement feature visualization (see Section 2 for details). In our own previous work, we have defined abstract visual representations for soccer match data and evaluated these with soccer analysts by means of interviews and case studies. While per se useful in many cases, we also observed that interpreting results obtained from abstract visual representations in context of the actual game situation required substantial mental effort by analysts. Often, experts wanted to verify observations made in the abstract visualization space in the video space, or even required the video space to interpret patterns in the visualization space. In effect, analysts we worked with wanted to bring analysis results obtained in abstract visualization space back to the pitch, as to paraphrase an expression often used by coaches during soccer practice. We hence identified the need to integrate soccer data visualization with soccer video for enhanced analysis and context provision. We contribute an automatic method that provides effective visual analysis in the domain of team sport analysis by integrating appropriate analytical visualizations within the video context. We address the system aspect, demonstrating the applicability of a computer vision framework enabling Visual Analytics in movement context. We identify and implement an appropriate computer vision technique to extract player positions and detect the relative view-port from standard TV broadcasts, which enables capturing movement data. Furthermore, this techniques enables to map two-dimensional analytical visualizations back to the video recordings in a perspectively correct way. We additionally address a methodological aspect, raising the question of how and which analytics methods from the "2D space" can be embedded in video recordings. We give a first discussion of effects of the combination of abstract visualization and video, providing empirical evidence by domain experts to this end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>We first discuss related work in video analysis and data extraction (Section 2.1) followed by an overview to video analytics (Section 2.2).</p><p>We outline research in the area of sports in general and related to soccer (Section 2.3) and position our approach with the aforementioned works in Section 2.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Object detection and tracking</head><p>Higher-level content analysis, e.g., for player movement, involves detection and tracking of players in the input video streams as well as mapping of the positions into a reference frame. Tracking has been studied for decades as one of the fundamental tasks in computer vision, see e.g. <ref type="bibr" target="#b47">[49]</ref> for a more recent overview. We therefore restrict the following discussion to the methods used in previous work on team sports analysis.</p><p>In position mapping, positions from the video are mapped to a physical reference frame, in our case the soccer pitch. A key approach to this mapping is to define and identify reference points in the video that correspond to known locations on the underlying soccer pitch. For this purpose, Choi et al. <ref type="bibr" target="#b43">[45]</ref> define a pitch model, incorporating known positions like the center circle and center line. To find the corresponding points within a video, lines and ellipses are identified in a given image by Hough-Transformation <ref type="bibr" target="#b11">[13]</ref>. Of these lines and ellipses, four positions are extracted and associated with the positions in the pitch model to estimate a coordinate transformation of the given image into the pitch model. Since it is a plane-to-plane transformation, it can be described by a projective linear map (homography) <ref type="bibr" target="#b14">[16]</ref>. A drawback of this method is, that there always have to be at least four positions associated with the soccer pitch and, most importantly, these positions have to be correct. In contrast to comparing images individually, rebuilding a larger image (e.g. panoramic views) from smaller subimages is a common technique in image vision called stitching. For example, Kim et al. <ref type="bibr" target="#b22">[24]</ref> look for identical lines in subsequent images of the video and map related lines onto each other by a coordinate transformation. This way, a complete view of the soccer pitch is obtained image by image. Brown et al. <ref type="bibr" target="#b5">[7]</ref> introduce an automated process for panorama stitching. The described approach involves the calculation of SIFT-features <ref type="bibr" target="#b29">[31]</ref> within the considered images. A transformation is computed by finding matching features in image pairs. We roughly follow their approach to generate a panoramic view of the soccer pitch seen in the video recording.</p><p>The next step after position mapping is to detect and track objects of interest. In case of team sport video analysis, these are typically the teams' players and the ball. In player detection, advances have been made in the last decades. Liu et al. <ref type="bibr" target="#b27">[29]</ref> recognize players with a socalled boosted cascade of Haar features. This detector is constructed with carefully chosen training data (players in different poses as positive examples, background and pitch parts as negative examples). For the detection of players on a soccer pitch, Hoernig et al. <ref type="bibr" target="#b15">[17]</ref> compute a pitch mask. For that matter, they assume that the soccer pitch is a rectangle. Furthermore, the dominant color of the pitch is defined as green. The potential positions of the players are obtained by subtracting the pitch mask from the processed image. Additionally, the found contours have to meet different predefined features (for example height relations). Perez et al. <ref type="bibr" target="#b34">[36]</ref> follow a probabilistic approach. First, a color histogram model is created, which describes the color distribution of a given player. The detection and tracking of the player is subsequently realized with a particle filter <ref type="bibr" target="#b13">[15]</ref>. Dearden et al. <ref type="bibr" target="#b10">[12]</ref> also introduce a combined approach. In the first step, a mask of the soccer pitch is computed. For this mask, the color histogram is defined and by subtraction the possible player areas obtained. The player areas are subsequently processed with a particle filter. Choi et al. <ref type="bibr" target="#b43">[45]</ref> use a combination of particle filter and matching of player templates. These templates are obtained by analyzing the defined player mask. The tracking of players with several stationary cameras is examined by Kang et al. <ref type="bibr" target="#b20">[22]</ref>. The modeling of players is achieved by a combination of color distribution and movement models. The tracking itself is performed by maximizing a multivariate distribution probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visualization for Video Analytics</head><p>Video analysis attracted interest of visualization researches in early 2000s when millions of CCTV cameras have been installed worldwide. The human operator is not able to watch the produced footage neither in real time nor afterwards. Respectively, it was necessary to develop methods for extracting features from video, track moving objects, identify abnormal situations, and present outputs in easy-to-comprehend summarized form. Paper <ref type="bibr" target="#b9">[11]</ref> proposed to visualize the dynamics of the detected features in so-called volume scene graphs. More recently, a series of papers from D. Weiskopf's group systematically considered challenges of video analysis, proposed a model for video visual analytics, and implemented it in a system for analysis of VAST Challenge 2009 data set <ref type="bibr" target="#b17">[19]</ref>. Later work <ref type="bibr" target="#b16">[18]</ref> especially addressed reconstruction of moving objects trajectories from video, clustering trajectories by similar paths and velocities, and representation of features dynamics for the clusters in a compact form. By projecting the extracted features to parallel time lines, this work provided a convenient tool for detection of unusual situations and browsing/querying the lengthy content of video.</p><p>Paper <ref type="bibr" target="#b25">[27]</ref> describes application of interactive video analysis to sport. After extracting trajectories of players from a video of a rugby game, the proposed system supports queries based on sketches. Based on a user's sketch of a desired trajectory, the system extracts candidate fragments and characterizes the extracted trajectories in respect to multiple trajectory attributes such as curvature, tortuosity etc. The extracted features of the candidate episodes are presented on a parallel coordinates plot. Multiple representations engage users in the process of exploring the video and corresponding trajectory patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sports Analysis</head><p>The application of visual analysis methods enabling an in-depth data analysis was already introduced in many sports. Polk et al. <ref type="bibr" target="#b39">[41]</ref> describe an analysis approach for tennis, based on meta-data as result, length of rallies, and service. Their visual method includes a comprehensive overview of the overall game and highlights strength and weaknesses of players based on pure statistics. The shot behavior of different teams in ice hockey is examined by Pileggi et al. <ref type="bibr" target="#b37">[39]</ref>. They focus on a visual representation, realized by a circular heatmap around the goal. The shade of the color describes for different distances the possibility of execution. Especially in team sports, the spatial area where the match takes place, is an important concept. For this reason, there exist several models to measure the utilization of the area, for example with voronoi cells <ref type="bibr" target="#b28">[30]</ref>.</p><p>In soccer, several visual data analysis methods have been proposed. Legg et al. <ref type="bibr" target="#b26">[28]</ref> try to capture and visualize the course of a match in an abstract and summarizing manner. They employ a timeline, depicting important events like shot on goal, as well as additional information and indicators for the outcome of different events. A complete system for the analysis of soccer matches is described by Perin et al. <ref type="bibr" target="#b35">[37]</ref>. Their system provides visualizations for many aspects of the match, like a generalized view of the course of the match or a clustered view of performed passes. Different phases of a match can also be compared in small-multiple view. Chung et al. <ref type="bibr" target="#b7">[9]</ref> describe an approach for the multivariate sorting of event data. The sorting is aimed for the efficient classification of match recordings for subsequent analysis and evaluation of the team performance. An approach for the interactive determination and analysis of interesting events during a soccer match is proposed by Janetzko et al. <ref type="bibr" target="#b42">[44]</ref> and extended with an application-specific visualization by Stein et al. <ref type="bibr" target="#b44">[46]</ref>. Horton et al. <ref type="bibr" target="#b18">[20]</ref> classify performed passes during a soccer match. Therefore, the quality of passes by means of distance, shot strength, and pressuring of the receiving player is evaluated. A general visual analysis approach for pressure in soccer matches has been introduced by Andrienko et al. <ref type="bibr" target="#b3">[5]</ref>. Perl et al. <ref type="bibr" target="#b36">[38]</ref> propose the analysis of tactical performance, based on a combination of pattern recognition with neural networks and analysis of ball possession.</p><p>Sport media broadcasters are integrating additional graphical cues in video and on the pitch for quite some time supported by companies such as Vizrt <ref type="bibr" target="#b1">[3]</ref> or SAP <ref type="bibr" target="#b0">[1]</ref>. Vizrt as one of the market leaders in this field, offers a product (Vizrt Libero) for virtual sports enhancements. Journalists and television stations use Vizrt Libero, for example, during television broadcasts to explain interesting match situations. They enable manually drawings of simple visual elements onto the pitch such as arrows or colored rectangles. Furthermore, Vizrt Libero allows the user to track specific players for small time frames. However, the analysis possibilities of the tracked players is limited. A tracked back four formation, for example, can be visually connected or a simple heat map can be calculated and displayed. Our system allows the user to automatically visualize complex advanced visualizations transferred from two-dimensional abstractions. Specifically, our system recognizes the positions of all visible players in a given video stream, and we use this information to compute various analytical measures which in turn can be visualized in the progressing video.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Positioning of our Work</head><p>We contribute a system for visual analysis of group movement in video data combining information visualization with video recordings. We rely on techniques for position mapping and object recognizing in video, and apply them to soccer recordings. We also rely on techniques for movement analysis enabling insights to the observed player movement patterns. Existing work in video visualization often focuses on summative views. In visual movement analysis <ref type="bibr" target="#b2">[4]</ref>, state-of-the-art techniques typically use visual abstractions from the real world. To the best of our knowledge, our system is the first to allow visual analysis of soccer matches relying on appropriately defined movement visualization techniques mapped with high precision into the match video. Hence, our approach provides analysis considering both visual abstraction of movement features and match video context, supporting effective use of both modalities in an integrated system.</p><p>In a sense, our approach also relates to the ideas of Immersive and Augmented Analytics which has recently again received interest by the visualization and analytics communities, e.g., as seen from the session on Immersive Analytics at IEEE InfoVis 2016 and the IEEE VR 2016 Workshop on Immersive Analytics. Our work adds to this direction specifically for team sports analysis, by bringing together abstract analytical visualization with media from the real world. <ref type="figure">Fig. 3</ref>: The chosen points for the transformation of the panoramic (left) into the normalized (right) view must allow referencing distances in both directions of the main axes. Afterwards, a calculated homography H n enables the transformation of panoramic view into normalized view and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VIDEO MOVEMENT TRACKING AND VISUALIZATION INTE-GRATION</head><p>The vital prerequisite for inspecting and analyzing team sport matches is movement data of players and the ball. A variety of companies (STATS, Opta, etc.) offer services acquiring movement, event, and statistical data based on their operating of capturing systems. However, many team sport clubs cannot take advantage from these services, for example, due to a lack of financial resources or the overly complex process of technical implementation. Instead of professional systems, especially clubs from lower or youth leagues in soccer as well as clubs from other team sports have one static video camera recording entire matches. Representatives from these clubs have shown an increasing interest in approaches on how to analyze their performance based on this video data. Consequently, we design our proposed system following two key requirements: the system should be capable of (a) extracting data from standard video recordings as well as (b) allow the user to overlay visualizations on the video material. Both should be easy to do for the non expert user, with only low-level technical requirements. The input to our system is the video stream of one camera, which zooms and rotates to capture as many players as possible.</p><p>This form of recording resembles common public television recordings of team sport matches, with one main camera positioned on the side of the pitch for a tactical overview. To illustrate our approach in this paper, accordingly, we use an example television match recording from the German Bundesliga being broadcasted on the Sky Sport TV channel operated by Sky UK Telecommunications [2]. All displayed figures are extracted from this match and enhanced by our proposed system. We align the frames of the video recordings with a normalized reference pitch to associate the positions in the video and on the pitch. In particular, our system is not limited to only process data from video to normalized pitch. Instead, we can also project visualizations rendered on the normalized pitch back to the original video, which allows for further analyses by directly watching the enhanced video stream. Currently, the ball detection is not done automatically but by manual annotation of events as passes, shots, etc. -similar to the ball acquisition by professional video tracking companies.</p><p>We implement our Visual Analytics system in Java, with a subset of time-critical computer vision methods in nVidia CUDA <ref type="bibr" target="#b33">[35]</ref> running on GPUs. An overview the proposed system is given in the subsequent sections. See <ref type="figure">Figure 2</ref> for an overview of the workflow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Player Detection</head><p>In order to calculate exact player positions on the pitch <ref type="figure">(Figure 2 (A)</ref>) it is necessary to segment them from the background in each frame, i.e. detect all of the pixels where a player is visible. Unfortunately, we cannot define a frame-independent player size: first, the recording camera can zoom and thus focal length can be different in different frames, second, the camera is located at the side of the pitch, and thus players on the opposite side of the pitch appear smaller. Other challenging factors stem from body pose and proportions, e.g., players' shape differs based on their activities, or from adverse imaging conditions, e.g. caused by illumination changes, especially for matches with floodlight or intense rain phases. The detection should ideally also work in real-time.</p><p>Thus, we turned to low-level appearance models which require only minimal characteristics about the searched objects to be known. In particular, we use methods based on edge detection and color based contour analysis, where we need to know dominant colors of the wanted object. During our design process, we applied a variety of image vision methods covering player classifiers <ref type="bibr" target="#b31">[33]</ref>, canny edge detection <ref type="bibr" target="#b6">[8]</ref>, contour-based player detection through pitch subtraction <ref type="bibr" target="#b15">[17]</ref> as well as player detection through contour analysis by color histograms <ref type="bibr" target="#b34">[36]</ref>. After evaluating the applied techniques, we found we achieve the best results by performing the player contour analysis through color histograms. A main reason is that this way, markings on the pitch do not influence player detection.</p><p>Our player detection method works in three steps. First, we create color histograms based of manually marked areas that are unique for players on the pitch. In our case, for example, player and team jerseys. Afterwards, we determine for each pixel in the image, whether the color of the pixel is contained in the color histogram with sufficient probability (i.e. a sufficient number of pixels in the marked area matches the color). To conclude exact player positions, we finally calculate the centroids of each detected area. Considering human anatomy, we use average human proportions to calculate the positions of feet, head and the corpus of the body. To obtain the extended bounding boxes enclosing the entire player, we enlarge the initially detected area by adding proportions dependent on empirically defined factors to all directions. Significantly smaller identified areas below a given threshold, for example player socks, are removed automatically. We illustrate our player detection in <ref type="figure">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Static Camera Generation</head><p>Previous systems typically use several static cameras, mounted at specific positions with certain angles and focal lengths, being calibrated for the sole purpose of making the player detection for the computer as efficient and effective as possible <ref type="bibr" target="#b32">[34]</ref>. Instead, we propose to use one single, stationary camera, whose motion only consist of rotations and occasional zooms. It is well known <ref type="bibr" target="#b14">[16]</ref> that under the additional assumption of pinhole projection, the video frames are then related to each other by a simple projective linear transformation called a homography. The advantage is that for the domain expert and final user, one single camera is set up easily without the need of longer preparations, special configurations, and calibrations.</p><p>However, in order to have comparable results as from several cameras and relate the different frames to each other, we automatically transform the images into a single, panoramic view of the pitch <ref type="figure">(Fig-Fig. 4</ref>: Illustration of our player detection method using jersey color. Extending the centroid area of the jersey, we obtain a player enclosing rectangle. The factors s h , s f and s a are empirically defined. ure 2 (B)). Our proposed approach follows Lowe and Brown <ref type="bibr" target="#b5">[7]</ref> who take a set of overlapping images as input. The set of input images is aligned automatically by iterating over pairs of consecutive frames, extracting and matching SIFT features <ref type="bibr" target="#b29">[31]</ref> and estimating the homography between first and subsequent frame. A homography is a 3 √ó 3 transformation matrix acting on projective image coordinates, which can be estimated by a least-squares approach embedded in RANSAC to get rid of outliers <ref type="bibr" target="#b14">[16]</ref>.</p><p>From the aligned frames, we select a subset of frames which spans the whole range of motion of the video camera and has sufficient overlap between frames to generate the full panoramic view. Usually, the first 2 minutes of a match are sufficient to generate a panorama reflecting (almost) the complete pitch. From the homographies computed initially, we can compute the alignment of every individual frame within the panoramic view, see <ref type="figure" target="#fig_1">Figure 5</ref> for an example transformation. However, for longer videos, we generate the panorama only from the beginning of the sequence, and align subsequent frames by estimating a homography directly using their and the panorama's SIFT features.</p><p>In a final pass, we generate a clean background panorama and remove foreground objects like e.g. the players. For this, we compute for every pixel in the panoramic view the median color over all frames of the selected subset. As the players are constantly moving, this should be a good approximation to the actual background color. A Graph Cut method is then used to hide objects which are only partially visible <ref type="bibr" target="#b23">[25]</ref>. In summary, we now have a panoramic view of the background as a common reference frame, as well as for each video frame, a homography H p which describes the coordinate transformation into the panoramic view. See <ref type="figure">Figure 2</ref> (C) for an illustration.</p><p>To obtain a normalized representation of the pitch, we map the panoramic view onto a user-supplied image -typically a standardized visualization of the pitch, see <ref type="figure">Figure 3</ref>. To define the transformation, the user selects at least four corresponding points in panoramic and normalized image manually. The four correspondences then determine a homography from the panoramic view to the reference image as before <ref type="bibr" target="#b14">[16]</ref>. Note that due to the lack of radial distortion calibration, this is currently only a rough approximation, pending improvements in future work. Furthermore, it is a plane-to-plane homography, valid only for points on the main pitch plane. The transformation from panorama to normalized pitch is denoted H n in the remainder of the paper. See <ref type="figure">Figure 2</ref> (D) for an illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Projection and Visualization Integration</head><p>From section 3.1, we have for each video frame the detections of the players. By sequential application of the homography H p from frame to panorama, as well as the homography H n from panorama to normalized frame, we can thus calculate player position coordinates on the normalized pitch, see <ref type="figure">Figure 2</ref> (D). All positions not corresponding to a position within the normalized pitch are discarded as likely misdetections.</p><p>To obtain player tracks and uniquely identify players, the detected player positions are registered by a simple location-based method, which assigns each position to the closest player in the previous frame who could realistically reach the new position within the timespan between frames. A new player is initialized for all remaining positions that could not be assigned to any existing player. This happens, for example, if the input frame did not contain all players.</p><p>However, incorrectly detected player positions can lead to an initialization of a new player as well. These misdetections typically only happen over a span of few frames, so we automatically remove short tracks with only very few positions or which do not generate new positions over a longer period. Afterwards, automatic methods to further clean the data are applied, e.g., if players overlap each other we interpolate their positions by taking their current speed into account. Another problem is that the homography H p , which maps a video frame into the panoramic view is not inevitably the optimal solution, as we compute H p with RANSAC for a fixed number of iterations. This may result in situations where the transformed player positions are differing from the actual ones. To counteract this problem, we validate our data by applying a moving average filter <ref type="bibr" target="#b40">[42]</ref>. In addition to the automatic systems, the user will also be given the opportunity to manually improve data gathering by interacting with the system in a variety of ways. We will evaluate the accuraccy of our location detection method in Section 5.</p><p>Our system described above has the advantage that we can perform all data analysis on the normalized reference pitch, as shown in the next section. Due to the simple homographies with respect to the video frames, we can easily embed any information visualizations targeted to the reference pitch within the original camera images, see <ref type="figure">Figure 2</ref> (E). To further emphasize the impression that resulting visualizations are drawn directly on the pitch and players are running on top of them, we remove all pixels that are related to the pitch and pitch markings from detected players regions, i.e. the red bounding boxes illustrated in <ref type="figure">Figure 4</ref>, by background subtraction. Afterwards, the cleaned player regions are drawn on top of the visualizations. In Section 4, we show diverse examples illustrating the many possibilities for analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VISUAL ANALYSIS OF SOCCER VIDEO</head><p>In the previous section, we described our system transforming the video space to a normalized pitch space, tracking objects, and mapping visualizations back into the video space. Although our system proposes a combined view of video and visualization, it is possible to show only video recordings or abstract visualization techniques depending on the respective analyst's needs. We identified in our expert discussions and previous studies three main analysis areas in the soccer domain. These three areas cover some core aspects of soccer analysis, namely, analyses based on regions, events, and players. For the demonstration of this three types of technique, we make use of previously proposed and established visualizations to showcase how existing analytical solutions can benefit from our system. Additionally, we propose new visualizations for each kind of technique. We describe the techniques in the following. Note that while we here focus on soccer, our framework can easily be extended to other invasive team ball games, like handball or basketball. Such adoptions would require a slight adaption of the tracking techniques, implementation of appropriate analytics methods, and corresponding visualizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Region-based Analysis</head><p>Spatial analyses in soccer mostly deal with the notion of control of regions. For example, one analysis task might be to represent which team or player was dominating which part of the pitch under specific conditions. Two recently proposed techniques include so-called interaction spaces and free spaces <ref type="bibr" target="#b45">[47]</ref>. Interaction spaces visualize the surrounding area that each player directly aims to control. They can be computed as the area that can be reached by a player, modeled as a function of velocity and heading <ref type="bibr" target="#b45">[47]</ref>. Intersecting interaction spaces between players of opposing teams are identified as duel areas. We transform interaction spaces using our system from previously pure two-dimensional visualization back to the video recording. An example of interaction spaces using our proposed system is presented in <ref type="figure">Figure 1</ref> (left). Free spaces, in contrast to interaction spaces, represent the region that can be reached by a player before any opposing players. In our approach, these regions are calculated by segmenting the pitch into grid cells assigning each cell to the player with the highest probability of arriving there first with respect to distance, speed, and heading. Resulting free spaces are assessed by their respective size, the number of opposing players, and the distance to the opposing goal. Free spaces that are most promising (exceed a specific size, small number of opposing players, close to goal) are visualized by highlighting the respective region on an abstracted soccer pitch. With the use of our proposed system, we can now visualize free spaces on top of the original video recording. An example for the resulting free space visualization is shown in the right of <ref type="figure">Figure 1</ref>.</p><p>In addition to the previously introduced visualizations, we also propose a new visualization to illustrate dominant regions of a team. These regions represent areas where one team is more in control than the opposing team. We calculate dominant regions by taking into account how many players of each team can reach a dynamic region of the pitch first. We segment the pitch into regular grid cells and calculate for each cell the order in which players can reach it. To ensure that we only identify dominant regions that are present over a longer period, we use a sliding window approach and calculate the moving average over the results. Using the marching squares-algorithm <ref type="bibr" target="#b30">[32]</ref>, we detect the contours of the resulting dominant areas that can be reached first by at least three players of the same team. The resulting dominant regions are visualized using a dark red to dark blue bipolar colormap (with transparent colors for tie areas) representing both teams. An example for the dominant region visualization is depicted in <ref type="figure" target="#fig_2">Figure 6</ref> (a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Event-based Analysis</head><p>Events in team sports can be defined as match-relevant actions which occur during playtime <ref type="bibr" target="#b46">[48]</ref>. Most events are based on the ball, e.g., like shot on goal, cross or pass. Event data is used by analysts to identify statistical patterns during a match, e.g., which passing preferences a player might have or whether a player prefers playing short passes instead of long passes. We integrated established and new approaches for event-based analysis into our system.</p><p>Ball passing in a game situation is the result of a complex decisionmaking process influenced by pressure of the opposing team and the relative positions of each player. The passing behavior is usually analyzed to reveal typical tactics and to improve overall game play. Players need to take many factors into account when deciding for low-risk or more insecure passes to gain space. Recently, an analysis technique calculating pass alternatives for a player in a given game situation was introduced <ref type="bibr" target="#b45">[47]</ref>. The overall goal was not to assess the quality of a pass but rather determine the risk involved for various passing alternatives. Resulting possible pass alternatives were visualized with arrows pointing towards potential receiving players on an abstract soccer pitch. Several criteria for the automatic assessment of passes were introduced reflecting the relative positions, distance, and direction. So far, arrows pointing towards potential receiving players on an abstract pitch are employed to visualize possible pass alternatives. While integrating the pass visualization into the video, we extended the original two-dimensional version <ref type="bibr" target="#b45">[47]</ref> by additionally highlighting players, for example, with a floating colored diamond-shape over their heads. In <ref type="figure" target="#fig_3">Figure 7</ref> (a), we show the previous two-dimensional visualization on an abstract rendered pitch in comparison to our enhanced version visualized on the pitch in <ref type="figure" target="#fig_3">Figure 7 (b)</ref>. Furthermore, analysts are also interested in the characteristics of player passing behavior. Understanding whether a player prefers to play short instead of long passes can provide tactical advantages for match preparation. To get an intuition about the passing preferences of a player, we developed a new visualization for player centered pass distances. <ref type="figure" target="#fig_2">Figure 6</ref> (b) illustrates our approach. Circular rings drawn around each player visualize the aggregated normalized pass distance of the respective player. Color saturation is used to indicate whether a player usually prefers short or long distance passes. We normalize the aggregated pass number globally for all players and distance bins. Concentric rings close to the player represent short passes. This visualization allows identifying players with many passes and reveals their usual passing behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Player-based Analysis</head><p>Besides regions and passes, sport analysts need to focus on individual players and their performance. Analysis typically either concentrates on statistical performance measures (e.g., distance covered by a specific players or failed passes) or actual player movement in context as key factor to reveal and predict tactical patterns. To support the assessment whether players move or not like expected in a given situation, we enable the user of our system to display the previous and next k seconds as live trajectory views in the video. We show the past trajectory different to the future trajectory by using transparency. An example can be seen in <ref type="figure" target="#fig_2">Figure 6 (c)</ref>.</p><p>When analyzing team sport it is, however, important to focus on more than the movement of a single entity. The collective movement -here expressed by the two opposing teams -reveals more insights about strategies and tactics. Players moving similarly or reacting on each other is important to observe as this might be an indicator of tactical patterns. Following the idea of Laube et al. <ref type="bibr" target="#b24">[26]</ref> and as an exemplary first step towards this challenging problem, we implemented a method to visualize players reacting on each other. We define a reaction as imitated behavior, for example, if one player is strongly accelerating in one direction and other players start accelerating in the same direction shortly afterwards. Using our proposed system, we increase the salience of players acting coherently. For example, we are able to give players that are to be grouped together the same jersey color. Having the same jersey color, however, may result in losing distinct teams. Our design alternative is to emphasize corresponding groups of players with distinctly colored halos instead. An example can be seen in <ref type="figure" target="#fig_2">Figure 6 (d)</ref> where two players react on the ball possessing player and accelerate very fast to position themselves in a good spot for a potential shot on goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION</head><p>We quantitatively assessed the quality (precision) of the tracked data using our system in comparison with data from commercial systems. We provide details on the performance of homography and panoramic view calculations as introduced in Section 3. Afterwards, we discuss our proposed combination of video and abstract visualization supported by insights from several expert studies. We additionally report expert feedback on the created example visualizations from Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Tracking Assessment</head><p>As our approach imposes fewer restrictions and no calibration needs to the data acquisition process than professional capturing systems, our available data quality might be lower when compared to well-calibrated, professional systems. Consequently, we assessed the quality of our extracted data and compared our generated data with data acquired by a professional data provider with a calibrated camera system. To this end, we analyzed a match from the UEFA Champions League between FC Bayern M√ºnchen and Manchester City FC where we have both professionally generated position data as well as data extracted with our method from a high definition (720p) recording. To be able to compare the resulting positioning data, we synchronized the video recording (25 frames per second) and the professionally generated position data (10 positions per second). The professional system uses a set of static cameras around the pitch and proprietary software to extract the player movement. As the calibration would need manpower, these camera systems are usually permanently installed in stadiums of prime teams. We observed a maximal distance between our retrieved position and the professional data of four meters. Nevertheless, the average deviation was less than two meters with a standard deviation of roughly half a meter. We consider this as a positive result as the accuracy of professional data is not publicly known. Furthermore, the definition of a point-based location for a two-legged running person is not clear per se already causing positional differences. From a subjective perspective, our extracted locations are very close to the players in the video recording and reflect the movement very well and there are no obviously and distracting systematic errors.</p><p>One of our final goals is to analyze the acquired movement data directly in the half-time break or after the match. Consequently, we addressed the efficiency of our approach. Furthermore, it is important to compute the reverse homographies near real-time as any changes in the Visual Analytics part should be directly visible in the recordings. Therefore, the introduced homography and panoramic view calculations were implemented highly parallelized on the GPU. The parallel nature of the feature extraction and matching process is well suited for modern GPU architectures and allows an implementation which is several times faster than an equally powerful CPU based method. To investigate the resulting efficiency of our implemented methods, we calculated panoramic views and homographies for several matches on a test system (Intel Core i7-6700, 16GB RAM, NVIDIA GeForce GTX 1070). The efficiency of our automatic panoramic view generation depends on the video resolution, complexity of camera movement and the amount of moving objects in the scene. We found that we are able to generate a panoramic view in an average of 40 to 50 seconds. The efficiency of a homography calculation depends on the panorama size, input resolution and the amount of visual detail. We were able to calculate a homography in 50 to 60 milliseconds. Estimating that a match lasts approximately 95 minutes (overtime included), we need around 140 to 170 minutes for the homography calculation. Mapping the abstract visualization to the video recordings and using the inverse homography takes 4 to 10 milliseconds being real time for interactive visualization purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Insights from Expert Studies</head><p>Eventually, we want to find out which image an expert or analyst is going to interpret better and trust more -a more abstract visualization or a visualization added on top of the 'real' world. Therefore, we invited two experts to test the usefulness of our system. One expert has been an active soccer player for 25 years and has been working as a coach for 11 years. Until recently, he was working for the German soccer first league club FC Bayern M√ºnchen as a certified coach in the youth sector. A certified coach needs to be experienced in the theory and practice of video analysis. Because of his experiences in video analysis, we consider his feedback as highly relevant for the evaluation of our system. The other expert has been an active soccer player and coach for more than 30 years. Both experts have in common that they need ways to analyze matches of their teams as well as possibilities to communicate findings and insights to the players of their team. Hence, we consider both experts as well-suited candidates to discuss our approach.</p><p>In several expert studies, we separately investigated the concept of our system as well as the example analyses with each expert. At the beginning of a study the expert was explained the system and the interaction possibilities, Afterwards, the various analysis methods and their intentions were introduced. In the following, each expert could openly navigate through the system and try out all available features and visualizations. Besides the interaction with the system, we performed open discussion rounds which we used to ask related questions. Furthermore, we encouraged the experts to express ad hoc comments (the thinking aloud method <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b12">14]</ref>). Expert interactions with the system were recorded for subsequent analysis. During the studies, we took notes of comments and recorded our observations. We were, additionally, highly interested in determining whether a video integrated visualization increases the experts' trust. Eventually, we asked about suggestions for improvement. The results of our expert studies are as follows.</p><p>The experts unanimously appreciated the possibility to perform the analysis directly in the video. Both experts consider embedded analysis tools and visualizations in video recordings as the natural (also: "perfect") procedure for in-depth analysis tasks in soccer. One of the reasons the experts mentioned is that the analysis in the video with moving real players is perceived more "natural" as in a generated view. This makes it easier for analysts to contextualize their findings from analytical visualizations. Consequently, the experts argued that their trust in the analysis strongly increases. To this end, they feel that our approach is already very advanced in terms of application in practice.</p><p>The analysis of free spaces in video recordings is seen very important by the experts. Free spaces help to effectively identify offensive options for the team that is in possession of the ball. Visualization and visibility of free spaces are seen likewise positive. The experts, however, found the high refresh rate of free spaces partially irritating. Their high update rate (each video frame) can result in situations where small changes in the resulting free spaces are causing a perceived 'flickering' in the video visualization. A possible solution beside the limitation to, e.g., ten updates per second could be to define core areas of free spaces and cut the partially rapid changing margins. Another straightforward option is to smooth the visual transitions over time. The transformation of interaction spaces to video recordings is seen positive, too. The experts consider interaction spaces in video recordings as additionally helpful to highlight player formations. Furthermore, our experts state that interaction spaces support the perception of players being far away from the camera.</p><p>The domain experts approve our approach for the calculation of dominant regions. They consider the nuances in our visualization of dominant regions representing the amount of players that have control over a specific area as a gain. Pass distances were seen positive as well. The experts had the hypothesis that such a visualization could in future be used for detecting player roles. Players might, for example, have been formally described as defenders but their playing style might be not known. Following this hypothesis, the experts were interested in future possibilities of classifying player behaviors and resulting improvements, for example, for the scouting process. Analyzing player behavior with our complimentary visualization of player movement trajectories in past and future was interesting for the invited experts when analyzing tackles or individual tactical behavior (e.g., offside trap). The experts mentioned that they would appreciate if players that are noticeable moving into different directions than other players get visually highlighted. Eventually, the experts approved our visualization of player reactions as beneficial information when analyzing group movement. According to our invited experts, players get trained to perform specific movement behavior, for example, to pull apart the defense lines of the opposing team and to open new free spaces. Our visualization, therefore, enables the experts to "make the invisible visible" (quoting one expert).</p><p>Additionally, we observed that the experts came up with new ideas inspecting integrated visualizations in combination with the real movement on the pitch. According to the experts, they became more aware of a visualization's limitations and possibilities for improvement in the future. As, for example, soccer players were not represented by moving dots on an abstract pitch anymore but with the real persons, the experts noticed that the body pose is currently not always reflected correctly in the calculation of interaction spaces. If a player is running forwards or backwards, the resulting interaction spaces are identical. This exemplary problem could not attract attention outside of the video visualization as no data about the body poses are collected. To this end, novel methods <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b38">40]</ref> from the field of human pose estimation could be used to gather data about body poses and take these into account, e.g., while calculating interaction spaces. Another idea the experts had was to extend the visualizations with respect to a players viewing direction. The viewing direction could, for example, be used to determine whether single players are able to perceive particular free spaces. Free spaces that can not be detected could be removed from the calculation. We believe it is an important and interesting finding of our evaluation to see experts being inspired by the analysis transformed back to the observed real world behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">IMPLICATIONS</head><p>Our work addresses two main aspects: a system aspect integrating computer vision methods with interactive visualization for video movement analysis. The second aspect involves questions of usability and analytical effectiveness prompted by the integration of analytical visualizations with the underlying video. We will outline and describe the implications for future work in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">System implications</head><p>As opposed to professional stadium-based video-based tracking systems, we are relying with non-calibrated single-sensor recordings of arbitrary focal lengths and lens systems. Consequently, our data acquisition misses movement players being not visible in the recording, e.g., goal keepers usually will be only visible if the ball is nearby. Another issue with single-camera tracking is that jumps of players lead to inaccuracies. We plan to improve the player detection by more sophisticated and novel methods tackling for example the radial distortion by camera lenses (visible in the right <ref type="figure">Figure 1)</ref>. A first starting point in this direction is the technique introduced by Kim et al. <ref type="bibr" target="#b21">[23]</ref> detecting straight lines over the video frames. Furthermore, we plan to extend the computer vision processing, such as to retrieve additional features like viewing direction, body postures, or even the facial expression like confidence or surprise, which may be valuable features for analysis and able to introduce more semantics to the analysis beyond spatiotemporal properties. Additionally, our next steps involve automatic ball detection and, consequently, automatically deriving events (e.g., passes, dribbling, etc.) based on ball movement.</p><p>Another future direction is the real-time analysis of soccer games with a live stream and live processing of the video recordings. Beside hardware requirements for real-time processing, the challenges are the proper presentations and suitable analysis methods for first ad-hoc explorative analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Integration implications</head><p>Our approach offers new opportunities not yet available in professional tracking systems. First of all, the combination of Visual Analytics methods with the raw video material is a unique possibility to enhance the usability and acceptance for domain experts. The combination of video and visualization bridges the gap between computer and human domain experts being crucial for Visual Analytics. We therefore believe that the inverse transformation from the abstract data model to the real world enables a more insightful and effective analysis. Experts can identify and reveal uncertainties in the analysis process more easy by relating their knowledge to the visualized analysis results. Furthermore, as we experienced in our expert studies that the experts come up with their own suggestions for visualizations, the combination of video and abstract visualization seem to be a promising communication medium when designing Visual Analytics systems.</p><p>To the best of our knowledge, any two-dimensional visualization that has been designed for the use on an abstract pitch can be used and transferred with our system. However, some additional preparations might be beneficial for visualizations over time, for example from Sacha et al. <ref type="bibr" target="#b41">[43]</ref>, such as presenting aggregated trajectories on a pitch without players. We will test this in our future work.</p><p>By merging the raw recording with two-dimensional visualizations, a potential problems may be overplotting, contrast effects, or distraction caused by non-match visual information in the video. Furthermore, the perspective of video recording at hand might not match the most interesting area. In our used recordings the upper side of the pitch is always smaller as it is further away, leading to less image space for the visualization in this area. Hence, we offer both the undistorted (plain two-dimensional) visual result representation and the real-world movement enriched by distorted visualizations. Detailed experiments should be done to assess which analysis tasks are more effectively done in either the raw video, in an abstract analytical visualization, or in the video with integrated visualization. Eventually, from such studies, an adaptive approach could be designed that chooses the most appropriate view based on task, user and situation in the match video.</p><p>We point out that of course other forms of integration of video and visualization are possible. For example, side-by-side approaches make use of explicit or implicit links, e.g., based on arcs or color-coding. One may exemplary investigate how approaches like VisLinks <ref type="bibr" target="#b8">[10]</ref> could be adapted to our case. Finally, in this work we have not specifically addressed user operations regarding interaction with the display. Future work may include using, e.g., sketch-based interfaces to search directly in the video recordings for events or scenes of interest. This could be an effective way to specify the context for a search, e.g., player formations or neighboring players directly from the video.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We presented a system for visual analysis of team sport data integrating video with analytical trajectory visualizations. Based on single camera video recordings of soccer matches, we derive and analyze movement data as well as transform the resulting analytical visualizations back to the original video. The integrated visualizations allow to include context information from the video in the analytical visualization and can bridge inherent uncertainties regarding pure visualization approaches. Our proposed workflow enables domain experts to investigate the data in their desired and needed way. Analysts can decide for video recordings with and without visualizations as well as more abstract visualizations on a two-dimensional pitch. The usefulness of our approach is shown by expert studies with real soccer domain experts intrigued by the potential analysis capabilities. Interesting future work besides technical challenges on the computer vision side include an indepth analysis of advantages and disadvantages of video, visualization as well as integrated video and visualization cases. Eventually, systems may be designed that can adaptively choose the best representation depending on task and data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 Fig. 2 :</head><label>12</label><figDesc>Workflow of our system. A simple (TV/video) recording serves as input.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 :</head><label>5</label><figDesc>Before homography (a) and after homography (b) calculation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 :</head><label>6</label><figDesc>The main Visual Analytics techniques in our approach are based on players, events and regions. When analyzing a player ((c) &amp; (d)), analysts want to detect movement patterns while event analysis (b) aims to, e.g, describe passing preferences. Region analysis (a) tries to segment the pitch into semantically meaningful units.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 :</head><label>7</label><figDesc>Pass Options were visualized so far on an abstract pitch (a)<ref type="bibr" target="#b45">[47]</ref>. Our proposed video visualization (b) allows us to add additional highlighting features such as a floating colored diamond-shape above the player heads in (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>‚Ä¢ Manuel Stein, Andreas Lamprecht, Thorsten Breitkreutz, Philipp Zimmermann, Bastian Goldl√ºcke, Michael Grossniklaus and Daniel A. Keim are with University of Konstanz. E-mail: forename.lastname@uni-konstanz.de. ‚Ä¢ Halldor Janetzko is with University of Z√ºrich. E-mail: Halldor.Janetzko@geo.uzh.ch. ‚Ä¢ Tobias Schreck is with Graz University of Technology. E-mail: Tobias.Schreck@cgv.tugraz.at.</figDesc><table /><note>‚Ä¢ Gennady Andrienko is with Fraunhofer IAIS, Germany and City University London, UK. E-Mail: Gennady.Andrienko@iais.fraunhofer.de.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the ERC Starting Grant "Light Field Imaging and Analysis" and the SFB Transregio 161 "Quantitative Methods for Visual Computing".</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<ptr target="https://www.sap.com/products/sports-one" />
		<title level="m">Sap sports one</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<ptr target="http://www.vizrt.com/.(Accessedon" />
		<title level="m">Vizrt</title>
		<imprint>
			<date type="published" when="2017-06-21" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Visual Analytics of Movement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wrobel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-37583-53</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visual analysis of pressure in football</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Budziak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dykes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Landesberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Thinking aloud: Reconciling theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ramey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on professional communication</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="261" to="278" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic panoramic image stitching using invariant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A computational approach to edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="698" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual analytics for multivariate sorting of sport event data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Parry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Laramee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Sports Data Visualization</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vislink: Revealing relationships amongst visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carpendale</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2007.705219</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conf. on Information Visualization (InfoVis))</title>
		<meeting>of the IEEE Conf. on Information Visualization (InfoVis))</meeting>
		<imprint>
			<date type="published" when="2007-12" />
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Video visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/VISUAL.2003.12504013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th IEEE Visualization 2003 (VIS&apos;03), VIS &apos;03</title>
		<meeting>the 14th IEEE Visualization 2003 (VIS&apos;03), VIS &apos;03<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">54</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tracking football player movement from a single moving camera using particle filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dearden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Demiris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grau</surname></persName>
		</author>
		<idno type="DOI">10.1049/cp:200619683</idno>
	</analytic>
	<monogr>
		<title level="j">IET</title>
		<imprint>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Use of the hough transformation to detect lines and curves in pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="15" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Protocol analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Ericsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>MIT press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Beyond the kalman filter: Particle filters for tracking applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ristic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arulampalam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Artech House</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Multiple View Geometry in Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Real time soccer field analysis from monocular TV video data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoernig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Radig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International Conference on Pattern Recognition and Image Analysis</title>
		<meeting><address><addrLine>Samara</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="567" to="570" />
		</imprint>
	</monogr>
	<note type="report_type">PRIA-11-2013</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scalable video visual analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>H√∂ferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>H√∂ferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heidemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<idno>doi: 10. 1177/1473871613488571 3</idno>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="26" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interactive schematic summaries for faceted exploration of surveillance video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>H√∂ferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>H√∂ferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heidemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weiskopf</surname></persName>
		</author>
		<idno type="DOI">10.1109/TMM.2013.22385213</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="908" to="920" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automated classification of passing in football</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Horton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gudmundsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Estephan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<editor>T. Cao, E.-P. Lim, Z.-H. Zhou, T.-B. Ho, D. W.-L. Cheung, and H. Motoda, eds., PAKDD</editor>
		<imprint>
			<biblScope unit="volume">9078</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="319" to="330" />
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deepercut: A deeper, stronger, and faster multi-person pose estimation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Soccer player tracking across uncalibrated camera streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance</title>
		<imprint>
			<publisher>VS-PETS</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="172" to="179" />
		</imprint>
	</monogr>
	<note>Conjunction with ICCV</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic radial distortion correction in zoom lens video camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Electronic Imaging</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust image mosaicing of soccer videos using self-calibration and line tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-S</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Anal. Appl</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="19" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Graphcut textures: Image and video synthesis using graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schdl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Essa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bobick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="286" />
			<date type="published" when="2003-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Discovering relative motion patterns in groups of moving point objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Laube</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Imfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Geographical Information Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="639" to="668" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Transformation of an uncertain video search pipeline to a sketch-based visual analytics loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Parry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2013.2073</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2109" to="2118" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Matchpad: Interactive glyph-based visualization for real-time sports performance analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H S</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Parry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1255" to="1264" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatic player detection, labeling and tracking in broadcast soccer video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">F</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="113" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Using voronoi diagrams to describe tactical behaviour in invasive team sports: an application in basketball</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baca</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="123" to="130" />
		</imprint>
		<respStmt>
			<orgName>Cuadernos de Psicologia del Deporte</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Geometric design and space planning using the marching squares and marching cube algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Maple</surname></persName>
		</author>
		<idno type="DOI">10.1109/GMAG.2003.12196716</idno>
	</analytic>
	<monogr>
		<title level="m">2003 International Conference on Geometric Modeling and Graphics, 2003. Proceedings</title>
		<imprint>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="90" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MATLAB and Computer Vision System Toolbox Release</title>
	</analytic>
	<monogr>
		<title level="j">The MathWorks Inc</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A computer vision based tracking system for indoor team sports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Monier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>R√ºckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The fourth International Conference on Intelligent Computing and Information Systems</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">C Programming Guide Version 4.0. Nvidia Corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuda</forename><surname>Nvidia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Color-based probabilistic tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vermaak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gangnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Soccerstories: A kick-off for visual soccer analysis. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Perin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vuillemot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Fekete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Tactics analysis in soccer-an advanced approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Perl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grunz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Memmert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Science in Sport</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="44" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Snapshot: Visualization to propel ice hockey analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pileggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Stolper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2819" to="2828" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deepcut: Joint subset partition and labeling for multi person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Tennivis: Visualization for tennis match analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Polk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2014.23464453</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2339" to="2348" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Digital Signal Processing: Principles Algorithms and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Proakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Manolakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Prentice Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dynamic Visual Abstraction of Soccer Movement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Al-Masoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrienko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Janetzko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Conference on Visualization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Featuredriven visual analytics of soccer data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sacha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Deussen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology (VAST), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="13" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Where are the ball and players? soccer game analysis with color-based tracking and image mosaick</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-S</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Analysis and Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Visual soccer analytics: Understanding the characteristics of collective team movement based on feature-driven analysis and abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>H√§u√üler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>J√§ckle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Janetzko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS International Journal of Geo-Information</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2159" to="2184" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Director&apos;s cut: Analysis and annotation of soccer matches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Janetzko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Breitkreutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Seebacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grossniklaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Couzin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2016.102</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2016-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">How to make sense of team sport data: From acquisition to data modeling and research aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Janetzko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Seebacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>J√§ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>H√∂lsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kosub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grossniklaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Online object tracking: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Regocnition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
