<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Geo-Spatial Visualization for Situational Awareness</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliot</forename><surname>Feibush</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Gagvani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Williams</surname></persName>
						</author>
						<title level="a" type="main">Geo-Spatial Visualization for Situational Awareness</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Terrain Visualization</term>
					<term>Situational Awareness</term>
					<term>DTED</term>
					<term>Digital Maps</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Situational awareness applications require a highly detailed geospatial visualization covering a large geographic area. Conventional polygon based terrain modeling would exceed the capacity of current computer rendering. Terrain visualization techniques for a situational awareness application are described in this case study. Visualizing large amounts of terrain data has been achieved using very large texture maps. Sun shading is applied to the terrain texture map to enhance perception of relief features. Perception of submarine positions has been enhanced using a translucent, textured water surface. Each visualization technique is illustrated in the accompanying video tape.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Situational awareness visualization applications require the representation of large geographic areas and thousands of military units. The extent of the area of interest (playbox) is typically one million square miles. Observers want to see the highest resolution data available and be able to navigate through the model at interactive rates. The geo-spatial information displayed consists of elevation data, a variety of maps, and high resolution imagery. The size of the playbox and the amount of data present a considerable demand on both the terrain model and the visualization software. A Joint Forces operation simultaneously involves ground, sea, and air forces. Military units must be displayed in the context of terrain, on the sea, under the sea, and in the air. Collateral maps and images also aid in understanding the movement and placement of units.</p><p>The Joint Operations Visualization Environment (JOVE) <ref type="bibr" target="#b4">[5]</ref> has been developed to assist top level military decision makers. JOVE uses three rear projected displays driven from an SGI Onyx2 Infinite Reality (IR) computer. Interaction is provided through a joystick and speech interface. JOVE also allows accurate navigation through the model over a range of viewer positions. A typical scene from the situational awareness application is shown in Video Sequence 1. This case study describes techniques used for realistic modeling and navigation of geo-spatial data in JOVE. Section 2 presents an outline of our model and its components. Section 3 describes visualization of elevation data. Section 4 describes techniques to improve perception of sea and under sea vessels. Section 5 discusses the visualization of maps and overhead imagery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Earth Model</head><p>Our model starts with a sphere representing the Earth. The entire world is portrayed because:</p><p>1. Units can move out of the playbox.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Far-ranging units, such as aircraft, could be stationed any-</head><p>where around the world.</p><p>Sarnoff Corporation, 201 Washington Road, Princeton, NJ 08540-6449 efeibush, ngagvani @sarnoff.com.</p><p>Systems and Scientific Software, Elkins Park, PA sass@acm.org.</p><p>3. Additional situations could develop outside of the detailed playbox.</p><p>Satellite imagery <ref type="bibr" target="#b0">[1]</ref> of the Earth is texture-mapped onto the geometric model. The cloudless imagery portrays the world at 4 kilometer resolution. Lines of latitude and longitude are drawn over the imagery at 10 degree intervals. The sphere geometry is modeled to use polygons efficiently and also to avoid thin triangles near the poles. The highest polygon density is in the playbox where most of the action occurs. Similarly, the near hemisphere containing the playbox is modeled with more polygons than the distant hemisphere. The three regions are modeled so there are no geometric discontinuities along the seams, as shown in Video Sequence 2. The entire earth and playbox can be modeled with about 4000 triangles in this way. The polygon geometry was generated using the OpenGL Optimizer toolkit which stitches together the two hemispheres and the playbox seamlessly.</p><p>A Cartesian coordinate system with its origin at a corner of the playbox is used for all graphics calculations. Cartesian coordinates were chosen over spherical coordinates (latitude, longitude and elevation) for fast processing by the hardware. The IR hardware implements a non-linear Z-buffer whose maximum precision is at low z values. Therefore, having the origin at a corner of the playbox allows the highest numerical precision in the most critical area and avoids artifacts during the hidden surface removal process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Elevation Visualization</head><p>Digital terrain elevation data (DTED) <ref type="bibr" target="#b6">[7]</ref> is available at 100 meter or closer postings. Each square degree of land at 100 meter resolution contains about 1,440,000 sample points. Since the playbox can cover over 200 square degrees, representing the DTED at full resolution with a uniformly triangulated polygonal model greatly exceeds the capabilities of current graphics computing. However, current high-end graphics hardware can display very large textures at high performance. Our first elevation visualization technique takes advantage of high resolution texture rendering. Our second technique uses a more "display efficient" polygonal model.</p><p>The first technique is to represent the entire elevation data as color-coded texture. The value of each elevation point is colorcoded by height and entered into a large texture map. This texture is mapped onto a spherical patch of geometry corresponding to the playbox. This enables displaying the terrain at its full resolution and makes for well defined coastlines and other detailed features as shown in Video Sequence 3 and Color Plate 1. The colorcoding enables the user to develop a perception of the terrain, such as which areas are tall mountains and which areas are flat plains. Initially we used just the color-coded value for the pixels in the texture map. Subsequently we "shaded" the color-coded pixels according to the three-dimensional shape (relief) of the terrain. Observers preferred combining color-coding with the visual cue of relief shading because it reinforced their perception of the terrain. The implementation of relief shaded DTED is described in section 3.1.</p><p>The second technique is to use a 3-D model of the terrain. A triangulated irregular network (TIN) model is employed to optimize rendering performance. Close to the surface, a three-dimensional picture of the terrain is preferable. This enables users to not only perceive hills and plains, but also gain line-of-sight information. For example, if two opposing tanks are near each other but are not firing, there could be a hill blocking their view. The implementation of relief modeled DTED is described in section 3.2.</p><p>The two techniques have been used to create terrain models that have been deployed at military exercises. Users involved with ground-based units preferred the 3-D relief model. Users of aircraft were satisfied with the shaded, color-coded texture. The relief shading is similar to the hill shading printed on maps that pilots typically use for mission planning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Color-Coded Relief-Shaded Textured DTED</head><p>Two methods are combined to better convey the topography of the digital elevation model. First, a color map was developed based upon the elevation coloring of Tactical Pilotage Charts <ref type="bibr" target="#b8">[9]</ref> produced by the National Imagery and Mapping Agency. This was used to translate each posting of the elevation model into an appropriately colored pixel in a texture map (Video Sequence 4A). Second, a reflectance map is computed using Method "P, A simple alternative" from <ref type="bibr" target="#b2">[3]</ref> that roughly simulates what the terrain might look like if viewed from above with the sun's illumination coming from the northwest (Video Sequence 4B). The method uses gradient information from the elevation data to produce a relief shaded texture. This reflectance map is used to modulate the colored pixels to achieve the final result (Video Sequence 4C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Relief-Modeled DTED</head><p>Visualization of the three-dimensional terrain is very useful for understanding the speed and movement of ground forces and for planning tactical maneuvers. Elevation data is triangulated into a TIN model using the method proposed by Garland &amp; Heckbert <ref type="bibr" target="#b1">[2]</ref>. A large monolithic model for the entire playbox cannot be interactively rendered. The model is therefore split into multiple tiles. Tiles outside the view volume are culled prior to rendering. Each tile also has multiple levels of detail (LOD) which switch to lower detail as the viewpoint moves further away. Contextual cues are used to accurately model coastlines, especially for low resolution tiles. Threshold based segmentation followed by edge detection is used to create a coastline mask from the elevation data. This mask is used as an input to the triangulation algorithm to generate a larger number of triangles near the coastline.</p><p>If each tile is individually modeled, the triangles do not match up at the edges between tiles. To alleviate this, a huge model is created for the entire playbox and then split into tiles. Such an approach allows seamless terrain at the cost of more triangles. However, when adjacent tiles are at different LODs, cracks can appear in the terrain. We display textured DTED (Section 3.1) below the terrain model to achieve a visually continuous appearance as in Video Sequence 5.</p><p>The relief model typically occupies several hundred megabytes of disk space and is time consuming to generate. To facilitate rapid color changes without regenerating the relief model, color is handled as a one-dimensional texture. Texture coordinates are assigned to the relief polygons according to elevation. A very small texture map is created using the elevation colors. The 1-D texture is rendered on the relief model and can be reloaded instantly. The relief model is scaled to exaggerate height. Rapid traversals for coordinate and normal computations are implemented in IRIS Performer to achieve scaling. Two-dimensional textures from maps and satellite imagery can also be draped on the terrain. Again, texture coordinate computation for switching between one and two-dimensional textures is built into the JOVE software for run-time switching of maps. The use of very large, 2-D textures for maps and imagery is described in Section 5.</p><p>The actual vertical displacement of terrain relative to its area is small. The vertical dimension only covers a few pixels when a large geographic area is rendered on the screen. To enhance the observer's perception, the vertical displacement is typically scaled up. In the JOVE user interface, there is a slider for interactively controlling the the vertical scale. Users typically prefer a scale factor of 5 when examining terrain in the 3-D relief model. The terrain is modeled as a spherical earth. It is not possible to apply a simple scale transformation to the original 3-D model. Therefore the 3-D coordinates of each point must be recalculated based on the scaled elevation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Sea and Under Sea Visualization</head><p>Joint Forces operations include sea craft and submarines. Our technique for displaying sea units is to model a translucent, textured surface for water areas within the playbox. Initially we created a noise texture tile that covered a</p><p>x square area (about 60 miles on a side). This was adequate for close-up views of the coastline, but became visually objectionable for playboxes with large water areas. In a distant view, showing a number of noise texture tiles, the macropattern of identical, adjacent, water texture tiles created a visual artifact. To eliminate the repetitive patterning, we generate a fractal sum noise texture <ref type="bibr" target="#b10">[11]</ref> with enough pixels to cover the entire playbox. This water texture is then merged with the textured DTED so that the DTED pixels replace the fractal pattern in areas not covered by water. Each pixel in the merged texture has a transparency value. The DTED pixels are opaque and the water pixels have varying degrees of transparency according to the noise function.</p><p>Opaque, blue, sea floor and walls are modeled below the water surface to visually enclose the sea area. The texture on the water enhances the perception of the surface and partially obscures the submarines. This clarifies the position of the submarine symbols as below the water. The lines of latitude and longitude are also drawn over the submarine symbols as in Video Sequence 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Maps and Images</head><p>Digital maps and imagery are available for display in the terrain model. They provide contextual geographic detail to enhance the observer's perception of the features pertaining to the tactical situation. Maps vary in scale from 1:2,000,000 Jet Navigational Charts to 1:50,000 Topographic Line Maps <ref type="bibr" target="#b9">[10]</ref>. The content of the map varies with scale. The scale of the content of Jet Navigational Charts matches the scale of a far ranging view of the entire playbox. The content of more detailed maps can not be resolved from a distant view. As the view moves in, the content of the more detailed maps can be seen so it is effective to switch to the display of a different map. Maps and images are stored as high resolution textures that are rendered onto small geometric surfaces positioned above the shaded DTED as in Video Sequence 7.</p><p>Joint Operation Graphics (JOG) <ref type="bibr" target="#b5">[6]</ref> , 1:250,000 maps are texture rendered onto the 3-D relief model. The scale of the JOGs is a good match to the relief model as shown in Video Sequence 8. If the map is higher resolution than the terrain, the map will appear distorted and visually conflict with the relief model. The land areas in the JOGs are shaded corresponding to the terrain. Rendering the JOG onto the 3-D model visually reinforces the map shading with the geometrical shape. Pilots and aircraft commanders felt this was a very effective presentation.</p><p>Color Plate 2 shows several types of geo-spatial data displayed simultaneously with symbols for military units. A JOG map is draped over the relief model and a CIB image <ref type="bibr" target="#b7">[8]</ref> is displayed on a surface positioned above the DTED.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Composite Map</head><p>A large map of central Korea was constructed and is shown in Video Sequence 9. The source data consisted of Topographic Line Maps (TLM) at 1:50,000 scale stored on 30 CDs. The size of the resulting texture map is 32K x 32K, over 1 billion pixels. This texture is stored on disk as a pre-computed mipmap of 16 levels with each level organized in 512 x 512 pixel tiles. Running on a Silicon Graphics Onyx 2 computer with Infinite Reality2 graphics hardware, the display of large textures is implemented using clipmaps <ref type="bibr" target="#b11">[12]</ref>. Clipmaps allow very large textures to be browsed by efficiently loading texture tiles from disk to the texture memory of the graphics hardware as needed. Each CD of map data contains an array of about 8K x 8K pixels. An 8K x 8K clipmap for a single CD of map data uses 8.66 megabytes of texture memory. The 32K x 32K clipmap uses 12.66 megabytes of texture memory. It is much more efficient to composite many map sections into one large clipmap than to create a clipmap for each CD of map data.</p><p>The "clipcenter" is a point on the model which has the highest resolution texture, with the resolution decreasing at points away from it. By default, the clipcenter is located at the center of the screen because that is where the user's gaze is expected to lie. The default clipcenter is good only for overhead views of geo-spatial data, but not for views from the surface of the earth, where the highest resolution should be near the bottom of the screen. We have implemented our own clipcentering algorithm which moves the clipcenter from the center of the screen to the bottom as the elevation angle (angle of view direction with earth's surface) changes from ninety degrees for an overhead view to zero degrees for a tangential view.</p><p>Hardware support for clipmaps is not available on lower end machines. Their hardware texture memory (typically 4MB) can only accommodate a 1K x 1K texture map. Hüttner <ref type="bibr" target="#b3">[4]</ref> has proposed a mipmap pyramid to overcome this limitation. The method requires run-time modification of the geometry which can be expensive. We use a simple paging scheme to browse large maps on an SGI Octane workstation with 4MB of texture memory. The map is divided into 512x512 pixel tiles. Flat geo-positioned geometry is created corresponding to the extents of each tile and preloaded into the Performer scene graph. Initially, traversal for all such geometry is turned off incurring no rendering burden. A set of four texture tiles closest to the current viewpoint is loaded on demand by the user. These textures are mapped on to their corresponding geometries which are made visible in the scene graph. When the viewer position changes, new tiles can be automatically loaded, or loaded on demand. With automatic loading we have been able to achieve update rates of 3 frames per second on an Octane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Situational awareness applications present significant challenges to terrain visualization. Large areas must be displayed in detail and a variety of military units must be displayed in the air, on land and at sea. Polygon based terrain modeling would exceed the capacity of current display systems. However, current graphics hardware supports very large texture maps. Therefore we have applied texturebased terrain modeling techniques to situational awareness.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A color-coded texture displays all the elevation points for a large area. A full resolution polygonal model would exceed current rendering capability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Military unit symbols are displayed with terrain (upper right), map draped on relief (upper left), and imagery to visualize the influence of geographic details on a situation.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>This work was sponsored by the National Information Display Laboratory (NIDL), Princeton, NJ.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The Geosphere Project</title>
		<ptr target="www.geosphere.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Fast Polygonal Approximation of Terrains and Height Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Heckbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garland</surname></persName>
		</author>
		<idno>CMU-CS- 95-181</idno>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
		<respStmt>
			<orgName>School of Computer Science,Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hill Shading and the Reflectance Map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Horn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Institute of Electrical and Electronics Engineers</title>
		<meeting>the Institute of Electrical and Electronics Engineers</meeting>
		<imprint>
			<date type="published" when="1981-01" />
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="14" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">High Resolution Textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hüttner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Late Breaking Hot Topics, IEEE Visualization</title>
		<imprint>
			<date type="published" when="1998-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Sarnoff Corporation, CN 5300, Princeton, NJ 08540-6449</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manual</forename><surname>Jove User</surname></persName>
		</author>
		<ptr target="www.sarnoff.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Joint Operations Graphic -Air/Ground (JOG A/G). National Imagery And Mapping Agency, Standardization Document Order Desk, Building 4D, 700 Robbins Avenue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mil-Prf-0089100a</surname></persName>
		</author>
		<ptr target="www.nima.mil" />
		<imprint>
			<biblScope unit="page" from="19111" to="5094" />
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Military Performance Specification DTED. National Imagery And Mapping Agency, Standardization Document Order Desk, Building 4D, 700 Robbins Avenue</title>
		<idno>MIL-PRF-890201</idno>
		<ptr target="www.nima.mil" />
		<imprint>
			<biblScope unit="page" from="19111" to="5094" />
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">National Imagery And Mapping Agency, Standardization Document Order Desk, Building 4D, 700 Robbins Avenue</title>
		<idno>MIL-PRF-898041</idno>
		<ptr target="www.nima.mil" />
		<imprint>
			<biblScope unit="page" from="19111" to="5094" />
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
	<note>Controlled Image Base (CIB)</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">National Imagery And Mapping Agency, Standardization Document Order Desk, Building 4D, 700 Robbins Avenue</title>
		<idno>MIL-T-89101(DMA)</idno>
		<ptr target="www.nima.mil" />
		<imprint>
			<biblScope unit="page" from="19111" to="5094" />
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
	<note>Tactical Pilotage Chart (TPC)</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Topographic Line Map. National Imagery And Mapping Agency, Standardization Document Order Desk, Building 4D, 700 Robbins Avenue</title>
		<idno>MIL-T-89301 (DMA) 1:50</idno>
		<ptr target="www.nima.mil" />
		<imprint>
			<biblScope unit="page" from="19111" to="5094" />
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An Image Synthesizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Perlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Proceedings, Annual Conference Series</title>
		<imprint>
			<date type="published" when="1985-07" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
	<note>SIGGRAPH 85</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Clipmap: A Virtual Mipmap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Migdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 98, Computer Graphics Proceedings, Annual Conference Series</title>
		<imprint>
			<date type="published" when="1998-07" />
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
