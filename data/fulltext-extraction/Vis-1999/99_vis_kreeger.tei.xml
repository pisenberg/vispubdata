<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mixing Translucent Polygons with Volumes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Kreeger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Visual Computing (CVC)</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution">State University of New York at Stony Brook Stony Brook</orgName>
								<address>
									<postCode>11794-4400</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Kaufman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Visual Computing (CVC)</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution">State University of New York at Stony Brook Stony Brook</orgName>
								<address>
									<postCode>11794-4400</postCode>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mixing Translucent Polygons with Volumes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Mixing polygons and volumes</term>
					<term>Translucent Polygon Rendering</term>
					<term>Volume rendering</term>
					<term>Ray casting</term>
					<term>Voxelization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Figure 1: Mixing polygons with multiple volumes: A scalpel (containing 368 polygons) cutting into a human head (from MRI) while visualizing blood vessels (from an angiogram): (a) translucent polygons reveal the blood vessels behind the scalpel, (b) opaque rendering obscures potentially dangerous movements (also in color plate).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many interactive applications such as medical systems, flight simulators, virtual environments, and location based entertainment (LBE) systems could benefit from the improved image quality and enhanced visual reality of mixing volumetric data with both opaque and translucent polygons at interactive to real-time rates. For example, <ref type="figure" target="#fig_9">Figure 1</ref> shows how a surgeon could use such a system to interactively practice an operation. In this example, multiple volumes are rendered in one scene while still being able to embed polygons. Since our algorithm works with standard OpenGL, many extensions such as this multiple volume example are possible. The Angiogram of the blood vessels show potential danger spots for the fkkreeger,arig@cs.sunysb.edu scalpel. Using simple opaque polygons as in <ref type="figure" target="#fig_9">Figure 1b</ref> obscures the vessels very close to the scalpel. During pre-operative surgical practice, the doctor can use translucent polygons as in <ref type="figure" target="#fig_9">Figure 1a</ref> to see the potentially dangerous areas otherwise hidden from the given viewpoint. Many first person LBE systems place the user behind the avatar or vehicle (e.g., F-15) that the user is controlling. Unfortunately, this obscures a portion of the view. Translucent rendering (as in <ref type="figure" target="#fig_10">Figure 2</ref>) allows the user to see the entire field of view right through the F-15 that he/she is piloting. Another application, shown in <ref type="figure" target="#fig_11">Figure 3</ref>, is a realistic image of steam emanating from boiling tea inside a glass teapot heated on an electric range. A second medical example ( <ref type="figure" target="#fig_1">Figure 5</ref>) allows an orthopedic surgeon to pre-operatively determine which manufacturer's prosthesis best fits the patient. Kaufman et al. <ref type="bibr" target="#b4">[5]</ref> showed that translucent polygons increase the surgeon's ability to visualize prosthesis placement. Kaufman et al., however, rendered only surfaces from the volume data into a Z-buffer and then blended the translucent polygons with the Z-buffered volume image.</p><p>The rendering of opaque polygons with volumetric data is fairly straightforward, using current Z-buffer methods. Therefore, we emphasize the much more difficult problem of embedding translucent polygons within the extents of volumetric data. Translucent polygons complicate the situation because all fragments (both translucent polygon pixels and volume samples) must be drawn in topologically depth sorted order. This is required because compositing translucent fragments with the over operator <ref type="bibr" target="#b13">[14]</ref> is not commutative. Therefore, polygons must be re-depth-sorted whenever the scene or viewing geometry changes. Additionally, the sorting must be topologically correct, including the handling of depth cycles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2: Translucent rendering permits viewing the entire field of view when the user is behind the avatar/vehicle (e.g., F-15 containing 2300 polygons) (also in color plate).</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3: Steam emanating from boiling tea inside a glass teapot (containing 3408 polygons) heated on an electric range (also in color plate).</head><p>Presently, no hardware solutions exist to render translucent polygons correctly even without mixing them with a volume. Although the A-buffer algorithm <ref type="bibr" target="#b1">[2]</ref> sorts correctly, it has never been implemented in hardware because it relies on a dynamically allocated list of depth sorted fragments for each pixel. The proposed hardware implementation of the A-buffer <ref type="bibr" target="#b5">[6]</ref> allows only some constant maximum depth complexity (number of overlapping polygons per pixel) in a single pass. Hence, the sorting is typically left to the application program on the CPU using techniques such as octrees, k-d trees and, most popularly, Binary Space Partition (BSP) trees. However, building the tree is a costly operation. Handling just a few thousand polygons takes over 1 second, even when taking advantage of frame-to-frame coherence to limit the computation to the affected subtrees <ref type="bibr" target="#b17">[18]</ref>.</p><p>An attempt to create a standard for mixing polygons and volumes were the OpenGL extensions proposed in the HP Voxelator <ref type="bibr" target="#b9">[10]</ref>. In their theoretical model, volumes and polygons were rendered by separate pipelines and the resulting images merged in the frame buffer using Z-depths for occlusion. This limited the proposal to opaque polygons and opaque volume projections. More recently, the SGI Volumizer <ref type="bibr" target="#b2">[3]</ref> proposed a method to handle volumes using the polygon pipeline and 3D texture mapping hardware. Opaque  polygons could be mixed with either opaque or translucent volume projections by utilizing Z-depth testing.</p><p>Several software systems have been used to generate high quality images with many differing rendering modalities, including mixing translucent polygons and volumes. However, these systems sacrifice frame rate for image quality and flexibility by rendering completely in software. While well suited for production applications, lack of interactivity leaves these systems unsuited for many other applications. These software systems commonly utilize ray tracing to render images with mixtures of translucent polygons and volumes <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16]</ref>. Although ray-tracing produces visually pleasing images, it is very slow and requires that the volume data be rendered in image order. Unfortunately, there are no volume rendering accelerators available to perform high quality image order ray tracing. Vizard II <ref type="bibr" target="#b10">[11]</ref> proposes to perform image order volume rendering, but relies on lossy compression of the gradients and barely achieves interactive frame rates.</p><p>An alternative to rendering volumes by image order ray tracing is to perform object order ray casting. Although both methods perform the correct depth sorting of volume samples, image order ray tracing utilizes memory bandwidth very inefficiently because of the almost random access to volume data. Object order algorithms, on the other hand, traverse the input data in storage order (e.g., shear warp <ref type="bibr" target="#b7">[8]</ref>, splatting <ref type="bibr" target="#b20">[21]</ref>, or slice order ray casting <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>), thus accelerating the rendering process due to the memory access coherence. One of the more common object order methods is to process the volume in slice order most perpendicular to the ray direction <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. Since all rays are processed in lock-step, memory is required to store the partially composited results. Often, as in 3D texture map based volume rendering <ref type="bibr" target="#b2">[3]</ref>, the actual frame buffer itself is used. Various solutions have been developed which provide interactive to real-time frame rates for volume rendering at various image qualities, all utilizing object order processing to exploit regular memory access patterns. The solutions range from low quality approximations on PCs at barely interactive rates (e.g., Voxar), through interactive rates on high end SGI workstations, to the highest quality rendering at 30Hz frame rates on specialized volume rendering accelerators (e.g., the new VolumePro PCI card from Mitsubishi Electric/Real Time Visualization <ref type="bibr" target="#b11">[12]</ref> and the U-Cube ultrasound visualization system from Japan Radio Co.both based on Cube-4, developed at Stony Brook <ref type="bibr" target="#b12">[13]</ref> and to become commercially available in 1999). The algorithm we present here also works at frame rates approaching 30Hz on the Cube-5 hybrid rendering architecture <ref type="bibr" target="#b6">[7]</ref>.</p><p>In this paper we employ a 3D texture map based volume rendering approach which allows us to render both opaque and translucent polygons with translucent volume data at interactive rates on a high end workstation. We utilize preshaded RGB or Luminancetextures so that we can achieve high quality images. In theory our methods will work with any texture map based volume rendering approach (e.g., Behrens and Raterings approach to add shadows <ref type="bibr" target="#b0">[1]</ref>). In Section 2, we overview previous work on mixing opaque polygons with volumes on OpenGL systems and discuss some anti-aliasing issues that we discovered. In Section 3, we describe our method to mix translucent polygons with volumes in volume object order and describe our method of bucketing the polygons into thin slabs which fit between the volume slices. Additionally, we show examples from our OpenGL implementation on a high-end 3D graphics system. Section 4 touches on some of the limitations of this method that we discovered along the way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Mixing Opaque Polygons with Volumes</head><p>Rendering mixtures of opaque polygons and volumetric data is straightforward on any system with a Z-buffer. The use of a Zbuffer algorithm to solve the hidden surface visibility of polygons can be easily extended to handle visibility of volume samples. The opaque polygons are drawn first. Subsequently, the volumetric samples, either opaque or translucent, are composited over the pixels using any volume rendering algorithm. The depth values of the opaque polygons are checked to keep volume samples which are hidden by opaque polygons from contributing to the final image.</p><p>On OpenGL systems which include 3D texture mapping support, the volume samples are rendered in a slice by slice method by texture mapping polygons parallel to the image plane <ref type="bibr" target="#b2">[3]</ref>. The polygons represent a (usually) planar set of samples, one for each pixel on the screen (ray cast through the volume). An overview of this system is shown in <ref type="figure" target="#fig_3">Figure 6</ref>.</p><p>High end OpenGL implementations are optimized for frame buffer operations. However, on lower end graphics accelerators the Z-buffer write operation should be turned off during volume rendering with glDepthMask(). Doing this avoids unnecessary writes to frame buffer memory.</p><p>When anti-aliased polygons are drawn on a high end workstation, it is best to utilize the gl multisampling sgis. The alternative, gl polygon smooth, creates anti-aliased edges by computing an alpha value for the percent coverage of each fragment and blending   into the frame buffer. However, only one color and one depth value is computed per fragment, and the polygons must be rendered in front-to-back order. Since the polygons are rendered before the volume, the edges are blended with the background color instead of the volume (see <ref type="figure" target="#fig_4">Figure 7b</ref>). On the other hand, gl multisampling sgis, performs rasterization to a higher resolution, storing depths, colors, etc. for each sub-pixel. This way, the correct depth of each subpixel can be used to composite volume samples into each sub-pixel. Before display, hardware averages the sub-pixels for a smooth antialiased image (see <ref type="figure" target="#fig_4">Figure 7c)</ref>.</p><p>In <ref type="figure" target="#fig_4">Figure 7</ref>, on the right (inside the white circle), one can see how both methods create pleasing anti-aliased edges when there is no volume behind the polygon. However, one can see on the left (inside the black circle) how the gl polygon smooth edge is blended with only the background color. The gl multisampling sgis triangle has edge pixels properly blended with the volume. Infinite Reality</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Volume Sample Plane</head><p>Polygon Slab</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Slab Boundary Interval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 8: Side view of dove-tailing translucent polygons and volume data. (The gaps between polygon slabs are shown for clarity. In reality, there is no overlap or gap as shown by the boundary intervals.)</head><p>frame buffer operations are optimized to perform multisampling at no cost to the frame rate. We have verified this on four different scenes at screen resolution up to 12801024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Mixing Translucent Polygons with Volumes</head><p>Rendering of volumetric datasets is a more demanding task than rendering polygons. Additionally, the only methods to achieve interactive or real-time frame rates for volume rendering utilize object order ray casting. Therefore, in our method presented here, we adapt polygon rendering to slice order ray casting, and synchronize the overall rendering process on a volume slice-by-slice basis instead of a polygon-by-polygon basis or pixel-by-pixel basis. In our method, each slice of the volume is sampled in planes perpendicular to the image plane. The planes are drawn in depth order from farthest from the eye to closest to the eye. Therefore, to mix translucent polygons with volumetric data, thin slabs of the polygons are rendered and composited in between the slices of the volume samples, as shown in <ref type="figure">Figure 8</ref>. In this 2D side view example, the rectangles represent all of the translucent objects which lay between two consecutive slices of the volume sample planes. The boundaries of the slabs should be created such that the union of all the slabs neither miss nor duplicate any region, such as less-than the current slice and greater-than-or-equal-to the next slice (see slab boundaries in <ref type="figure">Figure 8</ref>). The data from the volume slices and the translucent polygonal slabs are dove-tailed together in an alternating fashion. In this way the correct depth ordering of all contributing entities is preserved and use of the over operator to composite them creates correct colors in the final image pixels.</p><p>In our method, the opaque polygons are drawn first with Zbuffering. Before drawing any volume slices, the translucent polygons which lie behind the volume extent are drawn over the opaque polygons using any translucent polygon rendering algorithm (e.g., painters algorithm). Polygons which lie depth-wise within the volume extent, but above/below/left/right of the volume, are then drawn in slice order as if the volume slices were planes that extended to infinity cutting the translucent polygons.Finally, translucent polygons which lie in front of the volume are drawn.</p><p>OpenGL can be used to directly render the thin slabs of translucent polygonal objects. The polygons are shaded using the Gouraud shading model included in OpenGL. A naive approach would be to render the complete set of translucent polygons for every slab and set the hither and yon clip planes to cut out the current thin slab of data. Yet, for an n 3 volume, there could be up to n thin slabs that   must be rendered. Since a typical scene contains very few polygons which span all of the thin slabs, an alternative would be to clip the polygons to the slab boundaries and only render the portions of the polygons within each slab. This would substantially reduce the processing load on the polygon pipeline. However, it would require the application to clip every polygon against the two planes of each thin slab which contains that polygon. <ref type="figure" target="#fig_5">Figure 9</ref> demonstrates clipping triangles to thin slab boundaries and that we can take advantage of the fact that the two boundary planes are parallel to only keep the portions of the polygons which lie between the planes. The clipping process may create more triangles. There are four possibilities. The first case occurs when a triangle intersects the thin slab, but no vertices are within the slab boundaries. When this occurs, one vertex must be on one side of the slab and the other two on the other side, creating a trapezoid which is decomposed into two triangles. Next, consider when there is one vertex within the slab. In one situation, the remaining two vertices lay on the same side of the current slab creating only one triangle. The second situation is when the other two triangle vertices lay on opposite sides of the slab. This is the worst condition because it produces a pentagon, or three triangles. The final case is when two vertices lie within the slab, and once again a trapezoid is created resulting in two triangles. While this creates fewer polygons than clipping against each plane separately, it still can dramatically increase the triangle count.</p><p>Instead, we bucket sort the translucent polygons. We create a bucket for each thin slab between two volume sample planes. We traverse all the translucent polygons in the scene and place each  <ref type="figure" target="#fig_1">Figure 11: Normalized polygon count as a function of the: (a) frames from the test sequences -teapot and helicopter are rotated 5  degrees per frame, F-15 flying through a cloud, and hip is a prosthesis alignment search sequence, (b)</ref>  one in a bucket for each slab it intersects. For example, in <ref type="figure">Figure</ref> 10 triangle T1 is placed in all six slab buckets since it spans all of the slabs. Triangle T2 is placed in buckets S2 and S3, and likewise for the rest. While many polygons are rendered multiple times, there are still fewer polygons drawn than if they are clipped to the slab boundaries. For example, bucketing the four triangles from <ref type="figure" target="#fig_6">Figure 10</ref> would result in 12 triangles being sent to the graphics pipeline. If these triangles were clipped to the slab boundaries, as in <ref type="figure" target="#fig_5">Figure 9</ref>, 20 triangles would be sent to the graphics pipeline. The hither and yon clipping planes automatically cut the polygons early in the polygon processing pipeline, thus reducing fill rate requirements to be the same as if the polygons were truly clipped to the slab boundaries. Another advantage of bucketing is that it is a much less demanding process on the application program than clipping.</p><p>An alternative to bucketing is to create an active triangle list similar to the active edge list utilized in scan converting polygons. The triangles can be placed in the active list at the first slice where they intersect, and removed when they no longer intersect any more slices. A data structure can be pre-computed which indicates which slice each triangle is first encountered. This preprocessing is the same as for bucketing. In fact, the only differences between bucketing and active triangle lists is that bucketing does not have to check for triangle removal at each slice, but does use a larger data structure.</p><p>We analyzed the effectiveness of polygon bucketing using sequences of four test scenes: the hip prosthesis, the F-15 plane, the teapot, and the helicopter. The scalpel example in <ref type="figure" target="#fig_9">Figure 1</ref> was not used since the multiple volume scenario significantly affects the overall rendering performance. In each of the four test cases, our images were 300 2 and we rendered 100 volume slices. The number of polygons drawn per frame was normalized to the number of polygons in the model. The normalized polygon counts are shown in <ref type="figure" target="#fig_9">Figure 11a</ref>. The hip sequence is 92 images from an interactive search for the correct prosthesis placement. In frames 0 to 20, the model is rotated to match the alignment of the hip bones. The number of polygons drawn has a large variation in this region because different orientations cause the polygons to span a different number of slabs. From frames 20 through 75 the user translated the hip around at the same orientation. The perfectly flat regions in the graph represent the model moving in the X-Y directions only; therefore, the polygons remain in the same slab buckets. The regions of small variations appear when the model moves in the Zdirection and polygons enter and leave slab boundaries. In frames 75-92 the model returned to its original orientation.</p><p>In the helicopter sequence, the model is rotated 5 degrees per frame through 360 degrees. The helicopter consists of many triangles which span the length of the helicopter body. At 0 and 180 de-grees, these polygons span many buckets and cause multiple polygons to be drawn. At 90 and 270 degrees, most polygons are perpendicular to the view direction and parallel to the slab boundaries. This causes most polygons to be drawn only within one slab.</p><p>In the teapot scene, the viewer walks 360 degrees around the teapot. Since volume slices are always drawn perpendicular to the viewing direction, this has the same effect as spinning the model 360 degrees.</p><p>Finally, the F-15 sequence is a fly-over a terrain with a cloud that the plane flys directly though during frames 42 -81. Since the plane does not intersect the cloud except for this area, the number of polygons drawn is exactly the same as the number in the model. Only when the two objects intersect do some polygons get sent to the graphics pipeline multiple times. For our four test sequences, we see that the number of polygons drawn is about 2-3.5 times the original number of polygons in the models.</p><p>An attractive feature of our algorithm is that for applications which choose to trade-off image quality to keep a certain frame rate, the number of polygons drawn decreases as the number of slices drawn for the volume also decreases. This occurs because the inter-slice size increases as the number of volume slices decreases. <ref type="figure" target="#fig_9">Figure 11b</ref> shows how the number of polygons to be drawn decreases linearly when the slice count is reduced. The rendering rate achieved is proportional to the number of polygons drawn and the number of volume samples drawn (which is proportional to the number of volume slices drawn). The image quality degradation resulting from this trade-off affects only the volume data similar to taking fewer samples in a volume rendering algorithm. On the other hand, the polygonal objects appear exactly the same, since the inter-slice boundaries are invisible.</p><p>Previously, we (Silva et al. <ref type="bibr" target="#b14">[15]</ref>) and later Westermann and Ertl <ref type="bibr" target="#b18">[19]</ref> suggested to accelerate rendering by bucketing polygons according to which scanlines they would contribute to in the final image. Bucketing polygons in this way allowed visibility ordering for each scanline to be accelerated by a two pass method using standard graphics hardware. Our method differs in that we bucket the polygons according to Z-depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Handling Multiple Polygons Within One Slab</head><p>There exist two options for handling multiple translucent polygons being drawn to the same pixel within one thin slab. In the first option, the polygons could be drawn in the order they are stored in the display list using normal back-to-front compositing. While this method may produce the incorrect color, the amount of color error is limited since the polygons are translucent and are still sorted by bucketing them into the thin slabs. Additionally, the amount of this error can be computed as follows. Consider compositing two polygons over the previously computed ray at a given frame buffer pixel using the OpenGL blending operations. Using back-tofront compositing, each color channel is blended with the OpenGL glBlendFunc(gl src alpha,gl one minus src alpha). For each color channel, the first polygon has color Cp1 and alpha p1 and likewise for the second polygon. The ray currently has color CR. There are two cases, composite polygon 1 before polygon 2 and composite polygon 2 before polygon 1. If polygon 1 is composited first followed by polygon 2, the resulting color for the ray after some algebraic manipulation is:</p><formula xml:id="formula_0">C = CR + Cp1 p1 + Cp2 p2 + CR p1 p2 ,CR p1 , CR p2 , Cp1 p1 p2</formula><p>Similarly, the resulting color for compositing polygon 2 first is:</p><formula xml:id="formula_1">C = CR + Cp1 p1 + Cp2 p2 + CR p1 p2 ,CR p1 , CR p2 , Cp2 p1 p2</formula><p>Notice that the only difference in these two equations is the last term. In fact if we subtract the second equation from the first, we get the difference being:</p><formula xml:id="formula_2">diff = absCp2 , Cp1 p1 p2</formula><p>Thus, we can say that the amount of error from this method depends on the difference in color of the two polygons and the opacity of each. So, if two translucent polygons will be drawn to the same pixel in a thin slab and have the same color, there will be no error in the resulting ray no matter in what order they are drawn. Also, if the colors differ, we can compute the resulting color error by using the opacities of each. This measure could be used for the application to decide whether to utilize the slower, but more accurate, method we are about to introduce.</p><p>The second option to handle drawing multiple translucent polygons to the same pixel within one thin slab is also the more accurate one. By utilizing one of the methods mentioned earlier to depth sort, such as a BSP tree, proper ordering of all translucent polygons within each slab is maintained.Unfortunately, correct topological sorting is a very expensive task. For example, <ref type="figure" target="#fig_8">Figure 12</ref> shows the time it takes to bucket-and-sort polygons for the test sequences. The bucketing-only times were never more than 0.03 second and the median was 0.01 second. For most cases, sorting the polygons inside each bucket is proportional to the number of polygons in each bucket. For example, the hip has the most polygons (polygon counts in <ref type="figure" target="#fig_9">Figure 11</ref> are normalized to the actual model count). Our sorting algorithm contains a quick bounding box extent pre-check. For certain frames in the teapot and hip sequences, there are fewer polygons drawn, but the sorting still takes longer. This is due to the percentage of polygons which fail the pre-check and must be precisely checked for depth cycles. Unfortunately, for some cases skipping the sorting creates incorrect images. For example, for some frames of our teapot sequence, the polygons defining the tea lie within the same thin slab as the glass teapot walls. However, this occurs very rarely. In fact, out of 37K pixels drawn for the tea and teapot per frame, a maximum of 63 pixels blended tea polygons with teapot polygons. Without sorting, approximately half of these would be composited in the wrong order since the teapot completely surrounds the tea.</p><p>In the F-15 sequence, the plane stays in the same geometrical configuration with the viewpoint. Therefore, we take advantage of this fact and pre-sort the polygons. Even a naive bucketing algorithm will leave the polygons sorted when the plane intersects the cloud.</p><p>An application where polygon ordering never creates an incorrect color may take advantage of the speedup of only bucketing the polygons. For example, in the hip application in <ref type="figure" target="#fig_1">Figure 5</ref>, the polygons which have different colors are always separated by more than the slab thickness. Consequently, the incorrect color is never generated no matter how the polygonal model is aligned with the volume slices. For our helicopter sequence, we also measured no incorrect color blending operations. While this is not an argument for every application to skip the topological sorting step, we notice that many applications can benefit from the fact that the bucketing has done a "good" enough sorting job to create acceptable image quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Implementation</head><p>Our algorithm has been implemented in OpenGL on existing hardware by using 3D texture map hardware to achieve interactive volume rendering. Applications begin by rendering all opaque polygons with Z-buffering and multisampling if it is available. Then, all the translucent polygons behind the volume data are drawn using a method which creates the desired quality (e.g., painter's algorithm). Subsequently, mixing the translucent polygons with the volume data is dealt with in the following manner. Slices of volume data are drawn one at a time from back to front by projecting a polygon for that slice and texture mapping with 3D texture extensions. The volume slices are Z-depth checked and blended on top of the frame buffer. In between each volume slice, the translucent polygons in the bucket for the current thin slab are drawn, once again with Z-buffer checking and blending. The volume slices and polygon thin slabs are alternated until the end of the volume is reached. Finally, any translucent polygons which are in front of the volume data are drawn. <ref type="figure" target="#fig_0">Figures 2, 3, 4</ref>, and 5 are frames from test sequences generated on an Onyx2 with Infinite Reality graphics. We rendered the scenes with 100 slices of the volume into a 300 2 image. The helicopter frames were rendered at 7.6Hz and the teapot images at 12.5Hz. The F-15 sequence produced between 9 and 50Hz. Since the viewer flys through the volume in this sequence, the size of the volume on the screen changes dramatically and greatly affects the time it takes to render. Finally, the hip sequence produced frames at 4.8Hz. The hip dataset is textured using RGB texels, each taking 32 bits to store. This also greatly affects the rendering rate since the Infinite Reality texture memory system is optimized for 16 bit texels as we discuss in Section 7. We also rendered the hip with 250 volume slices to produce higher quality structures in the volume at about 2Hz.</p><p>Many volumes contain large portions of empty space. Techniques used in a system such as SGI Volumizer cull out this empty space, but require knowledge of the visible portions of the dataset. For example, with the teapot scene we pre-processed the steam volume to create tighter geometric boundaries around the steam. By using these polygons to texture map the volume into the frame buffer, we saved on the frame buffer fill rate. Using the tight geometric boundaries, the teapot scene was rendered in 0.07 seconds resulting in 14.3Hz instead of 12.5Hz frame rate when texturing the entire volume into the scene including empty samples -an increase, but still in the same order of magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Comparison to Voxelization</head><p>In current voxelization methods <ref type="bibr" target="#b16">[17]</ref>, when a surface is 3D scan converted into a 3D volume grid, the resolution of the grid is commonly chosen such that the size of a single voxel represents the smallest area that can be discerned by the human eye when it is rendered. In the x and y dimensions the polygons are drawn to screen resolution. In the z dimension, assume that the volume is being rendered with sufficient slice resolution so that each volume sample also represents the smallest area that can be discerned by the human eye. Therefore, each pixel bounded by two volume slices in the z dimension also represents this small area. Considering this, our method can be viewed as voxelizing on-the-fly by utilizing 3D graphics hardware.</p><p>This approach has been utilized by Fang and Chen <ref type="bibr" target="#b3">[4]</ref> to voxelize CSG trees after they have been converted to triangle meshes. Fang and Chen considered two surfaces occupying the same voxel as the union of two voxelized objects. Fuzzy set theory contains differing methods for computing the union of multivalued-objects. Fang and Chen used max blending, where each of the RGB channels is computed as the max of the two polygons for that channel. This can create incorrect colors when two solid light reflecting objects occupy the same voxel. Also, with surface modeled objects, just because two polygons are used to model the object does not mean that they represent two different objects. Unfortunately, while this method is faster than software voxelization, it is still too slow to be called interactive. This is because, to be performed correctly, the thin slabs of polygons must be first max-blended into an auxiliary buffer. Then, this slab can be either composited into the image or stored off as a volume slice. Therefore, for every slice of the volume, there is an additional glClear and an image-sized glCopy-Pixels. This increases the pixel fill-rate since even blank pixels are drawn into the frame buffer. Fang and Chen report 0.1 to 3 seconds to voxelize 128 3 volumes. Our implementation of max blending for on-the-fly voxelization/rendering of the F-15 scene took 0.4 seconds to render per frame, four times longer than our bucketing version.</p><p>An alternative formulation which has been utilized for voxelization <ref type="bibr" target="#b16">[17]</ref> is to take the weighted-average as follows</p><formula xml:id="formula_3">Cv = Cp1 p1 + Cp2 p2 p1 + p2</formula><p>where Cv is the color assigned to the voxel. We are able to weight the colors by their alpha before blending, by using glBlend-Func(gl src alpha, gl one). However, OpenGL is not able to compute the weighted-average equation since it can not divide by the sum of the alpha values after accumulating them. The OpenGL scale and bias factors multiply every pixel with some constant value, not by a value computed inside that pixel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attenuation Error Distance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Plane of Polygon</head><p>Volume Slices (a) (b) <ref type="figure" target="#fig_9">Figure 13</ref>:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Side view of error within a thin slab of polygons. The attenuation from the volume slice directly in front of each polygon fragment to that fragment is not considered. While this is a small amount the discontinuous color resulting on the face of the polygon is distracting to the human eye. (b) Example image of a polygon inside a homogeneous gel.</head><p>A last possible method is to pre-voxelize the translucent polygons and then render multiple volumes. Our method has the following advantages. Firstly, our method produces a significantly lower fill rate into the frame buffer than rendering a complete volume for the translucent polygons. The fill rate advantage can be as low as 50% of the voxelized/multiple-volume solution. Even if the translucent polygons are pre-voxelized, rendering their voxelized slices will create many frame buffer operations with blank fragments. Secondly, if we perform depth sorting of the buckets, we can gain viewpoint independence with correct color. With voxelization, the max blending does not create correct color and choosing an arbitrary order ties the voxelized representation to a given viewpoint. Lastly, our method allows polygonal objects to be dynamic without requiring re-voxelization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>As with most hardware acceleration, our method utilizes some approximations. Using the slice order mixing approach, the amount of light absorbed by the volume material is discretized to the level of each volume slice. Therefore, any polygon fragment which falls between two consecutive slices of the volume data receives the exact same amount of attenuation. While this error is very small, the discontinuity between regions of the polygon which fall between different volume slices might be distracting to the human eye. <ref type="figure" target="#fig_9">Figure 13</ref> shows a side view of this error. With software ray-tracing, the exact polygon surface intersection is computed eliminating this error. This effect is not noticeable in any of our example images. We experimented with different volumes at different resolutions, and were only able to see the effect on perfectly homogeneous volumetric "gels" (see <ref type="figure" target="#fig_9">Figure 13b</ref>). Any volume which contains any kind of heterogeneity hides this minimal error. For a perfectly homogeneous gel, it would be better to render the region using gl fog which, in addition to being faster, also creates more continuous attenuation levels.</p><p>Unfortunately, there are two drawbacks to using texture mapping hardware for volume rendering which affect some applications. First, the texture mapping hardware cannot accurately shade/light each sample of the volume such as supported in specialized volume rendering engines. Recent proposals <ref type="bibr" target="#b19">[20]</ref> to perform shading only work for approximating isosurface renderings and only perform diffuse, not specular, shading. While some applications can use pre-shaded volumes or do not need highly accurate shading, others require it. For our examples of clouds, we pre-shaded the volumes and rendered Luminance-textures. This approximation is valid since most flight simulation applications are lit by the sun which does not move quickly compared to cloud objects. For the hip scene we pre-shaded the volume into an RGB representation. While in this virtual simulation environment the light may move, high quality shading provides more intuitive understanding of the structures inside the data. This understanding is essential for this application and therefore can not be ignored.</p><p>Secondly, the 3D texture map approach to volume rendering does not achieve true 30Hz frame rates except for the highest end graphics workstations. The per-vertex geometry calculations for the volume slices is easily achievable with any level graphics hardware. However, since these systems are designed for rendering polygons, they must support random access to both the texture memory and frame buffer (see <ref type="figure" target="#fig_3">Figure 6</ref>). Therefore, memory bandwidth can not be optimized for the regular order that is utilized when rendering slices of the volume. For example, an Infinite Reality graphics engines with 4 raster manager boards is reported to place 710 million 16 bit textured, depth buffered fragments into the frame buffer per second. However, with only one board (a common configuration since they are the most expensive part), the fill rate quickly drops to 177 million fragments per second. In our tests we were only able to achieve up to 90 million fragments per second fill rate, below the published numbers since they do not include blending. Additionally, our hip example with 32 bit RGB textures performed even slower due to increased demand on the interpolation units in the texture mapping subsystem. However, the increased quality and accuracy provided by the 32 bit textures is required by the application.</p><p>We have previously presented a hybrid volume/polygon rendering architecture <ref type="bibr" target="#b6">[7]</ref> for the Cube-5 system which utilizes objectorder ray casting to achieve 30Hz rendering rates. The algorithm presented in this paper can be used in this system to render the translucent polygons in between the volume slices for faster, higher quality images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We have presented an algorithm which allows for the correct rendering of both translucent and opaque polygons mixed with volumetric data. We have shown how this algorithm works with slice order ray casting by rendering thin slabs of polygons between the volume slices. We have also shown that clipping of polygons to the thin slabs is not required. Instead, we presented a technique for bucketing the polygons and showed its efficiency. We have presented an implementation of our algorithm on general-purpose geometry hardware. We have demonstrated our algorithm with multiple scenarios showing examples of medical applications, flight simulators, location based entertainment, and virtual environments. Finally, we have discussed the limitations of the method which affect image quality and frame rate. In the future it would be interesting to determine how to quickly compute and use the error from bucketing only versus full sorting for each slab of translucent polygons. As we discussed in Section 4, the application program could bound the error and allocate processing to fully depth sort the slabs where incorrect compositing may cause significant color differences. Our algorithm is based on standard OpenGL, allowing numerous extensions such as mixing with multiple volumes as shown in <ref type="figure" target="#fig_9">Figure 1</ref>, or future work using stencil buffers to visualize intersections between polygonal objects and volumetric data.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 :</head><label>4</label><figDesc>A translucent helicopter (containing 2709 polygons) spinning in a cloud over a textured terrain (also in color plate).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>A prosthesis (containing 3758 polygons) being fit to a 256 3 CT scan of a hip (also in color plate).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Graphics accelerator solution, where volume slices compete with polygons for limited resources at the texture memory and frame buffer memory interfaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>An opaque polygon mixed with a gray translucent volume: (a) no anti-aliasing, (b) OpenGLGl polygon smooth, (c)gl multisample sgis extension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9 :</head><label>9</label><figDesc>Clipping triangles to thin slab boundaries may create more triangles. There are four possibilities when clipping a triangle to a thin slab defined by two parallel planes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 :</head><label>10</label><figDesc>Bucketing triangles results in 12 triangles being sent to the graphics pipeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>Application processing time for bucketing-and-sorting for the test sequences. (Bucketing-only times were never greater than 0.03 sec; the median was 0.01 sec.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 1 :</head><label>1</label><figDesc>Mixing polygons with multiple volumes: A scalpel (containing 368 polygons) cutting into a human head (from MRI) while visualizing blood vessels (from an angiogram): (a) translucent polygons reveal the blood vessels behind the scalpel, (b) opaque rendering obscures potentially dangerous movements.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 2 :</head><label>2</label><figDesc>Translucent rendering permits viewing the entire field of view when the user is behind the avatar/vehicle (e.g., F-15 containing 2300 polygons).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 3 :</head><label>3</label><figDesc>Steam emanating from boiling tea inside a glass teapot (containing 3408 polygons) heated on an electric range.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 4 :</head><label>4</label><figDesc>A translucent helicopter (containing 2709 polygons) spinning in a cloud over a textured terrain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 5 :</head><label>5</label><figDesc>A prosthesis (containing 3758 polygons) being fit to a 256 3 CT scan of a hip.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>number of volume slices for a single frame in each test sequence.</head><label></label><figDesc></figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the National Science Foundation under grant MIP9527694 and Office of Naval Research under grant N000149710402. The authors would like to thank previous reviewers for pointing out some of the SGI OpenGL extensions that made this a more complete work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adding Shadows to a Texture-Based Volume Renderer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1998-10" />
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The A-Buffer, an Antialiased Hidden Surface Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics</title>
		<imprint>
			<date type="published" when="1984-07" />
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="103" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">OpenGL Volumizer Programmer&apos;s Guide. Silicon Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Eckel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<pubPlace>Inc, Mountain View, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hardware Accelerated Voxelization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Workshop on Volume Graphics</title>
		<meeting>International Workshop on Volume Graphics<address><addrLine>Swansea, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-03" />
			<biblScope unit="page" from="185" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Intermixing Surface and Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3D Imaging in Medicine: Algorithms, Systems, Applications</title>
		<editor>K. H. Höhne, H. Fuchs, and S. M. Pizer</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1990-06" />
			<biblScope unit="page" from="217" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hardware Accelerated Rendering of CSG and Transparency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pease</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, SIGGRAPH 94</title>
		<imprint>
			<date type="published" when="1994-07" />
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hybrid Volume and Polygon Rendering with Cube Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kreeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware</title>
		<meeting>SIGGRAPH/Eurographics Workshop on Graphics Hardware</meeting>
		<imprint>
			<date type="published" when="1999-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering using a Shear-warp Factorization ot the Viewing Transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, SIGGRAPH 94</title>
		<imprint>
			<date type="published" when="1994-07" />
			<biblScope unit="page" from="451" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Hybrid Ray Tracer for Rendering Polygon and Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="1990-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Design of A High Performance Volume Visualization System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lichtenbelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware</title>
		<meeting>SIGGRAPH/Eurographics Workshop on Graphics Hardware</meeting>
		<imprint>
			<date type="published" when="1997-08" />
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">VIZARD II, A PCI-Card for Real-Time Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meissner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kanus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Strasser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGGRAPH/Eurographics Workshop on Graphics Hardware</title>
		<meeting>SIGGRAPH/Eurographics Workshop on Graphics Hardware</meeting>
		<imprint>
			<date type="published" when="1998-08" />
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The VolumePro Real-Time Ray-Casting System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hardenbergh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, SIGGRAPH 99</title>
		<imprint>
			<date type="published" when="1999-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cube-4 -A Scalable Architecture for Real-Time Volume Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1996-10" />
			<biblScope unit="page" from="47" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Compositing Digital Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, SIGGRAPH</title>
		<imprint>
			<date type="published" when="1984-07" />
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="253" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast Rendering of Irregular Grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1996-10" />
			<biblScope unit="page" from="15" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Volumetric ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization</title>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">vxt: A C++ Class Library for Object Voxelization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Šrámek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Workshop on Volume Graphics</title>
		<meeting>International Workshop on Volume Graphics<address><addrLine>Swansea, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-03" />
			<biblScope unit="page" from="295" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimization of the Binary Space Partition Algorithm (BSP) for the Visualization of Dynamic Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Torres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics &apos;90</title>
		<imprint>
			<date type="published" when="1990-09" />
			<biblScope unit="page" from="507" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The VSBUFFER: Visibility Ordering of Unstructured Volume Primitives by Polygon Drawing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization &apos;97</title>
		<meeting>Visualization &apos;97</meeting>
		<imprint>
			<date type="published" when="1997-10" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficiently Using Graphics Hardware in Volume Rendering Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, SIGGRAPH 98</title>
		<imprint>
			<date type="published" when="1998-07" />
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Footprint Evaluation for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, SIGGRAPH 90</title>
		<imprint>
			<date type="published" when="1990-07" />
			<biblScope unit="page" from="367" to="376" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
