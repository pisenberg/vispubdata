<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Enabling Classification and Shading for 3D Texture Mapping based Volume Rendering using OpenGL and Extensions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Meißner</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Graphics</orgName>
								<orgName type="institution">Lab University of Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Hoffmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Graphics</orgName>
								<orgName type="institution">Lab University of Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Straßer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Graphics</orgName>
								<orgName type="institution">Lab University of Tübingen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Enabling Classification and Shading for 3D Texture Mapping based Volume Rendering using OpenGL and Extensions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Volume Rendering</term>
					<term>3D Texture Mapping</term>
					<term>Rectilinear Grid</term>
					<term>Shading</term>
					<term>Classification</term>
					<term>OpenGL</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present a new technique which enables direct volume rendering based on 3D texture mapping hardware, enabling shading as well as classification of the interpolated data. Our technique supports accurate lighting for a one directional light source, semi-transparent classification, and correct blending. To circumvent the limitations of one general classification, we introduce multiple classification spaces which are very valuable to understand the visualized data, and even mandatory to comprehensively grasp the 3D relationship of different materials present in the volumetric data. Furthermore, we illustrate how multiple classification spaces can be realized using existing graphics hardware. In contrast to previously reported algorithms, our technique is capable of performing all the above mentioned tasks within the graphics pipeline. Therefore, it is very efficient: The three dimensional texture needs to be stored only once and no load is put onto the CPU. Besides using standard OpenGL functionality, we exploit advanced per pixel operations and make use of available OpenGL extensions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Volume rendering is an important technique for visualizing volumetric data produced by different types of 3D scanners, simulations, and many others. To overcome the inherent large amount of computation and the extreme bandwidth, texture mapping hardware has evolved to become the best known practical volume rendering method for rectilinear grid datasets. Despite the wide availability, 3D texture mapping based volume rendering has some severe limitations.</p><p>Classification and shading of interpolated data are two of the core features of volume rendering and very powerful techniques to visualize volumetric data. The first one can be achieved using a simple lookup right after the texture mapping stage. In the context of 3D texture mapping based volume rendering, the latter one has so far only been presented for iso-surface rendering <ref type="bibr" target="#b18">[19]</ref>. However, combining shading and semi-transparent classification within the graphics subsystem is of strong importance for interactive high quality volume rendering and the only missing link for 3D texture mapping to be able to perform all tasks of the volume rendering pipeline. Additionally, multiple classification spaces would allow a more comprehensive understanding of the 3D data and the relation of the materials present in the volume. Again, this should be performed within the graphics subsystem.</p><p>In this paper, we discuss the visualization of rectilinear grid volume data using texture mapping hardware, OpenGL, and extensions. Furthermore, we present techniques to combine shad-Email: fmeissner, uhoffman, strasserg@gris.uni-tuebingen.de, University of Tübingen, Auf der Morgenstelle 10/C9, D72076 Tübingen, Germany ing and classification within the graphics subsystem, and illustrate how multiple classification spaces can be enabled exploiting existing graphics hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>Over the past decade, numerous approaches for visualizing such data have been presented. In general, they can be classified into indirect volume rendering and direct volume rendering techniques.</p><p>In contrast to indirect volume rendering, where an intermediate representation (usually polygons extracted via Marching Cube <ref type="bibr" target="#b14">[15]</ref> or other surface extraction methods) is generated and then displayed, direct volume rendering uses the original data. Many approaches for direct volume rendering have been presented in the past <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b8">9]</ref>. However, due to the large amount of data, computations, and tremendous bandwidth requirements, software approaches are usually limited and far from interactive. One well known exception might be the ShearWarp algorithm <ref type="bibr" target="#b12">[13]</ref>, which can achieve interactivity taking advantage of optimizations such as run length encoding (preprocessing).</p><p>As an alternative to any software rendering, 3D texture mapping hardware has been recognized as a very efficient acceleration technique for volume rendering, right after the first SGI RealityEngine <ref type="bibr" target="#b0">[1]</ref> has been shipped. Cabral et al. <ref type="bibr" target="#b2">[3]</ref> rendered datasets of 256 3 voxels at interactive frame-rates on a four Raster Manager SGI Re-alityEngine Onyx with a single 150 MHz CPU. Similar results have been presented by Cullip and Neumann <ref type="bibr" target="#b3">[4]</ref>. The major drawback of the general texture mapping approach is the absence of shading functionality for volume data. To circumvent this, Van Gelder et al. <ref type="bibr" target="#b8">[9]</ref> proposed a 3-4 parameter lookup which is used to classify and shade the data. Unfortunately, no direct hardware support for such a lookup is available. Therefore, each time the viewing or classification changes, an entire new 3D texture needs to be generated. This applies as well for approaches storing a pre-shaded and pre-classified volume into texture memory. Problematic for all these approaches is the individual interpolation of color and opacity which can lead to severe artifacts <ref type="bibr" target="#b22">[23]</ref>. This could be circumvented by either pre-multiplying color with opacity -which is necessary whenever the classification for opacity changes -or by interpolating data instead of color.</p><p>Westermann et al. <ref type="bibr" target="#b18">[19]</ref> store density values and corresponding gradients in texture memory and extensively exploit OpenGL and extensions for unshaded volume rendering, shaded iso-surface rendering, and application of clipping geometry. Unfortunately, shading of the data cannot be combined with semi-transparent classification. It can only be achieved for iso-surface rendering using one color channel (monochrome).</p><p>Similarly, Dachille proposed to use the available hardware for efficient sample generation and possibly for blending. Shading is performed on the host to ensure high quality rendering <ref type="bibr" target="#b4">[5]</ref>. Again, density values and gradients are stored in texture memory. Classification and high-quality shading has been enabled while sacrificing interactivity for reasonable datasets ( 2M V oxels) and viewports ( 256 2 ), where rendering is in the order of seconds.</p><p>The combination of all features of volume rendering -semitransparent classification, three color channels, shading, and multiple classification spaces -has not been presented so far. This has been mainly due to the fact that not all functionality has been available in the graphics subsystem. However, approaches moving tasks out of the graphics pipeline to the host generally lack interactivity <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b4">5]</ref>, and hence, for reasonable frame-rates, it is vital to keep computations within the graphics subsystem.</p><p>Following Westermann et al. <ref type="bibr" target="#b18">[19]</ref>, we present volume rendering including shading and semi-transparent classification (RGB ). Similarly, we use standard OpenGL functionality as well as OpenGL extensions and an additional 2D lookup table (pixel texture <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>). Since this lookup is fairly small (2D), multiple classification spaces can be enabled exploiting advanced clipping operations. Since all operations are performed within the graphics pipeline, reasonable frame-rates can be achieved and will be presented in the following.</p><p>Section 2 briefly summarizes the state-of-the-art in texture mapping based volume rendering, how classification can be achieved, and how iso-surfaces can be shaded. Our new technique, enabling semi-transparent classification combined with shading is described in Section 3. In Section 4 we present multiple classification spaces and demonstrate how they can be realized using existing graphics hardware. Results and timings for a set of volume datasets are presented in Section 5. Finally, we conclude our paper and outline future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">State-of the Art</head><p>In this section we will briefly describe how three different tasks of the volume rendering pipeline have previously been achieved individually using standard OpenGL and extensions. This overview will illustrate the difficulties in combining the different tasks within existing graphic subsystems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Interpolation of Samples</head><p>Utilizing 3D texture mapping for volume rendering can be achieved effectively and will hence only be described in brief. Any threedimensional grid data can be classified, possibly shaded, and stored as a three-dimensional texture <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b21">22]</ref>. Alternatively, density values <ref type="bibr" target="#b16">[17]</ref> and gradients can be stored as three-dimensional texture <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b4">5]</ref>, which requires a transformation of the gradients to fit into the range of the texture ( 0; 1 ). This is achieved by normalizing the gradients at grid positions, adding one, and dividing them by two. <ref type="figure">Figure 1</ref>: Basic slicing mechanism applied in 3D texture mapping based volume rendering (from <ref type="bibr" target="#b18">[19]</ref>).</p><p>Using standard OpenGL 3D texture mapping functionality, any geometry defined via vertices and corresponding texture coordinates can be rendered such that values on the geometry surface are trilinearly interpolated from the 3D texture data. To ensure that the regions of the geometry within the 3D texture are processed correctly, clipping planes can be applied <ref type="bibr" target="#b8">[9]</ref>. Operating on transparent data requires that planes intersecting with the 3D texture are correctly blended into the frame-buffer. We process the planes in back-to-front order, however, front-to-back order can be used as well but the accumulated opacity needs to be stored for each pixel. <ref type="figure">Figure 1</ref> depicts the overall process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classification</head><p>Classification can be obtained very easily. First, original density values are stored as a 3D texture map. Second, slicing the 3D texture map results in interpolated density, which can then be used to perform a lookup replacing the RGB values. Hence, a color and opacity are assigned to each density. This takes place right after the 3D texture mapping stage, as depicted in <ref type="figure" target="#fig_0">Figure 2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Iso-surface Shading</head><p>Shading iso-surfaces of volumetric data can be performed using the color matrix (part of OpenGL 1.2, Imaging Subset) and has been presented first by Westermann et al. <ref type="bibr" target="#b18">[19]</ref>. <ref type="figure" target="#fig_1">Figure 3</ref> illustrates the color matrix and its lookups. Since our shading and classification technique uses a similar mechanism, we will summarize the properties of this shading. After an appropriate setup, the color matrix is used to calculate the diffuse shading intensity of one light source. The matrix to the right of Mrot (see Formula below) is necessary to transform the interpolated gradient values (stored in RGB) from range 0; 1 to range ,1; 1 .</p><formula xml:id="formula_0">M col = 0 B @ Lx Ly Lz 0 Lx Ly Lz 0 Lx Ly Lz 0 0 0 0 ,1 1 C A Mrot 0 B @ 2 0 0 ,1 0 2 0 ,1 0 0 2 ,1 0 0 0 1 1 C A</formula><p>The matrix to the left of Mrot is required to calculate the scalar product of gradient (stored in RGB) and light vector. Mrot represents the current viewing transformation. Multiplying the matrix with a vector containing the interpolated gradient calculates the diffuse shading intensity (I d ). Evaluating I = Ia + k d I d results in the final intensity, which can be achieved using the post-color matrix scale and bias stage (scale by k d and bias by Ia), which comes right after the color matrix, see <ref type="figure" target="#fig_1">Figure 3</ref>.</p><p>Unfortunately, the described mechanism requires that the alpha value of the fragment multiplied with the color matrix is set to one, otherwise no correct result is obtained. Hence, the channel cannot be used for other purposes, as semi-transparent representation. Despite the excellent visual results, this technique has two limitations: First, this shading technique can only be applied to isosurface rendering for monochrome data, and second, due to the matrix based shading calculation, only one light-source can be considered. For further details refer to <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Combined Shading and Classification</head><p>Achieving the goal of shaded and classified fragments is highly desirable and each individual task can be achieved as described in the previous Section. However, classifying the 3D texture mapped data as previously presented overwrites all four channels (RGB ) and hence, these channels cannot be used to keep the interpolated gradient for further shading using either the color matrix or any other mechanism. On the other hand, applying the previously described shading technique is not possible since it prevents semi-transparent classification.</p><p>Therefore, our technique performs shading and classification such that they can be combined: First, gradients and density values are stored in a 3D texture map. Slicing any plane generates fragments containing the interpolated gradient and density Gx; G y; G z; D . These fragments are sent down to the imaging subsystem to perform shading. Our shading technique calculates the shading intensity only, while keeping the interpolated density value (used later to perform classification). The task of generating shaded and classified fragments is finally accomplished by applying a 2D pixel texture (a degenerated 3D pixel texture), which serves as a lookup using the density value and the diffuse shading intensity. In the following, each of the three steps will be elaborated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Calculating the Shading Intensity</head><p>As described earlier, the color matrix can be used to perform shading. However, the previously described technique requires the channel to be set to one in order to transform the values of the gradient from range 0; 1 to ,1; 1 . To prevent that the -value needs to be set to one, we perform the gradient transformation before the color matrix. In the current implementation we use the scale and bias function within the pixel-transfer-operations (scale by 2 and bias by -1). Alternatively, the post-convolve scale and bias could be used which takes place right before the fragment gets multiplied with the color matrix, see <ref type="figure" target="#fig_2">Figure 4</ref>. To calculate the shading inten- </p><formula xml:id="formula_1">M col = 0 B @ 0 0 0 1 Lx Ly Lz 0 0 0 0 0 0 0 0 0 1 C A Mrot</formula><p>The fragments containing the interpolated gradient and density are then -during rendering -multiplied with the color matrix which results in:</p><formula xml:id="formula_2">M col 2 6 4 R G B 3 7 5 = 2 6 4 L ; N rot 0 0 3 7 5 == 2 6 4 D I d 0 0 3 7 5</formula><p>The stored density (D) can now be used to perform the classification lookup and get a RGB quadruple which needs to be multiplied with I d k d intensity (diffuse term) plus an ambient term Ia ka. Unfortunately, evaluating the shading equation is not feasible, since the remaining pipeline stages do not provide this functionality. However, it can be achieved using a pixel texture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pixel Textures</head><p>Pixel rently 3D and implemented on SGI IMPACT and SGI Octane MXE. A 2D pixel texture can be realized as degenerated 3D pixel texture. In general, pixel textures are applicable during glCopyPixels() and glDrawPixels() but the current implementation supports glDraw-Pixels() only. Therefore, all our textured slices need to be first rendered into the pixel buffer and then copied into the frame-buffer using glDrawPixels(), which unfortunately increases the time per frame. Once pixel textures will be supported for glCopyPixels() as well, higher frame-rates should be achievable. Even higher frame-rates would be achievable if pixel textures were already applied during the rendering process itself allowing one rendering pass. But it is not clear how this will affect the pipeline of the imaging subsystem. Maybe some future architectures will support this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Classification and Illumination</head><p>In a final step we need to perform the classification of the data and apply the illumination. We accomplish this task using the above described pixel textures. Fortunately, only a 2D pixel texture is necessary and the texture can be addressed using the interpolated density (D) and the calculated diffuse intensity (I d ) as s and t texture coordinate respectively (R and G channel). Despite the fact that we only calculate the diffuse shading term, ambient intensity (Ia) can be included as well as different ka and k d factors, possibly for each density value D. This allows us to include different material properties for the different density values. During the generation of the 2D lookup (pixel texture) these properties can be very easily incorporated. For each D and k d , the pixel texture contains a tuple R G B . Each entry of the pixel texture can be computed using the following formula:</p><formula xml:id="formula_3">" R G B = k d D I d " RD GD BD + kaD Ia " RD GD BD = D</formula><p>Obviously, the pixel texture needs to be re-generated whenever the classification, or the factors ka and k d (ka + k d = 1:0) are changed by the user. However, due to its small size (2D, 65K entries), the pixel texture can be calculated interactively. This is different to approaches storing a shaded and classified volume in texture memory where each time one of the above mentioned parameters or the light source changes, the entire 3D texture has to be recalculated. In contrast to our 2D pixel texture, this cannot be accomplished at interactive rates. Additionally, when changing the number of slicing planes, the opacity can be adjusted very quickly by simply updating the -values of the 2D pixel texture.</p><p>As a result of applying the pixel texture, we obtain RGB values which can be correctly blended into the frame-buffer, see <ref type="figure" target="#fig_0">Figure 12</ref> and color plates (the lower row illustrates the illumination for different values of the directional light vector). Now that shading and semi-transparent classification can be performed within the graphics subsystem, we can have a look at more advanced techniques for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Multiple Classification Spaces</head><p>Enabling classification of volume data is a key feature of volume rendering. Unfortunately, the limitations of a single transfer function for classification can be quite severe. Any material surrounded by a second material can only be visualized by classifying the surrounding material as transparent. However, understanding the 3D relationship of both materials might be of interest.</p><p>A simple way of realizing classification spaces are clipping planes and clipping geometry which have been introduced earlier <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19]</ref>. The major drawback of clipping planes or clipping geometry is that they simply clip fragments resulting in fully transparent samples, but do not enable different classification for different areas/spaces. Nevertheless, compromising frame-rate, dual or even multiple classification spaces can be enabled in different ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Clipping Planes</head><p>A clipping plane can be used to discard all data on one side of the plane, while rendering data on the other side of that plane. The basic idea of extending clipping planes, such that data on one side of the plane is classified differently than on the other side, is to apply multi-pass rendering. During the first pass, one pixel texture is applied while a second pixel texture is applied during the second pass. Between the two passes the orientation of the clipping plane needs to be reversed such that only the data which has been clipped in the previous pass is rendered during the second pass. Due to the small size, multiple pixel textures will not result in texture memory swapping which otherwise could reduce the frame-rate. With this simple mechanism two classification spaces can be enabled using one clipping plane.</p><p>To a certain extend, more complex clipping geometry can be achieved using multiple clipping planes. However, two planes possibly subdivide the data into four spaces and all four spaces need to be handled appropriately. To correctly handle multiple classification spaces using multiple clipping planes, the idea of multi-pass rendering can be extended. The basic idea is a multi-pass rendering with n passes, where n = 2 num clipping planes . During each pass the orientation of the clipping planes needs to be altered such that after n passes all combinations have been applied. Additionally, during each pass a different pixel texture is applied to the fragments, thus resulting in multiple classification spaces. Experiments have shown that between one and three clipping planes (resulting in two to eight classification spaces) were sufficient to reveal the desired information contained in the volume data. Nevertheless, the more clipping planes are used, the more render passes are necessary. Therefore, it is a trade-off between render-time and number of classification spaces used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Clipping Geometry</head><p>In some cases, simple clipping planes might not suffice and more complex clipping geometry is required. To enable more complex clipping geometry an approach borrowed from Westermann et al. <ref type="bibr" target="#b18">[19]</ref> can be extended such that dual classification can be applied.</p><p>The general principle is to determine the pixels residing within the cross-section of the plane and the clipping geometry for each plane to be rendered. For these pixels, the stencil buffer is locked and thus during rendering the textured plane, only the fragments of locked pixels (or unlocked pixels) are sent further down the pipeline. Obviously, this approach can easily be extended to allow dual classification spaces. In a first pass all pixels which are locked are rendered applying one pixel texture and during the second pass the unlocked pixels are rendered applying another pixel texture or vice versa. Thus, dual classification can be enabled for clipping planes and for more complex clipping geometry as well.</p><p>Combining multiple clipping geometries and multiple classification spaces can be accomplished using different stencil bits for each clipping geometry but has not yet been implemented.</p><p>The above described technique enables the application of volumetric lenses for volume rendering, where the lens itself can be described by any closed clipping geometry. Within the lens, the data can be classified differently than outside the volumetric lens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In this Section, we present the datasets used for rendering, compare our results with texture mapping based volume rendering using classification only, and show some images illustrating the usefulness of multiple classification spaces. All tests have been performed on a SGI Octane MXE with 4MByte of texture memory. Resulting timings are discussed at the end of this Section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>The datasets have been chosen carefully and are of different size to highlight the impact of texture memory size. Since density values and gradients are stored in texture memory, datasets of up to 128</p><p>Larger datasets require bricking and result in a reduced frame-rate. Due to the requirements of texture mapping, the datasets had to be adjusted in size such that each dimension is a power of two.</p><p>The datasets are presented in <ref type="table">Table 1</ref>, including their size and number of bricks. All datasets consist of 8 bit voxel data. The neghip64, silicium, and lobster fit within the 4 MByte of texture memory available on the Octane while the neghip128 and engine need to be bricked for rendering. Except the engine dataset, all datasets have been taken from the VolVis package <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>MByte  <ref type="table">Table 1</ref>: Test datasets. Due to the requirement of texture mapping each dataset had to be sized to a power of two. The size of each dataset includes voxel data plus gradient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Images</head><p>All datasets have been rendered using the techniques as described in Section 2.2 (refered to as the classical method) and our algorithm combining shading and classification (refered to as ColMatPixTex).</p><p>Larger images of higher quality can be found in <ref type="figure" target="#fig_0">Figure 12</ref> (see color plates). <ref type="figure" target="#fig_4">Figure 6</ref> shows images of the neghip64 dataset. As shown in  , the three dimensional structure can be well understood using our technique while no 3D structure can be detected in <ref type="figure" target="#fig_4">Figure  6</ref>(a)). The images generated rendering the silicium dataset are shown in <ref type="figure">Figure 7</ref>. Again, without shading hardly any structure can be conceived <ref type="figure">(Figure 7(a)</ref>). In contrast, using shading and classification reveals the structure comprehensively <ref type="figure">(Figure 7(b)</ref>). <ref type="figure">Figure 8</ref> shows the images generated from the lobster dataset. Three different materials can be classified: Resin, shell, and meat of the lobster each classified green, white, and red respectively. <ref type="figure">Figure  8</ref>(a) clearly lacks any illustration of the three dimensional character of the data, while <ref type="figure">Figure 8</ref>(b) reveals the shape of the lobster and its shell.</p><p>The engine dataset depicted in <ref type="figure" target="#fig_7">Figure 9</ref> contains an engine block, iron material, and noise around it. Using the classical approach <ref type="figure" target="#fig_7">(Figure 9</ref> a limited extend. In contrast, our technique reveals the structure of the different materials much better, see <ref type="figure" target="#fig_7">Figure 9</ref>(b).</p><p>As mentioned earlier, multiple classification spaces are very useful tools when it comes to understanding the relationship of different materials present in the volume. We rendered a set of images using simple clipping geometry and compared them to images generated using a lens allowing two classification spaces. <ref type="figure" target="#fig_8">Figure  10</ref>(a) shows the neghip128 dataset using a spherical clipping geometry discarding the fragments which reside within the lens while <ref type="figure" target="#fig_8">Figure 10</ref>(b) uses different classification within the lens than outside. Another example for the importance of multiple classification spaces and their usefulness is shown in <ref type="figure" target="#fig_9">Figure 11</ref>. Here, different classification is applied to the silicium dataset. Further results are depicted in the <ref type="figure" target="#fig_0">Figure 12</ref> (see color plates).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Timings</head><p>We measured the overall render-times for the presented datasets and additionally split them into two different render-times. Render-time I is the time consumed to slice the three dimensional texture and to write the interpolated planes from the pixel buffer into main mem-   <ref type="table">Table 2</ref>: Timing results of the different datasets. Render-time is overall time needed to render one frame. Render-time I is the time spent slicing the 3D texture and writing the slices into main memory while render-time II reveals the time spent on color matrix and pixel textures (glDrawPixels()). Num slices indicates the number of slices taken for the presented views (column Images). ory. Render-time II reveals the time needed to perform the shading and classification which is done via glDrawPixels() <ref type="bibr" target="#b0">1</ref> . <ref type="table">Table 2</ref> shows the timings for all datasets with varying viewport size. Since we have to use glDrawPixels(), the interpolated slices need to be copied into main memory to immediately be sent back to the graphics pipeline without altering them. The time for reading the values into main memory (glReadPixels()) is included in rendertime I while the time for sending them back into the graphics subsystem (glDrawPixels()) is included in render-time II. Between 60 and 80% of render-time I is spent readining the slices into main memory. Even worse, sending the values back to the graphics subsystem takes over 90% of render-time II. Hence, efficient support of pixel textures using glCopyPixels() is necessary to achieve interactive frame-rates ( 10 frames). The color matrix is already part of the imaging subsystem of OpenGL 1.2 and pixel textures will be supported on future SGI platforms, not limited to IMPACT systems. We hope that pixel textures will then migrate into OpenGL 1.3.</p><p>Another interesting property is the frame-time relative to the size of the viewport. Once enlarging the viewport by a factor of four, the rendering time only increases by a factor between 2:6 (engine and silicium) and 3:2 (lobster). Obviously, glReadPixels() and glDraw-Pixels() are more efficient the larger the selected area. However, we could also notice that the texture mapping itself is more efficient, which is probably due to the higher cache hit ratio during <ref type="bibr" target="#b0">1</ref> In general, pixel textures are supported for glCopyPixels() and glDraw-Pixels() but their current implementation as OpenGL 1.1 extension only supports the latter one. texture memory accesses (good fill-rate). Despite the different size of neghip64, silicium, and lobster, the frame-rates are very similar. However, changing the view for the silicium or lobster will increase the number of slicing planes due to the larger dimensions in X and Y, and hence increase the render time. Nevertheless, the texture memory access seems to be very efficient since frame-rate of neghip64 and lobster differ only a little despite the large difference in the size of the datasets (neghip64: It can also be observed that the texture swapping mechanismextensively using the system bus of the Octane -is very efficient. Comparing the frame-rate of the neghip128 and the engine (in both cases 128 slices are rendered), only a small difference can be noticed, despite the fact that the engine needs to be split into eight bricks while the neghip requires only two bricks.</p><p>Larger images of higher quality are presented in <ref type="figure" target="#fig_0">Figure 12</ref> (see color plates) shows how multiple classification spaces can be used. In general, the results show that pixel textures are very valuable for texture mapping based volume rendering. Optimal results could be achieved if pixel textures were already applicable during the rendering process or for glCopyPixels().</p><p>We presented a new technique for 3D texture mapping based volume rendering capable of performing all tasks within the graphics subsystem. Shading as well as semi-transparent classification of 8 bit volume data is provided. Furthermore, to circumvent the limitations of a single classification function, multiple classification spaces have been introduced and possible ways for implementation have been shown.</p><p>The presented method is capable of rendering ambient and diffuse shaded fragments and is based on standard OpenGL and advanced per pixel operations (OpenGL extensions). We believe that within the near future even more advanced per pixel operations will be made available since they can be used to great effect in many applications, not only in volume rendering. We also hope that pixel textures will soon be released in a more stable version. In their current release, they cause the X-server to crash every now and then.</p><p>Furthermore, we believe that pixel texture support using glCopy-Pixels() that allows for copying data within the graphics subsystem without copying it to and from main memory should noticeably improve the frame-time. Obviously, this is the main bottleneck of our current implementation.</p><p>Our future focus will be on extending dual classification spaces using clipping geometry to support more than one clipping geometry and looking closer at new OpenGL extensions. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Classification can be achieved performing a lookup, right after the 3D texture mapping stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Shading using color matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Shading using color matrix. sity while still keeping the interpolated density, we have to appro-priately setup the color matrix. The setup is shown in the following formula:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>textures are an extension to OpenGL which enables the interpretation of pixel-values as texture coordinates. R, G, B, and can be used as texture coordinates s, t, r, and q. Pixel textures take place right at the conversion of pixels to fragments. In case pixel textures are enabled, the color of the fragment is replaced by the result of a texture mapping operation, interpreting RGB as texture coordinates. This process is depicted inFigure 5. Pixel textures are cur-Pixel Textures within the graphics subsystem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>neghip64: (a) Classical approach. (b) ColMatPixTex.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 (</head><label>6</label><figDesc>b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>(a)) exposes the structure of the engine block, but only to silicon: (a) Classical approach. (b) ColMatPixTex. lobster: (a) Classical approach. (b) ColMatPixTex.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>engine: (a) Classical approach. (b) ColMatPixTex.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>neghip128: (a) Simple clipping geometry. (b) Lens allowing two classification spaces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 :</head><label>11</label><figDesc>Silicium: (a) Simple clipping lens. (b) Cubic clipping geometry with two classification spaces. (c) Spherical clipping geometry with two classification spaces. (d) as (b) but classification has been flipped.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>64 64 64, lobster: 128 128 64).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Color plates: (a) -(c) engine block (grey), metal (red), and CT noise (blue). Cubic lens is used to reveal inside information, different classifications have been applied for the two classification spaces. (d) -(f) silicon block; Center (yellow), hull (grey), and outer hull (purple). Cubic lens is used to enhance the relationship of the different areas. (g) -(i) lobster consisting of meat (red) and shell (white), surrounded by resin (green). Lens reveals local information removing the resin by applying different classification. (j) -(l) silicon block; Different light directions are selected to show the shading effect.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>This work is supported by the grant SFB 382 of the German Research Foundation. Special thanks to Rüdiger Westermann and Thomas Ertl of the University of Erlangen, Germany for providing their OpenInventor based volume rendering framework in which we incorporated the presented algorithm. We also would like to thank Tobias Hüttner for fruitful discussions and Michael Doggett, Dirk Bartz, and Anders Kugler for proof reading.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">RealityEngine Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Akeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, Proceedings of SIGGRAPH 93</title>
		<imprint>
			<date type="published" when="1993-08" />
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">VolVis: A Diversified System for Volume Visualization Research and Development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sobierajski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Visualization 94</title>
		<meeting>Visualization 94<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Accelerated Volume Rendering and Tomographic Reconstruction Using Texture Mapping Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Volume Visualization</title>
		<meeting><address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-10" />
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Accelerating Volume Reconstruction with 3D Texture Mapping Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Cullip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
		<idno>TR93-027</idno>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Chapel Hill</publisher>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science at the University of North Carolina</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">High-Quality Volume Rendering Using Texture Mapping Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dachille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kreeger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bitter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Eurographics/SIGGRAPH workshop on graphics hardware</title>
		<meeting>of Eurographics/SIGGRAPH workshop on graphics hardware<address><addrLine>Lisboa</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
	<note>Portugal</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Drebin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="1988-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">PixelFlow: The Realization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eyles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Molnar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Poulton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Greer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Eurographics Hardware Workshop</title>
		<meeting>the 12th Eurographics Hardware Workshop<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-08" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Back-to-Front Display of Voxel-Based Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="52" to="60" />
			<date type="published" when="1985-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Direct volume rendering with shading via three-dimensional textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Volume Visualization Symposium Proceedings</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-10" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Introducing pixel texture. Developer News</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hansen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997-05" />
			<biblScope unit="page" from="289" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<ptr target="http://www.opengl.org" />
	</analytic>
	<monogr>
		<title level="j">Silicon Graphics Inc. Pixel texture extension. Specifiaction document</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ray Tracing Volume Densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kajiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Von Herzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="165" to="173" />
			<date type="published" when="1984-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering Using a Shear-Warp factorization of the Viewing Transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, Proceedings of SIGGRAPH 94</title>
		<imprint>
			<date type="published" when="1994-07" />
			<biblScope unit="page" from="451" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics &amp; Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Marching-cubes: A high resolution 3d surface construction algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Cline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, Proceedings of SIGGRAPH 87</title>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="163" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Rendering Algorithm for Visualizing 3D Scalar Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sabella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics</title>
		<imprint>
			<date type="published" when="1988-08" />
			<biblScope unit="page" from="59" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tivor: An Interactive Visualization and Navigation Tool for Medical Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dietz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Sixth International Conference in Central Europe on Computer Graphics amd Visualization, February</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">V-BUFFER: Visible Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Upson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keeler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="59" to="64" />
			<date type="published" when="1988-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficiently Using Graphics Hardware in Volume Rendering Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ertl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, Proceedings of SIGGRAPH 98</title>
		<meeting><address><addrLine>Orlando, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-08" />
			<biblScope unit="page" from="169" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Footprint Evaluation for Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Westover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, Proceedings of SIGGRAPH 90</title>
		<imprint>
			<date type="published" when="1990-08" />
			<biblScope unit="page" from="367" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Coherent Projection Approach for Direct Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics, Proceedings of SIGGRAPH 91</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="275" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Direct Volume Rendering via 3D Textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<idno>UCSC-CRL- 9419</idno>
		<imprint>
			<date type="published" when="1994" />
			<pubPlace>Santa Cruz</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Opacity-Weighted Color Interpolation For Volume Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wittenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Goss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization</title>
		<meeting><address><addrLine>Research Triangle Park, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-10" />
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
