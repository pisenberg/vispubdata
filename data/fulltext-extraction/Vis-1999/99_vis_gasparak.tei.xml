<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-resolution Multi-field Ray Tracing: A mathematical overview</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gasparakis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Mitsubishi Electric Information Technology Center America</orgName>
								<orgName type="institution" key="instit2">Real Time Visualization</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-resolution Multi-field Ray Tracing: A mathematical overview</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>A rigorous mathematical review of ray tracing is presented. The concept of a generic voxel decoder acting on flexible voxel formats is introduced. The necessity of interpolating opacity weighted colors is proved, using a new definition of the blending process in terms of functional integrals. The continuum limit of the discrete opacity accumulation formula is presented, and its convexity properties are investigated. The issues pertaining to interpolation/classification order are discussed. The lighting equation is expressed in terms of opacity weighted colors. The multi-resolution (along the ray) correction of the opacity-weighted color is derived. The mathematics of filtering on the image plane are studied, and an upper limit of the local pixel size on the image plane is obtained. Interpolation of pixel values on the image plane is shown to be inequivalent to blending of interpolated samples.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Volume rendering is a well established and fastly growing field, with many applications in visualizing medical scans, geophysical and scientific datasets, among others. The fundamental primitive of volume rendering is a voxel, which here is understood to represent a collection of fields, each field corresponding to an attribute of the dataset in a given position in space. This concept is useful for multimodality visualization <ref type="bibr" target="#b3">[4]</ref>. For medical applications, one can have multiple scans of the same anatomy, using a different acquisition mode (CT, MRI, PET, ultrasound). One can also consider general 3D-scan converted fields, which can represent segmentation information, edgeness <ref type="bibr" target="#b5">[6]</ref>, shadows <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, material stress and displacement fields, among others.</p><p>Volume Rendering is a projection operator from voxel space to pixels on an image plane. Different volume rendering approaches correspond to a different choice of such an operator. This operator is usually decomposable into operators acting on intermediate auxiliary spaces. Each component operator is usually referred to as a stage of the rendering pipeline. In this paper we focus our attention on the ray tracing approach to volume rendering, although much of the discussion directly applies to all other approaches. In particular, we discuss the mathematics of the following stages of a general multi-field and multi-resolution ray-tracing pipeline:</p><p>Voxel Decoder, which maps a (potentially multi-field) voxel to a rgba value. Such a mapping needs to be general enough as to ac-£ 300 Baker Av., Suite 301, Concord, MA 01742, gasparakis@rtviz.com commodate for all usual cases of interest, yet constrained enough as to be easily implementable in hardware (such as <ref type="bibr" target="#b14">[15]</ref>) or software. We introduce the concept of fixed-grammar variable width cascaded decoder, which can accommodate for most of the cases of interest. The decoder is a generalization of the transfer function concept <ref type="bibr" target="#b4">[5]</ref>, in a way that is well-suited for multi-field visualization.</p><p>Interpolation unit <ref type="bibr" target="#b8">[9]</ref>, which examines the neighborhood of a sample, and assigns attributes to a sample, given the attributes of the voxel lattice around the sample. One can either classify the interpolated voxel subfields, or one can interpolate the classified voxels in the neighborhood of the sample.</p><p>In the case of voxel interpolation, one should allow for the ability to interpolate individual voxel subfields independently, and with potentially different interpolation modes. For example, one might want to interpolate intensity subfields linearly, but interpolate segmentation subfields either using a segmentation based probabilistic scheme, or simply do nearest neighbor interpolation <ref type="bibr" target="#b0">1</ref> .</p><p>In the case of color-opacity interpolation, one finds the rgba assignments of each of the voxels of a given sample, and interpolates them. Here there is a minor complication. One should consider the opacity-weighted colors and interpolate those, as was advocated in <ref type="bibr" target="#b1">[2]</ref> to avoid the self-occlusion artifact. This follows from the mathematics of the blending equation, as we will prove for a general interpolation filter. This proof will rely heavily on a powerful definition of the blending process as a functional (Monte Carlo) integral. This approach is reminiscent to the path-tracing approach of <ref type="bibr" target="#b6">[7]</ref>.</p><p>We introduce our notation: We generically denote as any r, g, or b component; denotes the opacity. When those values refer to an average around sample ×, we denote the average by ×. Let Ø denote transparency (Ø ½ ). For a generic alpha weighted color component we use the usual tilde notation:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>£</head><p>We use capital letters for denoting the corresponding accumulated values: RGB (generically C) <ref type="bibr" target="#b1">2</ref> .</p><p>Edgeness Modulation unit, which modulates the opacityweighted color (generalizing the usual <ref type="bibr" target="#b7">[8]</ref> or any lighting model, which is written in terms of c, and notc) and the opacity <ref type="bibr" target="#b8">[9]</ref>. The reason for expressing shading in terms of opacity-weighted colors is that the input of the shading stage is the output of the interpolation stage (which isc).</p><p>Blending unit, which calculates the contribution of the current sample when blended on the current ray, front to back. This is an integration (or discrete summation) process along the ray. The correct continuum limit of the transparency accumulation is introduced. The theory is presented in a general way, so that it is independent of the parametrization of the ray (i.e. independent of the choice of a local unit of length in the neighborhood of any sample on the ray). This formulation leads to a clean proof of the usual alpha correction ( <ref type="bibr">[13, pg133]</ref>), which is relevant when one supersamples along the ray <ref type="bibr" target="#b8">[9]</ref>, or in shear-warp ray tracing <ref type="bibr" target="#b2">[3]</ref>. We examine the effect of supersampling along the ray, and we prove that one should alpha correct the interpolated alpha values, as opposed to interpolating the alpha corrected alpha values of the neighborhood. Furthermore, one needs to rescale the opacity-weighted colors, in a way that we specify.</p><p>Pixel output unit, which filters the contributions of many adjacent rays to produce a pixel (supersampling on the image plane) <ref type="bibr" target="#b9">[10]</ref>. It is shown that such a filtering process is equivalent to just using one ray, however taking into account higher derivative (tensor) fields, and accumulating those too. We obtain an estimate of the discrepancy between the interpolated transparency of a bundle of rays in the neighborhood of a master ray, and the transparency of the master ray. This leads to an estimate of what is a reasonable definition of a pixel size in the neighborhood of the master ray. We also prove that there is no local sample interpolation scheme that can give the same effect as filtering on the image plane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CASCADED MULTI-FIELD VOXEL DE-CODER</head><p>Traditionally, one thinks of voxel fields as intensity (of some sort) describing a volume. However, one can think of a voxel as a container of multiple fields, each describing different attributes of space. This can be multi-modal scans of a volume (CT, MRI, PET, SPECT, ultrasound) <ref type="bibr" target="#b3">[4]</ref>, category fields <ref type="bibr" target="#b2">3</ref> (from manual or (semi)automatic segmentation), rgba pixel components, edgeness fields, or different state variables in scientific visualization (pressure, density, temperature, viscosity etc. In the above, £ stands for the usual multiplication and È stands for the usual addition. However we use a special notation because we will generalize these operations in what follows. The above is a doubly infinite sum, which could be truncated given the sampling frequency of the dataset. Even if finite, the above decomposition would need to involve few terms, if it was to be useful. In what follows a scheme is proposed where one keeps a fixed number of generalized "summands", while allowing for arbitrary operations (logical or arithmetical).</p><p>The general formalism now follows: Let  operations. We denote by £ the operator that combines the Ä with Ä : Ä £ Ä Ä´ µ This means that the operator £ is really the tensor product of four operators, one for each rgba component. This scheme iteratively defines a tree, each node being the contraction of (at least) two parent nodes. A good compromise between full generality and realistic applications is achieved by considering only voxels that can have a maximum of four voxel subfields: Î Ú¿ Ú ¾ Ú ½ Ú ¼µ, each subfield having variable width. Then, a cascaded lookup table can be implemented as a binary tree:</p><formula xml:id="formula_0">Î ÚÒ ½ Ú Ò ¾ Ú ½ Ú</formula><formula xml:id="formula_1">v 0 v 1 v 2 3 v L L L L 2 1 0 3</formula><p>Ä´Î µ ´Ä¿´Ú¿µ £¿¾ Ú¾´Ú¾µµ £´¿ ¾µ´½¼µ´Ä½´Ú½ µ £½¼ Ä¼´Ú¼µµ <ref type="bibr" target="#b0">(1)</ref> As shown clearly in <ref type="figure" target="#fig_0">fig.1</ref>, The £ operators are composite operators, comprising of four component-wise operations, one for each of the color-opacity channels. Useful operators (per rgba channel) are the sixteen logical operations, and some arithmetic ones, such as multiplication, multiplication of the complements with respect to one, addition, average, minimum, maximum, among others. It is to be emphasized that such a decoding scheme has fixed grammar (nodes); therefore it is easily and efficiently implementable by hardware or by software. If the bitwidths of the lookup tables in the decoder are not all equal (asymmetric decoder), there is an extra complication: one needs to define the fields using masks on the original voxel value. This is effectively a permutation of the labels of the subfields within the voxel (note that the masks can define subfields that overlap, which is very useful for luminance-alpha volumes). It is easy to see that such a scheme can accommodate for many (if not most) cases of interest. Here we provide some examples:</p><p>In the case of rgba volumes, each voxel is of the forḿ Ö µ. The lookup tables can be arbitrary functions, and all the £ operators can be £OR ´OR ª OR ª OR ª ORµ.</p><p>Consider the case where the lookup tables do not mix color components:</p><formula xml:id="formula_2">Ä¿´Öµ ´ ¿´Öµ ¼ ¼ ¼µ Ä¾´ µ 1 ¾´ µ ¼ ¼µ Ä½´ µ 1 ¼ ½´ µ ¼µ Ä¼´ µ 1 ¼ ¼ ¼´ µµ Then Ä¿´Öµ £OR Ä¾´ µ Ä¿¾´Ö µ ´ ¿´Öµ ¾´ µ ¼ ¼µ Ä½´ µ £OR Ä¼´ µ Ä½¼´ µ 1 ¼ ½´ µ ¼´ µµ</formula><p>The final result is Ä¿¾ £OR Ä½¼ ´ ¿´Öµ ¾´ µ ½´ µ ¼´ µµ ¯Similarly, if one of the voxel fields is a segmentation field, one can use the above strategy to modify the voxel's rgba assignment by a segmentation dependent rule. For concreteness, let us consider an example: Let´× µ be a dual field, where × is a category index and an intensity index. If</p><formula xml:id="formula_3">Ä½´× ½ µ 1 ¼ ¼ ½µ Ä¼´ µ Ö µ and £½¼ ÁND ª AND ª AND ª ORµ then Ä½´× ½ µ £½¼ Ä¼´ µ Ö ¼ ¼ ½µ</formula><p>The result is that the voxels that belong to the category × ½ are made opaque, and only the red component of the voxel's classified intensity is kept. It is clear that one is limited only by one's imagination about the operators that one uses. In particular, one can perform set-theory operations (such as find the union of all segments belonging to categories ½ ¾, and make their opacity zero, i.e. make those two segments invisible.</p><p>In the case of luminance-alpha volumes, let´Ð µ be a general voxel. Then</p><formula xml:id="formula_4">Ä½´Ðµ Ö´Ðµ ´Ðµ ´Ðµ ¼µ Ä¼´ µ 1 ¼ ¼ ´ µµ Ä½´Ðµ £OR Ä¼´ µ Ö´Ðµ ´Ðµ ´Ðµ ´ µµ</formula><p>The result is a pixel value, with extra bonus that one can apply further lookups on both the luminance and opacity values.</p><p>As examples of the use of arithmetic operators, consider the following operators, which can be useful in combining two different scans of the same object together:</p><formula xml:id="formula_5">£ Ñ Ü £Ø ½ ´½ µ´½ µ</formula><p>One can use the £ operator for each color component, and the £Ø operator for the opacity: Ö½ ½ ½ ½μ £ £ £ £Øμ Ö¼ ¼ ¼ ¼µ ¯One can also combine a volume with a shadow map of the same volume (representing the illumination of the volume by arbitrary light sources). The multi-field voxel is then´× µ,</p><p>where × now stands for the shadow value, which is the opacity accumulated at the voxel position, when the volume is illuminated by the light sources. Simple shadowing can be performed by:</p><formula xml:id="formula_6">¼ 1 ×µ £</formula><p>In terms of the decoder, consider the operation £ × ´¢ ¢ ¢ ¢µ (where ¢ is the usual multiplication):</p><formula xml:id="formula_7">× Ä½´×µ 1 × ½ × ½ × ½µ Ä¼´ µ Ö µ</formula><p>and conclude that</p><p>Ä½´×µ £ × Ä¼´ µ ´´½ ×µÖ ´½ ×µ ´½ ×µ µ</p><p>Further applications include depth shading (where one is given a depth field, which can be classified and combined with other subfields, thus simulating distance dependent fog), and stress/displacement fields (where one can modulate the sample's color by the local deformation stress of the volume). Also, if one is also given the normal field magnitude data as an input to the decoder, then one can use it to further modulate the rgba above by the edgeness value. This concept can be easily generalized to providing for lighting of one or more classified fields, with subsequent combination with other classified subfield contributions.</p><p>We will not proceed further with exploring applications in the present paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Interpolation</head><p>For a given ray, one needs to partition it, and consider samples along the ray. In this section, we assume that we have somehow chosen the geometrical position of such a sample. Then there are two choices: Either interpolate (per field) all the voxel values in the neighborhood of the sample, and then apply the decoding process, or decode the voxels in that neighborhood, and interpolate the result. In either case, one would need to apply the front to back (FTB) blending equations:</p><formula xml:id="formula_8">¼ • ´½ µ<label>(2)</label></formula><p>We rewrite the above in terms of the transparency and opacity weighted colors:</p><formula xml:id="formula_9">Ì ¼ Ì Ø (3) ¼ • Ì<label>(4)</label></formula><p>Equation <ref type="formula">3</ref>is a statistical assumption, namely that the transparency at each point defines a probability distribution, and that the distributions are independent for different sample points. If the neighborhoods that one uses around each sample point for interpolations are not disjoint, this assumption is not true, and one would have to take into account the correlation matrix of the distributions at consecutive sample points. In the case that one interpolates rgba values, it has been indicated in the literature <ref type="bibr" target="#b1">[2]</ref> that one gets better images if one interpolates opacity-weighted colors, because one avoids the self-occlusion effect. Here follows a general proof of that.</p><p>Consider a ray Ö, transversing though a lattice grid. We are interested in accumulating color and opacity along this ray. This involves two steps: Choosing sample points along the ray, and for the purposes of this section we assume such a choice already given (the ramifications of such a choice will be discussed in a later section).</p><p>In order to calculate the contribution of a sample to the blending equations, we need an interpolation procedure, which takes into account voxels in the neighborhood of the sample. Therefore, blending in D dimensions is best thought of as a D-dimensional integral.</p><p>For any sample × along the ray, there corresponds a neighborhood AE´×µ, which will be used to deduce the pixel contributions of the sample to the blending equation. The motivation and physical interpretation of our approach is as follows: for each sample point, pick a voxel in its neighborhood (call it the representative of the sample). This choice has to obey the probability distribution of the interpolation measure in this neighborhood. For any such choice, calculate the accumulated color and opacity of the ray. Repeat the experiment many times, with different choices of representatives, each time calculating the accumulated color and opacity. Then, average the results, and define those averages to be the color and opacity accumulated along the ray. This process is very common in modern theoretical physics <ref type="bibr" target="#b13">[14]</ref>. It has also been explored in a somewhat different context in <ref type="bibr" target="#b6">[7]</ref>. Referring to <ref type="figure" target="#fig_1">fig.2</ref>, we show a ray, as it crosses six non-intersecting neighborhoods. For each of these neighborhoods, we have a well defined probability, as given by the (normalized) distance of each of the (two) voxels to the sample point (which is, in this case,the intersection of the ray with the neighborhood). Due to the statistical independence of the neighborhoods, the probability of a given choice of representatives for all the neighborhoods (choice function), is just the product of the individual probabilities. We proceed with the formalism: we are given a ray Ö, and a collection of uniformly spaced samples along it, enumerated by × ¾ ¼ Ë . For each sample ×, we consider given a bounded interpolation neighborhood AE´×µ consisting of the voxels of which will be used to determine the pixel value at the sample position. Assume that × × ¼ µ AE´×µ AE´× ¼ µ 4</p><p>Assume a normalized measure of integration × on each neighborhood AE´×µ given. This measure can be used to define interpolation averages on that neighborhood:</p><formula xml:id="formula_11">× AE´×µ ×<label>(6)</label></formula><p>Consider the space¨Ö of all choice functions × AE´×µ.</p><p>Clearly, for each such choice of function, we can define the quantities:</p><formula xml:id="formula_12">Ì ´×µ × Ô ¼ Ø´ ´Ôµµ (7) ´×µ × Ô ¼ ´ ´ÔµµÌ ´× ½µ<label>(8)</label></formula><p>Those quantities involve only voxel positions, and they are therefore known a priori (without interpolation). Consider the measure induced on¨Ö by the product of the measures on each neighborhood:</p><formula xml:id="formula_13">¨ × ¼ ×<label>(9)</label></formula><p>4 This is an assumption, that a given interpolation scheme might, or might not, satisfy.</p><p>Clearly, we should define the transparency and color accumulated along the ray as the Monte Carlo average (functional integral) over the space¨Ö, using the above measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ì×</head><p>Ì ´×µ ¾¨Ö × ´×µ ¾¨Ö <ref type="bibr" target="#b9">(10)</ref> With the definitions above, we now proceed to prove that:</p><p>Theorem 1 The color and transparency accumulated along the ray can be determined using the iteration equations:</p><formula xml:id="formula_14">Ì×•½ Ì× Ø ×•½ ×•½ ×• ×•½ Ì×<label>(11)</label></formula><p>Proof:</p><p>We first write the invariant definitions above in a more explicit way.</p><p>We introduce a shorthand notation for the choice function; for sam-</p><formula xml:id="formula_15">ple ¾ ¼ × • ½ , let ¾ AE´ µ be its representative. Then ×</formula><p>is a discrete probability measure:</p><formula xml:id="formula_16">¾AE´×µ Ô×´ µ × Ô×´ ×µ ½<label>(12)</label></formula><p>and averages are defined by</p><formula xml:id="formula_17">× ¾AE´×µ Ô×´ µ ´ µ × Ô×´ ×µ ´ ×µ<label>(13)</label></formula><p>Then it easily follows:</p><formula xml:id="formula_18">Ì×•½ ¼ ×•½ ×•½ ¼ Ô´ µ ×•½ Ð ¼ Ø´ Ð µ Ì× Ø ×•½ (14) Similarly ×•½ ¼ ×•½ ×•½ ¼ Ô´ µ ´× • ½ µ ¼ ×•½ ×•½ ¼ Ô´ µ´ ´×µ • ´ ×•½µÌ ´×µµ × • ×•½ Ô´ ×•½µ ´ ×•½µµÌ× ×• ×•½ Ì×<label>(15)</label></formula><p>This concludes the proof. Equation <ref type="bibr" target="#b10">(11)</ref> above proves that in the case of classification before interpolation one should interpolate £ per sample point, as has been speculated in the past. The above arguments are independent of the interpolation scheme, as long as the interpolation neighborhoods around the samples do not overlap. In the general case, the argument above is only approximate. It is intuitively clear however that interpolating is much more mathematically sound than interpolating . Furthermore, we note that interpolating , is equivalent to saying that</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>£ £</head><p>This is clearly incorrect, because the color components and the opacity are derived by applying transfer functions (or a general decoder) on the same voxel value spatial distribution, which means that in general they are statistically correlated. We conclude this section with a 'philosophical' statement. When one interpolates after classification, one is guaranteed to obtain a smoother image (in particular, less aliasing artifacts). If one interpolates before classification, one might get artifacts that are due to the non-convexity of the transfer functions. As a numerical example, consider the transition (at the boundaries of an object) between empty space (voxel value Ú Ñ ¼), to a fixed value, say Ú Ó ½¼¼. Say that Ä´Ú Ó µ ´½ ¼ ¼ ½µ Ä´Ú Ñµ ´¼ ¼ ¼ ¼µ Ä´´Ú Ó • Ú Ñµ ¾µ ´¼ ½ ¼ ½µ. If one interpolates after classification, one would obtain a pale red at the boundaries, whereas if one interpolates before classification one would obtain green color (artifact) at the boundary. In general, it is much safer to interpolate pixel values after classification. The classification after interpolation path imposes non-local constraints, i.e. the pixel value of the sample is determined only by the average voxel value in the sample's neighborhood, independent of the variance of the voxel value there. For example, neighborhood voxel values ¼ ¾ ¼ and ½½ ½¾¾ would be mapped to the same pixel value (if one classified after interpolation), which is usually unreasonable. For the same reason, the classification after interpolation path is more sensitive to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NORMAL WEIGHTED MODULATION (NWM) OF COLOR (LIGHTING) AND OPACITY</head><p>Given the decoder's output <ref type="bibr" target="#b4">5</ref> , one can apply one's favorite lighting equation, and also perform edge-weighted modulation of the opacity. In this section we address the issue of how to modify the lighting equation, under the assumption that one knows the interpolated opacity weighted color, and the interpolated opacity. Therefore it is of interest to rewrite the lighting and edge-weighting equations using only those variables.</p><p>In general we consider functions of the form ´Ü µ, where Ü is a positive number and is a boolean variable.</p><p>´Ü trueµ ´Üµ ´Ü falseµ ½ ½</p><p>We define, as usual, the normal vector using the gradient of one of the voxel subfields:</p><formula xml:id="formula_19">Ò ÖÚ Ò Ò Ò Ò Ò</formula><p>We also define the auxiliary modulation quantities:</p><formula xml:id="formula_20">Å ¾´Ò× ¼ µ • Á Ò× ¿´Ò× ¼¼ µ (16) Å×Ô ×ÔÁ×Ô Ò× ´Ò× ¼¼¼ µ<label>(17)</label></formula><p>Then, it follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2 The normal weighted modulation equations expressed in terms of the variables</head><p>× are:</p><formula xml:id="formula_21">AE Ï Å × ½´Ò× µ × (18) AE Ï Å × Å × •Å×Ô ×Ô ×<label>(19)</label></formula><p>Equation (19) was derived by multiplying the usual expression for illumination of color components by equation (19). This multiplication is to be understood to take place before the interpolation, as explained in the previous section. Note that in equation (19) we allowed for edge-weighting the terms individually, allowing only terms linear in the length of the voxel value gradient. The physical assumption here is that the emissive, diffuse and specular components of the equation can be individually affected by the local edgeness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">MULTI-RESOLUTION INTEGRATION ALONG RAYS</head><p>There are two "canonical" ways of doing raytracing. Either always (independent of the view angle) have fixed step per ray, or not. The second case arises when one changes the sampling frequency along the ray, or in (orthographic, for simplicity) shear-warp ray tracing, where the distance between samples is view-dependent. If one does not compensate for the non-constancy of the distance between samples in the situations above, one would see that the the color of the rendered image changes. The solution of this problem usually goes by the name of alpha correction. Here the issue is revisited, in light of the £ interpolation. We will prove that: The argument simplifies in the continuum limit, so we rewrite eqs.</p><p>(27) as an integral along a ray Ö, parametrized by (where the "eye"</p><p>is positioned at</p><formula xml:id="formula_22">¼ ): Ì´ µ ÜÔ ¼ ¼ ÐÒ Ø´ ¼ µ<label>(28)</label></formula><p>The integral in the equation above is to be understood as a shorthand for the discrete sum. If taken seriously as an integral, then it is clear that it is equivalent to the usual integral only in first order (with respect to the opacity distribution) <ref type="bibr" target="#b5">6</ref> . This is not surprising, because the transition from a discrete equation to a continuum one is not uniquely defined. Equation (28) has the property that if the transparency of a sample is zero, then the accumulated transparency there becomes zero also: We see that reparametrization invariance of the accumulated transparency results in modifying the transparency locally, by exponentiation according to the local change of scale. This is the generalization of the known result, where ¼ Ñ , with Ñ being a constant (which depends on the view angle (for shear-warp) and the supersampling (along the ray) ratio). This proves (21). In the above equation we alpha-correct the opacity derived from the interpolated voxel value (as opposed to interpolating the alpha-corrected opacities for each voxel in the neighborhood of the sample). We do this is because the alpha correction arises from the change measure of integration along the ray; therefore one has to assume that the sample values are given and then alpha correct them. The color of the sample is not affected by this (local) change of scale, as is well known. The simplest way to prove this is noting that the usual color accumulation equation can be understood as a Stieljes-Lebesgue integral <ref type="bibr" target="#b6">7</ref> with scale invariant measure, and locally constant color. This proves (22). The philosophy behind the alpha correction is that the ray segment stretches, therefore the "density" of the material there changes; however the material itself does not get affected.</p><formula xml:id="formula_23">Ö ¿ ¼ Ø´ ¼µ ¼ µ Ì´ ¼µ ¼</formula><p>Interpolating opacity weighted colors introduces a minor complication, which we now turn to. One can define as the effective sample's color</p><formula xml:id="formula_24">× £ × × if × ¼ ¼ otherwise (31)</formula><p>In this expression it is clear that the self occlusion effect is avoided, because voxels in the neighborhood of the sample that are transparent do not contribute to the effective color of the sample. As we already showed, the sample's color is not affected by changing the scale (this holds true even if the change of scale is local): × × . Therefore:</p><formula xml:id="formula_25">£ × × £ × × £ Ñ´ ×µ £ × £ Ñ´ ×µ ×<label>(32)</label></formula><p>This proves (23). Note that the function Ñ´Üµ has a well defined limit (equal to Ñ) at Ü ¼. This concludes the proof of Thm. 3.</p><p>In real life, in supersampling or in subsampling, the locally constant color and opacity assumption is of course not satisfied. One should still use the same renormalization equations, with the understanding that this introduces an error. The error analysis is straightforward. Here we will make some comments of some theoretical interest, along these lines. The alpha correction equation has interesting convexity properties. Consider a ray segment Ö, of length Ð, and denote by Ö averages of functions defined on the ray. Then one can prove that Ì´Öµ ÜÔ´ ÐÒ Ø Ö Ðµ ÜÔ´ÐÒ Ø Ö Ðµ Ø Ð Ö (33) <ref type="bibr" target="#b6">7</ref> This can be viewed as a shorthand notation for ¼ ´ ¼ µ.</p><p>In the above equation we used Jensen's inequality, which is a fancy way of saying that the logarithm is a convex down function. Therefore we proved that:</p><p>Theorem 4 The transparency accumulated on a ray segment is less than or equal to the transparency that would be accumulated on the ray segment if it was uniform (with transparency equal to the average transparency of the given distribution).</p><p>This observation is fundamental because any continuum integral is defined in terms of a partition of its domain, in the limit that the mesh of the partition goes to zero. We see that as we make the mesh finer (by adding points to the current partition of the ray), the argument above shows that the value of the accumulated transparency (under the assumption that each bin is uniform, with value equal to its true average) becomes less and less, and this process converges by definition to the transparency accumulated on the original continuum ray.</p><p>As an application of this, we consider the effect of supersampling along a ray. Consider a cell defined by two neighboring voxels (assume a one dimensional ray, for simplicity), with transparencies Ø½ Ø ¾. Further consider AE samples between them, such that each bin of the partition has equal length. The interpolated values at each sample point are:</p><formula xml:id="formula_26">Ø´ AEµ AE • ½ Ø½ • ½ AE • ½ µØ¾ ¾ ½ AE (34) They satisfy ½ AE AE ½ Ø´ AEµ Ø½ • Ø¾ ¾ AE ½<label>(35)</label></formula><p>therefore Thm. 4 is applicable. The contribution of those AE samples to the transparency and color accumulation equations, Ì cell´AE µ and cell´AE µ respectively, is</p><formula xml:id="formula_27">Ìc´AEµ AE ½ Ø´ AEµ ½ AE (36) c´AE µ AE ½ ´ AEµ Ñ´ ´ AEµµ ½ Ð ½ Ø´Ð AEµ ½ AE (37)</formula><p>We focus on the transparency. From Thm. 4 follows that:</p><formula xml:id="formula_28">¼ Ð Ñ AE ½ Ìc´AEµ Ìc´AEµ Ìc´¾µ Ìc´½µ</formula><p>For convenience introduce the shorthand notation for the ratio:</p><formula xml:id="formula_29">´AEµ Ìc´AEµ Ìc´AE • ½ µ ´AEµ ½ AE</formula><p>Numerical simulations indicate that the convergence is pretty fast.</p><p>In particular, for all values of Ø½ Ø ¾ one obtains the following rough upper bounds:</p><p>´½µ ½ ¼ ´¾µ ½ ¼¿ ´¿µ ½ ¼¾ ´ µ ½ ¼½</p><p>and similar values for the color. In real life applications, subsampling a dataset as to increase the interactivity leads only to a loss of detail in the image, but not to a dramatic change in the bulk color of it. Similarly, supersampling of a dataset, with no lighting, again does not in general lead to any dramatic changes (which is understandable anyway, since supersampling a given volume does not really result to any increase of the information content). However, when lighting is enabled, supersampling can lead (if visualization parameters are chosen appropriately) to more pleasing results, i.e. better emphasis of surfaces (since one has more samples in the vicinity of the surface).</p><p>In concluding this section, we would like to make a couple of points. First, in single-field voxel visualization one traditionally absorbs the change of scale in the lookup tables. In the multi-field visualization case, it would be incorrect in general to modify all the corresponding lookup tables and use the same operators to combine them. The philosophical statement here is that the decoder has the responsibility of determining a sample's rgba. This process is interpolation and classification (in either order), and it doesn't have anything to do with integration along the ray. Therefore, for multifield visualization, it is imperative to use the alpha correction as part of the compositing unit. A similar argument applies to the calculation of the local normal. Such a calculation could be performed on the opacity value, or on the voxel value. This is again a local (derivative) operation that does not have anything to do with integration along the ray. Therefore, if one wanted to calculate normals as gradients of opacity, one would have to use the original (non alpha corrected) opacity.</p><p>Second, the convexity argument of eq. (33) applies to the case of classification before interpolation. In the case of classification after interpolation (i.e. we find the voxel value per sample, by interpolating each of the fields of the voxels in the neighborhood, and then we apply the decoder on that voxel value) one cannot make a general statement. However, in the case where the transparency transfer function is convex-down (at least in the range of the voxel values that are relevant in the neighborhood of the samples of interest along the ray), then theorem 4 still applies. The reason is that the logarithm is a convex-down function, and the composition of two convex-down functions is convex-down. For illustration of the argument, consider samples of voxel values Ú½ Ú ¾, and the sample of voxel value ½ ¾´Ú ½ • Ú¾µ, which one would use if one raytraced along that ray segment with a subsampling factor of two. Then:</p><formula xml:id="formula_30">½ ¾´Ð Ò Ø´Ú½µ • Ð Ò Ø´Ú¾µµ ÐÒ Ø´Ú½µ • Ø´Ú¾µ ¾ ÐÒ´Ø´Ú ½ • Ú¾ ¾ µµ</formula><p>In the equation above, the first inequality comes from the fact that the logarithm is convex-down, and the second inequality comes from the assumption that the transparency transfer function is convex-down. Exponentiating the above, one indeed obtains that Ø´Ú½µ ½ ¾ Ø´Ú¾µ ½ ¾ Ø´Ú ½ • Ú¾ ¾ µ as advertised above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SUPERSAMPLING ON THE IMAGE PLANE</head><p>In a previous section we investigated how the line integral changes if one changes the unit of length along a given ray. In this section we study how the visualization changes, depending on the frequency that one samples the image plane. The guiding principle is that the quantum of area on the image plane should be such that if one considers many rays within the pixel, and filters their pixel values, one should get a similar result (within a set threshold).</p><p>Consider a ray Ö, parametrized by ÜÖ´×µ, where s is the length along the ray. Let ×´Öµ be the total length of the ray. Here we will only deal with the orthographic case, where the ray is a straight line along the z-axis, and all rays are parallel to each other. Given a displacement vector Û on the image (xy) plane, one can consider the ray Ö • Û, which is simply the translation of all points of the initial master ray by Û (see <ref type="figure" target="#fig_2">fig. 3</ref>). Let Ì´Ö • Ûµ denote the transparency accumulated along that ray, as usual. Let AE´Öµ be a tubular neighborhood of the ray Ö, meaning a collection of Ûs, which define an 000000000000 000000000000 000000000000 000000000000 000000000000 000000000000 111111111111 111111111111 111111111111 111111111111 111111111111 111111111111 000000000000 000000000000 000000000000 000000000000 000000000000 000000000000  Equation (40) is a remarkable result. It explicitly collapses the accumulated opacity contributions of a tubular neighborhood of a given ray to a line integral along the ray. The new result is proportional to the old one, and the multiplicative modification depends on higher order derivatives transversely to the ray. Furthermore, (40) provides us with a measure of the ratio of the transparency of a pixel as calculated with supersampling on the image plane over the transparency as calculated using one ray only. If this ratio is not approximately equal to one, this means that one should shoot more rays in the vicinity of that ray. Assuming eqs. (38) and (39), one can easily prove: and we see that the gradient of the transparency does not contribute in the right hand side of (43), although we have already seen that it contributes in the left hand side.</p><formula xml:id="formula_31">Theorem 5</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>In this paper we presented a rigorous discussion of the mathematics of ray tracing. Our focus was multi-modal and multi-resolution invariant visualization. The concept of a general voxel decoder was introduced, which accommodates most if not all applications that are currently considered as important. We introduced the concept of functional integration, as the unifying principle between sample classification, interpolation and blending. Using this, we proved in general that one should interpolate opacity weighted colors. The lighting equation was rewritten as to use the opacity-weighted colors. When multi-resolution considerations are important (as is the case in shear-warp raytracing and in supersampling along the rays) we proved that one should correct (renormalize) the interpolated opacity and the interpolated opacity-weighted colors (as opposed to interpolating the renormalized opacities and opacity-weighted colors), and we provided the necessary equations. We investigated issues pertaining to interpolation/classification order, from the point of view of the convexity of the transfer functions and the convexity properties of the blending process. Finally, we considered supersampling along the image plane (in orthographic), and we proved that the effect of filtering the supersampled image is equivalent to a modified blending equation, which also takes into account the accumulation of auxiliary tensor fields. We also proved that, in the continuum limit, and for cylindrically symmetric weight functions, filtering on the image plane is not equivalent to any local sample interpolation scheme. Furthermore, we provided a condition that partially answers the question if one needs to cast more (or less) rays in the vicinity of a given ray (i.e. what is a reasonable definition of local pixel area).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Fixed grammar variable width cascaded decoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Non-intersecting interpolation neighborhoods along a ray, and two different paths (choice functions). The representatives are denoted by AE, ¢ respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Bundle of rays in the neighborhood N(r) of ray r. open set on the image plane. We introduce the quantity Ì´AE´Öµµ ¾ ÛÔ´ ÛµÌ´Ö • Ûµ which represents an interpolation of all the transparency contributions of all the rays in the tubular neighborhood, according to probability distribution Ô. The problem at hand is to find an analytic expression for this quantity, and compare it with the transparency attributed to only the ray Ö. Let the probability distribution be a 2d Gaussian filter: Ô´ Ûµ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Theorem 3</head><label>3</label><figDesc>Let Ñ be the local change of scale, around a sample × of a ray. In the discrete sampling limit, Ñ ½ means that we collapse Ñ identical samples to one, and ½ Ñ ½ means that we expand one sample to Ñ identical samples.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">The total accumulated</cell></row><row><cell cols="6">opacity and color are invariant under this operation, provided that</cell></row><row><cell cols="4">the following renormalizations are applied:</cell><cell></cell><cell></cell></row><row><cell>Ø ×</cell><cell></cell><cell>Ø Ñ ×</cell><cell></cell><cell></cell><cell>(20)</cell></row><row><cell>×</cell><cell></cell><cell>Ñ´</cell><cell>×µ</cell><cell></cell><cell>(21)</cell></row><row><cell>×</cell><cell></cell><cell>×</cell><cell></cell><cell></cell><cell>(22)</cell></row><row><cell>×</cell><cell></cell><cell cols="2">× Ñ´</cell><cell>×µ</cell><cell>(23)</cell></row><row><cell cols="6">The alpha correction functions appearing above are defined as fol-</cell></row><row><cell>lows:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ñ´</cell><cell>×µ</cell><cell cols="2">½ ´½</cell><cell>×µ Ñ</cell><cell>(24)</cell></row><row><cell>Ñ´</cell><cell>×µ</cell><cell>Ñ´</cell><cell>×</cell><cell>×µ</cell><cell>(25)</cell></row><row><cell cols="6">The solution of the usual transparency accumulation equation is</cell></row><row><cell></cell><cell></cell><cell>Ò</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Ì´Òµ</cell><cell cols="2">Ø´ µ</cell><cell></cell><cell>(26)</cell></row><row><cell></cell><cell></cell><cell>½</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Therefore</cell><cell></cell><cell>Ò</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Ì´Òµ</cell><cell>ÜÔ</cell><cell cols="2">ÐÒ Ø´ µ</cell><cell>(27)</cell></row><row><cell></cell><cell></cell><cell>½</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>does not accumulate to zero, even if all the opacities (absorption coefficients) along the ray are equal to one! Therefore (28) should be preferred over (29). Clearly, when one changes the parametrization along the ray, one should get the same result, because the physics of the problem should not depend on the parametrization along the ray. Let ¼ ¼´ µ be a change of variables in the integral. Then</figDesc><table><row><cell>where the transparency Ì ÜÔ Ö ¼ ¼ ÐÒ Ø´ ´ ¼ µµ ÜÔ</cell><cell>Ö</cell><cell>¼ ÐÒ´Ø´ ¼ µ ¼ µ (30)</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">This is in sharp contrast to the usual continuum limit</cell></row><row><cell></cell><cell></cell><cell>Ì´ µ ÜÔ´</cell><cell>¼</cell><cell>¼ ´ ¼ µµ</cell><cell>(29)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>AE´Öµ is a disc of radius ¿ . Furthermore, from (28) Ö Û denotes the gradient along the image plane, Å Û denotes the 2x2 block of the Hessian (of the logarithm of the transparency) along the image plane ÐÒ Ì´Öµµ¡´Á Î Å Öµ ½ ¡Ö Û ÐÒ Ì´Öµ (40)where Î ×´Öµ ¾ . As a sanity check, it is clear that if the transparency values transversely to the ray are uniform, or if ¼,</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>½ ¾ ¾</cell><cell>Û¡ Û ¾ ¾</cell><cell>(38)</cell></row><row><cell cols="3">so that Ì´Ö • Ûµ</cell><cell>Ê Ö• Û ÐÒ Ø´ ÜÖ´×µ• Ûµ ×</cell></row><row><cell cols="4">We now use the Taylor expansion of the logarithm of the trans-</cell></row><row><cell cols="4">parency function, to second order in Û:</cell></row><row><cell cols="2">ÐÒ Ø´ ÜÖ´×µ • Ûµ</cell><cell cols="2">ÐÒ Ø´ ÜÖ´×µµ • Û ¡ Ö Û ÐÒ Ø´ ÜÖ´×µµ • • ½ ¾ Û ¡ Å Û´ ÜÖ´×µµ ¡ Û (39)</cell></row><row><cell cols="3">Å ´ ÜÖ´×µµ</cell><cell>ÐÒ Ø ÜÖ´×µ</cell><cell>½ ¾</cell></row><row><cell cols="4">Collecting terms and performing the Gaussian integration 8 , one</cell></row><row><cell>obtains that</cell><cell></cell><cell></cell></row><row><cell>Ì´AE´Öµµ</cell><cell>¢</cell><cell cols="2">Ì´Öµ´ Ø´½ Î Å Öµµ ½ ¾ ¢ ¾ ¾ Ö Û</cell></row></table><note>wherethen Ì´AE´Öµµ Ì´Öµ.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>An upper bound Ëmax ¾ max´Ö µ, to the local pixel surface area around a given ray Ö, is given by solving the following Indeed, since by assumption Ô´ Ûµ Ô´ Ûµ, it follows by symmetry that Õ´ Ûµ Õ´ Ûµ.</figDesc><table><row><cell cols="2">eigenvalue equation:</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Ø´½ 2x2</cell><cell cols="3">¾ max´Ö µ×´Öµ Å Ö µ ¼</cell><cell>(41)</cell></row><row><cell cols="2">In particular,</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">¾ max´Ö µ</cell><cell>×´Öµ</cell><cell>½ Å Ö</cell><cell>(42)</cell></row><row><cell>where</cell><cell cols="4">Å Ö is the norm of the matrix Å Ö .</cell></row><row><cell cols="4">Finally, it also easily follows that:</cell></row><row><cell cols="5">Theorem 6 Image plane filtering is inequivalent to sample inter-</cell></row><row><cell cols="5">polation. In particular, for all probability distributions Õ´Ûµ: Ì´AE´Öµµ Ê Ö ÐÓ Ê ¾ ÛÕ´ÛµØ´ ÜÖ´×µ• Ûµ</cell><cell>(43)</cell></row></table><note>Therefore ¾ Û ÛÕ´ Ûµ ¼</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The reason for that is that there is no a priori notion of linear interpolation of segmentation fields, unless if one knows a priori (by construction) that the category field assignment is somehow monotonic.2 This is the conventional notation, instead of the cumbersomeR,G,B,C.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">In general, one could also embed the NWM unit within the decoder, which would allow for combining lit pixel values, according to logical or arithmetic operations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">ÐÓ ´½ µ.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">We assume that the Ûs span a neighborhood of radius at least ¿ , in which case we approximate the bounded integral with an infinite one.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGEMENTS</head><p>I would like to thank my colleagues in the Volume Graphics Group of Mitsubishi Electric for creating a very stimulating environment.</p><p>In particular the present work was influenced by stimulating discussions with Dr. L. Seiler on the topic of multi-scale interpolation. Also, thanks to Vikram Simha for introducing the concept of cascaded lookup for dual modality visualization to me, and to Dr. T.C. Zhao for providing valuable comments, and for reading the manuscript from a fellow physicist's perspective.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Compositing Digital Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="259" />
			<date type="published" when="1984-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Opacity-Weighted Color Interpolation for Volume Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malzbender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wittenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Volume Visualization Symposium/IEEE Visualization 98</title>
		<meeting>Volume Visualization Symposium/IEEE Visualization 98</meeting>
		<imprint>
			<date type="published" when="1998-10" />
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast Volume Rendering Using a Shear-Warp Factorization of the Viewing Transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lacroute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="458" />
			<date type="published" when="1994-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Visualization of Multimodality Medical Volume data using Object-Oriented Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zuiderveld</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
		<respStmt>
			<orgName>Utrecht University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D Thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semi-Automatic Generation of Transfer Functions for Direct Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Durkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization, ACM SIGGRAPH 98</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using Distance Maps for Accurate Surface Representation in Sampled Volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization, ACM SIGGRAPH 98</title>
		<imprint>
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Rendering Equation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kajiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH 86 Conference Proceedings</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="143" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Illumination for computer generated pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Phong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rendering of surfaces from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="28" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Computer Graphics-Principles and Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Hughes</surname></persName>
		</author>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, Massachusetts</pubPlace>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A hybrid ray tracer for rendering polygon and volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adding Shadows to a Texture-Based Volume Renderer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Volume Visualization, ACM SIGGRAPH 98</title>
		<imprint>
			<biblScope unit="page" from="39" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Introduction to Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lichtenbelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Naqvi</surname></persName>
		</author>
		<imprint>
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Quantum Many-Particle Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Negele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Orland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Physics Lecture Note Series</title>
		<imprint>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The VolumePro Real-Time Ray-Casting System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hardenbergh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knittel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">To Appear in Proceedings of SIGGRAPH 99</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
