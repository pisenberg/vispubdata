<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ACE: A Fast Multiscale Eigenvectors Computation for Drawing Huge Graphs *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
							<email>yehuda@wisdom.weizmann.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Applied Mathematics</orgName>
								<orgName type="institution">The Weizmann Institute of Science</orgName>
								<address>
									<settlement>Rehovot</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liran</forename><surname>Carmel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Applied Mathematics</orgName>
								<orgName type="institution">The Weizmann Institute of Science</orgName>
								<address>
									<settlement>Rehovot</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Harel</surname></persName>
							<email>harel@wisdom.weizmann.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Applied Mathematics</orgName>
								<orgName type="institution">The Weizmann Institute of Science</orgName>
								<address>
									<settlement>Rehovot</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ACE: A Fast Multiscale Eigenvectors Computation for Drawing Huge Graphs *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>algebraic multigrid</term>
					<term>multiscale/multilevel optimization</term>
					<term>graph drawing</term>
					<term>generalized eigenvalue problem</term>
					<term>Fiedler vector</term>
					<term>force directed layout</term>
					<term>the Hall energy</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We present an extremely fast graph drawing algorithm for very large graphs, which we term ACE (for Algebraic multigrid Computation of Eigenvectors). ACE exhibits an improvement of something like two orders of magnitude over the fastest algorithms we are aware of; it draws graphs of millions of nodes in less than a minute. ACE finds an optimal drawing by minimizing a quadratic energy function. The minimization problem is expressed as a generalized eigenvalue problem, which is rapidly solved using a novel algebraic multigrid technique. The same generalized eigenvalue problem seems to come up also in other fields, hence ACE appears to be applicable outside of graph drawing too.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A graph is a structure G(V, E), with V = {1, . . . , n} a set of n nodes, and E a set of weighted edges, w ij being the weight of the edge connecting nodes i and j. Many datasets are given in the form of pairwise similarities between entities. Identifying these similarities with the weights, such data are naturally represented as graphs, and their visualization can be carried out using graph drawing techniques.</p><p>In a very general sense, we expect the drawing of a graph to visually capture its inherent structure. Interpreting this vague desire into strict well-defined criterion for the purpose of assessing the quality of a drawing can be done in various ways, leading to many approaches to graph drawing <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">14]</ref>. One of the most popular approaches is to define an energy function (or a force model), whose minimization determines the optimal drawing. In this paper we concentrate on one particular form of an energy function, characterized by being simple and smooth, thus enabling rigorous analysis and a straightforward implementation. This particular function was first applied to graph drawing by Hall <ref type="bibr" target="#b11">[9]</ref>, and we therefore term it Hall's energy.</p><p>Most graph drawing methods suffer from lengthy computation times when applied to really large graphs. Several publications in the graph drawing conference of 2000 <ref type="bibr" target="#b12">[10,</ref><ref type="bibr" target="#b23">21,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b20">18]</ref> present fast graph drawing algorithms, but even the fastest of them ( <ref type="bibr" target="#b23">[21]</ref>) requires about 10 minutes for a typical 10 5 -node graph. In fact, a naive implementation of the minimization of Hall's energy would also encounter real difficulties on a 10 5 node graph. Recently, we have been able to achieve computation times comparable to ACE <ref type="bibr" target="#b13">[11]</ref>, using a different approach to graph drawing.</p><p>In this paper we suggest an extremely fast algebraic multigrid (AMG) implementation for minimizing Hall's energy (see <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">20]</ref> for information on AMG algorithms). It results in typical computation times of 10-20 seconds for 10 6 -node graphs. Furthermore, the problem that we will be solving is of more fundamental nature, and our algorithm can be used in areas outside of graph drawing, such as clustering, partitioning, ordering, and image segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Minimization Problem</head><p>A graph is uniquely described by the Laplacian, which will be proved to be a key feature of ACE: Definition 2.1 (Laplacian) Let G(V, E) be a graph. The Laplacian of the graph is the symmetric n × n matrix</p><formula xml:id="formula_0">L ij = n k=1 w ik i = j −w ij i = j i, j = 1, . . . , n.</formula><p>It can be easily seen that for the commonly encountered graphs, in which all the weights are non-negative, w ij ≥ 0, the Laplacian is positive semi-definite. A key observation of our work is that nice drawings are feasible if the Laplacian is positive semi-definite, regardless of the sign of the weights. Hence, we define a more general entity, that we shall be calling a PSD graph: 2. E is a set of weighted edges, such that the Laplacian of G is positive semi-definite.</p><p>3. M is a set of n strictly positive masses, m i being the mass of the i'th node.</p><p>We would like to dwell upon two notable features of a PSD graph. First, it contains node masses. Second, we permit negative edge weights, as long as the Laplacian remains positive semi-definite. Positive weights are interpreted as measuring the similarity between pairs of nodes, and negative ones measure dissimilarity -the larger the absolute value of −w ij the more dissimilar are nodes i and j.</p><p>Consequently, in the drawing we would expect nodes connected by large positive weights to be close to each other, and those connected by large negative weights to be distantly located. For later use, let us arrange the masses in the diagonal mass matrix M , with M ii = m i . Since it is obvious that both the Laplacian L and the mass matrix M completely define a PSD graph, we will freely use both G(V, E, M) and G(L, M ) to symbolize a PSD graph.</p><p>A reasonable approach to draw such a graph in onedimension would be to solve the constrained minimization problem</p><formula xml:id="formula_1">min x x T Lx<label>(1)</label></formula><p>given</p><formula xml:id="formula_2">x T Mx = 1 in the subspace x T M • 1 n = 0,</formula><p>where</p><formula xml:id="formula_3">x = (x 1 , . . . , x n )</formula><p>T is the vector of node coordinates. Here, the energy function to be minimized is the <ref type="bibr" target="#b1">2</ref> , which was first introduced by Hall <ref type="bibr" target="#b11">[9]</ref>. The positive semidefiniteness of the Laplacian assures that E(x) ≥ 0 for any drawing and any graph, thus guaranteeing the existence of a global minimum to the problem. The constraint x T Mx = 1 poses an overall scaling to the drawing. For, if x 0 is a minimizer of (1) with energy E 0 = x T 0 Lx 0 , then √ cx 0 (with energy cE 0 ) will be a minimizer of the same problem but with the constraint x T Mx = c. The constraint x T M • 1 n = 0, with 1 n being the n-vector (1, . . . , 1) T , limits us only to solutions that obey i m i x i = 0, thus avoiding the degenerate solution of putting all the nodes at the same location.</p><formula xml:id="formula_4">Hall energy E(x) def = x T Lx = 1 2 n i,j=1 w ij (x i − x j )</formula><p>In the full version of the paper, <ref type="bibr" target="#b17">[15]</ref>, we show that problem (1) is closely related to the generalized eigenvalue problem of (L, M ), Lu = µM u. Thus, it will be called hereinafter the generalized eigenprojection problem. L being positive semi-definite and M being positive definite leads to the generalized eigenvalues being non-negative, and to the existence of real M -orthonormal generalized eigenvectors. Throughout the paper we will use the convention µ 1 ≤ µ 2 ≤ . . . ≤ µ n for the generalized eigenvalues of (L, M ), and denote the corresponding real Morthonormal eigenvectors by u 1 , u 2 , . . . , u n . The vector u 1 = α1 n , which corresponds to µ 1 = 0, is the degenerate solution, which is forbidden by the second constraint. It is shown in <ref type="bibr" target="#b17">[15]</ref> that the generalized eigenprojection problem (1) is solved by u 2 , the lowest positive generalized eigenvector of (L, M ), and that the Hall energy at the minimum is just µ 2 . The subsequent local minima of (1) are obtained at u 3 , u 4 , . . ., with the corresponding energies µ 3 , µ 4 , . . .. If it is desired to plot the graph in a higher dimension, subsequent generalized eigenvectors may be taken. Thus, a 2-D drawing is obtained by taking the x-coordinates of the nodes to be given by u 2 , and the y-coordinates to be given by u 3 .</p><p>The special case analyzed by Hall <ref type="bibr" target="#b11">[9]</ref>, is obtained by taking graphs with positive weights and unit masses. In this case the vector u 2 , also known as the Fiedler vector, is of fundamental importance to many fields besides graph drawing. Another special case is taking the mass m i as the degree of the i'th node. Later, we show results of data drawn in this way. For more information, see <ref type="bibr" target="#b18">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The ACE Algorithm</head><p>Calculating the first few generalized eigenvectors of (L, M ), is a difficult task that presents a real problem for standard algorithms when n becomes around 10 5 . We suggest an algorithm that computes it very rapidly. ACE employs a technique common to the so-called algebraic multigrid (AMG) algorithms. These algorithms progressively express an originally high-dimensional problem in lower and lower dimensions, using a process called coarsening. On the coarsest scale the problem is solved exactly, and then starts a refinement process, during which the solution is progressively projected back into higher and higher dimensions, updated appropriately at each scale, until the original problem is reproduced. An AMG algorithm should be specifically designed for a given problem, so that the coarsening process keeps the essence of the problem unchanged, while the refinement process needs only fast updates to obtain an accurate solution at each scale.</p><p>As far as we know, this is the first time that a formal and rigorous AMG algorithm is developed for graph drawing. Several authors, including works from our own group, have designed "heuristic" multiscale/multilevel graph drawing algorithms, i.e., algorithms in which the relationship between the problems on the different scales is not rigorously defined; see <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">10,</ref><ref type="bibr" target="#b23">21,</ref><ref type="bibr" target="#b5">6]</ref>. Another important heuristic multiscale algorithm, from which we draw some of our inspiration, was developed by Barnard and Simon <ref type="bibr" target="#b0">[1]</ref>. It computes the Fiedler vector for use in the partitioning problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Coarsening Process</head><p>Let G be a PSD graph containing n nodes. A single coarsening step would be to replace G with another PSD graph G c containing only m &lt; n nodes (typically, m ≈ matrix A that interpolates m-dimensional vectors y ∈ R m into n-dimensional ones x = Ay. If y is a solution of the generalized eigenprojection problem of G c , a good interpolation matrix is one for which x = Ay is close enough to a solution of the generalized eigenprojection problem of G. Such interpolation matrices can be designed in various ways, to be discussed in Subsection 3.3. In the meantime, we just state the general definition of A:   The interpolation matrix defines a coarsening step completely: Given a fine n-node PSD graph G(L, M ) and an n × m interpolation matrix A, we take the coarse m-node PSD graph to be G c (L c , M c ). We now show how, given L, M , and A, we calculate the Laplacian L c , and the mass matrix M c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The sum of each row is one,</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Calculating the coarse mass matrix</head><p>The coarse masses are derived by: </p><formula xml:id="formula_5">m j = n i=1 A ij m i .</formula><p>Later we will justify this definition. In the meantime, let us just say that this law is nothing but a statement of mass conservation if we interpret the nodes of G as physical masses formed by breaking and re-fusing (as dictated by the interpolation matrix) pieces of the physical masses from which G c is built up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Calculating the coarse Laplacian The Hall energy of G(L, M</head><p>) is E = x T Lx, where x ∈ R n . Substituting x = Ay, we can express this energy in terms of the m-dimensional vector y, E = y T A T LAy. It would then be quite natural to define the Laplacian of G c to be</p><formula xml:id="formula_6">L c = A T LA, so that the Hall energy of G c (L c , M c ) is E = y T L c y.</formula><p>In <ref type="bibr" target="#b17">[15]</ref> we prove that L c is in itself a Laplacian, thus our definition is consistent.</p><p>Having found both L c and M c , G c is completely defined and the coarsening step comes to its end. Our definition of coarsening clarifies why we needed the concept of PSD graphs; negative weights might occur in G c even if all the weights of G are positive. A more detailed discussion of this appears in the full version of the paper, <ref type="bibr" target="#b17">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">The fine and coarse minimization problems</head><p>Given the coarse graph G c , its corresponding generalized eigenprojection problem is</p><formula xml:id="formula_7">min y y T L c y given y T M c y = 1<label>(2)</label></formula><p>in the subspace</p><formula xml:id="formula_8">y T M c • 1 m = 0.</formula><p>The issue that needs to be addressed now is the relationship between this problem and the original generalized eigenprojection problem (1) of the fine graph G. To bring the two problems into the same dimension, we substitute x = Ay in (1), obtaining the form</p><formula xml:id="formula_9">min y y T A T LAy given y T A T MAy = 1 (3)</formula><p>in the subspace y</p><formula xml:id="formula_10">T A T M • 1 n = 0.</formula><p>Due to the equality L c = A T LA, the function to be minimized is the same in both forms. Moreover, since</p><formula xml:id="formula_11">M c • 1 m = A T M • 1 n ,</formula><p>we are looking for solutions to both of these in the same subspace. The only difference between them is in the scaling constraint, since in general M c = A T MA. One can force equality by adopting certain strategies for calculating A (see 3.3). Yet other strategies, that may yield more powerful interpolation matrices, do not, indeed, obey an equality. Nevertheless, in the full paper <ref type="bibr" target="#b17">[15]</ref> we show that in these cases (2) is a reasonable approximation of (3), and consequently the solutions of both problems share much resemblance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Refinement Process</head><p>We keep coarsening further and further until we obtain a coarse PSD graph that is sufficiently small. Typically, we would stop the process when we have less than 100 nodes. The drawing of G(L, M ), the coarsest graph, is obtained from the lowest positive generalized eigenvectors of (L, M ), namely u 2 , u 3 , . . .. Since M is diagonal, we can formulate the problem as an eigenvalue problem Bv = µv, where</p><formula xml:id="formula_12">B = M − 1 2 LM − 1 2 and v = M 1 2</formula><p>u, which calls for finding the lowest positive eigenvectors of B. Due to the small size of B, finding its eigenvectors takes a negligible fraction of the total running time, which makes the choice of the algorithm a marginal issue. We chose to use a variation of the power iteration (PI) algorithm <ref type="bibr" target="#b24">[22]</ref>, which is designed for finding the largest eigenvectors of symmetric matrices. For S a symmetric matrix, its largest eigenvector is the asymptotic direction of Sv 0 , S <ref type="bibr" target="#b1">2</ref> </p><formula xml:id="formula_13">v 0 , S 3 v 0 . . ., where v 0</formula><p>is an initial guess. The next largest eigenvectors can be found using the same technique, taking v 0 orthogonal to the previously found (larger) eigenvectors. Our problem needs the lowest eigenvectors rather than the largest ones. We therefore preprocess the matrix B, transforming it into a different matrix,B, whose largest eigenvectors are identical with the lowest eigenvectors of B (see also <ref type="bibr" target="#b1">[2]</ref>). This is done using the Gershgorin bound <ref type="bibr" target="#b24">[22]</ref>, which is a theoretical upper bound for (the absolute value of) the largest eigenvalue of a matrix. Specifically, for our matrix this bound is given by:</p><formula xml:id="formula_14">g = max i   B ii + j =i |B ij |   .</formula><p>The matrixB = g • I − B has the same eigenvectors as B, but in reverse order -the largest eigenvectors has become the lowest ones. Consequently, it is now suitable for using with the PI algorithm. The pseudocode of this algorithm is given in <ref type="figure" target="#fig_5">Figure 1</ref>. The initial guessesû 2 ,û 3 , . . . are picked at random. The PI seems to be a good algorithm to use here, being intuitive, simple to implement, having assured convergence to the right eigenvector, and most of all suitable to the refinement process too. Given a certain eigenvector of B, say v i , we are able to calculate the generalized eigenvector</p><formula xml:id="formula_15">u i from u i = M − 1 2 v i . Function power iteration ({û 2 ,û 3 , . . . ,û p }, L, M, ) % {û 2 ,û 3 , .</formula><p>. . ,ûp} are initial guesses for {u 2 , u 3 , . . . , up} % L, M are the Laplacian and mass matrix of the graph % is the tolerance. We recommend using 10 −7 ≤ ≤ 10 Having solved the generalized eigenprojection problem of the coarsest PSD graph directly, we use the solution to accelerate the computation of the corresponding solution of the second coarsest PSD graph. We then proceed iteratively until the solution of the original problem is obtained.</p><formula xml:id="formula_16">−10 v 1 ← M 1 2 • 1 n % first (known) eigenvector v 1 ← v1 v1 % normalize the first eigenvector B ← M − 1 2 LM − 1 2 g ← Gershgorin(B) B ← g • I − B % reverse order of eigenvalues for i = 2 to p v i ← M 1 2û î v i ←v i vi repeat v i ←v i % orthogonalize against previous eigenvectors for j = 1 to i − 1 v i ← v i − (v T i v j )v j end for v i ←B • v i % power iteration v i ←v i vi % normalization untilv i • v i &gt; 1 − % check convergence in direction v i ←v i u i ← M − 1 2 v i end for return u 2 , . . . , u p</formula><p>How is this 'inductive step', from the coarser to the finer graph, to be carried out? Well, let G c (L c , M c ) be a coarse m-node PSD graph, and let u c 2 , u c 3 , . . . u c p be the first few solutions of its generalized eigenprojection problem. For two-dimensional drawing u c 2 and u c 3 are all that we need (thus p = 3), but we do not specify p so as to keep the algorithm general. Let the next fine n-node PSD graph be G(L, M ), and let u 2 , u 3 , . . . , u p be the first few solutions of its generalized eigenprojection problem. Let also A be the n × m interpolation matrix connecting G and G c . The refinement step uses u c 2 , u c 3 , . . . , u c p to obtain a good initial guess for u 2 , u 3 , . . . , u p , thus enabling their fast calculation. The basic idea of the refinement is that for a reasonable interpolation matrix,û i = Au c i is a good approximation of u i . Then, we have to apply an iterative algorithm whose input is the initial guessû i and whose output is the closest generalized eigenvector u i .</p><p>The iterative algorithm that we use is the same power iteration which we have already used to solve the coarsest problem, see <ref type="figure" target="#fig_5">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Interpolation Matrix</head><p>At this point, the multiscale scheme is completely defined, and the only thing left unexplained is how we construct a specific interpolation matrix A. As already mentioned, there is no unique recipe for this, and we can come up with many feasible methods. However, for the interpolation matrix to successfully fulfill its role, some guidelines should be followed: a) The interpolation matrix should faithfully retain the structure of G; i.e., similar fine nodes should be similarly interpolated. This is the most important property of the interpolation matrix, since it determines how close will the initial guess Au c i be to the desired solution u i . b) The interpolation matrix should be easy to compute in terms of running time. c) The sparser the interpolation matrix the better, since matrix manipulations will be faster.</p><p>Generally speaking, these guidelines are contradicting. Improving the preservation of the structure of a graph requires more accurate interpolation, and hence a denser and more complex matrix A. A good interpolation matrix thus reflects a reasonable compromise regarding the tradeoff between accuracy and simplicity. We now describe the two methods we have been using to construct A.</p><p>Edge Contraction Interpolation. In this method we interpolate each node of the finer graph from exactly one coarse node. To find an appropriate interpolation matrix, we first divide the nodes of the fine graph into small disjoint connected subsets, and then associate the members of each subset with a single coarse node. Consequently, the rows of all the members of the same subset in the interpolation matrix will be identical, having a single non-zero element (which is, of course, 1). A well known method to efficiently create such disjoint subsets is by contracting edges that participate in max-matching (see, e.g., <ref type="bibr" target="#b23">[21]</ref>), so that the cardinality of the subsets is either one or two.</p><p>The edge contraction method evidently prefers simplicity over accuracy. On the one hand, A is very sparse and is easy to compute, but on the other hand, the interpolation is crude, taking into consideration only the strongest connection of each node. The simple form of the resulting A gives rise to an elegant property of the edge contraction algorithm: it preserves the structure of the problem, that is, M c = A T MA, thus having identical structure to <ref type="bibr" target="#b1">(2)</ref> and <ref type="bibr" target="#b2">(3)</ref>.</p><p>Weighted Interpolation In this method, inspired by <ref type="bibr" target="#b2">[3]</ref>, we interpolate each node of the fine graph from possibly several coarse nodes. The first stage is to choose a subset of m nodes out of the n nodes of G, which will be the nodes of G c . Hereinafter, the elements of this subset, R ⊂ V , will be called representatives. A possible candidate for R could be a maximal independent set. For even better options, see <ref type="bibr" target="#b17">[15]</ref>. We fix the coordinates of the representatives by their values as given in the coarse problem, and then determine the coordinates of the nonrepresentatives as a weighted sum of their neighboring representatives, such that Hall's energy is minimized.</p><p>We denote the coarse node associated with the representative i by <ref type="bibr">[i]</ref>. The interpolation matrix A is built as follows: Let P i be the set of all representatives that are connected to fine node i by positive weights, and let p i be the sum of these weights. Similarly, let N i be the set of all representatives that are connected to fine node i by negative weights, and let n i be their sum. Then we define:</p><formula xml:id="formula_17">For i ∈ V − R : (4) A i[j] =    w ij /p i ifj ∈ P i and p i ≥ −n i w ij /n i ifj ∈ N i and p i &lt; −n i 0 otherwise For i ∈ R : A i[j] = 1 ifj = i 0 ifj = i,</formula><p>A complete derivation is given in the full paper, <ref type="bibr" target="#b17">[15]</ref>. Clearly, in comparison with the edge contraction technique, this algorithm prefers accuracy over simplicity: A is less sparse, more expensive to compute, but far more accurate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Comments on Running Time</head><p>In Subsection 3.3 we introduced two techniques for generating an interpolation matrix, edge contraction and weighted interpolation. Comparing the two with respect to the speed of ACE, necessitates taking into account two points, which will be briefly surveyed here. Further discussion and examples can be found in <ref type="bibr" target="#b17">[15]</ref>.</p><p>Sparsity vs. accuracy: The sparser the interpolation matrix, the faster is a single iteration of PI. Also, the more accurate is the interpolation matrix, the less PI iterations are required until convergence. It is difficult therefore to predict which would be faster in the refinement -the sparse but less accurate edge contraction, or the denser but more accurate weighted interpolation. We anticipate that the structure of homogeneous graphs, like grids, is satisfactorily preserved even with a sparse interpolation matrix. In these cases, we expect the edge contraction to be faster. However, for non-homogeneous graphs, the opposite is true, and we expect the weighted interpolation to be the faster.</p><p>Coarsening vs. refinement: Our implementation of the edge contraction method uses direct coarsening that does not involve matrix multiplication. Thus, with respect to coarsening time, edge contraction is much preferable to weighted interpolation. On the other hand, for non-homogeneous graphs, weighted interpolation exhibits faster refinement times. For relatively loose tolerance (large in PI), not much work is required during the refinement, and we can expect the coarsening time to be significant, resulting in faster performance of the edge contraction. However, as we decrease , the PI time becomes more and more dominant, yielding faster performance of the weighted interpolation. Sometimes, one is interested in computing more than two generalized eigenvectors. This might be the case when carrying out three-dimensional drawings, or in two-dimensional drawings where the coordinates are associated with generalized eigenvectors other than u 2 and u 3 ; see <ref type="figure" target="#fig_7">Figure 2e</ref>-f. In any case, when more than two generalized eigenvectors are requested, the expected PI time of ACE increases while the coarsening time does not change. Consequently, the advantages of weighted interpolation become more salient, which suggests to prefer it in such cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">The Algorithm in a Nutshell</head><p>Here now is an outline of the full ACE algorithm, in the form of the recursive function AMG Graph Drawing:</p><formula xml:id="formula_18">Function AMG Graph Drawing (L, M ) % L -the Laplacian of the graph % M -the mass matrix if dimension(L) &lt; threshold (u 2 , u 3 ) ← direct solution(L c , M c ) else</formula><p>Compute the interpolation matrix A ; Compute the Laplacian, L c ← A T LA ; Compute the mass matrix</p><formula xml:id="formula_19">M c ; (u c 2 , u c 3 ) ← AMG Graph Drawing(L c , M c ) ; (û 2 ,û 3 ) ← (Au c 2 , Au c 3 ) (u 2 , u 3 ) ← power iteration({û 2 ,û 3 }, L, M, ) ; end if return u 2 , u 3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Examples</head><p>We have tested our algorithm against a variety of graphs, taken from diverse sources. Here we present some of the more interesting results, all obtained using a dual processor Intel Xeon 1.7GHz PC. The program is nonparallel and ran on a single processor. <ref type="table">Table 1</ref> shows the results of applying ACE to a number of large graphs, each with more than 10 5 nodes, and gives a pretty good feeling for the speed of the algorithm. We used the edge contraction method, and a tolerance of = 10 −7 , asking ACE to compute the two generalized eigenvectors u 2 and u 3 . In the table, we provide the complexity of the graphs, as well as the computation times of the different parts of ACE. The last column of the table gives the number of PI iterations performed on the finest scale (the most expensive ones) during the computation of u 2 .</p><p>Graphs of around 10 5 nodes are drawn in a few seconds; with 10 6 nodes the algorithm takes 10-20 seconds. The largest graph consists of 7.5 • 10 6 nodes, and the running time is about two minutes. Thus, ACE exhibits a truly significant improvement in computation time for drawing large graphs. Moreover, one can use it to draw huge graphs of 10 6 -10 7 nodes, which we have not seen dealt with appropriately in the literature, in quite a reasonable amount of time.</p><p>Unfortunately, limitations of file size and printing resolution prevent us from bringing here full drawings of really huge graphs. Yet, for the reader to obtain a visual impression of the kind of drawings produced by ACE, we bring here a collection of drawings of smaller graphs.</p><p>Before discussing specific examples, here are some general comments about the nature of drawings produced by minimizing Hall's energy. On the one hand, we are assured to be in a global minimum of the energy, thus we might expect the global layout of the drawing to faithfully represent the structure of the graph. On the other hand, there is nothing in Hall's energy that prevents nodes from being very close. Hence, the drawing might show dense local arrangement.</p><p>These general claims are nicely demonstrated in the examples drawn in <ref type="figure" target="#fig_7">Figure 2</ref>. <ref type="figure" target="#fig_7">Figure 2a</ref> shows a folded grid, obtained by taking a square grid, removing the horizontal edges in its central region, and connecting opposing corners. This graph has high level of symmetry, which is perfectly reflected in the drawing. <ref type="figure" target="#fig_7">Figures 2b-c</ref> show additional examples of symmetric graphs. Besides the excellent preservation of symmetry in the two-dimensional layout, these graphs show how ACE handles graphs in which many different "textures" are embedded. The drawing of <ref type="figure" target="#fig_7">Figure 2d</ref>, the 4elt graph, resembles the one shown in the technical report version of <ref type="bibr" target="#b23">[21]</ref>, which was obtained using a different graph drawing approach. <ref type="figure" target="#fig_7">Figures 2e-f</ref> show the same graph, dwa512, drawn using two different sets of generalized eigenvectors, {u 2 , u 3 } and {u 3 , u 4 }, respectively. The graph is comprised of two grids, strongly connected via their centers. for its ability to divide the graph into its natural clusters, as is nicely demonstrated in <ref type="figure" target="#fig_7">Figure 2e</ref>. Whereas, <ref type="figure" target="#fig_7">Figure 2f</ref> reveals the grid-based structure.</p><p>As to be expected from the previous discussion, these drawings indeed exhibit rather impressive global layout, but also have locally dense regions.</p><p>We would like to give an example how ACE can be applied to information visualization. Electronic noses are chemical devices used to quantify odors (see, e.g., <ref type="bibr" target="#b6">[7]</ref>). They consist of an array of sensors that, upon stimulation by an odor, gives an odor-unique response pattern. These patterns are represented as multidimensional vectors (typically 8-64 dimensions), which calls for the use of exploratory visualization techniques. The data provided by the electronic nose can be transformed to the form of similarity matrix, and therefore can be represented as a graph (see details in <ref type="bibr" target="#b3">[4]</ref>). Giving each node a mass equal to its degree, we obtain the drawing shown in <ref type="figure" target="#fig_3">Figure 3</ref>. Here, the data is comprised of n = 300 measurements, taken by repeatedly measuring 30 different kinds (color coded in the figure) of odors. Two observations should be made with respect to this drawing. First, the odors in the upper-right corner are real outliers. ACE isolates them dramatically from the other, "normal", odors. Second, the different clusters of odors are very well separated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>It appears that the time performance of the ACE algorithm is sufficiently good to finally enable graph drawing tools to be used to visualize huge systems such as the World Wide Web or networks of protein-protein interactions. This remains to be seen.</p><p>Obviously, the quality of the algorithm's results depends on the appropriateness of Hall's energy to the problem of graph drawing. In comparison with many of the other energy functions used in graph drawing, Hall's energy is distinguished by its simple form. The tractability of <ref type="table">Table 1</ref>: Running times of the various components of ACE. Data for most graphs were taken from web sources, as indicated in the table.</p><p>The graphs grid1000 and grid1415, which are simple rectangular grids, were produced by us. the mathematical analysis that this brings with it yields the vastly improved computation speed and a guaranteed convergence to a global minimum. All this lends ACE stability and causes its results to be "globally aesthetic". On the other hand, local details of the graph might be aesthetically inferior with respect to the results of other, more complicated, energy functions. For certain applications it might be possible to combine the advantages of different graph drawing algorithms, obtaining the global layout of a huge graph with ACE, and then use slower methods to beautify particular regions of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph</head><p>Having ACE quickly determine the coordinates of the nodes of huge graphs poses new challenges for their actual display. Obviously, graphs with millions of nodes cannot be beneficially displayed or printed as is, and new display tools would be required. A promising direction is to display only a portion of a graph at any given time, using various smooth navigation tools. A survey of such methods can be found in, e.g., <ref type="bibr" target="#b14">[12]</ref>. Another interesting approach is to use the coarse graphs produced by ACE during the coarsening process as abstractions of the original graph for various display purposes. Moreover, in line with the previous paragraph, we could use ACE to produce the global layout and its abstractions, and then use other algorithms for the instantaneous drawing of zoomed portions.</p><p>In developing the ACE algorithm we restricted ourselves to the problem of graph drawing. However, what we have been actually doing is to devise an algorithm that quickly finds the first few generalized eigenvectors of any problem of the form</p><formula xml:id="formula_20">Lx = µM x,<label>(5)</label></formula><p>with L a Laplacian and M a real diagonal positive definite matrix. It seems that these limitations on L and M can be removed by some modifications to the algorithm.</p><p>Problems of the form (5), with L a Laplacian and M real diagonal positive definite, appear frequently also outside graph drawing; for example, in image segmentation <ref type="bibr" target="#b21">[19]</ref>, partitioning <ref type="bibr" target="#b0">[1]</ref>, and linear ordering <ref type="bibr" target="#b15">[13]</ref>, and we hope that ACE may be found useful by researchers in these and other fields.</p><p>Finally, we would like to emphasize that the two algorithms we proposed for calculating an interpolation matrix should be taken as suggestions only. Since there is no strict criterion for the evaluation of an interpolation matrix, those that we were using are not necessarily "optimal", and in fact we have a number of additional ideas about this issue that require further inspection. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 2 . 2 (</head><label>22</label><figDesc>Positive Semi-Definite (PSD) Graph) A PSD graph is a structure G(V, E, M) in which: 1. V = {1, . . . , n} is a set of n nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Definition 3 . 1 (</head><label>31</label><figDesc>Interpolation Matrix) An interpolation matrix A is an n × m matrix (with n &gt; m), such that 1. All elements of A are non-negative, A ij ≥ 0 ∀i, j.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>m j=1 A</head><label>j=1</label><figDesc>ij = 1 ∀i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 .</head><label>3</label><figDesc>A has a full column rank, rank(A) = m. Properties 1 and 2 follow naturally by interpreting the i'th row of A as a series of weights that shows how to determine coordinate x i given all the y's, namely, x i = m j=1 A ij y j . Property 3 prevents the possibility of two distinct m-dimensional vectors being interpolated to the same n-dimensional vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Definition 3 . 2 (</head><label>32</label><figDesc>Mass law) Let G be a fine n-node PSD graph with masses m 1 , m 2 , . . . , m n , and let A be an n×m interpolation matrix. The masses of the coarse PSD graph G c , i.e., m 1 , m 2 , . . . , m m , are given by:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 :</head><label>1</label><figDesc>The power iteration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>The Fiedler vector u 2 is known Application of ACE on data obtained from an electronic nose.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 :</head><label>2</label><figDesc>Examples of ACE drawings. a) A folded-grid, based on a 100 × 100 rectangular grid. |V | = 10, 000, |E| = 18, 713.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Taken from George Karypis' collection at: ftp.cs.umn.edu/users/kumar/Graphs ‡ Taken from Francois Pellegrini's Scotch graph collection, at:www.labri.u-bordeaux.fr/Equipe/PARADIS/Member/pelegrin/graph § Taken from the University of Greenwich Graph Partitioning Archive, at:www.gre.ac.uk/˜c.walshaw/partition</figDesc><table><row><cell></cell><cell></cell><cell>Size</cell><cell></cell><cell>Degree</cell><cell></cell><cell></cell><cell>Times [sec]</cell><cell></cell><cell>PI iterations</cell></row><row><cell>Name</cell><cell>V</cell><cell>E</cell><cell>min</cell><cell>avg.</cell><cell>max</cell><cell>PI</cell><cell>coarsening</cell><cell>total</cell><cell>(finest level)</cell></row><row><cell>598a  †</cell><cell>110,971</cell><cell>741,934</cell><cell>5</cell><cell>13.37</cell><cell>26</cell><cell>3.1</cell><cell>0.8</cell><cell>4</cell><cell>7</cell></row><row><cell>ocean  ‡</cell><cell>143,437</cell><cell>409,593</cell><cell>1</cell><cell>5.71</cell><cell>6</cell><cell>1</cell><cell>0.6</cell><cell>1.7</cell><cell>4</cell></row><row><cell>144  †</cell><cell>144,649</cell><cell>1,074,393</cell><cell>4</cell><cell>14.86</cell><cell>26</cell><cell>4.4</cell><cell>1.2</cell><cell>5.7</cell><cell>8</cell></row><row><cell>wave  §</cell><cell>156,317</cell><cell>1,059,331</cell><cell>3</cell><cell>13.55</cell><cell>44</cell><cell>3</cell><cell>0.8</cell><cell>3.9</cell><cell>12</cell></row><row><cell>m14b  †</cell><cell>214,765</cell><cell>1,679,018</cell><cell>4</cell><cell>15.64</cell><cell>40</cell><cell>5.4</cell><cell>1.7</cell><cell>7.3</cell><cell>7</cell></row><row><cell>mrngA  †</cell><cell>257,000</cell><cell>505,048</cell><cell>2</cell><cell>3.93</cell><cell>4</cell><cell>3.9</cell><cell>1.5</cell><cell>5.5</cell><cell>5</cell></row><row><cell>auto  †</cell><cell>448,695</cell><cell>3,314,611</cell><cell>4</cell><cell>14.77</cell><cell>37</cell><cell>14.1</cell><cell>4.5</cell><cell>19.1</cell><cell>7</cell></row><row><cell cols="2">grid1000 1,000,000</cell><cell>1,998,000</cell><cell>2</cell><cell>4.00</cell><cell>4</cell><cell>2.3</cell><cell>3.5</cell><cell>6.2</cell><cell>3</cell></row><row><cell>mrngB  †</cell><cell>1,017,253</cell><cell>2,015,714</cell><cell>2</cell><cell>3.96</cell><cell>4</cell><cell>14</cell><cell>7.8</cell><cell>22.3</cell><cell>6</cell></row><row><cell cols="2">grid1415 2,002,225</cell><cell>4,001,620</cell><cell>2</cell><cell>4.00</cell><cell>4</cell><cell>3.7</cell><cell>7.0</cell><cell>11.6</cell><cell>2</cell></row><row><cell>mrngC  †</cell><cell>4,039,160</cell><cell>8,016,848</cell><cell>2</cell><cell>3.97</cell><cell>4</cell><cell>34.7</cell><cell>24.7</cell><cell>61.6</cell><cell>4</cell></row><row><cell>mrngD  †</cell><cell cols="2">7,533,224 14,991,280</cell><cell>2</cell><cell>3.98</cell><cell>4</cell><cell>61.1</cell><cell>48.7</cell><cell>114.2</cell><cell>4</cell></row><row><cell>†</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">n). Of course, the structure of G c should be strongly linked to that of G, such that both describe approximately the same entity, but on different scales. We now establish a general framework for the coarsening.A key concept we will use is that of an interpolation matrix, which is the tool that links G and G c . This is an n×m</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Fast Multilevel Implementation of Recursive Spectral Bisection for Partitioning Unstructured Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Concurrency: Practice &amp; Experience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="101" to="117" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visualizing Bibliographic Networks with a Reshaped Landscape Metaphor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Brandes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Willhalm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th Joint Eurographics -IEEE TVCG Symp. Visualization (VisSym &apos;02)</title>
		<meeting>4th Joint Eurographics -IEEE TVCG Symp. Visualization (VisSym &apos;02)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="159" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Algebraic Multigrid Theory: The Symmetric Case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applied Mathematics and Computation</title>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="23" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visualizing and Classifying Odors Using a Similarity Matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9 th International Symposium on Olfaction and Electronic Nose (ISOEN02)</title>
		<imprint>
			<date type="published" when="2002-10-02" />
		</imprint>
	</monogr>
	<note>to appear in the</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Graph Drawing: Algorithms for the Visualization of Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">Di</forename><surname>Battista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tamassia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">G</forename><surname>Tollis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Multidimensional Approach to Force-Directed Layouts of Large Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gajer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Kobourov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing 2000</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="211" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Bartlett</surname></persName>
		</author>
		<title level="m">Electronic Noses, Principles and Applications</title>
		<meeting><address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Multi-Scale Method for Drawing Graphs Nicely</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="3" to="21" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The 4970 graph, taken from</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">|E| = 7400. c) The Crack graph, taken from Jordi Petit&apos;s collection, at www.lsi.upc.es/˜jpetit/MinLA/Experiments. |V | = 10, 240, |E| = 30, 380. d) The 4elt graph, taken from Francois Pellegrini&apos;s Scotch graph collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>|v | = 4970</surname></persName>
		</author>
		<ptr target="at:www.labri.u-bordeaux.fr/Equipe/PARADIS/Member/pelegrin/graph" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">|E| = 45, 878. e,f) The dwa512 graph, taken from the Matrix Market, at math.nist.gov/MatrixMarket. |V | = 512, |E| = 1004</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>|v | = 15</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">606</biblScope>
		</imprint>
	</monogr>
	<note>Drawn using {u2, u3} (e) and {u3, u4} (f)</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An r-dimensional Quadratic Placement Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="219" to="229" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Fast Multi-scale Method for Drawing Large Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing 2000</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="183" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Graph Drawing by High-Dimensional Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
	<note>to appear in Proceedings of Graph Drawing</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Graph Visualisation and Navigation in Information Visualisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Melancon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="24" to="43" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimal linear labelings and eigenvalues of graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Juvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mohar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="153" to="168" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Drawing Graphs: Methods and Models</title>
		<editor>M. Kaufmann and D. Wagner</editor>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">2025</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">ACE: A Fast Multiscale Eigenvectors Computation for Drawing Huge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
		<idno>MCS01-17</idno>
		<ptr target="www.wisdom.weizmann.ac.il/reports.html" />
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>The Weizmann Institute of Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On Spectral Graph Drawing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>manuscript</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Solution of Sparse Indefinite Systems of Linear Equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Numer. Anal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="617" to="629" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">FADE: Graph Drawing, Clustering, and Visual Abstraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Quigley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eades</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing 2000</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="183" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Normalized Cuts and Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="731" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An Introduction to Algebraic Multigrid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Stueben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Appendix A in</title>
		<editor>Multigrid (U. Trottenberg, C.W. Oosterlee, and A. Schuller</editor>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Multilevel Algorithm for Force-Directed Graph Drawing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Walshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Drawing 2000</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1984" />
			<biblScope unit="page" from="171" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Watkins</surname></persName>
		</author>
		<title level="m">Fundamentals of Matrix Computations</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley</publisher>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
