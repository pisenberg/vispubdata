<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Jakob</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gross</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Günther</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">received xx xxx. 201x; accepted xx xxx. 201x.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Scientific visualization</term>
					<term>deep learning</term>
					<term>flow maps</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Re 147.0 #0200 Re 3.0 #4600 Re 176.9 #7400 Re 2352.5 Fig. 1: Several laminar and turbulent time slices of unsteady 2D vector fields from our public, numerically-simulated set of fluid flows. The bottom left number is the unique identifier of the flow in our data set. Here, color encodes vorticity and the dark lines correspond to the attracting hyperbolic Lagrangian coherent structures, estimated as ridges of the finite-time Lyapunov exponent.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recent advances in machine learning unlocked a vast amount of successful research in the realms of computer vision, rendering, and natural language processing, as well as in many other fields. These days, however, deep learning has rarely been applied to solve flow visualization problems, despite its significant potential <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b44">45]</ref>. A glimpse over to the vision community shows a potential reason: unlike image data, fluid flows are not abundantly available at large scale. In particular, we are not aware of any public data bases that systematically probe a wide range of Reynolds numbers or flow features, at a scale that is sufficient for the training of a generalizing neural network. In order to spur more applied machine learning research in the flow visualization community, we simulated a fluid flow data set, which will be publicly released and permanently provided on the website of the authors' insti-tution. This paper contains the description of its construction, which resulted in 8,000 unsteady 2D vector fields, each with a resolution of 512 × 512 voxels and 1001 time steps, amounting to a total of 16 TB. The data contains a wide range of fluid flow patterns, such as vortices, bifurcations and Lagrangian coherent structures. Examples of which are shown in <ref type="figure" target="#fig_4">Fig. 1</ref>. To simulate the flows, we used an established CFD solver <ref type="bibr" target="#b51">[52]</ref>, which we deployed on a high-performance compute cluster for massive parallelism. We varied the Reynolds number in the range Re ∈ <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">4096]</ref>, covering a wide spectrum of laminar and turbulent flows. The flows are initialized with a mean-free Wavelet noise <ref type="bibr" target="#b16">[17]</ref> that follows Kolmogorov's energy cascade <ref type="bibr" target="#b45">[46]</ref>. In order to support longer tracing durations that are not restricted by domain boundaries, we extended the Wavelet noise to periodic boundary conditions and in order to obtain smooth initial conditions, we elevated the underlying basis functions to a quartic polynomial degree.</p><p>To demonstrate the utility of our flow data set, we apply machine learning to improve the accuracy of a Lagrangian transport analysis. As numerical fluid simulations are quickly growing in size across all application areas, whether it is in meteorology, fluid dynamics or cosmology, the analysis of transport behavior becomes more and more challenging. To avoid the storage of every single time step to disk, a recent trend is to calculate trajectories on the compute cluster, and to only store the locations that particles were advected to after a finite integration duration <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b56">57]</ref>. This gives rise to flow maps, which are a fundamental component for the analysis of Lagrangian coherent structures <ref type="bibr" target="#b32">[33]</ref>. Since flow maps are discretized, a Lagrangian transport analysis requires their interpolation. To improve the interpolation accuracy over a standard cubic interpolation method, a super-resolution CNN (SR-CNN) <ref type="bibr" target="#b20">[21]</ref> could be trained, which takes the sampled image as input and improves its accuracy. However, this design depends on the upsampling operation, which affects the computation time and the accuracy of the output. Rather than taking an upsampled image as input <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b72">73]</ref>, we let the network learn the upsampling operation itself <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b65">66]</ref>. Thus, we train an efficient sub-pixel convolutional neural network (ESPCN) by Shi et al. <ref type="bibr" target="#b59">[60]</ref> to interpolate flow map values in-between known grid points. The receptive field of the neural network is able to pick up flow properties from the neighborhood, implicitly making use of typical vector field characteristics. Compared to cubic upsampling, we achieve in most cases up to 40% lower interpolation error on unseen validation data at a negligible computation cost. Further, we compare the ESPCN network with the aforementioned SRCNN of Dong et al. <ref type="bibr" target="#b20">[21]</ref>, showing that ESPCN performs better at high-frequency detail. We apply networks for 2× and 4× upsampling not only to unseen examples of the simulated data set, but also demonstrate their utility on multiple unseen numerical simulations, as well as on measured winds around an island. We thereby show that the accuracy of the flow map interpolation can be increased over different scales, ranging from flows in lab conditions to noisy measurements from satellite images. Our neural flow map interpolation is a standalone product that can be deployed after regular flow map export from any given in-situ computation, making it easy to integrate in existing pipelines. We make the following contributions:</p><p>• We simulate and release a large numerical 2D fluid flow data set for machine learning, which contains a wide spectrum of laminar and turbulent fluid flows with periodic boundary conditions.</p><p>• We evaluate the efficient sub-pixel convolutional neural network (ESPCN) by Shi et al. <ref type="bibr" target="#b59">[60]</ref> and the super-resolution CNN (SR-CNN) by Dong et al. <ref type="bibr" target="#b20">[21]</ref> for 2× and 4× upsampling, which we adapted to the flow map interpolation problem. Unlike image data, flow map values are in physical domain coordinates and are sampled rather than integrated over a sensor.</p><p>A benchmark data set of fluid flows is not only relevant for machine learning <ref type="bibr" target="#b44">[45]</ref>. It could also serve as test bed for ensemble visualization techniques or conventional flow feature extraction algorithms. Research on fluid dynamics and dynamical systems, as well as particle swarm optimization of aerial micro robots <ref type="bibr" target="#b4">[5]</ref> recently became more datadriven. In those examples, data consisted of analytical flows only. Further, the graphics community is actively researching neural fluid control and stylization <ref type="bibr" target="#b43">[44]</ref>, which could also profit from public data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Open Flow Data</head><p>Data-driven methods require an abundance of data in order to generalize. Unfortunately, most public scientific data bases are highly specialized to an application area, such as oceanology and climatology <ref type="bibr" target="#b17">[18]</ref> or turbulence <ref type="bibr" target="#b42">[43]</ref>. None of those data bases was created with the goal in mind to provide a foundation for machine learning. At present, machine learning researchers would either have to simulate data themselves, using established CFD solvers, or synthetically generate data, for instance using parametric models <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">45]</ref>, which might not generalize well to real flows. Eckert et al. <ref type="bibr" target="#b23">[24]</ref> recently released ScalarFlow, a volumetric 3D data set of real-world captured fluid flows. Their data set contains 100 flow reconstructions, consisting of smoke plumes only. In comparison, our data set is 80 times larger, contains a range of Reynolds numbers and has periodic boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Learning</head><p>In recent years, neural networks have been used with great success in many research areas. In its essence, a traditional feed-forward neural network is a function approximation that finds non-linear mappings between an input and an output through supervised or unsupervised training. Auto-encoders <ref type="bibr" target="#b38">[39]</ref> have been used to compress data to a lowdimensional descriptive feature space and the regular layout of image data has been exploited by convolutional neural networks <ref type="bibr" target="#b48">[49]</ref> that learn convolution filter weights that are reused across the entire input image. On the other hand, generative models synthesize further instances of a given training distribution, either by learning probabilities explicitly (variational auto-encoders <ref type="bibr" target="#b46">[47]</ref>) or by utilizing an adversary that distinguishes between synthesized and real data (generative adversarial networks <ref type="bibr" target="#b30">[31]</ref>). We refer to Goodfellow et al. <ref type="bibr" target="#b29">[30]</ref> for a comprehensive introduction to deep learning. In this paper, we utilize a fully convolutional architecture to design our network, since unlike generative models, it does not hallucinate data, which we discuss later.</p><p>Machine Learning for Visualization. While there is plenty of research on explainability in machine learning <ref type="bibr" target="#b1">[2]</ref>, the application of machine learning algorithms to solve visualization problems has only recently gained more recognition. Frey <ref type="bibr" target="#b27">[28]</ref> introduced a neural network that picks the best sampling strategy for progressive similarity measures of spatio-temporal data sets. Zhou et al. <ref type="bibr" target="#b72">[73]</ref> applied a superresolution convolutional neural network (SRCNN) <ref type="bibr" target="#b20">[21]</ref> to upsample scalar fields. They assumed that the input was already upsampled with cubic interpolation. Raji et al. <ref type="bibr" target="#b53">[54]</ref> proposed to learn a similarity measure by using a siamese network which is further passed to a genetic optimizer to refine a transfer function. Fan and Hauser <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref> assisted users in the brushing of scatter plots. Similarly, Chen et al. <ref type="bibr" target="#b12">[13]</ref> aided in the selection from 3D point clouds. Berger et al. <ref type="bibr" target="#b5">[6]</ref> learnt a differentiable volume renderer, which enables the investigation of inverse problems and an analysis of the role of transfer functions in the image synthesis. Cheng et al. <ref type="bibr" target="#b13">[14]</ref> created a CNN-based volume visualization assistance for depicting complex structures. Shi et al. <ref type="bibr" target="#b58">[59]</ref> described how to estimate a viewpoint based on a CNN for volume visualization. Weiss et al. <ref type="bibr" target="#b66">[67]</ref> utilized a generative network to upsample isosurface renderings. He et al. <ref type="bibr" target="#b37">[38]</ref> used deep learning to map from visualization parameters to the output image, which was applied to parameter space exploration in in-situ settings of ensemble simulations.</p><p>Data-Driven Flow Analysis. In the realm of fluid flow analysis, deep learning has been used for ocean eddy detection. Lguensat et al. <ref type="bibr" target="#b50">[51]</ref> and Duo et al. <ref type="bibr" target="#b22">[23]</ref> located ocean eddies based on sea surface height and sea level anomaly, respectively. Bai et al. <ref type="bibr" target="#b2">[3]</ref> extracted eddies from streamline images and Franz et al. <ref type="bibr" target="#b26">[27]</ref> extracted and tracked eddies over time. More general flow patterns have been classified by Bin and Li <ref type="bibr" target="#b6">[7]</ref> (rotation, saddle, other), and further flow regimes have been identified by Ströfer et al. <ref type="bibr" target="#b61">[62]</ref> (recirculation, boundary layer, horseshoe vortex). Deng et al. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b63">64]</ref> learned a binary segmentation based on a thresholding of the objective instantaneous vorticity deviation. Hong et al. <ref type="bibr" target="#b39">[40]</ref> developed a Long Short-Term Memory (LSTM)-based model to predict access patterns for parallel particle tracing in order to reduce I/O costs. Han et al. <ref type="bibr" target="#b34">[35]</ref> used a latent space representation for the selection of streamlines and stream surfaces. By combining a recurrent and a generative adversarial network, Han and Wang <ref type="bibr" target="#b36">[37]</ref> generated temporal high-resolution sequences from low-resolution volumetric data. More recently, Han et al. <ref type="bibr" target="#b35">[36]</ref> reconstructed a vector field from previously traced streamlines by using a two-staged deep learning process. Kim and Günther <ref type="bibr" target="#b44">[45]</ref> used CNNs to extract reference frames in which the flow becomes steady in the presence of noise and resampling artifacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Super-Resolution Neural Networks</head><p>The recovery of a highresolution (HR) image from a single low-resolution (LR) image is known in the computer vision community as single image superresolution <ref type="bibr" target="#b70">[71]</ref>. Since multiple high-resolution images can result after down-sampling in the same low-resolution image, this problem is inherently ill-posed. A neural network, however, can learn data distributions and can thus recover a likely solution. Dong et al. <ref type="bibr" target="#b20">[21]</ref> introduced the so-called super-resolution convolutional neural network (SRCNN). The idea is as follows: i) A LR image is up-sampled with bicubic interpolation in a pre-processing step. ii) Overlapping image patches are then extracted and run through convolutional layers wrapped with non-linearities to extract features. iii) Finally, the feature patches are merged together to the HR patch by a final layer with linear activation. The necessity of upsampling the input image was lifted by Shi et al. <ref type="bibr" target="#b59">[60]</ref> and Dong et al. <ref type="bibr" target="#b21">[22]</ref> by learning a sub-pixel convolution filter or deconvolution filter, respectively, which were shown to be equivalent <ref type="bibr" target="#b60">[61]</ref>. Wang et al. <ref type="bibr" target="#b65">[66]</ref> further included a multi-scale reconstruction and Wang et al. <ref type="bibr" target="#b64">[65]</ref> utilized generative adversarial network to hallucinate plausible detail. We refer to Yang et al. <ref type="bibr" target="#b71">[72]</ref> for a recent single-image super-resolution benchmark. Images are different from flow maps: while color spaces are bound by certain values, e.g., in RGB space bounds are [0, 255], particle positions can take arbitrary real values. More importantly, image pixel values integrate the incident radiance across a sensor, whereas flow map values are point-wise measurements. Thus, LR images are modeled such that their unknown HR counterpart is convolved with a kernel <ref type="bibr" target="#b18">[19]</ref>. For flow maps, however, we can only sub-sample the unknown HR, resulting in inherent aliasing artifacts. Thus, it is interesting to evaluate the performance of convolutional architectures in the context of flow map analysis.</p><p>Data-Driven Super-Resolution for Fluid Flows. In graphics, super-resolution is used to improve fidelity in simulations. Chu and Thuerey <ref type="bibr" target="#b14">[15]</ref> learned a similarity measure between low-resolution and high-resolution data. Xie et al. <ref type="bibr" target="#b69">[70]</ref> proposed a temporally coherent volumetric GAN for super-resolution fluid flows. They introduced a temporal discriminator in addition to the common spatial one and further combined multiple physics fields, like density, velocity and vorticity. The idea of deploying a GAN for volumetric super-resolution has been further explored by Werhahn et al. <ref type="bibr" target="#b67">[68]</ref>. Their Multi-Pass GAN combines two separate generative adversarial networks, where one up-scales XY-slices and the other refines the volume along the Zaxis. Using a GAN is reasonable for graphics applications, however for visualization tasks it has not yet been studied how much hallucinations could falsify the data to better fit to the approximated distribution, and how this impacts the scientific data analysis. For this reason, we use a fully convolutional architecture instead to upsample flow maps, which leads to solutions that are more blurred. Users can therefore visually distinguish better where the network made errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Flow Map Interpolation</head><p>The following section introduces into the terminology of flow maps, and their discretization and interpolation, which sets the stage for the demonstration of our flow data set for deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Flow Maps and their Discretization</head><p>Given a vector field v(x,t), the flow map φ τ t0 (x 0 ) maps a particle seeded at position x 0 and time t 0 to the location it reaches after integration in v(x,t) for duration τ:</p><formula xml:id="formula_0">φ τ t0 (x 0 ) = x 0 + t0+τ t0 v(x(t),t) dt, with x(t 0 ) = x 0 (1)</formula><p>The flow map is a compact representation of the Lagrangian transport from time t 0 to t 0 + τ. Conceptually, the velocity field v(x,t) is no longer needed, once the flow map was calculated, as long as we are only interested in the transport from t 0 to t 0 + τ. This property made the flow map very appealing for in-situ processing, since storage of the velocity field v(x,t) can be avoided if the flow map is stored instead. In practice, the flow map is discretized to a finite set of seed points. Without loss of generality, we assume that the seed points x i, j are placed on a regular grid with resolution X ×Y , i.e., i ∈ {1,...,X} and j ∈ {1,...,Y }. For notational convenience, we express the discrete flow map as a set</p><formula xml:id="formula_1">Φ τ t0 = x i, j , φ τ t0 (x i, j )</formula><p>. In order to perform a detailed Lagrangian transport analysis it is beneficial to be able to query the flow at any given location. To obtain a continuous flow map approximation, we need an interpolation operator S:</p><formula xml:id="formula_2">φ τ t0,S (x 0 ) = S Φ τ t0 , x 0<label>(2)</label></formula><p>Compared to the original continuous flow map φ τ t0 (x 0 ) in Eq. <ref type="formula">1</ref>, the application of interpolation operator S to the discrete flow map in Eq. <ref type="formula" target="#formula_2">2</ref>introduces an interpolation error E τ t0,S (x 0 ):</p><formula xml:id="formula_3">Φ τ t0 (x) t τ x y t0 x1(t0) x2(t0) x3(t0) x4(t0) x5(t0) φ τ t0 (x1) φ τ t0 (x2) φ τ t0 (x3) φ τ t0 (x4) φ τ t0 (x5) φ τ t0,S (x5) E τ t0,S (x5)</formula><formula xml:id="formula_4">E τ t0,S (x 0 ) = φ τ t0 (x 0 ) − φ τ t0,S (x 0 )<label>(3)</label></formula><p>which is zero exactly at the known set of seed points: E τ t0,S (x i, j ) = 0. A schematic illustration of the flow map interpolation is shown in <ref type="figure" target="#fig_0">Fig. 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Flow Map Approximation</head><p>The flow map interpolation error is determined by three factors: the discretization (e.g., the spatial grid resolution X ×Y ), the integration durations (τ 1 , τ 2 , ...), and the interpolation operator S. To accelerate the computation of finite-time Lyapunov exponents (FTLE), Brunton and Rowley <ref type="bibr" target="#b9">[10]</ref> concatenated flow maps to reduce redundant particle integration of neighboring particles. Chandler et al. <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> interpolated a vector field from trajectories using SPH kernels. Agranovsky et al. <ref type="bibr" target="#b0">[1]</ref> interpolated particle trajectories for interactive flow exploration in a multi-resolution manner, where the coarse resolution serves for fast trajectory exploration and the finer resolution for more complex feature extraction. Sadlo and Peikert <ref type="bibr" target="#b55">[56]</ref> used adaptive mesh refinement to discretize the flow map in order to accelerate FTLE computations. Garth et al. <ref type="bibr" target="#b28">[29]</ref> and Barakat and Tricoche <ref type="bibr" target="#b3">[4]</ref> explored adaptive flow map sampling strategies. Sane et al. <ref type="bibr" target="#b56">[57]</ref> used a variable placement and a variable integration duration of the basis trajectories to lower the memory consumption. Rapp et al. <ref type="bibr" target="#b54">[55]</ref> discussed sampling strategies for the placement of pathlines in unsteady flows, which can reduce the number of lines to be stored in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">FLOW DATA SET</head><p>Our first goal is to create a versatile fluid flow data set that covers a wide range of fluid flow conditions. Fortunately, fluid dynamics behaves similar across a wide spectrum of scales, since energy is transferred between the scales in a cascading manner <ref type="bibr" target="#b47">[48]</ref>. Fluid dynamics is often studied in small lab conditions and is then extrapolated to larger scales. In atmospheric research, for instance, Boyer and Davies <ref type="bibr" target="#b8">[9]</ref> discussed the scaling of atmospheric flows to explore relationships between cloud vortex patterns behind islands and in the wake of a cylinder. Since lab conditions are a common ground, we model our fluid flow data set in dimensionless form, using the characteristic length L, velocity scale U, and Reynolds number Re.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Simulation Specifications</head><p>Next, we describe our simulation setup. We used the open source CFD solver Gerris <ref type="bibr" target="#b51">[52]</ref> to generate a total of 8,000 unsteady 2D fluid flows.</p><p>Domain Specification. For all simulations, we defined a spatial domain of [0, 1] 2 and a temporal domain of [0, 10]. In order to obtain valid particle trajectories throughout the full time range, we utilize periodic boundary conditions, such that particles never leave the spatial domain. For simplicity, we discretized the domain uniformly. To accelerate the simulation in the HPC environment, we subdivided the domain into 4 × 4 blocks. Gerris uses a cell-centered velocity discretization, which we shifted to a regular co-located grid. In all our experiments, we set a spatial discretization of 512 × 512, and simulated 1001 time steps, resulting in 2GB of memory per fluid flow. The domain size and the size of a single voxel determine the largest and smallest structures that can be resolved. The largest structure is denoted as the characteristic length scale, here L = 1, and the smallest structure is given by the Kolmogorov length scale η ≈ 1 512 = 2 −9 <ref type="bibr" target="#b15">[16]</ref>. Ensemble Parameters. Aside from the randomized initial conditions that are described subsequently, there are a number of simulation constants, which can be varied to obtain a wider range of flow conditions. First, the Reynolds number Re is a dimensionless number that characterizes the turbulence of the flow:</p><formula xml:id="formula_5">Re = UL ν<label>(4)</label></formula><p>with U being the velocity scale, L being the characteristic length and ν being the kinematic viscosity. Initial Conditions. To avoid warm-up periods and to capture transitional regimes, we initialize our fluid flows with random divergence-free vector fields v(x) that adhere to the Kolmogorov energy cascade <ref type="bibr" target="#b47">[48]</ref>. The synthesis of band-limited random scalar fields was described by Cook and DeRose <ref type="bibr" target="#b16">[17]</ref>, and is called Wavelet Noise. Their co-gradients produce band-limited vector fields w(x) that contain vortices of only a particular size. Kim et al. <ref type="bibr" target="#b45">[46]</ref> added fields of different scale with the proper energy weighting to obtain a divergence-free flow u(x) that follows the Kolmogorov scale, using:</p><formula xml:id="formula_6">u(x) = bmax ∑ b=bmin w(2 b x) 2 − 5 6 (b−bmin) (5)</formula><p>where [b min , b max ] defines the range of spectral bands. <ref type="figure">Fig. 3</ref> gives an example. We always set b min = 0 and the highest possible upper band is given by the grid resolution as log 2 512 = 9. To generate a range of laminar and turbulent flows, we linearly sample the upper band b max ∈ <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9]</ref>, which in turn determines the Reynolds number Re for this simulation as Re ≈ 2 b• <ref type="bibr" target="#b3">4</ref> 3 <ref type="bibr" target="#b62">[63]</ref>. Pseudo-codes for the generation of w(x) and u(x) are given in the appendices of <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b45">[46]</ref>, respectively, which we needed to extend to higher polynomial degree for continuity and periodic boundary conditions, as described below. Note that u(x) is mean-free, which means that the average velocity in the domain is zero. This property is very useful, as it allows us to specify the velocity scale U exactly by adding a random constant direction vector c with ||c|| = U:</p><formula xml:id="formula_7">v(x) initial flow = u(x) random + c constant (6)</formula><p>With this, we can control the overall movement direction and magnitude of our initial vector field v(x).</p><p>Continuity. Kim et al. <ref type="bibr" target="#b45">[46]</ref> interpolated Wavelet noise with a quadratic B-spline from a discrete set of Gaussian distributed noise samples. While they only added a small noise residual to an existing low-resolution flow simulation in order to fill up the missing turbulence scales, we synthesize the turbulent flow completely. Since wavelet noise <ref type="bibr" target="#b16">[17]</ref> is a streamfunction, differential properties of the vector field, such as the vorticity, require second-order derivatives, making those C 0 continuous with quadratic B-splines. While cubic interpolation improved the result slightly, we eventually chose a quartic interpolation, for which derived properties showed no artifacts, cf. <ref type="figure">Fig. 4</ref>. The quartic basis functions are listed in the additional material.</p><p>Boundary Conditions. The last remaining parameter of the fluid simulation is the boundary condition. Since we aim to perform a Lagrangian flow analysis, we need to be able to trace long particle trajectories. For this reason, we chose to set periodic boundary conditions, meaning that the flow that exits on the right enters on the left, the flow that exits at the top enters at the bottom, and vice versa for both cases. Care must be taken to make sure that the initial turbulent vector field v(x) of the previous section is periodic for both the values on the boundaries themselves as well as for all derivatives. Otherwise, boundary artifacts will be advected into the domain. To obtain periodic boundary conditions, we modified the wavelet noise sampling by introducing a scale-dependent modulo operation. Pseudocode of our modification is provided in the additional material.</p><p>Several flow examples of our simulation data set can be seen in <ref type="figure" target="#fig_4">Fig. 1</ref>. For reference, the mean velocity magnitude is 0.3176 and the mean vorticity magnitude is 2.6 × 10 −5 . In total, the simulation of the fluid data set took about 1,160 node hours on a compute cluster, using two 10-core Xeon E5-2630v4 processors per node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NEURAL FLOW MAP INTERPOLATION</head><p>Given the flow data set, we can now improve over existing flow map interpolation methods by predicting flow maps with a convolutional neural network. Given a flow map discretization Φ τ t0 , an existing interpolation operator S(Φ τ t0 , x 0 ), such as cubic interpolation, gives a flow map estimate φ τ t0,S (x 0 ) with error E τ t0,S (x 0 ), cf. Eq. (3). The error thereby depends on the upsampling operator S. The super-resolution CNN (SRCNN) <ref type="bibr" target="#b20">[21]</ref> takes such an upsampled image as input and corrects interpolation errors, resulting in an improved flow map φ τ t0,S (x 0 ). The residual error still depends on the operator S, which was chosen by a human. In order to remove this source of error, we use the CNN of Shi et al. <ref type="bibr" target="#b59">[60]</ref>, called ESPCN, which takes in our case the low-resolution flow map as input and learns to upsample the data in the last layer itself. Thus, the neural network will directly estimate the upsampled flow map φ τ t0 (x 0 ), resulting in a residual error E τ t0 (x 0 ) that does not depend on S. We use the following notation: cubic interp.:</p><formula xml:id="formula_8">E τ t0,S (x 0 ) conventional residual = φ τ t0 (x 0 ) ground truth − φ τ t0,S (x 0 ) existing interpolator<label>(7)</label></formula><p>SRCNN <ref type="bibr" target="#b20">[21]</ref>:</p><formula xml:id="formula_9">E τ t0,S (x 0 ) SRCNN residual = φ τ t0 (x 0 ) ground truth − φ τ t0,S (x 0 ) SRCNN interpolator<label>(8)</label></formula><p>ESPCN <ref type="bibr" target="#b59">[60]</ref>:  The neural flow map interpolation can be seen as a general postprocessing step that can be applied to any existing flow map computation to improve its accuracy.</p><formula xml:id="formula_10">E τ t0 (x 0 ) ESPCN residual = φ τ t0 (x 0 ) ground truth − φ τ t0 (x 0 ) ESPCN interpolator<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Network Architecture</head><p>The input to ESPCN is the low-resolution flow map, and the output is a flow map at k× higher resolution. We train networks for a specific factor k, e.g., k = 2 or k = 4. Since the input flow maps are stored on a regular grid, a convolutional neural network <ref type="bibr" target="#b48">[49]</ref> (CNN) architecture is beneficial, because convolution filter weights are shared across the input, which lowers the memory footprint significantly compared to a dense layer. Besides their rich feature provision, CNNs have the possibility to process varying input sizes at inference time. To handle the periodic boundaries at training time, we synthetically extend the patch size periodically and apply a valid boundary mode in the convolution kernels. The architecture of our network is illustrated in <ref type="figure" target="#fig_2">Fig. 5</ref>. We utilize two convolutional layers with ReLU activations and use a convolution filter size of f 1 × f 1 and f 2 × f 2 to compute n 1 and n 2 feature maps, respectively. Finally, a 3 × 3 deconvolution layer with stride 2 combines the feature maps and upscales the image to its target resolution. The hyperparameters f 1 , f 2 , n 1 and n 2 were optimized for our data and are reported later in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training and Testing</head><p>Since we use a supervised learning setup, we need to provide a ground truth high-resolution flow map at training time for a given lowresolution input flow map. To generate the ground truths, we traced 10 flow maps for T of our 8, 000 simulated flows at a high resolution of 512 × 512 grid points. We found that for our task, a randomly chosen subset of T = 3, 600 flows was sufficient. For the tracing of particles, we used a fourth-order Runge-Kutta integrator with a step size of 0.01. Since we would like to train a general neural network that is able to upsample for varying integration durations, we varied the integration duration τ ∈ <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10]</ref>, keeping t 0 = 0. This results in a total of N = 10×T ground truth flow maps, containing both laminar and turbulent flows. Our goal is to predict these ground truth flow maps from low-resolution flow maps. Thus, we downsampled the ground truth flow maps, using every k-th voxel for learning a k× upsampling task. To test how well the model generalizes we split the flow maps into 35, 000 training and 1, 000 test samples. Throughout the super-resolution literature, several loss functions have been proposed to assess the quality of the prediction. Since we do not process natural images, we do not apply a perceptual loss <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b49">50]</ref>. Instead, we follow Dong et al. <ref type="bibr" target="#b20">[21]</ref> and Shi et al. <ref type="bibr" target="#b59">[60]</ref> and use the conventional mean squared error (MSE) loss between the predicted flow map and the ground truth. We trained the network for 200 epochs using the Adam optimizer with a learning rate of 10 −4 .  <ref type="figure">Fig. 7</ref>: Study of the filter sizes f 1 and f 2 of the two convolutional layers of ESPCN for a fixed number of features n 1 = n 2 = 64 per layer. The filter size has a marginal effect on the residual, but affects the training time (in brackets) by a few hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Hyperparameter Tuning</head><p>Since ESPCN was tested by Shi et al. <ref type="bibr" target="#b59">[60]</ref> for image data and not for flow maps, we optimize the hyperparameters of the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Number of Features</head><p>First, we vary the number of features per convolutional layer. <ref type="figure">Fig. 6</ref> shows the residuals and the training time for combinations, ranging from (n 1 , n 2 ) ∈ { <ref type="bibr" target="#b63">(64,</ref><ref type="bibr" target="#b31">32)</ref>, <ref type="bibr" target="#b31">(32,</ref><ref type="bibr" target="#b63">64)</ref>, <ref type="bibr" target="#b63">(64,</ref><ref type="bibr" target="#b63">64)</ref>,...,(256, 256)}. The number of features amounts to the capacity of the network, which is loosely speaking a bound for the amount of information that can be learned. Increasing the number of features will naturally increase the training time, though it might not pay off in terms of the error residual. Further, this will also increase the memory consumption during training, requiring small batch sizes. In the remainder of the paper, we use n 1 = n 2 = 128 features, which is a trade-off between capacity and training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Filter Size</head><p>The filter size of a convolutional layer influences the receptive field of the network. The larger the filter, the more neighboring information can influence the output for a single pixel, i.e., the less local is the decision. For flow map upsampling, the immediate surrounding of a pixel is important, since the patterns are formed from fluid dynamical processes that are governed by physical laws, such as incompressibility.</p><p>The larger the filter, however, the more parameters, i.e., convolution filter weights, have to be learnt, which increases the training time. In <ref type="figure">Fig. 7</ref>, we compare the network performance for varying filter sizes f 1 , f 2 . We can see that the network performance marginally increases with larger filter sizes. In the remainder of the paper, we can therefore use f 1 = f 2 = 3 unless mentioned otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Generalization To Real-World Data</head><p>Our simulations have been carried out on a unit domain. Since neural networks perform best on data that is similar to what was seen during training, we normalize all flow maps during training and at inference time to the domain [−1, 1] 2 by taking the following steps: Later, we use this approach to upsample flow maps on numerically simulated flows, and on a measured flow that is given on a domain four orders of magnitude larger than our simulation domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>Next, we evaluate the ESPCN network in the context of neural flow map interpolation on the test data and other numerical data sets. For this, we compare the error residuals with the results of standard cubic upsampling and with SRCNN. We use the mean squared error (MSE), and the peak signal-to-noise ratio (PSNR) for the quantitative evaluations. An Adam optimizer with learning rate 0.0001 was used in all experiments unless stated otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Quantitative Analysis for Varying Duration</head><p>With increasing integration duration, the flow maps become more detailed, and the ridges in the FTLE field become sharper. Since both SRCNN and ESPCN have not been applied to flow maps before, we optimized the hyperparameters for both in order to provide a fair comparison. ESPCN has been optimized in Section 4.3. <ref type="figure">Fig. 8</ref> evaluates the choice of the optimizer and the loss function in SRCNN for varying integration durations. While Dong et al. <ref type="bibr" target="#b20">[21]</ref> used a stochastic gradient descent (SGD), we found that the Adam optimizer performed best in our case with an MSE loss, which serves as baseline for us. The Adam optimizer consistently outperformed cubic upsampling. It was expected that the residual error increases with longer integration duration, since the upsampling problem becomes more difficult to solve. The SRCNN receives a cubic up-sampled input, which is a predetermined filter. We compare this with ESPCN in <ref type="figure">Fig. 9</ref>, which takes a low resolution input directly and applies a sub-pixel convolution in the last layer in order to up-sample to the target resolution. ESPCN obtained a marginally smaller error than SRCNN. However, the training time of ESPCN is far shorter. While SRCNN trained for 42.6 hours, ESPCN needed only 14.6 hours, since the feature maps are calculated at lower resolution. ESPCN therefore becomes the preferred choice in terms of numbers. In the following, we study the differences visually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Qualitative Analysis for Varying Duration</head><p>To assess the utility in a Lagrangian transport analysis, we visualize the finite-time Lyapunov exponent <ref type="bibr" target="#b57">[58]</ref>:</p><formula xml:id="formula_11">FTLE(x,t, τ) = 1 |τ| ln λ max ∇φ τ t0 (x) T ∇φ τ t0 (x)<label>(10)</label></formula><p>which measures the separation of nearby released particles. The ridge lines of this field are considered an approximation to hyperbolic Lagrangian coherent structures <ref type="bibr" target="#b32">[33]</ref>. Our goal is to reduce the upsampling errors of the flow map, compared to standard cubic upsampling. To evaluate the networks, we compare their output with the cubic upsampling in <ref type="figure" target="#fig_4">Fig. 10</ref> (top row) for 2× and 4× upsampling. The full view of the domain is shown for 2× upsampling and lists the MSE and PSNR, whereas close-ups are shown for both 2× and 4×. See the additional material for the full view of 4× upsampling and the corresponding quantitative measures (MSE and PSNR). We can see that ESPCN outperformed SRCNN and cubic upsampling at ridge resampling in almost all cases, especially for 4× upsampling. The ESPCN network, however, can produce artifacts in laminar regions of the domain, especially for 4× upsampling. Tracing trajectories for a longer period of time is known to result in finer FTLE ridges, which are more prone to flow map interpolation errors. For this reason, we show the error maps for different integration durations in the additional material. <ref type="figure" target="#fig_4">Fig. 11a</ref> plots the MSE as a function of the integration duration for the competing upsampling techniques for 2× and 4× upsampling. ESPCN outperformed the other methods for all integration durations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Application to Other Flows</head><p>To test how well the network generalizes, we apply our method to numerically simulated and measured flows. <ref type="figure" target="#fig_0">Figs. 10 and 12</ref> show the results for 2× and 4× upsampling in five other numerical vector fields, and list the MSE and PSNR averaged across the domains. The BOUSSINESQ flow contains a fluid simulation of a heated cylinder <ref type="bibr" target="#b31">[32]</ref>, in which FTLE ridges get close to each other. In the CYLINDER flow <ref type="bibr" target="#b31">[32]</ref>, a Kármán vortex street forms. We take a closer look at ridges that are poorly sampled. With cubic upsampling, the ridge line decays into pieces, which are better connected with ESPCN. The GUADALUPE flow was acquired by Horváth et al. <ref type="bibr" target="#b40">[41]</ref> from satellite images. Despite the noise, the networks perform well. Note that the particles in this flow are traced on a scale that was four orders of magnitude larger than our simulation domain. The same situation occurred for the OCEAN flow, which was shared by Haller et al. <ref type="bibr" target="#b33">[34]</ref>. Finally, the DOUBLE CYLINDER shows the interaction of two vortex streets, which both form FTLE ridges. <ref type="figure" target="#fig_4">Figs. 11</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Comparison with Adaptive Sampling</head><p>Garth et al. <ref type="bibr" target="#b28">[29]</ref> and <ref type="bibr">Barakat and Tricoche [4]</ref> introduced adaptive flow map computation methods. In <ref type="figure" target="#fig_4">Fig. 14</ref>, we compare our networks with Sibson's C 1 continuous interpolation, as used by Barakat and Tricoche <ref type="bibr" target="#b3">[4]</ref> as baseline, which we implemented using CGAL. Sibson's C 1 continuous interpolation includes not only sparse values but also their gradients, which we numerically integrated as described by Barakat and Tricoche <ref type="bibr" target="#b3">[4]</ref>. The figure shows that the adaptive method reaches lower errors than the networks, especially when the ridges are sparse. In the future, it could be fruitful to implement a CNN on sparse inputs, e.g., based on PointNet <ref type="bibr" target="#b52">[53]</ref>, to further improve adaptive methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Performance</head><p>An advantage of neural networks over traditional dense particle tracing is their efficient evaluation once they are trained. In <ref type="table">Table 1</ref>, we report the regular tracing time of a flow map, and in comparison the inference timings for a single batch using SRCNN and ESPCN. The tracing cost of a 512 × 512 grid in a typical upsampling scenario scales linearly with the integration duration, ranging from 6 seconds (τ = 1) to almost 1 minute (τ = 9), and depends on parameters such as the integration step size, as well as on the memory IO bandwidth. With our neural network, the inference time is constant, since we trained our networks for various integration durations. For both SRCNN and ESPCN, the inference time of a single batch is at about 0.8 milliseconds. Up to 16 batches can be inferred in parallel. A main disadvantage of SRCNN, however, is its dependence on the prior cubic upsampling of the input flow map. This initial cubic upsampling takes about 0.038 seconds on the CPU. Thus, in practice ESPCN is about 48× faster than SRCNN. Training timings have been reported in Figs. 6-9, which were in the order of 42 hours (SRCNN) and 16 hours (ESPCN). All experiments were done on a single GPU (Nvidia GeForce GTX 1080Ti) with 10 GB memory, and with an Intel Core i7-7700K CPU with 8× 4.2GHz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Discussion</head><p>Any neural network is only as capable as its training data. At the moment, we trained on divergence-free flows only. Further, the flows do not contain obstacles or boundaries. We plan to extend the flow data set in the future to also include those configurations. Further, we would like to build a similar data set for 3D unsteady flow, which, however, will inevitably be about 100-1000 times larger due to the additional spatial dimension. At present, we observed grid pattern artifacts in laminar regions with the ESPCN method for 4× upsampling. Further, the longer the integration, the sharper the ridges become. 0.0008 <ref type="table">Table 1</ref>: Tracing cost and inference time for a single batch in seconds for a flow map with resolution 512 × 512 × 2.</p><p>only see the flow map at discrete samples and therefore receive for longer integration durations a potentially aliased input. These aliasing patterns can lead to noticeable problems in the predictions, resulting in wiggling ridge lines. In order to improve in those regions, we experimented with a gradient loss formulation in order to penalize not only differences in the flow map values, but also in their gradients. Unfortunately, the gradient loss did not show significant improvements. Rather than penalizing gradient differences only, it is imaginable to view the predicted image in the frequency domain and to penalize deviations in particular frequency bands. In addition, it is imaginable to explore other network architectures such as generative adversarial networks (GAN). GANs and CNNs lead to their own type of error. While a GAN models a data distribution and samples from it, which will fare better with perceptual error metrics, a CNN will obtain more blurred results. From a data analysis point-of-view, we can choose which type of error we prefer: do we like to have high-quality pictures where we cannot tell which structure is true and which is hallucinated, or do we prefer a blurred solution where the user is aware of the errors of the network? This is very likely application-dependent and it is worth studying how hallucinations actually influence the data analysis task, not just for our problem but for scientific visualization in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>We introduced an unsteady 2D fluid flow data set for machine learning purposes. The fluid flows were simulated with periodic boundary conditions and were initialized with Wavelet noise that follows the Kolmogorov energy spectrum. In total, the data set contains 8,000 fluid flows resulting in approximately 16 TB. Using this data set, we trained and compared two convolutional single image super-resolution neural network architectures, namely SRCNN and ESPCN, to upsample low-resolution flow maps in order to support a Lagrangian transport analysis. We applied the methods to unseen numerical simulations and wind measurements, demonstrating that ESPCN outperformed SRCNN at 4× upsampling across a wide range of different domain scales. Both performed similarly for 2× upsampling. With this work, we created a test bed for other data-driven approaches that can similarly address the flow map interpolation problem and compare with our results. Further, we hope that the fluid flow data set proves useful for other scientists in the community. Aside from applying the data set to other problems, it would be interesting to apply our flow map interpolation to flow map concatenation in time or in space <ref type="bibr" target="#b7">[8]</ref>, and to multi-resolution predictions. We hope that the data set spurs future work on data-driven flow analysis, including network design improvements (basis-predicting networks <ref type="bibr" target="#b68">[69]</ref>), design of custom layers, frequency-aware losses, convolutions on sparse samples <ref type="bibr" target="#b52">[53]</ref>, the learning of dynamical systems and other flow features (vortex boundaries, reference frames, hyperbolic trajectories), auto-encoding for compression and unsupervised feature extraction, as well as investigating the role of generative networks in scientific data analysis. Outside of deep learning, the data set could be useful for benchmarks of feature extraction algorithms, e.g., for unsteady vector field topology, vortex cascades and vortex boundaries. Further, it can serve as a test bed for ensemble visualization, vector field comparison metrics, flow pattern recognition, and symmetry detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Space-time visualization of a flow map interpolation from flow maps released from a 4 × 4 grid at time t 0 in a 2D flow. For seed point x 5 , the flow map is interpolated from grid vertices x 1 , x 2 , x 3 and x 4 , resulting in estimate φ τ t0,S (x 5 ) (blue), which entails an interpolation error E τ t0,S (x 5 ) (orange), compared to the ground truth φ τ t0 (x 5 ) (red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>3 Fig. 3 :Fig. 4 :</head><label>334</label><figDesc>Wavelet noise-based construction of a random vector field u(x), following Kolmogorov's energy spectrum. Note that each band w(x) is periodic and uses a different random seed. quadratic cubic quartic Quadratic, cubic and quartic B-spline interpolation of the lowest band. Vorticity is color-coded showing discontinuities for lower-order interpolations that negatively affect the flow simulation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 :</head><label>5</label><figDesc>The ESPCN architecture consists of two convolutional and one deconvolutional layer. A low-resolution flow map goes in and a high resolution flow map is predicted. The convolutional layers have filter size f 1 and f 2 , and compute n 1 and n 2 feature maps, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 8 :Fig. 9 :</head><label>89</label><figDesc>Hyperparameter adjustment for SRCNN at an upsampling factor of k = 2. We examine the performance of the stochastic gradient descent and the Adam optimizer, and we explore the choice of the loss function (MSE vs MAE). MSE with Adam optimizer performed best. The required training time is stated in brackets.<ref type="bibr" target="#b42">43</ref>.7 hrs) SRCNN MSE (42.6 hrs) ESPCN MAE (18.6 hrs) ESPCN MSE (14.7 hrs) Quantitative comparison of SRCNN and ESPCN for varying integration durations at 2× upsampling. ESPCN performed better by a small margin. The required training time is in brackets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 .</head><label>1</label><figDesc>Compute flow maps in the original unscaled domain. 2. Shift the mean of the resulting flow map to (0, 0). 3. Uniformly scale the flow map into the unit domain [−1, 1] 2 . 4. Apply the ESPCN or SRCNN, respectively. 5. Scale back to the original size. 6. Shift back to the original position.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 12 :</head><label>12</label><figDesc>Error maps and FTLE comparisons for different fluid flows. In all cases, the flow map was traced from t 0 = 0 up to τ. The top row of each data set contains the overview of the 2× upsampling and the quantitative error measures. The close-ups compare the 2× and 4× upsampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The Re value ranges from a steady regime (Re &lt; 50), to periodic vortex shedding (Re &lt; 200) to turbulent flows (Re &gt; 2000)<ref type="bibr" target="#b40">[41]</ref>. Since the transition is continuous, there is no exact threshold. The Kolomogorov length scale relates to the Reynolds number approximately by η ≈ L • Re −3/4<ref type="bibr" target="#b62">[63]</ref>. Therefore, we can resolve at most a Reynolds number of approximately Re ≈ 2 9• 4 3 = 4096. We varied Re in the range Re ∈<ref type="bibr" target="#b0">[1,</ref> 4096], and placed ν in the range ν ∈ [10 −5 , 10 −4 ]. Since L = 1, the velocity U is implied by Eq.(4), ranging from U ∈ [0.0001, 0.4096].</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>n2 =32 (14.7 hrs) n1 =32, n2 =64 (15.1 hrs) n1 =64, n2 =64 (16.7 hrs) n1 =64, n2 =128 (15.3 hrs) n1 =128, n2 =64 (11.8 hrs) n1 =128, n2 =128 (20.6 hrs) n1 =128, n2 =256 (23.3 hrs) n1 =256, n2 =128 (28.9 hrs) n1 =256, n2 =256 (67.9 hrs)Fig. 6: Varying the number of features n 1 and n 2 in the two convolutional layers of ESPCN for a fixed filter size of f 1 = f 2 = 3. Growing the feature size further does not pay off in terms of the remaining error residual compared to the increasing training time (in brackets).</figDesc><table><row><cell></cell><cell></cell><cell>cubic</cell><cell></cell><cell></cell></row><row><cell>mean squared error mean squared error</cell><cell>0 0.1 0.2 0.3 0 0.3 0.1 0.2</cell><cell>2 cubic f1=3, f2=3 (16.7 hrs) 4 Integration duration τ 6 4 6 f1=5, f2=3 (13.4 hrs) f1=3, f2=5 (15.2 hrs) n1 =64, 2 f1=5, f2=5 (16.4 hrs) f1=9, f2=9 (18.2 hrs)</cell><cell>8 8</cell><cell>1 0 1 0</cell></row><row><cell></cell><cell></cell><cell>Integration duration τ</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Error maps and FTLE comparisons for different fluid flows. In all cases, the flow map was traced from t 0 = 0 up to τ. The top row of each data set contains the overview of the 2× upsampling and the quantitative error measures. The close-ups compare the 2× and 4× upsampling.</figDesc><table><row><cell></cell><cell>cubic E τ t0,S cubic E τ t0,S</cell><cell cols="2">cubic FTLE cubic FTLE</cell><cell></cell><cell></cell><cell cols="2">SRCNN E SRCNN E</cell><cell>τ t0,S τ t0,S</cell><cell cols="3">SRCNN FTLE SRCNN FTLE</cell><cell></cell><cell>ESPCN E ESPCN E</cell><cell>τ t0 τ t0</cell><cell cols="3">ESPCN FTLE ESPCN FTLE</cell><cell cols="2">ground truth ground truth</cell></row><row><cell>FLOW #2000, τ = 7 τ = 70, 000 GUADALUPE,</cell><cell>MSE : 3.7 • 10 −2 PSNR : 22.60 2× 4× MSE : 1.0 • 10 8 PSNR : 44.35 2× 4×</cell><cell>2× 2×</cell><cell cols="2">4× 4×</cell><cell></cell><cell cols="3">MSE : 2.14 • 10 −2 PSNR : 24.97 2× 4× MSE : 6.3 • 10 7 PSNR : 46.57 2× 4×</cell><cell>2× 2×</cell><cell></cell><cell>4× 4×</cell><cell></cell><cell cols="2">MSE : 6.9 • 10 7 PSNR : 46.17 MSE : 1.69 • 10 −2 PSNR : 26.00 2× 4× 2× 4×</cell><cell>2× 2×</cell><cell cols="2">4× 4×</cell><cell></cell></row><row><cell></cell><cell>MSE : 1.0 • 10 −2 PSNR : 36.42</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">MSE : 6.8 • 10 −3 PSNR : 38.26</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MSE : 6.2 • 10 −3 PSNR : 38.53</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BOUSSINESQ, τ = 3 τ = 90 OCEAN,</cell><cell>2× MSE : 7.9 • 10 −2 4× PSNR : 47.16 2× 4×</cell><cell>2× 2×</cell><cell cols="2">4× 4×</cell><cell></cell><cell cols="3">2× MSE : 4.9 • 10 −2 4× PSNR : 49.24 2× 4×</cell><cell>2× 2×</cell><cell></cell><cell>4× 4×</cell><cell></cell><cell cols="2">2× MSE : 4.5 • 10 −2 4× PSNR : 49.59 2× 4×</cell><cell>2× 2×</cell><cell cols="2">4× 4×</cell><cell></cell></row><row><cell>τ = 7</cell><cell>MSE : 7.7 • 10 −3 PSNR : 34.64</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">MSE : 4.3 • 10 −3 PSNR : 37.17</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">MSE : 3.9 • 10 −3 PSNR : 37.66</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CYLINDER, τ = 7 DOUBLE CYLINDER,</cell><cell>MSE : 2.4 • 10 −2 PSNR : 32.57 2× 4× 2× 4×</cell><cell>2× 2×</cell><cell cols="2">4× 4×</cell><cell></cell><cell cols="3">MSE : 1.4 • 10 −2 PSNR : 34.80 2× 4× 2× 4×</cell><cell>2× 2×</cell><cell></cell><cell>4× 4×</cell><cell></cell><cell cols="2">MSE : 1.2 • 10 −2 PSNR : 35.32 2× 4× 2× 4×</cell><cell>2× 2×</cell><cell cols="2">4× 4×</cell><cell></cell></row><row><cell cols="2">0 0.3 Fig. 10: 2 cubic 2× SRCNN 2× 0.1 0.2 ESPCN 2× cubic 4× mean squared error SRCNN 4× ESPCN 4×</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>1 0</cell><cell>mean squared error</cell><cell>0 0.02 0.1 0.08 0.04 0.06</cell><cell></cell><cell>2 cubic 2× SRCNN 2× ESPCN 2× cubic 4× SRCNN 4× ESPCN 4×</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>1 0</cell><cell>mean squared error</cell><cell>0 0.02 0.08 0.04 0.06</cell><cell>2 cubic 2× SRCNN 2× ESPCN 2× cubic 4× SRCNN 4× ESPCN 4×</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>1 0</cell></row><row><cell></cell><cell cols="3">Integration duration τ</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Integration duration τ</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Integration duration τ</cell></row><row><cell></cell><cell cols="3">(a) FLOW #2000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">(b) BOUSSINESQ flow</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">(c) CYLINDER flow</cell></row><row><cell cols="20">Fig. 11: Error plots of real-world data for varying integration durations with up-scaling factor 2× and 4×. Compared to the cubic baseline at 2×</cell></row><row><cell cols="20">upsampling, SRCNN reduced the error residuals by 37.8% (FLOW #2000), 32.7% (BOUSSINESQ) and 39.4% (CYLINDER), whereas ESCPN</cell></row><row><cell cols="20">reduced the error residuals by 47.9% (FLOW #2000), 39.4% (BOUSSINESQ) and 44.9% (CYLINDER) at τ = 10. For 4× upsampling, SRCNN</cell></row><row><cell cols="20">reduced the error residuals by 28.6% (FLOW #2000), 12.2% (BOUSSINESQ) and 30.9% (CYLINDER), whereas ESCPN reduced the error residuals</cell></row><row><cell cols="13">by 42.9% (FLOW #2000), 35.6% (BOUSSINESQ) and 39.4% (CYLINDER) at τ = 10.</cell><cell></cell><cell></cell><cell cols="5">and 13 plot the MSE as a function of</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">time for cubic upsampling, SRCNN and ESPCN. For 2× upsampling,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Error plots of real-world data for varying integration durations with up-scaling factor 2× and 4×. Compared to the cubic baseline, SRCNN reduced the error residuals by 44.8% (GUADALUPE), 30.6% (OCEAN) and 42.4% (DOUBLE CYLINDER), whereas ESCPN reduced the error residuals by 43.5% (GUADALUPE), 31.7% (OCEAN) and 47.2% (DOUBLE CYLINDER) at τ = 10. For 4× upsampling, SRCNN reduced the error residuals by 36.3% (FLOW #2000), 29.6% (BOUSSINESQ) and 30.9% (CYLINDER), whereas ESCPN reduced the error residuals by 44.0% (FLOW #2000), 44.4% (BOUSSINESQ) and 47.6% (CYLINDER) at τ = 10.</figDesc><table><row><cell>•10 7 MSE: 9.5 • 10 −4 mean squared error cubic 2× SRCNN 2× Integration duration τ ESPCN 2× cubic 4× SRCNN 4× ESPCN 4× (a) GUADALUPE flow PSNR: 35.68 ESPCN MSE: 6.4 • 10 −4 PSNR: 37.39 Fig. 14: Comparison of ×4 up-sampling with adaptive flow map sam-20 40 0 0.1 0.2 0.3 Integration duration τ 60 mean squared error cubic 2× SRCNN 2× ESPCN 2× cubic 4× SRCNN 4× ESPCN 4× (b) OCEAN flow Sibson's C 1 MSE: 6.2 • 10 −4 PSNR: 37.52 pling using Sibson's C 1 continuous interpolation [4] with 128 × 128 samples. In this example we show the FTLE of close-ups of the flow #2000 for τ = 3. Networks with regular grid inputs are less efficient especially in regions without FTLE ridges. ESPCN (on average 42% error reduction) and SRCNN (on average 38% error reduction) performed similarly. At 4× upsampling, however, ESPCN (on average 42% error reduction) gave more favorable results than SRCNN (on average 28% error reduction) for high integration durations. Overall, ESPCN generalized the best in terms of ridge extraction. For 4× upsampling, however, ESPCN can exhibit grid artifacts in laminar regions. All flows except for the OCEAN and Fig. 13: SRCNN GUADALUPE flow have been simulated with Gerris [52].</cell><cell>80</cell><cell>100</cell><cell>mean squared error</cell><cell>0 5 • 10 −2 0.1</cell><cell>2 cubic 2× SRCNN 2× Integration duration τ 4 6 ESPCN 2× cubic 4× SRCNN 4× ESPCN 4× (c) DOUBLE CYLINDER flow</cell><cell>8</cell><cell>1 0</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the Swiss National Science Foundation (SNSF) Ambizione grant no. PZ00P2 180114.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A multi-resolution interpolation scheme for pathline based Lagrangian flow representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agranovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Obermaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">p. 93970K. International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">9397</biblScope>
		</imprint>
	</monogr>
	<note>Visualization and Data Analysis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Explaining deep neural networks with a polynomial time algorithm for shapley values approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ancona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Öztireli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning (PMLR)</title>
		<meeting>the 36th International Conference on Machine Learning (PMLR)<address><addrLine>Long Beach, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">97</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A streampath-based RCNN approach to ocean eddy detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<idno>doi: 10. 1109/ACCESS.2019.2931781</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="106336" to="106345" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive refinement of the flow map using sparse samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Barakat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tricoche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2753" to="2762" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vector field benchmark for collective search in unknown dynamic environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bartashevich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Knors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mostaghim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Swarm Intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="411" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A generative model for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1636" to="1650" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CNN-based flow field feature visualization method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Performability Engineering</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">434</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Accelerating advection via approximate block exterior flow maps. Electronic Imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bleile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2017</biblScope>
			<biblScope unit="page" from="140" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Laboratory studies of orographic effects in rotating and stratified flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Davies</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.fluid.32.1.165</idno>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="165" to="202" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast computation of finite-time Lyapunov exponent fields for unsteady flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Rowley</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.3270044</idno>
	</analytic>
	<monogr>
		<title level="j">Chaos: An Interdisciplinary Journal of Nonlinear Science</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">17503</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Analysis of error in interpolationbased pathline tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bujack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis (Short Papers)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Interpolation-based pathline tracing in particle-based flow visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Obermaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Joy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="80" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">LassoNet: Deep lasso-selection of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2019.2934332</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep-learning-assisted volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cardone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Krokos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Subramaniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varshney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1378" to="1391" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Data-driven synthesis of smoke flows with cnn-based feature descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thuerey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A primer on direct numerical simulation of turbulence -methods, procedures and guidelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Coleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Sandberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-03" />
		</imprint>
		<respStmt>
			<orgName>University of Southampton</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Project report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wavelet noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Derose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="803" to="811" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">ERA5: Fifth generation of ECMWF atmospheric reanalyses of the global climate. Copernicus climate change service climate data store (CDS</title>
	</analytic>
	<monogr>
		<title level="m">Copernicus Climate Change Service (C3S)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Blind image super-resolution with spatially variant degradations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cornillère</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Djelouah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yifan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schroers</surname></persName>
		</author>
		<idno type="DOI">10.1145/3355089.3356575</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2019-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A CNN-based vortex identification method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12650-018-0523-1</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Visualization</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="78" />
			<date type="published" when="2019-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image super-resolution using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="295" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Accelerating the super-resolution convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="391" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Oceanic mesoscale eddy detection method based on deep learning. Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Duo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno>doi: 10. 3390/rs11161921</idno>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scalarflow: a large-scale volumetric data set of real-world scalar transport flows for computer animation and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-L</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Um</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thuerey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast and accurate CNN-based brushing in scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="111" to="120" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Personalized sketch-based brushing in scatterplots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hauser</surname></persName>
		</author>
		<idno type="DOI">10.1109/MCG.2018.2881502</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="28" to="39" />
			<date type="published" when="2019-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ocean eddy identification and tracking using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milioto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kusche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IGARSS 2018 -2018 IEEE International Geoscience and Remote Sensing Symposium</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6887" to="6890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sampling and estimation of pairwise similarity in spatio-temporal data based on neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informatics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Efficient computation and visualization of coherent structures in fluid flow applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gerhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tricoche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1464" to="1471" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generic objective vortices for flow visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Theisel</surname></persName>
		</author>
		<idno>141:1-141:11</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH)</title>
		<meeting>SIGGRAPH)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Lagrangian coherent structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Haller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="137" to="162" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Defining coherent vortices objectively from the vorticity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hadjighasem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farazmand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Fluid Mechanics</title>
		<imprint>
			<biblScope unit="volume">795</biblScope>
			<biblScope unit="page" from="136" to="173" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">FlowNet: A deep learning framework for clustering and selection of streamlines and stream surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TVCG.2018.2880207</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Flow field reduction via reconstructing vector data from 3-d streamlines using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer graphics and applications</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="54" to="67" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">TSR-TVD: Temporal super-resolution for timevarying data analysis and visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">InSituNet: Deep image synthesis for parameter space exploration of ensemble simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Nashed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Peterka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Visualization and Computer Graphics (Proc. IEEE Scientific Visualization</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Reducing the dimensionality of data with neural networks. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="504" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Access pattern learning with long short-term memory for parallel particle tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Pacific Visualization Symposium (PacificVis)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Evolution of an atmospheric kÃ¡rmÃ¡n vortex street from high-resolution satellite winds: Guadalupe island case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Horváth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bresky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vogelzang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stoffelen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seethala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Günther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Buehler</surname></persName>
		</author>
		<idno type="DOI">10.1029/2019JD032121</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Geophysical Research: Atmospheres</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Perceptual losses for real-time style transfer and super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="694" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The Johns Hopkins turbulence databases: an open simulation laboratory for turbulence research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lalescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Eyink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="10" to="17" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Transport-Based Neural Style Transfer for Smoke Simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">C</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Solenthaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">188</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Robust reference frame extraction from unsteady 2D vector fields with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Günther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum (Proc. EuroVis)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Wavelet turbulence for fluid simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thürey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">50</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dissipation of energy in locally isotropic turbulence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Akademiia Nauk SSSR Doklady</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="1941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">EddyNet: A deep neural network for pixel-wise classification of oceanic eddies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lguensat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fablet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tandeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Geoscience and Remote Sensing Symposium</title>
		<meeting>IEEE Geoscience and Remote Sensing Symposium</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Free computational fluid dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Popinet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ClusterWorld</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Photo-guided exploration of volume data features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sisneros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Messmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.06815</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Void-and-cluster sampling of large scattered data and trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dachsbacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Efficient visualization of lagrangian coherent structures by filtered amr ridge extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sadlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peikert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1456" to="1463" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">An interpolation scheme for VDVP Lagrangian basis flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Childs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bujack</surname></persName>
		</author>
		<idno type="DOI">10.2312/pgv.20191115</idno>
	</analytic>
	<monogr>
		<title level="m">Eurographics Symposium on Parallel Graphics and Visualization. The Eurographics Association</title>
		<editor>H. Childs and S. Frey</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Definition and properties of lagrangian coherent structures from finite-time lyapunov exponents in two-dimensional aperiodic flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Shadden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lekien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Marsden</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.physd.2005.10.007</idno>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">212</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="271" to="304" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">CNNs based viewpoint estimation for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology (TIST)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1874" to="1883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.07009</idno>
		<title level="m">Is the deconvolution layer the same as a convolutional layer</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Data-driven, physicsbased feature extraction from fluid flow fields using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Ströfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Paterson</surname></persName>
		</author>
		<idno type="DOI">10.4208/cicp.oa-2018-0035</idno>
	</analytic>
	<monogr>
		<title level="j">Communications in Computational Physics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Direct numerical simulation for liquid metal applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tiselj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stalio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thermal Hydraulics Aspects of Liquid Metal Cooled Nuclear Reactors</title>
		<editor>F. Roelofs</editor>
		<imprint>
			<publisher>Woodhead Publishing</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="201" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">A rapid vortex identification method using fully convolutional segmentation network. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A fully progressive approach to single-image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schroers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="864" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">End-to-end image super-resolution via deep and shallow convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="31959" to="31970" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Volumetric isosurface rendering with deep learning-based super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thuerey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>p. in print</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A multi-pass gan for fluid flow super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Werhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thuerey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM on Computer Graphics and Interactive Techniques</title>
		<meeting>the ACM on Computer Graphics and Interactive Techniques</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Basis prediction networks for effective burst denoising with large kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gharbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sunkavalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11844" to="11853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">tempogan: A temporally coherent, volumetric gan for super-resolution fluid flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thuerey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Single-image super-resolution: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="372" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Deep learning for single image super-resolution: A brief review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3106" to="3121" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Volume upscaling with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Computer Graphics International Conference</title>
		<meeting>the Computer Graphics International Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
