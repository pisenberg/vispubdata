<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Hybrid MDS with Pivot-Based Searching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Morrison</surname></persName>
							<email>morrisaj@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Chalmers</surname></persName>
							<email>matthew@dcs.gla.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Glasgow</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Hybrid MDS with Pivot-Based Searching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T18:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CR Categories: F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problemsgeometrical problems and computations</term>
					<term>routing and layout</term>
					<term>sorting and searching; H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-clustering Algorithms</term>
					<term>performance Multidimensional scaling</term>
					<term>MDS</term>
					<term>spring models</term>
					<term>hybrid algorithms</term>
					<term>pivots</term>
					<term>near-neighbour search</term>
					<term>force directed placement</term>
				</keywords>
			</textClass>
			<abstract>
				<p>An algorithm is presented for the visualisation of multidimensional abstract data, building on a hybrid model introduced at InfoVis 2002. The most computationally complex stage of the original model involved performing a nearestneighbour search for every data item. The complexity of this phase has been reduced by treating all high-dimensional relationships as a set of discretised distances to a constant number of randomly selected pivot items. In improving this computational bottleneck, the complexity is reduced from O(N √ N) to O(N 5 4). As well as documenting this improvement, the paper describes evaluation with a data set of 108000 14-dimensional items; a considerable increase on the size of data previously tested. Results illustrate that the reduction in complexity is reflected in significantly improved run times and that no negative impact is made upon the quality of layout produced.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>At the heart of many techniques for information visualisation is the requirement to construct a two-dimensional representation of a multidimensional abstract data set (recently, for example <ref type="bibr" target="#b1">[Andrews et al. 2002]</ref>, <ref type="bibr" target="#b16">[Rodden et al. 2001]</ref>, <ref type="bibr" target="#b0">[Amenta and Klinger 2002]</ref>). As these data sets will often have no inherent two-dimensional mapping, an optimal configuration of objects is sought that preserves the intrinsic structure of the data. As such, data sets are often treated as proximity data and considered in terms of inter-object similar-ities. Data are positioned so that objects' relative proximities in the created layout represent as well as possible high-dimensional relationships.</p><p>A set of proximity data may be considered as a complete graph, with each object corresponding to a node and each inter-object distance represented as a weighted edge. Eigenvector-based techniques such as the ACE algorithm <ref type="bibr" target="#b9">[Koren et al. 2002</ref>] can be very efficient at positioning nodes in graphs of low connectivity. Cases involving very dense or fully connected graphs, however, are a distinct problem and so we examine alternatives to these matrix methods of node placement.</p><p>Spring models (see eg <ref type="bibr" target="#b7">[Fruchterman and Reingold 1991]</ref>, <ref type="bibr" target="#b6">[Chalmers 1996]</ref>) are one possible means of constructing such an object layout. A heuristic algorithm emulating a set of mechanical springs, a spring model updates object positions iteratively in an attempt to minimise a loss function based on the preservation of high-dimensional distances.</p><p>In InfoVis 2002, an algorithm was presented that combined sampling and spring model phases with a novel interpolation procedure to create representative layouts of multi-dimensional data in subquadratic time <ref type="bibr">[Morrison et al. 2002b]</ref> (and extended in <ref type="bibr" target="#b14">[Morrison et al. 2003]</ref>). It was shown that the algorithm executed significantly faster than the previous best spring model algorithm. A brief outline of the algorithm is provided in figure 1 as a summary, although readers are directed to the original paper for a more detailed description. The computational complexity of each stage is given in square brackets.</p><p>It is apparent from figure 1 that the interpolation stage has the highest complexity, making the model O(N √ N ) overall. Specifically, the parent-finding phase of interpolation is the bottleneck of the model. This paper focuses on this stage of the model. A novel method of parent-finding is introduced that reduces the complexity of the hybrid model to O(N 5 4 ). In addition to documenting and evaluating this algorithmic improvement, this paper also provides results of experiments on a data set of 108000 14-dimensional objects; a significant increase over the size of data previously tested.</p><p>The following section explains in more depth the purpose of the parent-finding phase of the algorithm. The original and improved strategies are presented, along with an analysis of their respective computational complexities. An evaluation section follows, which sees the new parent-finding solution being compared to the brute force approach used in the original model and evaluated in terms of run time, complexity and the accuracy of the parents found. Finally, the impact the improved parent-finding routine has on the full algorithm is assessed through a series of comparisons between the original and enhanced hybrid models.</p><p>To form a layout of N multivariate objects :</p><formula xml:id="formula_0">1. Select √ N subset of objects [O( √ N )]</formula><p>2. Create 2D layout of subset using Chalmers' <ref type="bibr" target="#b6">[Chalmers 1996]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Reducing Complexity With Pivots</head><p>This paper describes a faster means of achieving the first stage of interpolation (step 3(a) in <ref type="figure">figure 1</ref>). The spring model run on the original √ N sample has completed, and the remaining N − √ N objects in the data set must be mapped onto this layout. The first stage of this process is the assignment of each remaining object to a 'parent' in the sample layout. The interpolation of an object begins with the creation of a circle around its parent, with radius proportional to the high-dimensional distance between object and parent. From the description of the technique in <ref type="bibr">[Morrison et al. 2002b]</ref> it is clear that the accuracy of placement will to a large extent be governed by the size of this circle.</p><p>The similarity in high-dimensional space between an object and its parent will therefore determine how close the object is placed to its ideal location.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Parent Selection: A Near-Neighbour Search</head><p>This parent-finding stage is an example of near-neighbour search. A near-neighbour from the √ N sample layout is sought for every point to be placed. We desire the best possible approximation to the point's closest neighbour in order to maximise the accuracy of the point's placement.</p><p>The problem of near-neighbour searching was first studied in the 1960s <ref type="bibr" target="#b11">[Minsky and Papert 1969]</ref>. Although research into this area continued in the following years, little improvement has been made, especially when dealing with sets of high dimensionality <ref type="bibr" target="#b8">[Indyk and Motwani 1998]</ref>. <ref type="bibr">[Chávez et al. 2001b</ref>] survey a number of efficient search algorithms and organise them into a taxonomy under a common unifying model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Brute force approach</head><p>In the original hybrid algorithm, a brute force approach was adopted in finding parents whereby a linear search was executed on the subset of objects making up the original sample layout. A distance calculation was performed between the object to be interpolated and every item in the sample layout, with the item yielding the least distance chosen as the parent.</p><p>Pseudocode for this brute force approach can be written as follows.</p><p>For all N − √ N yet to be laid out For all √ N in sample Perform distance calculation The resultant complexity can be calculated as</p><formula xml:id="formula_1">(N − √ N ) √ N D = N √ N D − N D = O(N 3 2 D) (where D represents a high-dimensional distance calcula- tion).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Improving upon brute force through random sampling</head><p>A saving in computation may be achieved by selecting a sample of the original subset on which to base parent searches. A linear search is still required, but this search executes on a far smaller set of objects than the previous method. It is hoped that a representative sample may be selected, so that the quality of parent found will not be greatly affected by this shortcut. Assuming a sub-subset of √ samplesize (size N 1 4 ), this would execute as:</p><formula xml:id="formula_2">For all N − √ N yet to be laid out For all N 1 4 in sample of sample Perform distance calculation (N − √ N )N 1 4 D = N 5 4 D − N 3 4 D = O(N 5 4 D)</formula><p>This demonstrates a significant saving over the previous brute-force method.</p><p>It should be noted that, although quicker, this approach will not always select the best possible object to act as the parent. Consequently, object placement during interpolation will be less accurate than that achieved through use of the full brute force approach. It is for this reason that the more computationally complex brute force model was implemented in the original hybrid model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Pivot-based parent-finding</head><p>This section describes a novel routine whereby the complexity of parent-finding is reduced without impacting on the quality of parent selected.</p><p>This near-neighbour search algorithm is based upon the pivot-based method of dimensional reduction. First used in Burkhard-Keller Trees <ref type="bibr" target="#b3">[Burkhard and Keller 1973]</ref> as a means of hierarchical binary decomposition of a vector space, pivots are now being used as the basis for techniques such as the Fixed Queries Array <ref type="bibr">[Chávez et al. 2001a</ref>] for proximity searching.</p><p>Central to this method of near-neighbour search is the idea that preprocessing a data set can reduce the work necessary at query time, and hopefully reduce the number of operations required overall. To preprocess, we select k points from within the data set to act as 'pivots'. Pivots are treated as having a certain number of buckets, each representing different ranges of distance from the pivot (as shown in figure 2). The rest of the data set may be stored in these buckets as determined by proximity to the pivot. In doing so, the data dimensionality may be reduced to k through the representation of each point only as a set of discretised distances from the pivots. Figure 2: Diagram of one pivot object (represented by the shaded point). A pivot has a certain amount of buckets, shown as numbered discs between the dotted circles. Each remaining data item is stored in one bucket, as determined by its proximity to the pivot.</p><p>For our purposes, we select a certain number of objects from the √ N sample layout (as selected in step 1 of figure 1) to act as pivots. Preprocessing involves assigning each nonpivot in this √ N sample to a bucket for each of k pivots. Thereafter, when we wish to find an object's parent, a distance calculation is performed between the object and each of the pivots. From this distance calculation, the appropriate bucket for each pivot is determined, and the contents of each of these buckets are searched for the overall nearest neighbour.</p><p>In these calculations, we assume a constant number of pivots, k, and that the number of buckets chosen for each pivot is</p><formula xml:id="formula_3">√ samplesize = N 1 4</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprocessing:</head><p>For all √ N in sample For constant number of pivots Perform distance calculation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query:</head><p>For p in 1..constant number of pivots Distance calculation // determine bucket for q in p // Find closest point in this bucket For i in 1..number of points in bucket Perform distance calculation</p><p>The complexity of the preprocessing stage is simply √ N kD = O( √ N D). When performing a query, we have the following average case complexity (the average number of points in a bucket is represented by</p><formula xml:id="formula_4">sampleSize numBuckets ). k √ N N 1 4 D = O(N 1 4 D)</formula><p>The query will be performed for all N − √ N points not yet placed, so will be</p><formula xml:id="formula_5">(N − √ N )N 1 4 D = O(N 5 4 D)</formula><p>Overall, then, complexity will be O(</p><formula xml:id="formula_6">√ N D) + O(N 5 4 D) = O(N 5 4 D)</formula><p>Again, this is a considerable saving in complexity over brute-force; equivalent in fact to the previously described sampling method. It is worth emphasising that this analysis is based upon average-case performance. A worst-case situation would arise if all the objects were to fall into the same bucket for all pivots. This situation could conceivably arise if a data set consisted of a very tight cluster and a number of remote outlier objects, with the pivots being chosen from the outliers. This is very unlikely as we would expect the sampling used in pivot selection to reflect object distribution. In this case, however, the entire subset would have to be searched and the complexity would therefore return to O(N 3 2 D). It can be seen, then, that the worst-case complexity of this method is as good as the previously used brute-force approach. Moreover, this worst-case is a remote possibility and we expect significantly better performance in the grand majority of instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental comparison of parentfinding methods</head><p>In this section, the three methods of parent-finding outlined in section 2.1 are evaluated experimentally: brute force, random sampling, and pivot-based. Execution times for each method are graphed, as are measures of layout quality as determined via a metric described in section 3.3. Finally, the impact of the choice of parent-finding method on the hybrid model is explored by comparing run times with the non-pivot-enhanced model. Evaluation took the form of a series of test runs of each algorithm on a set of audio data. The data were sampled from British television broadcasts during the 2002 FIFA World Cup as part of an investigation into the application of audiobased event detection to sporting events <ref type="bibr" target="#b2">[Baillie and Jose 2003]</ref>. 108000 seconds of audio were recorded, with each second treated as an object to be visualised.</p><p>A completed layout of the data set is shown in figure 3. Two main clusters are apparent in the data: AB and C. AB has two subclusters, labelled A and B in the figure. Through isolating individual objects and listening to the associated audio clips, we can deduce that the left-most of the two visible structures represents speech, with the section labelled A corresponding to in-match commentary and section B comprising studio-based pre or post-match analysis. Section C represents music occurring during the broadcasts.</p><p>Discussions were conducted with the domain experts as to how the audio data should be processed for use in MDS experiments. It was decided that the experiment set should be generated using Linear Predictive Coding (see <ref type="bibr">[Rabiner and</ref> Juang 1993] for an introduction) to create a 14-dimensional data set, with each dimension representing a weighted cepstral coefficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Run times for parent-finding</head><p>It has been shown that both random sampling and pivotbased selection are of lower computational complexity than the brute force approach. <ref type="figure">Figure 4</ref> further illustrates that the distinction in complexity is reflected in run times. <ref type="figure">Figure 4</ref>: Time taken to complete each of three methods of parent-finding on 14-dimensional data sets of sizes 10800-108000 objects. The graph displays mean results of ten runs performed on each size using each model. The audio data has been sampled to generate ten sets ranging in size between 10800 and 108000 objects. The graph shows results averaged over ten runs of each model using each size.</p><p>As predicted from complexity calculations, the brute force method is the most time-consuming for all data sizes. It is also apparent that the sampling method is the quicker of the two low-complexity models. However, as the following sections illustrate, this saving in time comes at the expense of accuracy of results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Accuracy of parent found</head><p>A simple test was conducted to determine the effectiveness of the parent-finding algorithms. High-dimensional distances were calculated between every two objects in a data set then ordered such that, for every object, a list was constructed ordering every other object in terms of proximity. That is, for element x, the first item in the list would be x's nearest neighbour in the full set, the second item the second closest to x and so on.</p><p>Once this list had been created, a parent-finding algorithm was run for the N − √ N objects to be interpolated. For each of these objects, the quality of the parent found was assessed by its proximity to the head of the list of nearest neighbours. The results were averaged over all N − √ N searches. The results, taken from a set of 1000 items and averaged over 5 runs for each method, are shown in the table below. A further case is shown whereby a completely random member of the subset is chosen in each case to be the parent.</p><p>We can see from the table that although the pivot-based method of parent-finding has considerably lower complexity than the brute force approach, the quality of parent  <ref type="figure">4</ref>, but it has produced significantly less accurate parents than its two competitor techniques. The forthcoming sections discuss the trade-off between accuracy and run time for the parent-finding stage. Obviously, for any given interpolation object, it is unlikely that the ideal neighbour would be in the √ N sample. As the brute force model is guaranteed to find the best possible neighbour from the sample, we see that the best possible results we can hope for are roughly the √ N 'th best neighbour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Cluster centroids as parents</head><p>As a point of interest, if the interpolation phase is based on a layout arising from k-means clustering <ref type="bibr" target="#b10">[MacQueen 1967]</ref>, <ref type="bibr">[Morrison et al. 2002a</ref>] rather than random sampling, we can expect to do rather better than finding the √ N 'th best neighbour. Consider figure 5, where the sample layout of cluster centroids is uniformly spaced. In terms of distance from a parent, the worst case we could imagine is a point on the boundary of two cluster regions (point A). If we assume that the data are evenly distributed (this will obviously not be the case in an average data set, but serves to illustrate this example), with √ N points in each of the √ N clusters, we would expect a point such as A to be the furthest point from that parent. Hence, the parent for point A would be the √ N 'th nearest point to A. Similarly, a point such as B would be the nearest neighbour to its parent.  On average (again under conditions of even distribution), one would expect a parent to be the 1 2 √ N 'th nearest neighbour to a query point. This is indeed what was discovered, as the brute force method applied to a layout of k-means centroids yields an average result of 16th nearest neighbour for a 1000 element data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Post-interpolation stress</head><p>We have outlined three methods of parent-finding and their effectiveness at selecting a near-neighbour. It is now necessary to assess the impact of choice of parent on layout quality. The quality of a layout is calculated via the metric of mechanical stress outlined in equation 1, where lij represents current layout distance between objects i and j and hij represents high-dimensional distance. A lower stress value indicates a better layout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stress</head><formula xml:id="formula_7">= i&lt;j (hij − lij) 2 i&lt;j l 2 ij<label>(1)</label></formula><p>For each of the parent-finding methods, we calculate the stress after the completion of the interpolation phase, again averaged over ten runs of each size of the audio data. As may be seen from figure 6, stress levels may be somewhat erratic. This is due to the interpolation being very dependent on the initial random sampling and spring model phases.</p><p>Despite the fluctuations, we can see that both the brute force and pivot-based methods exhibit lower stress than the sampling approach. As explained earlier, the brute force method will provide the lowest stress that we could expect for any given run, so it is a side-effect of sampling that we see the pivot-based method lower on some sizes. This does, however, serve to illustrate that the two methods yield similar stress levels, and continue to do so as data size increases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Effect on full hybrid model</head><p>It has been established that the pivot-based method of parent-finding reduces complexity and run times from the brute force approach, while still finding accurate neighbours and therefore creating layouts of low stress. Finally in this section, an investigation is conducted into the effect of the choice of parent-finding model on the full hybrid model.</p><p>The stress present in the layout after interpolation was given in section 3.3. We aim to reduce this stress in the final stage of our visualisation technique, where a linear per iteration spring model is run over the entire data set (step 4 in figure 1). To attempt to find an optimal layout, the spring model may be set to terminate when the average velocity drops below a specified threshold; an effect we expect when the layout has converged to a state of low stress.</p><p>We would predict that a layout with a higher stress level after interpolation would require more iterations of this final <ref type="figure">Figure 7</ref>: Total times for layout generation for each of the parent-finding methods.</p><p>spring model until termination and therefore have longer run times overall. <ref type="figure">Figure 7</ref> (detailing experiments averaged over ten runs on the same audio data) illustrates the total times for the complete visualisation process. Here we see that the pivotenhanced model is clearly the fastest of the three. The model using random sampling was, as expected, by far the slowest, due to the extra iterations of the spring model required to lower its high stress. From this, it can be concluded that it is worth investing the extra effort in the parent-finding phase. Although techniques such as brute force and pivots take more time at this stage, the interpolation is performed more accurately, and, as such, the required number of final iterations is reduced, resulting in a saving of time overall.</p><p>The pivot-based model is the quickest overall due to the low complexity and accuracy of its parent-finding approach.</p><p>As the model has been set to terminate automatically when the layout approaches stability, layout qualities are expected to be constant across all variants of parent-finding procedure. This is indeed the case, with average stress values of 0.21452, 0.21445 and 0.21459 for the brute force, pivots and sampling models respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">The relationship between complexity and run times</head><p>It is worth emphasising that although the parent-finding stage has been shown to be the computational bottleneck in the hybrid model, it does not necessarily follow that it is the most time-consuming stage. <ref type="figure" target="#fig_6">Figure 8</ref> illustrates this point. The horizontal bars represent the time spent performing interpolation. Each bar is divided to show the proportions of time spent in parentfinding (left) and object placement (right). It is apparent that the object placement stage is the most time-consuming of the model. Although running in linear time, the constants selected are sufficiently large to result in longer run times than the O(N 5 4 ) parent-finding stage for data sets of this size. It may also be seen, however, that as the data size increases, the proportion of time spent on parent-finding also rises. As the size of data set continues to increase, it is likely that there will come a point where the more computationally complex stage overtakes the linear routine. We are beginning some initial test runs with larger sets of data to determine where this crossover occurs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>This paper has examined the most computationally expensive phase of the hybrid MDS algorithm of <ref type="bibr">[Morrison et al. 2002b]</ref>, namely parent-finding. We proposed a novel pivotbased technique for parent-finding, and compared it against both random sampling and the original brute force method. Algorithmic analysis shows that the technique lowers the computational complexity of the 2002 algorithm: O(N 5 4 ) rather than O(N 3 2 ). We also carried out some pilot experiments, involving larger data sets than we had previously been able to work with, which confirmed that the technique offers lower run times than its predecessor and produces good quality layouts in terms of stress. Our results also suggest that parentfinding becomes a more time-consuming part of the layout process as data sets get larger, and so the benefits of our algorithm should also increase with larger data sets.</p><p>Although our algorithm has been shown to perform well on the data described in this paper, we aim to further assess performance on data sets of varying size, dimensionality and distribution. In addition, it is our intention to perform comparisons between our parent-finding routine and alternative near-neighbour algorithms.</p><p>Overall, we have tried to make the most of the hybrid approach to algorithmic design, examining and profiling not just the overall algorithm but its components. Since large data sets with complex interrelationships are of increasing concern to scientists in many domains, we suggest that this kind of algorithm and this kind of algorithmic development can make a useful contribution to large-scale information visualisation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>-tune layout with a constant number of iterations of Chalmers' spring model run on the full data set [O(N )] Figure 1: 2002 Algorithm. Complexities are given in square brackets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Completed layout of audio data using hybrid MDS algorithm. Each point represents one second of sound. The clusters labelled A and B correspond to speech, while C represents music.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>2-dimensional layout of an approximately evenlydistributed data set with imposed clustering. Point A illustrates a worst-case example of distance from the parent, point B a best case.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Post-interpolation stress levels across different data sizes with 3 different parent-finders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Horizontal bars are divided to represent the proportion of time spent on parent-finding and object placement during interpolation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Accuracy of parents found, as determined by rank in list of nearest neighbours found is comparable. It is also worthy of note that the sampling method may have been the quickest in figure</figDesc><table><row><cell>Method</cell><cell>Rank</cell></row><row><cell>Brute Force</cell><cell>32</cell></row><row><cell>Sample</cell><cell>185</cell></row><row><cell>Pivots</cell><cell>35</cell></row><row><cell>Random</cell><cell>488</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgements</head><p>We thank Mark Baillie for providing data sets and sharing the results of his analysis and Greg Ross for assistance and discussion during algorithmic development.</p><p>We also thank the anonymous reviewers for taking the time to provide us with history and insight into classical MDS. Time and space constraints prevent us from further analysing this field here, although we intend to explore more of this literature in future work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visualizing sets of evolutionary trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Amenta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings InfoVis</title>
		<meeting>InfoVis</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="71" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The infosky visual explorer: Exploiting hierarchical structure and document similarities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kienreich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sabol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Droschl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kappe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tochtermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="166" to="181" />
		</imprint>
	</monogr>
	<note>formation Visualization 1, 3/4</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Audio-based event detection for sports video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baillie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference of Image and Video Retrieval</title>
		<meeting>the International Conference of Image and Video Retrieval</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>To appear in</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Some approaches to best-match file searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Burkhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="230" to="236" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fixed queries array: A fast and economical data structure for proximity searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chávez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Marroquín</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="113" to="135" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Searching in metric spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chávez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Marroquín</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="273" to="321" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A linear iteration time layout algorithm for visualising high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chalmers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="127" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Graph drawing by force-directed placement. Software -Practice and Experience 21</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M J</forename><surname>Fruchterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Reingold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1129" to="1164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Approximate nearest neighbors: towards removing the curse of dimensionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Indyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirtieth annual ACM symposium on Theory of computing</title>
		<meeting>the thirtieth annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="604" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ace: A fast multiscale eigenvectors computation for drawing huge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings InfoVis</title>
		<meeting>InfoVis</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Berkeley Symposium on Mathematics and Probability</title>
		<meeting>the Fifth Berkeley Symposium on Mathematics and Probability<address><addrLine>Berkeley</addrLine></address></meeting>
		<imprint>
			<publisher>University of California Press</publisher>
			<date type="published" when="1967" />
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Papert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<publisher>Perceptrons. MIT Press</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Combining and comparing clustering and layout algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chalmers</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2002-11" />
		</imprint>
		<respStmt>
			<orgName>Department of Computing Science, University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep. 148</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A hybrid layout algorithm for sub-quadratic multidimensional scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chalmers</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings InfoVis</title>
		<meeting>InfoVis</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="152" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast multidimensional scaling through sampling, springs and interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chalmers</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="68" to="77" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Fundamentals of Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><surname>Juang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Prentice-Hall, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Does organisation by similarity assist image browsing?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rodden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Basalaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sinclair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="190" to="197" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
