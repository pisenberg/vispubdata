<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NeuroBlocks -Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><forename type="middle">K</forename><surname>Al-Awami</surname></persName>
							<email>ali.awami@kaust.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanna</forename><surname>Beyer</surname></persName>
							<email>jbeyer@seas.harvard.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Haehn</surname></persName>
							<email>haehn@seas.harvard.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narayanan</forename><surname>Kasthuri</surname></persName>
							<email>bkasthur@bu.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
							<email>pfister@seas.harvard.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Hadwiger</surname></persName>
							<email>markus.hadwiger@kaust.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Engineering and Applied Sciences at</orgName>
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Medicine at Boston University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Center for Brain Science at</orgName>
								<orgName type="institution">Harvard University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">NeuroBlocks -Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2015.2467441</idno>
					<note type="submission">received 31 Mar. 2015; accepted 1 Aug. 2015; date of publication xx Aug. 2015; date of current version 25 Oct. 2015.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Neuroscience</term>
					<term>Segmentation</term>
					<term>Proofreading</term>
					<term>Data and Provenance Tracking</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Visualizing large-scale segmentation projects in connectomics. Left: The main view of NeuroBlocks, comprising a scalable &quot;pixelbased&quot; visualization of the current segmentation state on top, and a timeline for exploring the project&apos;s evolution at the bottom. Top right: Detailed view of a segmentation task assigned to a user, showing recent modifications and thumbnails of the corresponding tool states. Bottom right: Linked petascale volume rendering of the underlying microscopy data and the selected segmented object.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In recent years, connectomics has become a very promising subfield of neuroscience, with the aim to reconstruct the complete wiring diagram of the mammalian brain at nanometer resolution. To achieve this goal, high-resolution electron microscopy (EM) volumes of brain tissue are acquired at a rate above 10 to 40 megapixels per second <ref type="bibr" target="#b7">[8]</ref>, and subsequently have to be segmented, labeled, and analyzed.</p><p>Because of this, image and volume segmentation have become a major bottleneck in connectomics research. Successfully tackling the associated challenges requires a variety of tools as well as scalable visualization support. One area where visual representations and interactive visualization tools can be especially helpful is the integration of a wide variety of heterogeneous components, tasks, tools, and data types into a coherent, efficient workflow that is driven by interactive visualization. Currently, in neuroscience no existing tool targets this goal, which is therefore the aim of the work described in this paper.</p><p>Many tools used in current practice in neuroscience are still mostly based on performing manual segmentation, which is a very labor-and time-intensive process. Recently, a lot of research in computer vision and image processing has focused on developing (semi-) automatic segmentation methods for extracting cell boundaries and specific cell organelles from EM data. However, while fully automatic approaches in principle do not require any user interaction, they still exhibit higher error rates than manual segmentation. For this reason, a subsequent semi-automatic proofreading step is usually still necessary in practice, which again requires user interaction. To keep up with the fast increasing amount of raw data, neuroscientists now routinely manage a whole team comprising segmenters and proofreaders. They divide the segmentation tasks between these users, whose experience ranges from senior researchers to novice interns. This in turn makes managing and keeping track of the current segmentation data a very complex task. Users not only have different levels of experience, but might also be working remotely and at different locations. Furthermore, mentally keeping track of recent segmentation changes, double-checking and approving the changes of inexperienced users, as well as managing their workload and specific tasks has become a major issue that neuroscientists have to deal with.</p><p>Managing such a large-scale segmentation project is further complicated by the fact that a typical neuroscience lab uses a plethora of different tools for registration, segmentation, labeling, visualization, and analysis of the data. However, most of the time interfaces between different tools are non-existent. For example, navigating to the same spatial position in two different applications might require manually typing in the position that was extracted from one tool into the user interface of another tool. This also complicates keeping track of the current segmentation state, as switching between different tools is usually slow and cumbersome. Moreover, not all tools support the same kind of meta data, so interoperability becomes very difficult.</p><p>Therefore, it is an important goal to design a tool that supports neuroscientists in tracking the progress of very large volumetric segmentation data by offering visual abstractions and scalable views that makes tracking such a large amount of data feasible. Additionally, this tool needs to inherently support multiple users and different user groups, and should seamlessly integrate the diverse set of tools that are used in practice. At the same time, the visualization of the original microscopy data and the segmentation data in 2D and 3D is crucial, and needs to be tightly integrated into the overall workflow.</p><p>NeuroBlocks. We present a novel visualization system called Neu-roBlocks, for tracking the state, progress, and evolution of large segmented EM volumes. NeuroBlocks is a multi-user web-based application that supports provenance, accountability, and auditing of segmentation results. It tightly integrates 2D and 3D interactive visualizations of image and volume data, displays connectivity, and offers abstract data visualization views of the current and former segmentation states. It allows users to see, track, and manage segmentation data that are changing over time, together with the tools that were used in each step. It enables users to go back to any point of interest in time, and to the corresponding state of the tool used at that point.</p><p>Contributions. Our first contribution is the definition and discussion of a set of requirements and design guidelines for visually managing large-scale segmentation projects in the domain of neuroscience, which can be seen as a specific case of task progress management.</p><p>Our second contribution is the design of scalable visual representations for large segmentation data. Our visualizations are fully interactive, and allow users to track the current state, evolution, and progress of the on-going segmentation and proofreading tasks and projects.</p><p>Our third contribution is a direct integration of multi-user supportincluding different user groups with varying permissions, experience, and assigned tasks-into the visualization. NeuroBlocks allows auditing and crediting of users, and provides accountability of who did what and when. Furthermore, we enable users to seamlessly switch between different (segmentation) tools and their respective application states.</p><p>Finally, our fourth contribution is a demonstration of the utility of our design based on two case studies. The first case study is performed by a domain expert, who manages and tracks a large segmentation project. The second case study is performed by a relatively inexperienced proofreader, who uses NeuroBlocks to complete the assigned tasks and to quickly switch between different segmentation tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Connectomics. The main goal of connectomics is reverse-engineering the brain and its neuronal connectivity through the use of highresolution and high-throughput imaging techniques. Introductions to connectomics are given by Lichtman and Denk <ref type="bibr" target="#b26">[27]</ref> and Seung <ref type="bibr" target="#b32">[33]</ref>.</p><p>Segmentation and proofreading for connectomics. Before the neuronal connectivity can be extracted from EM data, correct annotation and segmentation of the acquired data volumes is necessary, which is currently one of the main bottlenecks in the connectomics pipeline. Despite its obvious limitations and lack of scalability, manual annotation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b29">30]</ref> is still widely used in practice. More recently, semi-automatic segmentation approaches <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b36">37]</ref> as well as fully automatic methods for segmenting neuronal structures <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b21">22]</ref> have received a lot of attention. While these automatic approaches are more scalable than manual segmentation and require only little or no user input, they still often need an additional proofreading step, where erroneous segmentations are fixed in a semi-automatic fashion <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>To handle huge amounts of EM and segmentation volumes, as well as additional annotations and labels, Burns et al. <ref type="bibr" target="#b10">[11]</ref> recently presented the open connectome project, a scalable data infrastructure for annotation and analysis of high-throughput brain imaging data.</p><p>Visualization in connectomics. Most visualization tools for connectomics focus either on displaying the abstract connectivity between cells, or on displaying the original image/volume and segmentation data. The Viking Viewer <ref type="bibr" target="#b2">[3]</ref> represents neurons as nodes in an abstract connectivity graph. NeuroMap <ref type="bibr" target="#b37">[38]</ref> makes use of circuit wiring diagrams to represent all possible connections of neurons. NeuroLines <ref type="bibr" target="#b0">[1]</ref> uses a relative distance-preserving subway map metaphor to visualize and explore neuronal connectivity at the level of individual synapses.</p><p>For exploring petavoxel EM data, Hadwiger et al. <ref type="bibr" target="#b15">[16]</ref> have presented a volume rendering pipeline that is entirely driven by the visibility of volume bricks in the final image, which was later extended to segmented volumes <ref type="bibr" target="#b6">[7]</ref>. BrainGazer <ref type="bibr" target="#b8">[9]</ref> and ConnectomeExplorer <ref type="bibr" target="#b5">[6]</ref> focus on interactive and visual queries to explore brain connectivity. We have integrated the latter framework into NeuroBlocks as one of several available options for 3D visualization.</p><p>However, all of these visualization applications assume a fixed segmentation state. They do not show the progress and evolution of largescale segmentation volumes and projects.</p><p>Provenance and progress tracking. Capturing provenance data in computational tasks (e.g., visualization systems) is crucial to make data exploration, processing, and analysis reproducable <ref type="bibr" target="#b12">[13]</ref>. The Vis-Trails system <ref type="bibr" target="#b3">[4]</ref> is an open-source framework that tracks and stores provenance data for visualization pipelines. It not only captures data provenance, but also provenance of the user's exploration process. VisTrails and its provenance management have been incorporated into many different applications, ranging from creating visualizations by analogy and query-by-example <ref type="bibr" target="#b31">[32]</ref>, to provenance-aware workflows for oceanography <ref type="bibr" target="#b18">[19]</ref>, and reproducable scientific experiments <ref type="bibr" target="#b13">[14]</ref>.</p><p>Other provenance systems include Halaschek et al. <ref type="bibr" target="#b17">[18]</ref>, who track provenance for annotation and management of images on the semantic web, while Simmhan et al. <ref type="bibr" target="#b35">[36]</ref> track the derivation history of data for provenance in data-driven workflows. More recently, Al-Naser et al. <ref type="bibr" target="#b1">[2]</ref> employ provenance in the context of seismic visualization to manage multi-user and multi-version seismic interpretations. However, none of these systems have tackled provenance for large segmentation data in complex, distributed workflows.</p><p>Pixel views and comparative visualization. The goal of pixel views or dense information views is to represent as many data objects as possible within the available screen space. Keim <ref type="bibr" target="#b22">[23]</ref> discusses design decisions for pixel-oriented views for visualizing large multi-dimensional data sets, including different pixel arrangements, such as Morton curves or query-based ordering. A common twodimensional space-filling approach for representing tree structures are Treemaps <ref type="bibr" target="#b33">[34]</ref> and their extension to squarified treemaps <ref type="bibr" target="#b9">[10]</ref>. Heatmaps are another type of dense information visualization, and are very popular in bioinformatics and genomics <ref type="bibr" target="#b25">[26]</ref>.</p><p>OnSet <ref type="bibr" target="#b30">[31]</ref> is a space-filling visualization of binary set data that supports comparison between and combination of sets, and scales to several hundred elements per set. Gleicher et al. <ref type="bibr" target="#b14">[15]</ref> have presented a general survey on comparative visualization. They introduce a general taxonomy of visual design for comparisons based on juxtaposition, superposition, and explicit encoding. More recently, Wang et al. <ref type="bibr" target="#b39">[40]</ref> have proposed a treemap approach for displaying similarity-based im- age collections on large tiled displays. Lindemann et al. <ref type="bibr" target="#b27">[28]</ref> have presented a volume visualization system for comparative visualization of segmentation masks from different modalities or different timesteps. However, they focus on medical data comprising only a small number of segmented objects, whereas in our target area of connectomics we have to deal with thousands of objects or more in a single data set.</p><p>Multi-scale and multiple linked views. Efficient means for exploring large numbers of data elements are hierarchical navigation metaphors and focus-and-context techniques <ref type="bibr" target="#b34">[35]</ref>. In the context of connectomics, NeuroLines <ref type="bibr" target="#b0">[1]</ref> uses a multi-level navigation metaphor, with the lowest level inspired by heat maps and extended table lenses <ref type="bibr" target="#b38">[39]</ref> for multi-column sorting. Lex et al. <ref type="bibr" target="#b25">[26]</ref> use a multi-tier focus-and-context approach for large heat maps in genomics.</p><p>An alternative approach to linking views-or even entire applications-together was presented in ManyVis <ref type="bibr" target="#b28">[29]</ref>, which is a framework that can combine different independent visualization tools into a single integrated application by intercepting and processing lowlevel user interactions. ManyVis was also used to implement rapid annotation of large microscopy images, with the focus of integrating an out-of-core visualizer into Adobe Photoshop. However, ManyVis does not incorporate provenance or tracking of segmentation changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BASIC DESIGN CONSIDERATIONS</head><p>We first discuss the major design considerations for NeuroBlocks, starting with the necessary neuroscience background, then describing the general goals, domain-specific tasks, and challenges we have identified. Finally, we motivate our design decisions and considerations, including lessons learned from previous alternative design prototypes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neuroscience Background and Workflow</head><p>The connectomics workflow of our collaborators starts with highthroughput electron microscopy image acquisition of tiny samples of mouse brain tissue. This results in image tiles with a resolution of 3-5 nm per pixel, and a slice thickness of 25-30 nm. Before further data processing, the image tiles are stitched and registered to form a single 3D volume with a slice resolution of 20,000 to 100,000 pixels, and up to tens of thousands of slices. The next step in the pipeline consists of segmenting and annotating the neural structures in the data, before visualization and final analysis can be performed (see <ref type="figure">Figure 2</ref>).</p><p>In connectomics, the main goal is to construct a wiring diagram of how individual neurons (i.e., nerve cells) are connected in the brain. Neurons transmit electrical signals to neighboring neurons over synapses, the connections between neurons. The size and form of neurons can vary widely, but typically they consist of several dendrites, tree-like branching structures that receive input from other neurons, and an axon, a long and narrow tubular structure that transmits signals away from the cell body towards other neurons. Additionally, neurons have several sub-structures or cell organelles, and even synapses have additional discriminating features, such as vesicles, boutons, or spines.</p><p>The high structural variability of neurons combined with the low signal-to-noise ratio of EM images make segmentation of this data type challenging. Therefore, and because of the large data sizes, segmentation is often the bottleneck of the entire connectome workflow.</p><p>Our collaborators use a wide variety of tools for registration, segmentation, visualization, and analysis. Almost every researcher has their own favorite tools, often very specific to the task they want to perform. Currently, our collaborating neuroscientists routinely use VAST <ref type="bibr" target="#b4">[5]</ref> for manual segmentation, and the RhoANA pipeline <ref type="bibr" target="#b21">[22]</ref> for automatic segmentation. The RhoANA pipeline performs state-ofthe-art automatic reconstruction of neuronal processes in terabyte EM data based on a random forest classifier coupled with an anisotropic smoothing prior in a conditional random field framework and 3D segment fusion. Our collaborators typically generate a slightly oversegmented dataset to simplify and speed up the semi-automatic proofreading step, which is performed in Mojo <ref type="bibr" target="#b24">[25]</ref> and Dojo <ref type="bibr" target="#b16">[17]</ref>. During this proofreading step, additional data and metadata can be generated, such as synapse labels (stored as x, y, z positions), textual labels, or segment names. For visualization and analysis, our collaborators use Matlab, ConnectomeExplorer <ref type="bibr" target="#b5">[6]</ref>, and NeuroLines <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Task Analysis</head><p>The design of NeuroBlocks was developed in close collaboration with neuroscientists working in the field of connectomics. Over the course of several months we have conducted detailed informal as well as semi-structured interviews with four domain scientists focusing on EM-based connectomics research: two grad students, one postdoctoral researcher, and one faculty. Our collaborators typically work on largescale segmentation projects, with data sets ranging up to hundreds of terabytes in size. Although oftentimes these data do not have to be segmented in their entirety, the required effort is still so large that many undergrads and interns are employed as segmenters or proofreaders, which places a significant management burden on the scientists.</p><p>A common finding in our interviews was that even though the ultimate goal of the neuroscientists is the analysis of their data, most of their time was spent on segmenting, labeling, and proofreading data (see <ref type="figure">Figure 2</ref>, bottom). Interestingly, even though three of them initially worked at the same lab, they all used different combinations of segmentation and visualization tools, and there was no "standard workflow." For example, switching from segmentation tools to visualization or analysis tools was mostly a hand-tuned, improvised solution and sometimes required several hours to export the data from one tool into the next. Keeping track of the current and previous states of the segmentation was not supported by any of their tools, even though our collaborators considered this to be one of the most cumbersome tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Domain Goals</head><p>The ultimate goal of our collaborators is doing research based on analysis of their segmented data. However, in order to achieve this, their immediate goal for NeuroBlocks is having a framework for managing, verifying, and tracking the state of individual segmentation projects.</p><p>This includes (a) seeing the current segmentation, (b) tracking its evolution, (c) managing multiple users with different levels of experience and having an overview of their current progress, (d) creating subtasks and tracking their progress, and (e) being able to look at the segmentation in 2D and 3D with different tools, and moreover being able to seamlessly switch between them.</p><p>For example, a scientist might assign four segmenters to four different proofreading tasks. The segmenters do not have a lot of experience, so the scientist has to individually approve all of their changes (e.g., by looking at a diff image in 2D or 3D), before they are merged into the main segmentation volume. Once these tasks are completed, the scientist can use NeuroBlocks to quickly extract a meaningful subset of the segmented data for a preliminary analysis of the data, or to generate a progress report of the current state of the segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Domain-Specific Tasks</head><p>We have identified the following domain tasks for managing largescale segmentation projects in neuroscience:</p><p>T1 -Overview and detail visualization of the current segmentation state. Dense segmentations of large EM volumes can contain hundreds of thousands of objects. Neuroscientists need to be able to get an overview of the entire data set, while also being able to look at individual segments in detail. A combination of 2D and 3D visualizations of the original volume data for highly detailed views in combination with visual abstractions for higher-level contextual information is required to fulfill this task.</p><p>T2 -Track changes to the segmentation volume. Especially in large-scale segmentation projects, with multiple people collaborating on the same data set, it is necessary to not only look at the current state of a segmentation, but also at previous states and their evolution.</p><p>T3 -Manage fine-grained segmentation tasks. Being able to discuss task-specific details, and to collect and visualize provenance of the used tools for a specific task, are crucial for accountability of segmentations, and for coordinating the tasks of multiple users.</p><p>T4 -Audit users and segmentations. The importance of provenance and accountability for creating scientific results based on a user's segmentation requires the possibility to audit and verify individual segmentations created by a specific user.</p><p>T5 -Switch seamlessly between different segmentation and visualization tools. One of the main unnecessary bottlenecks of our collaborating scientists is when they have to switch from one tool to another one. Therefore, it is crucial to develop a framework that seamlessly integrates the different tools that are currently used, while also planning for easy future extensibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Challenges</head><p>The goals and domain-specific tasks described above directly correspond to some of the challenges of designing a framework for managing large-scale segmentation projects. One of the biggest fundamental challenges is achieving scalability: with respect to overall data size, the number of segmentations, the number of segmentation changes, the number of current tasks, and the number of users.</p><p>Typical projects comprise many, often distributed users of different experience levels in segmentation and proofreading. The current strategy of our collaborators is to hire high-school interns for proofreading tasks. Naturally, not all interns will create segmentations of equally high quality. Therefore, multiple hierarchical levels of checking and approving changes to the segmentation need to be employed.</p><p>Finally, the diverse eco-system of the current segmentation and visualization tools available for connectomics data makes it difficult to find a common standard that is supported by the most common tools.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Design Iterations</head><p>Our collaborators were initially interested in having something similar to a virtual lab notebook, which would allow them to track their progress and jot down notes in a semi-structured fashion. Our first design was heavily based on this idea, and consisted of a virtual notebook that also allowed users to dynamically integrate external visualization and analysis applications into their notebooks (see <ref type="figure" target="#fig_0">Figure 3</ref> (a)).</p><p>This was well received and we subsequently focused more on the aspect of provenance, how to track the current analysis, and how to quickly explore similar analysis or visualization options. An initial design of this stage is shown in <ref type="figure" target="#fig_0">Figure 3</ref> (b). It includes a provenance tree of different analysis states. However, over the course of several meetings with our domain scientists it became obvious that their current main bottleneck was handling the segmentation part of their project, not the visualization by itself and the actual analysis. This means that for the major part of their projects they are mostly interested in the current state of their data and its segmentation. Only in the later stages of a project are they interested in the state of their analysis and visualization.</p><p>We therefore adjusted our objective from an analysis-centric view on their project to a data-centric view on their project, see <ref type="figure" target="#fig_0">Figure 3</ref> (c). This allowed the scientists to focus on the current segmentation and leverage a data abstraction based on specific neuroscience objects (e.g., axons, dendrites). This shift to a data-centric view drastically expanded the way our collaborators thought about the project, and was the single most important design decision during the course of the project. However, they found the initial treemap design with variable sized elements confusing and preferred a fixed size for all elements.</p><p>A sketch of the final design of NeuroBlocks is shown in <ref type="figure" target="#fig_0">Figure 3 (d)</ref>, with a main data view, a timeline, a task list and a detailon-demand view for showing details of a selected element in the data view. By using visualization not just for the analysis and exploration of the final data, but already for tracking their segmentation progress, our collaborators now have a much better grasp of their data, of the parts that are still missing and need to be identified and segmented, and they are more aware of potential problems in their segmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">VISUAL DESIGN</head><p>The final visual design that we have implemented comprises several linked views. <ref type="figure">Figure 1</ref> shows the main elements of a segmentation project in NeuroBlocks: a segmentation state view, a timeline, and different views for details-on-demand. Additionally, NeuroBlocks integrates 2D and 3D views of the original EM volume and segmentation data <ref type="figure">(Figure 1, right)</ref>, as well as "diff" views of segmentation changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Visualizing the Current Segmentation State</head><p>The objective for visualizing the current segmentation state is to provide a dense overview of the available segmentation data. To guarantee scalability to tens of thousands of segmented objects, the provided visualization abstracts and simplifies the underlying volumetric data significantly, but details can always be shown on demand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Segmentation State Pixel View</head><p>The main view of NeuroBlocks is the data-centric segmentation state pixel view. To achieve scalability with respect to the number of segments in the segmentation project, we chose a pixel-based representation of the data, where each visual element represents one segment. We call this visual element a pixel, even though it is usually larger than a screen pixel. This visual abstraction enables us to create a compact overview visualization that is dense in information and can show thousands of individual segments at the same time in the available screen space. Details of individual pixels can be shown on demand and explored in the multiple linked views (see Sec. 4.3).</p><p>In the default state, the segmentation state pixel view displays the current state of a segmentation project. Individual segments are shown as pixels and are structured in a hierarchy, according to a neuroscience taxonomy that our collaborators follow when labeling the data. For example, a segment can be categorized as segment ∈ spine ∈ dendrite ∈ neuron. Several segments can belong to the same segmentation object, and alternatively we can map entire segmentation objects to individual pixels, instead of mapping individual segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Sorting, Filtering and Layouting</head><p>Pixels in the pixel view are sorted, filtered, and highlighted based on user input. Default settings can be specified for each NeuroBlocks project separately. For example, in a project that focuses on proofreading of automatically segmented data, the project manager would get a view where pixels are sorted based on proofreading completion status with a color-coding that shows the number of modifications in a segment. This enables directly getting an overview of the current progress. Other options for sorting and filtering include showing only segments that were modified by a certain user, sorting by segment size, or highlighting all segments that were modified since the user last logged in. Pixels are always sorted from left to right and top to bottom, to correspond to the general reading direction. The individual pixel size is either set to a constant, or adjusts automatically based on the number of available segments. To ensure that the pixel size never falls below a certain threshold, a multi-scale representation is displayed if there are too many pixels for the current display (see Sec. <ref type="bibr" target="#b3">4</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.1.3).</head><p>The pixel view supports three main layouts: Pixels can either be displayed in a nested hierarchy, as treemap <ref type="bibr" target="#b33">[34]</ref>, or in a flat view. The nested hierarchy is shown in in <ref type="figure">Figure 1</ref>, and clusters segments based on their assigned neuroscience category. This category is typically assigned either during segmentation or proofreading. The treemap view also shows the data clustered based on segment category, but avoids any white space. The flat view avoids any clustering, and displays all segments as a single block. This is particularly useful for fast sorting and filtering over all segments, and for uncategorized data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Multi-Scale Visualization</head><p>Automatic segmentation methods typically over-segment data because merging segments in the subsequent proofreading step is easier and faster than splitting segments <ref type="bibr" target="#b16">[17]</ref>. This, however, often results in a large number of individual segments, exceeding the available screen space in our pixel view. Therefore, we developed a multi-scale pixelbased view, guaranteeing visibility of the entire data set on screen.</p><p>The multi-scale view is computed based on the sorting order of the segments, and recursively combines a pre-defined number of pixels into a single "super-pixel." Conceptually, this is similar to downsampling. However, we can specify the number of elements that are combined into a super-pixel as well as the type of aggregation operation (e.g., average, min, max). <ref type="figure" target="#fig_1">Figure 4</ref> shows a multi-scale pixel view with the coloring highlighting the recent changes in the segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Visualizing the Segmentation History and Evolution</head><p>In addition to showing a single timestep or snapshot of the segmentation, NeuroBlocks also supports exploring the evolution or provenance of the segmentation. In contrast to most provenance visualization systems, we do not focus on a graph-based visualization of provenance data, but chose a timeline-based approach for navigating between different segmentation states. This has the advantage that it is easy to navigate at multiple time scales, and that it is intuitive for novice users.</p><p>Exploring the evolution of the segmentation is supported in three different ways: First, by moving a slider through a timeline (see Sec. 4.2.1), users can navigate through the segmentation history. In this mode, the pixel view is synced to the time slider and shows the segmentation state at the position of the time slider. While moving the slider, the pixel view transitions between the different time steps in a smooth animation. This allows users to intuitively follow the evolution of the segmentation and see newly added segments or track how segments change size over time. Second, the user can choose two timestamps, and the pixel view will then show a direct comparison between these two states. This highlights the changes that have occurred between two distinct time steps. Segments can be color-coded and sorted based on different criteria, such as change in size, or showing the segments whose categorization changed in the specified time interval. Finally, NeuroBlocks offers a multi-scale time navigation. For a specified time span or time interval, the pixel view can display the frequency of change in segments. This time interval can be resized and moved interactively, similarly to the time slider.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Timeline View</head><p>In addition to navigating between different time steps and temporal intervals via time sliders and brushes, the timeline view can also directly visualize attributes over time. While the former can be used to explore the evolution of a segmentation project, and to explore the project in different time scales and intervals by using linking and brushing, the latter offers a direct visualization of user specified attributes over time, which are displayed as stacked area charts. The default attributes that are shown vary depending on the type of project and the current user. For example, it can show recent activity of all users, the amount of change in segments over time, or task status. The timeline in <ref type="figure">Figure 1</ref> shows the activity of different users, and how many segments they have modified recently. The timeline is implemented as a dynamic scale and allows users to switch between highly detailed views of individual days or hours, and coarse views of entire weeks or months.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Visualizing Details on Demand</head><p>Once the user has examined the high-level structure of a segmentation project, NeuroBlocks offers different views for exploring the details of individual objects, tasks, users, and segments. Details are typically shown on demand, whenever a segment is selected in the pixel view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Segment and Object Detail Views</head><p>Individual segments and objects (i.e., semantic structures that consist of more than one segment) can be examined in more detail in the segment view and the object view, respectively. <ref type="figure" target="#fig_2">Figure 5</ref> displays a segment detail view, including an interactive 3D preview of the selected segment (top left), the segmentation history (bottom left), and a connectivity view (top, second from right). <ref type="figure" target="#fig_2">Figure 5 (right)</ref> shows the selected segment in a ConnectomeExplorer 3D volume view.</p><p>The object and segment detail views allow users to explore previous edits to the segmentation, and allow senior users to approve or reject a proposed segmentation change. Additionally, the previous segmentation states of the selected segment can be displayed as thumbnails, and allow users to directly go back to that state in the corresponding segmentation tool by clicking on the thumbnail. Details about the segmented object, all its segments, revision history, and collaborators are shown in this view. Recent changes to the segmentation can be examined in detail and at full resolution in the integrated volume renderer, and then be approved or discarded by the user. The view at the bottom right shows a "diff" of the most recent merge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Connectivity View</head><p>Neuronal objects such as axons or dendrites are typically very highly interconnected. Therefore, NeuroBlocks offers an abstract object visualization that shows which segments are part of an object, and a nodelink diagram showing the directly connected neighbors ( <ref type="figure" target="#fig_2">Figure 5</ref>).</p><p>The center of the connectivity view shows the selected object as a circular node, and all the segments it contains as pixels within that object. Whenever a pixel is selected in the main pixel view, the connectivity view gets updated and the selected segment is highlighted in both views respectively. Connectivity of objects is based on the labeled synapses an object makes to neighboring cells. These connected objects are displayed in the connectivity view as small nodes that share an edge with the object in focus. Clicking on these nodes allows users to navigate to the connected objects and to explore them in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">External Views</head><p>One essential feature of NeuroBlocks is the integration of a diverse set of external tools that support segmentation, proofreading, visualization, and analysis. Currently, we have integrated Dojo, a web-based proofreading application (see <ref type="figure">Figure 1)</ref>, and ConnectomeExplorer, a scalable volume visualization and analysis application (see <ref type="figure" target="#fig_2">Figure 5</ref>).</p><p>Dojo supports fast volume navigation based on a 2D slice view and and also offers a basic interactive volume rendering view for previewing the current segment in 3D. Dojo enables operations such as semiautomatic merging and splitting of segments by directly drawing and clicking on the segments in the slice view.</p><p>ConnectomeExplorer allows for high-quality volume rendering of terabyte-sized datasets. It can render the original data in combination with the segmentation data and users can interactively change parameters such as clipping planes, transfer functions, or enabling/disabling segments. Additionally, ConnectomeExplorer has a "diff" view for visual comparison between two segmentation states.</p><p>While working with external tools, their current state is periodically sent to NeuroBlocks and stored in a provenance database. These state snapshots are displayed as thumbnails in NeuroBlocks and enable users to reset their tool to any previous state to continue working from there. Furthermore, we have integrated the Dojo proofreading tool directly into the main view of NeuroBlocks. In this way, whenever the user selects a specific element, a 2D or 3D rendering of that segment or object is directly displayed in the sidebar of NeuroBlocks, without having to switch between different views or windows (see <ref type="figure">Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Management Views</head><p>Similarly to the object view, the task view provides the details for a specific task, its recent activity, and the people assigned to work on it. From this view, it is also possible to navigate to individual objects or segments that were modified in that task, and to explore the recent states of the used external tools (see <ref type="figure">Figure 1 top, second from right)</ref>.</p><p>The user view is designed mainly for project managers and allows them to assign users to different groups with different default views and privileges. Furthermore, it offers an interface to audit users, the tasks they have been working on, and the objects that they have modified. Other user groups can look at their profile to get summary statistics of their work. These summary statistics include a graph showing the number of contributions (i.e., segmentation changes) users made over time and a calendar view showing their activity over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">INTERACTION DESIGN</head><p>The interaction features of NeuroBlocks were designed to support the domain-specific tasks discussed in Sec. 3.2 as intuitively as possible. NeuroBlocks supports multiple user roles that can have different privileges and default visualization views associated with them. By default, NeuroBlocks has three different user roles: segmenters and proofreaders, senior segmenters, and project managers -all with different default views and interaction possibilities. Project managers, for example, can create and assign tasks, audit segmentations, and assign users to different projects and tasks. Segmenters, on the other hand, can only modify segments based on their currently assigned tasks, and might need supervisor approval before their suggested changes are accepted into the current segmentation state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Project Status Exploration</head><p>Exploring the overall status of the current project is mainly done in the segmentation state view and the timeline view. User interaction consists of filtering, sorting, and color-coding pixels in these views based on different criteria, but default configurations are provided to support specific tasks. For example, in a manual segmentation project, the project manager would see all segments, sorted by creation date and color-coded according to size. This enables users to see which segments have been added recently, and to follow the progress of the segmentation (i.e., segments growing in size as they are being traced through the volume by a segmenter).</p><p>Furthermore, users can get details on individual segments in the provided linked views, and explore the evolution of the segmentation over time with time sliders and brushes in the timeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Task Creation</head><p>Segmentation tasks are created by project managers during their project exploration process and often depend on previouslyaccomplished tasks. For example, manual segmentation projects typically start with completely segmenting a single object of interest and labeling its synapses (by marking the synapse locations in the image viewer). Objects of interest are selected by domain scientists based on their domain-specific analysis goal and are identified by the objects' location, size, anatomy, or connectivity (e.g., a central, highlyconnected dendrite). In the next step, new segmentation tasks are created for all connected structures sharing synapses. New tasks can be defined at any spatial position or segment, and proofreaders are automatically set to the specified starting position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Task Completion</head><p>To minimize user interaction overhead, users who start working on a task are automatically transferred to the correct state and location in the integrated proofreading or segmentation tool. While they are working on their task, they can mark and report unclear areas in the data, and save additional comments. Their current progress is automatically saved in NeuroBlocks. Users can stop and interrupt their work at any time, and can later automatically resume at the exact same state, even when working on different computers. Once a task is marked as complete it will be submitted for approval to a project manager.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Task Approval and Audits</head><p>Project managers see a list of completed tasks and segmented objects that need approval, and can check the correctness of the data before they officially close a task or "lock" a segmented object. Locked objects are considered to be correctly segmented, and cannot be touched or modified anymore (unless explicitly re-opened).</p><p>Audits are a more formal evaluation of recent accomplished work to ensure that the project meets certain quality standards. NeuroBlocks supports audits for tasks, objects, segments and users. This helps in  <ref type="figure">Fig. 6</ref>. NeuroBlocks system design. The NeuroBlocks server integrates user management, handling of meta data, and a provenance database. External applications can use the NeuroBlocks plugin API to communicate with NeuroBlocks and access the original volume and segmentation data, which is stored on a shared filesystem.</p><p>identifying (junior) segmenters that need more training or do not have the required concentration for longer proofreading tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">SYSTEM DESIGN AND IMPLEMENTATION</head><p>The overall system design with the major components of NeuroBlocks is shown in <ref type="figure">Figure 6</ref>. NeuroBlocks is implemented as a web-based client/server application. The server integrates user management, handling of meta data, and can access the provenance database. The user only needs a web browser to connect to the server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Data Management</head><p>The original EM volume and the current segmentation volume are stored in a multi-resolution format on a shared file system, and can either be accessed directly from there or via on-demand data streaming from a data server process <ref type="bibr" target="#b15">[16]</ref>. To avoid having to store different snapshots of the entire segmentation volume over time, we only store the changes to the data in our provenance database, which allows us to roll back to previous versions without data loss. Currently, our provenance module is implemented as a MongoDB database. However, our modular design would allow us to easily plug in different provenance back-ends in the future, such as VisTrails <ref type="bibr" target="#b3">[4]</ref>, for example. All segmentation meta data (e.g., textual labels, marked synapse locations, object attributes) are stored in a MongoDB database, which can easily be extended to incorporate new attributes or object types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Multi-Tool Support</head><p>One of the main design decisions during the development of Neu-roBlocks was to support the largest possible number of external tools that are or might be used by neuroscientists to segment, analyze, and visualize their data. NeuroBlocks offers a general API to allow external applications to plug into the system. The API has been designed in a way that makes it very easy to integrate external tools, with a minimum amount of required programming on the tool side. After a handshake protocol and user authentication, external applications send their states and meta data to NeuroBlocks and receive updates in turn.</p><p>Currently, we have integrated two external applications that exemplify how very heterogeneous tools can easily be integrated into Neu-roBlocks: ConnectomeExplorer <ref type="bibr" target="#b5">[6]</ref> is a GPU-based volume renderer that runs locally on the user's machine and is integrated into Neu-roBlocks by using the general API. Dojo <ref type="bibr" target="#b16">[17]</ref>, on the other hand, is a web-based multi-user proofreading system for which we implemented a tighter coupling into NeuroBlocks. It still uses the general API for communication, but we display Dojo's views directly in NeuroBlocks, without using a separate browser window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Implementation</head><p>NeuroBlocks is implemented in JavaScript and uses Meteor, an open source JavaScript framework for client/server applications. The interactive visualizations are implemented in D3. The provenance and data handling back-ends are built on MongoDB (a noSQL database). Communication with external tools is based on TCP sockets and websockets. To run NeuroBlocks, users only require a web browser, no installation is needed. To run Dojo with high-quality rendering settings, the web browser has to support WebGL. To run ConnectomeExplorer for interactive 3D visualization of the data, a standard Windows PC with at recent NVIDIA GPU is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CASE STUDIES AND DISCUSSION</head><p>We present two case studies that demonstrate how NeuroBlocks is useful in managing large-scale connectomics segmentation projects. We evaluated the case studies with our collaborating neuroscienctists from the Harvard Center for Brain Science and the School of Medicine at Boston University. Throughout the project, we had regular meetings with them to discuss the goals and detailed tasks in NeuroBlocks. We performed informal as well as semi-structured interviews and used the fly-on-the-wall observation technique, to observe the scientists' typical workflow without direct participation or interference from our side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Case Study 1: Managing a Segmentation Project</head><p>The first case study focused on a manually segmented data set of a 955 GB electron microscopy volume. Previously, the scientists had already sparsely segmented around 4,000 objects and labeled 943 synapses, by managing a team of summer interns and grad students. Since the first step of this segmentation had already been performed prior to the development of NeuroBlocks, we were only able to extract a small amount of provenance data from this initial segmentation state. However, for all modifications after the initial segmentation, we were able to fully employ NeuroBlocks and its provenance tracking capabilities. The initial segmentation of the EM volume was performed with VAST <ref type="bibr" target="#b4">[5]</ref>. For each labeled synapse several attributes were extracted from the EM volume. In the later stages of the project, the scientists used Dojo <ref type="bibr" target="#b16">[17]</ref> for segmentation and proofreading.</p><p>In this first case study, our target user group was a segmentation project manager-in our case a senior researcher. The main objective of the senior researcher was to quickly identify interesting areas of the segmentation, and to create tasks for his project members based on his exploration. The researcher started by exploring the main segmentation state view in NeuroBlocks, focusing on the current state of the segmentation (T1 -Overview and detail visualization of current segmentation). He was focusing on three main structures of interest: three large dendrites, and the structures that connect to them. The three dendrites and their synapses had already been segmented previously, but some of the structures connecting to these synapses had only been quickly marked and not segmented completely. The researcher quickly identified these structures by using the filtering capabilities of NeuroBlocks to only show the interesting subset of the data, and then sorted the pixel view according to segment size. Subsequently looking at the small segments that were connected to the dendrites in Dojo's integrated 3D view allowed him to identify new segmentation targets (T3 -Manage fine-grained segmentation tasks). The researcher then created and assigned new tasks, by filling out new task descriptions and specifying start positions for the follow-up segmentation in Dojo.</p><p>While the segmenters were working on the data, the manager regularly checked their progress, and discussed ambiguous areas and segmentations with them (T2 -Track segmentation changes). Once the users were done, the senior researcher double-checked their work, using ConnectomeExplorer's 3D and "diff" views, before approving the segmentation (T4 -Audit users and segmentation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Case Study 2: Proofreading Automatic Segmentation</head><p>The second case study focused on an electron microscopy volume that was automatically segmented and required manual proofreading. The automatic segmentation was performed by the RhoANA pipeline <ref type="bibr" target="#b21">[22]</ref>, <ref type="figure">Fig. 7</ref>. Case study 2: Proofreader workflow. After task creation and assignment by a project manager (a), it is displayed in the segmenter's task list, which allows switching to the specified segment in the proofreading tool (b). Progress there is sent back to NeuroBlocks (c). After task completion, the project manager can double-check the new segmentation using the integrated volume renderer (d), and set the task to complete if satisfied.</p><p>resulting in a slightly over-segmented data set that required proofreading based on segment merging, and labeling of structures according to user-defined categories (e.g., axons, dendrites, spines).</p><p>For this case study, we focused on the segmenter and proofreader user group, and observed a user with relatively little proofreading experience. The complete workflow of this case study is shown in <ref type="figure">Figure 7</ref>. After logging into NeuroBlocks, the user could directly examine her assigned tasks and start working on one of them. Starting the proofreading process automatically sets the user to the specified position in Dojo (if a position was defined during task creation). During proofreading, all state changes (i.e., segment merges or splits) are automatically transferred to NeuroBlocks, which stores it in the provenance database (T2 -Track segmentation changes). During proofreading, the segmenter added several comments to her current task, to discuss ambiguous cell boundaries with more experienced segmenters (T3 -Manage fine-grained segmentation tasks). While waiting for answers, she suspended working on the current task and started other tasks that were assigned to her. After the ambiguity was resolved, she could directly continue with her first task where she originally left of, without losing the original tool state (T5 -Seamless switching between different tools). After checking her work in the integrated 3D view and setting the task status to complete, a segment approval notification was automatically triggered for the project manager.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Discussion</head><p>In this section we present the qualitative feedback we received from our collaborating scientists, and discuss limitations and as well as design lessons we learned during the development of NeuroBlocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.1">Qualitative Feedback</head><p>Qualitative feedback from our collaborators indicated three main advantages of NeuroBlocks that match our design goals:</p><p>First, it was a lot easier for neuroscientists to keep track of a project in NeuroBlocks than in their previous workflow. The distributed task assignment of NeuroBlocks was extremely helpful, especially when more than just one or two people are working on a project.</p><p>Second, NeuroBlocks was found to speed up and simplify the previous workflow. By seamlessly integrating external proofreading and visualization tools, users could easily switch from one tool to another and back again, without manual data importing and exporting, and without having to manually copy and paste meta data. Finally, users found NeuroBlocks most useful when the segments were categorized into the different neural object types defined by our collaborators' taxonomy (e.g., spines, dendrites, neurons) early in the process. The reason is that the segmentation state pixel view makes use of this categorization to display the segments sorted into the corresponding hierarchy. If the categorization is unknown, the visualization results in a flat view of the segments, which is still useful, but not as informative as the hierarchical view. Currently, the segment categorization is done manually during proofreading, but in the future the automatic segmentation pipeline could propose an initial object category for each segment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2">Lessons Learned</head><p>One of the crucial decisions during the design of NeuroBlocks was switching from a visualization and analysis-centric to a data-centric focus. This strategy allowed us to build a system that supports project management and tracking tasks much more intuitively by leveraging more abstract and high-level visualizations to get an overview of the current project state. This first design decision goes hand in hand with our next finding: By forgoing the typical graph-based provenance visualization, and providing a timeline-based provenance visualization triggered by users moving time sliders and brushes, we have created an intuitive way to explore the evolution of a project, even for users new to provenance systems. Tracking the overall progress of a project is a lot easier when one does not need to focus on individual changes or clusters, but can browse via smooth animations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.3">Limitations</head><p>The main limitations of NeuroBlocks with respect to interoperability with external tools is that these tools need to use the NeuroBlocks API for transmitting and receiving state information. Even though the API is well-documented and flexible, this process usually requires access to the source code and recompilation of the external applications.</p><p>We have tested the scalability of our system by simulating provenance data for tens of thousands of proofreading steps in a teravoxel data set. Our multi-scale pixel view can potentially scale to thousands of segments per visual element and ensures on-screen visibility of all segments. However, as all multi-resolution and aggregation views, this comes at the cost of losing information on individual segments that are a part of a super-pixel. That is why we offer users the possibility to switch from the multi-scale pixel view with guaranteed visibility to a high-resolution pixel view with a scroll bar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSIONS AND FUTURE WORK</head><p>We have presented the design and implementation of NeuroBlocks, a system for visual tracking of large-scale segmentation and proofreading projects in the field of connectomics. NeuroBlocks enables scientists to track the current state and evolution of their on-going segmentation and proofreading project, and provides a scalable visualization that can handle thousands of segmented objects. We have incorporated a provenance management system for tracking the project evolution and auditing of segmentation and users, and support multiple users and multiple user groups with different default views, tasks and permissions. NeuroBlocks allows to seamlessly integrate external tools and handle their respective application states. We believe that by combining a high-level abstract pixel view of the entire segmentation data with highly-detailed spatial 2D and 3D views of the EM volume and its segmentation, we have created a powerful visual system that allows scientists to focus on the essential parts of their research, rather than on management, data handling, and interoperability issues.</p><p>In the future, we plan to extend NeuroBlocks into a complete virtual lab notebook that will allow scientists to not only track the progress of their segmentation, but also the progress of their visualization and analysis, and the discovery of new scientific insight. Another promising research direction is the integration of dynamic and evolving guidelines for different types of science projects that will allow students with little experience to follow common templates.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 .</head><label>3</label><figDesc>Design iterations of NeuroBlocks. (a) virtual lab notebook; (b) provenance-driven analysis; (c) data-centric view; (d) final design.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Multi-scale pixel view of the current segmentation state. "Downsampling" the full-resolution pixel view ensures overview visibility of all data. Here, as an example, elements are sorted by size, and colorcoded according to the number of recent modifications. All individual segments comprising the selected super-pixel are shown in the top right. The bottom right shows a connectivity graph of the selected object.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .</head><label>5</label><figDesc>Segmentation object details and volume rendering integration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Manuscript received 31 Mar. 2015; accepted 1 Aug. 2015; date of publication 20 Aug. 2015; date of current version 25 Oct. 2015. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org. Digital Object Identifier no. 10.1109/TVCG.2015.2467441</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was partially supported by King Abdullah University of Science and Technology and NSF grant OIA-1125087.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NeuroLines: A subway map metaphor for visualizing nanoscale neuronal connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Awami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE InfoVis &apos;14)</title>
		<meeting>IEEE InfoVis &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2369" to="2378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A visualization architecture for collaborative analytical and data provenance activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Naser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rasheed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brooke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Information Visualisation (IV &apos;13)</title>
		<meeting>Information Visualisation (IV &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The Viking Viewer for connectomics: Scalable multi-user annotation and summarization of large volume data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koshevoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Marc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Microscopy</title>
		<imprint>
			<biblScope unit="volume">241</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="28" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Vistrails: Enabling interactive multiple-view visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bavoil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Crossno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization &apos;05</title>
		<meeting>IEEE Visualization &apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="135" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">VAST -Volume Annotation and Segmentation Tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berger</surname></persName>
		</author>
		<idno>31/07/2015</idno>
		<ptr target="https://software.rc.fas.harvard.edu/lichtman/vast/" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ConnectomeExplorer: Query-guided visual analysis of large volumetric neuroscience data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Awami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE SciVis &apos;13)</title>
		<meeting>IEEE SciVis &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="2868" to="2877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring the connectome: Petascale volume visualization of microscopy data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Awami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="50" to="61" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Network anatomy and in vivo physiology of visual cortical neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kerlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wetzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yurgenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Soucy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">471</biblScope>
			<biblScope unit="issue">7337</biblScope>
			<biblScope unit="page" from="177" to="182" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Braingazer -visual queries for neurobiology research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Šoltészová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Gröller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hladůvka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bühler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization &apos;09)</title>
		<meeting>IEEE Visualization &apos;09)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1497" to="1504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Squarified treemaps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bruls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huizing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Wijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint EG / IEEE TCVG Symp. on Visualization &apos;99</title>
		<meeting>Joint EG / IEEE TCVG Symp. on Visualization &apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The open connectome project data cluster: Scalable analysis and vision for highthroughput neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Roncal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kleissas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lillaney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Manavalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perlman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grosenick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deisseroth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Szalay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Vogelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Vogelstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.3543</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>cs.DC</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TrakEM2 software for neural circuit reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cardona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saalfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schindelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Arganda-Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Preibisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Longair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tomancak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hartenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Douglas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">38011</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Provenance for computational tasks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. in Science and Engg</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Making computations and publications reproducible with vistrails</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. in Science and Engg</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="25" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Visual comparison for information visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gleicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Albers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jusufi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="289" to="309" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Interactive volume exploration of petascale microscopy data streams using a visualizationdriven virtual memory approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE SciVis &apos;12)</title>
		<meeting>IEEE SciVis &apos;12)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="2285" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Design and evaluation of interactive proofreading tools for connectomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Haehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Knowles-Barley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE SciVis &apos;14)</title>
		<meeting>IEEE SciVis &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2466" to="2475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Annotation and provenance tracking in semantic web photo libraries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Halaschek-Wiener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Golbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Parsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hendler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Intern. Prov. and Ann. Workshop (IPAW &apos;06</title>
		<meeting>Intern. Prov. and Ann. Workshop (IPAW &apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="82" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">End-to-end eScience: Integrating workflow, query, visualization, and provenance at an ocean observatory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bellinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baptista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 4th Int. Conf. on eScience</title>
		<meeting>IEEE 4th Int. Conf. on eScience</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Boundary learning by optimization with topological constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bollmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmstädter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Briggman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mendenhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hayworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schalek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tapia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR &apos;10</title>
		<meeting>IEEE CVPR &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2488" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-automated neuron boundary detection and nonbranching process segmentation in electron microscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jurrus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Giuly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Paiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Ellisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Jorgensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="29" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Large-scale automatic reconstruction of neuronal processes from electron microscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kaynig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vázquez-Reina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Knowles-Barley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1303.7186</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>q-bio.NC</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Designing pixel-oriented visualization techniques: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="78" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Space-time wiring specificity supports direction selectivity in the retina</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zlateski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Purcaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balkam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Behabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyewirers</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">509</biblScope>
			<biblScope unit="issue">7500</biblScope>
			<biblScope unit="page" from="331" to="336" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mojo 2.0: Connectome annotation tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Knowles-Barley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kasthuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroinformatics</title>
		<imprint>
			<biblScope unit="issue">60</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Caleydo: Design and evaluation of a visual analysis framework for gene expression data in its biological context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kruijff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schmalstieg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Pacific Visualization Symposium (PacificVis&apos;10)</title>
		<meeting>of IEEE Pacific Visualization Symposium (PacificVis&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The big and the small: Challenges of imaging the brain&apos;s circuits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lichtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Denk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">334</biblScope>
			<biblScope unit="issue">6056</biblScope>
			<biblScope unit="page" from="618" to="623" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Interactive comparative visualization of multimodal brain tumor segmentation data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lindemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Laukamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinrichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision, Modeling &amp; Visualization</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ManyVis: Multiple applications in an integrated visualization environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rungta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Summa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Demir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Bremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE SciVis &apos;13)</title>
		<meeting>IEEE SciVis &apos;13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="2878" to="2885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">CATMAID: Collaborative annotation toolkit for massive amounts of image data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saalfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cardona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hartenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tomančák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1984" to="1986" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Onset: A visualization technique for large-scale binary set data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sadana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Major</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE InfoVis &apos;14)</title>
		<meeting>IEEE InfoVis &apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1993" to="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Querying and creating visualizations by analogy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Trans. on Visualization and Computer Graphics (Proc. IEEE Vis &apos;07)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1560" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reading the book of memory: Sparse sampling versus dense mapping of connectomes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="29" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tree visualization with tree-maps: 2-d space-filling approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="99" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The eyes have it: A task by data type taxonomy for information visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Symposium on Visual Languages (VL &apos;96)</title>
		<meeting>IEEE Symposium on Visual Languages (VL &apos;96)</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="336" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Karma2: Provenance management for data driven workflows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Simmhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Plale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Web Services Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Ilastik: Interactive learning and segmentation toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Straehle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Symp. on Biomedical Imaging: From Nano to Macro</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="230" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">neuroMapinteractive graph-visualization of the fruit fly&apos;s neural circuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sorger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bühler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schulze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symp. on Biological Data Vis. (BioVis&apos;13)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Combining extended table lens and treemap techniques for visualizing tabular data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Telea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurographics/IEEE VGTC Conf. on Visualization (EuroVis&apos;06)</title>
		<meeting>Eurographics/IEEE VGTC Conf. on Visualization (EuroVis&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="51" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Similarity-based visualization of large image collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Reese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Nemiroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="183" to="203" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
