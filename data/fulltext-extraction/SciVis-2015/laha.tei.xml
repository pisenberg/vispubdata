<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Classification of User Tasks in Visual Analysis of Volume Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bireswar</forename><surname>Laha</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
								<address>
									<addrLine>2 4 Virginia Tech</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Brown University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">J</forename><surname>Socha</surname></persName>
						</author>
						<title level="a" type="main">A Classification of User Tasks in Visual Analysis of Volume Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Task Taxonomy</term>
					<term>Empirical Evaluation</term>
					<term>Volume Visualization</term>
					<term>Scientific Visualization</term>
					<term>Virtual Reality</term>
					<term>3D Interaction Human-centered computing-Visualization-Visualization theory</term>
					<term>concepts and paradigms</term>
					<term>and Visualization design and evaluation methods; Computing methodologies-Modeling and simulation-Simulation types and techniques-Scientific visualization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Scientific and medical data generated through modalities such as magnetic resonance imaging (MRI), computed tomography (CT), confocal microscopy, positron emission tomography (PET) and simulations are in 3D volumetric format and are static or time varying. Visualization of volume data is invaluable in numerous domains including biology, medicine, palaeontology, geophysics, materials science, and astrophysics <ref type="bibr" target="#b10">[11]</ref>.</p><p>Visualization researchers are developing innovative approaches such as Focus+Context techniques <ref type="bibr" target="#b5">[6]</ref> and GPU researchers are significantly speeding up the rendering of volume data <ref type="bibr" target="#b6">[7]</ref>. But volume visualization remains an active area of research, with deeprooted challenges including segmentation (extracting the regions of interest in a volume by manual, automatic or semi-automatic methods), understanding occluded and cluttered data, and viewing volume data on 2D displays.</p><p>To address these challenges, workers in the visualization, virtual reality (VR), and 3D user interface (3DUI) communities run empirical studies to evaluate the effects of the fidelity of system components, and visualization and/or interaction techniques on analysis of volume datasets, typically using volume data and tasks from one or two scientific domains. However, many such studies, while significant within specific fields, cannot be generalized to other scientific domains, primarily because no generic grouping exists of the visual analysis tasks performed in various scientific domains. This has been described <ref type="bibr" target="#b11">[12]</ref> as the foremost current scientific visualization research challenge and has also been identified as a major limitation of prior VR empirical studies <ref type="bibr" target="#b13">[14]</ref>.</p><p>In addition, a major challenge in running empirical studies with domain scientists is the limited accessibility to well-trained study participants, both because of the very limited availability of expert domain scientists to possible confounds in measuring task performance due to differences in participants' prior knowledge. A viable solution might be to map tasks performed by domain scientists to more abstract tasks requiring no expert knowledge. This would preserve the nuances of the tasks themselves (as important to the domain scientists) but also make them fully understandable to non-experts <ref type="bibr" target="#b13">[14]</ref>. Such a task categorization would let visualization researchers use novice participants while ensuring that the results are also applicable to specific domains.</p><p>Finally, traditional empirical studies in visualization, VR and 3D interaction (3DI) have evaluated task performance with basic interaction tasks such as rotation, translation, and scaling. But such results do not help VR system designers seeking a more usercentric approach to system design (which will need closer ties to domain tasks), nor do they help domain scientists trying to use such findings. This is becoming very important as our research becomes increasingly interdisciplinary.</p><p>We therefore aimed to develop a generic framework, or taxonomy, describing visual analysis tasks with volume data. The work has three goals: 1) generalizability of empirical results across domains, 2) understandability of abstract scientific tasks by novices, and 3) usefulness of results to domain scientists. The framework described here has a goal-based categorization of visual analysis tasks, a set of supporting tasks, a set of data visualization parameters and some dataset properties that we believe can influence the performance measures on the basic tasks.</p><p>Below we describe related work and explain our methodology: deciding on the primary task set by interviewing scientists and researchers from multiple domains, and then reaching a broader population by a survey evaluating our initial design. We summarize the survey results, which supported the design of our task taxonomy, and discuss its role in empirical evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>There have been several prior attempts at creating high-level generic task taxonomies, but these mainly target information visualization. We touch upon some of the important ones here.</p><p>Shneiderman designed one of the first task taxonomies for information visualization <ref type="bibr" target="#b27">[28]</ref>. He proposed a task-by-data-type taxonomy with seven data types (1-, 2-, 3-dimensional data, temporal and multidimensional data, and tree and network data) and seven tasks (overview, zoom, filter, details-on-demand, relate, history, and extract). Zhou and Feiner proposed a visual task taxonomy <ref type="bibr" target="#b34">[35]</ref> for interfacing high-level presentation intent with low-level visual techniques; their approach characterizes visual tasks by their visual accomplishments and implications.</p><p>Morse and colleagues proposed a domain-independent taxonomy of visual tasks <ref type="bibr" target="#b19">[20]</ref> to test visualization in isolation from the rest of the system. They defined tests using a high-level taxonomy to generalize the evaluation results to newer systems, ignoring tasks achieved only in older, less capable systems. They discussed methods for exhaustively testing the capabilities of an information retrieval system based on their task taxonomy. Amar and Stasko presented a task-based framework <ref type="bibr" target="#b0">[1]</ref> for bridging analytic gaps in information visualization, seeking generalizations for design and evaluation of information visualization systems across users, data sets, and domains.</p><p>Tory and Moller presented a high-level visualization task taxonomy <ref type="bibr" target="#b29">[30]</ref> to categorize visualization algorithms rather than data. Their categorization was based on a design model (the assumptions the algorithms make about the data they visualize) that considers the user's conceptual model. They claim that such a categorization is more flexible and also explains how information and scientific visualization domains might relate and overlap.</p><p>Valiati and colleagues used a taxonomy based on previous designs <ref type="bibr" target="#b31">[32]</ref> and reported task performance with two visualization techniques in a multidimensional dataset. They claimed that such a taxonomy would guide in the selection of visual and interaction metaphors, and in the usability testing of visualization techniques.</p><p>More recently, Brehmer and Munzner presented a typology of visualization tasks to bridge the gap between low-and high-level tasks <ref type="bibr" target="#b2">[3]</ref>. It characterizes a task based on why and how it is performed and what its inputs and outputs are. Roth came up with an empirically derived and ecologically valid taxonomy for interactive cartography and geovisualization <ref type="bibr" target="#b23">[24]</ref> by conducting semi-structured interviews of expert interactive map users and doing a card-sorting study with expert interactive map designers.</p><p>Looking at task as a multifaceted concept, Schulz and colleagues defined a design space of visualization tasks <ref type="bibr" target="#b24">[25]</ref> with five design dimensions capturing the main aspects of tasks distributed across different task descriptions. Sedig and Parsons came up with a general theoretical framework amalgamating concepts from interaction and complex cognitive activities <ref type="bibr" target="#b25">[26]</ref>; they believe their design can stimulate creativity and innovation across domains and disciplines.</p><p>Despite this prior work on task categorization, a comprehensive taxonomy of tasks focusing on 3D spatial data analysis is still lacking <ref type="bibr" target="#b11">[12]</ref>. But this work inspired us to design a taxonomy considering the data type <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28]</ref> and the characteristics of the visualization algorithms <ref type="bibr" target="#b29">[30]</ref> and to seek generalization for design and evaluation of visualization systems <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DESIGNING THE VISUAL ANALYSIS TASK TAXONOMY</head><p>The idea of an abstract visual analysis task taxonomy came from free-form interviews with domain scientists in medical biology, geophysics, materials science, biomechanics, and paleontology. We also interviewed a professional imaging analyst who works daily with various MRI and CT scans of humans and animals. We held these interviews to identify tasks for our empirical research on the effects of VR system fidelity on analysis of volume datasets; during these sessions, the researchers gave examples of visual analysis tasks they typically perform with the volume datasets they use or encounter in their daily research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Criteria used for task categorization</head><p>Although the kind of tasks each researcher described were specific to their own domain, we observed an interesting trend in their task descriptions: many of the tasks were comparable among the domains at a fundamental level. For example, the geophysicist follows cracks through the plates in the Earth's mantle, the biomechanics scientist tracks tracheal tubes inside a beetle, the medical biologist tracks blood vessels inside a mouse's leg, and the paleontologist tracks the jagged boundaries between cells inside a microscopic fossil. The medical biologist searches for floating soft tissues inside a dense mass of structures, while the paleontologist searches for intracellular bodies (such as nuclei) inside the cells. The biomechanics researcher wants to know the morphology of the beetle's tracheal system, while the paleontologist looks for the overall structure of a fossil. These observations inspired us to group tasks in these disparate scientific domains under a common umbrella of abstract tasks based on the scientists' objectives. At an abstract level, we characterize the three examples above as spatial judgment, search, and shape description respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Initial task categorization</head><p>As we ran multiple VR experiments producing empirical findings in disparate scientific domains <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, we did not want to restrict any significant result just to the domain of a particular experiment. Associating the results with the abstract categories would let us link and generalize them across multiple domains. We identified a few abstract task categories to map the tasks from these multiple VR experiments: search, spatial understanding, path following, quantitative estimation, shape description and pattern recognition. We discussed these task groups with colleagues at workshops on Immersive Volumetric Interaction 1 and Immersive Visualization Revisited <ref type="bibr" target="#b1">2</ref> , and in general at recent IEEE VIS and IEEE VR conferences. This suggested a set of supporting factors in the design (see section 4.2) that made the taxonomy more comprehensive. We also found that our path following and spatial understanding categories were closely connected. After further discussions with domain scientists, we saw that path following would refer to an action taken to carry out a search or a spatial understanding task but would not constitute a category of its own; it thus was subsumed into the other categories, so that our proposed task taxonomy had five categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPOSED TASK TAXONOMY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Basic task categorization</head><p>Here we provide the basic grouping of the abstract task categories based on their goals (see section 6). We also give our definition of each group, along with an example in each subgroup. 1. Search: We define a search task as one in which the user is looking for a feature in the dataset. a. Presence/Absen ce − Searching for presence/absence of a particular feature/object in a dataset. E.g., "Search for distinct bone segments in this sample." b. Counting − Counting objects/features when they are present. E.g., "Count the total number of tracheal tubes and categorize them by diameter." 2. Pattern Recognition: We define a pattern as a characteristic that is repeated or a trend we see as we look through a dataset. a. Trend − Looking for a trend. E.g., "Blood vessels on one side of the dataset are narrow and get progressively bigger as we go through the dataset. Identify on which side of the dataset we notice this trend." b. Repetition − Does a pattern repeat itself in different parts?</p><formula xml:id="formula_0">1 http://w-ivi.</formula><p>How often? E.g., "Looking through the sample longitudinally, count the number of fibers curving through the sample and the number of straight fibers." 3. Spatial Understanding: Tasks in which the user makes a judgment in a 3D context about the position and/or orientation of a feature in an absolute or relative sense. E.g., "Which sets of tubes are located closest to the front of the dataset?" a. Absolute − Locating a feature/object which is the highest, lowest, farthest, or closest to/from a viewpoint, or in the overall dataset. E.g., "Which sets of tubes are located closest to the front of the dataset?" b. Relative − Judging whether feature/object 'A' is higher/ lower/farther/closer than another feature/object 'B'. E.g., "Does the red fiber pass over or under the blue one?" c. Intersection − Judging whether two features intersect or are distinct. E.g., "Does the left side of the tracheal system connect to the right side throughout the body?" 4. Quantitative Estimation: These include tasks in which the user must quantitatively estimate some property of the dataset or part of it. Examples of things estimated in a volume dataset are density, size, volume, distance, length, surface area, curvature, angle, velocity and other scalar quantities. a. Absolute estimation. E.g., "What is the density of the highlighted region of the bone marrow?" b. Relative estimation (binary). E.g., "Study the thickness of the borders and the joints between the cells. Are different joints and borders of comparable or variable thickness?" c. Relative estimation (quantitative). E.g., "How many times denser is the boundary of the cells at the center than the outer boundary of the cluster?" 5. Shape Description: In these tasks, the user describes the shape of the whole or some part of the dataset qualitatively. E.g., "What is the cross-sectional shape of each tracheal tube? Shapes run from circular to flattened ellipses."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Other factors influencing visual analysis performance</head><p>Volume visualization researchers and colleagues we met at professional conferences observed that although the basic categorization may cover tasks from different domains, the type of volume data generated can vary in different ways between domains. Also, there are various algorithms to visualize volume datasets and different ways to explore the rendering. Based on their suggestions, we included the following dimensions or factors in our framework both to make this framework more comprehensive and also to bring in varied and important perspectives on empirical results tied to the above abstract task categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Based on viewing style</head><p>We can explore volume datasets in a virtual world from a firstperson view (egocentric) or a third-person view (exocentric). 1. Egocentric − navigating or flying through/within the data 2. Exocentric − viewing by spinning the data and looking from various angles from the outside</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Based on volume-rendering algorithms</head><p>There are many different ways to visualize or render a volume. In 1986 Kajiya presented the rendering equation <ref type="bibr" target="#b9">[10]</ref> that captures comprehensively a variety of rendering algorithms, as the aim of rendering is to model light scattering from various surfaces. The list below gives a high-level categorization of the different volume rendering algorithms, adapted from <ref type="bibr" target="#b18">[19]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Based on the temporal nature of the data</head><p>Volume data can vary based on how it is obtained. If we scan a static object in 3D, say a CT scan of a human body part, we get a non-time-varying dataset. If we scan a volume over some time, e.g. using a Doppler ultrasound to look at blood flow in a human heart, or astronomical surveys over a period of time, we get time-varying data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Time varying 2. Static/non-time varying</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Based on dimensionality of the volume data</head><p>Volume data map material properties of the object that it represents, such as color, density, refractive index, etc. If a dataset maps just one material property we call it single-dimensional; if it maps more than one material property we call it multidimensional ( <ref type="bibr" target="#b8">[9]</ref>, chapter 9). The dimensionality here refers to the material properties, not to the different domains of volume data.</p><p>1. Single-dimensional 2. Multidimensional</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATING THE DESIGN OF THE TAXONOMY</head><p>We wanted to verify if our proposed taxonomy made sense in the broader scientific community, particularly researchers using volume data outside the set of people we interviewed. Mainly, we were interested in knowing: To explore the above questions we ran a survey targeting people from academia and industry doing volume data analysis, including scientists and researchers at various universities as well as imaging analysts and similar professionals in industry. The survey was reviewed and approved by the Institutional Review Board at our university and was hosted on Qualtrics.com. Estimated time to complete the survey was around 20 minutes. We provided incentive to take the survey by giving $20 Amazon gift cards to ten randomly chosen survey takers after the survey was completed. We contacted a wide variety of people worldwide who work regularly with volume datasets, using various professional email listservs as well as through our direct and indirect professional contacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overview of survey</head><p>The full survey, available online <ref type="bibr" target="#b2">3</ref> , had the three subsections described below. We provided a pre-determined initial framework (as opposed to a fully open-ended survey) to collect the responses in a structured fashion. Survey structure was finalized using input from various workshops and conferences over multiple years. We also allowed for additional respondent feedback for missing tasks and/or categories in the post-questionnaire part of our survey. Finally, we tried to be domain-neutral by designing the basic framework using input from scientists from multiple domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Background information</head><p>This part captured the demographics of the survey-taker, such as domain expertise and experience with analyzing volume data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Task categorization</head><p>The next survey part had specific questions tied to each basic task category. For each task category, we first gave its definition and its subcategories (if any). We also provided one example task from three different domains (medical biology, paleontology, and biomechanics) in each category, prepared by our collaborating scientists in those domains. We then captured the respondent's level of agreement in each category. Finally, we asked for at least one task from the respondent's domain in each category or an example task they believed closest to those in that category (when they had a low level of agreement to that category).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Post-questionnaire</head><p>The final part of the survey had questions related to respondents' daily division of time among the categories, tasks that they thought were missing (with abstract groups into which they would put the tasks), and their general level of agreement with our design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Results and discussion</head><p>167 respondents (23 to 77 years of age, median 40) took the survey over about six months. There were 112 males, 31 females, and 24 who declined to identify their gender. 107 self-reported as scientists, medical practitioners, or radiologists working or doing research with volume datasets; 19 as professional imaging analysts; and 41 as other or declined to identify their profession. The respondents came from a variety of scientific domains, like geology/geophysics (3), medical biology (10), paleontology (1), biomechanics (3), cell biology (1), engineering <ref type="bibr" target="#b25">(26)</ref>, medicine (8), radiology (9), architecture (2), animation and 3D modeling <ref type="formula">7</ref>, and others <ref type="bibr" target="#b19">(20)</ref>. Their experience with volume data ranged from less than a year (9) to 2-5 years (38), 5-10 years (28), and more than 10 years (33). Many respondents did not identify their scientific domain (77) or their experience level (59).</p><p>Most respondents (67 respondents) had worked with more than 20 different volume datasets; among the rest: three had used just one dataset, 15 had used between two and five datasets, 10 had used between five and 10 datasets, and 13 had used between 10 and 20 datasets. Of the data used, 24% is time-varying data (76% static or non-time-varying), and 70% is single-valued (30% multivalued).</p><p>The respondents predominantly analyze segmented data (79), but some work with raw volume data as well <ref type="bibr" target="#b12">(13)</ref>. 30 reported using automatic segmentation and 16 used manual methods, but most reported using both automatic and manual methods (59). 24 reported using an egocentric method (navigating or flying through/within the data) and 63 people used exocentric methods (rotating the data and viewing from various outside angles).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Agreement with classification</head><p>The participants reported their level of agreement with our design of the task taxonomy on a 1-7 scale (1 being the least and 7 the most). The box plot in <ref type="figure">Figure 1</ref> shows their agreement and their responses for each task category in our task taxonomy.</p><p>Although each plot above has variance ranging from 1 to 7, the 25th percentile of each is above the scale average of 4, except in the shape description category. The box plot on overall agreement shows that most respondents agreed in general with our design of the task taxonomy. The other five plots indicate that most respondents agreed with the definition and the categorization of the individual task types as well, with weakest agreement shown on our shape description categorization. Also, at least one respondent had the lowest and at least one had the highest agreement with our definition of every task category (responses ranged from 1 through 7). Although most of the population seems to agree with the categorization, the wide range in their responses points to the lack of a general consensus, pointing out the difficulty of designing a taxonomy or framework that is satisfactory to everyone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Time division of the respondents between the categories</head><p>The box plot in <ref type="figure">Figure 2</ref> shows the time spent by respondents on work in the different task categories. There is no significant difference between categories in the mean time spent by respondents. However, some participants reported spending 80% or more time in any one of search, pattern recognition, spatial judgment, or quantitative estimation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.3">Correlations between different entries in our survey</head><p>We ran nonparametric Spearman's ρ tests between the different measures in our survey, looking for correlation at the 5% significance level. Here we report significant correlations only.</p><p>We found a significant correlation (ρ=0.2282; p=0.0474) between the domain of the respondents and their use of segmentation, indicating that the need to segment volume datasets may vary among scientific domains, or that different domains have different standards of data representation and analysis. The domains in which respondents reported using segmentation more than others are medical biology, engineering, medicine and radiology.</p><p>We saw a significant correlation between the amount of time respondents spend for shape description tasks and their involvement with single-valued (ρ=0.2632; p=0.0440) and multivalued data (ρ=-0.2718; p=0.0373). This indicates that respondents using singlevalued data would more likely need to describe shapes in volume data. Multivalued data visualization might focus more on understanding the relation between the variables' representations.</p><p>We found no significant correlation between the division of time between our task types and the domains they came from, except for an almost significant correlation for time spent in quantitative estimation tasks to domains (ρ=0.2456; p=0.0925). This indicates that quantitative estimation tasks might be more common in some domains than others, such as engineering, radiology, animation, and 3D modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.4">Task examples given by the respondents</head><p>Respondents gave examples of tasks from their specific domains for each task category, totaling close to 500 individual tasks from numerous domains. But respondents' mapping of this huge variety of tasks to our task categories supports our basic hypothesis that a few abstract task categories could capture most of the tasks performed by various scientists across multiple disparate domains.</p><p>Detailed analysis of each individual task and the respondents' mapping to our taxonomy indicate that different tasks in a category would be broadly similar. For example, describing shapes of voids between tightly packed fibers (from medical biology) by an imaging analyst and looking at 3D shape variation among fossils and extinct specimens by paleontologists are grouped in shape description tasks; quantitative characteristics of the distribution of cerebral fluid (medical biology) and estimating how large one mantle-plume is, relative to another (geophysics), are grouped in quantitative estimation tasks; whether a structure is connected to another structure in airline baggage search, evaluating distance between lesions (in stereotactic radiosurgery or SRS of brain) and determining the tracheal tubes connecting the left and right sides in a beetle (biomechanics) are grouped in spatial judgment tasks. Further subdivision of the categories might help fine-tune the tasks in each category, but does not appear to be necessary.</p><p>Respondents did not suggest any new categories, indicating that our taxonomy was seen as comprehensive. Detailed analysis of their inputs showed, however, that our design would benefit from another dimension, "supporting tasks." We define a supporting task as one used in the process of analyzing volume data but not an analysis task by itself. Inherently, these are also not abstract tasks that we want to map across multiple scientific domains, so they do not qualify in our basic goal-based list. For example, we observed that an analyst's objective might be to compare multiple datasets, not just to complete the tasks in one dataset. We thus added "data comparison" as a supporting task. <ref type="figure" target="#fig_2">Figure 3</ref> shows the final task taxonomy framework. The main component is "Goal-based Task Categorization", highlighting that the basis of our classification was the end objective in visual analysis tasks. The framework includes a set of supporting tasks (see section 5.5.4, final paragraph), a set of data visualization parameters, and some dataset properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">THE FINAL TASK TAXONOMY</head><p>We see the basic goal-based tasks as "work operators" (required for accomplishing the main objective) and the supporting tasks as "enabling operators" (required to prepare for or clean up after achieving the desired objective), as described by Whitefield et al. <ref type="bibr" target="#b33">[34]</ref>. Our full list of supporting tasks includes 1) Segmentation and filtering; 2) Navigation; 3) Manipulation or View Modification; 4) Selection; 5) Path Following; and 6) Data Comparison.</p><p>The data visualization parameters include the technique or  algorithm used to visualize the data and the hardware platform (desktop, large display wall, immersive displays, etc.) displaying the data. The dataset properties include dimensionality and the temporal nature of the data. Each of these factors (supporting tasks, data visualization parameters, and dataset properties) can affect task analysis individually and together. However, a discussion of their individual effects is beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Overlap among categories from non-goal-based perspectives</head><p>We saw possible overlap between tasks in the spatial understanding and some of the other categories, such as quantitative estimation, pattern recognition, and search when we do not treat the categories as merely goal-based and consider the intermediate analytic steps For example, to identify or match a pattern, to do a quantitative estimation, or while searching, we may need to make a spatial judgment. Also, to answer whether a structure is bigger or smaller than another (relative quantitative estimation), we may need to know how close or far the structures are, since in visual analysis with perspective rendering, distance from the viewpoint affects size. And in matching two patterns, we may have to understand their 3D arrangement. In this context, it is important to note that our taxonomy aims at categorizing the tasks based on the mutually exclusive nature of their goals. So although methods used in carrying out a task may borrow properties from another task category (since categories are not mutually exclusive when treated as analytic steps), we can group them based on their final objective, as intended by the domain scientists. But tasks might be treated as combining more than one of these categories under a classification not based solely on objective, but considering intermediate analytic steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparisons with some previous classifications</head><p>Here we compare and contrast our design with some prominent designs in the literature. Both dataset properties in our design (dimensionality and temporal nature) are reflected in Shneiderman's taxonomy <ref type="bibr" target="#b27">[28]</ref>. But while his visual-informationseeking mantra overview, zoom and filter, and details-on-demand was based on the steps in the task analysis, our basic categorization is based on the goal of the analysis task. Similarly, Pretorius et al. recently described tasks in multivariate network analysis <ref type="bibr" target="#b22">[23]</ref> considering the entity studied, its properties, and the analytic activity performed on the entity, thus differentiating it from our goal-based task categorization. Sedlmair et al. recently proposed a framework for visual parameter space analysis <ref type="bibr" target="#b26">[27]</ref> consisting of a data-flow model, a set of navigation strategies, and a categorization of analysis tasks. Their holistic approach is similar to ours in creating a framework of task taxonomy along with supporting dimensions. But again, their basic categorization criteria differ from ours: analysis-based as opposed to goal-based. Munzner's recent theoretical work <ref type="bibr" target="#b20">[21]</ref>, quite comprehensive in information visualization, identifies "actions" and "targets" as important parameters in task analysis and considers (action, target) pairs in her typology. This is very close to our focus on the target of task analysis, although our targets are more domain-oriented than those in her design. The two designs are similar in their consideration of data attributes for abstraction.</p><p>Our interviewing domain scientists from disparate domains to come up with the initial list of task categories is reflected in the recent work of Brehmer et al. <ref type="bibr" target="#b3">[4]</ref>,for characterizing task sequences in visualizing dimensionally reduced data. Lee et al. recently broke down complex tasks for graph visualization into a series of lowlevel tasks <ref type="bibr" target="#b17">[18]</ref>. Although the basis of division in their case was the tasks performed during analysis (compared to the objective of task analysis, as in our case), we share the vision of creating a taxonomy to generalize results from controlled empirical experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Limitations of the task taxonomy and the survey</head><p>It is important to highlight possible limitations of our design choices. Our task taxonomy was designed in consultation with just a handful of scientific domain experts, and 167 scientists from around the world responded to our evaluation survey. This is a very small subset compared to the total number of people currently analyzing scientific data and the wide variety of scientific domains generating volume data. We tried to be broad and representative by asking people from as many disparate domains as possible to review and comment on the design of the task taxonomy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Top-down (pre-classified choices) vs. bottom-up (open-ended) approaches</head><p>Instead of asking survey respondents an open question about categories appropriate for their tasks, we gave them a preestablished category set. Such pre-classified choices could have seeded their initial thinking and curtailed different ideas they might have had. But even considering this possible effect, we think our survey was very valuable in that the initial design was done in consultation with multiple domain experts in the first place and thus the initial ideas were informed by domain needs. Also, the high overall agreement of the respondents to our design (first box plot in <ref type="figure">Figure 1</ref>) suggests that their tasks are well represented through our taxonomy and the design did not miss any of their common tasks. Our post-questionnaire captured the tasks of the respondents that didn't fit any of our categories, and we analyzed and recategorized all tasks identified through this mechanism (see section 5.5.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">Redundancy and equivalency of categories</head><p>It is important to note that our survey methodology might not be so efficient in detecting redundancy in task categories as a whole. But again, the high agreement of the respondents with the individual categories ( <ref type="figure">Figure 1</ref>) means that none of the categories were redundant to a majority of the respondents.</p><p>The survey does not prove equivalence among the different tasks identified within each category, and it does not guarantee that the taxonomy will generalize our findings. But it does provide a valuable evaluation of a first-of-its-kind taxonomy designed in consultation with domain scientists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ROLE OF THE TASK TAXONOMY IN EMPIRICAL EVALUATIONS</head><p>The generic task categories from our taxonomy helped us generalize the findings in our various studies evaluating the effects of display characteristics and 3D interaction techniques for volume data. Our latest VR empirical study <ref type="bibr" target="#b15">[16]</ref> mapped the evaluation tasks directly to our task categories, helping to analyze our findings based on task types. This analysis identified that stereo alone, or head tracking with greater field of regard (total size of the visual field, in degrees of visual angle, surrounding the user), aids in spatial judgment and searching. We also revisited the tasks from our 2012 VR experiment <ref type="bibr" target="#b16">[17]</ref>, categorizing them based on our taxonomy, and did a meta-analysis of our results based on this task taxonomy. This gave us preliminary insight on how different rendering styles affect volume data analysis tasks. We found that greater field of regard improves in task performance in analyzing volume datasets with 3D texture rendering, whereas stereo is useful for analyzing isosurfaces.</p><p>Our use of some of the task categories (search and pattern recognition) from our taxonomy in our first evaluation of the Volume Cracker prototype <ref type="bibr" target="#b14">[15]</ref> helped produce results meaningful to domain scientists in this study. In our second evaluation of the bare-hand version of the volume cracker (BHVC), we again used tasks directly mapped to this task taxonomy <ref type="bibr" target="#b12">[13]</ref>; this helped us produce generalizable results from this evaluation.</p><p>Our recent VR study <ref type="bibr" target="#b15">[16]</ref> found some consistency in the significant findings within our task categories, and substantial consistency in the results within each task category in the evaluation study of the BHVC technique <ref type="bibr" target="#b12">[13]</ref>. These results highlight the strength of our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Analysis of tasks from previous studies</head><p>Here we analyze visual analysis tasks reported in some of previous 3D visualization research using this new classification. While full analysis of all prior evaluation tasks and studies falls outside the scope of this conference paper, we believe what follows to be an interesting start. Sobel et al. used particle flurries to produce "synaptic visualization" in scalar fields <ref type="bibr" target="#b28">[29]</ref>. The analysis requires visualizing pathlines in 3D. The goal is to understand the 3D flow, which groups the task as relative spatial understanding (3b) individually, and as pattern recognition (2a) if comparing with known 3D pathlines.</p><p>Vector-field visualizations of multivalued 3D data have similar goals, such as the threads and halos of Wenger et al. <ref type="bibr" target="#b32">[33]</ref>. More specific tasks, as reported by Forsberg et al. <ref type="bibr" target="#b7">[8]</ref>, could be search (1a; tasks 1 and 4 in <ref type="bibr" target="#b7">[8]</ref>), pattern recognition (2b), absolute spatial understanding (3a) and relative spatial understanding (3c).</p><p>Tory et al. <ref type="bibr" target="#b30">[31]</ref> designed a parallel coordinate system for exploratory volume visualization. Experts evaluated the usability of their interface, based on their heuristics, for search tasks (1a).</p><p>The various analysis tasks for the Egg chamber data, in the comparative study by Prabhat et al. <ref type="bibr" target="#b21">[22]</ref>, would fall under 4c, 2b, 1b, 5, 1a, 1b; for the Brain dataset: 4c, 3c, 3b, 3c and 1b, and for the Gut dataset: 4c, 3a, 3a, 2b, 2b and 1b of <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>Chen et al. <ref type="bibr" target="#b4">[5]</ref> evaluated tasks in the analysis of 3D streamtube visualization of DMRI data. These tasks, based on their goals, would be 4b, 1a, 2b, 1a and 2b in our categorization <ref type="figure" target="#fig_2">(Figure 3)</ref>.</p><p>As we note, some subjectivity could be involved in categorizing analysis tasks within the task categories. But at the same time, we should remember that the aim of such an exercise would not be the categorization itself, but the ability to derive and predict the effects of the category on task performance and system design for the domain scientists. For example, visualization researchers would accumulate results tied to the categories, and system designers would look at those results to predict how effective a system would be for tasks performed within specific categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Possible alternative organizations of the taxonomy</head><p>This classification is a first of its kind in the volume visualization community, and it is clear that many alternate forms can exist, depending on their purpose and utility. We discuss a few here, understanding that the scope of the design and evaluation of these and other forms will be the future work in our community.</p><p>Some task classifications use parameters for classifying tasks in their categorization. For example, Bowman et al. provide variables that significantly affect user performance and usability <ref type="bibr" target="#b1">[2]</ref>. We avoided defining such parameters because we categorized the tasks based on their goal, a clear criterion for task grouping.</p><p>Task classification could be structured more hierarchically, with perception-based task groups at the lowest level, then more cognitive task groups, and finally goal-oriented groups (as in our current classification). We avoided any hierarchy in our design because we wanted to keep it simple and easy to use in running empirical experiments. Our classification is targeted at the level of domain experts, but the level and complexity may vary between different user groups, such as between visualization solution designers and domain experts.</p><p>Domain ontologies can also be mapped in a task categorization. Although that would make the classification more domain-specific, the utility of such forms in specific domains might be greater.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION</head><p>We have described a taxonomy of visual analysis tasks for volume datasets and the results from a survey evaluating our design. Our findings suggest that this design is sufficiently nuanced and comprehensive to capture the tasks from a wide variety of scientific domains. We believe this classification is an important step forward in creating a rich framework of abstract task categorization that we can use reliably and on which we can base future results. This work will provide a framework to share and generalize empirical findings from studies in the visualization, VR, and 3D UI communities, using datasets from multiple scientific domains. This theoretical framework is aimed at bringing about broader and richer impact of our fundamental findings in the broader scientific community working with volume datasets.</p><p>The most obvious use of this taxonomy is in choosing tasks while designing an experiment. For example, in a study to compare multiple visualization techniques, the designer can choose tasks from several or all of the categories in our classification <ref type="figure" target="#fig_2">(Figure 3</ref>). This will give the findings of the study broader impact beyond the domains from where the volume dataset(s) originated.</p><p>Researchers can also use this taxonomy to revisit and categorize tasks in prior empirical studies. Mapping the findings from previous studies to the generic task categories will make the results more generalizable. We can also carry out a meta-analysis of multiple studies to see if the results are consistent within each task category. This will make our task categories more reliable or will identify missing features and help to make our framework more comprehensive.</p><p>Finally, while designing empirical studies to analyze task performance, we can take into account the supporting tasks, data visualization parameters and dataset properties relevant to the scenario, in order to reduce confounds in our results as well as investigate how they affect task performance. For example, our recent VR study <ref type="bibr" target="#b15">[16]</ref> found preliminary evidence suggesting that the effects of the VR system components may be mediated by the visualization technique used to render volume data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>: 1. Decomposition 2. Isosurface rendering 3. Maximum intensity projection (MIP) 4. Alpha blending 5. X-ray rendering</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Box plot showing match between task description and survey respondents' expectations Box plot showing respondents' division of time between different tasks in our survey 4.2.4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The task taxonomy framework</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">laha@stanford.edu, 2 bowman@vt.edu,<ref type="bibr" target="#b2">3</ref> dhl@brown.edu, 4 jjsocha@vt.edu</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://web.stanford.edu/~laha/docs/Survey_Task_Taxonomy_2014_BL_DB _DL_JS.pdf</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This research was supported by NSF (1320046, 1319606 and 0938047), an IBM PhD Fellowship (2013-14), Virginia Tech Institute for Critical Technology and Applied Science (ICTAS) and Research Computing's Visionarium Lab. DOE supported use of the Advanced Photon Source (DE-AC02-06CH11357). We thank the many domain scientists for discussions that shaped this taxonomy.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Knowledge Task-Based Framework for Design and Evaluation of Information Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Symposium on Information Visualization</title>
		<meeting>the IEEE Symposium on Information Visualization<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="143" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kruijff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Laviola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Poupyrev</surname></persName>
		</author>
		<title level="m">3D user interfaces: theory and practice</title>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Multi-Level Typology of Abstract Visualization Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions of Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2376" to="2385" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visualizing dimensionally-reduced data: Interviews with analysts and a characterization of task sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ingram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the ACM Proceedings of the Fifth Workshop on Beyond Time and Errors: Novel Evaluation Methods for Visualization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Auchus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2130" to="2139" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Focus and context for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Brodlie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at the Proceedings of the Theory and Practice of Computer Graphics</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-time interactive visualization and manipulation of the volumetric data using GPUbased methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Dietrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Nedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Olabarriaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Comba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Zanchet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M M</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Montero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5367</biblScope>
			<biblScope unit="page" from="181" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparing 3D vector field visualization methods: A user study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Forsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions of Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1219" to="1226" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Johnson</surname></persName>
		</author>
		<title level="m">Visualization handbook</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Rendering Equation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kajiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="143" to="150" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Kaufman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="165" to="167" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reimagining the Scientific Visualization Interaction Paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Isenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="51" to="57" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Design of the Bare-Hand Volume Cracker for Analysis of Raw Volumetric Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at the 2014 IEEE VR Workshop on Immersive Volumetric Interaction (WIVI 2014)</title>
		<meeting><address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Identifying the Benefits of Immersion in Virtual Reality for Volume Data Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>presented at the Immersive Visualization Revisited Workshop of the IEEE VR conference</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Volume Cracker: A Bimanual 3D Interaction Technique for Analysis of Raw Volumetric Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Symposium on Spatial User Interaction</title>
		<meeting><address><addrLine>SUI), CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="61" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effects of VR System Fidelity on Analyzing Isosurface Visualization of Volume Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Socha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions of Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="513" to="522" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effects of Immersion on Visual Analysis of Volume Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Laha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sensharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Schiffbauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="597" to="606" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Task taxonomy for graph visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Parr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Henry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">presented at the Proceedings of the 2006 AVI workshop on Beyond time and errors: novel evaluation methods for information visualization</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Interactive volume rendering with ray tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Marmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Slusallek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eurographics State of the Art Reports</title>
		<imprint>
			<biblScope unit="page" from="115" to="136" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Evaluating visualizations: using a taxonomic guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Morse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Olsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="637" to="662" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munzner</surname></persName>
		</author>
		<title level="m">Visualization Analysis and Design</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A Comparative Study of Desktop, Fishtank, and Cave Systems for the Exploration of Volume Rendered Confocal Data Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Forsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Katzourin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wharton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Slater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="551" to="563" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tasks for multivariate network analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Pretorius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Purchase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Stasko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multivariate Network Visualization</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="77" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions of Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2356" to="2365" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Design Space of Visualization Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nocke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heitzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions of Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2366" to="2375" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Interaction design for complex cognitive activities with visual representations: A pattern-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sedig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Parsons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visual Parameter Space Analysis: A Conceptual Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sedlmair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heinzl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Piringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2161" to="2170" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1996 IEEE Symposium on Visual Languages</title>
		<meeting>the 1996 IEEE Symposium on Visual Languages<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page">336</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Particle flurries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Forsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Zeleznik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pivkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="76" to="85" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rethinking Visualization: A High-Level Taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="151" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A parallel coordinates style interface for exploratory volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="80" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A taxonomy of tasks for guiding the evaluation of multidimensional visualizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R A</forename><surname>Valiati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Pimenta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M D S</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 AVI workshop on BEyond time and errors: novel evaluation methods for information visualization</title>
		<meeting>the 2006 AVI workshop on BEyond time and errors: novel evaluation methods for information visualization<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Interactive Volume Rendering of Thin Thread Structures within Multivalued Scientific Data Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Keefe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Laidlaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions of Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="664" to="672" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On distinguishing work tasks and enabling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Whitefield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Escgate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Denley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Byerley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="347" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visual task characterization for automated visual discourse synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Feiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press/Addison-Wesley Publishing Co</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="392" to="399" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
