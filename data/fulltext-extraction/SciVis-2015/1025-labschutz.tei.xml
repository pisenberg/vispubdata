<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Labschütz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bruckner</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Eduard</forename><surname>Gröller</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Hadwiger</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Rautek</surname></persName>
						</author>
						<title level="a" type="main">JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2015.2467331</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T19:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Data Transformation and Representation</term>
					<term>GPUs and Multi-core Architectures</term>
					<term>Volume Rendering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for computation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The display and processing of large volume data poses a challenge due to high computational complexity and memory demands. Memory limitations have become the predominant bottleneck for volumetric data processing and visualization on recent GPU hardware. In practice, however, many types of volume data sets are sparse. Considering their data characteristics such as the regularity and distribution of values within the volume, they can be represented in a more efficient manner than by common regular grids.</p><p>Many different approaches have been proposed for handling sparse volumetric data. For example, bricking techniques and tree representations, such as the octree, kd-tree or N 3 tree, provide a hierarchical solution for data sets of relatively low sparsity. For data sets of medium sparsity, spatial hashing makes more efficient access and storage possible. Extremely sparse data can be efficiently represented and accessed via binary search in sorted voxel lists.</p><p>In general, sparse volume data structures result in a tradeoff between memory efficiency and access performance as more complex memory layouts typically require more costly look-up code, resulting in reduced runtime performance.</p><p>In this paper we present JiTTree, a new type of sparse volume data representation that enables memory-efficient storage and highperformance data access. In contrast to other data structures, JiTTree enables the generation of just-in-time compiled GPU code. It automatically adapts to local data properties and it avoids the performance drawbacks of conventional hybrid data structures. Our approach optimizes the memory layout and the corresponding GPU code using a novel on-the-fly optimization scheme. We flexibly support the combination of several existing sparse data structures to minimize memory consumption while enabling high runtime performance. To the best of our knowledge, this is the first volumetric data structure that simultaneously adapts memory layout and traversal code in a just-in-time manner. We demonstrate that our approach is superior to other data structures in terms of memory consumption for most practical data sets while enabling high-performance look-ups for many common volume processing tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>An overview of spatial data structures is given in the book by Samet <ref type="bibr" target="#b22">[23]</ref>. The survey by Gaede and Günther <ref type="bibr" target="#b6">[7]</ref> includes the concept of spatial hashing, which is a one or two level indirection in the most basic case. Both of these surveys only consider CPU based data structures.</p><p>Hierarchical trees were introduced for representing two dimensional and three dimensional data. Quad-trees <ref type="bibr" target="#b4">[5]</ref> lead to octrees and multidimensional binary search trees (kd-trees) <ref type="bibr" target="#b2">[3]</ref>. The latter were used as a compact volume representation for ray tracing, first on the CPU and later on the GPU.</p><p>Variants of octrees are discussed in the survey by Knoll <ref type="bibr" target="#b13">[14]</ref>. Linear octrees (as introduced for quad-trees by Gargantini <ref type="bibr" target="#b7">[8]</ref>) store all values in a specific order. No internal nodes are kept. Therefore these octrees require a fixed size per entry, independently of the sparsity of the data. Pointer octrees allow sparse data to be represented in a more compact way: a list of pointers and a list of values are stored in two separate arrays. First GPU implementations of sparse pointer octrees are found in the work of Beosnon and Davis <ref type="bibr" target="#b1">[2]</ref>, which uses octrees for surface texture encoding. More recently Crassin et al. <ref type="bibr" target="#b3">[4]</ref> uses a pointer octree for volume rendering. These approaches provide an adaptive representation for a whole volume. Nevertheless, for a densely populated volume (or region), a pointer octree introduces an overhead due to its internal nodes. Additionally, the look-up into an octree causes a performance overhead for the indirections when traversing the octree to the leaves.</p><p>Recently, algorithms were formulated to generate octrees on the GPU. For instance, Lauterbach et al. <ref type="bibr" target="#b14">[15]</ref> presented an efficient bottom-up generation scheme. Starting from a list of entries they sort the nodes depending on their Morton code. An algorithm for parallel octree construction that uses a full volume to construct a sparse octree was described by Ziegler <ref type="bibr" target="#b28">[29]</ref>. The basis of the octree construction algorithm are histogram pyramids <ref type="bibr" target="#b29">[30]</ref> also used in the voxel list generation. We have based our voxel list and octree generation on this parallel algorithm. Voxel list access was improved by using spatial hashing or binary search. Perfect spatial hashing <ref type="bibr" target="#b15">[16]</ref> provides faster access for sparse data than an octree <ref type="table">. Nevertheless, the generation of a suitable hash  function and an offset table can be computationally demanding.</ref> Binary search provides an alternative to spatial hashing for a small number of elements. The only requirement for binary search is a sorted list. To efficiently sort a list, voxel radix sort by Satish et al. <ref type="bibr" target="#b23">[24]</ref> can be used. Histogram pyramids <ref type="bibr" target="#b29">[30]</ref> provide an alternative to sort the non-zero points in a volume in Morton order.</p><p>Bricking on the CPU was used to improve cache coherency by Grimm et al. <ref type="bibr" target="#b8">[9]</ref>. Kähler et al. <ref type="bibr" target="#b12">[13]</ref> use a CPU based kd-tree on top of a bricking approach to render adaptive mesh refinement data. They render the bricks sequentially in back-to-front order. Ruijters et al. <ref type="bibr" target="#b21">[22]</ref> use bricking on the GPU for volume rendering. To reduce the workload on the GPU, they generate a CPU side octree for each brick. The octree is traversed with a threshold for sampling the brick data which is used in slice based rasterization. Virtual memory management <ref type="bibr" target="#b9">[10]</ref> can be used to complement our brick-based data structure as well, but it is an orthogonal concept to compact sparse representations.</p><p>Glift <ref type="bibr" target="#b16">[17]</ref> provides an abstraction layer to build data structures on top of OpenGL. The library was used to formulate a dynamic, sparse, adaptive structure for shadow maps and 3D painting. Glift uses an adaptive bricking approach on the GPU. The introduction of OpenCL and CUDA allows developers to build such data structures more easily. Just-in-time compilation makes it possible to dynamically allocate the required memory on the GPU and to remove unnecessary code.</p><p>Our work is based on the partial evaluation of programs that is described by Jones et al. <ref type="bibr" target="#b11">[12]</ref>. We partially evaluate the GPU programs for performance reasons but also to make our data structure more flexible. More recently Rompf et al. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> and Sujeeth et al. <ref type="bibr" target="#b24">[25]</ref> have described a lightweight modular staging approach that enables the deferral of parts of the program compilation to a later stage. The reason is that at a late stage the compiler is aware of the data and can thereby generate optimized programs. We show how such a data aware compilation can be used to generate an efficient sparse volume data structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">JITTREE OVERVIEW</head><p>A JiTTree is a high performance memory efficient volumetric representation with access functions that are tailored to one specific data set. The main concept of the JiTTree is the just-in-time compilation stage that transforms data into efficient access functions. Thereby it enables the use of multiple kinds of data structures to represent one volume, without introducing a significant traversal overhead. For instance a JiTTree can store some of the data using an octree, while other parts of the data are represented as dense grids. We call these data structures (octree, dense grid, etc.) the elemental data structures to distinguish them from the hybrid data structure that combines them. In general a hybrid data structure consists of elemental data structures, to locally better represent a data set. The more elemental data structures are used the higher is the potential that the memory efficiency increases. However, with conventional approaches more elemental data structures mean a higher overhead during data traversal. Instead of depending on the number of elemental data structures, the traversal overhead of a JiTTree depends on the homogeneity of the data set. We achieve this by just-in-time compiling traversal code that is tailored to a specific data set and its optimal hybrid representation. Rompf et al. <ref type="bibr" target="#b19">[20]</ref> show that such a data aware compilation stage can be used to optimize performance. To illustrate the key concept of our data structure we consider the example of a binary search tree. <ref type="figure" target="#fig_0">Figure 1</ref> shows the binary tree of a sorted list. During look-up the tree is traversed from top to bottom. When the key is found the index of the element in the compact array is returned.</p><p>Similarly to our sparse volume approach, a binary search tree enables efficient access to a sparse array. Let a be an array of <ref type="bibr" target="#b14">15</ref>  Listing 1 shows the pseudo code of the recursive tree traversal. The search key is compared to the root node. If the search key is smaller than the current node's key, the traversal continues in the left subtree. If it is greater the search continues in the right sub-tree. If the key is equal the search is successful and returns the index [0..14] of the compact array. The search tree enables the use of a sparse array which makes it possible to remove the empty elements in the sorted list. Thereby, it greatly saves storage space. Traversal is efficient but nevertheless incurs an overhead in comparison to a dense array. The node.key instructions in Listing 1 are the memory fetches that are introduced for tree traversal, and the node.index instruction is the memory fetch that is introduced to retrieve the index into the compact array. The just-in-time transformation of such a tree directly incorporates the data of the tree into the code. It thereby eliminates the need for memory fetches and greatly reduces traversal overhead. Listing 2 shows the pseudo code of the just-in-time compiled search tree.</p><p>1 // jit find function with look-up key k 2 // k is assumed to exist in the tree 3 uint find(key) 4 { // compare key to root key  Listing 2: JiTTree look-up function pseudo code By explicitly compiling the data into the code the access becomes less memory-bound during tree traversal. This is beneficial for many data processing algorithms.</p><p>For our case of multiple elemental data structures the compact array a comp needs to store types and pointers. The types are encoded as colors in the example of <ref type="figure" target="#fig_0">Figure 1</ref>. If we want to execute a function f oo on the elements we first have to look-up their type and then route the function call to the specialized function of that type. In case of the recursive look-up the execution of a function is shown in Listing 3. The overhead to resolve types is eliminated and specialized functions can directly be called. These same concepts apply to the JiTTree. It eliminates memory fetches in the top level traversal code and inlines type specialization. This eliminates type resolving as well as the switch statements that route execution between the different elemental data structures. Therefore, the access time to one node is independent of the number of different elemental node types. As a consequence the JiTTree can have an arbitrary number of different kinds of sparse data structures that improve the overall quality of the JiTTree without introducing new memory fetches. This is an important property of a hybrid data structure that was to the best of our knowledge never achieved before.</p><p>In essence the JiTTree decreases memory requirements by increasing program length. GPU algorithms are known to be either memorybound (i.e., the performance is limited by the number of memory fetches), compute-bound (i.e., the performance is limited by the number of arithmetic computations, also called high computational density), or instruction-throughput-bound (i.e., the performance is limited by the non-arithmetic instructions) <ref type="bibr" target="#b27">[28]</ref>. The just-in-time compilation is an attempt to shift some of the burden from the GPU's memory cache to the instruction cache making the overall algorithm less memory-bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DATA STRUCTURE LAYOUT</head><p>The basic principle of our data structure is to adapt to the local sparsity of a specific data set. Other volume representations often make the distinction between dense and empty (or homogenous) regions and treat these regions differently. We aim to locally better adapt to a certain level of sparsity of the data than these representations by introducing more fine grained distinctions. A data set typically contains many subregions with different sparsity characteristics. Each of the regions can be optimally encoded by one data representation. Very sparse regions are for instance better represented by a voxel list, medium sparse regions lend themselves best to hash tables <ref type="bibr" target="#b15">[16]</ref> and octrees, while dense regions are most efficiently stored in a dense representation. For our implementation of the JiTTree we chose a combination of four different representations: empty, voxel list, octree, dense. Each type performs best for a different level of sparsity. We describe these elemental node types from highest to lowest sparsity in Section 4.1. Each brick holds one of the elemental data structures: dense, voxel list, octree or is an empty region. In (b) the basic data layout is shown. The volume consists of a list of bricks which point to elemental leaf nodes.</p><p>To support local adaptation our data structure is designed as a pointer based tree. <ref type="figure" target="#fig_4">Figure 2</ref> shows an example for our data layout. Similar to volume bricking approaches <ref type="bibr" target="#b25">[26]</ref> we divide the data into bricks. In contrast to other bricking schemes our data structure allows every brick to be represented by a different data structure. The goal is to pick the optimal representation for each brick while globally optimizing brick size, as well as the layout of the data structure. In Section 6 we describe the implementation of the root level in the bricking hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Elemental node types</head><p>The memory optimal data structure for one brick of a volume depends on the position and the number of non-zero entries. In this work we consider three different data structures which form, together with the empty brick type, the four elemental node types:</p><p>• Empty volume: Empty bricks are simply omitted when the data is uploaded to the GPU.</p><p>• Voxel list: A voxel list is represented as a set of quadruples (x, y, z, value). Each of the x, y, z coordinates theoretically requires log 2 (m) bits where m is the side length of the volume. Voxel lists are memory efficient for extremely sparse volumes. A major drawback of voxel lists is that access to the data requires O(n) steps, where n is the number of elements in the list. It is possible to decrease the look-up time in a sorted voxel list with binary search to O(log(n)).</p><p>• Octree: The octree itself is an adaptive data structure performing best for medium sparse data sets. In addition to the leaf nodes a full pointer octree has (m 3 − 1)/7 internal nodes, where m must be a power of two. The access performance depends on the side length of the volume and not the number of elements with a worst case access of O(log(m)) traversal steps. As a result, in very sparse cases, voxel list access can outperform octree access. We have implemented a pointer octree <ref type="bibr" target="#b26">[27]</ref>. Each node of the tree stores exactly 8 pointers to its children. Pointers are indices into a one dimensional array and can also point to an empty element. In our case the leaf nodes store bricks with 2 3 values. In our implementation the maximum overhead of pointers for a full octree is approximately <ref type="bibr">1 6</ref> of the number of values in the dense volume. However, octrees are shift sensitive <ref type="bibr" target="#b22">[23]</ref> and the number of internal nodes in a sparse octree depends on the exact location of the octree.</p><p>• Dense volume: A Cartesian grid has the lowest overhead per data voxel and is therefore memory efficient for very dense data. However, the major advantage of a dense grid is fast access and in many cases it makes sense to trade some memory for better performance. Among the many octree implementations the best one, with regard to bit overhead per voxel, is the pointer-less octree (as used by Balmelli <ref type="bibr" target="#b0">[1]</ref>) with 0 bit overhead per entry. An octree containing one leaf node has the theoretical minimal size of 3 log 2 (m), which is the number of bits required to store the Morton code <ref type="bibr" target="#b18">[19]</ref> to reach the brick containing the entry. The Morton code encodes each octree traversal step with 3 bits to reach one of the 8 child nodes. In total there are log 2 (m) levels in an octree of side-length m. The octree properties in the table are representative for pointer octrees. If the octree contains only one value, the upper bound is reached. In addition to the data value, the octree requires log 2 (m) pointers (one for each octree level) to address the single non-zero entry. The number of internal nodes of a full octree is approximately 1/7 of the number of leaf nodes. Therefore, a full octree requires ∼ 1/7 pointer per data entry. <ref type="table" target="#tab_3">Table 1</ref> also shows that the dense volume representation has the best access performance. The optimal memory representation depends on the data set. The dense representation is optimal for full volumes, but has the highest overhead for a single value. The worst case of the octree performs better than the worst case of the dense data representation. The voxel list has a constant overhead per non-zero voxel independent of the number of values inside a volume. The memory requirement of a specific representation depends on the density inside a volume block, the data type of the data entries and for the octree, the exact location of the non-empty voxels inside the volume. It can be seen that the three data structures complement each other since they are optimal for cases where the others perform poorly.</p><p>Other data structures such as hash tables or multilevel bricking could further complement the data structures. However, for the moment we restrict ourselves to the analysis of our data structure using the described elemental node types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">OPTIMIZATION OF ELEMENTAL NODE LEVEL</head><p>We optimize the hybrid data structure with respect to memory by locally adapting the elemental node types and globally adapting the brick size. The performance is optimized through several low-level optimizations that can be added on demand by a data aware compiler.</p><p>Memory optimization: To find a representation that requires a minimum of memory it is necessary to pick a combination of the most suitable elemental node and an optimal block size m. To determine the layout of a specific volume data set, we use different variations of a parallel reduction. The size of a dense representation is known beforehand, as dm 3 where m is the side-length of a brick and d is the number of bytes of one data entry. To estimate the size of a voxel list inside a sub-volume it is necessary to find the number of non-zero values. We efficiently achieve this by applying a parallel reduction. The octree size estimation requires two adapted reductions: one to determine the number of leaves and one to determine the number of internal nodes in the final sparse octree. Finding the number of leaf nodes requires a reduction on a binary occupancy volume (i.e., voxels are one for non-zero values and zero otherwise). Finding the number of internal nodes requires a reduction starting at a binary representation at level = height − 1 of the octree. In our case, the octree is slightly modified to support leaves of 8 values instead of single scalar octree leaf values, which basically shifts the reductions up by one level inside the tree. This is done because, pointers to the leaf nodes only make sense if the data values are much larger than the pointers. This is not the case for most scalar data, therefore leaves with 8 values require less memory than the full pointer octree and the access performance is also higher.</p><p>To globally optimize the memory requirement we compute the memory requirements of each brick for a given brick size. It is sufficient to choose the minimal elemental data structure for each brick. From the results of all considered brick sizes the global minimum is picked as the memory optimal solution.</p><p>Performance optimization: During the performance optimization stage different low level data dependent optimizations can be applied. Our data aware compilation stage makes use of high level information and thereby applies better optimizations than the regular (nondata aware) compiler. Code branches that are known not to be traversed because of the specific configuration of the memory optimal data structure are removed during the just-in-time compilation step. For instance, for a configuration that does not contain any voxel lists, all code that is specific to the voxel lists is removed from the program. Note that a regular compiler (e.g., the OpenCL compiler) cannot apply this dead code removal since it depends on the data representation.</p><p>A software stack cache for regular access patterns is another low level optimization that is performed by our compiler. This leads to performance benefits for ray traversal for very small work group sizes only. For ray traversal patterns a simplified version of the kd-restart algorithm <ref type="bibr" target="#b5">[6]</ref> is used to perform empty space skipping. When hitting an empty brick the algorithm directly advances to the most distant point on the empty brick bounding box. This saves redundant look-ups in empty bricks and results in speed up factors of up to 1.5. All these optimizations can be enabled on demand and are disabled (i.e., removed from the code) without any side effects if they do not improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">OPTIMIZATION OF ROOT LEVEL</head><p>The root node representation stores the type and the pointer to every brick inside an array. This representation can either directly be uploaded to the GPU or it can be transformed to code through a just-intime compilation step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Direct volume bricking approach</head><p>The direct bricking approach stores internal nodes as a tuple (type, pointer). The size of the bricks is globally defined in our current implementation. The type can be one of the elemental node types. The pointer is handled in a type specific way. <ref type="figure" target="#fig_5">Figure 3</ref> gives a conceptual overview of the data structure. At the root level, each node needs to store a type and a pointer, which consists of two 4 byte integers in our case.  Every look-up starts by an address translation and then retrieves the (type, pointer) tuple of the brick. Look-ups for empty nodes can be discarded at this point. The specialized look-up procedures are:</p><p>• Dense volume bricks store a pointer into the dense volume array at the root level. The size of the dense volume array is m 3 times the number of dense volume bricks.</p><p>• To access one of multiple voxel lists stored in a buffer it is necessary to define the start and end voxel of each list in addition to its entries. One look-up retrieves the start offset from an offset array. Afterward, the list is traversed to search for a specific coordinate. If the coordinate is not found the look-up returns zero.</p><p>• For the octree the brick pointer directly points to the root of the tree inside a global octree pointer array. The brick resolution determines the maximal traversal depth of the octree. The octree is traversed until it reaches a leaf node or an empty node. The actual values are stored in a separate region of the memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Just-in-Time compilation approach</head><p>To reduce the traversal overhead that is introduced by the root level we use just-in-time compilation that eliminates the data fetch by incorporating it into the code. As described in Section 3, a search tree is used to efficiently index the data. We use a kd-tree to index the elemental bricks of our data structure. The kd-tree splits the set of bricks at brick boundaries into large homogeneous regions containing only one elemental type. This makes it possible to discard empty regions fast. Homogeneous sub regions implement a bricking approach that uses only a single brick type, which locally reduces the number of branches. x y z <ref type="figure">Fig. 4</ref>: Example of a kd-tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dense Octree</head><p>To group bricks with the same type, our splitting criterion maximizes the information gain, as introduced by Mitchell <ref type="bibr" target="#b17">[18]</ref> in the context of optimizing decision trees. The entropy E of a region S with respect to the brick types is given in Equation 1. b is the number of different brick types, in our case four. p i is the portion of the bricks with type i.</p><formula xml:id="formula_0">E(S) = − b ∑ i=1 p i log b p i (1)</formula><p>Minimizing the average entropy is equivalent to maximizing information gain. We calculate the average entropy for each possible split as given in Equation 2. The volume is recursively split into two subregions S j , j = 2. Lets define v j as the volume of a sub-region (i.e., a kd-tree child) S j , the information gain I(S) is then computed as</p><formula xml:id="formula_1">I(S) = ∑ j v j v E(S j )<label>(2)</label></formula><p>where the entropy of each sub-region E(S j ) is weighted by the volume of this sub-region v j normalized by the total volume v.</p><p>Splitting is applied recursively until each kd-tree leaf contains bricks of only one elemental node type. <ref type="figure">Figure 4</ref> shows an example where a volume consists of eight bricks, each of size 32 3 . After the kd-tree is constructed it is just-in-time compiled. Listing 5 shows the code for the kd-tree in <ref type="figure">Figure 4</ref>.  (iv) index in-baking: the indices of the octrees (i.e., index oct1 and index oct2 ) and dense bricks (i.e., index dense1 and index dense2 ) are literals that are directly baked into the code. This eliminates one memory fetch per leaf node.</p><p>Leaves that are empty return zero. Leaves that contain a single nonzero elemental node directly call the specific get method. In the case of multiple bricks in one leaf node the kd-tree generation guarantees that they are of the same type. Therefore the same get method is called for all of them. However, the index (which is a parameter of the get method) is different for each brick. By generating local index arrays we can further optimize the code, remove additional branching and benefit from the above mentioned kd-tree generation that reduces the number of leaf nodes.</p><p>Listing 6 shows code for the unoptimized case where three dense bricks are next to each other and fall into the same kd-tree leaf node. The array index[] is initialized with the literals index dense1 , index dense2 , and index dense3 , that are resolved at compile time. The indexTransform function transforms the global coordinates to a local linear index into the kd-tree cell. As a consequence the get method can be executed in parallel by all threads reducing branch divergence. This optimization is only applicable in the case that bricks of the same type cluster in a region and are grouped by the kd-tree into one cell. In Listings 6 and 7 only three bricks of the same type are grouped together. In practice these groups often become larger and more branches are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">IMPLEMENTATION</head><p>OpenCL and CUDA (version 7) support run-time compilation and therefore lend themselves to just-in-time compilation approaches. Our JiTTree implementation was done using OpenCL. A source-to-source compiler takes an OpenCL program with specialized instructions for memory access and translates it to pure OpenCL code during runtime. The compiler can better specialize the generated code when the data set is known. Computation on multiple independently generated JiT-Trees is done by defining them as separate kernel arguments.</p><p>To speed up the memory optimization phase a fast calculation of the memory requirements is essential. Regions containing only zero values are marked with the empty type and no further optimization is needed. The computation of the memory requirements for a dense node is trivial. For voxel list nodes a single parallel reduction operation is needed to compute the number of non-zero values. The size of the octree nodes is calculated by first counting the number of octree leaf nodes and then counting the number of internal nodes. This is efficiently achieved by computing two reduction operations. These computations are all done efficiently in parallel. The memory requirements of the elemental node types are sufficient to compute the memory optimal JiTTree for a given brick size. We repeat this computation for different brick sizes to get the overall most efficient hybrid data structure.</p><p>After a specific representation of the data structure is defined we either apply a bricking approach or generate a just-in-time compiled kd-tree. Our source-to-source compiler first generates a kd-tree on the application side based on the previously defined brick types. The kd-tree is recursively unrolled into non-recursive OpenCL code. The sourceto-source compiler generates code for internal kd-tree nodes as well as for leaf nodes. Internal nodes generate conditionals (i.e., if/else statements). Leaf nodes are either empty (code returns zero), contain a single brick (code calls a get method) or contain multiple bricks of the same type (code uses leaf node branch removal described in Section 6.2).</p><p>The memory for the different elemental data structures is allocated once the optimal data structure is known. The actual initialization of the data structures is done per brick. The initialization of voxel lists and octrees on the GPU is done using histogram pyramids <ref type="bibr" target="#b29">[30]</ref>. We make use of the fact that voxel lists initialized via histogram pyramids are sorted in Morton order. Therefore binary search is used when the data is accessed.</p><p>The octree nodes are generated using a variant of OcPyramids <ref type="bibr" target="#b28">[29]</ref>, that combine multiple histogram pyramids. In our implementation we allow a block of size 2 3 in the leaf nodes resulting in a more compact octree with an overhead of approximately <ref type="bibr" target="#b0">1</ref> 6 pointer per data entry for a full octree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">RESULTS</head><p>The results are generated on a machine using an NVIDIA GeForce GTX TITAN X, Intel Core i7-4770K @ 3.50 GHz and 16 GB RAM. The screen resolution for rendering is 768 × 768 pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Memory consumption</head><p>We compare the memory requirement for 15 data sets shown in Table 2. Larger renderings can be seen in <ref type="figure" target="#fig_0">Figure 10</ref>. Noise was removed from most of the shown data sets since we are interested in the investigation of sparse data sets. Wherever we applied a threshold to a data set we denote this in <ref type="table" target="#tab_7">Table 2</ref> with the specific threshold indicated as subscript. The data after thresholding are shown as icons. It is important to note that we also tested our data structure on all shown data sets without applying a threshold. Although our data structure is not designed for dense data, it outperforms other representations, such as a dense bricking or a dense representation, for most cases. However, for a better analysis of the data structure we used data sets with varying sparsity. We compared the final size in relation to the total size of a dense representation. The percentage of non-zero values gives the theoretical lower bound for the optimal data structure. The last column shows the distribution of elemental node types for the memory optimal JiTTree. Grey denotes the empty, green the dense, orange the octree and blue the voxel list representation.</p><p>The Vessels data set, for example, has a high number of voxel list bricks, which means that many bricks contain only a very small number of non-zero values. The stag beetle data set results in a low overhead because it contains a large number of empty bricks and most bricks containing non-zero values are densely populated. In our experiments our approach never exceeded three times the size of the lower bound solution.</p><p>In comparison to perfect spatial hashing, which achieves an overhead of 3 − 7 bit per data entry for very sparse data, we have shown that our approach can be applied to a broader range of volumes (also with much higher density). The overhead of our data structure for the tested data sets lies between 1.8 and 27.7 bit per non-zero voxel. Volumes with very dense and very sparse regions, can be represented very efficiently with our approach. Still, the approach is extensible to other elemental representations such as spatial hashing, to further improve the overall performance for special data set characteristics. <ref type="figure" target="#fig_9">Figure 5</ref> shows the memory requirements for two data sets for different brick sizes and different elemental data. In <ref type="figure" target="#fig_9">Figure 5a</ref> the hydrogen data set is shown. It can be represented optimally with a brick size of 8. A combination of dense, octree and voxel list (Opt.) performs better than any bricked solution using the octree, the dense, or the voxel list representation only. Even though the voxel list does not provide good results over the whole data set, there are still very sparse bricks that are best represented by a voxel list as seen in <ref type="table" target="#tab_7">Table 2</ref>.</p><p>In <ref type="figure" target="#fig_9">Figure 5b</ref> the results for the Engine data set are shown. The data is represented effectively by an octree with a larger brick size. Nevertheless, the memory optimal (Opt.) solution still performs better. If for a specific data set a single elemental data structure would be the best solution, our approach would degenerate and fall back to this solution. However, we have never observed this in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Performance</head><p>The performance was tested for a mean filter with different kernel sizes as well as for volume ray casting. <ref type="figure" target="#fig_10">Figure 6</ref> shows the performance for the mean filter. As expected the dense node type results in the best performance for all brick sizes and kernel sizes. The memory optimized data structure (i.e., a mixture of dense, octree and voxel list) is still faster than an octree bricking solution for these data sets.  <ref type="figure">Figure 7</ref> compares the performance of the direct volume bricking approach of the memory optimal solution (Section 6.1) with the JIT compilation approach of the memory optimal solution (Section 6.2). The JIT approach improves the performance in most cases with an average speed up factor of 1.29 over all measured cases. The highest speed up in <ref type="figure">Figure 7</ref>, a factor of 1.79, is given for the stag beetle dataset at a  <ref type="figure">Figure 8</ref> shows the performance of a 3x3x3 mean filter for different data representations. The dense bricking approach (green) performs better with a smaller brick size. The octree bricking (orange) does not decrease its memory requirement significantly with a smaller brick size. Nevertheless it is faster for a smaller brick size since the traversal depth is reduced. The memory optimized solutions (black) perform best in terms of memory consumption over all different brick sizes. The just-in-time compiled variations (purple) improve the performance of the memory optimal solutions. A comparison with voxel lists was omitted from <ref type="figure">Figure 8</ref>, since their performance is much worse for an entire data set. Nevertheless, voxel lists perform optimal in terms of memory for very sparse nodes, which makes them attractive for a hybrid data structure.  <ref type="table" target="#tab_9">Table 3</ref> shows the JIT generated code properties and build times for a typical case. The number of leaf nodes increases with the number of bricks. However, the dependency is not linear since the kd-tree groups bricks of the same type together. Therefore, the number of leaves does not grow as fast as the number of bricks.  <ref type="figure">Fig. 9</ref>: Performance of ray casting with the JIT approach compared to the memory optimal bricking (black line).</p><p>In contrast to filtering, the JIT approach does not perform well for ray casting as shown in <ref type="figure">Figure 9</ref>. In our experiments we found that it only outperforms the direct bricking for small, homogeneous data sets. Larger data sets with a high number of bricks are better handled with a direct bricking approach. We suspect that the ray access pattern leads to much higher branch divergence than the stencil access pattern for the mean filter calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">DISCUSSION AND FUTURE WORK</head><p>Our hybrid data structure performs very well in terms of adaptation resulting in low memory consumption. By adding more elemental data structures we hope to approach the theoretical optimum of memory consumption with our hybrid data structure in the future. One of the most important properties of a modern GPU data structure is to reduce memory bandwidth (which is the bottleneck in memory-bound kernels). With our just-in-time compilation approach we can offload some of the burden reducing the memory bandwidth. However, just-intime compilation comes at the cost of longer programs and especially nested conditionals. In some cases this transforms memory-bound programs into instruction-bound programs. Also with our approach we are exhausting the capabilities of the current OpenCL compilers. This limits the JiTTree to compile only up to 32768 leaf nodes. For higher node counts we get inconsistent compile times. Our experiments show that the just-in-time compilation of the root level is a viable option to improve performance. In the future we want to investigate other spatial subdivision schemes that can be just-in-time compiled to further increase performance.</p><p>We want to improve the JIT compilation approach for other memory access patterns like ray traversal. One potential cause of the lower performance in this case is branch divergence which can be addressed with optimization techniques like branch distribution and iteration delaying <ref type="bibr" target="#b10">[11]</ref>.</p><p>Another direction for research is to investigate how to add dynamic write capabilities to our current implementation. For the moment we have focused on read-only access since most other efficient sparse data structures are also optimized for this situation. Finally, the addition of spatial hashing would further increase the adaptivity of our hybrid data structure. Also it could be a candidate for a just-in-time compiled root level.</p><p>In addition, it could be beneficial to defer the JIT compilation even further. For instance on compute clusters each node could justin-time compile the optimal data structure for a sub-domain of the data. Further experiments (for instance integration of the JiTTree with OpenMP) are necessary to understand the applicability of our approach in such scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">CONCLUSION</head><p>Sparse data structures are an important tool for efficient computations on the GPU. Our hybrid data structure makes it possible to combine multiple elemental data structures resulting in lower memory requirements. The individual elemental data structures can be exchanged and improved separately. JiTTree reaches a noticeable benefit even with a set of simple elemental data structures. We demonstrated that the involved optimization leads to good results for a broad range of data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The research presented in this publication was supported by the King Abdullah University of Science and Technology (KAUST) Visual Computing Center, and the ViMaL project (FWF -Austrian Science Fund, no. P21695). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Binary search tree example. Color encodes the data type.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>15 else if(key &gt; 106) // traverse right subtree 16 // code omitted for brevity 17 ...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>18 else return 7</head><label>187</label><figDesc>; 19 }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>/</head><label></label><figDesc>/ function foo uses recursive traversal // type specialization via switch statement value foo(key, root) { // tree traversal to get index uint index = find(key, root); // compact array lookup element e = a comp [index]; // specialize function call by element type switch(e.type) { case green: return foo green (e.address); case orange: return foo orange (e.address); case blue: return foo blue (e.address); } } Listing 3: foo member function evaluation pseudo code Through JIT compilation we inline the traversal code, the type specialization and the address look-up into the foo function. Listing 4 shows the result of JIT compiling the member function foo of the elements in the sparse array. // function foo inlined traversal // type specialization done at jit compilation value foo(key, root) { // compare key to root key if(key &lt; 106) // traverse left subtree if(key &lt; 8) // traverse left-left subtree // call specialized function if(key &lt; 4) return foo green (addr 0 ); else if(key &gt; 4) return foo green (addr 2 ); else return foo green (addr 1 ); if(key &gt; 8) // traverse left-right subtree if(key &lt; 13) return foo green (addr 4 ); else if(key &gt; 13) return foo orange (addr 6 ); else return foo green (addr 5 ); else return foo green (addr 3 ); else if(key &gt; 106) // traverse right subtree // code omitted for brevity ... else return foo orange (addr 7 ); } Listing 4: foo JIT function evaluation pseudo code</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 :</head><label>2</label><figDesc>(a) shows a volume that is split into 3<ref type="bibr" target="#b2">3</ref> bricks each of size m 3 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 :</head><label>3</label><figDesc>Conceptual data layout: root level nodes point to the elemental data structures. Traversal is specific to the type of a brick. Different traversals are shown for the different elemental node types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>1 / 4 if 9 else // traverse right subtree 10 if 12 if</head><label>1491012</label><figDesc>/ jit get function with look-up position (x,y,z) 2 voxel get(x,y,z) 3 { // compare to splitting positions 32) return get oct (index oct1 , x,y,z);8 else return get dense (index dense1 , x,y,z); (y &lt; 32) return get dense (index dense2 , x,y,z); 13 else return get oct (index oct2 , x,y,z); 14 } Listing 5: JiTTree get function pseudo code In Listing 5, four optimizations were applied: (i) traversal optimization: no memory fetches are required for the kd-tree traversal. The splitting axis order is directly encoded in the conditionals. Splitting plane positions are inserted as literals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>(</head><label></label><figDesc>ii) efficient discarding of empty regions: empty regions are quickly discarded without any memory fetches.(iii) implicit specialization: no routing between specializations of the get functions of different elemental data structures is required. The get dense and get oct functions are inserted at the leaf nodes. No type checks are required, and no type dependent switch statement is needed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>/Listing 6 :Listing 7 :</head><label>67</label><figDesc>/ jit get function without leaf node branch removal voxel get(x,y,z) { ... // traversal to a leaf node if(z &lt; 32) return get dense (index dense1 , x,y,z); else if (z &lt; 64) return get dense (index dense2 , x,y,z); else return get dense (index dense3 , x,y,z); } Leaf node pseudo code without branch removal Although the three branches call the same get method, the index parameter differs. The branches can only be removed by introducing a local index array that holds the valid index for each brick. Listing 7 shows code for the fifth optimization that we apply: (v) leaf node branch removal: branches that are introduced by the leaf nodes of the kd-tree are removed by introducing a local index array. // jit get function with leaf node branch removal voxel get(x,y,z) { ... // traversal to a leaf node index[] = {index dense1 , index dense2 , index dense3 }; i = index[indexTransform(x,y,z)]; return get dense (i, x,y,z); } Leaf node pseudo code with branch removal</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 5 :</head><label>5</label><figDesc>Memory requirement of dense, octree, voxel list and memory optimal bricking. The memory optimal bricking outperforms any other bricking for most cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 6 :</head><label>6</label><figDesc>Performance of a mean filter with kernel sizes 7 3 , 5 3 and 3<ref type="bibr" target="#b2">3</ref> in ms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 :</head><label>10</label><figDesc>Volume rendering of the benchmark data sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>•</head><label></label><figDesc>Matthias Labschütz is with KAUST, E-mail: mlabschuetz@cg.tuwien.ac.at. • Stefan Bruckner is with University of Bergen, E-mail: stefan.bruckner@uib.no. • M. Eduard Gröller is with TU Wien and VrVis Research Center, E-mail: mailto:meister@cg.tuwien.ac.at. • Markus Hadwiger is with KAUST, E-mail: markus.hadwiger@kaust.edu.sa. • Peter Rautek is with KAUST, E-mail: peter.rautek@kaust.edu.sa. Manuscript received 31 Mar. 2015; accepted 1 Aug. 2015; date of publication xx Aug. 2015; date of current version 25 Oct. 2015. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Theoretical comparison of the properties of different elemental node types. m is the side length of a data block. n is the number of non-zero elements inside the data block. d is the size of one data entry in bits. p is the pointer size which needs to be sufficiently large.</figDesc><table><row><cell></cell><cell>Access time</cell><cell cols="4">Bit overhead / non-empty Voxel Shift sensitive Allows empty space skipping upper bound lower bound</cell></row><row><cell>Dense volume Pointer octree Voxel List</cell><cell>O(1) O(log(m)) O(log(n))</cell><cell>∼ dm 3 p log 2 (m) 3 log 2 (m)</cell><cell>0 ∼ p/7 3 log 2 (m)</cell><cell>no yes no</cell><cell>no yes no</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1</head><label>1</label><figDesc>gives a theoretical comparison of the implemented elemental node type data structures. The upper bound is reached if the volume is practically empty, the lower bound is reached if the volume contains no zero entries.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Elemental nodes depend on the size of the data type in bytes d. Dense volumes store full bricks of data values. Each list stores one 4 byte pointer to its last element in the list offset array. Each list element stores a data value and three 2 byte values as its coordinates. Internal octree nodes always store eight 4 byte pointers and leaf nodes store eight data values.</figDesc><table><row><cell></cell><cell>Root level</cell><cell>...</cell><cell></cell></row><row><cell></cell><cell></cell><cell>2x4 bytes</cell><cell></cell></row><row><cell></cell><cell>Dense volume</cell><cell></cell><cell>...</cell></row><row><cell></cell><cell></cell><cell>m 3 x d</cell><cell></cell></row><row><cell>Elemental node types</cell><cell>Octree pointer List offset (length) List Element</cell><cell>8x4 bytes ... 6 bytes + d 4 bytes</cell><cell>... ...</cell></row><row><cell></cell><cell>Octree value</cell><cell></cell><cell>...</cell></row><row><cell></cell><cell></cell><cell>8 x d</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 :</head><label>2</label><figDesc>Memory consumption results. The brick types are empty (gray), dense (green), octree (orange) and voxel list (blue)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Non-zero values</cell><cell>Final size</cell><cell>Type of bricks</cell></row><row><cell>Image</cell><cell>Volume size</cell><cell>Optimal brick size</cell><cell>(%)</cell><cell>(% of dense)</cell><cell>(% of volume)</cell></row><row><cell>Bonsai th=0.08</cell><cell>512x512x189</cell><cell>16x16x16</cell><cell>8.17</cell><cell>14.85</cell><cell></cell></row><row><cell>Bunny th=0.08</cell><cell>512x512x361</cell><cell>8x8x8</cell><cell>28.76</cell><cell>34.28</cell><cell></cell></row><row><cell>Carp th=0.08</cell><cell>256x256x512</cell><cell>16x16x16</cell><cell>16.27</cell><cell>19.82</cell><cell></cell></row><row><cell>Christmas tree th=0.03</cell><cell>512x499x512</cell><cell>16x16x16</cell><cell>1.47</cell><cell>4.02</cell><cell></cell></row><row><cell>Engine th=0.08</cell><cell>256x256x256</cell><cell>8x8x8</cell><cell>8.34</cell><cell>12.32</cell><cell></cell></row><row><cell>Frog th=0.08</cell><cell>256x256x44</cell><cell>8x8x8</cell><cell>11.22</cell><cell>18.23</cell><cell></cell></row><row><cell>Hydrogen</cell><cell>128x128x128</cell><cell>8x8x8</cell><cell>32.72</cell><cell>38.58</cell><cell></cell></row><row><cell>Monkey-CT</cell><cell>256x256x62</cell><cell>16x16x16</cell><cell>17.11</cell><cell>29.68</cell><cell></cell></row><row><cell>Piggy Bank th=0.03</cell><cell>512x512x134</cell><cell>8x8x8</cell><cell>23.72</cell><cell>30.53</cell><cell></cell></row><row><cell>Porsche th=0.03</cell><cell>559x1023x347</cell><cell>16x16x16</cell><cell>40.31</cell><cell>52.46</cell><cell></cell></row><row><cell>Schaedel th=0.03</cell><cell>512x512x333</cell><cell>8x8x8</cell><cell>15.64</cell><cell>23.14</cell><cell></cell></row><row><cell>Stag beetle</cell><cell>832x832x494</cell><cell>16x16x16</cell><cell>4.06</cell><cell>4.75</cell><cell></cell></row><row><cell>Kingsnake th=0.15</cell><cell>1024x1024x795</cell><cell>16x16x16</cell><cell>43.68</cell><cell>44.85</cell><cell></cell></row><row><cell>Vessels th=0.15</cell><cell>1024x1024x1024</cell><cell>16x16x16</cell><cell>1.67</cell><cell>4.22</cell><cell></cell></row><row><cell>Connectomics</cell><cell>1024x1024x1024</cell><cell>16x16x16</cell><cell>29.68</cell><cell>34.04</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 3 :</head><label>3</label><figDesc>JIT generated code properties and build times for the Connectomics data set.</figDesc><table><row><cell></cell><cell></cell><cell>max. branch</cell><cell>kd-tree</cell><cell>OpenCL</cell></row><row><cell cols="2"># bricks # leaves</cell><cell>depth</cell><cell>gen. (ms)</cell><cell>comp. (ms)</cell></row><row><cell>8</cell><cell>1</cell><cell>0</cell><cell>0.05</cell><cell>151</cell></row><row><cell>64</cell><cell>12</cell><cell>6</cell><cell>0.62</cell><cell>275</cell></row><row><cell>512</cell><cell>95</cell><cell>14</cell><cell>6.42</cell><cell>3086</cell></row><row><cell>4096</cell><cell>363</cell><cell>17</cell><cell>67.44</cell><cell>5365</cell></row><row><cell>32768</cell><cell>2148</cell><cell>22</cell><cell>1085.25</cell><cell>78306</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 3</head><label>3</label><figDesc>also shows the sourceto-source kd-tree generation and the OpenCL compile times.</figDesc><table><row><cell>Performance in % of direct volume bricking approach</cell><cell>256 0.6 0.8 1 1.2 1.4</cell><cell>128 Opt. approach Stag beetle JIT Schaedel JIT Bonsai JIT Carp JIT Engine JIT</cell><cell>64</cell><cell>32</cell></row><row><cell></cell><cell></cell><cell>Brick Size</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Quadtree for embedded surface visualization: Constraints and efficient data structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Balmelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kovaevi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vetterli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Image Processing (ICIP)</title>
		<meeting>Int. Conf. Image essing (ICIP)</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="487" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Octree textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="785" to="790" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multidimensional binary search trees used for associative searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Bentley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="509" to="517" />
			<date type="published" when="1975-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gigavoxels: Rayguided streaming for efficient and detailed voxel rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Crassin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Neyret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games, I3D &apos;09</title>
		<meeting>the 2009 Symposium on Interactive 3D Graphics and Games, I3D &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quad trees a data structure for retrieval on composite keys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bentley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Kd-tree acceleration structures for a gpu raytracer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sugerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Conference on Graphics Hardware</title>
		<meeting>the ACM SIGGRAPH/EUROGRAPHICS Conference on Graphics Hardware<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multidimensional access methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gaede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Günther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="170" to="231" />
			<date type="published" when="1998-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An effective way to represent quadtrees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gargantini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="905" to="910" />
			<date type="published" when="1982-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A refined data addressing and processing scheme to accelerate volume raycasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanitsar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gröller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="719" to="729" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Interactive volume exploration of petascale microscopy data streams using a visualizationdriven virtual memory approach. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2285" to="2294" />
			<date type="published" when="2012-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reducing branch divergence in gpu programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Abdelrahman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on General Purpose Processing on Graphics Processing Units</title>
		<meeting>the Fourth Workshop on General Purpose Processing on Graphics Processing Units</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Partial evaluation and automatic program generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Gomard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sestoft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Prentice-Hall, Inc</publisher>
			<pubPlace>Upper Saddle River, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Interactive volume rendering of large sparse data sets using adaptive mesh refinement hierarchies. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kähler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Hege</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="351" />
			<date type="published" when="2003-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A survey of octree volume rendering methods. Scientific Computing and Imaging Institute</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Knoll</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of Utah</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lauterbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luebke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fast BVH construction on GPUs. Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="375" to="384" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Perfect spatial hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lefebvre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="579" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Glift: Generic, efficient, random-access gpu data structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lefohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Strzodka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="99" />
			<date type="published" when="2006-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Machine learning: An artificial intelligence approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A computer oriented geodetic data base and a new technique in file sequencing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Morton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Business Machines Company</title>
		<imprint>
			<date type="published" when="1966" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Lightweight modular staging: a pragmatic approach to runtime code generation and compiled DSLs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rompf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Odersky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="121" to="130" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Optimizing data structures in high-level programs: New directions for extensible compilers based on staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rompf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Sujeeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jovanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jonnalagedda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Odersky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGPLAN Notices</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="497" to="510" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Optimizing GPU Volume Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ruijters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter School of Computer Graphics (WSCG) 2006</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Samet</surname></persName>
		</author>
		<title level="m">Spatial data structures</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Designing efficient sorting algorithms for manycore GPUs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Satish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 IEEE International Symposium on Parallel&amp;Distributed Processing, IPDPS &apos;09</title>
		<meeting>the 2009 IEEE International Symposium on Parallel&amp;Distributed Processing, IPDPS &apos;09<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Delite: A compiler architecture for performance-oriented embedded domain-specific languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Sujeeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rompf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Odersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
		<idno>134:1-134:25</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Embedded Computer Systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4s</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficiently rendering large volume data using texture mapping hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint EUROGRAPH-ICS -IEEE TCVG Symposium on Visualization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="121" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Octrees for faster isosurface generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilhelms</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="57" to="62" />
			<date type="published" when="1990-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A quantitative performance analysis model for gpu architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Owens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th IEEE International Symposium on High-Performance Computer Architecture (HPCA 17)</title>
		<meeting>the 17th IEEE International Symposium on High-Performance Computer Architecture (HPCA 17)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="382" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">GPU data structures for graphics and vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Postfach</title>
		<imprint>
			<biblScope unit="volume">151141</biblScope>
			<biblScope unit="page">66041</biblScope>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Universität des Saarlandes</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">GPU point list generation through histogram pyramids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tevs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VMV</title>
		<meeting>VMV</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="137" to="141" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
