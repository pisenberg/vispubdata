<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Occlusion Spectrum for Volume Classification and Visualization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Carlos</forename><forename type="middle">D</forename><surname>Correa</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwan-Liu</forename><surname>Ma</surname></persName>
						</author>
						<title level="a" type="main">The Occlusion Spectrum for Volume Classification and Visualization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-20T19:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Transfer functions</term>
					<term>Ambient Occlusion</term>
					<term>Volume Rendering</term>
					<term>Interactive Classification</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Fig. 1. Left: MRI of a meningionma. Transfer functions (TF) based on boundaries (insets on the left: top, 1D TF with gradient modulation, bottom, 2D TF of intensity vs. gradient magnitude) cannot separate the tumor from the vessels (where gradients are also strong). A transfer function based on occlusion separates the tumor from the vessels and the ventricular structures from skull and skin. Right: CT dataset with contrast agent. Classification is difficult due to overlap between bone and vessel structures (see red color in ribcage in the insets). An occlusion-based TF properly classifies bone and also highlights internal structures (blue).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>One of the issues in classifying and visualizing 3D volumetric data sets is the lack of explicit geometric information and limited semantics. However, the reliance on 3D images to describe complex 3D objects and processes is what permits scientists to quickly visualize the results of MRI scans or flow simulations without time-consuming pre-processing or segmentation. Due to the speed and parallelization of texture processing, most visualization systems rely on classification schemes that extract local information to better represent the materials in a volume data set. In the simplest case, the value at each voxel suffices. In most cases, however, additional information, such as gradient and higher order derivatives, are necessary for classification <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b10">11]</ref>. Nonetheless, the information required to compute these</p><p>â€¢ Carlos D. <ref type="bibr">Correa</ref>  derivatives still can be categorized as local. In this paper, we advocate for the use of more global metrics to characterize the structures in a 3D volumetric object. This global metric should encode enough information to distinguish between features that appear coherently within a certain spatial neighborhood. In this work, we study the issue of using occlusion information to classify volumetric objects. Specifically, we use the ambient occlusion of a voxel as a metric for classification. Ambient occlusion has the advantage of being viewpoint independent and encodes the average contribution of the surrounding neighborhood to the visibility of every voxel in the volume. We noticed that the distribution of occlusion for certain features varies coherently depending on the relationship between these features and their surroundings. For example, in medical images, bones have an occlusion distribution clearly differentiated from skin tissue or contrast-enhanced vessels, which may have the same intensity in the image modality. Therefore, we can characterize some of these components more clearly when considering their ambient occlusion contribution. Traditionally, ambient occlusion has been used for improving the rendering of volumetric models, particularly isosurfaces. In our paper, we use a more general notion of ambient occlusion, which includes the contribution of all voxels around a given point to its visibility. Rather than a rendering quantity, we use the result as an independent variable that can be combined with intensity value to provide more meaningful transfer functions.</p><p>We refer to the distribution of ambient occlusion in a data set as the occlusion spectrum of the data set. When combined with the intensity values, the 2D distribution provides a classification space that separates features that are highly occluded, e.g., those at the interior of objects, from those that are not occluded, such as the outer layers of an object. For example, MR images often exhibit the same intensity values for certain features that are clearly internal, e.g., bones, with others that are at the boundaries, such as skin. An example is shown in <ref type="figure" target="#fig_0">Figure 2</ref>, where we highlight some of the structures that appear when we select different regions in the spectrum, such as ventricular anatomy, skull, brain and skin. Analogously, flow simulations often exhibit regions where the internal and external characteristics of flow differ greatly. The occlusion spectrum of these data sets enables scientists to separate regions of interest depending on their overall spatial characteristics and formulate hypotheses about the spatial nature of the quantity they are visualizing.</p><p>Using our method for classification is advantageous because ambient occlusion: (1) encodes the contribution of the voxels in the neighborhood of a given point with a single scalar value, rather than an n-dimensional vector or histogram; (2) is easy to compute for sampled volumetric data and can be implemented rather effortlessly in current programmable hardware, and (3) exhibits spatial coherence, important for identifying features and their spatial relationships.</p><p>At first, the occlusion spectrum leads easily to 2D transfer functions, where one dimension is intensity value and the other is occlusion. This type of classification proves very useful for a large number of datasets from a variety of domains. We show that the occlusion spectrum helps isolate regions that are spatially concentrated in regions of varying occlusion, and represents a different classification space. Instead of highlighting boundaries, as many current classification methods do, they highlight structure. Nonetheless, 2D transfer function editors may not be easy to understand for non-expert users. For this reason, we also present a simpler editor that preserves the simplicity of 1D transfer function editors with simple manipulations to control the desired effect of occlusion. The issue of occlusion also poses a question of what exactly makes a given intensity value to be more occluding than another. In this paper, we present a method that automatically finds a visibility mapping that results in the occlusion spectrum that maximizes the variance along certain intensity intervals of interest. This ensures that the features along those intensity values are more likely to be separated than others. Through a number of examples, we show that the occlusion spectrum, when used for classification, is a powerful technique aimed at extracting features that share certain spatial characteristics. Currently, this requires either segmentation or cutaway views. We show that we can obtain similar or better results without expensive data pre-processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The classification of volumetric models has been the focus of research since the inception of visualization systems and volume graphics. The ever-ubiquitous 1D transfer function seems still the most common approach, despite the advances made towards higher dimensional transfer functions, such as those based on first (i.e., gradient) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b10">11]</ref> and second derivatives (i.e., curvature) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b11">12]</ref>. Yet these methods are popular in visualization systems because they use mostly local information, which makes them easy to implement and readily fit for parallel computation in modern GPUs. Recently, a number of techniques, which attempt to move towards gathering more global information, have been proposed, leading to a continuous spectrum of techniques. In one end, next to convolution-based approaches (e.g., gradient and curvature) are lighting transfer functions <ref type="bibr" target="#b16">[17]</ref> and shape detection filters <ref type="bibr" target="#b26">[26]</ref>. These methods are still based on derivatives and highlight material boundaries. The latter, however, uses the matrix of second derivatives to better identify the local shape of tissues (i.e., line, thin plate and blob). Several researchers have recognized the limitations of these gradient-based approaches. For example, Pfister et al. <ref type="bibr" target="#b19">[20]</ref>  and Lundstrom et al. <ref type="bibr" target="#b17">[18]</ref> noted that noise usually distorts material boundaries. Rottger et al. also recognized that spatial information is inherently lost in traditional 1D or 2D histograms, and expanded these with spatial information <ref type="bibr" target="#b23">[23]</ref>. As a solution to the blurring of gradientbased 2D histograms, Sereda et al. propose a different way of selecting boundaries, searching for high and low values in paths that follow the gradient near the voxels in a boundary <ref type="bibr" target="#b29">[28]</ref>.</p><p>Lundstrom et al. proposed the use of local histograms to better represent the distribution of intensity values in a given neighborhood <ref type="bibr" target="#b17">[18]</ref>. This departs from convolution-based approaches in that it requires a larger neighborhood. Their results show that the use of local histograms greatly improves tissue separation for the case of overlapping intensity ranges. The search for better tissue separation has motivated a series of more global approaches, which require additional information about the entire data set to aid classification. These approaches rely more on finding structure than highlighting boundaries. Takahashi uses topology to guide the transfer function design <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b30">29]</ref>. In particular, Takahashi et al. use topological relationships between structures to measure the inclusion of isosurfaces <ref type="bibr" target="#b31">[30]</ref>. They propose a similar dimension, called inclusion level, that focuses on structure rather than boundaries. Their method requires finding critical points, which may not be robust to noise, so they must rely on a thresholding mechanism. Zhang and Bajaj follow a similar approach for the visualization of protein pockets, using signed distance transforms to quantify the inclusion of isosurfaces <ref type="bibr" target="#b35">[34]</ref>. Due to the issue with noise, they restrict their application to smooth free-form surfaces. In this paper, our notion of occlusion is more general and not restricted to nested structures. Correa and Ma use size-based transfer functions to classify features based on their size <ref type="bibr" target="#b2">[3]</ref>. Huang and Ma use region growing to guide the definition of 2D transfer functions <ref type="bibr" target="#b8">[9]</ref>.</p><p>One issue with these approaches is the reliance on complex high dimensional spaces for classification. A number of user interface (UI) mechanisms have been proposed, including the contour spectrum <ref type="bibr" target="#b0">[1]</ref>, which reduces classification to handling a series of curves, transfer function widgets <ref type="bibr" target="#b13">[14]</ref> and user painting <ref type="bibr" target="#b33">[32]</ref>. Rezk-Salama et al. use high-level semantics to define and adapt widgets from one data set to another <ref type="bibr" target="#b21">[21]</ref>. In this paper, we explore a novel dimension for classification, namely the ambient occlusion of individual voxels. Ambient occlusion is a single dimension that summarizes the contribution of voxels in a large neighborhood of a given point and is spatially coherent. It is equivalent to finding the centroid of the weighted histogram of intensities around that voxel. Bottom: An example of an occlusion spectrum for a simple 1D profile. Two structures of intensity i are depicted, one surrounded by a low intensity, the other by a medium intensity. The ambient occlusion is essentially an averaging operation. As a result, the intensities for the first structure are "smoothed" down to a low intensity in the range (i0, i1), while the other structure is smoothed down to the range (i2, i). When we plot these intervals in a 2D histogram, we see a clear separation of structures.</p><p>Ambient occlusion was introduced by Zhukov <ref type="bibr" target="#b36">[35]</ref> as the notion of obscurance to model the ambient illumination of an object without costly global illumination operations. Since then, ambient occlusion has become a fast technique for obtaining high quality renderings of illuminated objects and has been successfully been implemented in the GPU <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b1">2]</ref>. Since ambient occlusion requires evaluating the visibility of a point with respect to a number of occluders, some have proposed acceleration techniques such as occlusion fields <ref type="bibr" target="#b14">[15]</ref> and the use of pre-computed information such as local histograms <ref type="bibr" target="#b24">[24]</ref> or mutual probabilities <ref type="bibr" target="#b5">[6]</ref>. For a complete survey on ambient occlusion techniques, refer to Knecht <ref type="bibr" target="#b12">[13]</ref>, and Mendez and Sbert <ref type="bibr" target="#b18">[19]</ref>.</p><p>Recently, there has been a growing interest in improving volume rendering with ambient occlusion and other approximation of global illumination. Ritschel uses the GPU to compute the visibility of volume data sets and provide natural illumination effects such as soft shadows and attenuation <ref type="bibr" target="#b22">[22]</ref>. Wyman et al. <ref type="bibr" target="#b34">[33]</ref> use precomputed illumination volumes to incorporate global illumination of isosurfaces. Ropinski et al. <ref type="bibr" target="#b24">[24]</ref> present a system for dynamic ambient occlusion that adapts to changes in visibility such as transfer function manipulation. The use of ambient occlusion was exploited by Tarini et al. to enhance the visualization of large molecules. They show that ambient occlusion results in an enhanced perception of he 3D shape of large proteins <ref type="bibr" target="#b32">[31]</ref>. Ruiz et al. also use obscurances to generate high quality renderings of volumetric objects at a low cost. Coupled with color bleeding, their framework results in realistic volume rendered images effective for visualization <ref type="bibr" target="#b25">[25]</ref>. For more details on ambient occlusion for volume rendering, see the tutorial notes by Hadwiger et al. <ref type="bibr" target="#b6">[7]</ref>. In our work, although the process of constructing the occlusion spectrum is borrowed from ambient occlusion computation, our focus is quite different. Rather than using occlusion exclusively for rendering, we use occlusion for classification. This implies a fundamental difference with our predecessors, in that we do not rely on pre-classification of tissue to determine visibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE OCCLUSION SPECTRUM</head><p>The occlusion spectrum refers to the distribution of ambient occlusion of a given intensity value in a 3D volumetric object. We can represent this as a 2D histogram, where one axis is the intensity value and the other axis is the occlusion. Unlike 2D histograms based on</p><formula xml:id="formula_0">Linear Ramp M(x) = S(x) Truncated Linear Ramp M(x) = S(x) Ï„ 0 &lt; S(x) &lt; Ï„ 1 0 otherwise Distance weighted M(x) = S(x)e âˆ’||xâˆ’xc|| 2</formula><p>Opacity weighted M(x) = Î±(x) gradient magnitude, this spectrum does not highlight boundaries, but structures. A concentration in the 2D spectrum towards the higher occlusion values indicates structures that are more "internal" since they are more likely to be occluded, whereas concentrations in the lower occlusion values indicate more "external" structures. An example of the occlusion spectrum of an MRI data set in shown in <ref type="figure" target="#fig_0">Figure 2</ref>. Here, we see an intensity value interval where there are structures such as skin, skull and lateral ventricles. Once they are plotted in terms of their occlusion, they can be separated clearly. Similarly, brain intensities can be separated from occluding skin tissue. As a result, we can obtain a visualization that isolates the brain without the need for segmentation.</p><p>To compute the occlusion spectrum, we turn to the ambient occlusion of a point, which represents the obscurance of the point due to the neighboring voxels in a volume. Unlike traditional ambient occlusion, which only computes this quantity for visible points, we define an adaptive visibility mapping that considers every voxel in a neighborhood around the voxel. We show that this quantity is equivalent to computing the centroid of the weighted histogram of intensities around the voxel. We then construct the spectrum as the 2D histogram of intensity vs. occlusion. One of the key properties of this histogram is the ability to separate structures of interest. Depending on the visibility mapping function, this separation may be impaired. For this reason, we present a general methodology that finds the best parameters for the visibility function that maximizes the likelihood of separation. These steps are detailed in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ambient Occlusion</head><p>To quantify and measure the occlusion of a voxel, we turn to ambient occlusion, used widely to approximate the ambient attenuation of a point given the surrounding scene. This can be expressed as:</p><formula xml:id="formula_1">AO(x) = 1 Ï€ â„¦ (1 âˆ’V (x, Ï‰))(Ï‰ â€¢ n)dÏ‰ (1)</formula><p>where x is the location of a point or voxel, n represents the normal of the surface through this point and V (x, Ï‰) is the visibility of x along a direction Ï‰. The directions Ï‰ are taken to cover the hemisphere â„¦ defined by the normal of the point. When AO(x) = 0, the point is unoccluded.</p><p>In this paper, we use a more general notion of occlusion, which also takes into account the intensities in the other hemisphere. Therefore, we define occlusion as the weighted average of the visibility of a point along directions in a sphere ( <ref type="figure" target="#fig_1">Fig. 3a)</ref>:</p><formula xml:id="formula_2">O(x) â‰ˆ 1 N Ï€ âˆ‘ Ï† =0 2Ï€ âˆ‘ Î¸ =0 A(x, Ï‰(Î¸ , Ï† ))<label>(2)</label></formula><p>where N is the number of neighbors and A(x, Ï‰) is the directional occlusion of a point along direction Ï‰, defined as:</p><formula xml:id="formula_3">A(x, Ï‰) = T âˆ‘ t=0 M(x + tÏ‰)<label>(3)</label></formula><p>where T is the number of samples along direction Ï‰ and M(x) is a visibility mapping function of a sample x. In the case of traditional ambient occlusion on isosurfaces, the mapping function is a binary function that is 0 when the intensity is the isovalue of interest and the point is in the hemisphere defined by the gradient of the central voxel.</p><p>Here, we define more general visibility mappings, which should retain as much information as possible about the distribution of intensities in the neighborhood of a voxel. <ref type="table" target="#tab_1">Table 1</ref> summarizes some of the mappings we have explored, including data-centric approaches such as linear ramps and Gaussian weighted neighborhoods, and renderingcentric approaches such as user-defined opacity mappings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Rationale</head><p>This concept of occlusion can be considered as a weighted average of the neighborhood surrounding a voxel. The rationale behind this classification space is that occlusion can be considered as the convolution of the volume with a low pass filter. As long as the filter has a size larger than the structures we want to classify, the average is affected by the distribution of voxels surrounding this structure. <ref type="figure" target="#fig_1">Consider Figure 3</ref>, where we plot a 1D intensity profile, composed of two structures of intensity i, one of which is surrounded by a low intensity and the other surrounded by a medium intensity. When we convolve the profile with a low-pass filter, i.e., we compute the average response, the intensity of the first structure decreases to interval (i 0 , i 1 ) and the second structure decreases to interval (i 2 , i), where i 1 &lt; i 2 . When we plot these in a 2D histogram, the two regions with the same intensity can be separated. It can be seen that the occlusion is the centroid of the weighted histogram of the neighborhood of a voxel. Let f i denote the frequency of occurrence of M(x) = i. Therefore, âˆ‘ i f i = N, where N is the number of voxels in the spherical neighborhood N R (x) of voxel x and radius R.</p><formula xml:id="formula_4">O(x 0 ) = 1 N âˆ‘ xâˆˆN R (x 0 ) M(x) = âˆ‘ i i f i âˆ‘ i f i<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Occlusion Properties</head><p>The occlusion spectrum has a series of properties essential for robust classification.</p><p>Coherence. The occlusion spectrum is coherent. That is, for a pair of neighboring points in the volume, it is expected that occlusion varies smoothly. This is achieved by its definition, since occlusion is essentially a convolution. Let G be a convolution filter describing the </p><formula xml:id="formula_5">âˆ‚ O(x) âˆ‚ x = âˆ‚ G â€¢ S(x) âˆ‚ x = G â€¢ âˆ‚ S(x) âˆ‚ x<label>(5)</label></formula><p>Thus, the occlusion retains the coherence properties of the volume, as long as the convolution filter (G), determined by the mapping function M, is continuous. Noise and bias. Occlusion is also inherently robust to additive noise and multiplicative bias, because of the averaging performed by the convolution. Let use consider a transformed scalar field S â€² (x) = Î² (x)S(x) + E, where Î² is a multiplicative bias and E âˆ¼ N(0, Ïƒ 2 ) is an additive noise of mean 0 and variance Ïƒ 2 . Therefore, the occlusion on the transformed scalar field is</p><formula xml:id="formula_6">G â€¢ S â€² (x) â‰¤ Î² max G â€¢ S(x)<label>(6)</label></formula><p>for a maximum bias Î² max in the neighborhood of a point, which means that the occlusion distribution is not transformed by the additive noise but is scaled due to bias. As long as the variance of the bias does not exceed the size of the largest structure we can separate, this scaling does not affect the separability in the occlusion space. An example is shown in <ref type="figure" target="#fig_2">Figure 4</ref>. Shape and Size. Occlusion is also robust to changes in shape and size, as shown in <ref type="figure" target="#fig_2">Figure 4</ref>, as long as the neighborhood is larger than the size of structures we wish to detect. That is, for larger structures, they voxels become self-occluded and the neighborhood intensities have little effect in the occlusion value.</p><p>To understand the effect of size, we ran a sensitivity plot of the occlusion computation for different neighborhood sizes. <ref type="figure" target="#fig_4">Figure 6</ref> shows four sensitivity plots for datasets of two modalities. The horizontal axes represent the intensity value and radius of the occlusion sphere, and the vertical shows the (normalized) variance of the occlusion spectrum. The larger the area under a curve is, the larger the overall variance of the occlusion spectrum becomes, and therefore, so the likelihood of separating features. As expected, small neighborhoods do not provide enough variance. Large neighborhoods, on the other hand, also drop variance when they are much larger than the structures we want to detect. Therefore, we consistently see a shape in these plots that indicates the best radius towards the middle of the pltted interval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Adaptive Mapping Selection</head><p>One of the key advantages of the occlusion spectrum is its ability to separate structures with the same intensity based on the data distribution in its neighborhood. Because the occlusion depends on a visibility mapping function, the effectiveness of the spectrum depends on the parameters of this mapping function. For example, when we consider a truncated ramp function, the cutoff values Ï„ 0 and Ï„ 1 affect the average intensity of the local neighborhood. Furthermore, a given mapping can maximize the separability of certain structures in one intensity, but hinders it for another intensity. Let us consider a phantom data set consisting of two spheres surrounded by a hollowed structure. One of the spheres is a high intensity surrounded by a medium intensity, and the other is of medium intensity surrounded by low intensity, as shown in <ref type="figure" target="#fig_3">Figure 5</ref>. A mapping function is found that separates the sphere from the outer layer for the high intensity, but fails to separate the one for the medium intensity. Another mapping function works for the medium intensity but fails for the high one. Therefore, it becomes necessary to select a mapping adaptively, depending on the intensities of interest the user wishes to classify. In general, this can be accomplished by finding the best parameters that maximize the variance of means of the occlusion spectrum for the intensity interval of interest. This, however, requires to compute the occlusion for each combination of parameters, which is computationally expensive. Instead, we present a faster mechanism based on local histograms, depicted in <ref type="bibr">Figure 5(Top)</ref>. For each intensity interval of interest we compute the local histogram for each voxel. The occlusion can be found as the centroid of each of these histograms. Next, we compute the distribution of occlusion for the intensity intervals and cluster them. Finally, we find the variance of the means. We repeat this process for each parameter in the mapping function. The mapping is the one that maximizes the variance of means of the occlusion distribution. A result of such an adaptive mapping is seen in <ref type="figure" target="#fig_3">Figure 5</ref>, where we can clearly see the structures of interest clearly separated in the occlusion spectrum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OCCLUSION TRANSFER FUNCTION (OTF)</head><p>The most immediate application of the occlusion spectrum is the classification based on occlusion. An occlusion transfer function is therefore a mapping from the space spanned by the scalar values S and the occlusion O into color and opacity, S Ã— O â†’ [0, 1] <ref type="bibr" target="#b3">4</ref> . By tagging different regions of the resulting 2D histogram and assigning color and opacity, users can select regions with similar intensity values but in rather different locations within the data set.</p><p>An OTF differs from other gradient-based transfer functions in that material boundaries are not the main criteria for deciding what to classify. Although regions of certain homogeneity might exhibit different occlusion signatures than those on the boundary of materials, the main factor remains the degree of occlusion, independent (for most part) of whether they have large or small gradients. An example is shown in <ref type="figure" target="#fig_5">Figure 7</ref>, which depicts a meningioma or brain tumor. On the left, we show the result of classifying based on intensity and gradient magnitude using a 2D transfer function. A gradient-based transfer function does not help identification much, since the overlapping intensities also exhibit large gradients. With an OTF (right), we can isolate the tumor from the arteries and veins, and the occluding tissue due to noise and overlapping intensities. This works robustly for tumors and similar structures because these are features that are consistently surrounded by a certain intensity range (e.g., brain tissue), that is different from other structures of similar intensity (e.g., air in the case of the occluding tissue on the skull). Although tumors may appear in different locations (thereby changing the occlusion values), they are still separable from low occluded structures such as skin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Occlusion Transfer Function Editor</head><p>One of the issues of high-dimensional transfer functions is the reliance on complex widgets and spaces to specify the color and opacity mappings. Even for 2D transfer functions, the detection of material boundaries as arcs in the resulting histogram may not be straightforward as affected by noise and bias. It is no surprise that most medical systems still rely on simple 1D editors to highlight features of interest, despite the obvious and well-studied limitations of such approach. The 2D occlusion transfer function is no exception. Effective classification requires the user to control widgets in 2D space, while keeping track of an elusive third dimension that tacitly represents opacity. Representing these in a 3D space would only complicate the matter. However, we have found that the idea of occlusion fits well the idea of a separable 2D space. This is mainly due to the intrinsic orthogonality of these two dimensions. Any intensity value can potentially exhibit any degree of occlusion, so that the y-dimension can be grasped intuitively as the interiority of a material.</p><p>Nonetheless, we believe that our approach can better serve the general users of visualizations with a simpler interface. To achieve this, we make the following observations: (1) The 1D classification is ubiquitous and easy to understand. (2) Assigning different colors to the same intensity value at different occlusion levels may be misleading whenever color is used to indicate the magnitude of a given quantity.</p><p>In our interface, we decouple the 2D classification space into two 1D spaces. This is motivated by the notion of improving the likelihood of a point being part of a given structure one dimension at a time. The opacity function of a sample point is the defined as:</p><formula xml:id="formula_7">Î±(x) = Î± S (S(x))Î± O (S(x), O(x))<label>(7)</label></formula><p>where Î± S is an opacity mapping based on intensity, and Î± O is an opacity mapping based on occlusion. In our case, we define Î± S (s) =</p><formula xml:id="formula_8">âˆ‘ i G Âµ i ,Ïƒ i (s)</formula><p>as a sum of Gaussians. The first space <ref type="figure" target="#fig_6">(Figure 8</ref>) retains the characteristics of a typical 1D classification based on intensity values, including color selection. The X dimension denotes the intensity values, while the Y dimension denotes opacity. In the second space (bottom), we retain the X dimension as the intensity values and add the occlusion spectrum as a plot. The Y dimension corresponds to occlusion. To change the opacity based on occlusion, we use occlusion curves, which span the entire domain, but can be adjusted in the Ydimension (occlusion). These curves represent the means of Gaussian bells and the size of the area around the curve represents the standard deviation of the Gaussian. Therefore, the opacity mapping is defined as:</p><formula xml:id="formula_9">Î± O (s, o) = G Âµ s ,Ïƒ s (o)</formula><p>for an intensity value s and an occlusion o.</p><p>Interacting with these curves simplifies much of the complexity added by dimensional transfer functions, although it is limited to a single extra variable, in this case opacity. <ref type="figure" target="#fig_6">Figure 8</ref> depicts the classification process. On top, the intensity intervals in red and orange are associated with high occlusion, isolating the meningioma. Next, the user highlights a different intensity interval corresponding to brain, but also to occluding tissue such as skin. Therefore, at the bottom, the user moves the curve towards the upper end, selecting the structures with high occlusion for that intensity interval, namely the brain tissue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation</head><p>The occlusion spectrum is the 2D histogram resulting from two volumes, the original intensity volume, and the ambient occlusion volume. In our implementation, since ambient occlusion is used for classification, we pre-compute it as a separate volume. This makes the rendering stage of our technique computationally comparable to that of 2D transfer functions based on gradient magnitude. The occlusion volume, since it is essentially an average, can be of lower resolution than the original data. To compute the ambient occlusion volume we use the programmability of current GPUs and the render-to-3D-texture capabilities. We render a number of quadrilaterals corresponding to the different slices of the ambient occlusion volume. Each of these quadrilaterals is processed in parallel in a fragment shader that computes the occlusion at every voxel by explicitly encoding Eq. 2. After all slices are processed, the result is a 3D volume containing the occlusion at every voxel. Finally, classification is incorporated into a GPU-based ray casting shader that uses a 2D texture look-up to obtain the color and opacity of each sample point according to their intensity and occlusion values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CASE STUDIES 5.1 Cancer Diagnosis on Breast CT</head><p>According to the National Cancer Institute in the U.S <ref type="bibr" target="#b9">[10]</ref>, breast cancer incidence in women in the United States is 1 to 8, or about 13%. The need to diagnose early a breast cancer tumor is becoming increasingly pressing as the imaging modalities improve and their costs are reduced. The goal of screening exams is to find cancers before they start to cause symptoms. Since cancers at this stage are usually small, the ability to extract the right information from the different imaging modalities becomes crucial. Current imaging methods include ultrasound, digital mammography, MRI, positron emission tomography (PET) and CT scans <ref type="bibr" target="#b9">[10]</ref>. We used the occlusion spectrum to classify tumors at varying stages from a set of patients obtained using breast CT scans. <ref type="figure" target="#fig_7">Figure 9</ref> shows a series of images from three different patients with different characteristics. In our experiments, we found that the occlusion spectra of these data sets are very similar, even with dramatic changes in the visibility. For example, <ref type="figure" target="#fig_7">Figure 9</ref>(middle) shows a patient with a breast implant. Due to the quantitative nature of CT, the implant shares the same intensity values of the tumor and glandular tissue. In <ref type="figure" target="#fig_7">Figure 9</ref> we see zoomed-in views of regions of interest, presumably containing cancerous tissue, for traditional (using intensity and gradient modulation) and occlusion-based classification, on the left and right insets, respectively. In general, intensity and gradientbased classification of the 3D volume can only focus on the glandular tissue and requires low opacity to gain sufficient visibility. The result is a rather homogeneous collection of fuzzy blobs, often obscured by other non glandular tissue. If the radiologist requires to add other tissue for context, the tumor would not be seen unless a cutting plane is introduced. With occlusion-based classification, on the other hand, the results are more clearly segmented from the surrounding tissue and can even show some of the vascular structures that feed the growing tumor. In our preliminary evaluation of our technique, an expert in breast cancer imaging found the results of our classification most useful since we show, for the first time, a clear view of the tumor and the surrounding blood vessels. In traditional imaging, the radiologist goes back and forth between a set of 2D images, and, depending on the size and orientation of certain features, determines whether a particular blob is a vessel or a tumor.</p><p>We have also discussed our results with a surgeon specialized in cancer treatment. As suggested by the expert, one important implication of occlusion-based classification is the extraction of layers, essential for the planning of surgical procedures, especially for the treatment of cancer. Although radiologists are still used to 2D medical visualization metaphors, the use of 3D imaging often lets them see new structures that may imply updates in a planned surgical procedure. The ability to depict the different layers surrounding a tumor lets surgeons determine the best course of action and whether a particular surgical procedure is warranted. For example, certain tumors can be treated with thermal ablation as an alternative to open surgery, reducing the health risks of the patient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Simulation of 3D Phenomena</head><p>Another interesting domain is the visualization of simulation data sets. Although the occlusion spectrum for anatomical data sets seems to correlate to specific organs and tissues, there is no evident analogy in simulation data sets. However, the occlusion spectrum tells us about the relative spatial distribution of quantities of interest. The occlusion transfer function therefore enables the scientist to formulate questions such as what is the distribution of a given range of values, e.g., velocity or vorticity, in the interior of the volume as compared to its exterior. For example, in combustion simulations, regions of weakly burning flames are often obscured by strongly burning regions. These obscured regions, however, are of most interest to scientists interested in understanding processes such as reignition.</p><p>A similar problem occurs in hydrodynamic simulations such as the simulation of core collapse supernovae. The scientists are interested in visualizing the interplay of different quantities such as pressure, density and energy that result in shock waves and the ensuing explosion. The direct visualization of entropy has been a common way of understanding the formation and behavior of these shockwaves. However, these shockwaves are often formed in both the internal regions near the core and the outermost regions. Therefore, visualizing these quantities near the core becomes difficult. An example is shown in <ref type="figure">Figure 10</ref>, where the visualization of entropy at the interior is obscured by the outer shells of entropy. As an alternative, most visualization systems let the user define a cutaway, which provides visibility of the core and the surrounding entropy <ref type="figure">(Figure 10</ref>(middle)) However, this results in the formation of structures due to the cut that are not in the original data set and may be misleading. Here we can classify in terms of occlusion. In this transfer function, we maintain the same color mapping and intensity opacity, but modulate opacity with respect to occlusion, so that innermost regions are assigned a higher opacity. The result is shown in <ref type="figure">Figure 10(right)</ref>. Note that the same internal structures are shown, but without the misleading issues introduced by a cutaway. An important consideration when applying occlusion to simulation datasets is their temporal nature. From time step to time step, the occlusion spectrum varies. Therefore, an occlusion transfer function that highlights certain region may not be as effective for the next transfer function. This, however, is not exclusive of the occlusion spectrum but also to general 1D and 2D histograms, and general solutions to both must be sought after.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We have presented a novel technique for classifying volumetric objects based on occlusion. The issue of occlusion has been the focus of numerous efforts, mostly in an attempt to minimize it and provide visibility of otherwise obscured structures. In this paper, we have shown that we can understand occlusion in a rather different way, which is a scalar field that encodes, in a single dimension, the spatial structure of complex datasets. We presented the occlusion spectrum of a volumetric dataset, which encodes the 2D distribution of intensity values and occlusion. This space separates structures based on the distribution of intensities in their neighborhood. Therefore, the occlusion dimension directly maps, in most cases, to the internality of a structure. Features that appear isolated or at the exterior of larger structures can be clearly separated from those at the interior.</p><p>In our validation with medical imaging experts we found that occlusion (1) is an easily grasped concept that relates directly to the way they interact with anatomical data and that helps decide certain procedures such as surgical planning, and (2) leads to better quantification of cancer tumors due to the ability to isolate them without the need for segmentation. One of the issues of 2D transfer functions is the higher dimensionality of the classification space, which implies a number of user interface challenges. In our experiments, we found that the occlusion spectra of data sets of certain type maintain some similarity. Therefore, it is possible to generate classification templates that can be re-targeted across data sets without much user intervention. Since ambient occlusion is spatially coherent and easy to implement in contemporary graphics hardware, we believe it can be deployed in most visualization systems without much effort. Combined with other capabilities, such as cutaway planes and advanced lighting, occlusionbased volume rendering can be used to obtain images with unprecedented clarity and quality. <ref type="figure">Fig. 10</ref>. Occlusion-based classification of a supernova simulation. Left: traditional classification via a 1D transfer function based on intensity value (entropy) enhanced with gradient magnitude modulation. Middle: To visualize internal dynamics, scientists often use cutaways, which introduce additional structure due to the cut. Right: an occlusion TF lets scientists see internal dynamics without losing information due to cuts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>The Occlusion Spectrum for an MRI data set. Anatomical structures (e.g., skull, brain, ventricles) appear depending on how internal they are.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Top: Ambient occlusion is obtained as the average of occlusion contribution from samples around a voxel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Properties of the occlusion spectrum. (a) Phantom data set. Note the separation of structures even though they share the same intensity.(b) Structures of different shape and size. (c) Gaussian noise of Ïƒ = 1.0. (d) Multiplicative bias.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Top: Adaptive Mapping Selection is computed in a series of steps: (1) Obtain local histograms (2) compute the occlusion spectrum for a set of mapping parameters and clustering (3) obtain variance of means (4) repeat for next set of parameters. The mapping is the one with maximum variance of means. Middle: A data set consisting of two sets of nested structures, the first of high intensity surrounded by medium intensity (left), the other medium surrounded by low intensity (right). Mapping selection that maximizes variance for the high intensity (left) fails to separate the other. Conversely, a mapping that maximizes for the medium intensity (right) fails to separate the high intensities. Bottom: An adaptive mapping separates the structures for both high and medium intensities, as seen in the occlusion spectrum.occlusion operation. The occlusion can be described as the convolution: O(x) = G â€¢ S(x). The spatial derivative of the occlusion is then:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Sensitivity plots of the occlusion spectrum for two MRI and two CT datasets with respect to radius of occlusion sphere. The horizontal axes show intensity values vs. radius of the occlusion sphere. The vertical axis shows the variance of occlusion. Notice the consistent peaks around radii of 50 âˆ’ 100 voxels, for a volume of diameter 256.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Occlusion-based Classification of a meningioma. Left: A 2D transfer function based on boundaries highlights the tumor and vessels from noise and other structures, but these intensities overlap and have similar gradient magnitude. The result is a commingled visualization of tumor and vessels. Right: An occlusion-based transfer function gives higher visibility to the tumor, and it is clearly separated from the vessels. Note also that it removes some of the noise in the forehead.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Example of 1D editors for occlusion. Top: the user highlights the skin intensities (on the left, low opacity), vessels (red) and the meningioma (orange). The occlusion curve appears towards the top, highlighting only internal structures (the tumor). Middle: the user increases the opacity of brain intensities. Fatty tissue and other structures share the same intensity and occlude the brain. Bottom: The user moves the occlusion curve towards the top, so that only the internal structure (the brain) is shown while the outer layers are left transparent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 9 .</head><label>9</label><figDesc>Occlusion-based classification of CT scans for breast cancer detection. For each data set, we show at the bottom the result of classification based on intensity and gradient magnitude modulation vs. occlusion-based classification, for regions containing tumors. Boundary-based transfer functions get visibility of the tumor at the expense of reducing the opacity and clarity of the image. With an occlusion transfer function, we can render a more defined surface of the tumor, as well as the nearby vessels and skin for context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Visibility mappings for the computation of occlusion, where S(x) is the intensity of a point x.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors wish to thank the sources of our data sets: Prof. John M. Boone from the Biomedical Engineering department at UC Davis, the Terascale Supernova Initiative, the OsiriX Foundation and Jeff Orchard. This research was supported by the U.S. National Science Foundation through grants CCF-0911422, OCI-0325934, OCI-0749227, and OCI-0850566, and the U.S. Department of Energy through the SciDAC program with Agreement No. DE-FC02-06ER25777.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The contour spectrum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Schikore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization &apos;97</title>
		<meeting>IEEE Visualization &apos;97<address><addrLine>Los Alamitos, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="167" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">GPU Gems 2, chapter Dynamic Ambient Occlusion and Indirect Lighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bunnell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Addison Wesley</publisher>
			<biblScope unit="page" from="223" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Size-based transfer functions: A new volume exploration technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Correa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1380" to="1387" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automating transfer function design for comprehensible volume rendering based on 3d field topology analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Azuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Visualization</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="467" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dynamic anisotropic occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographcs 2006 Short Presentations</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An information-theoretic ambient occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>GonzÃ¡lez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Aesthetics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Advanced illumination techniques for GPU volume raycasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadwiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Asia &apos;08: ACM SIGGRAPH ASIA 2008 courses</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Curvature-based transfer functions for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>HladÅ¯vka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>KÃ¶nig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>GrÃ¶ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spring Conference on Computer Graphics</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rgvis: Region growing based techniques for volume visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Pacific Conference on Computer Graphics and Applications</title>
		<meeting>Pacific Conference on Computer Graphics and Applications</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">N. C. Institute. www.cancer.gov</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-automatic generation of transfer functions for direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Durkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VVS &apos;98: Proceedings of the 1998 IEEE symposium on Volume visualization</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Curvature-based transfer functions for direct volume rendering: Methods and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">State of the art report on ambient occlusion. techreport, Institute of Computer Graphics and Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Knecht</surname></persName>
		</author>
		<idno>A-1040</idno>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page" from="9" to="11" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Vienna University of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kniss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="255" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ambient occlusion fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kontkanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Symposium on Interactive 3D graphics and games</title>
		<meeting>Symposium on Interactive 3D graphics and games</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Display of surfaces from volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lighting transfer functions using gradient aligned sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization &apos;04</title>
		<meeting>IEEE Visualization &apos;04</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Local histograms for design of transfer functions in direct volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lundstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ljung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ynnerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1570" to="1579" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From obscurances to ambient occlusion: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>MÃ©ndez-Feliu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Computer</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="196" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kindlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schroeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The transfer function bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Machiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Graph. Appl</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="16" to="22" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">High-level user interfaces for transfer function design with semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rezk-Salama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohlmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1021" to="1028" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast GPU-based Visibility Computation for Natural Illumination of Volume Data Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Short Paper Proc. of Eurographics</title>
		<editor>P. Cignoni and J. Sochor</editor>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Spatialized transfer functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roettger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EuroVis</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Interactive volume rendering with dynamic ambient occlusion and color bleeding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ropinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meyer-Spradow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Diepenbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mensmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hinrichs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="567" to="576" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Obscurance-based volume rendering framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Boada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feixas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Volume Graphics</title>
		<meeting>of Volume Graphics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Tissue classification based on 3d local intensity structure for volume rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-F</forename><surname>Westin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhalerao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shiraga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="160" to="180" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hardware-accelerated ambient occlusion computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sarlette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vision, Modeling, and Visualization</title>
		<editor>B. Girod, M. Magnor, and H.-P. Seidel</editor>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="331" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Akademische Verlagsgesellschaft Aka GmbH</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualization of boundaries in volumetric data sets using LH histograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sereda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W O</forename><surname>Serlie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Gerritsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="208" to="218" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Topological volume skeletonization and its application to transfer function design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graph. Models</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="49" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Scientific Visualization: The Visual Extraction of Knowledge from Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takeshima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fujishiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Nielson</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">255</biblScope>
			<biblScope unit="page" from="185" to="206" />
		</imprint>
	</monogr>
	<note>Emphasizing isosurface embeddings in direct volume rendering</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Ambient occlusion and edge cueing for enhancing real time molecular visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cignoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Montani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1237" to="1244" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A novel interface for higherdimensional classification of volume data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-Y</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Lum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Visualization</title>
		<meeting>IEEE Visualization</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="505" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Interactive display of isosurfaces with global illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shirley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="186" to="196" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Extraction, quantification and visualization of protein pockets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bajaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Systems Bioinformatics Conference</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="275" to="286" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An ambient light illumination model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhukov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Inoes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kronin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rendering Techniques &apos;98</title>
		<editor>G. Drettakis and N. Max</editor>
		<meeting><address><addrLine>Wien New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="45" to="56" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
