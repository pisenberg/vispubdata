<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/pisenberg/grobid/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Visual Causality Analyst: An Interactive Interface for Causal Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Klaus</forename><surname>Mueller</surname></persName>
						</author>
						<title level="a" type="main">The Visual Causality Analyst: An Interactive Interface for Causal Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TVCG.2015.2467931</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2021-02-19T20:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visual knowledge discovery</term>
					<term>Causality</term>
					<term>Hypothesis testing</term>
					<term>Visual evidence</term>
					<term>High-dimensional data</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inf erred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analysta novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables wit hin one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recovering the causal relations from purely observational data is one of the ultimate goals for data analysts and a fundamental problem in science. After decades of efforts by many, causality research gained particularly strong attention when Judea Pearl, a long time pioneer of the field, won the Turing award in 2011 for the underlying mathematical framework of causal inference. The advantage of knowing the causal relations rather than just statistical associations, e. g., correlations, is that the former enables explicit guidance in predicting the effects of actions perturbing the observed system.</p><p>The most reliable way to determine causation is by controlled experiments. However, controlled experiments are often either impossible or associated with high cost and thus impractical in real world. A loose detour usually taken is trying to express causation by correlations calculated from observational data. One typical example of this is the website Google Correlate <ref type="bibr" target="#b0">[1]</ref> which can provide visitors with endless hours of entertainment by entering any search term and then browsing a long list of spurious correlations the term has with either time or US states. But while users of Google can easily tolerate the many irrelevant links the search engine typically generates, for other applications, such as healthcare diagnosis and financial prediction, blindly inferring causation from spurious correlations can have severe consequences.</p><p>To infer a precise model describing and measuring causal relations embedded in observational data, the theory of causal inference and analysis, started with the work of Pearl <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, Spirts <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, and others, has become a hot topic in recent years. While many  Jun <ref type="bibr">Wang</ref>    modern causal discovery algorithms claim that they can generate causal models with enough accuracy, they usually hold very strong assumptions on data distributions (e.g. Multinomial, or continuous with Gaussian sample error) that are hard to keep in practice, and make algorithms unstable when error relations are generated in early stages. Thus none can guarantee an answer that is accurate in the sense of being completely consistent with the real world. Even with the emergence of big data the automated derivation of a consistent causal model remains challenging because it requires a fundamental theory of how and why the observed phenomena occur. This in turn requires creativity with the human expert in the inference process. This is feasible when the model is sufficiently small, that is, the number of variables in the model is manageable. However, big data not only increases the number of observations, it also typically gives access to a greatly increased number of variables. These can help users build a consistent theory of the real world phenomena but the process is difficult to manage without visual support.</p><p>The system we describe in this paper, the Visual Causality Analyst, is a first step into creating such a visual support system. It offers various interactive and automatic tools for visual causal discovery. Following previous work on correlation maps <ref type="bibr" target="#b5">[6]</ref> and Pearl's depicting of the causality structure as a directed acyclic graph (DAG) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7]</ref> our framework visualizes the causal relations as an interactive spatial 2D layout, in which each edge connecting two variables implies a causal relation and the direction of an edge identifies the effect from the cause. Our interface also offers real time visual interactions where users are allowed to arbitrarily change the relations between variables and the impact of each modification is visualized simultaneously on the graph. Mathematical measurements of causal relations in the form of either linear regression analysis (targeting numeric variables) or logistic regression analysis (targeting categorical variables) are calculated and fed back along with the interactive operations, enabling users to explore potential causalities with statistical proof. Subsequently, these measurements are then also visualized in the spatial layout in terms of edge colors and opacities.</p><p>The main utility for computational causal inference lies in the conditional independence (CI) test, which is usually conducted via G-test or partial correlation. The former applies to discrete (categorical) data, while the latter applies to continuous (numerical) variables. None can handle both. We choose the partial correlation approach since our motivating domain application has mostly numerical variables and discretizing numerical variables into bins causes loss of detail <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> which is undesirable. To go the other way, we are inspired by recent work of Zhang et al. <ref type="bibr" target="#b5">[6]</ref> which for each pair of categorical and numerical variables reorders and repositions the levels of the categorical variable such that Pearson's correlation between the pair is optimized. To accommodate the computational causal inference process we extend Zhang's level reordering and repositioning mechanism from a single numerical variable to sets of numerical variables. This global optimization mechanism enables the causal inference algorithms to return plausible results on datasets containing both continuous and discrete data.</p><p>Our paper is structured as follows. Section 2 discusses related work. Section 3 introduces theoretical background and contributions. Section 4 introduces our novel Visual Causality Analyst interface. Case studies on multiple datasets are given in Section 5, and Section 6 ends with conclusions and an outlook on future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>As mentioned, causality has been an active research topic and research on the visualization of causal networks has also emerged. In the following we shall briefly review this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1</head><p>Causality Visualization A number of methods have been developed for the visualization of causality. The Hasse diagram is one of the earliest systems that have the ability to represent causal relations. It was originally introduced in order theory and has been adopted for demonstrating distributed systems <ref type="bibr" target="#b9">[10]</ref>, parallel processes <ref type="bibr" target="#b10">[11]</ref>, and many other information structures that contain causal events. However, since Hasse diagrams typically produce layouts with a large amount of intersecting edges and lack the ability to represent causal semantics, it can be difficult to comprehend them, especially when the number of variables is large and causal relationships are complex.</p><p>Growing-squares <ref type="bibr" target="#b11">[12]</ref> and its enhancement growing-polygons <ref type="bibr" target="#b12">[13]</ref> are both animated techniques that focus on visualizing sets of connected causal events called processes. The latter uses n-sided polygons to represent n processes and the gradual change of processes is visualized by animating the polygon's change of size. However, the growing-polygons can only illustrate causality at the process level with very limited abilities of signifying causal relation strengths. Kadaba et al. <ref type="bibr" target="#b13">[14]</ref> address these problems by depicting causal relations by node-link arrows and glyphs, leveraging simple animation of node sizes to indicate interactions between the factors and the target. While such a graph design can be effective for causality visualization, it only feeds back brief semantics of a causal relation, e.g. positive or negative. However, when explicit causal measurements need to be demonstrated on the graph, no existing causal visualization approach can give a plausible result. Wongsuphasawat and Gotz <ref type="bibr" target="#b14">[15]</ref> describe a system that visualizes alternative pathway chains of temporal event sequences. While these chains suggest causal effects they are not casual networks. Also, their system focuses mainly on event flow visualization and has no support for interactive statistical causal reasoning.</p><p>According to Pearl's DAG patterns of causal structures <ref type="bibr" target="#b1">[2]</ref>, a 2D spatial graph layout of the network is a natural fit. Spatial graph layouts have been widely used in information visualization in various contexts. A related example is the visualization of Bayesian belief networks <ref type="bibr" target="#b15">[16]</ref>, in which the layout is guided by a temporal order, and multiple visual variables like color, node size, and proximity are used to represent network semantics. More recently, Zhang et al. <ref type="bibr" target="#b5">[6]</ref> demonstrated an interactive correlation map with spatial representations. By ways of slider bars, users can filter edges corresponding to weak relations. Our work is inspired by these methods and we extend them for the visualization of causal relations, providing a suite of interactive utilities to manipulate the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2</head><p>Causality Representation and Inference Our framework provides automatic discovery of causalities in the data, thus causality representation and inference algorithms are closely related to our work. The causality system is often represented as Bayesian Networks (BN) <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, in which causal relations are represented as dependencies measured by conditional probabilities. Algorithms recognizing BN structures usually require knowledge of the data distributions, which is difficult to achieve in practice especially with continuous data. For this type of data, Structural Causal Models <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b18">19]</ref> which assume effects are linear functions of their causes plus Gaussian noise are better suited. The structure of this model is typically built via a multi-phase process involving a number of CI tests using partial correlations <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b3">4]</ref>. Unfortunately, these algorithms often fail when categorical variables are included in the data. Introducing dummy variables is a standard technique in statistics <ref type="bibr" target="#b22">[23]</ref>, but the resulting significant increase in the number of variables may lead to an exponential increase in the number of CI tests needed, and also the mutual exclusions among dummies from the same variable can be very difficult to guarantee.</p><p>For the purpose of handling both categorical and numerical variables in a correlation network, Zhang et al. <ref type="bibr" target="#b5">[6]</ref> recently proposed an algorithm that uses a pairwise optimization approach to reorder and reposition the levels of each categorical variable with respect to each numerical variable. The new levels are computed by maximizing Pearson's correlation with the pair's numerical variable. This approach is superior to other encoding methods like <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref> in that it provides both reordered and optimized distances between categories. However, in contrast to correlation networks, causal inference requires a global frame and so the algorithm proposed by Zhang et al. is not directly applicable. But it served as an inspiration for the global optimization approach we developed which computes the new level values of a categorical variable with respect to all numerical variables in the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THEORETICAL BACKGROUND AND CONTRIBUTIONS</head><p>Our causality analysis framework comprises the following three steps: (1) find all true CI relations embedded in the observational data (see Section 3.1), (2) build a DAG that is consistent (termed faithful) to all of these conditions (see Section 3.2), and (3) compute the causal strengths of the relations coded by the DAG (see Section 3.4). Steps 1 and 2 make use of correlation analysis where we require a novel transformation of categorical to numerical variables which we introduce in Section 3.3. Conversely, step 3 uses dedicated regression analyses where no such transformation is needed. Our treatment of steps 1-3 is necessarily brief and the reader is referred to the tutorials by Pearl <ref type="bibr" target="#b6">[7]</ref> and Spirtes <ref type="bibr" target="#b25">[26]</ref> for more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Causality Analysis and CI Test</head><p>The idea of causality analysis is based on counterfactual theory, which can be explained in terms of the form "If A had not occurred, B would not have occurred". Although counter facts cannot be treated equally as causation on a philosophical level <ref type="bibr" target="#b26">[27]</ref>, causality analysis serves uniquely in telling us how a distribution would differ if external conditions were changed by treatments or interventions <ref type="bibr" target="#b6">[7]</ref>. To achieve such functionality, CI tests are used as core instruments. The goal of a CI test is to find out whether two variables are related when the rest of the system is controlled, i.e., test the dependency of two variables while eliminating the impact of all other variables or at least a subset of them. This can be interpreted as a simulation of a controlled experiment on observed data. In statistics, for some variables and in a numerical dataset, a CI test is equivalent to a test for zero partial correlations between and given a set of other variables in the dataset. This is called conditioning on <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. The partial correlation between and given is defined as the correlation of the residuals from regressions of on and of on . In a dataset, the partial correlations from each pair of variables conditioned on all remaining variables form a partial correlation matrix. Such a matrix can be efficiently computed based on the correlation matrix , so that with − = ( ), we have</p><formula xml:id="formula_0">• \{ } = − √<label>(1)</label></formula><p>where and are two variables, and</p><p>• \{ } is the partial correlation of and given all other variables in the dataset. Then with the partial correlation matrix, we are able to find all potential causal relations. This process as a whole is often called feature extraction, which is the first step in many causal discovery algorithms <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b27">28]</ref>.</p><p>However, variables actually independent to each other may still be found causally related when conditioned on certain variables. Suppose a graduate school admits students only by the sum of one's GPA and personal statement score. We may find these two scores negatively correlated within those who are admitted, as high GPA with low statement score or low GPA with high statement score is just enough for being admitted. But there is no apparent causal relation between the two scores in the real world. This means some variables (admission status in this example) cannot be conditioned on in finding the true CI relations between two variables. Such variables are called colliders and their descendants, and conditioning on them will generate false causations and introduce triangle patterns. The right set of variables to be conditioned on so that two variables can be deemed having a CI relation is called d-separating set. If no such set can be found in the dataset for a pair of variables, we can infer there is direct causation between them. All terms refer to <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2</head><p>Causal Graph and Inference The goal of causality analysis is to build a causal graph that is faithful to all the CI relations embedded in the observational data. A causal graph = ( , ) is a DAG that consists of a set of vertices denoting the variables and a set of directed edges denoting the causal relations between two variables. Assuming there is no latent variable, the basic graph pattern of the causal relations among any three observed variables related to each other are: (1) a chain of causal influences ( <ref type="figure" target="#fig_1">Fig. 2a</ref>), (2) a common cause influencing multiple variables (confounding, <ref type="figure" target="#fig_1">Fig. 2b</ref>), or (3) a common effect caused by multiple variables (selection bias, <ref type="figure" target="#fig_1">Fig. 2c</ref>). The first two patterns imply the same conditional independency which is "A is independent of B conditioning on C". But the third pattern, also called the Vstructure, is different as C is just the collider of A and B as mentioned in the previous subsection, thus the true independency of A and B can be recognized only when C is NOT conditioned on.</p><p>However, in feature extraction we simply conditioned on all other variables and no causal relations are oriented, thus patterns as <ref type="figure" target="#fig_1">Fig. 2c</ref> would become an undirected triangle, and patterns in <ref type="figure" target="#fig_1">Fig. 2a</ref> and b would look the same. The resulting undirected graph is often called a Markov field or a moral graph depending on the author.</p><p>How to remove false links and orient the edges correctly is one of the major issues in modern causal inference researches. The usual procedure is to look at each pair of connected variables and conduct a subset search for colliders in variables forming triangles with them. If colliders are found then the two variables are disconnected and Vstructures are recognized. This process costs a number of CI tests exponential to the number of variables forming triangles with each variable pair in the undirected graph. This is where the main computation cost lies. After all triangles have been processed a constraint propagation algorithm is run and a maximally but often partially oriented DAG is obtained <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>It is worth noting that partially oriented graphs returned by such a causal inference process only represent observationally equivalent classes <ref type="bibr" target="#b1">[2]</ref> of true causal graphs, as there may be multiple DAG corresponding to the same set of CI relations. Expressed formally, for the generated and some variables , and Z in ,</p><formula xml:id="formula_1">, adjacent in ⟺ → or → in reality → ← in ⟺ → ← in reality (2)</formula><p>This means that we will always need further verification to obtain the perfect causal graph in practice. Our system is purposed to help analysts in this verification task, using visualization to allow them to maintain their bearings on all levels of scale.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Correlations of Categorical &amp; Numerical Variables</head><p>To efficiently compute the partial correlation matrix for the CI tests, we need to calculate a correlation matrix first. While correlations between pairs of numerical variables and pairs of categorical variables can be achieved accordingly with Pearson's correlation coefficient and Cramer's V, traditional methods applicable for correlations between numerical and categorical variables, e.g.t-test, ANOVA, and MANOVA, have the problem that they are not normalized, so that one must consult significance tables to measure </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4</head><p>the association between two variables. However, the ability to handle mixed types of variables is often required in practical applications. Our solution to this problem makes use of Zhang et al.'s approach <ref type="bibr" target="#b5">[6]</ref> which returns a maximized Pearson's correlation between a pair of numerical and categorical variables using the following equation:</p><formula xml:id="formula_2">( ) = ( ( ))<label>(3)</label></formula><p>Here, ( ) is the value assigned to level of categorical variable regarding to numerical variable and ( ( )) is the average of corresponding to level of . This will bring an optimized ordering and distances of 's levels regarding . This method, however, is only partially useful for casual analysis because the level ordering and adjustment for a given categorical variable will be different for each numerical variable. This is fine for correlation analysis but causal reasoning requires global consistence of variable values in all CI tests. In the following we describe a novel generalization of the scheme of Zhang et al. that can achieve this.</p><p>An ideal globally consistent value mapping should be such that correlations between the categorical and all numerical variables are simultaneously maximized. A naïve idea would be to simply mediate all pairwise optimized values mapped from each numerical variable, setting up the target equation as,</p><formula xml:id="formula_3">min ∑ ∑‖ ( ) − ( )‖ =1 =1 (4)</formula><p>in which we suppose there is a categorical variable with levels and numerical variables , i = {1, 2, … , } in the dataset.</p><p>( ) is the global optimized value we require for level of , and ( ) is the pairwise optimized value for level with regards to numeric variable .</p><p>However, with the empirical knowledge that strong causal relations typically lead to strong correlations (although this is not true reversely), the values of 's levels should more depend on numerical variables that are strongly correlated with it, but less on those are weakly correlated with it. This can be easily implemented by weighting the inner summation of equation <ref type="bibr" target="#b3">(4)</ref> with the pairwise optimized correlation between and , namely .</p><p>If two orderings of 's levels regarding two different numerical variables and are just opposite to each other, solving equation (4) will result in that all 's levels have similar values. The solution is to reverse one of two orderings so that the two become identical. This is equivalent to changing the sign of its pairwise optimized correlation weighting the inner summation. The mechanism to decide whether a level ordering should be reversed can be achieved by testing the sign of a correlation of orderings measurement, in which we consider 's level ordering , regarding to as a standard, then reverse the ordering , with regards to when the correlation of , and , is negative. The selection of can be the one with largest pairwise correlation with , call it . Let Θ( , ) be the decision function representing the process and ( , ) be the correlation function, then,</p><formula xml:id="formula_4">Θ( , ) = ( ( , ,<label>, )) (5)</label></formula><p>We are now ready to put together the final target equation, using Θ( , ) and as weights in the outer summation of equation <ref type="formula">4</ref>:</p><formula xml:id="formula_5">min ∑ Θ ∑‖ ( ) − ( )‖ =1 =1 (6)</formula><p>Here we use Θ to denote Θ( , ) for convenience We found that satisfactory results can be achieved when = 2. Then by making (6) equal to 0 and differentiating on ( ), we can solve the optimization problem and obtain a closed formula,</p><formula xml:id="formula_6">( ) = ∑ Θ ( ) =1 ∑ Θ =1<label>(7)</label></formula><p>As ∑ Θ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>=1</head><p>only serves as a normalization factor, also combining equation <ref type="formula" target="#formula_2">3</ref>we obtain,</p><formula xml:id="formula_7">( ) ∝ ∑ Θ ( ( )) =1<label>(8)</label></formula><p>With equation <ref type="formula" target="#formula_7">8</ref>, we can now assign numerical values to 's levels, which can be used consistently in causal inference processes. For the last two variable pairs, the different sign of global from pairwise correlation means that the level ordering is just the opposite. <ref type="figure">Fig. 3b</ref> and c show two parallel coordinate tiles before and after the transformation, respectively. We observe that after the transformation, (1) categories (levels) that behave similarly are put close to each other; and (2) the correlation is more visible in the parallel coordinate plots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.4</head><p>Regression Analysis After the structure of the causal graph model has been recovered, we need tools to model, measure, and test the causal relations statistically. In Pearl's theory of Structural Causal Models <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b6">7]</ref>, linear regressions are used as such tools. Linear regression measures the linear relationships between a dependent variable and one or more explanatory variables , = {1, 2, … , }, taking the form  <ref type="figure">Fig. 3</ref>. Effects of global optimization on the categorical variable origin from the auto MPG dataset <ref type="bibr" target="#b28">[29]</ref>. (a) Comparisons between correlations of origin and several numerical variables under pairwise optimization and global optimization. The correlation value are similar in scale under two value mapping approaches. The different signs of correlations in the last two rows mean the level ordering after global value mapping is just the opposite to that after pairwise value mapping. (b) The parallel coordinate view of mpg, origin, and weight before global value mapping. (c) The parallel coordinate view of mpg, origin, and weight after global value mapping. We can see that both ordering and distances between categories are optimized, so that correlation is more visible than that in (b). = 1 1 + 2 2 + ⋯ + + <ref type="bibr" target="#b8">(9)</ref> In this equation, the subscript indicates the -th observation and represents the intercept, which is interpreted as causal effects from latent factors (e.g. unobserved variables, sampling noise) in causality theory; is the regression coefficient for , which is also taken as the main measurement of causal strength. If is a level categorical variable, it is turned into − 1 binary dummy variables, each standing for a level of . Linear regression analysis can test the statistical significance of each explanatory variable via student's ttest, as well as test the goodness of fit of the whole model via F-test, R-squared coefficients, and many other statistical utilities.</p><p>Our framework uses logistic regression analysis to measure causal relations targeting categorical variables. Logistic regression analysis, although named "regression", is actually a model of classification probabilities, i.e. the probability of the categorical variable taking a certain level. It is a better fit than linear regression analysis in models targeting categorical variables. It takes the form of a logistic function as:</p><formula xml:id="formula_8">( ) = 1 1 + − , where = 1 1 + 2 2 + ⋯ + + (10)</formula><p>in which is the structural coefficient for and measurement of causal strength, with error term representing the disturbance from latent factors. If is a categorical variable with levels, it is turned into − 1 dummy variables. Logistic regression analysis can also test for variable significances (via Wald statistics) and for goodness of fit (via deviance, likelihood ratio tests, and so on). Note here the optimized values of categorical variables are not used in either regression analyses, but only in causal structure inference processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE VISUAL CAUSALITY ANALYST</head><p>In the following we use the Auto MPG dataset <ref type="bibr" target="#b28">[29]</ref> to illustrate our interface and the interactions we defined on it. This dataset has eight variables -one of them categorical (origin) -and 392 instances. <ref type="figure" target="#fig_0">Fig.  1</ref> shows all elements of our interface. The main window contains the 2D spatial layout of the causal graph in the center and the regression analysis view on the right. The variable type window on the left opens when a new dataset is read in, allowing the user to indicate which of the variables are numerical and which are categorical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.1</head><p>The Causal Graph Display The causal graph is generated by the causal inference algorithm described in Section 3, using our global value mapping scheme for the categorical variables. The causal graph display provides an overview of all data dimensions in terms of their causal relations in variable space. In this display the vertices correspond to variables, laid out via a Fruchterman-Reingold force-directed model <ref type="bibr" target="#b29">[30]</ref>. We set all edges to have the same natural strength so that vertices are uniformly spread on the canvas. The color of a vertex encodes the type of variable, blue for numerical and yellow for categorical. We use a different color for categorical variables since they will usually turn into dummy variables for the regression analysis. As such, each yellow vertex in the graph may correspond to multiple variables used in several regression analyses.</p><p>The edges of the graph link two variables in terms of their causal relationships. The direction icon on an edge encodes the direction of the causal relation, going from cause to effect. The colors of the direction icon encode the type of the causal relation. Green arrows encode positive relations, red arrows encode negative relations, and a yellow arrow emanating from a categorical variable corresponds to multiple relations between the target and dummies of the categorical variable. If the target variable is a categorical variable, the arrow will be yellow too. The reason to use yellow arrows is that complex causal relation involving categorical variables cannot be simply described as negative or positive.</p><p>The opacity of the edge encodes the amount of change that is exerted by the cause onto the effect, which is measured by regression coefficients. A more visible edge has a stronger effect. However, edges with too low opacities are often difficult to observe on the graph. Thus gamma correction is introduced such that for an edge connecting variable and with regression coefficient , its opacity is</p><formula xml:id="formula_9">= | | + (11)</formula><p>where is the normalizer to make all opacities lie in the range of [0, 1] , is the gamma value, and is the offset to guarantee minimum opacity. Usually we set = 0.8 and = 0.1 to avoid an edge to be rendered too weak to be observed, and at the same time rendering a strong edge evidently darker than a weak edge. Below the graph in <ref type="figure" target="#fig_0">Fig. 1</ref> is a control panel that allows users to run the causal inference algorithm -via the causal layout button -as well as add edges, give them cause-effect directions, and test these in the regression analysis after which a re-layout of the casual graph might be run. Slider bars allow the user to either filter away or enhance the opacity of weak edges. There is also a button to load new data which pops up the specification window on the left.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2</head><p>The Regression Analysis View When a variable is selected the system computes the regression model for all variables with incoming casual edges to it. In statistics, the former variable is often called the response variable, while the latter are the predictor variables. The regression analysis view shows the linear regression coefficient for each predictor variable as well as the p-value to give an indication of. The fit of the overall model can be gauged by the R-square metric. It is 1.0 when the regression model fit perfectly. The R-square metric gains in meaning especially when it is used to compare regression models. If R-square decreases significantly when a predictor variable is dropped from the model then there is a good chance that this variable was required. Another test statistics our system reports is the F-value gauged by the Fstatistics. The F-statistics is also particularly useful for comparing two competing models. We can write</p><formula xml:id="formula_10">= ( 1 − 2 2 ) ( 1 − 2 2 ) ⁄ (12)</formula><p>where is the residual sum-of-squares (RSS) of a model and is its degrees of freedom which is the number of observations minus the number of predictors minus 1. Let's assume that 1 is the RSS for the model with fewer predictor variables. Assume 1 is higher than 2 which is the RSS of the model with more predictors, and 1 is higher than 2 since there are fewer predictors. Now, If the more complicated model is correct, we can expect the relative increase in RSS (going from the complicated to the simple model) to be greater than the relative increase in the degrees of freedom, or</p><formula xml:id="formula_11">( 1 − 2 ) 2 ⁄ &gt; ( 1 − 2 ) 2 ⁄</formula><p>. The significance of this increase can be tested via the F-statistics, but even informally, when is large when a predictor variable is included in the model, we know that this predictor was valuable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Illustrative Example #1</head><p>In the graph of <ref type="figure" target="#fig_0">Fig. 1</ref> the user has selected a few edges to highlight the causal flow they are part of. For example, the user marked all edges that link the miles per gallon (mpg) rating of a car to the factors that might cause this rating (and the physical process behind it). These factors are weight, origin, and model_year. The regression analysis window gives the statistical measurements and proofs for the identified causal models by means of linear regression and logistic regression analyses. Here we learn that weight has a strong negative effect (the regression coefficient is -0.647), while the effects of the other factors are rather mild. All but one effect is statistically significant -their p-values are less than 0.05. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Interaction with the Causal Graph Interface</head><p>It is often the case that true causalities may be missing or are wrong in a causal graph built from observational data. For this reason further verifications (hypothesis tests) on identified causal relationships are always needed. These verifications usually require modification of the causal graph by means of connecting two vertices and assigning the causal direction, reversing the direction of an edge, deleting an edge, or marking an edge as unknown (of direction). Furthermore, especially in the presence of large causal graphs, users will wish to focus on certain variables and their casual relationships while hiding all others.</p><p>Our causal inference interface provides interactive utilities capable to perform all of the above functions with visual feedback. That is to say, whenever the causal graph is modified, the impact of the modification on the rest of the graph, e.g. direction icon colors and edge opacities, will be updated immediately. Vertices of variables of interest can be selected either in the graph or by marking them in the variable list. Edge selection is achieved by either clicking on them in the graph view or choosing them in the control panel. We note, however, that any deselected (hidden) variable should still be taken into consideration in the causal structure learning process as we need to condition on them in CI tests. If hidden variables are not considered then erroneous causal relationships might be inferred. This is similar to the case when important variables have not even been observed. In both cases our visual interface provides a helpful medium for human experts to recognize these false relationships and seek their resolution.</p><p>Causality is subtle, and to test and measure it, we make use of the statistics and regression analyses tools described in Sections 3.4 and 4.2. We show the results of these analyses, such as coefficients and others in the regression analysis view whenever a causal graph is generated. The analysis view also provides automatic update on the analysis results whenever the graph is modified by the user. Finally, if an edge on the graph is selected, all regression analysis results involving it will be highlighted to made salient for the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.5</head><p>Illustrative Example #2 <ref type="figure">Fig. 4a</ref> shows another example for the Auto MPG dataset. Here, the user has decided to focus on the causal graph of weight, horsepower, and timeTo60mph, hiding all other variables and relationships. The graph implies that a light car with high horsepower tends to have short acceleration time, which is consistent with real world knowledge. However, we also see in the graph that high horsepower increases weight which would bring down timeTo60mph. To research this conflict we delete the edge from horsepower to timeTo60mph and observe (in <ref type="figure">Fig. 4b</ref>) that weight and timeTo60mph are now negatively related (the visualization updated accordingly). A visual indicator is that the edge opacity dropped compared to the opacity in <ref type="figure">Fig. 4a</ref>. This new relationship is inconsistent with common knowledge and it likely means that only considering weight cannot explain acceleration well. To explore this argument more deeply, a detailed statistical proof is needed. This proof can be provided by the regression analysis view of our framework. <ref type="figure">Fig. 4c and d</ref> are two screen shots of the regression analysis view showing linear models of timeTo60mph, corresponding to the graph models in <ref type="figure">Figs. 4a</ref> and b, generated and updated automatically. We observe from <ref type="figure">Fig. 4c</ref> that when taking both horsepower and weight as causes, horsepower plays a much greater role (with regression coefficient -1.049) in effecting timeTo60mph than weight (with regression coefficient 0.632). When only regressing on weight, its regression coefficient is indeed negative (-0.343, <ref type="figure">Fig. 4d</ref>). However, the R-square coefficient in <ref type="figure">Fig. 4d</ref> is only 0.161, which is much lower than that in <ref type="figure">Fig. 4c</ref> where it was 0.622. This means that the linear model described in <ref type="figure">Fig. 4d</ref> is much worse than that in <ref type="figure">Fig. 4c</ref>, and we verified our previous guess that only considering weight will not explain acceleration well. Likewise the F-value drops by a large amount which also indicates that horsepower is a significant casual variable should not be dismissed.</p><p>We learn from this investigation that horsepower is indeed a good predictor for acceleration and that the apparent conflict due to the positive causal link between horsepower and weight might be related to the weight variable and not timeTo60mph. So we would continue our investigation there (see Section 5.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CASE STUDIES</head><p>We demonstrate our framework with the following three datasets, the first of which we have already used in the previous example.</p><p>Auto MPG dataset: This dataset contains 392 complete records of cars with 8 attributes: mpg, cylinders, displacement, horsepower, weight, timeTo60mph, model_ year, and origin, in which origin is a three-category nominal variable and all other variables are continuous. All car models in the dataset use gasoline and were built before 1983. This dataset was retrieved from the UCI Machine Learning Repository <ref type="bibr" target="#b28">[29]</ref>.</p><p>Sales campaign dataset: The dataset has been synthesized based on actual data describing the sales marketing and its effects on a company's financials. There are 600 data samples each representing one salesperson, and 10 numeric variables: %Completed, #Leads, LeadsWon, #Opportunity, PipeRevn (pipeline revenue), ExpectROI (Return on Investment), Cost, Cost/WonLead, PlanRev (planned revenue), and planROI. This data set was previously adopted for demonstrating the correlation map by Zhang et al. in <ref type="bibr" target="#b5">[6]</ref>. We can now make more explicit decisions by ways of causality analysis with our new interface.</p><p>Heart disease Dataset: This is a realistic dataset on heart disease diagnosis, retrieved from the UCI Machine Learning Repository <ref type="bibr" target="#b28">[29]</ref>. The dataset has 270 diagnosis records, each per person, with 7 categorical variables: sex, chestPainType, fastBloodSuger, restECD (electrocardiographic), angina, thalassemia, and disease; and 6 numeric attributes: bloodPressure, serumChol (Cholestoral), maxHeartRate, exerST(ST depression induced by exercise), slopeExerST, and numVessels (colored by flourosopy). <ref type="figure">Fig. 4</ref>. The visual feedback and statistical analysis provided by the Visual Causality Analyst. (a) A visualized causal graph structure of variable weight, horsepower, and timeTo60mpg from the auto MPG dataset, generated by our framework. (b) The visual feedback after deleting the edge from horsepower to timeTo60mpg. Here weight becomes a negative cause of timeTo60mpg, which is inconsistent with common knowledge. (c) A screen shot of linear regression analysis targeting timeTo60mpg in line with the causal model of (a). (d) A screen shot of linear regression analysis targeting timeTo60mpg in line with the causal model of (b). Comparing (c) and (d) we can see that only regressing on weight cannot explain timeTo60mpg well, due to the dropping of R-and F-Test value from (c) to (d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.1</head><p>Causality Analysis: Auto MPG Dataset We firstly present the basic concepts of our Visual Causality Analyst interface with the auto MPG dataset. <ref type="figure" target="#fig_4">Fig. 5a</ref> gives an initial casual graph generated by randomly assigning values to levels of origin. We see here that horsepower is mistakenly drawn as the positive cause of cylinders and displacement. It is common knowledge that these two edges should at least be reversed. The reason for such errors is typical. The feature extraction found an undirected edge between horsepower and origin with origin's random level values, then cancelled it in the d-separating set search and directed the causal relation as horsepowe → displacement and origin → displacement. This error then spread in later processes and affected the direction between horsepower-cylinders.</p><p>A better causal graph is shown in <ref type="figure" target="#fig_4">Fig. 5b</ref>, which is generated by using globally optimized level values of origin. Now we can see that all causal relations between horsepower, cylinders and displacement are correct. We also found that the categorical variable origin plays a weak (low edge opacity) cause of displacement and mpg. As origin will turn into dummy variables, it is represented by a yellow vertex. Also the arrows on edges leaving from origin are colored yellow as each denotes multiple coefficients. <ref type="figure" target="#fig_4">Fig. 5c</ref> shows an enhanced causal graph after setting the regression coefficient threshold to 0.4. All weak causal relations are filtered away. We now observe that origin and model_year are independent of all other variables, and the direct relation between horsepower and weight has also been eliminated.</p><p>Our original purpose for this dataset was to predict car mpg and find the direct and indirect causes for it. <ref type="figure" target="#fig_4">Fig. 5c</ref> suggests that timeTo60mph and horsepower are not related to mpg since there is no causal edge pointing to it. Thus we may unselect them and only lay out those variables that have strong direct or indirect causal relations with mpg. Having done this we obtain the causal graph of <ref type="figure" target="#fig_4">Fig. 5d</ref>, which is a chain of causal relations with four variables. <ref type="figure" target="#fig_4">Fig.  5h</ref> shows the parallel coordinates plot of these variables in the order of the causal chain. We can clearly observe a flow of associations from cylinders to mpg.</p><p>This chain is consistent with the mechanics of cars, at least when it comes to cars captured in this dataset. Adding cylinders to such a car increases its displacement, but not the other way around since we can also increase displacement by adding volume to the current set of cylinders. More displacement (and the power it affords) requires a heavier car for stability. But moving the extra weight around requires more gasoline, decreasing mpg.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.1.1</head><p>Interactive exploration of causal relationships One may want to further explore the potential causal relationships that are not suggested by the graph in <ref type="figure" target="#fig_4">Fig. 5b</ref>. This can also be easily achieved with the interactive tools provided by our framework.</p><p>For example, the causal graph did not draw direct edges between displacement and mpg. However, we might wish to test the hypothesis if this causal relation actually exists. To do this, we can simply select the pair of variables as cause and effect, respectively, in the control panel and assign the edge. The resulting causal graph is shown in <ref type="figure" target="#fig_4">Fig. 5e</ref>, with the added edge highlighted. Colors and opacities of other edges on the graph may change accordingly if the causal relations they represent are affected by such operation.</p><p>To determine whether this causal relation holds, we need to refer to statistical analyses. Two screen shots of the linear regression analyses results before and after adding the edge are shown in <ref type="figure" target="#fig_4">Fig. 5f</ref> and g. Since the p-value of displacement from the student t-test is too large (p = 0.339) in <ref type="figure" target="#fig_4">Fig. 5g</ref>, together with the dropping of F-value, the direct causal relation between displacement and mpg should not be considered as existing. Hence there is no direct relationship between displacement and mpg. Raising the displacement of a car mpg, which is a chain of causal relationships from cylinders to mpg. (e) The causal graph in which an edge from displacement to mpg is added and highlighted. (f) A screen shot of linear regression analysis on mpg without displacement. (g) A screen shot of linear regression analysis on mpg with displacement. We see that displacement has a large p-value in (g), also the F-Test in (g) is decreased from that in (f), so displacement should not be considered as a direct cause of mpg. (h) The parallel coordinate view of the variables related to mpg, in the order consistent to the causal relationships represented in (d). A clear flow of data variable relations can be observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8</head><p>usually will not directly lead to the decrease of its mpg. But when displacement increases, usually the car will be heavier (as mentioned before), which causes the mpg to reduce, since weight negatively changes mpg. In this case, weight serves as a mediator variable completing the chain of displacement and mpg.</p><p>Many more conclusions can be drawn and many more explorations can be done from this single causality visualization. Therefore we believe our Visual Causality Analyst is powerful and effective for casual reasoning explorations, and the graphs in <ref type="figure" target="#fig_4">Fig. 5</ref> may potentially be helpful for consumers to select cars, as well as for car manufacturers to balance their offering of models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2</head><p>Strategizing: Sales Campaign Dataset In this example, we use the Sales Campaign dataset to show how business executives may analyze sales behaviors and strategize with our Visual Causality Analyst software.</p><p>To give some background, a sales pipeline typically starts with a lead generator responsible for developing prospective customers called leads with whom salespersons may actually close deals. Leads may become won leads when they give positive feedback and then opportunities when they offer further interests. For each won leads, an increased sales pitch at cost per won lead (cost/WL) will be invested. The goal of the entire sales effort is to increase the expected return on investment (ExpectROI), and ultimately maximize pipeline revenue (PipeRevn). In <ref type="bibr" target="#b5">[6]</ref> a correlation map was used on the same dataset to showcase its features. In the following, we will demonstrate that by upgrading to the Visual Causality Analyst, the decision making process becomes even more explicit.</p><p>Suppose a team of sales data analysts in the company are busy analyzing the sales strategy for the following year, basing on last years' data from their sales teams. Their first step is to build the causal graph of all data attributes to get an overview on how their sales system actually functions. This process is straightforwardimport the data with an Excel spreadsheet and lay out the initial causal graph shown in <ref type="figure" target="#fig_3">Fig. 6a</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2.1</head><p>Strategy development After drawing the sales system's causal graph, the analysts proceed in developing effective business strategies using our interface.</p><p>To achieve the goal of increasing the pipeline revenue, the analysts first filter out weak relations in the graph and select a series of related causal relations, highlighted in <ref type="figure" target="#fig_3">Fig. 6b</ref>. These relations form several routes starting from some variables and finally pointing to PipeRevn. Clearly on the graph, the variable #Leads is the starting point of multiple routes to the final goal. In all of these routes, #Leads plays a positive factor for PipeRevn, which means increasing the former will lead to an increase of the latter in the end. So the first strategy might be to generate more leads, i.e. reach out to more people to look for potential customers, simply and clearly.</p><p>Another variable related to the goal of the sales data analysts is Cost/WL which is the sales pitch invested into each won lead. However, the effect of increasing this variable can have both a Cost. Here the purpose is to investigate the effect of Cost/WL on PipeRevn. As the scale of the direct effect of Cost/WL on PipeRevn is larger than the indirect effect via Cost, the total effect of rising Cost/WL will be the reduction of PipeRevn. (d) A correlation map view browsing only variables in a similar strategizing scenario. However, variables correlated to each other may not necessarily imply any causal relationship. positive and a negative effect on PipeRevn. The positive effect is through the variable Cost, which is the salesman's total investment. The negative effect can be both direct and indirect through multiple routes. To resolve this conflict, we can refer to the coefficients analysis view of the software. Here we present two screen shots in <ref type="figure" target="#fig_3">Fig. 6c</ref>. They show that the direct effect of Cost/WL in the linear regression model of PipeRevn is larger than that of the indirect relation (Cost/WL →Cost) × (Cost→ PipeRevn). In addition, the coefficient of ExpectROI on PipeRevn is more than twice that of Cost, and Cost/WL negatively impacts ExpectROI. Thus, to increase PipeRevn we are advised to not increase Cost/WL -in fact, we might rather decrease it.</p><p>These two strategies essentially imply that, to increase the revenue, each of the company's salespersons should put more effort in exploring new customers. Further, the model indicates that once a potential customer has already shown interest, there is no need to invest extra promotions. It may even have some negative impact on closing the deal.</p><p>The strategic guidance our Visual Causality Analyst can provide is explicit and assuring, partly due to its visualization of the casual relationships and partly due to its interactive response rates. When users see the causal graph, they can visually think and form hypotheses that a certain action might potentially lead to a certain outcome. Further, via the regression analysis the size of the effect can also be measured and communicated. This is a significant improvement over the correlation map proposed in prior work <ref type="figure" target="#fig_3">(Fig.  6d)</ref>, by browsing which, users may learn how two variables are correlated in past data (e.g. Cost/WL and ExpectROI, #Leads and ExpectROI etc.), but variables strongly correlated to each other may not necessarily imply any causal relationship. And thus, adjusting a variable just based on the correlation map alone will not necessarily lead to the expected change in another variable in the real world.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analyzing Categories: Heart Disease Dataset</head><p>In this final example we will demonstrate how the Visual Causality Analyst can also be used to visually analyze the causal relationships in medical data that include mixed types of variables.</p><p>Suppose an expert on cardiology has been keeping a collection of medical records on his past patients and wishes to identify the most effective methods for diagnosing heart diseases. The expert opens our software and imports his data, then generates the initial causal graph shown in <ref type="figure" target="#fig_6">Fig. 7a</ref>. Since there are multiple variables that are categorical, we observe many nodes and arrows on edges that are colored yellow.</p><p>Any edges on the graph directly pointing to and from disease indicate either diagnostics (the outgoing edges) or causes (the incoming edges) of heart disease. These edges and the causal relationships they represent are of greatest interest to the expert. From <ref type="figure" target="#fig_6">Fig. 7a</ref> he learns that restECD, numVessels, maxHeartRate, serumChol, chestPainType, and thalassemia are all variables directly linked to disease. Thus he unselects all other variables and re-lays out the graph, which yields <ref type="figure" target="#fig_6">Fig. 7b</ref>.</p><p>In <ref type="figure" target="#fig_6">Fig. 7b</ref>, the categorical variable restECD has three levels where each represents a type of electrocardiographic test result. To test which type of electrocardiographic result is caused by heart disease, we need to consult the logistic regression analysis. <ref type="figure" target="#fig_6">Fig. 7c</ref> is a screen shot of the analysis result targeting each of restECD's level. In the first model, disease has a negative coefficient and a small pvalue, which means restECD-0.0 is not a sign of heart disease, or even a sign of a healthy heart. In the second model, although disease has a positive coefficient, its p-value is too large. The values of other statistical metrics, such as low Chi-Squared value, high model pvalue, low deviance, etc. all indicate that restECD-1.0 is likely irrelevant to heart disease diagnosis. The last logistic model, restECD-2.0, disease shows both a positive coefficient and a small p-value, and therefore this test seems to be a valuable means to diagnose an impending heart disease. The expert is satisfied having succeeded in finding an effective means for heart disease diagnostics from his treasure trove of data.</p><p>A similar process can be conducted on the variable chestPainType. The logistic regression analysis targeting each of its four categories is shown in <ref type="figure" target="#fig_6">Fig. 7d</ref>. Here we observe that only chestPainType-4.0 has both a positive coefficient and a zero p-value. Other statistical features of this model, e.g. high Chi-Square value and high deviance also indicate that chestPainType-4.0 should be considered a sign of heart disease. Other types of chest pains are either irrelevant (chestPainType-1.0) or not a sign of disease (chestPainType-2.0 and 3.0).</p><p>There are many more hypotheses that the expert might discover, test and prove or disprove given his data and using our software. We cannot list them all here. But the case study presented shows that the Visual Causality Analyst is well applicable for health sciences data, as well as all other scientific dataset with mixed types of variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION AND FUTURE WORK</head><p>We have presented the Visual Causal Analyst -the first interactive framework for visual causal reasoning and visual causal discovery for high-dimensional data. An added novelty of our framework is that it supports both numerical and categorical variables, which is important for real-world applications. Our interface can serve both as a causality exploration environment and as a platform to visually demonstrate, explain, and justify causal relations that exist in the data with statistical proof provided by linear regression analyses and logistic regression analyses. Our framework is general and applicable to a wide set of real cases, as demonstrated by our case studies.</p><p>A present limitation of our framework is that causal relations may exist and vary in different data clusters. Therefore a prior visualization and possibly clustering of the data might be advised. Interactive clustering algorithms, such as ClusterSculptor <ref type="bibr" target="#b30">[31]</ref>, would allow users to first isolate an independent data cluster and then deduce causalities only on this partial data.</p><p>Future work will also focus on visualizing the test statistics, such as R-squared and F-value directly in the visualization. Since the comparison of models (that is, configurations with certain causal edges missing or added) is a frequent task, we might add an information visualization widget that would allow users to compare the values of the test statistics for these alternative models and convey the statistical relevance of the different values.</p><p>Another frontier is the ability to perform visual causal reasoning with time series data. This is of great interest to scientists, policy makers, economists, etc. Although we can deal with time series data by simply treating time as a data variable, a dedicated visual analytic approach will be better, possibly using Granger causality.</p><p>Finally, we should note that causality can be affected by outliers, non-linear relationships, heteroskedasticity, and multicollinearity. To achieve more statistical robustness, techniques for outlier detection and removal, non-linear causality need to be added to our system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>An overview of the Visual Causality Analyst framework running on the auto MPG dataset<ref type="bibr" target="#b28">[29]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Three basic patterns of causal relations among any tree observed variables related to each other: (a) a chain of causal relations from A to B via C; (b) a common cause C influencing both A and B; (c) a common effect caused by both A and B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig. 3aillustrates how this global optimization performs for the auto MPG dataset<ref type="bibr" target="#b28">[29]</ref> ( = 7, 392 data points). In the table, the first column gives the variable pairs, in which origin is a categorical variable and all others are numerical variables. The second column shows the correlation using Zhang et al.'s pairwise optimized assignment for each level of origin. The third column shows the (similar) correlations obtained with our global optimization method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>6</head><label>6</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Causal reasoning on auto MPG dataset with the Visual Causality Analyst. (a) The causal graph generated by randomly assigning values to origin's categories, which introduces several error edges. (b) The causal graph generated by assigning globally optimized values to origin's categories. (c) The graph with regression coefficient threshold of 0.4. Weak causal relations are filtered away. (d) The graph relevant to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Strategizing with the Visual Causality Analyst for the sales campaign dataset. (a) The causal graph generated from the dataset showing how the sales system works. (b) All the routes pointing to PipeRevn from some variable, indicating possible strategies to increase pipeline revenue. Here #Leads and Cost/WL are two variables that all routes start from. (c) Screen shots of linear regression analyses on PipeRevn and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Analyzing heart disease dataset with the Visual Causality Analyst. (a) An original causal graph generated by the new framework. As there are multiple categorical variables, many nodes and arrows are colored yellow. (b) The causal graph targeting disease, in which only variables and relations relevant to disease are selected and shown. (c) Screen shots of logistic regression analyses on each of the three restECD's categories. Only electrocardiographic type restECD-2.0 is found as a sign of heart disease, due to the positive regression coefficient and small pvalue of disease in its logistic model. (d) Screen shots of logistic regression analyses on each of the four chestPainType's categories. The last type chestPainType-4.0 should be considered positively relevant to heart disease, while other types are either irrelevant or not a sign of heart disease.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and Klaus Mueller are with the Visual Analytics and Imaging Lab at the Computer Science Department, Stony Brook University, Stony Brook, NY. E-mail: {junwang2, mueller}@cs.stonybrook.edu.  Klaus Mueller is also with the Computer Science Dept. at SUNY Korea. Manuscript received 31 Mar. 2015; accepted 1 Aug. 2015; date of publication xx xxx 2015; date of current version xx xxx 2015. For information on obtaining reprints of this article, send e-mail to: tvcg@computer.org.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Manuscript received 31 Mar. 2015; accepted 1 Aug. 2015; date of publication 20 Aug. 2015; date of current version 25 Oct. 2015. For information on obtaining reprints of this article, please send e-mail to: tvcg@computer.org. Digital Object Identifier no. 10.1109/TVCG.2015.2467931</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This research was partially supported by NSF grant IIS 1117132 and the MSIP (Ministry of Science, ICT and Future Planning), Korea, under the "ICT Consilience </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Google Correlate</title>
		<ptr target="http://www.google.com/trends/correlate/" />
		<imprint>
			<date type="published" when="2014-03-20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<title level="m">Causality: Models, Reasoning and Inference</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<title level="m">Causation, Prediction, and Search</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Causality from probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visual Correlation Analysis of Numerical and Categorical Data on the Correlation Map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zadok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="289" to="303" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An Introduction to Causal Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Biostatistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1557" to="4679" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dichotomizing continuous predictors in multiple regression: a bad idea</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Royston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sauerbrei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="141" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Finding what is not there through the unfortunate binning of results: The Mendel effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wainera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gessarolib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verdib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chance</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="52" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Definition of Data Consistency Using Event Lattices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications</title>
		<meeting>the International Conference on Parallel and Distributed Processing Techniques and Applications</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Parallel N-free Order Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Viennot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="406" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Animated visualization of causal relations through growing 2D geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tsigas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Visualization</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="154" to="172" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Causality visualization using animated growing polygons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elmqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tsigas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Information Visualization</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Visualizing Causal Semantics using Animations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Kadaba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leboe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1254" to="1260" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wongsuphasawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2659" to="2668" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visualization of Bayesian belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Zapata-Rivera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Neufeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Greer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Visualization&apos;99, Late Breaking Hot Topics</title>
		<meeting>IEEE Visualization&apos;99, Late Breaking Hot Topics</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Being Bayesian About Network Structure. A Bayesian Approach to Structure Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="95" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Bayesian network approach to making inferences in causal maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nadkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Shenoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="479" to="498" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Causal Discovery with Continuous Additive Noise Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2009" to="2053" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An Efficient Causal Discovery Algorithm for Linear Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 16th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Partial correlation and conditional correlation as measures of conditional independence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sibuya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Australian &amp; New Zealand Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="647" to="664" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using Markov Blankets for Causal Structure Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Pellet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1295" to="1342" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Using multivariate statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Tabachnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Fidell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Harper &amp; Row</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ordering categorical data to improve visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE symposium on information visualization</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Applied multiple regression/correlation analysis for the behavioral sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Aiken</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>3rd ed.), Routledge</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Introduction to Causal Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1643" to="1662" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Winship</surname></persName>
		</author>
		<title level="m">Counterfactuals and causal inference</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Equivalence and synthesis of causal models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pear</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Sixth Annual Conference on Uncertainty in Artificial Intelligence</title>
		<meeting><address><addrLine>Mountain View</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<title level="m">{UCI} Machine Learning Repository</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>University of California, Irvine, School of Information and Computer Sciences</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Graph drawing by forcedirected placement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Fruchterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Reingold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Software: Practice and experience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1129" to="1164" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">ClusterSculptor: A Visual Analytics Tool for High-Dimensional Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zelenyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Imre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Analytics Science and Technology</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
