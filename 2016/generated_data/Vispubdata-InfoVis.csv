Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited,Award
conference_external,2017,Topological Analysis of Inertial Dynamics,10.1109/TVCG.2016.2599018,http://dx.doi.org/10.1109/TVCG.2016.2599018,950,959,Journals & Magazines,"Traditional vector field visualization has a close focus on velocity, and is typically constrained to the dynamics of massless particles. In this paper, we present a novel approach to the analysis of the force-induced dynamics of inertial particles. These forces can arise from acceleration fields such as gravitation, but also be dependent on the particle dynamics itself, as in the case of magnetism. Compared to massless particles, the velocity of an inertial particle is not determined solely by its position and time in a vector field. In contrast, its initial velocity can be arbitrary and impacts the dynamics over its entire lifetime. This leads to a four-dimensional problem for 2D setups, and a six-dimensional problem for the 3D case. Our approach avoids this increase in dimensionality and tackles the visualization by an integrated topological analysis approach. We demonstrate the utility of our approach using a synthetic time-dependent acceleration field, a system of magnetic dipoles, and N-body systems both in 2D and 3D.",,Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias;Luis Gustavo Nonato;Filip Sadlo,"Heidelberg University, Germany;Heidelberg University, Germany;ZAH, Heidelberg University, Germany;Universidade de Såo Paulo, Såo Carlos, Brazil;Universidade de Såo Paulo, Såo Carlos, Brazil;Heidelberg University, Germany",,"Visualization of inertial dynamics,N-body systems,magnetism,acceleration,,,",,2,,
InfoVis,2017,Iterating between Tools to Create and Edit Visualizations,10.1109/TVCG.2016.2598609,http://dx.doi.org/10.1109/TVCG.2016.2598609,481,490,Journals & Magazines,"A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, data-driven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.",,Alex Bigelow;Steven Drucker;Danyel Fisher;Miriah Meyer,University of Utah;Microsoft Research;Microsoft Research;University of Utah,,"Visualization,iteration,illustration,,,,",,10,,
conference_external,2017,Visualization as Seen through its Research Paper Keywords,10.1109/TVCG.2016.2598827,http://dx.doi.org/10.1109/TVCG.2016.2598827,771,780,Journals & Magazines,"We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the IEEE Visualization conference series (now called IEEE VIS) between 1990-2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the IEEE VIS reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for IEEE VIS papers since 1990 to find related work or make informed keyword choices.",,Petra Isenberg;Tobias Isenberg;Michael Sedlmair;Jian Chen;Torsten Möller,"Inria, France;Inria, France;University of Vienna, Austria;University of Maryland, Baltimore County, USA;University of Vienna, Austria",,"data analysis,research themes,research topics,taxonomy,visualization history,theory,",,9,,
conference_external,2017,Vol<sup>2</sup>velle: Printable Interactive Volume Visualization,10.1109/TVCG.2016.2599211,http://dx.doi.org/10.1109/TVCG.2016.2599211,861,870,Journals & Magazines,"Interaction is an indispensable aspect of data visualization. The presentation of volumetric data, in particular, often significantly benefits from interactive manipulation of parameters such as transfer functions, rendering styles, or clipping planes. However, when we want to create hardcopies of such visualizations, this essential aspect is lost. In this paper, we present a novel approach for creating hardcopies of volume visualizations which preserves a certain degree of interactivity. We present a method for automatically generating Volvelles, printable tangible wheel charts that can be manipulated to explore different parameter settings. Our interactive system allows the flexible mapping of arbitrary visualization parameters and supports advanced features such as linked views. The resulting designs can be easily reproduced using a standard printer and assembled within a few minutes.",,Sergej Stoppel;Stefan Bruckner,University of Bergen;University of Bergen,,"Physical Visualization,Interaction,Volume Visualization,Illustrative Visualization,,,",,2,,
InfoVis,2017,Visualization by Demonstration: An Interaction Paradigm for Visual Data Exploration,10.1109/TVCG.2016.2598839,http://dx.doi.org/10.1109/TVCG.2016.2598839,331,340,Journals & Magazines,"Although data visualization tools continue to improve, during the data exploration process many of them require users to manually specify visualization techniques, mappings, and parameters. In response, we present the Visualization by Demonstration paradigm, a novel interaction method for visual data exploration. A system which adopts this paradigm allows users to provide visual demonstrations of incremental changes to the visual representation. The system then recommends potential transformations (Visual Representation, Data Mapping, Axes, and View Specification transformations) from the given demonstrations. The user and the system continue to collaborate, incrementally producing more demonstrations and refining the transformations, until the most effective possible visualization is created. As a proof of concept, we present VisExemplar, a mixed-initiative prototype that allows users to explore their data by recommending appropriate transformations in response to the given demonstrations.",,Bahador Saket;Hannah Kim;Eli T. Brown;Alex Endert,Georgia Institute of Technology;Georgia Institute of Technology;DePaul University;Georgia Institute of Technology,,"Visualization by Demonstration,Visualization Tools,Visual Data Exploration,,,,",,11,,
conference_external,2017,Physics-Based Visual Characterization of Molecular Interaction Forces,10.1109/TVCG.2016.2598825,http://dx.doi.org/10.1109/TVCG.2016.2598825,731,740,Journals & Magazines,"Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.",,Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Àlvar Vinacua;Pere-Pau Vázquez,"ViRVIG Group, Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Visual Computing Group, Ulm University;ViRVIG Group, UPC, Barcelona;ViRVIG Group, UPC, Barcelona",,"Molecular visualization,binding analysis,,,,,",,4,,
InfoVis,2017,Screenit: Visual Analysis of Cellular Screens,10.1109/TVCG.2016.2598587,http://dx.doi.org/10.1109/TVCG.2016.2598587,591,600,Journals & Magazines,"High-throughput and high-content screening enables large scale, cost-effective experiments in which cell cultures are exposed to a wide spectrum of drugs. The resulting multivariate data sets have a large but shallow hierarchical structure. The deepest level of this structure describes cells in terms of numeric features that are derived from image data. The subsequent level describes enveloping cell cultures in terms of imposed experiment conditions (exposure to drugs). We present Screenit, a visual analysis approach designed in close collaboration with screening experts. Screenit enables the navigation and analysis of multivariate data at multiple hierarchy levels and at multiple levels of detail. Screenit integrates the interactive modeling of cell physical states (phenotypes) and the effects of drugs on cell cultures (hits). In addition, quality control is enabled via the detection of anomalies that indicate low-quality data, while providing an interface that is designed to match workflows of screening experts. We demonstrate analyses for a real-world data set, CellMorph, with 6 million cells across 20,000 cell cultures.",,Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister,Harvard University;Harvard University;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Harvard University,,"High-content screening,visual analysis,feature selection,image classification,biology,multivariate,hierarchy",,0,,
InfoVis,2017,Small Multiples with Gaps,10.1109/TVCG.2016.2598542,http://dx.doi.org/10.1109/TVCG.2016.2598542,381,390,Journals & Magazines,"Small multiples enable comparison by providing different views of a single data set in a dense and aligned manner. A common frame defines each view, which varies based upon values of a conditioning variable. An increasingly popular use of this technique is to project two-dimensional locations into a gridded space (e.g. grid maps), using the underlying distribution both as the conditioning variable and to determine the grid layout. Using whitespace in this layout has the potential to carry information, especially in a geographic context. Yet, the effects of doing so on the spatial properties of the original units are not understood. We explore the design space offered by such small multiples with gaps. We do so by constructing a comprehensive suite of metrics that capture properties of the layout used to arrange the small multiples for comparison (e.g. compactness and alignment) and the preservation of the original data (e.g. distance, topology and shape). We study these metrics in geographic data sets with varying properties and numbers of gaps. We use simulated annealing to optimize for each metric and measure the effects on the others. To explore these effects systematically, we take a new approach, developing a system to visualize this design space using a set of interactive matrices. We find that adding small amounts of whitespace to small multiple arrays improves some of the characteristics of 2D layouts, such as shape, distance and direction. This comes at the cost of other metrics, such as the retention of topology. Effects vary according to the input maps, with degree of variation in size of input regions found to be a factor. Optima exist for particular metrics in many cases, but at different amounts of whitespace for different maps. We suggest multiple metrics be used in optimized layouts, finding topology to be a primary factor in existing manually-crafted solutions, followed by a trade-off between shape and displacement. But the rich range of possible optimized layouts leads us to challenge single-solution thinking; we suggest to consider alternative optimized layouts for small multiples with gaps. Key to our work is the systematic, quantified and visual approach to exploring design spaces when facing a trade-off between many competing criteria-an approach likely to be of value to the analysis of other design spaces.",,Wouter Meulemans;Jason Dykes;Aidan Slingsby;Cagatay Turkay;Jo Wood,"giCentre, City University, London;giCentre, City University, London;giCentre, City University, London;giCentre, City University, London;giCentre, City University, London",,"Geographic visualization,small multiples,whitespace,design space,metrics,optimization,",,5,,
conference_external,2017,Direct Multifield Volume Ray Casting of Fiber Surfaces,10.1109/TVCG.2016.2599040,http://dx.doi.org/10.1109/TVCG.2016.2599040,941,949,Journals & Magazines,"Multifield data are common in visualization. However, reducing these data to comprehensible geometry is a challenging problem. Fiber surfaces, an analogy of isosurfaces to bivariate volume data, are a promising new mechanism for understanding multifield volumes. In this work, we explore direct ray casting of fiber surfaces from volume data without any explicit geometry extraction. We sample directly along rays in domain space, and perform geometric tests in range space where fibers are defined, using a signed distance field derived from the control polygons. Our method requires little preprocess, and enables real-time exploration of data, dynamic modification and pixel-exact rendering of fiber surfaces, and support for higher-order interpolation in domain space. We demonstrate this approach on several bivariate datasets, including analysis of multi-field combustion data.",,Kui Wu;Aaron Knoll;Benjamin J Isaac;Hamish Carr;Valerio Pascucci,"University of Utah;SCI InstituteUniversity of UtahArgonne National Laboratory;ICSE, University of Utah;School of ComputingUniversity of Leeds;SCI InstituteUniversity of Utah",,"Volume Rendering,Isosurface,Multidimensional Data,,,,",,1,,
conference_external,2017,Characterizing Guidance in Visual Analytics,10.1109/TVCG.2016.2598468,http://dx.doi.org/10.1109/TVCG.2016.2598468,111,120,Journals & Magazines,"Visual analytics (VA) is typically applied in scenarios where complex data has to be analyzed. Unfortunately, there is a natural correlation between the complexity of the data and the complexity of the tools to study them. An adverse effect of complicated tools is that analytical goals are more difficult to reach. Therefore, it makes sense to consider methods that guide or assist users in the visual analysis process. Several such methods already exist in the literature, yet we are lacking a general model that facilitates in-depth reasoning about guidance. We establish such a model by extending van Wijk's model of visualization with the fundamental components of guidance. Guidance is defined as a process that gradually narrows the gap that hinders effective continuation of the data analysis. We describe diverse inputs based on which guidance can be generated and discuss different degrees of guidance and means to incorporate guidance into VA tools. We use existing guidance approaches from the literature to illustrate the various aspects of our model. As a conclusion, we identify research challenges and suggest directions for future studies. With our work we take a necessary step to pave the way to a systematic development of guidance techniques that effectively support users in the context of VA.",,Davide Ceneda;Theresia Gschwandtner;Thorsten May;Silvia Miksch;Hans-Jörg Schulz;Marc Streit;Christian Tominski,"Vienna University of Technology, Austria;Vienna University of Technology, Austria;Fraunhofer IGD, Darmstadt, Germany;Vienna University of Technology, Austria;University of Rostock, Germany;Johannes Kepler University, Linz, Austria;University of Rostock, Germany",,"Visual analytics,guidance model,assistance,user support,,,",,15,,
InfoVis,2017,Multi-Granular Trend Detection for Time-Series Analysis,10.1109/TVCG.2016.2598619,http://dx.doi.org/10.1109/TVCG.2016.2598619,661,670,Journals & Magazines,"Time series (such as stock prices) and ensembles (such as model runs for weather forecasts) are two important types of one-dimensional time-varying data. Such data is readily available in large quantities but visual analysis of the raw data quickly becomes infeasible, even for moderately sized data sets. Trend detection is an effective way to simplify time-varying data and to summarize salient information for visual display and interactive analysis. We propose a geometric model for trend-detection in one-dimensional time-varying data, inspired by topological grouping structures for moving objects in two- or higher-dimensional space. Our model gives provable guarantees on the trends detected and uses three natural parameters: granularity, support-size, and duration. These parameters can be changed on-demand. Our system also supports a variety of selection brushes and a time-sweep to facilitate refined searches and interactive visualization of (sub-)trends. We explore different visual styles and interactions through which trends, their persistence, and evolution can be explored.",,Goethem Arthur Van;Frank Staals;Maarten Löffler;Jason Dykes;Bettina Speckmann,"TU, Eindhoven;MADALGO, Aarhus University;Utrecht University;City University, London;TU, Eindhoven",,"Interactive Exploration,Trend Detection,Time Series,,,,",,2,,
InfoVis,2017,Authoring Data-Driven Videos with DataClips,10.1109/TVCG.2016.2598647,http://dx.doi.org/10.1109/TVCG.2016.2598647,501,510,Journals & Magazines,"Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce DataClips, an authoring tool aimed at lowering the barriers to crafting data videos. DataClips allows non-experts to assemble data-driven “clips” together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that DataClips can reproduce over 90% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using DataClips, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use DataClips with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience.",,Fereshteh Amini;Nathalie Henry Riche;Bongshin Lee;Andres Monroy-Hernandez;Pourang Irani,"University of Manitoba, Canada;Microsoft;Microsoft;Microsoft;University of Manitoba, Canada",,"data video,narrative visualization,data storytelling,authoring tools,visualization systems,,",,7,,
InfoVis,2017,HindSight: Encouraging Exploration through Direct Encoding of Personal Interaction History,10.1109/TVCG.2016.2599058,http://dx.doi.org/10.1109/TVCG.2016.2599058,351,360,Journals & Magazines,"Physical and digital objects often leave markers of our use. Website links turn purple after we visit them, for example, showing us information we have yet to explore. These “footprints” of interaction offer substantial benefits in information saturated environments - they enable us to easily revisit old information, systematically explore new information, and quickly resume tasks after interruption. While applying these design principles have been successful in HCI contexts, direct encodings of personal interaction history have received scarce attention in data visualization. One reason is that there is little guidance for integrating history into visualizations where many visual channels are already occupied by data. More importantly, there is not firm evidence that making users aware of their interaction history results in benefits with regards to exploration or insights. Following these observations, we propose HindSight - an umbrella term for the design space of representing interaction history directly in existing data visualizations. In this paper, we examine the value of HindSight principles by augmenting existing visualizations with visual indicators of user interaction history (e.g. How the Recession Shaped the Economy in 255 Charts, NYTimes). In controlled experiments of over 400 participants, we found that HindSight designs generally encouraged people to visit more data and recall different insights after interaction. The results of our experiments suggest that simple additions to visualizations can make users aware of their interaction history, and that these additions significantly impact users' exploration and insights.",,Mi Feng;Cheng Deng;Evan M. Peck;Lane Harrison,Worcester Polytechnic Institute;Worcester Polytechnic Institute;Bucknell University;Worcester Polytechnic Institute,,"Visualization,Interaction,History,,,,",,9,,
InfoVis,2017,Immersive Collaborative Analysis of Network Connectivity: CAVE-style or Head-Mounted Display?,10.1109/TVCG.2016.2599107,http://dx.doi.org/10.1109/TVCG.2016.2599107,441,450,Journals & Magazines,"High-quality immersive display technologies are becoming mainstream with the release of head-mounted displays (HMDs) such as the Oculus Rift. These devices potentially represent an affordable alternative to the more traditional, centralised CAVE-style immersive environments. One driver for the development of CAVE-style immersive environments has been collaborative sense-making. Despite this, there has been little research on the effectiveness of collaborative visualisation in CAVE-style facilities, especially with respect to abstract data visualisation tasks. Indeed, very few studies have focused on the use of these displays to explore and analyse abstract data such as networks and there have been no formal user studies investigating collaborative visualisation of abstract data in immersive environments. In this paper we present the results of the first such study. It explores the relative merits of HMD and CAVE-style immersive environments for collaborative analysis of network connectivity, a common and important task involving abstract data. We find significant differences between the two conditions in task completion time and the physical movements of the participants within the space: participants using the HMD were faster while the CAVE2 condition introduced an asymmetry in movement between collaborators. Otherwise, affordances for collaborative data analysis offered by the low-cost HMD condition were not found to be different for accuracy and communication with the CAVE2. These results are notable, given that the latest HMDs will soon be accessible (in terms of cost and potentially ubiquity) to a massive audience.",,Maxime Cordeil;Tim Dwyer;Karsten Klein;Bireswar Laha;Kim Marriott;Bruce H. Thomas,"Monash University;Monash University;Monash University;Stanford University, USA;Monash University;University of South Australia",,"Oculus Rift,CAVE,Immersive Analytics,Collaboration,3D Network,,",,26,,
conference_external,2017,Visualization and Extraction of Carvings for Heritage Conservation,10.1109/TVCG.2016.2598603,http://dx.doi.org/10.1109/TVCG.2016.2598603,801,810,Journals & Magazines,"We present novel techniques for visualizing, illustrating, analyzing, and generating carvings in surfaces. In particular, we consider the carvings in the plaster of the cloister of the Magdeburg cathedral, which dates to the 13th century. Due to aging and weathering, the carvings have flattened. Historians and restorers are highly interested in using digitalization techniques to analyze carvings in historic artifacts and monuments and to get impressions and illustrations of their original shape and appearance. Moreover, museums and churches are interested in such illustrations for presenting them to visitors. The techniques that we propose allow for detecting, selecting, and visualizing carving structures. In addition, we introduce an example-based method for generating carvings. The resulting tool, which integrates all techniques, was evaluated by three experienced restorers to assess the usefulness and applicability. Furthermore, we compared our approach with exaggerated shading and other state-of-the-art methods.",,Kai Lawonn;Erik Trostmann;Bernhard Preim;Klaus Hildebrandt,"University of Koblenz-Landau, Germany;Fraunhofer Institute for Factory Operation and Automation IFF, Germany;University of Magdeburg, Germany;Delft University of Technology, The Netherlands",,"Feature extraction,heritage preservation,Frangi filter,surface analysis,feature filtering,,",,3,,
conference_external,2017,Visualizing the Hidden Activity of Artificial Neural Networks,10.1109/TVCG.2016.2598838,http://dx.doi.org/10.1109/TVCG.2016.2598838,101,110,Journals & Magazines,"In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles.",,Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falcão;Alexandru C. Telea,University of GroningenUniversity of Campinas;University of São Paulo;University of Campinas;University of Groningen,,"Artificial neural networks,dimensionality reduction,algorithm understanding,,,,",,35,,
conference_external,2017,Visual Analytics for Mobile Eye Tracking,10.1109/TVCG.2016.2598695,http://dx.doi.org/10.1109/TVCG.2016.2598695,301,310,Journals & Magazines,"The analysis of eye tracking data often requires the annotation of areas of interest (AOIs) to derive semantic interpretations of human viewing behavior during experiments. This annotation is typically the most time-consuming step of the analysis process. Especially for data from wearable eye tracking glasses, every independently recorded video has to be annotated individually and corresponding AOIs between videos have to be identified. We provide a novel visual analytics approach to ease this annotation process by image-based, automatic clustering of eye tracking data integrated in an interactive labeling and analysis system. The annotation and analysis are tightly coupled by multiple linked views that allow for a direct interpretation of the labeled data in the context of the recorded video stimuli. The components of our analytics environment were developed with a user-centered design approach in close cooperation with an eye tracking expert. We demonstrate our approach with eye tracking data from a real experiment and compare it to an analysis of the data by manual annotation of dynamic AOIs. Furthermore, we conducted an expert user study with 6 external eye tracking researchers to collect feedback and identify analysis strategies they used while working with our application.",,Kuno Kurzhals;Marcel Hlawatsch;Christof Seeger;Daniel Weiskopf,University of Stuttgart;University of Stuttgart;Stuttgart Media University;University of Stuttgart,,"Eye tracking,visual analytics,video visualization,,,,",,6,,
conference_external,2017,Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers,10.1109/TVCG.2016.2598828,http://dx.doi.org/10.1109/TVCG.2016.2598828,61,70,Journals & Magazines,"Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.",,Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams,"University of California, Santa Barbara;Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research",,"Performance analysis,classification,usable machine learning,,,,",,19,,
conference_external,2017,Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data,10.1109/TVCG.2016.2598430,http://dx.doi.org/10.1109/TVCG.2016.2598430,901,910,Journals & Magazines,"We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40%-50%.",,Daniel Jönsson;Anders Ynnerman,"Linköping University, Nörrköping, Sweden;Linköping University, Nörrköping, Sweden",,"Volume rendering,photon mapping,global illumination,participating media,,,",,1,,
conference_external,2017,Toward Theoretical Techniques for Measuring the Use of Human Effort in Visual Analytic Systems,10.1109/TVCG.2016.2598460,http://dx.doi.org/10.1109/TVCG.2016.2598460,121,130,Journals & Magazines,"Visual analytic systems have long relied on user studies and standard datasets to demonstrate advances to the state of the art, as well as to illustrate the efficiency of solutions to domain-specific challenges. This approach has enabled some important comparisons between systems, but unfortunately the narrow scope required to facilitate these comparisons has prevented many of these lessons from being generalized to new areas. At the same time, advanced visual analytic systems have made increasing use of human-machine collaboration to solve problems not tractable by machine computation alone. To continue to make progress in modeling user tasks in these hybrid visual analytic systems, we must strive to gain insight into what makes certain tasks more complex than others. This will require the development of mechanisms for describing the balance to be struck between machine and human strengths with respect to analytical tasks and workload. In this paper, we argue for the necessity of theoretical tools for reasoning about such balance in visual analytic systems and demonstrate the utility of the Human Oracle Model for this purpose in the context of sensemaking in visual analytics. Additionally, we make use of the Human Oracle Model to guide the development of a new system through a case study in the domain of cybersecurity.",,R. Jordan Crouser;Lyndsey Franklin;Alex Endert;Kris Cook,Smith College;Smith College;Smith College;Smith College,,"Theoretical models,human oracle,visual analytics,mixed initiative systems,semantic interaction,sensemaking,",,5,,
conference_external,2017,<italic>TextTile</italic>: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text,10.1109/TVCG.2016.2598447,http://dx.doi.org/10.1109/TVCG.2016.2598447,161,170,Journals & Magazines,"We describe TextTile, a data visualization tool for investigation of datasets and questions that require seamless and flexible analysis of structured data and unstructured text. TextTile is based on real-world data analysis problems gathered through our interaction with a number of domain experts and provides a general purpose solution to such problems. The system integrates a set of operations that can interchangeably be applied to the structured as well as to unstructured text part of the data to generate useful data summaries. Such summaries are then organized in visual tiles in a grid layout to allow their analysis and comparison. We validate TextTile with task analysis, use cases and a user study showing the system can be easily learned and proficiently used to carry out nontrivial tasks.",,Cristian Felix;Anshul Vikram Pandey;Enrico Bertini,New York University;New York University;New York University,,"Exploratory Text Analysis,Knowledge Discovery,Text Visualization,,,,",,5,,
InfoVis,2017,Vega-Lite: A Grammar of Interactive Graphics,10.1109/TVCG.2016.2599030,http://dx.doi.org/10.1109/TVCG.2016.2599030,341,350,Journals & Magazines,"We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.",,Arvind Satyanarayan;Dominik Moritz;Kanit Wongsuphasawat;Jeffrey Heer,Stanford University;University of Washington;University of Washington;University of Washington,,"Information visualization,interaction,systems,toolkits,declarative specification,,",,40,,
conference_external,2017,Hairy Slices: Evaluating the Perceptual Effectiveness of Cutting Plane Glyphs for 3D Vector Fields,10.1109/TVCG.2016.2598448,http://dx.doi.org/10.1109/TVCG.2016.2598448,990,999,Journals & Magazines,"Three-dimensional vector fields are common datasets throughout the sciences. Visualizing these fields is inherently difficult due to issues such as visual clutter and self-occlusion. Cutting planes are often used to overcome these issues by presenting more manageable slices of data. The existing literature provides many techniques for visualizing the flow through these cutting planes; however, there is a lack of empirical studies focused on the underlying perceptual cues that make popular techniques successful. This paper presents a quantitative human factors study that evaluates static monoscopic depth and orientation cues in the context of cutting plane glyph designs for exploring and analyzing 3D flow fields. The goal of the study was to ascertain the relative effectiveness of various techniques for portraying the direction of flow through a cutting plane at a given point, and to identify the visual cues and combinations of cues involved, and how they contribute to accurate performance. It was found that increasing the dimensionality of line-based glyphs into tubular structures enhances their ability to convey orientation through shading, and that increasing their diameter intensifies this effect. These tube-based glyphs were also less sensitive to visual clutter issues at higher densities. Adding shadows to lines was also found to increase perception of flow direction. Implications of the experimental results are discussed and extrapolated into a number of guidelines for designing more perceptually effective glyphs for 3D vector field visualizations.",,Andrew H. Stevens;Thomas Butkiewicz;Colin Ware,The Center for Coastal and Ocean MappingThe University of New Hampshire;The Center for Coastal and Ocean MappingThe University of New Hampshire;The Center for Coastal and Ocean MappingThe University of New Hampshire,,"Flow visualization,3D vector fields,Cutting planes,Glyphs,Perception,Evaluation,Human factors",,0,,
conference_external,2017,Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths,10.1109/TVCG.2016.2598797,http://dx.doi.org/10.1109/TVCG.2016.2598797,321,330,Journals & Magazines,"Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difficult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback.",,Zhicheng Liu;Yang Wang;Mira Dontcheva;Matthew Hoffman;Seth Walker;Alan Wilson,"Adobe Research;University of California, Davis;Adobe Research;Adobe Research;Adobe Research;Adobe Systems Inc.",,"Clickstream Data,sequence mining,visual analytics,event sequences,,,",,21,,
InfoVis,2017,Exploring the Possibilities of Embedding Heterogeneous Data Attributes in Familiar Visualizations,10.1109/TVCG.2016.2598586,http://dx.doi.org/10.1109/TVCG.2016.2598586,581,590,Journals & Magazines,"Heterogeneous multi-dimensional data are now sufficiently common that they can be referred to as ubiquitous. The most frequent approach to visualizing these data has been to propose new visualizations for representing these data. These new solutions are often inventive but tend to be unfamiliar. We take a different approach. We explore the possibility of extending well-known and familiar visualizations through including Heterogeneous Embedded Data Attributes (HEDA) in order to make familiar visualizations more powerful. We demonstrate how HEDA is a generic, interactive visualization component that can extend common visualization techniques while respecting the structure of the familiar layout. HEDA is a tabular visualization building block that enables individuals to visually observe, explore, and query their familiar visualizations through manipulation of embedded multivariate data. We describe the design space of HEDA by exploring its application to familiar visualizations in the D3 gallery. We characterize these familiar visualizations by the extent to which HEDA can facilitate data queries based on attribute reordering.",,Mona Hosseinkhani Loorak;Charles Perin;Christopher Collins;Sheelagh Carpendale,"Department of Computer Science, University of Calgary;Department of Computer Science, University of Calgary;University of Ontario;Department of Computer Science, University of Calgary",,"Multi-dimensional data,Hybrid visualization,,,,,",,5,,
conference_external,2017,Urban Pulse: Capturing the Rhythm of Cities,10.1109/TVCG.2016.2598585,http://dx.doi.org/10.1109/TVCG.2016.2598585,791,800,Journals & Magazines,"Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an “urban pulse” which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework.",,Fabio Miranda;Harish Doraiswamy;Marcos Lage;Kai Zhao;Bruno Gonçalves;Luc Wilson;Mondrian Hsieh;Cláudio T. Silva,New York University;New York University;Universidade Federal Fluminense;New York University;New York University;Kohn Pedersen Fox Associates PC;Kohn Pedersen Fox Associates PC;New York University,,"Topology-based techniques,urban data,visual exploration,,,,",,13,,
conference_external,2017,SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations,10.1109/TVCG.2016.2598432,http://dx.doi.org/10.1109/TVCG.2016.2598432,1,10,Journals & Magazines,"The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.",,Dongyu Liu;Di Weng;Yuhong Li;Jie Bao;Yu Zheng;Huamin Qu;Yingcai Wu,"Zhejiang UniversityHong Kong University of Science and Technology;State Key Lab of CAD & CGZhejiang University;University of Macau;Microsoft Research, Beijing, China;Microsoft Research, Beijing, China;Hong Kong University of Science and Technology;State Key Lab of CAD & CGZhejiang University",,"optimal billboard locations,taxi trajectory,visual analytics,comparative analysis,,,",,28,,
conference_external,2017,ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories,10.1109/TVCG.2016.2598664,http://dx.doi.org/10.1109/TVCG.2016.2598664,291,300,Journals & Magazines,"Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey's graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories.",,Panpan Xu;Honghui Mei;Liu Ren;Wei Chen,Bosch Research North America;Zhejiang University;Bosch Research North America;Zhejiang University,,"Temporal Data,Marey's Graph,Visual Analytics,Manufacturing,Smart Factory,Connected Industry,Industry 4.0",,16,,
conference_external,2017,In Situ Distribution Guided Analysis and Visualization of Transonic Jet Engine Simulations,10.1109/TVCG.2016.2598604,http://dx.doi.org/10.1109/TVCG.2016.2598604,811,820,Journals & Magazines,"Study of flow instability in turbine engine compressors is crucial to understand the inception and evolution of engine stall. Aerodynamics experts have been working on detecting the early signs of stall in order to devise novel stall suppression technologies. A state-of-the-art Navier-Stokes based, time-accurate computational fluid dynamics simulator, TURBO, has been developed in NASA to enhance the understanding of flow phenomena undergoing rotating stall. Despite the proven high modeling accuracy of TURBO, the excessive simulation data prohibits post-hoc analysis in both storage and I/O time. To address these issues and allow the expert to perform scalable stall analysis, we have designed an in situ distribution guided stall analysis technique. Our method summarizes statistics of important properties of the simulation data in situ using a probabilistic data modeling scheme. This data summarization enables statistical anomaly detection for flow instability in post analysis, which reveals the spatiotemporal trends of rotating stall for the expert to conceive new hypotheses. Furthermore, the verification of the hypotheses and exploratory visualization using the summarized data are realized using probabilistic visualization techniques such as uncertain isocontouring. Positive feedback from the domain scientist has indicated the efficacy of our system in exploratory stall analysis.",,Soumya Dutta;Chun-Ming Chen;Gregory Heinlein;Han-Wei Shen;Jen-Ping Chen,"The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Mechanical and Aerospace Engineering, The Ohio State University;The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Mechanical and Aerospace Engineering, The Ohio State University",,"In situ analysis,rotating stall analysis,Gaussian mixture model,incremental distribution modeling,feature analysis,high performance computing,collaborative development",,6,,
conference_external,2017,Visualizing Dimension Coverage to Support Exploratory Analysis,10.1109/TVCG.2016.2598466,http://dx.doi.org/10.1109/TVCG.2016.2598466,21,30,Journals & Magazines,"Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.",,Ali Sarvghad;Melanie Tory;Narges Mahyar,University of Victoria;Tableau Research;University of British Columbia,,"Dimension coverage,Tabular data,History,Empirical laboratory study,Exploratory data analysis,Scented widgets,",,10,,
InfoVis,2017,Visplause: Visual Data Quality Assessment of Many Time Series Using Plausibility Checks,10.1109/TVCG.2016.2598592,http://dx.doi.org/10.1109/TVCG.2016.2598592,641,650,Journals & Magazines,"Trends like decentralized energy production lead to an exploding number of time series from sensors and other sources that need to be assessed regarding their data quality (DQ). While the identification of DQ problems for such routinely collected data is typically based on existing automated plausibility checks, an efficient inspection and validation of check results for hundreds or thousands of time series is challenging. The main contribution of this paper is the validated design of Visplause, a system to support an efficient inspection of DQ problems for many time series. The key idea of Visplause is to utilize meta-information concerning the semantics of both the time series and the plausibility checks for structuring and summarizing results of DQ checks in a flexible way. Linked views enable users to inspect anomalies in detail and to generate hypotheses about possible causes. The design of Visplause was guided by goals derived from a comprehensive task analysis with domain experts in the energy sector. We reflect on the design process by discussing design decisions at four stages and we identify lessons learned. We also report feedback from domain experts after using Visplause for a period of one month. This feedback suggests significant efficiency gains for DQ assessment, increased confidence in the DQ, and the applicability of Visplause to summarize indicators also outside the context of DQ.",,Clemens Arbesser;Florian Spechtenhauser;Thomas Mühlbacher;Harald Piringer,"VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria",,"Data Quality Assessment,High-Dimensional Data,Hierarchical Aggregation,Linked Views,,,",,8,,
InfoVis,2017,Investigating the Use of a Dynamic Physical Bar Chart for Data Exploration and Presentation,10.1109/TVCG.2016.2598498,http://dx.doi.org/10.1109/TVCG.2016.2598498,451,460,Journals & Magazines,"Physical data representations, or data physicalizations, are a promising new medium to represent and communicate data. Previous work mostly studied passive physicalizations which require humans to perform all interactions manually. Dynamic shape-changing displays address this limitation and facilitate data exploration tasks such as sorting, navigating in data sets which exceed the fixed size of a given physical display, or preparing “views” to communicate insights about data. However, it is currently unclear how people approach and interact with such data representations. We ran an exploratory study to investigate how non-experts made use of a dynamic physical bar chart for an open-ended data exploration and presentation task. We asked 16 participants to explore a data set on European values and to prepare a short presentation of their insights using a physical display. We analyze: (1) users' body movements to understand how they approach and react to the physicalization, (2) their hand-gestures to understand how they interact with physical data, (3) system interactions to understand which subsets of the data they explored and which features they used in the process, and (4) strategies used to explore the data and present observations. We discuss the implications of our findings for the use of dynamic data physicalizations and avenues for future work.",,Faisal Taher;Yvonne Jansen;Jonathan Woodruff;John Hardy;Kasper Hornbæk;Jason Alexander,Lancaster University;University of Copenhagen;Lancaster University;Lancaster University;University of Copenhagen;Lancaster University,,"Shape-changing displays,physicalization,physical visualization,bar charts,user behaviour,data presentation,",,5,,
InfoVis,2017,booc.io: An Education System with Hierarchical Concept Maps and Dynamic Non-linear Learning Plans,10.1109/TVCG.2016.2598518,http://dx.doi.org/10.1109/TVCG.2016.2598518,571,580,Journals & Magazines,"Information hierarchies are difficult to express when real-world space or time constraints force traversing the hierarchy in linear presentations, such as in educational books and classroom courses. We present booc.io, which allows linear and non-linear presentation and navigation of educational concepts and material. To support a breadth of material for each concept, booc.io is Web based, which allows adding material such as lecture slides, book chapters, videos, and LTIs. A visual interface assists the creation of the needed hierarchical structures. The goals of our system were formed in expert interviews, and we explain how our design meets these goals. We adapt a real-world course into booc.io, and perform introductory qualitative evaluation with students.",,Michail Schwab;Hendrik Strobelt;James Tompkin;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister,Harvard Paulson SEAS;Harvard Paulson SEAS;Harvard Paulson SEAS;HarvardX;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Paulson SEAS,,"Hierarchies,information visualization,education,,,,",,3,,
conference_external,2017,Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis,10.1109/TVCG.2016.2598495,http://dx.doi.org/10.1109/TVCG.2016.2598495,241,250,Journals & Magazines,"Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a “human in the loop” process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.",,Dominik Sacha;Leishi Zhang;Michael Sedlmair;John A. Lee;Jaakko Peltonen;Daniel Weiskopf;Stephen C. North;Daniel A. Keim,"University of Konstanz, Germany;Middlesex University, UK;University of Vienna, Austria;SSS, IREC, MIRO, Université catholique de LouvainUCLBelgian F.R.S.-FNRS.;Helsinki Institute for Information Technology HIIT, Aalto University, University of Tampere, Finland;University of Konstanz, Germany;Infovisible LLC, Oldwick, U.S.A.;VISUS, University of Stuttgart, Germany",,"Interactive visualization,machine learning,visual analytics,dimensionality reduction,,,",,33,,
conference_external,2017,What do Constraint Programming Users Want to See? Exploring the Role of Visualisation in Profiling of Models and Search,10.1109/TVCG.2016.2598545,http://dx.doi.org/10.1109/TVCG.2016.2598545,281,290,Journals & Magazines,"Constraint programming allows difficult combinatorial problems to be modelled declaratively and solved automatically. Advances in solver technologies over recent years have allowed the successful use of constraint programming in many application areas. However, when a particular solver's search for a solution takes too long, the complexity of the constraint program execution hinders the programmer's ability to profile that search and understand how it relates to their model. Therefore, effective tools to support such profiling and allow users of constraint programming technologies to refine their model or experiment with different search parameters are essential. This paper details the first user-centred design process for visual profiling tools in this domain. We report on: our insights and opportunities identified through an on-line questionnaire and a creativity workshop with domain experts carried out to elicit requirements for analytical and visual profiling techniques; our designs and functional prototypes realising such techniques; and case studies demonstrating how these techniques shed light on the behaviour of the solvers in practice.",,Sarah Goodwin;Christopher Mears;Tim Dwyer;Maria Garcia de la Banda;Guido Tack;Mark Wallace,"Adaptive Visualisation LabMonash University;Faculty of Information Technology, Monash University;Adaptive Visualisation LabMonash University;Faculty of Information Technology, Monash University;Faculty of Information Technology, Monash University;Faculty of Information Technology, Monash University",,"visual analytics,user-centred design,profiling,constraint programming,tree visualisations,,",,8,,
conference_external,2017,<italic>VLAT</italic>: Development of a Visualization Literacy Assessment Test,10.1109/TVCG.2016.2598920,http://dx.doi.org/10.1109/TVCG.2016.2598920,551,560,Journals & Magazines,"The Information Visualization community has begun to pay attention to visualization literacy; however, researchers still lack instruments for measuring the visualization literacy of users. In order to address this gap, we systematically developed a visualization literacy assessment test (VLAT), especially for non-expert users in data visualization, by following the established procedure of test development in Psychological and Educational Measurement: (1) Test Blueprint Construction, (2) Test Item Generation, (3) Content Validity Evaluation, (4) Test Tryout and Item Analysis, (5) Test Item Selection, and (6) Reliability Evaluation. The VLAT consists of 12 data visualizations and 53 multiple-choice test items that cover eight data visualization tasks. The test items in the VLAT were evaluated with respect to their essentialness by five domain experts in Information Visualization and Visual Analytics (average content validity ratio = 0.66). The VLAT was also tried out on a sample of 191 test takers and showed high reliability (reliability coefficient omega = 0.76). In addition, we demonstrated the relationship between users' visualization literacy and aptitude for learning an unfamiliar visualization and showed that they had a fairly high positive relationship (correlation coefficient = 0.64). Finally, we discuss evidence for the validity of the VLAT and potential research areas that are related to the instrument.",,Sukwon Lee;Sung-Hee Kim;Bum Chul Kwon,"School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Samsung Electronics Co., Ltd., Seoul, South Korea;IBM T.J. Watson Research Center, Yorktown Heights, NY, USA",,"Visualization Literacy,Assessment Test,Instrument,Measurement,Aptitude,Education,",,7,,
conference_external,2017,Backward Finite-Time Lyapunov Exponents in Inertial Flows,10.1109/TVCG.2016.2599016,http://dx.doi.org/10.1109/TVCG.2016.2599016,970,979,Journals & Magazines,"Inertial particles are finite-sized objects that are carried by fluid flows and in contrast to massless tracer particles they are subject to inertia effects. In unsteady flows, the dynamics of tracer particles have been extensively studied by the extraction of Lagrangian coherent structures (LCS), such as hyperbolic LCS as ridges of the Finite-Time Lyapunov Exponent (FTLE). The extension of the rich LCS framework to inertial particles is currently a hot topic in the CFD literature and is actively under research. Recently, backward FTLE on tracer particles has been shown to correlate with the preferential particle settling of small inertial particles. For larger particles, inertial trajectories may deviate strongly from (massless) tracer trajectories, and thus for a better agreement, backward FTLE should be computed on inertial trajectories directly. Inertial backward integration, however, has not been possible until the recent introduction of the influence curve concept, which - given an observation and an initial velocity - allows to recover all sources of inertial particles as tangent curves of a derived vector field. In this paper, we show that FTLE on the influence curve vector field is in agreement with preferential particle settling and more importantly it is not only valid for small (near-tracer) particles. We further generalize the influence curve concept to general equations of motion in unsteady spatio-velocity phase spaces, which enables backward integration with more general equations of motion. Applying the influence curve concept to tracer particles in the spatio-velocity domain emits streaklines in massless flows as tangent curves of the influence curve vector field. We demonstrate the correlation between inertial backward FTLE and the preferential particle settling in a number of unsteady vector fields",,Tobias Günther;Holger Theisel,"Visual Computing Group, University of Magdeburg;Visual Computing Group, University of Magdeburg",,"Inertial particles,finite-time Lyapunov exponents,backward integration,preferential particle settling,,,",,1,,
conference_external,2017,Designing Progressive and Interactive Analytics Processes for High-Dimensional Data Analysis,10.1109/TVCG.2016.2598470,http://dx.doi.org/10.1109/TVCG.2016.2598470,131,140,Journals & Magazines,"In interactive data analysis processes, the dialogue between the human and the computer is the enabling mechanism that can lead to actionable observations about the phenomena being investigated. It is of paramount importance that this dialogue is not interrupted by slow computational mechanisms that do not consider any known temporal human-computer interaction characteristics that prioritize the perceptual and cognitive capabilities of the users. In cases where the analysis involves an integrated computational method, for instance to reduce the dimensionality of the data or to perform clustering, such non-optimal processes are often likely. To remedy this, progressive computations, where results are iteratively improved, are getting increasing interest in visual analytics. In this paper, we present techniques and design considerations to incorporate progressive methods within interactive analysis processes that involve high-dimensional data. We define methodologies to facilitate processes that adhere to the perceptual characteristics of users and describe how online algorithms can be incorporated within these. A set of design recommendations and according methods to support analysts in accomplishing high-dimensional data analysis tasks are then presented. Our arguments and decisions here are informed by observations gathered over a series of analysis sessions with analysts from finance. We document observations and recommendations from this study and present evidence on how our approach contribute to the efficiency and productivity of interactive visual analysis sessions involving high-dimensional data.",,Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser,"City University, London, UK;Sabanci University, Turkey;Sabanci University, Turkey;University of Bergen, Norway",,"Progressive analytics,high dimensional data,iterative refinement,visual analytics,,,",,16,,
InfoVis,2017,Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation,10.1109/TVCG.2016.2598885,http://dx.doi.org/10.1109/TVCG.2016.2598885,411,420,Journals & Magazines,"Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar.",,Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott,"Monash University, Data61, CSIRO, Victoria;Monash University;Monash University;Monash University, Data61, CSIRO, Victoria",,"Flow Maps,Matrix Visualisation,Cartographic Information Visualisation,,,,",,16,,
InfoVis,2017,Colorgorical: Creating discriminable and preferable color palettes for information visualization,10.1109/TVCG.2016.2598918,http://dx.doi.org/10.1109/TVCG.2016.2598918,521,530,Journals & Magazines,"We present an evaluation of Colorgorical, a web-based tool for creating discriminable and aesthetically preferable categorical color palettes. Colorgorical uses iterative semi-random sampling to pick colors from CIELAB space based on user-defined discriminability and preference importances. Colors are selected by assigning each a weighted sum score that applies the user-defined importances to Perceptual Distance, Name Difference, Name Uniqueness, and Pair Preference scoring functions, which compare a potential sample to already-picked palette colors. After, a color is added to the palette by randomly sampling from the highest scoring palettes. Users can also specify hue ranges or build off their own starting palettes. This procedure differs from previous approaches that do not allow customization (e.g., pre-made ColorBrewer palettes) or do not consider visualization design constraints (e.g., Adobe Color and ACE). In a Palette Score Evaluation, we verified that each scoring function measured different color information. Experiment 1 demonstrated that slider manipulation generates palettes that are consistent with the expected balance of discriminability and aesthetic preference for 3-, 5-, and 8-color palettes, and also shows that the number of colors may change the effectiveness of pair-based discriminability and preference scores. For instance, if the Pair Preference slider were upweighted, users would judge the palettes as more preferable on average. Experiment 2 compared Colorgorical palettes to benchmark palettes (ColorBrewer, Microsoft, Tableau, Random). Colorgorical palettes are as discriminable and are at least as preferable or more preferable than the alternative palette sets. In sum, Colorgorical allows users to make customized color palettes that are, on average, as effective as current industry standards by balancing the importance of discriminability and aesthetic preference.",,Connor C. Gramazio;David H. Laidlaw;Karen B. Schloss,"Dept. of Computer Science at Brown University;Dept. of Computer Science at Brown University;Dept. of Cognitive, Linguistic, and Psychological Sciences at Brown University",,"Aesthetics in Visualization,Color Perception,Metrics & Benchmarks,Visual Design,Visualization,,",,11,,
conference_external,2017,An Analysis of Machine- and Human-Analytics in Classification,10.1109/TVCG.2016.2598829,http://dx.doi.org/10.1109/TVCG.2016.2598829,71,80,Journals & Magazines,"In this work, we present a study that traces the technical and cognitive processes in two visual analytics applications to a common theoretic model of soft knowledge that may be added into a visual analytics process for constructing a decision-tree model. Both case studies involved the development of classification models based on the “bag of features” approach. Both compared a visual analytics approach using parallel coordinates with a machine-learning approach using information theory. Both found that the visual analytics approach had some advantages over the machine learning approach, especially when sparse datasets were used as the ground truth. We examine various possible factors that may have contributed to such advantages, and collect empirical evidence for supporting the observation and reasoning of these factors. We propose an information-theoretic model as a common theoretic basis to explain the phenomena exhibited in these two case studies. Together we provide interconnected empirical and theoretical evidence to support the usefulness of visual analytics.",,Gary K. L. Tam;Vivek Kothari;Min Chen,Swansea University;University of Oxford;University of Oxford,,"Visual analytics,classification,decision tree,model,facial expression,visualization image,information theory",,15,,
conference_external,2017,Comparing Cross-Sections and 3D Renderings for Surface Matching Tasks Using Physical Ground Truths,10.1109/TVCG.2016.2598602,http://dx.doi.org/10.1109/TVCG.2016.2598602,781,790,Journals & Magazines,"Within the visualization community there are some well-known techniques for visualizing 3D spatial data and some general assumptions about how perception affects the performance of these techniques in practice. However, there is a lack of empirical research backing up the possible performance differences among the basic techniques for general tasks. One such assumption is that 3D renderings are better for obtaining an overview, whereas cross sectional visualizations such as the commonly used Multi-Planar Reformation (MPR) are better for supporting detailed analysis tasks. In the present study we investigated this common assumption by examining the difference in performance between MPR and 3D rendering for correctly identifying a known surface. We also examined whether prior experience working with image data affects the participant's performance, and whether there was any difference between interactive or static versions of the visualizations. Answering this question is important because it can be used as part of a scientific and empirical basis for determining when to use which of the two techniques. An advantage of the present study compared to other studies is that several factors were taken into account to compare the two techniques. The problem was examined through an experiment with 45 participants, where physical objects were used as the known surface (ground truth). Our findings showed that: 1. The 3D renderings largely outperformed the cross sections; 2. Interactive visualizations were partially more effective than static visualizations; and 3. The high experience group did not generally outperform the low experience group.",,Andreas J. Lind;Stefan Bruckner,"University of Bergen, Norway;University of Bergen, Norway",,"Human-Computer Interaction,Quantitative Evaluation and Volume Visualization,,,,,",,1,,
conference_external,2017,Decal-Maps: Real-Time Layering of Decals on Surfaces for Multivariate Visualization,10.1109/TVCG.2016.2598866,http://dx.doi.org/10.1109/TVCG.2016.2598866,821,830,Journals & Magazines,"We introduce the use of decals for multivariate visualization design. Decals are visual representations that are used for communication; for example, a pattern, a text, a glyph, or a symbol, transferred from a 2D-image to a surface upon contact. By creating what we define as decal-maps, we can design a set of images or patterns that represent one or more data attributes. We place decals on the surface considering the data pertaining to the locations we choose. We propose a (texture mapping) local parametrization that allows placing decals on arbitrary surfaces interactively, even when dealing with a high number of decals. Moreover, we extend the concept of layering to allow the co-visualization of an increased number of attributes on arbitrary surfaces. By combining decal-maps, color-maps and a layered visualization, we aim to facilitate and encourage the creative process of designing multivariate visualizations. Finally, we demonstrate the general applicability of our technique by providing examples of its use in a variety of contexts.",,Allan Rocha;Usman Alim;Julio Daniel Silva;Mario Costa Sousa,University of Calgary;University of Calgary;University of Calgary;University of Calgary,,"Multivariate,Visualization,Real-time,Decal,Surface,Layering,Design",,4,,
conference_external,2017,VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model,10.1109/TVCG.2016.2598497,http://dx.doi.org/10.1109/TVCG.2016.2598497,251,260,Journals & Magazines,"Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.",,Bowen Yu;Cláudio T. Silva,New York University;New York University,,"Visualization framework,data flow,subset flow model,tabular data,,,",,5,,
InfoVis,2017,PROACT: Iterative Design of a Patient-Centered Visualization for Effective Prostate Cancer Health Risk Communication,10.1109/TVCG.2016.2598588,http://dx.doi.org/10.1109/TVCG.2016.2598588,601,610,Journals & Magazines,"Prostate cancer is the most common cancer among men in the US, and yet most cases represent localized cancer for which the optimal treatment is unclear. Accumulating evidence suggests that the available treatment options, including surgery and conservative treatment, result in a similar prognosis for most men with localized prostate cancer. However, approximately 90% of patients choose surgery over conservative treatment, despite the risk of severe side effects like erectile dysfunction and incontinence. Recent medical research suggests that a key reason is the lack of patient-centered tools that can effectively communicate personalized risk information and enable them to make better health decisions. In this paper, we report the iterative design process and results of developing the PROgnosis Assessment for Conservative Treatment (PROACT) tool, a personalized health risk communication tool for localized prostate cancer patients. PROACT utilizes two published clinical prediction models to communicate the patients' personalized risk estimates and compare treatment options. In collaboration with the Maine Medical Center, we conducted two rounds of evaluations with prostate cancer survivors and urologists to identify the design elements and narrative structure that effectively facilitate patient comprehension under emotional distress. Our results indicate that visualization can be an effective means to communicate complex risk information to patients with low numeracy and visual literacy. However, the visualizations need to be carefully chosen to balance readability with ease of comprehension. In addition, due to patients' charged emotional state, an intuitive narrative structure that considers the patients' information need is critical to aid the patients' comprehension of their risk information.",,Anzu Hakone;Lane Harrison;Alvitta Ottley;Nathan Winters;Caitlin Gutheil;Paul K. J. Han;Remco Chang,Tufts University;Worcester Polytechnic Institute;Tufts University;Tufts University;Maine Medical Center;Maine Medical Center;Tufts University,,"Design studies,task and requirement analysis,presentation,production,and dissemination,medical visualization,",,3,,
conference_external,2017,A Fractional Cartesian Composition Model for Semi-Spatial Comparative Visualization Design,10.1109/TVCG.2016.2598870,http://dx.doi.org/10.1109/TVCG.2016.2598870,851,860,Journals & Magazines,"The study of spatial data ensembles leads to substantial visualization challenges in a variety of applications. In this paper, we present a model for comparative visualization that supports the design of according ensemble visualization solutions by partial automation. We focus on applications, where the user is interested in preserving selected spatial data characteristics of the data as much as possible-even when many ensemble members should be jointly studied using comparative visualization. In our model, we separate the design challenge into a minimal set of user-specified parameters and an optimization component for the automatic configuration of the remaining design variables. We provide an illustrated formal description of our model and exemplify our approach in the context of several application examples from different domains in order to demonstrate its generality within the class of comparative visualization problems for spatial data ensembles.",,Ivan Kolesár;Stefan Bruckner;Ivan Viola;Helwig Hauser,"Department of Informatics, University of Bergen, Norway;Department of Informatics, University of Bergen, Norway;TU Wien, Austria;Department of Informatics, University of Bergen, Norway",,"Visualization Models,Integrating Spatial and Non-Spatial Data Visualization,Design Methodologies,,,,",,3,,
InfoVis,2017,Evaluation of Graph Sampling: A Visualization Perspective,10.1109/TVCG.2016.2598867,http://dx.doi.org/10.1109/TVCG.2016.2598867,401,410,Journals & Magazines,"Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies.",,Yanhong Wu;Nan Cao;Daniel Archambault;Qiaomu Shen;Huamin Qu;Weiwei Cui,"Hong Kong University of Science and Technology;New York University, Shanghai;Swansea University;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research Asia",,"Graph visualization,graph sampling,empirical evaluation,,,,",,11,,
conference_external,2017,Corresponding Supine and Prone Colon Visualization Using Eigenfunction Analysis and Fold Modeling,10.1109/TVCG.2016.2598791,http://dx.doi.org/10.1109/TVCG.2016.2598791,751,760,Journals & Magazines,"We present a method for registration and visualization of corresponding supine and prone virtual colonoscopy scans based on eigenfunction analysis and fold modeling. In virtual colonoscopy, CT scans are acquired with the patient in two positions, and their registration is desirable so that physicians can corroborate findings between scans. Our algorithm performs this registration efficiently through the use of Fiedler vector representation (the second eigenfunction of the Laplace-Beltrami operator). This representation is employed to first perform global registration of the two colon positions. The registration is then locally refined using the haustral folds, which are automatically segmented using the 3D level sets of the Fiedler vector. The use of Fiedler vectors and the segmented folds presents a precise way of visualizing corresponding regions across datasets and visual modalities. We present multiple methods of visualizing the results, including 2D flattened rendering and the corresponding 3D endoluminal views. The precise fold modeling is used to automatically find a suitable cut for the 2D flattening, which provides a less distorted visualization. Our approach is robust, and we demonstrate its efficiency and efficacy by showing matched views on both the 2D flattened colons and in the 3D endoluminal view. We analytically evaluate the results by measuring the distance between features on the registered colons, and we also assess our fold segmentation against 20 manually labeled datasets. We have compared our results analytically to previous methods, and have found our method to achieve superior results. We also prove the hot spots conjecture for modeling cylindrical topology using Fiedler vector representation, which allows our approach to be used for general cylindrical geometry modeling and feature extraction.",,Saad Nadeem;Joseph Marino;Xianfeng Gu;Arie Kaufman,"Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY",,"Medical visualization,colon registration,geometry-based techniques,mathematical foundations for visualization,,,",,5,,
InfoVis,2017,Map LineUps: Effects of spatial structure on graphical inference,10.1109/TVCG.2016.2598862,http://dx.doi.org/10.1109/TVCG.2016.2598862,391,400,Journals & Magazines,"Fundamental to the effective use of visualization as an analytic and descriptive tool is the assurance that presenting data visually provides the capability of making inferences from what we see. This paper explores two related approaches to quantifying the confidence we may have in making visual inferences from mapped geospatial data. We adapt Wickham et al.'s `Visual Line-up' method as a direct analogy with Null Hypothesis Significance Testing (NHST) and propose a new approach for generating more credible spatial null hypotheses. Rather than using as a spatial null hypothesis the unrealistic assumption of complete spatial randomness, we propose spatially autocorrelated simulations as alternative nulls. We conduct a set of crowdsourced experiments (n=361) to determine the just noticeable difference (JND) between pairs of choropleth maps of geographic units controlling for spatial autocorrelation (Moran's I statistic) and geometric configuration (variance in spatial unit area). Results indicate that people's abilities to perceive differences in spatial autocorrelation vary with baseline autocorrelation structure and the geometric configuration of geographic units. These results allow us, for the first time, to construct a visual equivalent of statistical power for geospatial data. Our JND results add to those provided in recent years by Klippel et al. (2011), Harrison et al. (2014) and Kay &amp;amp; Heer (2015) for correlation visualization. Importantly, they provide an empirical basis for an improved construction of visual line-ups for maps and the development of theory to inform geospatial tests of graphical inference.",,Roger Beecham;Jason Dykes;Wouter Meulemans;Aidan Slingsby;Cagatay Turkay;Jo Wood,"giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London",,"Graphical inference,spatial autocorrelation,just noticeable difference,geovisualization,statistical significance,,",,10,,
conference_external,2017,Progressive Direct Volume-to-Volume Transformation,10.1109/TVCG.2016.2599042,http://dx.doi.org/10.1109/TVCG.2016.2599042,921,930,Journals & Magazines,"We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. We finally demonstrate the utility of our technique for different applications, compare our approach against alternatives, and evaluate its characteristics with a variety of different data sets.",,Steffen Frey;Thomas Ertl,University of Stuttgart;University of Stuttgart,,"Volume transformation,Volume visualization,progressive,automatic,parallel,time-varying data,streaming data",,2,,
conference_external,2017,<bold>AnaFe</bold>: Visual<bold>Anal</bold>ytics of Image-derived Temporal<bold>Fe</bold>atures—Focusing on the Spleen,10.1109/TVCG.2016.2598463,http://dx.doi.org/10.1109/TVCG.2016.2598463,171,180,Journals & Magazines,"We present a novel visualization framework, AnaFe, targeted at observing changes in the spleen over time through multiple image-derived features. Accurate monitoring of progressive changes is crucial for diseases that result in enlargement of the organ. Our system is comprised of multiple linked views combining visualization of temporal 3D organ data, related measurements, and features. Thus it enables the observation of progression and allows for simultaneous comparison within and between the subjects. AnaFe offers insights into the overall distribution of robustly extracted and reproducible quantitative imaging features and their changes within the population, and also enables detailed analysis of individual cases. It performs similarity comparison of temporal series of one subject to all other series in both sick and healthy groups. We demonstrate our system through two use case scenarios on a population of 189 spleen datasets from 68 subjects with various conditions observed over time.",,Ievgeniia Gutenko;Konstantin Dmitriev;Arie E. Kaufman;Matthew A. Barish,"Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY",,"Visual Knowledge Discovery,Temporal Feature Analysis,Radiomics,Spleen,Abdominal Imaging,,",,0,,
conference_external,2017,AxiSketcher: Interactive Nonlinear Axis Mapping of Visualizations through User Drawings,10.1109/TVCG.2016.2598446,http://dx.doi.org/10.1109/TVCG.2016.2598446,221,230,Journals & Magazines,"Visual analytics techniques help users explore high-dimensional data. However, it is often challenging for users to express their domain knowledge in order to steer the underlying data model, especially when they have little attribute-level knowledge. Furthermore, users' complex, high-level domain knowledge, compared to low-level attributes, posits even greater challenges. To overcome these challenges, we introduce a technique to interpret a user's drawings with an interactive, nonlinear axis mapping approach called AxiSketcher. This technique enables users to impose their domain knowledge on a visualization by allowing interaction with data entries rather than with data attributes. The proposed interaction is performed through directly sketching lines over the visualization. Using this technique, users can draw lines over selected data points, and the system forms the axes that represent a nonlinear, weighted combination of multidimensional attributes. In this paper, we describe our techniques in three areas: 1) the design space of sketching methods for eliciting users' nonlinear domain knowledge; 2) the underlying model that translates users' input, extracts patterns behind the selected data points, and results in nonlinear axes reflecting users' complex intent; and 3) the interactive visualization for viewing, assessing, and reconstructing the newly formed, nonlinear axes.",,Bum Chul Kwon;Hannah Kim;Emily Wall;Jaegul Choo;Haesun Park;Alex Endert,"IBM T.J. Watson Research Center, Yorktown Heights, NY, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Korea University, Seoul, South Korea;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA",,"axis mapping,interactive model steering,sketch,axis visualization,human-centered visual analytics,,",,11,,
InfoVis,2017,Visualizing Social Media Content with SentenTree,10.1109/TVCG.2016.2598590,http://dx.doi.org/10.1109/TVCG.2016.2598590,621,630,Journals & Magazines,"We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.",,Mengdie Hu;Krist Wongsuphasawat;John Stasko,Georgia Institute of Technology;Twitter Inc.;Georgia Institute of Technology,,"text visualization,social media,natural language processing,word cloud,Twitter,,",,11,,
InfoVis,2017,cite2vec: Citation-Driven Document Exploration via Word Embeddings,10.1109/TVCG.2016.2598667,http://dx.doi.org/10.1109/TVCG.2016.2598667,691,700,Journals & Magazines,"Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme - cite2vec - that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/document compositions and document:phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-specified concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization.",,Matthew Berger;Katherine McDonough;Lee M. Seversky,Air Force Research Laboratory;Northeastern University;Air Force Research Laboratory,,"document visualization,word embeddings,,,,,",,8,,
conference_external,2017,A Versatile and Efficient GPU Data Structure for Spatial Indexing,10.1109/TVCG.2016.2599043,http://dx.doi.org/10.1109/TVCG.2016.2599043,911,920,Journals & Magazines,"In this paper we present a novel GPU-based data structure for spatial indexing. Based on Fenwick trees-a special type of binary indexed trees-our data structure allows construction in linear time. Updates and prefixes can be computed in logarithmic time, whereas point queries require only constant time on average. Unlike competing data structures such as summed-area tables and spatial hashing, our data structure requires a constant amount of bits for each data element, and it offers unconstrained point queries. This property makes our data structure ideally suited for applications requiring unconstrained indexing of large data, such as block-storage of large and block-sparse volumes. Finally, we provide asymptotic bounds on both run-time and memory requirements, and we show applications for which our new data structure is useful.",,Jens Schneider;Peter Rautek,Visual Computing Center(VCC)King Abdullah University of Science and Technology (KAUST);Visual Computing Center(VCC)King Abdullah University of Science and Technology (KAUST),,"GPU-based Data Structures,Binary Index Trees,Sparse Data,,,,",,0,,
conference_external,2017,Visualization of Time-Varying Weather Ensembles across Multiple Resolutions,10.1109/TVCG.2016.2598869,http://dx.doi.org/10.1109/TVCG.2016.2598869,841,850,Journals & Magazines,"Uncertainty quantification in climate ensembles is an important topic for the domain scientists, especially for decision making in the real-world scenarios. With powerful computers, simulations now produce time-varying and multi-resolution ensemble data sets. It is of extreme importance to understand the model sensitivity given the input parameters such that more computation power can be allocated to the parameters with higher influence on the output. Also, when ensemble data is produced at different resolutions, understanding the accuracy of different resolutions helps the total time required to produce a desired quality solution with improved storage and computation cost. In this work, we propose to tackle these non-trivial problems on the Weather Research and Forecasting (WRF) model output. We employ a moment independent sensitivity measure to quantify and analyze parameter sensitivity across spatial regions and time domain. A comparison of clustering structures across three resolutions enables the users to investigate the sensitivity variation over the spatial regions of the five input parameters. The temporal trend in the sensitivity values is explored via an MDS view linked with a line chart for interactive brushing. The spatial and temporal views are connected to provide a full exploration system for complete spatio-temporal sensitivity analysis. To analyze the accuracy across varying resolutions, we formulate a Bayesian approach to identify which regions are better predicted at which resolutions compared to the observed precipitation. This information is aggregated over the time domain and finally encoded in an output image through a custom color map that guides the domain experts towards an adaptive grid implementation given a cost model. Users can select and further analyze the spatial and temporal error patterns for multi-resolution accuracy analysis via brushing and linking on the produced image. In this work, we collaborate with a domain expert whose feedback shows the effectiveness of our proposed exploration work-flow.",,Ayan Biswas;Guang Lin;Xiaotong Liu;Han-Wei Shen,"GRAVITY group, The Ohio State University;Purdue University;GRAVITY group, The Ohio State University;GRAVITY group, The Ohio State University",,"Ensemble,time-varying,multi-resolution,sensitivity analysis,,,",,7,,
InfoVis,2017,"Hashedcubes: Simple, Low Memory, Real-Time Visual Exploration of Big Data",10.1109/TVCG.2016.2598624,http://dx.doi.org/10.1109/TVCG.2016.2598624,671,680,Journals & Magazines,"We propose Hashedcubes, a data structure that enables real-time visual exploration of large datasets that improves the state of the art by virtue of its low memory requirements, low query latencies, and implementation simplicity. In some instances, Hashedcubes notably requires two orders of magnitude less space than recent data cube visualization proposals. In this paper, we describe the algorithms to build and query Hashedcubes, and how it can drive well-known interactive visualizations such as binned scatterplots, linked histograms and heatmaps. We report memory usage, build time and query latencies for a variety of synthetic and real-world datasets, and find that although sometimes Hashedcubes offers slightly slower querying times to the state of the art, the typical query is answered fast enough to easily sustain a interaction. In datasets with hundreds of millions of elements, only about 2% of the queries take longer than 40ms. Finally, we discuss the limitations of data structure, potential spacetime tradeoffs, and future research directions.",,Cícero A. L. Pahins;Sean A. Stephens;Carlos Scheidegger;João L. D. Comba,Instituto de InformáticaUFRGS;University of Arizona;University of Arizona;Instituto de InformáticaUFRGS,,"Scalability,data cube,multidimensional data,interactive exploration,,,",,10,,
InfoVis,2017,Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement,10.1109/TVCG.2016.2598876,http://dx.doi.org/10.1109/TVCG.2016.2598876,511,520,Journals & Magazines,"Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets.",,Chris Bryan;Kwan-Liu Ma;Jonathan Woodring,"University of California, Davis;University of California, Davis;Los Alamos National Laboratory",,"Narrative visualization,storytelling,annotations,comic strip visualization,time-varying data,,",,7,,
conference_external,2017,Visual Analysis of MOOC Forums with iForum,10.1109/TVCG.2016.2598444,http://dx.doi.org/10.1109/TVCG.2016.2598444,201,210,Journals & Magazines,"Discussion forums of Massive Open Online Courses (MOOC) provide great opportunities for students to interact with instructional staff as well as other students. Exploration of MOOC forum data can offer valuable insights for these staff to enhance the course and prepare the next release. However, it is challenging due to the large, complicated, and heterogeneous nature of relevant datasets, which contain multiple dynamically interacting objects such as users, posts, and threads, each one including multiple attributes. In this paper, we present a design study for developing an interactive visual analytics system, called iForum, that allows for effectively discovering and understanding temporal patterns in MOOC forums. The design study was conducted with three domain experts in an iterative manner over one year, including a MOOC instructor and two official teaching assistants. iForum offers a set of novel visualization designs for presenting the three interleaving aspects of MOOC forums (i.e., posts, users, and threads) at three different scales. To demonstrate the effectiveness and usefulness of iForum, we describe a case study involving field experts, in which they use iForum to investigate real MOOC forum data for a course on JAVA programming.",,Siwei Fu;Jian Zhao;Weiwei Cui;Huamin Qu,Hong Kong University of Science and Technology;Autodesk Research;Microsoft Research;Hong Kong University of Science and Technology,,"Discussion forum,MOOC,temporal visualization,visual analytics,,,",,8,,
conference_external,2017,PhenoStacks: Cross-Sectional Cohort Phenotype Comparison Visualizations,10.1109/TVCG.2016.2598469,http://dx.doi.org/10.1109/TVCG.2016.2598469,191,200,Journals & Magazines,"Cross-sectional phenotype studies are used by genetics researchers to better understand how phenotypes vary across patients with genetic diseases, both within and between cohorts. Analyses within cohorts identify patterns between phenotypes and patients (e.g., co-occurrence) and isolate special cases (e.g., potential outliers). Comparing the variation of phenotypes between two cohorts can help distinguish how different factors affect disease manifestation (e.g., causal genes, age of onset, etc.). PhenoStacks is a novel visual analytics tool that supports the exploration of phenotype variation within and between cross-sectional patient cohorts. By leveraging the semantic hierarchy of the Human Phenotype Ontology, phenotypes are presented in context, can be grouped and clustered, and are summarized via overviews to support the exploration of phenotype distributions. The design of PhenoStacks was motivated by formative interviews with genetics researchers: we distil high-level tasks, present an algorithm for simplifying ontology topologies for visualization, and report the results of a deployment evaluation with four expert genetics researchers. The results suggest that PhenoStacks can help identify phenotype patterns, investigate data quality issues, and inform data collection design.",,Michael Glueck;Alina Gvozdik;Fanny Chevalier;Azam Khan;Michael Brudno;Daniel Wigdor,"Autodesk ResearchUniversity of Toronto;University of Toronto;Inria;Autodesk Research;Hospital for Sick Children, University of Toronto, Toronto;University of Toronto",,"Cross-sectional cohort analysis,Phenotypes,Human Phenotype Ontology (HPO),,,,",,4,,
conference_external,2017,Jacobi Fiber Surfaces for Bivariate Reeb Space Computation,10.1109/TVCG.2016.2599017,http://dx.doi.org/10.1109/TVCG.2016.2599017,960,969,Journals & Magazines,"This paper presents an efficient algorithm for the computation of the Reeb space of an input bivariate piecewise linear scalar function f defined on a tetrahedral mesh. By extending and generalizing algorithmic concepts from the univariate case to the bivariate one, we report the first practical, output-sensitive algorithm for the exact computation of such a Reeb space. The algorithm starts by identifying the Jacobi set of f, the bivariate analogs of critical points in the univariate case. Next, the Reeb space is computed by segmenting the input mesh along the new notion of Jacobi Fiber Surfaces, the bivariate analog of critical contours in the univariate case. We additionally present a simplification heuristic that enables the progressive coarsening of the Reeb space. Our algorithm is simple to implement and most of its computations can be trivially parallelized. We report performance numbers demonstrating orders of magnitude speedups over previous approaches, enabling for the first time the tractable computation of bivariate Reeb spaces in practice. Moreover, unlike range-based quantization approaches (such as the Joint Contour Net), our algorithm is parameter-free. We demonstrate the utility of our approach by using the Reeb space as a semi-automatic segmentation tool for bivariate data. In particular, we introduce continuous scatterplot peeling, a technique which enables the reduction of the cluttering in the continuous scatterplot, by interactively selecting the features of the Reeb space to project. We provide a VTK-based C++ implementation of our algorithm that can be used for reproduction purposes or for the development of new Reeb space based visualization techniques.",,Julien Tierny;Hamish Carr,"Sorbonne Universites, UPMC UnivParis06, CNRS, LIP6 UMR 7606, France;University of Leeds",,"Topological data analysis,multivariate data,data segmentation,,,,",,3,,
InfoVis,2017,Embedded Data Representations,10.1109/TVCG.2016.2598608,http://dx.doi.org/10.1109/TVCG.2016.2598608,461,470,Journals & Magazines,"We introduce embedded data representations, the use of visual and physical representations of data that are deeply integrated with the physical spaces, objects, and entities to which the data refers. Technologies like lightweight wireless displays, mixed reality hardware, and autonomous vehicles are making it increasingly easier to display data in-context. While researchers and artists have already begun to create embedded data representations, the benefits, trade-offs, and even the language necessary to describe and compare these approaches remain unexplored. In this paper, we formalize the notion of physical data referents - the real-world entities and spaces to which data corresponds - and examine the relationship between referents and the visual and physical representations of their data. We differentiate situated representations, which display data in proximity to data referents, and embedded representations, which display data so that it spatially coincides with data referents. Drawing on examples from visualization, ubiquitous computing, and art, we explore the role of spatial indirection, scale, and interaction for embedded representations. We also examine the tradeoffs between non-situated, situated, and embedded data displays, including both visualizations and physicalizations. Based on our observations, we identify a variety of design challenges for embedded data representation, and suggest opportunities for future research and applications.",,Wesley Willett;Yvonne Jansen;Pierre Dragicevic,University of Calgary;University of Copenhagen;Inria,,"Information visualization,data physicalization,ambient displays,ubiquitous computing,augmented reality,,",,9,,
conference_external,2017,Visualizing Shape Deformations with Variation of Geometric Spectrum,10.1109/TVCG.2016.2598790,http://dx.doi.org/10.1109/TVCG.2016.2598790,721,730,Journals & Magazines,"This paper presents a novel approach based on spectral geometry to quantify and visualize non-isometric deformations of 3D surfaces by mapping two manifolds. The proposed method can determine multi-scale, non-isometric deformations through the variation of Laplace-Beltrami spectrum of two shapes. Given two triangle meshes, the spectra can be varied from one to another with a scale function defined on each vertex. The variation is expressed as a linear interpolation of eigenvalues of the two shapes. In each iteration step, a quadratic programming problem is constructed, based on our derived spectrum variation theorem and smoothness energy constraint, to compute the spectrum variation. The derivation of the scale function is the solution of such a problem. Therefore, the final scale function can be solved by integral of the derivation from each step, which, in turn, quantitatively describes non-isometric deformations between two shapes. To evaluate the method, we conduct extensive experiments on synthetic and real data. We employ real epilepsy patient imaging data to quantify the shape variation between the left and right hippocampi in epileptic brains. In addition, we use longitudinal Alzheimer data to compare the shape deformation of diseased and healthy hippocampus. In order to show the accuracy and effectiveness of the proposed method, we also compare it with spatial registration-based methods, e.g., non-rigid Iterative Closest Point (ICP) and voxel-based method. These experiments demonstrate the advantages of our method.",,Jiaxi Hu;Hajar Hamidian;Zichun Zhong;Jing Hua,Wayne State University;Wayne State University;Wayne State University;Wayne State University,,"Geometry-based Technique,Spectral Analysis,Biomedical Visualization,,,,",,0,,
InfoVis,2017,WeightLifter: Visual Weight Space Exploration for Multi-Criteria Decision Making,10.1109/TVCG.2016.2598589,http://dx.doi.org/10.1109/TVCG.2016.2598589,611,620,Journals & Magazines,"A common strategy in Multi-Criteria Decision Making (MCDM) is to rank alternative solutions by weighted summary scores. Weights, however, are often abstract to the decision maker and can only be set by vague intuition. While previous work supports a point-wise exploration of weight spaces, we argue that MCDM can benefit from a regional and global visual analysis of weight spaces. Our main contribution is WeightLifter, a novel interactive visualization technique for weight-based MCDM that facilitates the exploration of weight spaces with up to ten criteria. Our technique enables users to better understand the sensitivity of a decision to changes of weights, to efficiently localize weight regions where a given solution ranks high, and to filter out solutions which do not rank high enough for any plausible combination of weights. We provide a comprehensive requirement analysis for weight-based MCDM and describe an interactive workflow that meets these requirements. For evaluation, we describe a usage scenario of WeightLifter in automotive engineering and report qualitative feedback from users of a deployed version as well as preliminary feedback from decision makers in multiple domains. This feedback confirms that WeightLifter increases both the efficiency of weight-based MCDM and the awareness of uncertainty in the ultimate decisions.",,Stephan Pajer;Marc Streit;Thomas Torsney-Weir;Florian Spechtenhauser;Torsten Möller;Harald Piringer,VRVis Research Center;University Linz;University of Vienna;VRVis Research Center;University of Vienna;VRVis Research Center,,"Visual analysis,decision making,multi-objective optimization,interactive ranking,rank sensitivity,,",,13,,
conference_external,2017,Hybrid Tactile/Tangible Interaction for 3D Data Exploration,10.1109/TVCG.2016.2599217,http://dx.doi.org/10.1109/TVCG.2016.2599217,881,890,Journals & Magazines,"We present the design and evaluation of an interface that combines tactile and tangible paradigms for 3D visualization. While studies have demonstrated that both tactile and tangible input can be efficient for a subset of 3D manipulation tasks, we reflect here on the possibility to combine the two complementary input types. Based on a field study and follow-up interviews, we present a conceptual framework of the use of these different interaction modalities for visualization both separately and combined-focusing on free exploration as well as precise control. We present a prototypical application of a subset of these combined mappings for fluid dynamics data visualization using a portable, position-aware device which offers both tactile input and tangible sensing. We evaluate our approach with domain experts and report on their qualitative feedback.",,Lonni Besançon;Paul Issartel;Mehdi Ammi;Tobias Isenberg,"Inria Saclay, Univ. Paris Saclay, France;Univ. Paris Saclay, France;Limsi/CNRS, France;Inria, France",,"Interaction,tactile input,tangible input,3D data visualization,,,",,5,,
InfoVis,2017,Evaluating the Impact of Binning 2D Scalar Fields,10.1109/TVCG.2016.2599106,http://dx.doi.org/10.1109/TVCG.2016.2599106,431,440,Journals & Magazines,"The expressiveness principle for visualization design asserts that a visualization should encode all of the available data, and only the available data, implying that continuous data types should be visualized with a continuous encoding channel. And yet, in many domains binning continuous data is not only pervasive, but it is accepted as standard practice. Prior work provides no clear guidance for when encoding continuous data continuously is preferable to employing binning techniques or how this choice affects data interpretation and decision making. In this paper, we present a study aimed at better understanding the conditions in which the expressiveness principle can or should be violated for visualizing continuous data. We provided participants with visualizations employing either continuous or binned greyscale encodings of geospatial elevation data and compared participants' ability to complete a wide variety of tasks. For various tasks, the results indicate significant differences in decision making, confidence in responses, and task completion time between continuous and binned encodings of the data. In general, participants with continuous encodings were faster to complete many of the tasks, but never outperformed those with binned encodings, while performance accuracy with binned encodings was superior to continuous encodings in some tasks. These findings suggest that strict adherence to the expressiveness principle is not always advisable. We discuss both the implications and limitations of our results and outline various avenues for potential work needed to further improve guidelines for using continuous versus binned encodings for continuous data types.",,Lace Padilla;P. Samuel Quinan;Miriah Meyer;Sarah H. Creem-Regehr,"Department of Psychology, University of Utah;University of UtahSchool of Computing;University of UtahSchool of Computing;Department of Psychology, University of Utah",,"Geographic/Geospatial Visualization,Qualitative Evaluation,Color Perception,Perceptual Cognition,,,",,9,,
conference_external,2017,GazeDx: Interactive Visual Analytics Framework for Comparative Gaze Analysis with Volumetric Medical Images,10.1109/TVCG.2016.2598796,http://dx.doi.org/10.1109/TVCG.2016.2598796,311,320,Journals & Magazines,"We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients' volumetric CT images.",,Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bohyoung Kim;Jinwook Seo,"Seoul National University;Soongsil University;Samsung Medical Center;Bundang Hospital, Seoul National University;Hankuk University of Foreign Studies;Seoul National University",,"Eye tracking,gaze visualization,gaze pattern comparison,volumetric medical images,context-embedded interactive scatterplot,interactive temporal chart,",,0,,
InfoVis,2017,Towards Unambiguous Edge Bundling: Investigating Confluent Drawings for Network Visualization,10.1109/TVCG.2016.2598958,http://dx.doi.org/10.1109/TVCG.2016.2598958,541,550,Journals & Magazines,"In this paper, we investigate Confluent Drawings (CD), a technique for bundling edges in node-link diagrams based on network connectivity. Edge-bundling techniques are designed to reduce edge clutter in node-link diagrams by coalescing lines into common paths or bundles. Unfortunately, traditional bundling techniques introduce ambiguity since edges are only bundled by spatial proximity, rather than network connectivity; following an edge from its source to its target can lead to the perception of incorrect connectivity if edges are not clearly separated within the bundles. Contrary, CDs bundle edges based on common sources or targets. Thus, a smooth path along a confluent bundle indicates precise connectivity. While CDs have been described in theory, practical investigation and application to real-world networks (i.e., networks beyond those with certain planarity restrictions) is currently lacking. Here, we provide the first algorithm for constructing CDs from arbitrary directed and undirected networks and present a simple layout method, embedded in a sand box environment providing techniques for interactive exploration. We then investigate patterns and artifacts in CDs, which we compare to other common edge-bundling techniques. Finally, we present the first user study that compares edge-compression techniques, including CD, power graphs, metro-style, and common edge bundling. We found that users without particular expertise in visualization or network analysis are able to read small CDs without difficulty. Compared to existing bundling techniques, CDs are more likely to allow people to correctly perceive connectivity.",,Benjamin Bach;Nathalie Henry Riche;Christophe Hurter;Kim Marriott;Tim Dwyer,"Microsoft Research-Inria Joint Centre, France;Microsoft Research, WA, USA;ENAC, Toulouse, France;Monash University, Melbourne, Australia;Monash University, Melbourne, Australia",,"Network visualization,edge compression,confluent,power graph,bundling,,",,10,,
InfoVis,2017,Optimizing Hierarchical Visualizations with the Minimum Description Length Principle,10.1109/TVCG.2016.2598591,http://dx.doi.org/10.1109/TVCG.2016.2598591,631,640,Journals & Magazines,"In this paper we examine how the Minimum Description Length (MDL) principle can be used to efficiently select aggregated views of hierarchical datasets that feature a good balance between clutter and information. We present MDL formulae for generating uneven tree cuts tailored to treemap and sunburst diagrams, taking into account the available display space and information content of the data. We present the results of a proof-of-concept implementation. In addition, we demonstrate how such tree cuts can be used to enhance drill-down interaction in hierarchical visualizations by implementing our approach in an existing visualization tool. Validation is done with the feature congestion measure of clutter in views of a subset of the current DMOZ web directory, which contains nearly half million categories. The results show that MDL views achieve near constant clutter level across display resolutions. We also present the results of a crowdsourced user study where participants were asked to find targets in views of DMOZ generated by our approach and a set of baseline aggregation methods. The results suggest that, in some conditions, participants are able to locate targets (in particular, outliers) faster using the proposed approach.",,Rafael Veras;Christopher Collins,University of OntarioInstitute of Technology;University of OntarioInstitute of Technology,,"Hierarchy data,data aggregation,multiscale visualization,tree cut,antichain,,",,6,,
conference_external,2017,Magnostics: Image-Based Search of Interesting Matrix Views for Guided Network Exploration,10.1109/TVCG.2016.2598467,http://dx.doi.org/10.1109/TVCG.2016.2598467,31,40,Journals & Magazines,"In this work we address the problem of retrieving potentially interesting matrix views to support the exploration of networks. We introduce Matrix Diagnostics (or Magnostics), following in spirit related approaches for rating and ranking other visualization techniques, such as Scagnostics for scatter plots. Our approach ranks matrix views according to the appearance of specific visual patterns, such as blocks and lines, indicating the existence of topological motifs in the data, such as clusters, bi-graphs, or central nodes. Magnostics can be used to analyze, query, or search for visually similar matrices in large collections, or to assess the quality of matrix reordering algorithms. While many feature descriptors for image analyzes exist, there is no evidence how they perform for detecting patterns in matrices. In order to make an informed choice of feature descriptors for matrix diagnostics, we evaluate 30 feature descriptors-27 existing ones and three new descriptors that we designed specifically for MAGNOSTICS-with respect to four criteria: pattern response, pattern variability, pattern sensibility, and pattern discrimination. We conclude with an informed set of six descriptors as most appropriate for Magnostics and demonstrate their application in two scenarios; exploring a large collection of matrices and analyzing temporal networks.",,Michael Behrisch;Benjamin Bach;Michael Hund;Michael Delz;Laura Von Rüden;Jean-Daniel Fekete;Tobias Schreck,"University of Konstanz, Germany;Microsoft Research-Inria Joint Centre, Saclay, France;University of Konstanz, Germany;University of Konstanz, Germany;Capgemini, RWTH Aachen University;Inria, Saclay, France;Graz University of Technology, Austria",,"Matrix Visualization,Visual Quality Measures,Quality Metrics,Feature Detection/Selection,Relational Data,,",,7,,
InfoVis,2017,Quantifying the Visual Impact of Classification Boundaries in Choropleth Maps,10.1109/TVCG.2016.2598541,http://dx.doi.org/10.1109/TVCG.2016.2598541,371,380,Journals & Magazines,"One critical visual task when using choropleth maps is to identify spatial clusters in the data. If spatial units have the same color and are in the same neighborhood, this region can be visually identified as a spatial cluster. However, the choice of classification method used to create the choropleth map determines the visual output. The critical map elements in the classification scheme are those that lie near the classification boundary as those elements could potentially belong to different classes with a slight adjustment of the classification boundary. Thus, these elements have the most potential to impact the visual features (i.e., spatial clusters) that occur in the choropleth map. We present a methodology to enable analysts and designers to identify spatial regions where the visual appearance may be the result of spurious data artifacts. The proposed methodology automatically detects the critical boundary cases that can impact the overall visual presentation of the choropleth map using a classification metric of cluster stability. The map elements that belong to a critical boundary case are then automatically assessed to quantify the visual impact of classification edge effects. Our results demonstrate the impact of boundary elements on the resulting visualization and suggest that special attention should be given to these elements during map design.",,Yifan Zhang;Ross Maciejewski,Arizona State University;Arizona State University,,"Choropleth,Classification,Visualization,Geodemographics,Geovisualization,,",,4,,
conference_external,2017,<italic>PowerSet</italic>: A Comprehensive Visualization of Set Intersections,10.1109/TVCG.2016.2598496,http://dx.doi.org/10.1109/TVCG.2016.2598496,361,370,Journals & Magazines,"When analyzing a large amount of data, analysts often define groups over data elements that share certain properties. Using these groups as the unit of analysis not only reduces the data volume, but also allows detecting various patterns in the data. This involves analyzing intersection relations between these groups, and how the element attributes vary between these intersections. This kind of set-based analysis has various applications in a variety of domains, due to the generic and powerful notion of sets. However, visualizing intersections relations is challenging because their number grows exponentially with the number of sets. We present a novel technique based on Treemaps to provide a comprehensive overview of non-empty intersections in a set system in a scalable way. It enables gaining insight about how elements are distributed across these intersections as well as performing fine-grained analysis to explore and compare their attributes both in overview and in detail. Interaction allows querying and filtering these elements based on their set memberships. We demonstrate how our technique supports various use cases in data exploration and analysis by providing insights into set-based data, beyond the limits of state-of-the-art techniques.",,Bilal Alsallakh;Liu Ren,BOSCH Research;BOSCH Research,,"Set visualization,treemaps,interaction,scalability,,,",,6,,
InfoVis,2017,Surprise! Bayesian Weighting for De-Biasing Thematic Maps,10.1109/TVCG.2016.2598618,http://dx.doi.org/10.1109/TVCG.2016.2598618,651,660,Journals & Magazines,"Thematic maps are commonly used for visualizing the density of events in spatial data. However, these maps can mislead by giving visual prominence to known base rates (such as population densities) or to artifacts of sample size and normalization (such as outliers arising from smaller, and thus more variable, samples). In this work, we adapt Bayesian surprise to generate maps that counter these biases. Bayesian surprise, which has shown promise for modeling human visual attention, weights information with respect to how it updates beliefs over a space of models. We introduce Surprise Maps, a visualization technique that weights event data relative to a set of spatia-temporal models. Unexpected events (those that induce large changes in belief over the model space) are visualized more prominently than those that follow expected patterns. Using both synthetic and real-world datasets, we demonstrate how Surprise Maps overcome some limitations of traditional event maps.",,Michael Correll;Jeffrey Heer,University of Washington;University of Washington,,"Thematic Maps,Bayesian Surprise,Event Visualization,Spatia-temporal data,,,",,3,,
conference_external,2017,A Visual Analytics Approach for Understanding Reasons behind Snowballing and Comeback in MOBA Games,10.1109/TVCG.2016.2598415,http://dx.doi.org/10.1109/TVCG.2016.2598415,211,220,Journals & Magazines,"To design a successful Multiplayer Online Battle Arena (MOBA) game, the ratio of snowballing and comeback occurrences to all matches played must be maintained at a certain level to ensure its fairness and engagement. Although it is easy to identify these two types of occurrences, game developers often find it difficult to determine their causes and triggers with so many game design choices and game parameters involved. In addition, the huge amounts of MOBA game data are often heterogeneous, multi-dimensional and highly dynamic in terms of space and time, which poses special challenges for analysts. In this paper, we present a visual analytics system to help game designers find key events and game parameters resulting in snowballing or comeback occurrences in MOBA game data. We follow a user-centered design process developing the system with game analysts and testing with real data of a trial version MOBA game from NetEase Inc. We apply novel visualization techniques in conjunction with well-established ones to depict the evolution of players' positions, status and the occurrences of events. Our system can reveal players' strategies and performance throughout a single match and suggest patterns, e.g., specific player' actions and game events, that have led to the final occurrences. We further demonstrate a workflow of leveraging human analyzed patterns to improve the scalability and generality of match data analysis. Finally, we validate the usability of our system by proving the identified patterns are representative in snowballing or comeback matches in a one-month-long MOBA tournament dataset.",,Quan Li;Peng Xu;Yeuk Yin Chan;Yun Wang;Zhipeng Wang;Huamin Qu;Xiaojuan Ma,"Hong Kong University of Science and Technology;NetEase, Inc.;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;China Academy of Art;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology",,"Game play data visualization,visual knowledge discovery,visual knowledge representation,and game reconstruction,,,",,5,,
conference_external,2017,Time-Hierarchical Clustering and Visualization of Weather Forecast Ensembles,10.1109/TVCG.2016.2598868,http://dx.doi.org/10.1109/TVCG.2016.2598868,831,840,Journals & Magazines,"We propose a new approach for analyzing the temporal growth of the uncertainty in ensembles of weather forecasts which are started from perturbed but similar initial conditions. As an alternative to traditional approaches in meteorology, which use juxtaposition and animation of spaghetti plots of iso-contours, we make use of contour clustering and provide means to encode forecast dynamics and spread in one single visualization. Based on a given ensemble clustering in a specified time window, we merge clusters in time-reversed order to indicate when and where forecast trajectories start to diverge. We present and compare different visualizations of the resulting time-hierarchical grouping, including space-time surfaces built by connecting cluster representatives over time, and stacked contour variability plots. We demonstrate the effectiveness of our visual encodings with forecast examples of the European Centre for Medium-Range Weather Forecasts, which convey the evolution of specific features in the data as well as the temporally increasing spatial variability.",,Florian Ferstl;Mathias Kanzler;Marc Rautenhaus;Rüdiger Westermann,Technical University of Munich;Technical University of Munich;Technical University of Munich;Technical University of Munich,,"Ensemble visualization,uncertainty visualization,meteorological visualization,iso-contours,time-varying data,clustering,",,10,,
conference_external,2017,SemanticTraj: A New Approach to Interacting with Massive Taxi Trajectories,10.1109/TVCG.2016.2598416,http://dx.doi.org/10.1109/TVCG.2016.2598416,11,20,Journals & Magazines,"Massive taxi trajectory data is exploited for knowledge discovery in transportation and urban planning. Existing tools typically require users to select and brush geospatial regions on a map when retrieving and exploring taxi trajectories and passenger trips. To answer seemingly simple questions such as “What were the taxi trips starting from Main Street and ending at Wall Street in the morning?” or “Where are the taxis arriving at the Art Museum at noon typically coming from?”, tedious and time consuming interactions are usually needed since the numeric GPS points of trajectories are not directly linked to the keywords such as “Main Street”, “Wall Street”, and “Art Museum”. In this paper, we present SemanticTraj, a new method for managing and visualizing taxi trajectory data in an intuitive, semantic rich, and efficient means. With SemanticTraj, domain and public users can find answers to the aforementioned questions easily through direct queries based on the terms. They can also interactively explore the retrieved data in visualizations enhanced by semantic information of the trajectories and trips. In particular, taxi trajectories are converted into taxi documents through a textualization transformation process. This process maps GPS points into a series of street/POI names and pick-up/drop-off locations. It also converts vehicle speeds into user-defined descriptive terms. Then, a corpus of taxi documents is formed and indexed to enable flexible semantic queries over a text search engine. Semantic labels and meta-summaries of the results are integrated with a set of visualizations in a SemanticTraj prototype, which helps users study taxi trajectories quickly and easily. A set of usage scenarios are presented to show the usability of the system. We also collected feedback from domain experts and conducted a preliminary user study to evaluate the visual system.",,Shamal Al-Dohuki;Yingyu Wu;Farah Kamw;Jing Yang;Xin Li;Ye Zhao;Xinyue Ye;Wei Chen;Chao Ma;Fei Wang,Kent State University;Kent State University;Kent State University;UNC Charlotte;China Petroleum University;Kent State University;Kent State University;Zhejiang University;Kent State University;Zhejiang University,,"Taxi Trajectories,Taxi Document,Textualization,Name Query,Semantic Interaction,Text Search Engine,",,26,,
conference_external,2017,Categorical Colormap Optimization with Visualization Case Studies,10.1109/TVCG.2016.2599214,http://dx.doi.org/10.1109/TVCG.2016.2599214,871,880,Journals & Magazines,"Mapping a set of categorical values to different colors is an elementary technique in data visualization. Users of visualization software routinely rely on the default colormaps provided by a system, or colormaps suggested by software such as ColorBrewer. In practice, users often have to select a set of colors in a semantically meaningful way (e.g., based on conventions, color metaphors, and logological associations), and consequently would like to ensure their perceptual differentiation is optimized. In this paper, we present an algorithmic approach for maximizing the perceptual distances among a set of given colors. We address two technical problems in optimization, i.e., (i) the phenomena of local maxima that halt the optimization too soon, and (ii) the arbitrary reassignment of colors that leads to the loss of the original semantic association. We paid particular attention to different types of constraints that users may wish to impose during the optimization process. To demonstrate the effectiveness of this work, we tested this technique in two case studies. To reach out to a wider range of users, we also developed a web application called Colourmap Hospital.",,H. Fang;S. Walton;E. Delahaye;J. Harris;D. A. Storchak;M. Chen,"University of Oxford and International Seismological Centre;University of Oxford, UK;International Seismological Centre, UK;International Seismological Centre, UK;International Seismological Centre, UK;University of Oxford, UK",,"Color,categorical colormap,optimization,seismological data visualization,London tube map,,",,5,,
conference_external,2017,VisMatchmaker: Cooperation of the User and the Computer in Centralized Matching Adjustment,10.1109/TVCG.2016.2599378,http://dx.doi.org/10.1109/TVCG.2016.2599378,231,240,Journals & Magazines,"Centralized matching is a ubiquitous resource allocation problem. In a centralized matching problem, each agent has a preference list ranking the other agents and a central planner is responsible for matching the agents manually or with an algorithm. While algorithms can find a matching which optimizes some performance metrics, they are used as a black box and preclude the central planner from applying his domain knowledge to find a matching which aligns better with the user tasks. Furthermore, the existing matching visualization techniques (i.e. bipartite graph and adjacency matrix) fail in helping the central planner understand the differences between matchings. In this paper, we present VisMatchmaker, a visualization system which allows the central planner to explore alternatives to an algorithm-generated matching. We identified three common tasks in the process of matching adjustment: problem detection, matching recommendation and matching evaluation. We classified matching comparison into three levels and designed visualization techniques for them, including the number line view and the stacked graph view. Two types of algorithmic support, namely direct assignment and range search, and their interactive operations are also provided to enable the user to apply his domain knowledge in matching adjustment.",,Po-Ming Law;Wenchao Wu;Yixian Zheng;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,,"Centralized matching,matching visualization,interaction techniques,visual analytics,,,",,1,,
conference_external,2017,Familiarity Vs Trust: A Comparative Study of Domain Scientists' Trust in Visual Analytics and Conventional Analysis Methods,10.1109/TVCG.2016.2598544,http://dx.doi.org/10.1109/TVCG.2016.2598544,271,280,Journals & Magazines,"Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts' trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems.",,Aritra Dasgupta;Joon-Yong Lee;Ryan Wilson;Robert A. Lafrance;Nick Cramer;Kristin Cook;Samuel Payne,Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory,,"trust,transparency,familiarity,uncertainty,biological data analysis,,",,6,,
conference_external,2017,Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations,10.1109/TVCG.2016.2598543,http://dx.doi.org/10.1109/TVCG.2016.2598543,261,270,Journals & Magazines,"User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst's manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas.",,Jian Zhao;Michael Glueck;Simon Breslav;Fanny Chevalier;Azam Khan,Autodesk Research;Autodesk Research;Autodesk Research;INRIA;Autodesk Research,,"Externalization user-authored annotation,exploratory sequential data analysis,graph-based visualization,,,,",,8,,
conference_external,2017,NameClarifier: A Visual Analytics System for Author Name Disambiguation,10.1109/TVCG.2016.2598465,http://dx.doi.org/10.1109/TVCG.2016.2598465,141,150,Journals & Magazines,"In this paper, we present a novel visual analytics system called NameClarifier to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, NameClarifier quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of NameClarifier.",,Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research,,"Name disambiguation,analytical reasoning,,,,,",,6,,
conference_external,2017,A Visual Analytics Approach for Categorical Joint Distribution Reconstruction from Marginal Projections,10.1109/TVCG.2016.2598479,http://dx.doi.org/10.1109/TVCG.2016.2598479,51,60,Journals & Magazines,"Oftentimes multivariate data are not available as sets of equally multivariate tuples, but only as sets of projections into subspaces spanned by subsets of these attributes. For example, one may find data with five attributes stored in six tables of two attributes each, instead of a single table of five attributes. This prohibits the visualization of these data with standard high-dimensional methods, such as parallel coordinates or MDS, and there is hence the need to reconstruct the full multivariate (joint) distribution from these marginal ones. Most of the existing methods designed for this purpose use an iterative procedure to estimate the joint distribution. With insufficient marginal distributions and domain knowledge, they lead to results whose joint errors can be large. Moreover, enforcing smoothness for regularizations in the joint space is not applicable if the attributes are not numerical but categorical. We propose a visual analytics approach that integrates both anecdotal data and human experts to iteratively narrow down a large set of plausible solutions. The solution space is populated using a Monte Carlo procedure which uniformly samples the solution space. A level-of-detail high dimensional visualization system helps the user understand the patterns and the uncertainties. Constraints that narrow the solution space can then be added by the user interactively during the iterative exploration, and eventually a subset of solutions with narrow uncertainty intervals emerges.",,Cong Xie;Wen Zhong;Klaus Mueller,"Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University",,"Joint Distribution Reconstruction,Solution Space,High-dimensional Data,Multivariate Data,Parallel Coordinates,,",,9,,
conference_external,2017,V<sc>iz</sc>I<sc>t</sc>C<sc>ards</sc>: A Card-Based Toolkit for Infovis Design Education,10.1109/TVCG.2016.2599338,http://dx.doi.org/10.1109/TVCG.2016.2599338,561,570,Journals & Magazines,"Shifts in information visualization practice are forcing a reconsideration of how infovis is taught. Traditional curricula that focused on conveying research-derived knowledge are slowly integrating design thinking as a key learning objective. In part, this is motivated by the realization that infovis is a wicked design problem, requiring a different kind of design work. In this paper we describe, VizItCards, a card-driven workshop developed for our graduate infovis class. The workshop is intended to provide practice with good design techniques and to simultaneously reinforce key concepts. VizItCards relies on principles of collaborative-learning and research on parallel design to generate positive collaborations and high-quality designs. From our experience of simulating a realistic design scenario in a classroom setting, we find that our students were able to meet key learning objectives and their design performance improved during the class. We describe variants of the workshop, discussing which techniques we think match to which learning goals.",,Shiqing He;Eytan Adar,School of Information at the University of Michigan;School of Information at the University of Michigan,,"information visualization education,peer learning,toolkit,card,design workshop,,",,5,,
conference_external,2017,TopicLens: Efficient Multi-Level Visual Topic Exploration of Large-Scale Document Collections,10.1109/TVCG.2016.2598445,http://dx.doi.org/10.1109/TVCG.2016.2598445,151,160,Journals & Magazines,"Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its significant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workflow. Instead, most such systems are limited to utilizing a fixed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called TopicLens that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efficiently computed on the fly. To support this interaction in real time while maintaining view consistency, we propose a novel efficient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with TopicLens. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of TopicLens using real-world datasets.",,Minjeong Kim;Kyeongpil Kang;Deokgun Park;Jaegul Choo;Niklas Elmqvist,"Korea University;Korea University;University of Maryland, College Park, MD, USA;Korea University;University of Maryland, College Park, MD, USA",,"topic modeling,nonnegative matrix factorization,t-distributed stochastic neighbor embedding,magic lens,text analytics,,",,12,,
conference_external,2017,Blockwise Human Brain Network Visual Comparison Using NodeTrix Representation,10.1109/TVCG.2016.2598472,http://dx.doi.org/10.1109/TVCG.2016.2598472,181,190,Journals & Magazines,"Visually comparing human brain networks from multiple population groups serves as an important task in the field of brain connectomics. The commonly used brain network representation, consisting of nodes and edges, may not be able to reveal the most compelling network differences when the reconstructed networks are dense and homogeneous. In this paper, we leveraged the block information on the Region Of Interest (ROI) based brain networks and studied the problem of blockwise brain network visual comparison. An integrated visual analytics framework was proposed. In the first stage, a two-level ROI block hierarchy was detected by optimizing the anatomical structure and the predictive comparison performance simultaneously. In the second stage, the NodeTrix representation was adopted and customized to visualize the brain network with block information. We conducted controlled user experiments and case studies to evaluate our proposed solution. Results indicated that our visual analytics method outperformed the commonly used node-link graph and adjacency matrix design in the blockwise network comparison tasks. We have shown compelling findings from two real-world brain network data sets, which are consistent with the prior connectomics studies.",,Xinsong Yang;Lei Shi;Madelaine Daianu;Hanghang Tong;Qingsong Liu;Paul Thompson,"Chinese Academy of Sciences, SKLCSInstitute of Software;Chinese Academy of Sciences, SKLCSInstitute of Software;Imaging Genetics CenterMark &#x0026; Mary Stevens Institute for Neuroimaging &#x0026; InformaticsUniversity of Southern California;School of Computing, Informatics and Decision Systems EngineeringArizona State University;Chinese Academy of Sciences, SKLCSInstitute of Software;Imaging Genetics CenterMark &#x0026; Mary Stevens Institute for Neuroimaging &#x0026; InformaticsUniversity of Southern California",,"Brain Network,Visual Comparison,Hybrid Representation,,,,",,11,,
InfoVis,2017,Gaussian Cubes: Real-Time Modeling for Visual Exploration of Large Multidimensional Datasets,10.1109/TVCG.2016.2598694,http://dx.doi.org/10.1109/TVCG.2016.2598694,681,690,Journals & Magazines,"Recently proposed techniques have finally made it possible for analysts to interactively explore very large datasets in real time. However powerful, the class of analyses these systems enable is somewhat limited: specifically, one can only quickly obtain plots such as histograms and heatmaps. In this paper, we contribute Gaussian Cubes, which significantly improves on state-of-the-art systems by providing interactive modeling capabilities, which include but are not limited to linear least squares and principal components analysis (PCA). The fundamental insight in Gaussian Cubes is that instead of precomputing counts of many data subsets (as state-of-the-art systems do), Gaussian Cubes precomputes the best multivariate Gaussian for the respective data subsets. As an example, Gaussian Cubes can fit hundreds of models over millions of data points in well under a second, enabling novel types of visual exploration of such large datasets. We present three case studies that highlight the visualization and analysis capabilities in Gaussian Cubes, using earthquake safety simulations, astronomical catalogs, and transportation statistics. The dataset sizes range around one hundred million elements and 5 to 10 dimensions. We present extensive performance results, a discussion of the limitations in Gaussian Cubes, and future research directions.",,Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger,University of Arizona;Universidade Federal de Pernambuco;University of Arizona;University of Arizona;University of Arizona,,"Data modeling,dimensionality reduction,interactive visualization,data cubes,,,",,10,,
InfoVis,2017,Data-Driven Guides: Supporting Expressive Design for Information Graphics,10.1109/TVCG.2016.2598620,http://dx.doi.org/10.1109/TVCG.2016.2598620,491,500,Journals & Magazines,"In recent years, there is a growing need for communicating complex data in an accessible graphical form. Existing visualization creation tools support automatic visual encoding, but lack flexibility for creating custom design; on the other hand, freeform illustration tools require manual visual encoding, making the design process time-consuming and error-prone. In this paper, we present Data-Driven Guides (DDG), a technique for designing expressive information graphics in a graphic design environment. Instead of being confined by predefined templates or marks, designers can generate guides from data and use the guides to draw, place and measure custom shapes. We provide guides to encode data using three fundamental visual encoding channels: length, area, and position. Users can combine more than one guide to construct complex visual structures and map these structures to data. When underlying data is changed, we use a deformation technique to transform custom shapes using the guides as the backbone of the shapes. Our evaluation shows that data-driven guides allow users to create expressive and more accurate custom data-driven graphics.",,Nam Wook Kim;Eston Schweickart;Zhicheng Liu;Mira Dontcheva;Wilmot Li;Jovan Popovic;Hanspeter Pfister,"John A. Paulson School of Engineering and Applied SciencesHarvard University;Computer Science department, Cornell University;Adobe Research;Adobe Research;Adobe Research;Adobe Research;John A. Paulson School of Engineering and Applied SciencesHarvard University",,"Information graphics,visualization,design tools,2D graphics,,,",,10,,
conference_external,2017,PelVis: Atlas-based Surgical Planning for Oncological Pelvic Surgery,10.1109/TVCG.2016.2598826,http://dx.doi.org/10.1109/TVCG.2016.2598826,741,750,Journals & Magazines,"Due to the intricate relationship between the pelvic organs and vital structures, such as vessels and nerves, pelvic anatomy is often considered to be complex to comprehend. In oncological pelvic surgery, a trade-off has to be made between complete tumor resection and preserving function by preventing damage to the nerves. Damage to the autonomic nerves causes undesirable post-operative side-effects such as fecal and urinal incontinence, as well as sexual dysfunction in up to 80 percent of the cases. Since these autonomic nerves are not visible in pre-operative MRI scans or during surgery, avoiding nerve damage during such a surgical procedure becomes challenging. In this work, we present visualization methods to represent context, target, and risk structures for surgical planning. We employ distance-based and occlusion management techniques in an atlas-based surgical planning tool for oncological pelvic surgery. Patient-specific pre-operative MRI scans are registered to an atlas model that includes nerve information. Through several interactive linked views, the spatial relationships and distances between the organs, tumor and risk zones are visualized to improve understanding, while avoiding occlusion. In this way, the surgeon can examine surgically relevant structures and plan the procedure before going into the operating theater, thus raising awareness of the autonomic nerve zone regions and potentially reducing post-operative complications. Furthermore, we present the results of a domain expert evaluation with surgical oncologists that demonstrates the advantages of our approach.",,Noeska Smit;Kai Lawonn;Annelot Kraima;Marco DeRuiter;Hessam Sokooti;Stefan Bruckner;Elmar Eisemann;Anna Vilanova,"Delft University of TechnologyUniversity of Bergen;University of Koblenz, Landau;Leiden University Medical Center;Leiden University Medical Center;Leiden University Medical Center;University of Bergen;Delft University of Technology;Delft University of Technology",,"Atlas,surgical planning,medical visualization,,,,",,3,,
conference_external,2017,OSPRay - A CPU Ray Tracing Framework for Scientific Visualization,10.1109/TVCG.2016.2599041,http://dx.doi.org/10.1109/TVCG.2016.2599041,931,940,Journals & Magazines,"Scientific data is continually increasing in complexity, variety and size, making efficient visualization and specifically rendering an ongoing challenge. Traditional rasterization-based visualization approaches encounter performance and quality limitations, particularly in HPC environments without dedicated rendering hardware. In this paper, we present OSPRay, a turn-key CPU ray tracing framework oriented towards production-use scientific visualization which can utilize varying SIMD widths and multiple device backends found across diverse HPC resources. This framework provides a high-quality, efficient CPU-based solution for typical visualization workloads, which has already been integrated into several prevalent visualization packages. We show that this system delivers the performance, high-level API simplicity, and modular device support needed to provide a compelling new rendering framework for implementing efficient scientific visualization workflows.",,I Wald;GP Johnson;J Amstutz;C Brownlee;A Knoll;J Jeffers;J Günther;P Navratil,Intel Corp;Intel Corp;Intel Corp;Intel Corp;SCI InsituteUniversity of Utah;Intel Corp;Intel Corp;Texas Advanced Computing Center,,",,,,,,",,12,,
InfoVis,2017,The Attraction Effect in Information Visualization,10.1109/TVCG.2016.2598594,http://dx.doi.org/10.1109/TVCG.2016.2598594,471,480,Journals & Magazines,"The attraction effect is a well-studied cognitive bias in decision making research, where one's choice between two alternatives is influenced by the presence of an irrelevant (dominated) third alternative. We examine whether this cognitive bias, so far only tested with three alternatives and simple presentation formats such as numerical tables, text and pictures, also appears in visualizations. Since visualizations can be used to support decision making - e.g., when choosing a house to buy or an employee to hire - a systematic bias could have important implications. In a first crowdsource experiment, we indeed partially replicated the attraction effect with three alternatives presented as a numerical table, and observed similar effects when they were presented as a scatterplot. In a second experiment, we investigated if the effect extends to larger sets of alternatives, where the number of alternatives is too large for numerical tables to be practical. Our findings indicate that the bias persists for larger sets of alternatives presented as scatterplots. We discuss implications for future research on how to further study and possibly alleviate the attraction effect.",,Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic,"Inria and Universit&#x00E9; Paris-Saclay;Inria, Univ Paris-Sud &#x0026; CNRS (LRI)Universit&#x00E9; Paris-Saclay;Inria and Universit&#x00E9; Paris-Saclay",,"Information visualization,decision-making,decoy effect,attraction effect,asymmetric dominance effect,cognitive bias,",,16,,
conference_external,2017,Towards Better Analysis of Deep Convolutional Neural Networks,10.1109/TVCG.2016.2598831,http://dx.doi.org/10.1109/TVCG.2016.2598831,91,100,Journals & Magazines,"Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.",,Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu;Shixia Liu,"School of Software and TNListTsinghua University;Dept. of Comp. Sci. &#x0026; Tech., State Key Lab of Intell. Tech. &#x0026; Sys.TNList LabCBICR Center;School of Software and TNListTsinghua University;Dept. of Comp. Sci. &#x0026; Tech., State Key Lab of Intell. Tech. &#x0026; Sys.TNList LabCBICR Center;School of Software and TNListTsinghua University;School of Software and TNListTsinghua University",,"Deep convolutional neural networks,rectangle packing,matrix reordering,edge bundling,biclustering,,",,56,,
conference_external,2017,Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution,10.1109/TVCG.2016.2598789,http://dx.doi.org/10.1109/TVCG.2016.2598789,711,720,Journals & Magazines,"Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer's fitness for use in classrooms.",,Chris Bryan;Gregory Guterman;Kwan-Liu Ma;Harris Lewin;Denis Larkin;Jaebum Kim;Jian Ma;Marta Farré,"University of California, Davis;University of California, Davis;University of California, Davis;University of California, Davis;Royal Veterinary College, University of London;Konkuk University, Seoul;Carnegie Mellon University;Royal Veterinary College, University of London",,"Bioinformatic visualization,education,learning,genome evolution,chromosome,user study,",,2,,
conference_external,2017,A Grammar-based Approach for Modeling User Interactions and Generating Suggestions During the Data Exploration Process,10.1109/TVCG.2016.2598471,http://dx.doi.org/10.1109/TVCG.2016.2598471,41,50,Journals & Magazines,"Despite the recent popularity of visual analytics focusing on big data, little is known about how to support users that use visualization techniques to explore multi-dimensional datasets and accomplish specific tasks. Our lack of models that can assist end-users during the data exploration process has made it challenging to learn from the user's interactive and analytical process. The ability to model how a user interacts with a specific visualization technique and what difficulties they face are paramount in supporting individuals with discovering new patterns within their complex datasets. This paper introduces the notion of visualization systems understanding and modeling user interactions with the intent of guiding a user through a task thereby enhancing visual data exploration. The challenges faced and the necessary future steps to take are discussed; and to provide a working example, a grammar-based model is presented that can learn from user interactions, determine the common patterns among a number of subjects using a K-Reversible algorithm, build a set of rules, and apply those rules in the form of suggestions to new users with the goal of guiding them along their visual analytic process. A formal evaluation study with 300 subjects was performed showing that our grammar-based model is effective at capturing the interactive process followed by users and that further research in this area has the potential to positively impact how users interact with a visualization system.",,Filip Dabek;Jesus J Caban,"National Intrepid Center of Excellence, Walter Reed National Military Medical Center, Bethesda, MD;National Intrepid Center of Excellence, Walter Reed National Military Medical Center, Bethesda, MD",,"Visual Analytics,User Interactions,Analytic Provenance,Machine Learning,,,",,6,,
InfoVis,2017,An Evaluation of Visual Search Support in Maps,10.1109/TVCG.2016.2598898,http://dx.doi.org/10.1109/TVCG.2016.2598898,421,430,Journals & Magazines,"Visual search can be time-consuming, especially if the scene contains a large number of possibly relevant objects. An instance of this problem is present when using geographic or schematic maps with many different elements representing cities, streets, sights, and the like. Unless the map is well-known to the reader, the full map or at least large parts of it must be scanned to find the elements of interest. In this paper, we present a controlled eye-tracking study (30 participants) to compare four variants of map annotation with labels: within-image annotations, grid reference annotation, directional annotation, and miniature annotation. Within-image annotation places labels directly within the map without any further search support. Grid reference annotation corresponds to the traditional approach known from atlases. Directional annotation utilizes a label in combination with an arrow pointing in the direction of the label within the map. Miniature annotation shows a miniature grid to guide the reader to the area of the map in which the label is located. The study results show that within-image annotation is outperformed by all other annotation approaches. Best task completion times are achieved with miniature annotation. The analysis of eye-movement data reveals that participants applied significantly different visual task solution strategies for the different visual annotations.",,Rudolf Netzel;Marcel Hlawatsch;Michael Burch;Sanjeev Balakrishnan;Hansjörg Schmauder;Daniel Weiskopf,"VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart",,"Visual search,laboratory study,eye tracking,map visualization,,,",,5,,
conference_external,2017,Combined Visualization of Vessel Deformation and Hemodynamics in Cerebral Aneurysms,10.1109/TVCG.2016.2598795,http://dx.doi.org/10.1109/TVCG.2016.2598795,761,770,Journals & Magazines,"We present the first visualization tool that combines patient-specific hemodynamics with information about the vessel wall deformation and wall thickness in cerebral aneurysms. Such aneurysms bear the risk of rupture, whereas their treatment also carries considerable risks for the patient. For the patient-specific rupture risk evaluation and treatment analysis, both morphological and hemodynamic data have to be investigated. Medical researchers emphasize the importance of analyzing correlations between wall properties such as the wall deformation and thickness, and hemodynamic attributes like the Wall Shear Stress and near-wall flow. Our method uses a linked 2.5D and 3D depiction of the aneurysm together with blood flow information that enables the simultaneous exploration of wall characteristics and hemodynamic attributes during the cardiac cycle. We thus offer medical researchers an effective visual exploration tool for aneurysm treatment risk assessment. The 2.5D view serves as an overview that comprises a projection of the vessel surface to a 2D map, providing an occlusion-free surface visualization combined with a glyph-based depiction of the local wall thickness. The 3D view represents the focus upon which the data exploration takes place. To support the time-dependent parameter exploration and expert collaboration, a camera path is calculated automatically, where the user can place landmarks for further exploration of the properties. We developed a GPU-based implementation of our visualizations with a flexible interactive data exploration mechanism. We designed our techniques in collaboration with domain experts, and provide details about the evaluation.",,Monique Meuschke;Samuel Voss;Oliver Beuing;Bernhard Preim;Kai Lawonn,"University of Magdeburg, Germany;University of Magdeburg, Germany;University of Magdeburg, Germany;University of Magdeburg, Germany;University of Koblenz-Landau, Germany",,"Medical visualizations,aneurysms,blood flow,wall thickness,wall deformation,projections,",,4,,
conference_external,2017,Glyphs for General Second-Order 2D and 3D Tensors,10.1109/TVCG.2016.2598998,http://dx.doi.org/10.1109/TVCG.2016.2598998,980,989,Journals & Magazines,"Glyphs are a powerful tool for visualizing second-order tensors in a variety of scientic data as they allow to encode physical behavior in geometric properties. Most existing techniques focus on symmetric tensors and exclude non-symmetric tensors where the eigenvectors can be non-orthogonal or complex. We present a new construction of 2d and 3d tensor glyphs based on piecewise rational curves and surfaces with the following properties: invariance to (a) isometries and (b) scaling, (c) direct encoding of all real eigenvalues and eigenvectors, (d) one-to-one relation between the tensors and glyphs, (e) glyph continuity under changing the tensor. We apply the glyphs to visualize the Jacobian matrix fields of a number of 2d and 3d vector fields.",,Tim Gerrits;Christian Rössl;Holger Theisel,"Visual Computing group at the University of Magdeburg, Germany;Visual Computing group at the University of Magdeburg, Germany;Visual Computing group at the University of Magdeburg, Germany",,"Glyph-based Techniques,Tensor Field Data,Flow Visualization,,,,",,2,,
conference_external,2017,Molecular Surface Maps,10.1109/TVCG.2016.2598824,http://dx.doi.org/10.1109/TVCG.2016.2598824,701,710,Journals & Magazines,"We present Molecular Surface Maps, a novel, view-independent, and concise representation for molecular surfaces. It transfers the well-known world map metaphor to molecular visualization. Our application maps the complex molecular surface to a simple 2D representation through a spherical intermediate, the Molecular Surface Globe. The Molecular Surface Map concisely shows arbitrary attributes of the original molecular surface, such as biochemical properties or geometrical features. This results in an intuitive overview, which allows researchers to assess all molecular surface attributes at a glance. Our representation can be used as a visual summarization of a molecule's interface with its environment. In particular, Molecular Surface Maps simplify the analysis and comparison of different data sets or points in time. Furthermore, the map representation can be used in a Space-time Cube to analyze time-dependent data from molecular simulations without the need for animation. We show the feasibility of Molecular Surface Maps for different typical analysis tasks of biomolecular data.",,Michael Krone;Florian Frieß;Katrin Scharnowski;Guido Reina;Silvia Fademrecht;Tobias Kulschewski;Jürgen Pleiss;Thomas Ertl,"Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany",,"Molecular Visualization,Maps,Cartography,Data Aggregation,Dimensionality Reduction,Space-time Cube,",,6,,
conference_external,2017,GlyphLens: View-Dependent Occlusion Management in the Interactive Glyph Visualization,10.1109/TVCG.2016.2599049,http://dx.doi.org/10.1109/TVCG.2016.2599049,891,900,Journals & Magazines,"Glyph as a powerful multivariate visualization technique is used to visualize data through its visual channels. To visualize 3D volumetric dataset, glyphs are usually placed on 2D surface, such as the slicing plane or the feature surface, to avoid occluding each other. However, the 3D spatial structure of some features may be missing. On the other hand, placing large number of glyphs over the entire 3D space results in occlusion and visual clutter that make the visualization ineffective. To avoid the occlusion, we propose a view-dependent interactive 3D lens that removes the occluding glyphs by pulling the glyphs aside through the animation. We provide two space deformation models and two lens shape models to displace the glyphs based on their spatial distributions. After the displacement, the glyphs around the user-interested region are still visible as the context information, and their spatial structures are preserved. Besides, we attenuate the brightness of the glyphs inside the lens based on their depths to provide more depth cue. Furthermore, we developed an interactive glyph visualization system to explore different glyph-based visualization applications. In the system, we provide a few lens utilities that allows users to pick a glyph or a feature and look at it from different view directions. We compare different display/interaction techniques to visualize/manipulate our lens and glyphs.",,Xin Tong;Cheng Li;Han-Wei Shen,The Ohio State University;The Ohio State University;The Ohio State University,,"View-dependent visualization,focus + context techniques,manipulation and deformation,glyph-based techniques,human-computer interaction,,",,4,,
InfoVis,2017,Probabilistic Graph Layout for Uncertain Network Visualization,10.1109/TVCG.2016.2598919,http://dx.doi.org/10.1109/TVCG.2016.2598919,531,540,Journals & Magazines,"We present a novel uncertain network visualization technique based on node-link diagrams. Nodes expand spatially in our probabilistic graph layout, depending on the underlying probability distributions of edges. The visualization is created by computing a two-dimensional graph embedding that combines samples from the probabilistic graph. A Monte Carlo process is used to decompose a probabilistic graph into its possible instances and to continue with our graph layout technique. Splatting and edge bundling are used to visualize point clouds and network topology. The results provide insights into probability distributions for the entire network-not only for individual nodes and edges. We validate our approach using three data sets that represent a wide range of network types: synthetic data, protein-protein interactions from the STRING database, and travel times extracted from Google Maps. Our approach reveals general limitations of the force-directed layout and allows the user to recognize that some nodes of the graph are at a specific position just by chance.",,Christoph Schulz;Arlind Nocaj;Jochen Goertler;Oliver Deussen;Ulrik Brandes;Daniel Weiskopf,VISUSUniversity of Stuttgart;University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;VISUSUniversity of Stuttgart,,"Uncertainty visualization,graph layout,graph visualization,edge bundling,Monte Carlo method,,",,10,,
conference_external,2017,Multi-Resolution Climate Ensemble Parameter Analysis with Nested Parallel Coordinates Plots,10.1109/TVCG.2016.2598830,http://dx.doi.org/10.1109/TVCG.2016.2598830,81,90,Journals & Magazines,"Due to the uncertain nature of weather prediction, climate simulations are usually performed multiple times with different spatial resolutions. The outputs of simulations are multi-resolution spatial temporal ensembles. Each simulation run uses a unique set of values for multiple convective parameters. Distinct parameter settings from different simulation runs in different resolutions constitute a multi-resolution high-dimensional parameter space. Understanding the correlation between the different convective parameters, and establishing a connection between the parameter settings and the ensemble outputs are crucial to domain scientists. The multi-resolution high-dimensional parameter space, however, presents a unique challenge to the existing correlation visualization techniques. We present Nested Parallel Coordinates Plot (NPCP), a new type of parallel coordinates plots that enables visualization of intra-resolution and inter-resolution parameter correlations. With flexible user control, NPCP integrates superimposition, juxtaposition and explicit encodings in a single view for comparative data visualization and analysis. We develop an integrated visual analytics system to help domain scientists understand the connection between multi-resolution convective parameters and the large spatial temporal ensembles. Our system presents intricate climate ensembles with a comprehensive overview and on-demand geographic details. We demonstrate NPCP, along with the climate ensemble visualization system, based on real-world use-cases from our collaborators in computational and predictive science.",,Junpeng Wang;Xiaotong Liu;Han-Wei Shen;Guang Lin,The Ohio State University;The Ohio State University;The Ohio State University;Purdue University,,"Parallel coordinates plots,parameter analysis,multi-resolution climate ensembles,,,,",,13,,
conference_external,2017,Preface,10.1109/TVCG.2016.2599300,http://dx.doi.org/10.1109/TVCG.2016.2599300,xi,xv,Journals & Magazines,"The papers in this special issue were presented at IEEE VIS 2016, held during October 23-28, 2016 in Baltimore, MD. VIS contains three conferences, held concurrently: the IEEE Visual Analytics Science and Technology Conference (IEEE VAST 2016), the IEEE Information Visualization Conference (IEEE InfoVis 2016), and the IEEE Scientific Visualization Conference (IEEE SciVis2016). ",,Gennady Andrienko;Shixia Liu;John Stasko;Niklas Elmqvist;Bongshin Lee;Kwan-Liu Ma;James Ahrens;Robert M. Kirby;Jos Roerdink,"VAST, Fraunhofer Institute IAIS, City University, London;VAST, Tsinghua University;VAST, Georgia Institute of Technology;InfoVis, University of Maryland, College Park;InfoVis, Microsoft Research;InfoVis, University of California, Davis;SciVis, Los Alamos National Laboratory;SciVis, University of Utah;SciVis, University of Groningen",,",,,,,,",,0,,
conference_external,2017,Message from the Editor-in-Chief,10.1109/TVCG.2016.2599299,http://dx.doi.org/10.1109/TVCG.2016.2599299,x,x,Journals & Magazines,Presents the message from the editor-in-chief for this issue of the publication.  ,,Leila De Floriani,University of Genova,,",,,,,,",,0,,
conference_external,2017,Contents,10.1109/TVCG.2016.2599309,http://dx.doi.org/10.1109/TVCG.2016.2599309,iii,ix,Journals & Magazines,Presents the table of contents for this issue of the publication.,,,,,",,,,,,",,0,,
conference_external,2017,VIS Conference Committee,10.1109/TVCG.2016.2599311,http://dx.doi.org/10.1109/TVCG.2016.2599311,xvii,xvii,Journals & Magazines,Provides a listing of the IEEE VIS 2016 conference committee members.,,,,,",,,,,,",,0,,
conference_external,2017,Committee,10.1109/TVCG.2016.2599308,http://dx.doi.org/10.1109/TVCG.2016.2599308,xx,xx,Journals & Magazines,Provides a listing of the IEEE VIS 2016 conference committee members.,,,,,",,,,,,",,0,,
conference_external,2017,IEEE Visualization and Graphics Technical Committee (VGTC),10.1109/TVCG.2016.2599310,http://dx.doi.org/10.1109/TVCG.2016.2599310,xvi,xvi,Journals & Magazines,Provides a listing of the Technical Committee members for this issue of the publication.,,Cláudio T. Silva,VGTC,,",,,,,,",,0,,
conference_external,2017,Committee,10.1109/TVCG.2016.2599312,http://dx.doi.org/10.1109/TVCG.2016.2599312,xviii,xix,Journals & Magazines,Provides a listing of the IEEE VIS 2016 conference committee members.,,,,,",,,,,,",,0,,
conference_external,2017,IEEE Transactions on Visualization and Computer Graphics,10.1109/TVCG.2016.2599304,http://dx.doi.org/10.1109/TVCG.2016.2599304,1,1,Journals & Magazines,Presents the inside cover for this issue of the publication.,,,,,",,,,,,",,0,,
conference_external,2017,Author Index,10.1109/TVCG.2016.2618199,http://dx.doi.org/10.1109/TVCG.2016.2618199,xxvi,xxvii,Journals & Magazines,Presents the author index for this issue of the publication.,,,,,",,,,,,",,0,,
conference_external,2017,The 2016 Visualization Technical Achievement Award,10.1109/TVCG.2016.2599302,http://dx.doi.org/10.1109/TVCG.2016.2599302,xxv,xxv,Journals & Magazines,"The 2016 Visualization Technical Achievement Award goes to David Ebert in recognition of foundational work in visual analytics, both through development of fundamental predictive techniques and as Director of the Purdue/DHS Visual Analytics Center of Excellence.",,David Ebert,Purdue University,,",,,,,,",,0,,
conference_external,2017,Paper Reviewers,10.1109/TVCG.2016.2599301,http://dx.doi.org/10.1109/TVCG.2016.2599301,xxi,xxiii,Journals & Magazines,Presents a listing of the reviewers who contributed to this issue of the publication.,,,,,",,,,,,",,0,,
conference_external,2017,The 2016 Visualization Career Award,10.1109/TVCG.2016.2599298,http://dx.doi.org/10.1109/TVCG.2016.2599298,xxiv,xxiv,Journals & Magazines,"The 2016 Visualization Career Award goes to John Dill in recognition of major industrial and academic research advances spanning CAE/CAD, HCI, and data visualization as well as organizational leadership that helped develop the field of visual analytics.",,John Dill,Simon Fraser University,,",,,,,,",,0,,
